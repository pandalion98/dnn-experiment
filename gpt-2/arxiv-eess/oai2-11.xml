<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T07:11:35Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|10001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08186</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08186</id><created>2019-09-10</created><authors><author><keyname>Fish</keyname><forenames>Ryan</forenames></author><author><keyname>Liang</keyname><forenames>Youzhi</forenames></author><author><keyname>Saleeby</keyname><forenames>Kyle</forenames></author><author><keyname>Spirnak</keyname><forenames>Jonathan</forenames></author><author><keyname>Sun</keyname><forenames>Mingxiu</forenames></author><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author></authors><title>Dynamic Characterization of Arrows through Stochastic Perturbation</title><categories>eess.SY cs.SY</categories><comments>6 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current arrow spine measurements rely on statically hanging a known weight at
the shaft center and measuring the maximum deflection. This archaic method of
measuring arrow stiffness ignores dynamic nature of the arrow when released
from the bow. For this project, we built an apparatus to measure the dynamic
characteristics of the arrow to better indicate arrow performance. Using
stochastic perturbations from a voice coil actuator and displacement
measurements, we successfully estimated the natural frequency, damping
parameter, and mechanical stiffness of carbon, wood, and aluminum arrows of
varying spines. Parameter estimates using a second order parameterized model
showed agreement with the manufacturer rated spine values. In addition, high
cycle fatigue testing was completed on each arrow material but showed no
significant changes in arrow parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08188</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08188</id><created>2019-09-17</created><authors><author><keyname>Amari</keyname><forenames>Abdelkerim</forenames></author><author><keyname>Lin</keyname><forenames>Xiang</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Fiber Nonlinearity Mitigation via the Parzen Window Classifier for
  Dispersion Managed and Unmanaged Links</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><comments>4 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning techniques have recently received significant attention as
promising approaches to deal with the optical channel impairments, and in
particular, the nonlinear effects. In this work, a machine learning-based
classification technique, known as the Parzen window (PW) classifier, is
applied to mitigate the nonlinear effects in the optical channel. The PW
classifier is used as a detector with improved nonlinear decision boundaries
more adapted to the nonlinear fiber channel. Performance improvement is
observed when applying the PW in the context of dispersion managed and
dispersion unmanaged systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08216</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08216</id><created>2019-09-18</created><authors><author><keyname>Zhang</keyname><forenames>Kaige</forenames></author><author><keyname>Zhang</keyname><forenames>Yingtao</forenames></author><author><keyname>Cheng</keyname><forenames>Heng-Da</forenames></author></authors><title>CrackGAN: A Labor-Light Crack Detection Approach Using Industrial
  Pavement Images Based on Generative Adversarial Learning</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully convolutional network is a powerful tool for per-pixel semantic
segmentation/detection. However, it is problematic when coping with crack
detection using industrial pavement images: the network may easily &quot;converge&quot;
to the status that treats all the pixels as background (BG) and still achieves
a very good loss, named &quot;All Black&quot; phenomenon, due to the data imbalance and
the unavailability of accurate ground truths (GTs). To tackle this problem, we
introduce crack-patch-only (CPO) supervision and generative adversarial
learning for end-to-end training, which forces the network to always produce
crack-GT images while reserves both crack and BG-image translation abilities by
feeding a larger-size crack image into an asymmetric U-shape generator to
overcome the &quot;All Black&quot; issue. The proposed approach is validated using four
crack datasets; and achieves state-of-the-art performance comparing with that
of the recently published works in efficiency and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08244</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08244</id><created>2019-09-18</created><authors><author><keyname>Salmanogli</keyname><forenames>Ahmad</forenames></author><author><keyname>Gokcen</keyname><forenames>Dincer</forenames></author><author><keyname>Gecim</keyname><forenames>H. Selcuk</forenames></author></authors><title>Entanglement Sustainability in Quantum Radar</title><categories>quant-ph cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum radar is generally defined as a detection sensor that utilizes the
microwave photons like a classical radar. At the same time, it employs quantum
phenomena to improve detection, identification, and resolution capabilities.
However, the entanglement is so fragile, unstable, and difficult to create and
to preserve for a long time. Also, more importantly, the entangled states have
a tendency to leak away as a result of noise. The points mentioned above
enforces that the entangled states should be carefully studied at each step of
the quantum radar detection processes as follows. Firstly, the creation of the
entanglement between microwave and optical photons into the tripartite system
is realized. Secondly, the entangled microwave photons are intensified.
Thirdly, the intensified photons are propagated into the atmosphere
(attenuation medium) and reflected from a target. Finally, the backscattered
photons are intensified before the detection. At each step, the parameters
related to the real mediums and target material can affect the entangled states
to leak away easily. In this article, the entanglement behavior of a designed
quantum radar is specifically investigated. In this study, the quantum
electrodynamics theory is generally utilized to analyze the quantum radar
system to define the parameters influencing the entanglement behavior. The
tripartite system dynamics of equations of motions are derived using the
quantum canonical conjugate method. The results of simulations indicate that
the features of the tripartite system and the amplifier are designed in such a
way to lead the detected photons to remain entangled with the optical modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08267</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08267</id><created>2019-09-18</created><updated>2020-01-15</updated><authors><author><keyname>Schoels</keyname><forenames>Tobias</forenames></author><author><keyname>Palmieri</keyname><forenames>Luigi</forenames></author><author><keyname>Arras</keyname><forenames>Kai O.</forenames></author><author><keyname>Diehl</keyname><forenames>Moritz</forenames></author></authors><title>An NMPC Approach using Convex Inner Approximations for Online Motion
  Planning with Guaranteed Collision Avoidance</title><categories>cs.RO cs.SY eess.SY math.OC</categories><comments>Submitted to RA-L+ICRA2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though mobile robots have been around for decades, trajectory
optimization and continuous time collision avoidance remains subject of active
research. Existing methods trade off between path quality, computational
complexity, and kinodynamic feasibility. This work approaches the problem using
a model predictive control (MPC) framework, that is based on a novel convex
inner approximation of the collision avoidance constraint. The proposed Convex
Inner ApprOximation (CIAO) method finds kinodynamically feasible and continuous
time collision free trajectories, in few iterations, typically one. For a
feasible initialization, the approach is guaranteed to find a feasible
solution, i.e. it preserves feasibility. Our experimental evaluation shows that
CIAO outperforms state of the art baselines in terms of planning efficiency and
path quality. Experiments on a robot with 12 states show that it also scales to
high-dimensional systems. Furthermore real-world experiments demonstrate its
capability of unifying trajectory optimization and tracking for safe motion
planning in dynamic environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08278</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08278</id><created>2019-09-18</created><authors><author><keyname>Wang</keyname><forenames>Xiaojie</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>SINR Analysis of Different Multicarrier Waveforms over Doubly Dispersive
  Channels</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless channels generally exhibit dispersion in both time and frequency
domain, known as doubly selective or doubly dispersive channels. To combat the
delay spread effect, multicarrier modulation (MCM) such as orthogonal frequency
division multiplexing (OFDM) and its universal filtered variant (UF-OFDM) is
employed, leading to the simple per-subcarrier one tap equalization. The
time-varying nature of the channel, in particular, the
intra-multicarrier-symbol channel variation induces spectral broadening and
thus inter-carrier interference (ICI). Existing works address both effects
separately, focus on the one effect while ignoring the respective other. This
paper considers both effect simultaneously for cyclic prefix (CP)-, zero padded
(ZP)- and UF-based OFDM with simple one tap equalization, assuming a general
wireless channel model. For this general channel model, we show that the
independent (wide sense stationary uncorrelated scatter, WSSUS) selectivity in
time and frequency starts to intertwine in contrast to the ideal cases with
single selectivity. We derive signal-to-interference-plus-noise ratio (SINR) in
closed form for arbitrary system settings and channel parameters, e.g.,
bandwidth, delay- and Doppler-spread. With the SINR analysis, we compare the
three MCM schemes under different channel scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08281</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08281</id><created>2019-09-18</created><authors><author><keyname>Bodduna</keyname><forenames>Kireeti</forenames></author><author><keyname>Weickert</keyname><forenames>Joachim</forenames></author></authors><title>Poisson Noise Removal Using Multi-Frame 3D Block Matching</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3D block matching (BM3D) filter belongs to the state-of-the-art
techniques for eliminating additive white Gaussian noise from single-frame
images. There exist four multi-frame extensions of BM3D as of today. In this
work, we combine these extensions with a variance stabilising transformation
(VST) for eliminating Poisson noise. Our evaluation reveals that the extension
which retains the original noise model of the noisy images and additionally has
a comprehensive connectivity of 2D and temporal image information at both pixel
and patch levels, gives the best results. Additionally, we find a surprising
change in performance of one the four extensions due to the specific
application of the VST. Finally, we also introduce a simple low-pass filtering
as a preprocessing step for the best performing extension. This can give rise
to a significant additional improvement of 0.94 dB in the output according to
the peak signal to noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08300</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08300</id><created>2019-09-18</created><authors><author><keyname>Callebaut</keyname><forenames>Gilles</forenames></author><author><keyname>Leenders</keyname><forenames>Guus</forenames></author><author><keyname>Buyle</keyname><forenames>Chesney</forenames></author><author><keyname>Crul</keyname><forenames>Stijn</forenames></author><author><keyname>Van der Perre</keyname><forenames>Liesbet</forenames></author></authors><title>LoRa Physical Layer Evaluation for Point-to-Point Links and Coverage
  Measurements in Diverse Environments</title><categories>eess.SP</categories><comments>This paper is accepted and published in the Conference Proceedings of
  2019 European Conference on Networks and Communications (EuCNC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on Point-to-Point LoRa connections. We report on coverage
measurements performed in three distinct environments, i.e., coastal, forest
and urban. Our field experiments demonstrate coverage up to 1 km with antennas
at only 1.5 m height in an urban scenario. In free Line-of-Sight (LoS) this
coverage is extended to 4 km. Based on these results, we are developing a path
loss model in future work. The developed hardware and software including
measurements are open-source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08315</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08315</id><created>2019-09-18</created><authors><author><keyname>Ramos</keyname><forenames>Daniel</forenames></author><author><keyname>Maro&#xf1;as</keyname><forenames>Juan</forenames></author><author><keyname>Lozano-Diez</keyname><forenames>Alicia</forenames></author></authors><title>Bayesian Strategies for Likelihood Ratio Computation in Forensic Voice
  Comparison with Automatic Systems</title><categories>eess.AS cs.CV cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper explores several strategies for Forensic Voice Comparison (FVC),
aimed at improving the performance of the LRs when using generative Gaussian
score-to-LR models. First, different anchoring strategies are proposed, with
the objective of adapting the LR computation process to the case at hand,
always respecting the propositions defined for the particular case. Second, a
fully-Bayesian Gaussian model is used to tackle the sparsity in the training
scores that is often present when the proposed anchoring strategies are used.
Experiments are performed using the 2014 i-Vector challenge set-up, which
presents high variability in a telephone speech context. The results show that
the proposed fully-Bayesian model clearly outperforms a more common
Maximum-Likelihood approach, leading to high robustness when the scores to
train the model become sparse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08326</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08326</id><created>2019-09-18</created><updated>2019-10-03</updated><authors><author><keyname>Wang</keyname><forenames>Hong</forenames></author><author><keyname>Wu</keyname><forenames>Yichen</forenames></author><author><keyname>Li</keyname><forenames>Minghan</forenames></author><author><keyname>Zhao</keyname><forenames>Qian</forenames></author><author><keyname>Meng</keyname><forenames>Deyu</forenames></author></authors><title>A Survey on Rain Removal from Video and Single Image</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rain streaks might severely degenerate the performance of video/image
processing tasks. The investigations on rain removal from video or a single
image has thus been attracting much research attention in the field of computer
vision and pattern recognition, and various methods have been proposed against
this task in the recent years. However, there is still not a comprehensive
survey paper to summarize current rain removal methods and fairly compare their
generalization performance, and especially, still not a off-the-shelf toolkit
to accumulate recent representative methods for easy performance comparison and
capability evaluation. Aiming at this meaningful task, in this study we present
a comprehensive review for current rain removal methods for video and a single
image. Specifically, these methods are categorized into model-driven and
data-driven approaches, and more elaborate branches of each approach are
further introduced. Intrinsic capabilities, especially generalization, of
representative state-of-the-art methods of each approach have been evaluated
and analyzed by experiments implemented on synthetic and real data both
visually and quantitatively. Furthermore, we release a comprehensive
repository, including direct links to 74 rain removal papers, source codes of 9
methods for video rain removal and 20 ones for single image rain removal, 19
related project pages, 6 synthetic datasets and 4 real ones, and 4 commonly
used image quality metrics, to facilitate reproduction and performance
comparison of current existing methods for general users. Some limitations and
research issues worthy to be further investigated have also been discussed for
future research of this direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08331</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08331</id><created>2019-09-18</created><authors><author><keyname>Hu</keyname><forenames>Guozhen</forenames></author><author><keyname>Li</keyname><forenames>Baobin</forenames></author></authors><title>Coupling Chaotic System Based on Unit Transform and Its Applications in
  Image Encryption</title><categories>cs.CR eess.IV</categories><comments>41 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chaotic maps are very important for establishing chaos-based image encryption
systems. This paper introduces a coupling chaotic system based on a certain
unit transform, which can combine any two 1D chaotic maps to generate a new one
with excellent performance. The chaotic behavior analysis has verified this
coupling system's effectiveness and progress. In particular, we give a specific
strategy about selecting an appropriate unit transform function to enhance
chaos of generated maps. Besides, a new chaos based pseudo-random number
generator, shorted as CBPRNG, is designed to improve the distribution of
chaotic sequences. We give a mathematical illustration on the uniformity of
CBPRNG, and test the randomness of it. Moreover, based on CBPRNG, an image
encryption algorithm is introduced. Simulation results and security analysis
indicate that the proposed image encryption scheme is competitive with some
advanced existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08345</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08345</id><created>2019-09-18</created><authors><author><keyname>Xi</keyname><forenames>Jianxiang</forenames></author><author><keyname>Wang</keyname><forenames>Cheng</forenames></author><author><keyname>Yang</keyname><forenames>Xiaojun</forenames></author><author><keyname>Yang</keyname><forenames>Bailong</forenames></author></authors><title>Limited-budget output consensus for descriptor multiagent systems with
  energy constraints</title><categories>cs.MA cs.SY eess.SY</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current paper deals with limited-budget output consensus for descriptor
multiagent systems with two types of switching communication topologies; that
is, switching connected ones and jointly connected ones. Firstly, a singular
dynamic output feedback control protocol with switching communication
topologies is proposed on the basis of the observable decomposition, where an
energy constraint is involved and protocol states of neighboring agents are
utilized to derive a new two-step design approach of gain matrices. Then,
limited-budget output consensus problems are transformed into asymptotic
stability ones and a valid candidate of the output consensus function is
determined. Furthermore, sufficient conditions for limited-budget output
consensus design for two types of switching communication topologies are
proposed, respectively. Finally, two numerical simulations are shown to
demonstrate theoretical conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08356</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08356</id><created>2019-09-18</created><authors><author><keyname>Wahlstr&#xf6;m</keyname><forenames>Johan</forenames></author><author><keyname>Kok</keyname><forenames>Manon</forenames></author><author><keyname>de Gusmao</keyname><forenames>Pedro Porto Buarque</forenames></author><author><keyname>Abrudan</keyname><forenames>Traian E.</forenames></author><author><keyname>Trigoni</keyname><forenames>Niki</forenames></author><author><keyname>Markham</keyname><forenames>Andrew</forenames></author></authors><title>Sensor Fusion for Magneto-Inductive Navigation</title><categories>eess.SP stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magneto-inductive navigation is an inexpensive and easily deployable solution
to many of today's navigation problems. By utilizing very low frequency
magnetic fields, magneto-inductive technology circumvents the problems with
attenuation and multipath that often plague competing modalities. Using
triaxial transmitter and receiver coils, it is possible to compute position and
orientation estimates in three dimensions. However, in many situations,
additional information is available that constrains the set of possible
solutions. For example, the receiver may be known to be coplanar with the
transmitter, or orientation information may be available from inertial sensors.
We employ a maximum a posteriori estimator to fuse magneto-inductive signals
with such complementary information. Further, we derive the Cramer-Rao bound
for the position estimates and investigate the problem of detecting distortions
caused by ferrous material. The performance of the estimator is compared to the
Cramer-Rao bound and a state-of-the-art estimator using both simulations and
real-world data. By fusing magneto-inductive signals with accelerometer
measurements, the median position error is reduced almost by a factor of two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08367</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08367</id><created>2019-09-18</created><authors><author><keyname>Li</keyname><forenames>Zhiping</forenames></author></authors><title>Design and Realization of a Reflectarray Compact Antenna Test Range</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a reflectarray compact antenna test range (RACATR). The
new range layout is designed to suppress the unwanted diffraction. A fast near
field optimization method has been used to determine the phase distribution of
the only phased aperture efficiently in numerical example. The full wave
simulation results of the linear reflectarray support that this facility design
approach is working well to suppress the structural interference such as the
mirror reflection and the edge diffraction. A 460 mm,460 mm square reflectarray
was manufactured and measured. Satisfying the requirement of the quiet zone
field distribution, the quasi-plane wave is achieved from 26.5~28.5 GHz by
linearly adjusting the feed location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08415</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08415</id><created>2019-09-17</created><authors><author><keyname>Badri</keyname><forenames>Pouya</forenames></author><author><keyname>Sojoodi</keyname><forenames>Mahdi</forenames></author></authors><title>LMI-based robust stability and stabilization analysis of
  fractional-order interval systems with time-varying delay</title><categories>eess.SY cs.SY math.DS math.OC</categories><comments>arXiv admin note: text overlap with arXiv:1807.10827</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the robust stability and stabilization analysis of
interval fractional-order systems with time-varying delay. The stability
problem of such systems is solved first, and then using the proposed results a
stabilization theorem is also included, where sufficient conditions are
obtained for designing a stabilizing controller with a predetermined order,
which can be chosen to be as low as possible. Utilizing efficient lemmas, the
stability and stabilization theorems are proposed in the form of LMIs, which is
more suitable to check due to various existing efficient convex optimization
parsers and solvers. Finally, two numerical examples have shown the
effectiveness of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08444</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08444</id><created>2019-09-16</created><authors><author><keyname>Zhao</keyname><forenames>Zishuo</forenames></author><author><keyname>Wang</keyname><forenames>Haoyun</forenames></author></authors><title>Musical Instrument Classification via Low-Dimensional Feature Vectors</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music is a mysterious language that conveys feeling and thoughts via
different tones and timbre. For better understanding of timbre in music, we
chose music data of 6 representative instruments, analysed their timbre
features and classified them. Instead of the current trend of Neural Network
for black-box classification, our project is based on a combination of MFCC and
LPC, and augmented with a 6-dimensional feature vector designed by ourselves
from observation and attempts. In our white-box model, we observed significant
patterns of sound that distinguish different timbres, and discovered some
connection between objective data and subjective senses. With a totally
32-dimensional feature vector and a naive all-pairs SVM, we achieved improved
classification accuracy compared to a single tool. We also attempted to analyze
music pieces downloaded from the Internet, found out different performance on
different instruments, explored the reasons and suggested possible ways to
improve the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08451</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08451</id><created>2019-09-18</created><authors><author><keyname>Maeng</keyname><forenames>Sung Joon</forenames></author><author><keyname>Yap&#x131;c&#x131;</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author><author><keyname>Bhuyan</keyname><forenames>Arupjyoti</forenames></author></authors><title>Hybrid Precoding for mmWave Massive MIMO with One-Bit DAC</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid beamforming is key to achieving energy-efficient 5G wireless networks
equipped with massive amount of antennas. Low-resolution data converters bring
yet another degree of freedom to energy efficiency for the state-of-the-art 5G
transceivers. In this work, we consider the design of hybrid precoders for
massive multiple-input multiple-output (MIMO) channels in millimeter-wave
(mmWave) spectrum along with one-bit digital-to-analog converters (DACs) and
finite-quantized phase shifters. In particular, we propose an
alternating-optimization-based precoder design which recursively computes the
covariance of the quantization distortion, and updates the precoders
accordingly. Numerical results verify that the achievable rate improves quickly
through iterations that involve updates to the weight matrix, distortion
covariance of the quantization, and the respective precoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08459</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08459</id><created>2019-09-18</created><authors><author><keyname>Franzese</keyname><forenames>Vittorio</forenames></author><author><keyname>Topputo</keyname><forenames>Francesco</forenames></author></authors><title>Line-of-Sight Deep-Space Autonomous Navigation</title><categories>eess.SY astro-ph.IM cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous navigation is one of the main enabling technologies for future
space missions. While conventional spacecraft are navigated through ground
stations, their employment for deep-space CubeSats yields costs comparable to
those of the platform. This paper introduces an extended Kalman filter
formulation for spacecraft navigation exploiting the line-of-sight observations
of visible Solar System objects to infer the spacecraft state. The
line-of-sight error budget builds upon typical performances of deep-space
CubeSats and includes uncertainties deriving from the platform attitude, the
image processing, and the performances of the sensors. The errors due to the
low-thrust propagation and light-time delays to the navigation beacons are also
taken into account. Preliminary results show the feasibility of the deep-space
autonomous navigation exploiting the line-of-sight directions to visible
beacons with a 3-sigma accuracy of 1000km for the position components and 2 m/s
for the velocity components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08461</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08461</id><created>2019-09-18</created><authors><author><keyname>Chakrabarti</keyname><forenames>Sambuddha</forenames></author><author><keyname>Baldick</keyname><forenames>Ross</forenames></author></authors><title>Look-Ahead SCOPF (LASCOPF) for Tracking Demand Variation via Auxiliary
  Proximal Message Passing (APMP) Algorithm</title><categories>eess.SY cs.SY</categories><comments>Accepted for publication in Elsevier ScienceDirect-International
  Journal of Electrical Power and Energy Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will consider the Look-Ahead Security Constrained Optimal
Power Flow (LASCOPF) problem looking forward multiple dispatch intervals, in
which the load demand varies over dispatch intervals according to some
forecast. We will consider the base-case and several contingency scenarios in
the upcoming as well as in the subsequent dispatch intervals. We will formulate
and solve the problem in a Model Predictive Control (MPC) paradigm. We will
present the Auxiliary Proximal Message Passing (APMP) algorithm to solve this
problem, which is a bi-layered decomposition-coordination type distributed
algorithm, consisting of an outer Auxiliary Problem Principle (APP) layer and
an inner Proximal Message Passing (PMP) layer. The APP part of the algorithm
distributes the computation across several dispatch intervals and the PMP part
performs the distributed computation within each of the dispatch interval
across different devices (i.e. generators, transmission lines, loads) and nodes
or nets. We will demonstrate the effectiveness of our method with a series of
numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08483</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08483</id><created>2019-09-18</created><authors><author><keyname>Sung</keyname><forenames>Yoonchang</forenames></author><author><keyname>Dixit</keyname><forenames>Deeksha</forenames></author><author><keyname>Tokekar</keyname><forenames>Pratap</forenames></author></authors><title>Environmental Hotspot Identification in Limited Time with a UAV Equipped
  with a Downward-Facing Camera</title><categories>cs.RO eess.SP</categories><comments>7 pages, 6 figures, Submitted to IEEE International Conference on
  Robotics and Automation (ICRA), 2020</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We are motivated by environmental monitoring tasks where finding the global
maxima (i.e., hotspot) of a spatially varying field is crucial. We investigate
the problem of identifying the hotspot for fields that can be sensed using an
Unmanned Aerial Vehicle (UAV) equipped with a downward-facing camera. The UAV
has a limited time budget which it must use for learning the unknown field and
identifying the hotspot. Our first contribution is to show how this problem can
be formulated as a novel variant of the Gaussian Process (GP) multi-armed
bandit problem. The novelty is two-fold: (i) unlike standard multi-armed bandit
settings, the arms ; and (ii) unlike standard GP regression, the measurements
in our problem are image (i.e., vector measurements) whose quality depends on
the altitude at which the UAV flies. We present a strategy for finding the
sequence of UAV sensing locations and empirically compare it with a number of
baselines. We also present experimental results using images gathered onboard a
UAV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08494</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08494</id><created>2019-09-18</created><authors><author><keyname>Manilow</keyname><forenames>Ethan</forenames></author><author><keyname>Wichern</keyname><forenames>Gordon</forenames></author><author><keyname>Seetharaman</keyname><forenames>Prem</forenames></author><author><keyname>Roux</keyname><forenames>Jonathan Le</forenames></author></authors><title>Cutting Music Source Separation Some Slakh: A Dataset to Study the
  Impact of Training Data Quality and Quantity</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted for publication at WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music source separation performance has greatly improved in recent years with
the advent of approaches based on deep learning. Such methods typically require
large amounts of labelled training data, which in the case of music consist of
mixtures and corresponding instrument stems. However, stems are unavailable for
most commercial music, and only limited datasets have so far been released to
the public. It can thus be difficult to draw conclusions when comparing various
source separation methods, as the difference in performance may stem as much
from better data augmentation techniques or training tricks to alleviate the
limited availability of training data, as from intrinsically better model
architectures and objective functions. In this paper, we present the
synthesized Lakh dataset (Slakh) as a new tool for music source separation
research. Slakh consists of high-quality renderings of instrumental mixtures
and corresponding stems generated from the Lakh MIDI dataset (LMD) using
professional-grade sample-based virtual instruments. A first version,
Slakh2100, focuses on 2100 songs, resulting in 145 hours of mixtures. While not
fully comparable because it is purely instrumental, this dataset contains an
order of magnitude more data than MUSDB18, the {\it de facto} standard dataset
in the field. We show that Slakh can be used to effectively augment existing
datasets for musical instrument separation, while opening the door to a wide
array of data-intensive music signal analysis tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08500</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08500</id><created>2019-09-18</created><authors><author><keyname>Aloufi</keyname><forenames>Ranya</forenames></author><author><keyname>Haddadi</keyname><forenames>Hamed</forenames></author><author><keyname>Boyle</keyname><forenames>David</forenames></author></authors><title>Emotion Filtering at the Edge</title><categories>eess.AS cs.CR cs.HC cs.SD</categories><comments>6 pages, 6 figures, Sensys-ML19 workshop in conjunction with the 17th
  ACM Conference on Embedded Networked Sensor Systems (SenSys 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice controlled devices and services have become very popular in the
consumer IoT. Cloud-based speech analysis services extract information from
voice inputs using speech recognition techniques. Services providers can thus
build very accurate profiles of users' demographic categories, personal
preferences, emotional states, etc., and may therefore significantly compromise
their privacy. To address this problem, we have developed a privacy-preserving
intermediate layer between users and cloud services to sanitize voice input
directly at edge devices. We use CycleGAN-based speech conversion to remove
sensitive information from raw voice input signals before regenerating
neutralized signals for forwarding. We implement and evaluate our emotion
filtering approach using a relatively cheap Raspberry Pi 4, and show that
performance accuracy is not compromised at the edge. In fact, signals generated
at the edge differ only slightly (~0.16%) from cloud-based approaches for
speech recognition. Experimental evaluation of generated signals show that
identification of the emotional state of a speaker can be reduced by ~91%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08510</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08510</id><created>2019-09-06</created><authors><author><keyname>Tsang</keyname><forenames>Tony</forenames></author><author><keyname>Chung</keyname><forenames>Lam Sai</forenames></author></authors><title>Remote Monitoring L.V. Switchboard Power Status With 5G New Radio
  Network Application</title><categories>eess.SP</categories><comments>13 Pages</comments><acm-class>F.2.2; I.2.7</acm-class><journal-ref>published 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a power distribution system of most of the buildings, A Low Voltage (L.V.)
switchboard was applied to protect the system. There are different components
in the switchboard (e.g. circuit breakers, over current protection relay, earth
fault protection relay etc.). There are also some components for measure the
power quality which is the power analyser. A power analyser (including
Voltmeter, Ammeter, Multi-meter) is using to measure the power quality in the
electrical power distribution system. Most of the electrical power
distributions systems have been connected the power analysers to a building
management system. The power analysers connected to a computer in a fixed
position that means if someone wants to check the power distribution status,
the person needs to go to the computer to check. In this project, a system
would be made to monitoring the power status by 5G New Radio (NR) Network
application with android smartphone. Since 5G NR Network can provide a
theoretical peak download capacity of 20 Gigabits per second. It would be more
convenient to monitoring the power status in different place by checking though
in the Internet of Things (IoT)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08522</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08522</id><created>2019-09-17</created><authors><author><keyname>Solmaz</keyname><forenames>G&#xfc;rkan</forenames></author><author><keyname>Wu</keyname><forenames>Fang-Jing</forenames></author><author><keyname>Cirillo</keyname><forenames>Flavio</forenames></author><author><keyname>Kovacs</keyname><forenames>Ern&#xf6;</forenames></author><author><keyname>Santana</keyname><forenames>Juan Ram&#xf3;n</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Luis</forenames></author><author><keyname>Sotres</keyname><forenames>Pablo</forenames></author><author><keyname>Mu&#xf1;oz</keyname><forenames>Luis</forenames></author></authors><title>Toward Understanding Crowd Mobility in Smart Cities through the Internet
  of Things</title><categories>eess.SP</categories><comments>This work is published in IEEE Communications Magazine, This work has
  been partially funded by the Spanish Government (MINECO) under Grant
  Agreement No. TEC2015-71329-C2-1-R ADVICE project and by the EU Horizon 2020
  Programme under Grant Agreements No. 731993 AUTOPILOT, 643943 FIESTA-IoT, and
  643275 FESTIVAL projects</comments><journal-ref>IEEE Communications Magazine, vol. 57, no. 4, pp. 40-46, April
  2019</journal-ref><doi>10.1109/MCOM.2019.1800611</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding crowd mobility behaviors would be a key enabler for crowd
management in smart cities, benefiting various sectors such as public safety,
tourism and transportation. This article discusses the existing challenges and
the recent advances to overcome them and allow sharing information across
stakeholders of crowd management through Internet of Things (IoT) technologies.
The article proposes the usage of the new federated interoperable semantic IoT
platform (FIESTA-IoT), which is considered as &quot;a system of systems&quot;. The
platform can support various IoT applications for crowd management in smart
cities. In particular, the article discusses two integrated IoT systems for
crowd mobility: 1) Crowd Mobility Analytics System, 2) Crowd Counting and
Location System (from the SmartSantander testbed). Pilot studies are conducted
in Gold Coast, Australia and Santander, Spain to fulfill various requirements
such as providing online and offline crowd mobility analyses with various
sensors in different regions. The analyses provided by these systems are shared
across applications in order to provide insights and support crowd management
in smart city environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08537</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08537</id><created>2019-09-18</created><authors><author><keyname>Li</keyname><forenames>Chengyao</forenames></author><author><keyname>Waslander</keyname><forenames>Steven L.</forenames></author></authors><title>Visual Measurement Integrity Monitoring for UAV Localization</title><categories>cs.RO cs.CV eess.IV</categories><comments>Published in Safety, Security, and Rescue Robotics 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) have increasingly been adopted for safety,
security, and rescue missions, for which they need precise and reliable pose
estimates relative to their environment. To ensure mission safety when relying
on visual perception, it is essential to have an approach to assess the
integrity of the visual localization solution. However, to the best of our
knowledge, such an approach does not exist for optimization-based visual
localization. Receiver autonomous integrity monitoring (RAIM) has been widely
used in global navigation satellite systems (GNSS) applications such as
automated aircraft landing. In this paper, we propose a novel approach inspired
by RAIM to monitor the integrity of optimization-based visual localization and
calculate the protection level of a state estimate, i.e. the largest possible
translational error in each direction. We also propose a metric that
quantitatively evaluates the performance of the error bounds. Finally, we
validate the protection level using the EuRoC dataset and demonstrate that the
proposed protection level provides a significantly more reliable bound than the
commonly used $3\sigma$ method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08560</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08560</id><created>2019-09-18</created><updated>2019-12-13</updated><authors><author><keyname>Ma</keyname><forenames>Wen-Loong</forenames></author><author><keyname>Ames</keyname><forenames>Aaron D</forenames></author></authors><title>From Bipedal Walking to Quadrupedal Locomotion: Full-Body Dynamics
  Decomposition for Rapid Gait Generation</title><categories>cs.RO cs.SY eess.SY</categories><comments>Submitted to IEEE Robotics and Automation Letters (RA-L)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper systematically decomposes a quadruped into bipeds to rapidly
generate walking gaits, and then recomposes these gaits to obtain quadrupedal
locomotion. We begin by decomposing the full-order, nonlinear and hybrid
dynamics of a three-dimensional quadrupedal robot, including its continuous and
discrete dynamics, into two bipedal systems that are subject to external
forces. Using the hybrid zero dynamics (HZD) framework, gaits for these bipedal
robots can be rapidly generated (on the order of seconds) along with
corresponding controllers. The decomposition is performed in such a way that
the bipedal walking gaits and controllers can be composed to yield dynamic
walking gaits for the original quadrupedal robot --- the result, therefore, is
the rapid generation of dynamic quadruped gaits utilizing the full-order
dynamics. This methodology is demonstrated through the rapid generation (3.96
seconds on average) of four stepping-in-place gaits and one ambling gait at
0.35 m/s on a quadrupedal robot --- the Vision 60, with 36 state variables and
12 control inputs --- both in simulation and through outdoor experiments. This
suggested a new approach for fast quadrupedal trajectory planning using
full-body dynamics, without the need for empirical model simplification,
wherein methods from dynamic bipedal walking can be directly applied to
quadrupeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08574</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08574</id><created>2019-09-18</created><authors><author><keyname>Kaheman</keyname><forenames>Kadierdan</forenames></author><author><keyname>Kaiser</keyname><forenames>Eurika</forenames></author><author><keyname>Strom</keyname><forenames>Benjamin</forenames></author><author><keyname>Kutz</keyname><forenames>J. Nathan</forenames></author><author><keyname>Brunton</keyname><forenames>Steven L.</forenames></author></authors><title>Learning Discrepancy Models From Experimental Data</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>8 pages, 5 figures, accepted by Conference on Decision and Control
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First principles modeling of physical systems has led to significant
technological advances across all branches of science. For nonlinear systems,
however, small modeling errors can lead to significant deviations from the
true, measured behavior. Even in mechanical systems, where the equations are
assumed to be well-known, there are often model discrepancies corresponding to
nonlinear friction, wind resistance, etc. Discovering models for these
discrepancies remains an open challenge for many complex systems. In this work,
we use the sparse identification of nonlinear dynamics (SINDy) algorithm to
discover a model for the discrepancy between a simplified model and measurement
data. In particular, we assume that the model mismatch can be sparsely
represented in a library of candidate model terms. We demonstrate the efficacy
of our approach on several examples including experimental data from a double
pendulum on a cart. We further design and implement a feed-forward controller
in simulations, showing improvement with a discrepancy model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08585</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08585</id><created>2019-09-18</created><authors><author><keyname>Mohamed</keyname><forenames>Mohamed Naveed Gul</forenames></author><author><keyname>Chakravorty</keyname><forenames>Suman</forenames></author><author><keyname>Shell</keyname><forenames>Dylan A.</forenames></author></authors><title>Decoupling stochastic optimal control problems for efficient solution:
  insights from experiments across a wide range of noise regimes</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of robotic planning under uncertainty in this paper.
This problem may be posed as a stochastic optimal control problem, a solution
to which is fundamentally intractable owing to the infamous &quot;curse of
dimensionality&quot;. Hence, we consider the extension of a &quot;decoupling principle&quot;
that was recently proposed by some of the authors, wherein a nominal open-loop
problem is solved followed by a linear feedback design around the open-loop,
and which was shown to be near-optimal to second order in terms of a &quot;small
noise&quot; parameter, to a much wider range of noise levels. Our empirical evidence
suggests that this allows for tractable planning over a wide range of
uncertainty conditions without unduly sacrificing performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08601</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08601</id><created>2019-09-18</created><updated>2019-09-25</updated><authors><author><keyname>Nakahira</keyname><forenames>Yorie</forenames></author><author><keyname>Liu</keyname><forenames>Quanying</forenames></author><author><keyname>Sejnowski</keyname><forenames>Terrence J.</forenames></author><author><keyname>Doyle</keyname><forenames>John C.</forenames></author></authors><title>Diversity-enabled sweet spots in layered architectures and
  speed-accuracy trade-offs in sensorimotor control</title><categories>math.OC cs.IT cs.SY eess.SY math.IT q-bio.NC</categories><comments>10 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Nervous systems sense, communicate, compute, and actuate movement using
distributed components with trade-offs in speed, accuracy, sparsity, noise, and
saturation. Nevertheless, the resulting control can achieve remarkably fast,
accurate, and robust performance due to a highly effective layered control
architecture. However, there is no theory explaining the effectiveness of
layered control architectures that connects speed-accuracy trade-offs (SATs) in
neurophysiology to the resulting SATs in sensorimotor control. In this paper,
we introduce a theoretical framework that provides a synthetic perspective to
explain why there exists extreme diversity across layers and within levels.
This framework characterizes how the sensorimotor control SATs are constrained
by the hardware SATs of neurons communicating with spikes and their sensory and
muscle endpoints, in both stochastic and deterministic models. The theoretical
predictions of the model are experimentally confirmed using driving experiments
in which the time delays and accuracy of the control input from the wheel are
varied. These results show that the appropriate diversity in the properties of
neurons and muscles across layers and within levels help create systems that
are both fast and accurate despite being built from components that are
individually slow or inaccurate. This novel concept, which we call
&quot;diversity-enabled sweet spots&quot; (DESSs), explains the ubiquity of heterogeneity
in the sizes of axons within a nerve as well the resulting superior performance
of sensorimotor control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08602</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08602</id><created>2019-09-18</created><authors><author><keyname>Joshi</keyname><forenames>Girish</forenames></author><author><keyname>Chowdhary</keyname><forenames>Girish</forenames></author></authors><title>Deep Model Reference Adaptive Control</title><categories>cs.LG cs.SY eess.SY</categories><comments>Accepted in IEEE CDC-2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new neuroadaptive architecture: Deep Neural Network based Model
Reference Adaptive Control (DMRAC). Our architecture utilizes the power of deep
neural network representations for modeling significant nonlinearities while
marrying it with the boundedness guarantees that characterize MRAC based
controllers. We demonstrate through simulations and analysis that DMRAC can
subsume previously studied learning based MRAC methods, such as concurrent
learning and GP-MRAC. This makes DMRAC a highly powerful architecture for
high-performance control of nonlinear systems with long-term learning
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08656</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08656</id><created>2019-09-18</created><authors><author><keyname>Cheng</keyname><forenames>Lin</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Dynamic Bandwidth Allocation in Small-Cell Networks: An Economics
  Approach</title><categories>cs.NI cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and experimentally demonstrate a bandwidth allocation method based
on the comparative advantage of spectral efficiency among users in a multi-tone
small-cell radio access system with frequency-selective fading channels. The
method allocates frequency resources by ranking the comparative advantage of
the spectrum measured at the receivers ends. It improves the overall spectral
efficiency of the access system with low implementation complexity and
independently of power loading. In a two-user wireless transmission experiment,
we observe up to 23.1% average capacity improvement by using the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08685</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08685</id><created>2019-09-18</created><authors><author><keyname>Nawaz</keyname><forenames>Shah</forenames></author><author><keyname>Janjua</keyname><forenames>Muhammad Kamran</forenames></author><author><keyname>Gallo</keyname><forenames>Ignazio</forenames></author><author><keyname>Mahmood</keyname><forenames>Arif</forenames></author><author><keyname>Calefati</keyname><forenames>Alessandro</forenames></author></authors><title>Deep Latent Space Learning for Cross-modal Mapping of Audio and Visual
  Signals</title><categories>cs.CV cs.SD eess.AS</categories><comments>Accepted to DICTA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel deep training algorithm for joint representation of audio
and visual information which consists of a single stream network (SSNet)
coupled with a novel loss function to learn a shared deep latent space
representation of multimodal information. The proposed framework characterizes
the shared latent space by leveraging the class centers which helps to
eliminate the need for pairwise or triplet supervision. We quantitatively and
qualitatively evaluate the proposed approach on VoxCeleb, a benchmarks
audio-visual dataset on a multitude of tasks including cross-modal
verification, cross-modal matching, and cross-modal retrieval. State-of-the-art
performance is achieved on cross-modal verification and matching while
comparable results are observed on the remaining applications. Our experiments
demonstrate the effectiveness of the technique for cross-modal biometric
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08703</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08703</id><created>2019-09-18</created><authors><author><keyname>Agadakos</keyname><forenames>Ioannis</forenames></author><author><keyname>Agadakos</keyname><forenames>Nikolaos</forenames></author><author><keyname>Polakis</keyname><forenames>Jason</forenames></author><author><keyname>Amer</keyname><forenames>Mohamed R.</forenames></author></authors><title>Deep Complex Networks for Protocol-Agnostic Radio Frequency Device
  Fingerprinting in the Wild</title><categories>cs.CR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers have demonstrated various techniques for fingerprinting and
identifying devices. Previous approaches have identified devices from their
network traffic or transmitted signals while relying on software or operating
system specific artifacts (e.g., predictability of protocol header fields) or
characteristics of the underlying protocol (e.g.,frequency offset). As these
constraints can be a hindrance in real-world settings, we introduce a
practical, generalizable approach that offers significant operational value for
a variety of scenarios, including as an additional factor of authentication for
preventing impersonation attacks. Our goal is to identify artifacts in
transmitted signals that are caused by a device's unique hardware
&quot;imperfections&quot; without any knowledge about the nature of the signal. We
develop RF-DCN, a novel Deep Complex-valued Neural Network (DCN) that operates
on raw RF signals and is completely agnostic of the underlying applications and
protocols. We present two DCN variations: (i) Convolutional DCN (CDCN) for
modeling full signals, and (ii) Recurrent DCN (RDCN) for modeling time series.
Our system handles raw I/Q data from open air captures within a given spectrum
window, without knowledge of the modulation scheme or even the carrier
frequencies. While our experiments demonstrate the effectiveness of our system,
especially under challenging conditions where other neural network
architectures break down, we identify additional challenges in signal-based
fingerprinting and provide guidelines for future explorations. Our work lays
the foundation for more research within this vast and challenging space by
establishing fundamental directions for using raw RF I/Q data in novel
complex-valued networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08714</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08714</id><created>2019-09-18</created><authors><author><keyname>Rabbani</keyname><forenames>Hami</forenames></author><author><keyname>Liga</keyname><forenames>Gabriele</forenames></author><author><keyname>Oliari</keyname><forenames>Vinicius</forenames></author><author><keyname>Beygi</keyname><forenames>Lotfollah</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author><author><keyname>Karlsson</keyname><forenames>Magnus</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>A General Analytical Model of Nonlinear Fiber Propagation in the
  Presence of Kerr Nonlinearity and Stimulated Raman Scattering</title><categories>eess.SP</categories><comments>24 pages, 4 figures, 7 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Ultra-wideband fiber optical transmission suffers from nonlinear interference
(NLI) noise caused by both Kerr nonlinerity and stimulated Raman scattering
(SRS). Mathematical models that address the interplay between Kerr
nonliniearity and SRS exist. The main drawback of such Gaussian noise (GN)
models is that they overestimate NLI due to a Gaussianity assumption made on
the signal. This problem can be partially compensated by adding modulation
format-dependent correction terms, as recently done for the cross phase
modulation term in C+L band transmission. In this paper, we introduce a general
model that accounts for both Kerr nonlinearity and SRS, accounting for all
terms of nonlinear interactions, including self channel interference, cross
channel interference, and multi channel interference. The derived analytical
expressions are valid for non-Gaussian signals and are obtained by taking into
account frequency-dependent dispersion and frequency-dependent gain/loss caused
by the SRS. The model can handle different modulation formats in different WDM
channels, different symbol rates, multi-span systems with different fibers, and
hybrid amplification schemes. The main contribution of this work is thus to
comprehensively and accurately combine the modulation format and symbol rate
dependence of the NLI with the SRS phenomenon in a very general fashion.
Numerical results indicate that when both SRS and arbitrary modulation formats
are considered, previous models may inaccurately predict the NLI power by up to
4 dB. Our proposed model, on the other hand, accurately describes the effect of
SRS on the NLI power over a wide range of scenarios, including low-cardinality
modulation formats, and medium-to-low symbol-rate transmitted channels.
Split-step Fourier simulations support our analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08723</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08723</id><created>2019-09-18</created><updated>2019-10-14</updated><authors><author><keyname>Wang</keyname><forenames>Yiming</forenames></author><author><keyname>Chen</keyname><forenames>Tongfei</forenames></author><author><keyname>Xu</keyname><forenames>Hainan</forenames></author><author><keyname>Ding</keyname><forenames>Shuoyang</forenames></author><author><keyname>Lv</keyname><forenames>Hang</forenames></author><author><keyname>Shao</keyname><forenames>Yiwen</forenames></author><author><keyname>Peng</keyname><forenames>Nanyun</forenames></author><author><keyname>Xie</keyname><forenames>Lei</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Khudanpur</keyname><forenames>Sanjeev</forenames></author></authors><title>Espresso: A Fast End-to-end Neural Speech Recognition Toolkit</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Espresso, an open-source, modular, extensible end-to-end neural
automatic speech recognition (ASR) toolkit based on the deep learning library
PyTorch and the popular neural machine translation toolkit fairseq. Espresso
supports distributed training across GPUs and computing nodes, and features
various decoding approaches commonly employed in ASR, including look-ahead
word-based language model fusion, for which a fast, parallelized decoder is
implemented. Espresso achieves state-of-the-art ASR performance on the WSJ,
LibriSpeech, and Switchboard data sets among other end-to-end systems without
data augmentation, and is 4--11x faster for decoding than similar systems (e.g.
ESPnet).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08758</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08758</id><created>2019-09-18</created><updated>2019-12-07</updated><authors><author><keyname>Sheffield</keyname><forenames>Edward Y.</forenames></author></authors><title>Extracting Super-resolution Structures inside a Single Molecule or
  Overlapped Molecules from One Blurred Image</title><categories>eess.IV cs.HC</categories><comments>Edward Y. Sheffield is a pen name of Yaohua Xie
  (Yaohua.Xie@hotmail.com, fjpnxyh2000@163.com,
  http://orcid.org/0000-0001-6780-3156)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In some super-resolution techniques, adjacent points are illuminated at
different times. Thereby, their locations and light intensities can be detected
even if the images are very blurred due to diffraction. According to
conventional theories, the points' inner details cannot be recovered because
the images' high frequency components are removed due to the diffraction-limit.
But this study finds an exception, and full information can be extracted from a
diffraction-blurred image. In such a &quot;resolvable condition&quot;, neither profile
nor detail information is damaged by diffraction. Thereby, it can be recovered
reversibly by solving equation systems in spatial domain or frequency domain.
This condition is tightly relevant to the imaging condition of existing
super-resolution techniques. Based on the condition, a method is proposed which
can achieve unlimited high resolutions in principle, and its effectiveness is
demonstrated by both theoretical analysis and simulation experiments. It can
also work without any observed image outside the region of interest. Simulation
experiments also show its tolerance to certain level of noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08768</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08768</id><created>2019-09-18</created><authors><author><keyname>Li</keyname><forenames>Haiyang</forenames></author><author><keyname>Topputo</keyname><forenames>Francesco</forenames></author><author><keyname>Baoyin</keyname><forenames>Hexi</forenames></author></authors><title>Autonomous Time-Optimal Many-Revolution Orbit Raising for Electric
  Propulsion GEO Satellites via Neural Networks</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geostationary Earth orbit (GEO) satellites are of great significance in the
space market. Low-thrust propulsion has been highly developed in the last
decades because it is fuel-saving. Therefore, the design of GEO satellites is
rapidly changing from classic high-thrust propulsion more and more toward
low-thrust propulsion. However, the transfer time will be quite long using
low-thrust propulsion and it will be very expensive if the ground supports the
whole orbit raising. Therefore, autonomous orbit raising is necessary. Deep
neural networks are trained to learn the optimal control. Results show that
DNNs can be applied in this long-duration optimal control problem and have
excellent performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08774</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08774</id><created>2019-09-18</created><authors><author><keyname>Aneja</keyname><forenames>Nagender</forenames></author><author><keyname>Aneja</keyname><forenames>Sandhya</forenames></author></authors><title>Transfer Learning using CNN for Handwritten Devanagari Character
  Recognition</title><categories>cs.CV cs.LG eess.IV</categories><journal-ref>IEEE International Conference on Advances in Information
  Technology (ICAIT), ICAIT - 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents an analysis of pre-trained models to recognize
handwritten Devanagari alphabets using transfer learning for Deep Convolution
Neural Network (DCNN). This research implements AlexNet, DenseNet, Vgg, and
Inception ConvNet as a fixed feature extractor. We implemented 15 epochs for
each of AlexNet, DenseNet 121, DenseNet 201, Vgg 11, Vgg 16, Vgg 19, and
Inception V3. Results show that Inception V3 performs better in terms of
accuracy achieving 99% accuracy with average epoch time 16.3 minutes while
AlexNet performs fastest with 2.2 minutes per epoch and achieving 98\%
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08782</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08782</id><created>2019-09-18</created><authors><author><keyname>Ilharco</keyname><forenames>Gabriel</forenames></author><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author><author><keyname>Baldridge</keyname><forenames>Jason</forenames></author></authors><title>Large-scale representation learning from visually grounded untranscribed
  speech</title><categories>cs.CV cs.CL cs.SD eess.AS</categories><journal-ref>The SIGNLL Conference on Computational Natural Language Learning
  (CoNLL), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Systems that can associate images with their spoken audio captions are an
important step towards visually grounded language learning. We describe a
scalable method to automatically generate diverse audio for image captioning
datasets. This supports pretraining deep networks for encoding both audio and
images, which we do via a dual encoder that learns to align latent
representations from both modalities. We show that a masked margin softmax loss
for such models is superior to the standard triplet loss. We fine-tune these
models on the Flickr8k Audio Captions Corpus and obtain state-of-the-art
results---improving recall in the top 10 from 29.6% to 49.5%. We also obtain
human ratings on retrieval outputs to better assess the impact of incidentally
matching image-caption pairs that were not associated in the data, finding that
automatic evaluation substantially underestimates the quality of the retrieved
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08800</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08800</id><created>2019-09-19</created><authors><author><keyname>Barzegar</keyname><forenames>Alireza</forenames></author><author><keyname>Sadollah</keyname><forenames>Ali</forenames></author><author><keyname>Su</keyname><forenames>Rong</forenames></author></authors><title>A Novel Fully Informed Water Cycle Algorithm for Solving Optimal Power
  Flow Problems in Electric Grids</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal power flow (OPF) is a key tool for planning and operations in energy
grids. The line-flow constraints, generator loading effect, piece-wise cost
functions, emission, and voltage quality cost make the optimization model
non-convex and computationally cumbersome to solve. Metaheuristic techniques
for solving the problem have emerged as a promising solution to solve the
complex OPF problem. Recently, the water cycle algorithm (WCA), a method
inspired by the observation of the water cycle process and the surface run-off
model was proposed for solving optimization problems. This paper proposes an
improved version of WCA that uses the concept of sharing global and local
information among individuals to improve the exploitation ability compared with
the standard WCA. The so called fully informed WCA (FIWCA) is tested against
standard WCA and other metaheuristic techniques studied in the literature on
IEEE 30 and 57 bus systems for various scenarios. Comparison and discussion
regarding the performance and reliability of the metaheuristics approaches
studied in literature are discussed. The obtained optimization results show
that the better performance of proposed FIWCA comparing with the WCA and other
algorithms especially in term of stability performance over replications.
Consequently, it emerges as a tool for solving OPF in a reliable and efficient
manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08801</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08801</id><created>2019-09-19</created><updated>2019-09-20</updated><authors><author><keyname>Fischer</keyname><forenames>Samuel M.</forenames></author></authors><title>Locally optimal routes for route choice sets</title><categories>eess.SY cs.DS cs.SY</categories><comments>Keywords: alternative paths; choice set; local optimality; road
  network; route choice</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Route choice is often modelled as a two-step procedure in which travellers
choose their routes from small sets of promising candidates. Many methods
developed to identify such choice sets rely on assumptions about the mechanisms
behind the route choice and require corresponding data sets. Furthermore,
existing approaches often involve considerable complexity or perform many
repeated shortest path queries. This makes it difficult to apply these methods
in comprehensive models with numerous origin-destination pairs. In this paper,
we address these issues by developing an algorithm that efficiently identifies
locally optimal routes. Such paths arise from travellers acting rationally on
local scales, whereas unknown factors may affect the routes on larger scales.
Though methods identifying locally optimal routes are available already, these
algorithms rely on approximations and return only few, heuristically chosen
paths for specific origin-destination pairs. This conflicts with the demands of
route choice models, where an exhaustive search for many origins and
destinations would be necessary. We therefore extend existing algorithms to
return (almost) all admissible paths between a large number of
origin-destination pairs. We test our algorithm on a road network modelling the
Canadian province British Columbia and analyze the distribution of locally
optimal paths in the province.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08813</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08813</id><created>2019-09-19</created><authors><author><keyname>Araake</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaino</keyname><forenames>Sho</forenames></author><author><keyname>Tsuji</keyname><forenames>Toshiaki</forenames></author></authors><title>Design of Resonance Ratio Control with Relative Position Information for
  Two-inertia System</title><categories>eess.SY cs.SY</categories><comments>6 pages, 14 figures, accepted by AIM2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-inertia systems are prone to resonance vibrations that degrade their
control performances. These unwanted vibrations can be effectively suppressed
by control methods based on a disturbance observer (DOB). Vibration suppression
control methods using the information of both the motor and load sides have
been widely researched in recent years. Methods that exploit the spring
deflection or torsional force of two-inertia systems have delivered promising
performances. However, few conventional methods have exploited the relative
position information, and the discussion of position control is currently
insufficient. Focusing on the relative position, this study proposes a new
resonance ratio control (RRC) based on the relative acceleration and state
feedback. The structure of the proposed RRC is derived theoretically and the
proposed method is experimentally validated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08856</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08856</id><created>2019-09-19</created><authors><author><keyname>Eitel</keyname><forenames>Fabian</forenames></author><author><keyname>Ritter</keyname><forenames>Kerstin</forenames></author></authors><title>Testing the robustness of attribution methods for convolutional neural
  networks in MRI-based Alzheimer's disease classification</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Attribution methods are an easy to use tool for investigating and validating
machine learning models. Multiple methods have been suggested in the literature
and it is not yet clear which method is most suitable for a given task. In this
study, we tested the robustness of four attribution methods, namely
gradient*input, guided backpropagation, layer-wise relevance propagation and
occlusion, for the task of Alzheimer's disease classification. We have
repeatedly trained a convolutional neural network (CNN) with identical training
settings in order to separate structural MRI data of patients with Alzheimer's
disease and healthy controls. Afterwards, we produced attribution maps for each
subject in the test data and quantitatively compared them across models and
attribution methods. We show that visual comparison is not sufficient and that
some widely used attribution methods produce highly inconsistent outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08868</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08868</id><created>2019-09-19</created><authors><author><keyname>Zaech</keyname><forenames>Jan-Nico</forenames></author><author><keyname>Gao</keyname><forenames>Cong</forenames></author><author><keyname>Bier</keyname><forenames>Bastian</forenames></author><author><keyname>Taylor</keyname><forenames>Russell</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Unberath</keyname><forenames>Mathias</forenames></author></authors><title>Learning to Avoid Poor Images: Towards Task-aware C-arm Cone-beam CT
  Trajectories</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted for oral presentation at the International Conference on
  Medical Image Computing and Computer Assisted Intervention (MICCAI) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metal artifacts in computed tomography (CT) arise from a mismatch between
physics of image formation and idealized assumptions during tomographic
reconstruction. These artifacts are particularly strong around metal implants,
inhibiting widespread adoption of 3D cone-beam CT (CBCT) despite clear
opportunity for intra-operative verification of implant positioning, e.g. in
spinal fusion surgery. On synthetic and real data, we demonstrate that much of
the artifact can be avoided by acquiring better data for reconstruction in a
task-aware and patient-specific manner, and describe the first step towards the
envisioned task-aware CBCT protocol. The traditional short-scan CBCT trajectory
is planar, with little room for scene-specific adjustment. We extend this
trajectory by autonomously adjusting out-of-plane angulation. This enables
C-arm source trajectories that are scene-specific in that they avoid acquiring
&quot;poor images&quot;, characterized by beam hardening, photon starvation, and noise.
The recommendation of ideal out-of-plane angulation is performed on-the-fly
using a deep convolutional neural network that regresses a detectability-rank
derived from imaging physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08869</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08869</id><created>2019-09-19</created><authors><author><keyname>Zhang</keyname><forenames>Yongbing</forenames></author><author><keyname>Liu</keyname><forenames>Yangzhe</forenames></author><author><keyname>Li</keyname><forenames>Xiu</forenames></author><author><keyname>Jiang</keyname><forenames>Shaowei</forenames></author><author><keyname>Dixit</keyname><forenames>Krishna</forenames></author><author><keyname>Zhang</keyname><forenames>Xinfeng</forenames></author><author><keyname>Ji</keyname><forenames>Xiangyang</forenames></author></authors><title>PgNN: Physics-guided Neural Network for Fourier Ptychographic Microscopy</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier ptychography (FP) is a newly developed computational imaging approach
that achieves both high resolution and wide field of view by stitching a series
of low-resolution images captured under angle-varied illumination. So far, many
supervised data-driven models have been applied to solve inverse imaging
problems. These models need massive amounts of data to train, and are limited
by the dataset characteristics. In FP problems, generic datasets are always
scarce, and the optical aberration varies greatly under different acquisition
conditions. To address these dilemmas, we model the forward physical imaging
process as an interpretable physics-guided neural network (PgNN), where the
reconstructed image in the complex domain is considered as the learnable
parameters of the neural network. Since the optimal parameters of the PgNN can
be derived by minimizing the difference between the model-generated images and
real captured angle-varied images corresponding to the same scene, the proposed
PgNN can get rid of the problem of massive training data as in traditional
supervised methods. Applying the alternate updating mechanism and the total
variation regularization, PgNN can flexibly reconstruct images with improved
performance. In addition, the Zernike mode is incorporated to compensate for
optical aberrations to enhance the robustness of FP reconstructions. As a
demonstration, we show our method can reconstruct images with smooth
performance and detailed information in both simulated and experimental
datasets. In particular, when validated in an extension of a high-defocus,
high-exposure tissue section dataset, PgNN outperforms traditional FP methods
with fewer artifacts and distinguishable structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08886</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08886</id><created>2019-09-19</created><authors><author><keyname>G&#xfc;ltekin</keyname><forenames>Yunus Can</forenames></author><author><keyname>Fehenberger</keyname><forenames>Tobias</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Willems</keyname><forenames>Frans M. J.</forenames></author></authors><title>Probabilistic Shaping for Finite Blocklengths: Distribution Matching and
  Sphere Shaping</title><categories>eess.SP</categories><comments>18 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide for the first time a systematic comparison of
distribution matching (DM) and sphere shaping (SpSh) algorithms for short
blocklength probabilistic amplitude shaping. For asymptotically large
blocklengths, constant composition distribution matching (CCDM) is known to
generate the target capacity-achieving distribution. As the blocklength
decreases, however, the resulting rate loss diminishes the efficiency of CCDM.
We claim that for such short blocklengths and over the additive white Gaussian
channel (AWGN), the objective of shaping should be reformulated as obtaining
the most energy-efficient signal space for a given rate (rather than matching
distributions). In light of this interpretation, multiset-partition DM (MPDM),
enumerative sphere shaping (ESS) and shell mapping (SM), are reviewed as
energy-efficient shaping techniques. Numerical results show that MPDM and SpSh
have smaller rate losses than CCDM. SpSh--whose sole objective is to maximize
the energy efficiency--is shown to have the minimum rate loss amongst all. We
provide simulation results of the end-to-end decoding performance showing that
up to 1 dB improvement in power efficiency over uniform signaling can be
obtained with MPDM and SpSh at blocklengths around 200. Finally, we present a
discussion on the complexity of these algorithms from the perspective of
latency, storage and computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08898</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08898</id><created>2019-09-19</created><authors><author><keyname>Meine</keyname><forenames>Hans</forenames></author><author><keyname>Hering</keyname><forenames>Alessa</forenames></author></authors><title>Efficient Prealignment of CT Scans for Registration through a Bodypart
  Regressor</title><categories>eess.IV cs.CV cs.LG</categories><comments>Extended Abstract accepted at MIDL 2019</comments><report-no>MIDL/2019/ExtendedAbstract/r1xYAvZXqN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Convolutional neural networks have not only been applied for classification
of voxels, objects, or images, for instance, but have also been proposed as a
bodypart regressor. We pick up this underexplored idea and evaluate its value
for registration: A CNN is trained to output the relative height within the
human body in axial CT scans, and the resulting scores are used for quick
alignment between different timepoints. Preliminary results confirm that this
allows both fast and robust prealignment compared with iterative approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08914</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08914</id><created>2019-09-19</created><authors><author><keyname>Colombo</keyname><forenames>Leonardo</forenames></author><author><keyname>de Marina</keyname><forenames>Hector Garcia</forenames></author><author><keyname>Li&#xf1;&#xe1;n</keyname><forenames>Mar&#xed;a Barbero</forenames></author><author><keyname>de Diego</keyname><forenames>David Mart&#xed;n</forenames></author></authors><title>On the observability of relative positions in left-invariant multi-agent
  control systems and its application to formation control</title><categories>eess.SY cs.MA cs.RO cs.SY math.OC</categories><comments>Accepted paper for CDC conference 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the localization problem between agents while they run a
formation control algorithm. These algorithms typically demand from the agents
the information about their relative positions with respect to their neighbors.
We assume that this information is not available. Therefore, the agents need to
solve the observability problem of reconstructing their relative positions
based on other measurements between them. We first model the relative
kinematics between the agents as a left-invariant control system so that we can
exploit its appealing properties to solve the observability problem. Then, as a
particular application, we will focus on agents running a distance-based
control algorithm where their relative positions are not accessible but the
distances between them are.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08942</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08942</id><created>2019-09-19</created><authors><author><keyname>Prokopenko</keyname><forenames>Denis</forenames></author><author><keyname>Stadelmann</keyname><forenames>Jo&#xeb;l Valentin</forenames></author><author><keyname>Schulz</keyname><forenames>Heinrich</forenames></author><author><keyname>Renisch</keyname><forenames>Steffen</forenames></author><author><keyname>Dylov</keyname><forenames>Dmitry V.</forenames></author></authors><title>Synthetic CT Generation from MRI Using Improved DualGAN</title><categories>eess.IV</categories><report-no>MIDL/2019/ExtendedAbstract/S1em7ZOkFN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Synthetic CT image generation from MRI scan is necessary to create
radiotherapy plans without the need of co-registered MRI and CT scans. The
chosen baseline adversarial model with cycle consistency permits unpaired
image-to-image translation. Perceptual loss function term and coordinate
convolutional layer were added to improve the quality of translated images. The
proposed architecture was tested on paired MRI-CT dataset, where the synthetic
CTs were compared to corresponding original CT images. The MAE between the
synthetic CT images and the real CT scans is 61 HU computed inside of the true
CTs body shape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08959</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08959</id><created>2019-09-18</created><authors><author><keyname>Marcinkiewicz</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Mrukwa</keyname><forenames>Grzegorz</forenames></author></authors><title>Quantitative Impact of Label Noise on the Quality of Segmentation of
  Brain Tumors on MRI scans</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last few years, deep learning has proven to be a great solution to
many problems, such as image or text classification. Recently, deep
learning-based solutions have outperformed humans on selected benchmark
datasets, yielding a promising future for scientific and real-world
applications. Training of deep learning models requires vast amounts of high
quality data to achieve such supreme performance. In real-world scenarios,
obtaining a large, coherent, and properly labeled dataset is a challenging
task. This is especially true in medical applications, where high-quality data
and annotations are scarce and the number of expert annotators is limited. In
this paper, we investigate the impact of corrupted ground-truth masks on the
performance of a neural network for a brain tumor segmentation task. Our
findings suggest that a) the performance degrades about 8% less than it could
be expected from simulations, b) a neural network learns the simulated biases
of annotators, c) biases can be partially mitigated by using an
inversely-biased dice loss function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08961</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08961</id><created>2019-09-16</created><authors><author><keyname>Wang</keyname><forenames>Weimin</forenames></author><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Sun</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>Acoustic scene analysis with multi-head attention networks</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic Scene Classification (ASC) is a challenging task, as a single scene
may involve multiple events that contain complex sound patterns. For example, a
cooking scene may contain several sound sources including silverware clinking,
chopping, frying, etc. What complicates ASC more is that classes of different
activities could have overlapping sounds patterns (e.g. both cooking and
dishwashing could have silverware clinking sound). In this paper, we propose a
multi-head attention network to model the complex temporal input structures for
ASC. The proposed network takes the audio's time-frequency representation as
input, and it leverages standard VGG plus LSTM layers to extract high-level
feature representation. Further more, it applies multiple attention heads to
summarize various patterns of sound events into fixed dimensional
representation, for the purpose of final scene classification. The whole
network is trained in an end-to-end fashion with back-propagation. Experimental
results confirm that our model discovers meaningful sound patterns through the
attention mechanism, without using explicit supervision in the alignment. We
evaluated our proposed model using DCASE 2018 Task 5 dataset, and achieved
competitive performance on par with previous winner's results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08963</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08963</id><created>2019-09-10</created><authors><author><keyname>AlAshery</keyname><forenames>Mohamed Kareem Abdel Rahman</forenames></author></authors><title>Coupling Wind Farm with Nuclear Power Plant</title><categories>eess.SY cs.SY</categories><comments>Ain Shams University, Electrical Power and Machines Engineering, MSc
  Thesis, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Climate change has been identified as one of the greatest challenges facing
nations, governments, businesses and citizens of the globe. The threats of
climate change demand an increase in the share of renewable energy from the
total of energy generation. Meanwhile, there are tremendous efforts to decrease
the reliance on fossil fuel energies which opens the venue for increasing the
usage of alternative resources such as nuclear energy. Many countries (e.g.
Egypt) are planning to meet increasing electricity demands by increasing both
renewable (especially wind energy) and nuclear energies contributions in
electricity generation. In the planning phase of siting both new Wind Farms
(WFs) and Nuclear Power Plants (NPPs), many benefits and challenges exist. An
important aspect taken into consideration during the NPP siting is the
existence of ultimate heat sink which is sea water in most cases. That is why
most NPPs are sited on sea coasts. On the other hand, during WF siting, the
main influential aspect is the existence of good wind resources. Many coastal
areas around the world fulfill this requirement for WF siting. Coupling both
NPPs and WFs in one site or nearby has many benefits and obstacles as well. In
this thesis, based on international experience and literature reviews, the
benefits and obstacles of this coupling/adjacency are studied and evaluated.
Various case studies are carried out to verify the coupling/adjacency concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08974</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08974</id><created>2019-09-19</created><authors><author><keyname>Wang</keyname><forenames>Le</forenames></author><author><keyname>Xi</keyname><forenames>Jianxiang</forenames></author><author><keyname>He</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Guangbin</forenames></author></authors><title>Robust time-varying formation design for multi-agent systems with
  disturbances: Extended-state-observer method</title><categories>cs.MA cs.SY eess.SY</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust time-varying formation design problems for second-order multi-agent
systems subjected to external disturbances are investigated. Firstly, by
constructing an extended state observer, the disturbance compensation is
estimated, which is a critical term in the proposed robust time-varying
formation control protocol. Then, an explicit expression of the formation
center function is determined and impacts of disturbance compensations on the
formation center function are presented. With the formation feasibility
conditions, robust time-varying formation design criteria are derived to
determine the gain matrix of the formation control protocol by utilizing the
algebraic Riccati equation technique. Furthermore, the tracking performance and
the robustness property of multi-agent systems are analyzed. Finally, the
numerical simulation is provided to illustrate the effectiveness of theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08980</identifier>
 <datestamp>2020-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08980</id><created>2019-09-17</created><updated>2020-01-23</updated><authors><author><keyname>Xiang</keyname><forenames>YuChen</forenames></author><author><keyname>Foreman</keyname><forenames>Matthew R.</forenames></author><author><keyname>T&#xf6;r&#xf6;k</keyname><forenames>Peter</forenames></author></authors><title>SNR Enhancement in Brillouin Microspectroscopy using Spectrum
  Reconstruction</title><categories>eess.SP physics.optics</categories><journal-ref>Biomedical Optics Express Vol. 11, Issue 2, pp. 1020-1031 (2020)</journal-ref><doi>10.1364/BOE.380798</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brillouin imaging suffers from intrinsically low signal-to-noise ratios
(SNR). Such low SNRs can render common data analysis protocols unreliable,
especially for SNRs below $\sim10$. In this work we exploit two denoising
algorithms, namely maximum entropy reconstruction (MER) and wavelet analysis
(WA), to improve the accuracy and precision in determination of Brillouin
shifts and linewidth. Algorithm performance is quantified using Monte-Carlo
simulations and benchmarked against the Cram\'er-Rao lower bound. Superior
estimation results are demonstrated even at low SNRS ($\geq 1$). Denoising was
furthermore applied to experimental Brillouin spectra of distilled water at
room temperature, allowing the speed of sound in water to be extracted.
Experimental and theoretical values were found to be consistent to within
$\pm1\%$ at unity SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08986</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08986</id><created>2019-09-16</created><authors><author><keyname>Wang</keyname><forenames>Zhao-Yang</forenames></author><author><keyname>Zhou</keyname><forenames>Xiao-Yun</forenames></author><author><keyname>Li</keyname><forenames>Peichao</forenames></author><author><keyname>Riga</keyname><forenames>Celia</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author></authors><title>Instantiation-Net: 3D Mesh Reconstruction from Single 2D Image for Right
  Ventricle</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D shape instantiation which reconstructs the 3D shape of a target from
limited 2D images or projections is an emerging technique for surgical
intervention. It improves the currently less-informative and insufficient 2D
navigation schemes for robot-assisted Minimally Invasive Surgery (MIS) to 3D
navigation. Previously, a general and registration-free framework was proposed
for 3D shape instantiation based on Kernel Partial Least Square Regression
(KPLSR), requiring manually segmented anatomical structures as the
pre-requisite. Two hyper-parameters including the Gaussian width and component
number also need to be carefully adjusted. Deep Convolutional Neural Network
(DCNN) based framework has also been proposed to reconstruct a 3D point cloud
from a single 2D image, with end-to-end and fully automatic learning. In this
paper, an Instantiation-Net is proposed to reconstruct the 3D mesh of a target
from its a single 2D image, by using DCNN to extract features from the 2D image
and Graph Convolutional Network (GCN) to reconstruct the 3D mesh, and using
Fully Connected (FC) layers to connect the DCNN to GCN. Detailed validation was
performed to demonstrate the practical strength of the method and its potential
clinical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08987</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08987</id><created>2019-09-18</created><authors><author><keyname>Shamim</keyname><forenames>Mohammed Zubair M.</forenames></author><author><keyname>Syed</keyname><forenames>Sadatullah</forenames></author><author><keyname>Shiblee</keyname><forenames>Mohammad</forenames></author><author><keyname>Usman</keyname><forenames>Mohammed</forenames></author><author><keyname>Ali</keyname><forenames>Syed</forenames></author></authors><title>Automated detection of oral pre-cancerous tongue lesions using deep
  learning for early diagnosis of oral cavity cancer</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>25 pages, 10 figures</comments><report-no>01</report-no><msc-class>68Txx</msc-class><doi>10.13140/RG.2.2.28808.16643</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discovering oral cavity cancer (OCC) at an early stage is an effective way to
increase patient survival rate. However, current initial screening process is
done manually and is expensive for the average individual, especially in
developing countries worldwide. This problem is further compounded due to the
lack of specialists in such areas. Automating the initial screening process
using artificial intelligence (AI) to detect pre-cancerous lesions can prove to
be an effective and inexpensive technique that would allow patients to be
triaged accordingly to receive appropriate clinical management. In this study,
we have applied and evaluated the efficacy of six deep convolutional neural
network (DCNN) models using transfer learning, for identifying pre-cancerous
tongue lesions directly using a small data set of clinically annotated
photographic images to diagnose early signs of OCC. DCNN model based on Vgg19
architecture was able to differentiate between benign and pre-cancerous tongue
lesions with a mean classification accuracy of 0.98, sensitivity 0.89 and
specificity 0.97. Additionally, the ResNet50 DCNN model was able to distinguish
between five types of tongue lesions i.e. hairy tongue, fissured tongue,
geographic tongue, strawberry tongue and oral hairy leukoplakia with a mean
classification accuracy of 0.97. Preliminary results using an (AI+Physician)
ensemble model demonstrate that an automated initial screening process of
tongue lesions using DCNNs can achieve near-human level classification
performance for diagnosing early signs of OCC in patients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09006</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09006</id><created>2019-09-19</created><authors><author><keyname>Zhang</keyname><forenames>Chaoping</forenames></author><author><keyname>Dubost</keyname><forenames>Florian</forenames></author><author><keyname>de Bruijne</keyname><forenames>Marleen</forenames></author><author><keyname>Klein</keyname><forenames>Stefan</forenames></author><author><keyname>Poot</keyname><forenames>Dirk H. J.</forenames></author></authors><title>APIR-Net: Autocalibrated Parallel Imaging Reconstruction using a Neural
  Network</title><categories>eess.SP cs.CV eess.IV physics.med-ph</categories><comments>To appear in the proceedings of MICCAI 2019 Workshop Machine Learning
  for Medical Image Reconstruction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has been successfully demonstrated in MRI reconstruction of
accelerated acquisitions. However, its dependence on representative training
data limits the application across different contrasts, anatomies, or image
sizes. To address this limitation, we propose an unsupervised, auto-calibrated
k-space completion method, based on a uniquely designed neural network that
reconstructs the full k-space from an undersampled k-space, exploiting the
redundancy among the multiple channels in the receive coil in a parallel
imaging acquisition. To achieve this, contrary to common convolutional network
approaches, the proposed network has a decreasing number of feature maps of
constant size. In contrast to conventional parallel imaging methods such as
GRAPPA that estimate the prediction kernel from the fully sampled
autocalibration signals in a linear way, our method is able to learn nonlinear
relations between sampled and unsampled positions in k-space. The proposed
method was compared to the start-of-the-art ESPIRiT and RAKI methods in terms
of noise amplification and visual image quality in both phantom and in-vivo
experiments. The experiments indicate that APIR-Net provides a promising
alternative to the conventional parallel imaging methods, and results in
improved image quality especially for low SNR acquisitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09024</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09024</id><created>2019-09-19</created><authors><author><keyname>Catellier</keyname><forenames>Andrew A.</forenames></author><author><keyname>Voran</keyname><forenames>Stephen D.</forenames></author></authors><title>WEnets: A Convolutional Framework for Evaluating Audio Waveforms</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new convolutional framework for waveform evaluation, WEnets,
and build a Narrowband Audio Waveform Evaluation Network, or NAWEnet, using
this framework. NAWEnet is single-ended (or no-reference) and was trained three
separate times in order to emulate PESQ, POLQA, or STOI with testing
correlations 0.95, 0.92, and 0.95, respectively when training on only 50% of
available data and testing on 40%. Stacks of 1-D convolutional layers and
non-linear downsampling learn which features are important for quality or
intelligibility estimation. This straightforward architecture simplifies the
interpretation of its inner workings and paves the way for future
investigations into higher sample rates and accurate no-reference subjective
speech quality predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09040</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09040</id><created>2019-09-19</created><authors><author><keyname>Yu</keyname><forenames>Pian</forenames></author><author><keyname>Dimarogonas</keyname><forenames>Dimos V.</forenames></author></authors><title>Approximately symbolic models for a class of continuous-time nonlinear
  systems</title><categories>eess.SY cs.SY math.OC</categories><comments>Accepted by the 58th IEEE Conference on Decision and Control, Nice</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete abstractions have become a standard approach to assist control
synthesis under complex specifications. Most techniques for the construction of
discrete abstractions are based on sampling of both the state and time spaces,
which may not be able to guarantee safety for continuous-time systems. In this
work, we aim at addressing this problem by considering only state-space
abstraction. Firstly, we connect the continuous-time concrete system with its
discrete (state-space) abstraction with a control interface. Then, a novel
stability notion called controlled globally asymptotic/practical stability with
respect to a set is proposed. It is shown that every system, under the
condition that there exists an admissible control interface such that the
augmented system (composed of the concrete system and its abstraction) can be
made controlled globally practically stable with respect to the given set, is
approximately simulated by its discrete abstraction. The effectiveness of the
proposed results is illustrated by a simulation example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09097</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09097</id><created>2019-09-19</created><authors><author><keyname>Dlamini</keyname><forenames>Thembelihle</forenames></author></authors><title>Core Network Management Procedures for Self-Organized and Sustainable 5G
  Cellular Networks</title><categories>eess.SP</categories><comments>2 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Future Mobile Networks (MNs), 5G and beyond 5G, will require a paradigm shift
from traditional resource allocation mechanisms as Base Stations (BSs) will be
empowered with computation capabilities (i.e., offloading and computation is
performed closer to mobile users). This is motivated by the expected data
explosion in the volume, variety, and velocity, generated by pervasive mobile
and Internet of Things (IoT) devices at the network edge. Towards efficient
resource management, within the Multi-access Edge Computing (MEC) paradigm, we
make use of the Long Short-Term Memory (LSTM) neural network for time series
forecasting and control-theoretic techniques for foresighted optimization, thus
bringing intelligent mechanisms for handling network resources within the
network edge. Here, we propose online algorithms for autoscaling and
reconfiguring the computing-plus-communication resources within the virtualized
computing platform, and also enable dynamic switching on/off BSs by taking into
account the forecasted traffic load and harvested energy. The main goal is to
minimize the overall energy consumption, with a guarantee of Quality of Service
(QoS). Our numerical results, obtained through trace-driven simulations, show
that the proposed optimization strategies lead to a considerable reduction in
the energy consumed by the edge computing and communication facilities,
promoting energy self-sustainability within the MN through the use of green
energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09116</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09116</id><created>2019-09-19</created><updated>2020-02-23</updated><authors><author><keyname>Kahn</keyname><forenames>Jacob</forenames></author><author><keyname>Lee</keyname><forenames>Ann</forenames></author><author><keyname>Hannun</keyname><forenames>Awni</forenames></author></authors><title>Self-Training for End-to-End Speech Recognition</title><categories>cs.CL cs.LG eess.AS</categories><comments>To be published in the 45th IEEE International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP) 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit self-training in the context of end-to-end speech recognition. We
demonstrate that training with pseudo-labels can substantially improve the
accuracy of a baseline model. Key to our approach are a strong baseline
acoustic and language model used to generate the pseudo-labels, filtering
mechanisms tailored to common errors from sequence-to-sequence models, and a
novel ensemble approach to increase pseudo-label diversity. Experiments on the
LibriSpeech corpus show that with an ensemble of four models and label
filtering, self-training yields a 33.9% relative improvement in WER compared
with a baseline trained on 100 hours of labelled data in the noisy speech
setting. In the clean speech setting, self-training recovers 59.3% of the gap
between the baseline and an oracle model, which is at least 93.8% relatively
higher than what previous approaches can achieve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09124</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09124</id><created>2019-09-19</created><authors><author><keyname>Rathore</keyname><forenames>Saima</forenames></author><author><keyname>Iftikhar</keyname><forenames>Muhammad Aksam</forenames></author><author><keyname>Mourelatos</keyname><forenames>Zissimos</forenames></author></authors><title>Prediction of overall survival and molecular markers in gliomas via
  analysis of digital pathology images using deep learning</title><categories>eess.IV cs.CV</categories><comments>4 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cancer histology reveals disease progression and associated molecular
processes, and contains rich phenotypic information that is predictive of
outcome. In this paper, we developed a computational approach based on deep
learning to predict the overall survival and molecular subtypes of glioma
patients from microscopic images of tissue biopsies, reflecting measures of
microvascular proliferation, mitotic activity, nuclear atypia, and the presence
of necrosis. Whole-slide images from 663 unique patients [IDH: 333
IDH-wildtype, 330 IDH-mutants, 1p/19q: 201 1p/19q non-codeleted, 129 1p/19q
codeleted] were obtained from TCGA. Sub-images that were free of artifacts and
that contained viable tumor with descriptive histologic characteristics were
extracted, which were further used for training and testing a deep neural
network. The output layer of the network was configured in two different ways:
(i) a final Cox model layer to output a prediction of patient risk, and (ii) a
final layer with sigmoid activation function, and stochastic gradient decent
based optimization with binary cross-entropy loss. Both survival prediction and
molecular subtype classification produced promising results using our model.
The c-statistic was estimated to be 0.82 (p-value=4.8x10-5) between the risk
scores of the proposed deep learning model and overall survival, while
accuracies of 88% (area under the curve [AUC]=0.86) were achieved in the
detection of IDH mutational status and 1p/19q codeletion. These findings
suggest that the deep learning techniques can be applied to microscopic images
for objective, accurate, and integrated prediction of outcome for glioma
patients. The proposed marker may contribute to (i) stratification of patients
into clinical trials, (ii) patient selection for targeted therapy, and (iii)
personalized treatment planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09132</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09132</id><created>2019-09-13</created><updated>2020-02-19</updated><authors><author><keyname>Krishna</keyname><forenames>Gautam</forenames></author><author><keyname>Tran</keyname><forenames>Co</forenames></author><author><keyname>Han</keyname><forenames>Yan</forenames></author><author><keyname>Carnahan</keyname><forenames>Mason</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H</forenames></author></authors><title>Spoken Speech Enhancement using EEG</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate spoken speech enhancement using
electroencephalography (EEG) signals using a generative adversarial network
(GAN) based model, gated recurrent unit (GRU) regression based model, temporal
convolutional network (TCN) regression model and finally using a mixed TCN GRU
regression model.
  We compare our EEG based speech enhancement results with traditional log
minimum mean-square error (MMSE) speech enhancement algorithm and our proposed
methods demonstrate significant improvement in speech enhancement quality
compared to the traditional method. Our overall results demonstrate that EEG
features can be used to clean speech recorded in presence of background noise.
To the best of our knowledge this is the first time a spoken speech enhancement
is demonstrated using EEG features recorded in parallel with spoken speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09150</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09150</id><created>2019-09-19</created><authors><author><keyname>Delaney</keyname><forenames>Anne Marie</forenames></author><author><keyname>Brophy</keyname><forenames>Eoin</forenames></author><author><keyname>Ward</keyname><forenames>Tomas E.</forenames></author></authors><title>Synthesis of Realistic ECG using Generative Adversarial Networks</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Access to medical data is highly restricted due to its sensitive nature,
preventing communities from using this data for research or clinical training.
Common methods of de-identification implemented to enable the sharing of data
are sometimes inadequate to protect the individuals contained in the data. For
our research, we investigate the ability of generative adversarial networks
(GANs) to produce realistic medical time series data which can be used without
concerns over privacy. The aim is to generate synthetic ECG signals
representative of normal ECG waveforms. GANs have been used successfully to
generate good quality synthetic time series and have been shown to prevent
re-identification of individual records. In this work, a range of GAN
architectures are developed to generate synthetic sine waves and synthetic ECG.
Two evaluation metrics are then used to quantitatively assess how suitable the
synthetic data is for real world applications such as clinical training and
data analysis. Finally, we discuss the privacy concerns associated with sharing
synthetic data produced by GANs and test their ability to withstand a simple
membership inference attack. For the first time we both quantitatively and
qualitatively demonstrate that GAN architecture can successfully generate time
series signals that are not only structurally similar to the training sets but
also diverse in nature across generated samples. We also report on their
ability to withstand a simple membership inference attack, protecting the
privacy of the training set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09175</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09175</id><created>2019-09-19</created><authors><author><keyname>Cherukuri</keyname><forenames>Venkateswararao</forenames></author><author><keyname>BG</keyname><forenames>Vijay Kumar</forenames></author><author><keyname>Bala</keyname><forenames>Raja</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author></authors><title>Deep Retinal Image Segmentation with Regularization Under Geometric
  Priors</title><categories>eess.IV</categories><comments>Accepted to IEEE TIP</comments><doi>10.1109/TIP.2019.2946078</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vessel segmentation of retinal images is a key diagnostic capability in
ophthalmology. This problem faces several challenges including low contrast,
variable vessel size and thickness, and presence of interfering pathology such
as micro-aneurysms and hemorrhages. Early approaches addressing this problem
employed hand-crafted filters to capture vessel structures, accompanied by
morphological post-processing. More recently, deep learning techniques have
been employed with significantly enhanced segmentation accuracy. We propose a
novel domain enriched deep network that consists of two components: 1) a
representation network that learns geometric features specific to retinal
images, and 2) a custom designed computationally efficient residual task
network that utilizes the features obtained from the representation layer to
perform pixel-level segmentation. The representation and task networks are {\em
jointly learned} for any given training set. To obtain physically meaningful
and practically effective representation filters, we propose two new
constraints that are inspired by expected prior structure on these filters: 1)
orientation constraint that promotes geometric diversity of curvilinear
features, and 2) a data adaptive noise regularizer that penalizes false
positives. Multi-scale extensions are developed to enable accurate detection of
thin vessels. Experiments performed on three challenging benchmark databases
under a variety of training scenarios show that the proposed prior guided deep
network outperforms state of the art alternatives as measured by common
evaluation metrics, while being more economical in network size and inference
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09181</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09181</id><created>2019-09-19</created><authors><author><keyname>Xie</keyname><forenames>Hongxiang</forenames></author><author><keyname>Rodr&#xed;guez-Fern&#xe1;ndez</keyname><forenames>Javier</forenames></author><author><keyname>Gonz&#xe1;lez-Prelcic</keyname><forenames>Nuria</forenames></author></authors><title>Dictionary Learning for Channel Estimation in Hybrid Frequency-Selective
  mmWave MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>30 pages, 8 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exploiting channel sparsity at millimeter wave (mmWave) frequencies reduces
the high training overhead associated with the channel estimation stage.
Compressive sensing (CS) channel estimation techniques usually adopt the
(overcomplete) wavelet/Fourier transform matrix as a sparsifying dictionary.
This may not be the best choice when considering non-uniform arrays, antenna
gain/phase errors, mutual coupling effects, etc. We propose two dictionary
learning (DL) algorithms to learn the best sparsifying dictionaries for channel
matrices from observations obtained with hybrid frequency-selective mmWave
multiple-input-multiple-output (MIMO) systems. First, we optimize the combined
dictionary, i.e., the Kronecker product of transmit and receive dictionaries,
as it is used in practice to sparsify the channel matrix. Second, considering
the different array structures at the transmitter and receiver, we exploit
separable DL to find the best transmit and receive dictionaries. Once the
channel is expressed in terms of the optimized dictionaries, various CS-based
sparse recovery techniques can be applied for low overhead channel estimation.
The proposed DL algorithms perform well under low SNR conditions inherent to
any mmWave communication systems before the precoders/combiners can be
optimized. The effectiveness of the proposed DL algorithms has been
corroborated via numerical simulations with different system configurations,
array geometries and hardware impairments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09183</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09183</id><created>2019-09-19</created><updated>2020-02-20</updated><authors><author><keyname>Wu</keyname><forenames>Ruiyuan</forenames></author><author><keyname>Wai</keyname><forenames>Hoi-To</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>Hybrid Inexact BCD for Coupled Structured Matrix Factorization in
  Hyperspectral Super-Resolution</title><categories>eess.SP eess.IV math.OC</categories><comments>32 pages, 3 figures, 5 tables. Codes available at
  https://github.com/REIYANG/HiBCD. To appear in IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a first-order optimization method for coupled structured
matrix factorization (CoSMF) problems that arise in the context of
hyperspectral super-resolution (HSR) in remote sensing. To best leverage the
problem structures for computational efficiency, we introduce a hybrid inexact
block coordinate descent (HiBCD) scheme wherein one coordinate is updated via
the fast proximal gradient (FPG) method, while another via the Frank-Wolfe (FW)
method. The FPG-type methods are known to take less number of iterations to
converge, by numerical experience, while the FW-type methods can offer lower
per-iteration complexity in certain cases; and we wish to take the best of
both. We show that the limit points of this HiBCD scheme are stationary. Our
proof treats HiBCD as an optimization framework for a class of multi-block
structured optimization problems, and our stationarity claim is applicable not
only to CoSMF but also to many other problems. Previous optimization research
showed the same stationarity result for inexact block coordinate descent with
either FPG or FW updates only. Numerical results indicate that the proposed
HiBCD scheme is computationally much more efficient than the state-of-the-art
CoSMF schemes in HSR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09197</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09197</id><created>2019-09-19</created><authors><author><keyname>Kantareddy</keyname><forenames>Sai Nithin R.</forenames></author><author><keyname>Mathews</keyname><forenames>Ian</forenames></author><author><keyname>Sun</keyname><forenames>Shijing</forenames></author><author><keyname>Layurova</keyname><forenames>Mariya</forenames></author><author><keyname>Thapa</keyname><forenames>Janak</forenames></author><author><keyname>Correa-Baena</keyname><forenames>Juan-Pablo</forenames></author><author><keyname>Buonassisi</keyname><forenames>Rahul Bhattacharyya Tonio</forenames></author><author><keyname>Sarma</keyname><forenames>Sanjay E.</forenames></author><author><keyname>Peters</keyname><forenames>Ian Marius</forenames></author></authors><title>Perovskite PV-powered RFID: enabling low-cost self-powered IoT sensors</title><categories>eess.SP cs.SY eess.SY</categories><journal-ref>IEEE Sensors Journal 2019</journal-ref><doi>10.1109/JSEN.2019.2939293</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photovoltaic (PV) cells have the potential to serve as on-board power sources
for low-power IoT devices. Here, we explore the use of perovskite solar cells
to power Radio Frequency (RF) backscatter-based IoT devices with a few {\mu}W
power demand. Perovskites are suitable for low-cost, high-performance,
low-temperature processing, and flexible light energy harvesting that hold the
possibility to significantly extend the range and lifetime of current
backscatter techniques such as Radio Frequency Identification (RFID). For these
reasons, perovskite solar cells are prominent candidates for future low-power
wireless applications. We report on realizing a functional perovskite-powered
wireless temperature sensor with 4 m communication range. We use a 10.1%
efficient perovskite PV module generating an output voltage of 4.3 V with an
active area of 1.06 cm2 under 1 sun illumination, with AM 1.5G spectrum, to
power a commercial off-the-shelf RFID IC, requiring 10 - 45 {\mu}W of power.
Having an on-board energy harvester provides extra-energy to boost the range of
the sensor (5x) in addition to providing energy to carry out high-volume sensor
measurements (hundreds of measurements per min). Our evaluation of the
prototype suggests that perovskite photovoltaic cells are able to meet the
energy needs to enable fully autonomous low-power RF backscatter applications
of the future. We conclude with an outlook into a range of applications that we
envision to leverage the synergies offered by combining perovskite
photovoltaics and RFID.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09225</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09225</id><created>2019-09-19</created><authors><author><keyname>Dias</keyname><forenames>Philipe A.</forenames></author><author><keyname>Malafronte</keyname><forenames>Damiano</forenames></author><author><keyname>Medeiros</keyname><forenames>Henry</forenames></author><author><keyname>Odone</keyname><forenames>Francesca</forenames></author></authors><title>Gaze Estimation for Assisted Living Environments</title><categories>cs.CV eess.IV</categories><comments>Work to be published in its final version at WACV '20</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective assisted living environments must be able to perform inferences on
how their occupants interact with one another as well as with surrounding
objects. To accomplish this goal using a vision-based automated approach,
multiple tasks such as pose estimation, object segmentation and gaze estimation
must be addressed. Gaze direction in particular provides some of the strongest
indications of how a person interacts with the environment. In this paper, we
propose a simple neural network regressor that estimates the gaze direction of
individuals in a multi-camera assisted living scenario, relying only on the
relative positions of facial keypoints collected from a single pose estimation
model. To handle cases of keypoint occlusion, our model exploits a novel
confidence gated unit in its input layer. In addition to the gaze direction,
our model also outputs an estimation of its own prediction uncertainty.
Experimental results on a public benchmark demonstrate that our approach
performs on pair with a complex, dataset-specific baseline, while its
uncertainty predictions are highly correlated to the actual angular error of
corresponding estimations. Finally, experiments on images from a real assisted
living environment demonstrate the higher suitability of our model for its
final application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09235</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09235</id><created>2019-09-19</created><authors><author><keyname>Qu</keyname><forenames>Ante</forenames></author><author><keyname>James</keyname><forenames>Doug L.</forenames></author></authors><title>On the Impact of Ground Sound</title><categories>cs.SD cs.CE eess.AS</categories><comments>8 pages, 11 figures. In Proceedings of the 22nd International
  Conference on Digital Audio Effects (DAFx-19), Birmingham, UK, September 2-6,
  2019. Audio examples can be downloaded publicly at
  http://graphics.stanford.edu/papers/ground/</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Rigid-body impact sound synthesis methods often omit the ground sound. In
this paper we analyze an idealized ground-sound model based on an elastodynamic
halfspace, and use it to identify scenarios wherein ground sound is
perceptually relevant versus when it is masked by the impacting object's modal
sound or transient acceleration noise. Our analytical model gives a smooth,
closed-form expression for ground surface acceleration, which we can then use
in the Rayleigh integral or in an &quot;acoustic shader&quot; for a finite-difference
time-domain wave simulation. We find that when modal sound is inaudible, ground
sound is audible in scenarios where a dense object impacts a soft ground and
scenarios where the impact point has a low elevation angle to the listening
point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09263</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09263</id><created>2019-09-19</created><updated>2019-09-23</updated><authors><author><keyname>Yoon</keyname><forenames>Jihyeun</forenames></author><author><keyname>Kim</keyname><forenames>Kyungyul</forenames></author><author><keyname>Jang</keyname><forenames>Jongseong</forenames></author></authors><title>Propagated Perturbation of Adversarial Attack for well-known CNNs:
  Empirical Study and its Explanation</title><categories>cs.CV cs.LG eess.IV</categories><journal-ref>ICCV 2019 Workshop on Interpreting and Explaining Visual
  Artificial Intelligence Models</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Neural Network based classifiers are known to be vulnerable to
perturbations of inputs constructed by an adversarial attack to force
misclassification. Most studies have focused on how to make vulnerable noise by
gradient based attack methods or to defense model from adversarial attack. The
use of the denoiser model is one of a well-known solution to reduce the
adversarial noise although classification performance had not significantly
improved. In this study, we aim to analyze the propagation of adversarial
attack as an explainable AI(XAI) point of view. Specifically, we examine the
trend of adversarial perturbations through the CNN architectures. To analyze
the propagated perturbation, we measured normalized Euclidean Distance and
cosine distance in each CNN layer between the feature map of the perturbed
image passed through denoiser and the non-perturbed original image. We used
five well-known CNN based classifiers and three gradient-based adversarial
attacks. From the experimental results, we observed that in most cases,
Euclidean Distance explosively increases in the final fully connected layer
while cosine distance fluctuated and disappeared at the last layer. This means
that the use of denoiser can decrease the amount of noise. However, it failed
to defense accuracy degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09266</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09266</id><created>2019-09-19</created><authors><author><keyname>Hu</keyname><forenames>Zhixiong</forenames></author><author><keyname>Xu</keyname><forenames>Yijun</forenames></author><author><keyname>Korkali</keyname><forenames>Mert</forenames></author><author><keyname>Chen</keyname><forenames>Xiao</forenames></author><author><keyname>Mili</keyname><forenames>Lamine</forenames></author><author><keyname>Tong</keyname><forenames>Charles H.</forenames></author></authors><title>Uncertainty Quantification in Stochastic Economic Dispatch using
  Gaussian Process Emulation</title><categories>eess.SY cs.SY stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing penetration of renewable energy resources in power systems,
represented as random processes, converts the traditional deterministic
economic dispatch problem into a stochastic one. To solve this stochastic
economic dispatch, the conventional Monte Carlo method is prohibitively time
consuming for medium- and large-scale power systems. To overcome this problem,
we propose in this paper a novel Gaussian-process-emulator-based approach to
quantify the uncertainty in the stochastic economic dispatch considering wind
power penetration. Based on the dimension-reduction results obtained by the
Karhunen-Lo\`eve expansion, a Gaussian-process emulator is constructed. This
surrogate allows us to evaluate the economic dispatch solver at sampled values
with a negligible computational cost while maintaining a desirable accuracy.
Simulation results conducted on the IEEE 118-bus system reveal that the
proposed method has an excellent performance as compared to the traditional
Monte Carlo method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09273</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09273</id><created>2019-09-19</created><authors><author><keyname>Tesfaldet</keyname><forenames>Mattie</forenames></author><author><keyname>Snelgrove</keyname><forenames>Xavier</forenames></author><author><keyname>Vazquez</keyname><forenames>David</forenames></author></authors><title>Fourier-CPPNs for Image Synthesis</title><categories>cs.CV eess.IV</categories><comments>Accepted at ICCV Workshops '19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compositional Pattern Producing Networks (CPPNs) are differentiable networks
that independently map (x, y) pixel coordinates to (r, g, b) colour values.
Recently, CPPNs have been used for creating interesting imagery for creative
purposes, e.g., neural art. However their architecture biases generated images
to be overly smooth, lacking high-frequency detail. In this work, we extend
CPPNs to explicitly model the frequency information for each pixel output,
capturing frequencies beyond the DC component. We show that our Fourier-CPPNs
(F-CPPNs) provide improved visual detail for image synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09282</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09282</id><created>2019-09-19</created><authors><author><keyname>Lewis</keyname><forenames>W. Cannon</forenames><suffix>II</suffix></author><author><keyname>Moll</keyname><forenames>Mark</forenames></author><author><keyname>Kavraki</keyname><forenames>Lydia E.</forenames></author></authors><title>How Much Do Unstated Problem Constraints Limit Deep Robotic
  Reinforcement Learning?</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY</categories><comments>Rice University technical report</comments><doi>10.25611/az5z-xt37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Reinforcement Learning is a promising paradigm for robotic control which
has been shown to be capable of learning policies for high-dimensional,
continuous control of unmodeled systems. However, RoboticReinforcement Learning
currently lacks clearly defined benchmark tasks, which makes it difficult for
researchers to reproduce and compare against prior work. ``Reacher'' tasks,
which are fundamental to robotic manipulation, are commonly used as benchmarks,
but the lack of a formal specification elides details that are crucial to
replication. In this paper we present a novel empirical analysis which shows
that the unstated spatial constraints in commonly used implementations of
Reacher tasks make it dramatically easier to learn a successful control policy
with DeepDeterministic Policy Gradients (DDPG), a state-of-the-art Deep RL
algorithm. Our analysis suggests that less constrained Reacher tasks are
significantly more difficult to learn, and hence that existing de facto
benchmarks are not representative of the difficulty of general robotic
manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09300</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09300</id><created>2019-09-19</created><authors><author><keyname>Li</keyname><forenames>Tianhong</forenames></author><author><keyname>Fan</keyname><forenames>Lijie</forenames></author><author><keyname>Zhao</keyname><forenames>Mingmin</forenames></author><author><keyname>Liu</keyname><forenames>Yingcheng</forenames></author><author><keyname>Katabi</keyname><forenames>Dina</forenames></author></authors><title>Making the Invisible Visible: Action Recognition Through Walls and
  Occlusions</title><categories>cs.CV cs.LG eess.IV</categories><comments>ICCV 2019. The first two authors contributed equally to this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding people's actions and interactions typically depends on seeing
them. Automating the process of action recognition from visual data has been
the topic of much research in the computer vision community. But what if it is
too dark, or if the person is occluded or behind a wall? In this paper, we
introduce a neural network model that can detect human actions through walls
and occlusions, and in poor lighting conditions. Our model takes radio
frequency (RF) signals as input, generates 3D human skeletons as an
intermediate representation, and recognizes actions and interactions of
multiple people over time. By translating the input to an intermediate
skeleton-based representation, our model can learn from both vision-based and
RF-based datasets, and allow the two tasks to help each other. We show that our
model achieves comparable accuracy to vision-based action recognition systems
in visible scenarios, yet continues to work accurately when people are not
visible, hence addressing scenarios that are beyond the limit of today's
vision-based action recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09313</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09313</id><created>2019-09-20</created><authors><author><keyname>Liu</keyname><forenames>Jiaming</forenames></author><author><keyname>Sun</keyname><forenames>Yu</forenames></author><author><keyname>Kamilov</keyname><forenames>Ulugbek S.</forenames></author></authors><title>Infusing Learned Priors into Model-Based Multispectral Imaging</title><categories>eess.IV cs.CV</categories><comments>arXiv admin note: text overlap with arXiv:1905.05113</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new algorithm for regularized reconstruction of multispectral
(MS) images from noisy linear measurements. Unlike traditional approaches, the
proposed algorithm regularizes the recovery problem by using a prior specified
\emph{only} through a learned denoising function. More specifically, we propose
a new accelerated gradient method (AGM) variant of regularization by denoising
(RED) for model-based MS image reconstruction. The key ingredient of our
approach is the three-dimensional (3D) deep neural net (DNN) denoiser that can
fully leverage spationspectral correlations within MS images. Our results
suggest the generalizability of our MS-RED algorithm, where a single trained
DNN can be used to solve several different MS imaging problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09316</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09316</id><created>2019-09-20</created><authors><author><keyname>Wu</keyname><forenames>Penghai</forenames></author><author><keyname>Yin</keyname><forenames>Zhixiang</forenames></author><author><keyname>Zeng</keyname><forenames>Chao</forenames></author><author><keyname>Duan</keyname><forenames>Sibo</forenames></author><author><keyname>Gottsche</keyname><forenames>Frank-Michael</forenames></author><author><keyname>Ma</keyname><forenames>Xiaoshaung</forenames></author><author><keyname>Li</keyname><forenames>Xinghua</forenames></author><author><keyname>Yang</keyname><forenames>Hui</forenames></author><author><keyname>Shen</keyname><forenames>Huanfeng</forenames></author></authors><title>Spatially Continuous and High-resolution Land Surface Temperature: A
  Review of Reconstruction and Spatiotemporal Fusion Techniques</title><categories>physics.ao-ph eess.IV physics.data-an</categories><comments>41 pages, 7 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remotely sensed, spatially continuous and high spatiotemporal resolution
(hereafter referred to as high resolution) land surface temperature (LST) is a
key parameter for studying the thermal environment and has important
applications in many fields. However, difficult atmospheric conditions, sensor
malfunctioning and scanning gaps between orbits frequently introduce spatial
discontinuities into satellite-retri1eved LST products. For a single sensor,
there is also a trade-off between temporal and spatial resolution and,
therefore, it is impossible to obtain high temporal and spatial resolution
simultaneously. In recent years the reconstruction and spatiotemporal fusion of
LST products have become active research topics that aim at overcoming this
limitation. They are two of most investigated approaches in thermal remote
sensing and attract increasing attention, which has resulted in a number of
different algorithms. However, to the best of our knowledge, currently no
review exists that expatiates and summarizes the available LST reconstruction
and spatiotemporal fusion methods and algorithms. This paper introduces the
principles and theories behind LST reconstruction and spatiotemporal fusion and
provides an overview of the published research and algorithms. We summarized
three kinds of reconstruction methods for missing pixels (spatial, temporal and
spatiotemporal methods), two kinds of reconstruction methods for cloudy pixels
(Satellite Passive Microwave (PMW)-based and Surface Energy Balance (SEB)-based
methods) and three kinds of spatiotemporal fusion methods (weighted
function-based, unmixing-based and hybrid methods). The review concludes by
summarizing validation methods and by identifying some promising future
research directions for generating spatially continuous and high resolution LST
products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09323</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09323</id><created>2019-09-20</created><authors><author><keyname>Lin</keyname><forenames>Jintian</forenames></author><author><keyname>Zhang</keyname><forenames>Yichao</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoru</forenames></author><author><keyname>Chen</keyname><forenames>Qingyue</forenames></author></authors><title>Post-Disturbance Dynamic Frequency Features Prediction Based on
  Convolutional Neural Network</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The significant imbalance between power generation and load caused by severe
disturbance may make the power system unable to maintain a steady frequency. If
the post-disturbance dynamic frequency features can be predicted and emergency
controls are appropriately taken, the risk of frequency instability will be
greatly reduced. In this paper, a predictive algorithm for post-disturbance
dynamic frequency features is proposed based on convolutional neural network
(CNN) . The operation data before and immediately after disturbance is used to
construct the input tensor data of CNN, with the dynamic frequency features of
the power system after the disturbance as the output. The operation data of the
power system such as generators unbalanced power has spatial distribution
characteristics. The electrical distance is presented to describe the spatial
correlation of power system nodes, and the t-SNE dimensionality reduction
algorithm is used to map the high-dimensional distance information of nodes to
the 2-D plane, thereby constructing the CNN input tensor to reflect spatial
distribution of nodes operation data on 2-D plane. The CNN with deep network
structure and local connectivity characteristics is adopted and the network
parameters are trained by utilizing the backpropagation-gradient descent
algorithm. The case study results on an improved IEEE 39-node system and an
actual power grid in USA shows that the proposed method can predict the lowest
frequency of power system after the disturbance accurately and quickly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09339</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09339</id><created>2019-09-20</created><authors><author><keyname>Fan</keyname><forenames>Ye</forenames></author><author><keyname>Liao</keyname><forenames>Xuewen</forenames></author><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Secure Interference Exploitation Precoding in MISO Wiretap Channel:
  Destructive Region Redefinition with Efficient Solutions</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 12 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the physical layer security for a K-user
multiple-input-single-output (MISO) wiretap channel in the presence of a
malicious eavesdropper, where we propose several interference exploitation (IE)
precoding schemes for different types of the eavesdropper. Specifically, in the
case where a common eavesdropper decodes the signal directly and Eve's full
channel state information (CSI) is available at the transmitter, we show that
the required transmit power can be further reduced by re-designing the
`destructive region' of the constellations for symbol-level precoding and
re-formulating the power minimization problem. We further study the SINR
balancing problems with the derived `complete destructive region' with full,
statistical and no Eve's CSI, respectively, and show that the SINR balancing
problem becomes non-convex with statistical or no Eve's CSI. On the other hand,
in the presence of a smart eavesdropper using maximal likelihood (ML)
detection, the security cannot be guaranteed with all the existing approaches.
To this end, we further propose a random jamming scheme (RJS) and a random
precoding scheme (RPS), respectively. To solve the introduced convex/non-convex
problems in an efficient manner, we propose an iterative algorithm for the
convex ones based on the Karush-Kuhn-Tucker (KKT) conditions, and deal with the
non-convex ones by resorting to Taylor expansions. Simulation results show that
all proposed schemes outperform the existing works in secrecy performance, and
that the proposed algorithm improves the computation efficiency significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09347</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09347</id><created>2019-09-20</created><authors><author><keyname>Purohit</keyname><forenames>Harsh</forenames></author><author><keyname>Tanabe</keyname><forenames>Ryo</forenames></author><author><keyname>Ichige</keyname><forenames>Kenji</forenames></author><author><keyname>Endo</keyname><forenames>Takashi</forenames></author><author><keyname>Nikaido</keyname><forenames>Yuki</forenames></author><author><keyname>Suefusa</keyname><forenames>Kaori</forenames></author><author><keyname>Kawaguchi</keyname><forenames>Yohei</forenames></author></authors><title>MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine
  Investigation and Inspection</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, to appear in DCASE 2019 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Factory machinery is prone to failure or breakdown, resulting in significant
expenses for companies. Hence, there is a rising interest in machine monitoring
using different sensors including microphones. In the scientific community, the
emergence of public datasets has led to advancements in acoustic detection and
classification of scenes and events, but there are no public datasets that
focus on the sound of industrial machines under normal and anomalous operating
conditions in real factory environments. In this paper, we present a new
dataset of industrial machine sounds that we call a sound dataset for
malfunctioning industrial machine investigation and inspection (MIMII dataset).
Normal sounds were recorded for different types of industrial machines (i.e.,
valves, pumps, fans, and slide rails), and to resemble a real-life scenario,
various anomalous sounds were recorded (e.g., contamination, leakage, rotating
unbalance, and rail damage). The purpose of releasing the MIMII dataset is to
assist the machine-learning and signal-processing community with their
development of automated facility maintenance. The MIMII dataset is freely
available for download at: https://zenodo.org/record/3384388
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09349</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09349</id><created>2019-09-20</created><updated>2019-10-02</updated><authors><author><keyname>Bello</keyname><forenames>Juan Luis Gonzalez</forenames></author><author><keyname>Kim</keyname><forenames>Munchurl</forenames></author></authors><title>Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom</title><categories>eess.IV cs.CV eess.SP</categories><comments>Check our video at https://www.youtube.com/watch?v=Gz76VYwUzZ8</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3D-zoom operation is the positive translation of the camera in the
Z-axis, perpendicular to the image plane. In contrast, the optical zoom changes
the focal length and the digital zoom is used to enlarge a certain region of an
image to the original image size. In this paper, we are the first to formulate
an unsupervised 3D-zoom learning problem where images with an arbitrary zoom
factor can be generated from a given single image. An unsupervised framework is
convenient, as it is a challenging task to obtain a 3D-zoom dataset of natural
scenes due to the need for special equipment to ensure camera movement is
restricted to the Z-axis. In addition, the objects in the scenes should not
move when being captured, which hinders the construction of a large dataset of
outdoor scenes. We present a novel unsupervised framework to learn how to
generate arbitrarily 3D-zoomed versions of a single image, not requiring a
3D-zoom ground truth, called the Deep 3D-Zoom Net. The Deep 3D-Zoom Net
incorporates the following features: (i) transfer learning from a pre-trained
disparity estimation network via a back re-projection reconstruction loss; (ii)
a fully convolutional network architecture that models depth-image-based
rendering (DIBR), taking into account high-frequency details without the need
for estimating the intermediate disparity; and (iii) incorporating a
discriminator network that acts as a no-reference penalty for unnaturally
rendered areas. Even though there is no baseline to fairly compare our results,
our method outperforms previous novel view synthesis research in terms of
realistic appearance on large camera baselines. We performed extensive
experiments to verify the effectiveness of our method on the KITTI and
Cityscapes datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09398</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09398</id><created>2019-09-20</created><updated>2020-01-12</updated><authors><author><keyname>von Tschirschnitz</keyname><forenames>Maximilian</forenames></author><author><keyname>Wagner</keyname><forenames>Marcel</forenames></author><author><keyname>Pahl</keyname><forenames>Marc-Oliver</forenames></author><author><keyname>Carle</keyname><forenames>Georg</forenames></author></authors><title>Clock Error Analysis of Common Time of Flight based Positioning Methods</title><categories>cs.NI eess.SP</categories><comments>Published in IEEEXplore:
  https://ieeexplore.ieee.org/abstract/document/8911772</comments><doi>10.1109/IPIN.2019.8911772</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, many applications such as production or rescue settings rely on highly
accurate entity positioning. Advanced Time of Flight (ToF) based positioning
methods provide highaccuracy localization of entities. A key challenge for ToF
based positioning is to synchronize the clocks between the participating
entities. This paper summarizes and analyzes ToA and TDoA methods with respect
to clock error robustness. The focus is on synchronization-less methods, i.e.
methods which reduce the infrastructure requirement significantly. We introduce
a unified notation to survey and compare the relevant work from literature.
Then we apply a clock error model and compute worst case location-accuracy
errors. Our analysis reveals a superior error robustness against clock errors
for so called Double-Pulse methods when applied to radio based ToF positioning
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09399</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09399</id><created>2019-09-20</created><authors><author><keyname>Agravat</keyname><forenames>Rupal</forenames></author><author><keyname>Raval</keyname><forenames>Mehul S</forenames></author></authors><title>Brain Tumor Segmentation and Survival Prediction</title><categories>eess.IV cs.CV cs.LG q-bio.QM stat.ML</categories><comments>9 Pages</comments><journal-ref>BraTS 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper demonstrates the use of the fully convolutional neural network for
glioma segmentation on the BraTS 2019 dataset. Three-layers deep
encoder-decoder architecture is used along with dense connection at encoder
part to propagate the information from coarse layer to deep layers. This
architecture is used to train three tumor sub-components separately.
Subcomponent training weights are initialized with whole tumor weights to get
the localization of the tumor within the brain. At the end, three segmentation
results were merged to get the entire tumor segmentation. Dice Similarity of
training dataset with focal loss implementation for whole tumor, tumor core and
enhancing tumor is 0.92, 0.90 and 0.79 respectively. Radiomic features along
with segmentation results and age are used to predict the overall survival of
patients using random forest regressor to classify survival of patients in
long, medium and short survival classes. 55.4% of classification accuracy is
reported for training dataset with the scans whose resection status is
gross-total resection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09417</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09417</id><created>2019-09-20</created><authors><author><keyname>Vlaski</keyname><forenames>Stefan</forenames></author><author><keyname>Vandenberghe</keyname><forenames>Lieven</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Regularized Diffusion Adaptation via Conjugate Smoothing</title><categories>math.OC cs.DC cs.MA eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this work is to develop and study a distributed strategy for
Pareto optimization of an aggregate cost consisting of regularized risks. Each
risk is modeled as the expectation of some loss function with unknown
probability distribution while the regularizers are assumed deterministic, but
are not required to be differentiable or even continuous. The individual,
regularized, cost functions are distributed across a strongly-connected network
of agents and the Pareto optimal solution is sought by appealing to a
multi-agent diffusion strategy. To this end, the regularizers are smoothed by
means of infimal convolution and it is shown that the Pareto solution of the
approximate, smooth problem can be made arbitrarily close to the solution of
the original, non-smooth problem. Performance bounds are established under
conditions that are weaker than assumed before in the literature, and hence
applicable to a broader class of adaptation and learning problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09437</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09437</id><created>2019-09-20</created><updated>2020-02-24</updated><authors><author><keyname>Islam</keyname><forenames>Md Jahidul</forenames></author><author><keyname>Enan</keyname><forenames>Sadman Sakib</forenames></author><author><keyname>Luo</keyname><forenames>Peigen</forenames></author><author><keyname>Sattar</keyname><forenames>Junaed</forenames></author></authors><title>Underwater Image Super-Resolution using Deep Residual Multipliers</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deep residual network-based generative model for single image
super-resolution (SISR) of underwater imagery for use by autonomous underwater
robots. We also provide an adversarial training pipeline for learning SISR from
paired data. In order to supervise the training, we formulate an objective
function that evaluates the \textit{perceptual quality} of an image based on
its global content, color, and local style information. Additionally, we
present USR-248, a large-scale dataset of three sets of underwater images of
'high' (640x480) and 'low' (80x60, 160x120, and 320x240) spatial resolution.
USR-248 contains paired instances for supervised training of 2x, 4x, or 8x SISR
models. Furthermore, we validate the effectiveness of our proposed model
through qualitative and quantitative experiments and compare the results with
several state-of-the-art models' performances. We also analyze its practical
feasibility for applications such as scene understanding and attention modeling
in noisy visual conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09440</identifier>
 <datestamp>2019-11-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09440</id><created>2019-09-20</created><updated>2019-11-22</updated><authors><author><keyname>Jensen</keyname><forenames>Tobias Lindstr&#xf8;m</forenames></author><author><keyname>De Carvalho</keyname><forenames>Elisabeth</forenames></author></authors><title>An Optimal Channel Estimation Scheme for Intelligent Reflecting Surfaces
  based on a Minimum Variance Unbiased Estimator</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a wireless system with Intelligent Reflective Surfaces (IRS) containing
many passive elements, we consider the problem of channel estimation. All the
links from the transmitter to the receiver via each IRS elements (or groups)
are estimated. As the estimation performance are dependent on the setting of
the IRS, we design an optimal channel estimation scheme where the IRS elements
follow an optimal series of activation patterns. The optimal design is guided
by results for the minimum variance unbiased estimation. The IRS setting during
the channel estimation period mimics a series of discrete Fourier transforms.
We show theoretically and with simulations that the estimation variance is one
order smaller compared to existing on/off methods proposed in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09441</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09441</id><created>2019-09-20</created><authors><author><keyname>Aydogdu</keyname><forenames>Canan</forenames></author><author><keyname>Carvajal</keyname><forenames>Gisela K.</forenames></author><author><keyname>Eriksson</keyname><forenames>Olof</forenames></author><author><keyname>Hellsten</keyname><forenames>Hans</forenames></author><author><keyname>Herbertsson</keyname><forenames>Hans</forenames></author><author><keyname>Keskin</keyname><forenames>Musa Furkan</forenames></author><author><keyname>Nilsson</keyname><forenames>Emil</forenames></author><author><keyname>Rydstr&#xf6;m</keyname><forenames>Mats</forenames></author><author><keyname>Van&#xe4;s</keyname><forenames>Karl</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author></authors><title>Radar Interference Mitigation for Automated Driving</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous driving relies on a variety of sensors, especially on radars,
which have unique robustness under heavy rain/fog/snow and poor light
conditions. With the rapid increase of the amount of radars used on modern
vehicles, where most radars operate in the same frequency band, the risk of
radar interference becomes a compelling issue. This article analyses automotive
radar interference and proposes several new approaches, which combine
industrial and academic expertise, toward the path of interference-free
autonomous driving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09459</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09459</id><created>2019-09-19</created><updated>2019-12-23</updated><authors><author><keyname>Zheng</keyname><forenames>Qiang</forenames></author><author><keyname>Zeng</keyname><forenames>Lingzao</forenames></author><author><keyname>Cao</keyname><forenames>Zhendan</forenames></author><author><keyname>Karniadakis</keyname><forenames>George Em</forenames></author></authors><title>Physics-informed semantic inpainting: Application to geostatistical
  modeling</title><categories>eess.IV cs.LG physics.comp-ph stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in geostatistical modeling is to infer the
heterogeneous geological field based on limited measurements and some prior
spatial statistics. Semantic inpainting, a technique for image processing using
deep generative models, has been recently applied for this purpose,
demonstrating its effectiveness in dealing with complex spatial patterns.
However, the original semantic inpainting framework incorporates only
information from direct measurements, while in geostatistics indirect
measurements are often plentiful. To overcome this limitation, here we propose
a physics-informed semantic inpainting framework, employing the Wasserstein
Generative Adversarial Network with Gradient Penalty (WGAN-GP) and jointly
incorporating the direct and indirect measurements by exploiting the underlying
physical laws. Our simulation results for a high-dimensional problem with 512
dimensions show that in the new method, the physical conservation laws are
satisfied and contribute in enhancing the inpainting performance compared to
using only the direct measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09505</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09505</id><created>2019-09-20</created><updated>2019-10-15</updated><authors><author><keyname>Chang</keyname><forenames>Yuchen</forenames></author><author><keyname>Matsumoto</keyname><forenames>Keigo</forenames></author><author><keyname>Narumi</keyname><forenames>Takuji</forenames></author><author><keyname>Tanikawa</keyname><forenames>Tomohiro</forenames></author><author><keyname>Hirose</keyname><forenames>Michitaka</forenames></author></authors><title>Redirection Controller Using Reinforcement Learning</title><categories>cs.LG cs.RO eess.SP</categories><comments>13 pages, 9 figures, IEEE Access under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing demand for planning redirected walking techniques and
applying them to physical environments with obstacles. Such techniques are
mainly managed using three kinds of methods: direct scripting, generalized
controller, and physical- or virtual-environment analysis to determine user
redirection. The first approach is effective when a user's path and both
physical and virtual environments are fixed; however, it is difficult to handle
irregular movements and reuse other environments. The second approach has the
potential of reusing any environment but is less optimized. The last approach
is highly anticipated and versatile, although it has not been sufficiently
developed. In this study, we propose a novel redirection controller using
reinforcement learning with advanced plannability/versatility. Our simulation
experiments show that the proposed strategy can reduce the number of resets by
20.3% for physical-space conditions with multiple obstacles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09541</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09541</id><created>2019-09-20</created><authors><author><keyname>Motamed</keyname><forenames>Saman</forenames></author><author><keyname>Gujrathi</keyname><forenames>Isha</forenames></author><author><keyname>Deniffel</keyname><forenames>Dominik</forenames></author><author><keyname>Oentoro</keyname><forenames>Anton</forenames></author><author><keyname>Haider</keyname><forenames>Masoom A.</forenames></author><author><keyname>Khalvati</keyname><forenames>Farzad</forenames></author></authors><title>A Transfer Learning Approach for Automated Segmentation of Prostate
  Whole Gland and Transition Zone in Diffusion Weighted MRI</title><categories>eess.IV cs.CV cs.LG q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The segmentation of prostate whole gland and transition zone in Diffusion
Weighted MRI (DWI) are the first step in designing computer-aided detection
algorithms for prostate cancer. However, variations in MRI acquisition
parameters and scanner manufacturing result in different appearances of
prostate tissue in the images. Convolutional neural networks (CNNs) which have
shown to be successful in various medical image analysis tasks including
segmentation are typically sensitive to the variations in imaging parameters.
This sensitivity leads to poor segmentation performance of CNNs trained on a
source cohort and tested on a target cohort from a different scanner and hence,
it limits the applicability of CNNs for cross-cohort training and testing.
Contouring prostate whole gland and transition zone in DWI images are
time-consuming and expensive. Thus, it is important to enable CNNs pretrained
on images of source domain, to segment images of target domain with minimum
requirement for manual segmentation of images from the target domain. In this
work, we propose a transfer learning method based on a modified U-net
architecture and loss function, for segmentation of prostate whole gland and
transition zone in DWIs using a CNN pretrained on a source dataset and tested
on the target dataset. We explore the effect of the size of subset of target
dataset used for fine-tuning the pre-trained CNN on the overall segmentation
accuracy. Our results show that with a fine-tuning data as few as 30 patients
from the target domain, the proposed transfer learning-based algorithm can
reach dice score coefficient of 0.80 for both prostate whole gland and
transition zone segmentation. Using a fine-tuning data of 115 patients from the
target domain, dice score coefficient of 0.85 and 0.84 are achieved for
segmentation of whole gland and transition zone, respectively, in the target
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09552</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09552</id><created>2019-09-20</created><updated>2020-02-14</updated><authors><author><keyname>Wu</keyname><forenames>Tong</forenames></author><author><keyname>Tong</keyname><forenames>Liang</forenames></author><author><keyname>Vorobeychik</keyname><forenames>Yevgeniy</forenames></author></authors><title>Defending Against Physically Realizable Attacks on Image Classification</title><categories>cs.LG cs.AI cs.CV eess.IV stat.ML</categories><comments>camera-ready</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of defending deep neural network approaches for image
classification from physically realizable attacks. First, we demonstrate that
the two most scalable and effective methods for learning robust models,
adversarial training with PGD attacks and randomized smoothing, exhibit very
limited effectiveness against three of the highest profile physical attacks.
Next, we propose a new abstract adversarial model, rectangular occlusion
attacks, in which an adversary places a small adversarially crafted rectangle
in an image, and develop two approaches for efficiently computing the resulting
adversarial examples. Finally, we demonstrate that adversarial training using
our new attack yields image classification models that exhibit high robustness
against the physically realizable attacks we study, offering the first
effective generic defense against such attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09577</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09577</id><created>2019-09-13</created><authors><author><keyname>Kuchaiev</keyname><forenames>Oleksii</forenames></author><author><keyname>Li</keyname><forenames>Jason</forenames></author><author><keyname>Nguyen</keyname><forenames>Huyen</forenames></author><author><keyname>Hrinchuk</keyname><forenames>Oleksii</forenames></author><author><keyname>Leary</keyname><forenames>Ryan</forenames></author><author><keyname>Ginsburg</keyname><forenames>Boris</forenames></author><author><keyname>Kriman</keyname><forenames>Samuel</forenames></author><author><keyname>Beliaev</keyname><forenames>Stanislav</forenames></author><author><keyname>Lavrukhin</keyname><forenames>Vitaly</forenames></author><author><keyname>Cook</keyname><forenames>Jack</forenames></author><author><keyname>Castonguay</keyname><forenames>Patrice</forenames></author><author><keyname>Popova</keyname><forenames>Mariya</forenames></author><author><keyname>Huang</keyname><forenames>Jocelyn</forenames></author><author><keyname>Cohen</keyname><forenames>Jonathan M.</forenames></author></authors><title>NeMo: a toolkit for building AI applications using Neural Modules</title><categories>cs.LG cs.CL cs.SD eess.AS</categories><comments>6 pages plus references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NeMo (Neural Modules) is a Python framework-agnostic toolkit for creating AI
applications through re-usability, abstraction, and composition. NeMo is built
around neural modules, conceptual blocks of neural networks that take typed
inputs and produce typed outputs. Such modules typically represent data layers,
encoders, decoders, language models, loss functions, or methods of combining
activations. NeMo makes it easy to combine and re-use these building blocks
while providing a level of semantic correctness checking via its neural type
system. The toolkit comes with extendable collections of pre-built modules for
automatic speech recognition and natural language processing. Furthermore, NeMo
provides built-in support for distributed training and mixed precision on
latest NVIDIA GPUs. NeMo is open-source https://github.com/NVIDIA/NeMo
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09585</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09585</id><created>2019-09-18</created><authors><author><keyname>Mohapatra</keyname><forenames>Debasish Ray</forenames></author><author><keyname>Zappi</keyname><forenames>Victor</forenames></author><author><keyname>Fels</keyname><forenames>Sidney</forenames></author></authors><title>An extended two-dimensional vocal tract model for fast acoustic
  simulation of single-axis symmetric three-dimensional tubes</title><categories>cs.SD eess.AS</categories><comments>5 pages, 2 figures, Interspeech 2019 submission</comments><doi>10.21437/Interspeech.2019-1764</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The simulation of two-dimensional (2D) wave propagation is an affordable
computational task and its use can potentially improve time performance in
vocal tracts' acoustic analysis. Several models have been designed that rely on
2D wave solvers and include 2D representations of three-dimensional (3D) vocal
tract-like geometries. However, until now, only the acoustics of straight 3D
tubes with circular cross-sections have been successfully replicated with this
approach. Furthermore, the simulation of the resulting 2D shapes requires
extremely high spatio-temporal resolutions, dramatically reducing the speed
boost deriving from the usage of a 2D wave solver. In this paper, we introduce
an in-progress novel vocal tract model that extends the 2D Finite-Difference
Time-Domain wave solver (2.5D FDTD) by adding tube depth, derived from the area
functions, to the acoustic solver. The model combines the speed of a light 2D
numerical scheme with the ability to natively simulate 3D tubes that are
symmetric in one dimension, hence relaxing previous resolution requirements. An
implementation of the 2.5D FDTD is presented, along with evaluation of its
performance in the case of static vowel modeling. The paper discusses the
current features and limits of the approach, and the potential impact on
computational acoustics applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09612</identifier>
 <datestamp>2019-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09612</id><created>2019-09-16</created><authors><author><keyname>Carrillo</keyname><forenames>Fabio</forenames></author><author><keyname>Roner</keyname><forenames>Simon</forenames></author><author><keyname>von Atzigen</keyname><forenames>Marco</forenames></author><author><keyname>Schweizer</keyname><forenames>Andreas</forenames></author><author><keyname>Nagy</keyname><forenames>Ladislav</forenames></author><author><keyname>Vlachopoulos</keyname><forenames>Lazaros</forenames></author><author><keyname>Snedeker</keyname><forenames>Jess G.</forenames></author><author><keyname>F&#xfc;rnstahl</keyname><forenames>Philipp</forenames></author></authors><title>An Automatic Genetic Algorithm Framework for the Optimization of
  Three-dimensional Surgical Plans of Forearm Corrective Osteotomies</title><categories>physics.med-ph eess.IV</categories><comments>37 pages, 15 figures, submitted to Medical Image Analysis Journal</comments><journal-ref>Medical Image Analysis, 101598 (2019)</journal-ref><doi>10.1016/j.media.2019.101598</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  3D computer-assisted corrective osteotomy has become the state-of-the-art for
surgical treatment of complex bone deformities. Despite available technologies,
the automatic generation of clinically acceptable, ready-to-use preoperative
planning solutions is currently not possible for such pathologies. Multiple
contradicting and mutually dependent objectives have to be considered, as well
as clinical and technical constraints, generally requiring iterative manual
adjustments. This leads to unnecessary efforts and unbearable clinical costs,
hindering also the quality of patient treatment. In this paper, we propose an
optimization framework for the generation of ready-to-use preoperative planning
solutions in a fully automatic fashion. An automatic diagnostic assessment
using patient-specific 3D models is performed for 3D malunion quantification
and definition of the optimization parameters. Afterward, clinical objectives
are translated into the optimization module, and controlled through tailored
fitness functions based on a weighted and multi-staged optimization approach.
The optimization is based on a genetic algorithm capable of solving
multi-objective optimization problems with non-linear constraints. The
framework outputs a complete preoperative planning solution including position
and orientation of the osteotomy plane, transformation to achieve the bone
reduction, and position and orientation of the fixation plate and screws. A
qualitative validation was performed on 36 consecutive cases of radius
osteotomy where solutions generated by the optimization algorithm (OA) were
compared against the gold standard (GS) solutions generated by experienced
surgeons. Solutions were blinded and presented to 6 readers, who voted OA
solutions to be better in 55% of the time. The quantitative evaluation was
based on different error measurements, showing average improvements with
respect to the GS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09629</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09629</id><created>2019-09-20</created><authors><author><keyname>Lugmayr</keyname><forenames>Andreas</forenames></author><author><keyname>Danelljan</keyname><forenames>Martin</forenames></author><author><keyname>Timofte</keyname><forenames>Radu</forenames></author></authors><title>Unsupervised Learning for Real-World Super-Resolution</title><categories>eess.IV cs.CV</categories><comments>To appear in the AIM 2019 workshop at ICCV. Includes supplementary
  material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most current super-resolution methods rely on low and high resolution image
pairs to train a network in a fully supervised manner. However, such image
pairs are not available in real-world applications. Instead of directly
addressing this problem, most works employ the popular bicubic downsampling
strategy to artificially generate a corresponding low resolution image.
Unfortunately, this strategy introduces significant artifacts, removing natural
sensor noise and other real-world characteristics. Super-resolution networks
trained on such bicubic images therefore struggle to generalize to natural
images. In this work, we propose an unsupervised approach for image
super-resolution. Given only unpaired data, we learn to invert the effects of
bicubic downsampling in order to restore the natural image characteristics
present in the data. This allows us to generate realistic image pairs,
faithfully reflecting the distribution of real-world images. Our
super-resolution network can therefore be trained with direct pixel-wise
supervision in the high resolution domain, while robustly generalizing to real
input. We demonstrate the effectiveness of our approach in quantitative and
qualitative experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09676</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09676</id><created>2019-09-20</created><authors><author><keyname>Kakhki</keyname><forenames>M. Kazemnia</forenames><affiliation>federal university of rio de janeiro</affiliation></author><author><keyname>Mansur</keyname><forenames>W. J.</forenames><affiliation>federal university of rio de janeiro</affiliation></author><author><keyname>Aghazadeh</keyname><forenames>K.</forenames><affiliation>tehran university</affiliation></author></authors><title>Robust and high-resolution seismic complex trace analysis</title><categories>physics.geo-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismic attributes calculated by conventional methods are susceptible to
noise. Conventional filtering reduces the noise in the cost of losing the
spectral bandwidth. The challenge of having a high-resolution and robust signal
processing tool motivated us to propose a sparse time-frequency decomposition
while is stabilized for random noise. The procedure initiates by using
Sparsity-based adaptive S-transform to regularize abrupt variations in
frequency content of the nonstationary signals. Then, considering the fact that
a higher amplitude of a frequency component results in a higher signal to noise
ratio, an adaptive filter is applied to the time-frequency spectrum which is
sparcified previously. The proposed zero adaptive filter enhances the high
amplitude frequency components while suppresses the lower ones. The performance
of the proposed method is compared to the sparse S-transform and the robust
window Hilbert transform in estimation of instantaneous attributes by applying
on synthetic and real data sets. Seismic attributes estimated by the proposed
method is superior to the conventional ones in terms of its robustness and high
resolution image. The proposed approach has a vast application in
interpretation and identification of geological structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09678</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09678</id><created>2019-09-20</created><authors><author><keyname>Fekom</keyname><forenames>Mathilde</forenames></author><author><keyname>Vayatis</keyname><forenames>Nicolas</forenames></author><author><keyname>Kalogeratos</keyname><forenames>Argyris</forenames></author></authors><title>Sequential Dynamic Resource Allocation for Epidemic Control</title><categories>eess.SY cs.AI cs.DM cs.SI cs.SY math.OC</categories><comments>6 pages, 5 figures</comments><msc-class>68W27, 65C50, 90B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under the Dynamic Resource Allocation (DRA) model, an administrator has the
mission to allocate dynamically a limited budget of resources to the nodes of a
network in order to reduce a diffusion process (DP) (e.g. an epidemic). The
standard DRA assumes that the administrator has constantly full information and
instantaneous access to the entire network. Towards bringing such strategies
closer to real-life constraints, we first present the Restricted DRA model
extension where, at each intervention round, the access is restricted to only a
fraction of the network nodes, called sample. Then, inspired by sequential
selection problems such as the well-known Secretary Problem, we propose the
Sequential DRA (SDRA) model. Our model introduces a sequential aspect in the
decision process over the sample of each round, offering a completely new
perspective to the dynamic DP control. Finally, we incorporate several
sequential selection algorithms to SDRA control strategies and compare their
performance in SIS epidemic simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09703</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09703</id><created>2019-09-20</created><authors><author><keyname>Chapman</keyname><forenames>Margaret P.</forenames></author><author><keyname>Lacotte</keyname><forenames>Jonathan P.</forenames></author><author><keyname>Smith</keyname><forenames>Kevin M.</forenames></author><author><keyname>Yang</keyname><forenames>Insoon</forenames></author><author><keyname>Han</keyname><forenames>Yuxi</forenames></author><author><keyname>Pavone</keyname><forenames>Marco</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire J.</forenames></author></authors><title>Risk-sensitive safety specifications for stochastic systems using
  Conditional Value-at-Risk</title><categories>eess.SY cs.SY</categories><comments>under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a safety analysis method that facilitates a tunable
balance between worst-case and risk-neutral perspectives. First, we define a
risk-sensitive safe set to specify the degree of safety attained by a
stochastic system. This set is defined as a sublevel set of the solution to an
optimal control problem that is expressed using the Conditional Value-at-Risk
(CVaR) measure. This problem does not satisfy Bellman's Principle, thus our
next contribution is to show how risk-sensitive safe sets can be
under-approximated by the solution to a CVaR-Markov Decision Process. Our third
and fourth contributions are to show that a value iteration algorithm solves
the reduced problem and enables tractable policy synthesis for a class of
linear systems. Fifth, we develop a realistic numerical example of a stormwater
system to show that our approach can be applied to non-linear systems. Finally,
we compare the CVaR criterion to the exponential disutility criterion. The
latter allocates control effort evenly across the cost distribution to reduce
variance, while the CVaR criterion focuses control effort on a given worst-case
quantile--where it matters most for safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09705</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09705</id><created>2019-09-20</created><authors><author><keyname>Mousavi</keyname><forenames>Hossein K.</forenames></author><author><keyname>Liu</keyname><forenames>Guangyi</forenames></author><author><keyname>Yuan</keyname><forenames>Weihang</forenames></author><author><keyname>Tak&#xe1;&#x10d;</keyname><forenames>Martin</forenames></author><author><keyname>Mu&#xf1;oz-Avila</keyname><forenames>H&#xe9;ctor</forenames></author><author><keyname>Motee</keyname><forenames>Nader</forenames></author></authors><title>A Layered Architecture for Active Perception: Image Classification using
  Deep Reinforcement Learning</title><categories>cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML</categories><comments>Submitted to ICRA-2020</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a planning and perception mechanism for a robot (agent), that can
only observe the underlying environment partially, in order to solve an image
classification problem. A three-layer architecture is suggested that consists
of a meta-layer that decides the intermediate goals, an action-layer that
selects local actions as the agent navigates towards a goal, and a
classification-layer that evaluates the reward and makes a prediction. We
design and implement these layers using deep reinforcement learning. A
generalized policy gradient algorithm is utilized to learn the parameters of
these layers to maximize the expected reward. Our proposed methodology is
tested on the MNIST dataset of handwritten digits, which provides us with a
level of explainability while interpreting the agent's intermediate goals and
course of action.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09710</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09710</id><created>2019-09-20</created><authors><author><keyname>Chen</keyname><forenames>Yutao</forenames></author><author><keyname>Scarabottolo</keyname><forenames>Nicolo</forenames></author><author><keyname>Bruschetta</keyname><forenames>Mattia</forenames></author><author><keyname>Beghi</keyname><forenames>Alessandro</forenames></author></authors><title>An Efficient Move Blocking Strategy for Multiple Shooting based
  Nonlinear Model Predictive Control</title><categories>math.OC cs.SY eess.SY</categories><doi>10.1049/iet-cta.2019.0168</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Move blocking (MB) is a widely used strategy to reduce the degrees of freedom
of the Optimal Control Problem (OCP) arising in receding horizon control. The
size of the OCP is reduced by forcing the input variables to be constant over
multiple discretization steps. In this paper, we focus on developing
computationally efficient MB schemes for multiple shooting based nonlinear
model predictive control (NMPC). The degrees of freedom of the OCP is reduced
by introducing MB in the shooting step, resulting in a smaller but sparse OCP.
Therefore, the discretization accuracy and level of sparsity is maintained. A
condensing algorithm that exploits the sparsity structure of the OCP is
proposed, that allows to reduce the computation complexity of condensing from
quadratic to linear in the number of discretization nodes. As a result,
active-set methods with warm-start strategy can be efficiently employed, thus
allowing the use of a longer prediction horizon. A detailed comparison between
the proposed scheme and the nonuniform grid NMPC is given. Effectiveness of the
algorithm in reducing computational burden while maintaining optimization
accuracy and constraints fulfillment is shown by means of simulations with two
different problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09736</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09736</id><created>2019-09-20</created><authors><author><keyname>Wang</keyname><forenames>Yinsong</forenames></author><author><keyname>Shahrampour</keyname><forenames>Shahin</forenames></author></authors><title>Distributed Parameter Estimation in Randomized One-hidden-layer Neural
  Networks</title><categories>eess.SY cs.LG cs.SY</categories><comments>8 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses distributed parameter estimation in randomized
one-hidden-layer neural networks. A group of agents sequentially receive
measurements of an unknown parameter that is only partially observable to them.
In this paper, we present a fully distributed estimation algorithm where agents
exchange local estimates with their neighbors to collectively identify the true
value of the parameter. We prove that this distributed update provides an
asymptotically unbiased estimator of the unknown parameter, i.e., the first
moment of the expected global error converges to zero asymptotically. We
further analyze the efficiency of the proposed estimation scheme by
establishing an asymptotic upper bound on the variance of the global error.
Applying our method to a real-world dataset related to appliances energy
prediction, we observe that our empirical findings verify the theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09773</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09773</id><created>2019-09-21</created><authors><author><keyname>Ding</keyname><forenames>Qiaoqiao</forenames></author><author><keyname>Chen</keyname><forenames>Gaoyu</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoqun</forenames></author><author><keyname>Huang</keyname><forenames>Qiu</forenames></author><author><keyname>Gao</keyname><forenames>Hui Jiand Hao</forenames></author></authors><title>Low-Dose CT with Deep Learning Regularization via Proximal Forward
  Backward Splitting</title><categories>eess.IV</categories><comments>8pages 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low dose X-ray computed tomography (LDCT) is desirable for reduced patient
dose. This work develops image reconstruction methods with deep learning (DL)
regularization for LDCT. Our methods are based on unrolling of proximal
forward-backward splitting (PFBS) framework with data-driven image
regularization via deep neural networks. In contrast with PFBS-IR that utilizes
standard data fidelity updates via iterative reconstruction (IR) method,
PFBS-AIR involves preconditioned data fidelity updates that fuse analytical
reconstruction (AR) method and IR in a synergistic way, I.e. fused analytical
and iterative reconstruction (AIR). The results suggest that DL-regularized
methods (PFBS-IR and PFBS-AIR) provided better reconstruction quality from
conventional wisdoms (AR or IR), and DL-based postprocessing method
(FBPConvNet). In addition, owing to AIR, PFBS-AIR noticeably outperformed
PFBS-IR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09866</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09866</id><created>2019-09-21</created><authors><author><keyname>Rastgoftar</keyname><forenames>Hossein</forenames></author><author><keyname>Atkins</keyname><forenames>Ella</forenames></author></authors><title>Resilient Continuum Deformation Coordination</title><categories>eess.SY cs.SY</categories><comments>15 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper applies the principles of continuum mechanics to safely and
resiliently coordinate a multi-agent team. A hybrid automation with two
operation modes, Homogeneous Deformation Mode (HDM) and Containment Exclusion
Mode (CEM), are developed to robustly manage group coordination in the presence
of unpredicted agent failures. HDM becomes active when all agents are healthy,
where the group coordination is defined by homogeneous transformation
coordination functions. By classifying agents as leaders and followers, a
desired n-D homogeneous transformation is uniquely related to the desired
trajectories of n+1 leaders and acquired by the remaining followers in
real-time through local communication. The paper offers a novel approach for
leader selection as well as naturally establishing and reestablishing
inter-agent communication whenever the agent team enters the HDM. CEM is
activated when at least one agent fails to admit group coordination. This paper
applies unique features of decentralized homogeneous transformation
coordination to quickly detect each arising anomalous situation and excludes
failed agent(s) from group coordination of healthy agents. In CEM, agent
coordination is treated as an ideal fluid flow where the desired agents' paths
are defined along stream lines inspired by fluid flow field theory to
circumvent exclusion spaces surrounding failed agent(s).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09887</identifier>
 <datestamp>2020-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09887</id><created>2019-09-21</created><updated>2020-02-26</updated><authors><author><keyname>Hosseini</keyname><forenames>Nozhan</forenames></author><author><keyname>Matolak</keyname><forenames>David W.</forenames></author></authors><title>Nonlinear Quasi-Synchronous Multi User Chirp Spread Spectrum Signaling</title><categories>eess.SP</categories><comments>Chirp signaling; Chirp Spread Spectrum; Quasi-synchronous; Multi-user
  communication system; This version contains Appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi user orthogonal chirp spread spectrum (OCSS) improves the spectral
inefficiency of chirp spread spectrum (CSS) but is only feasible with perfect
synchronism and without any channel dispersion. Either asynchronism or channel
dispersion causes multiple access interference (MAI), which degrades
performance. Conditions with small timing offsets we term quasi-synchronous
(QS). In this paper, we investigate binary CSS signaling in QS conditions. We
derive the bit error probability analytically and validate both numerical and
simulation results with our theoretical result for any time-frequency (TF)
chirp waveform. We also propose two new sets of nonlinear chirps to improve CSS
system performance. We numerically evaluate cross-correlation distributions,
and show that in practical QS conditions our two new nonlinear chirp designs
outperform the classical linear chirp and multiple existing nonlinear chirps
from the literature. We also demonstrate that our nonlinear CSS designs
outperform existing chirps in two realistic (empirically modeled) dispersive
air to ground channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09890</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09890</id><created>2019-09-21</created><authors><author><keyname>Cerna</keyname><forenames>Dana</forenames></author><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author></authors><title>Construction of wavelet dictionaries for ECG modelling</title><categories>math.NA cs.NA eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of sparse modelling of ECG signals is to represent an ECG record,
given by sample points, as a linear combination of as few elementary components
as possible. This can be achieved by creating a redundant set, called a
dictionary, from where the elementary components are selected. The success in
sparsely representing an ECG record depends on the nature of the dictionary
being considered. In this paper we focus on the construction of different
families of wavelet dictionaries, which are appropriate for the purpose of
reducing dimensionality of ECG signals through sparse representation modelling.
The suitability of wavelet dictionaries for ECG modelling, applying the
Optimized Orthogonal Matching Pursuit approach for the selection process, was
demonstrated in a previous work on the MIT-BIH Arrhythmia database consisting
of 48 records each of which of 30 min length. This paper complements the
previous one by presenting the technical details, methods, algorithms, and
MATLAB software facilitating the construction of different families of wavelet
dictionaries. The implementation allows for straightforward further extensions
to include additional wavelet families. The sparsity in the representation of
an ECG record significantly improves in relation to the sparsity produced by
the corresponding wavelet basis. This result holds true for the 17 wavelet
families considered here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09910</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09910</id><created>2019-09-21</created><updated>2020-01-14</updated><authors><author><keyname>Jafarzadeh</keyname><forenames>Mohsen</forenames></author><author><keyname>Hussey</keyname><forenames>Daniel Curtiss</forenames></author><author><keyname>Tadesse</keyname><forenames>Yonas</forenames></author></authors><title>Deep learning approach to control of prosthetic hands with
  electromyography signals</title><categories>eess.SP cs.LG cs.RO</categories><comments>Conference. Houston, Texas, USA. September, 2019</comments><msc-class>68T40</msc-class><acm-class>I.2</acm-class><journal-ref>2019 IEEE International Symposium on Measurement and Control in
  Robotics (ISMCR)</journal-ref><doi>10.1109/ISMCR47492.2019.8955725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural muscles provide mobility in response to nerve impulses.
Electromyography (EMG) measures the electrical activity of muscles in response
to a nerve's stimulation. In the past few decades, EMG signals have been used
extensively in the identification of user intention to potentially control
assistive devices such as smart wheelchairs, exoskeletons, and prosthetic
devices. In the design of conventional assistive devices, developers optimize
multiple subsystems independently. Feature extraction and feature description
are essential subsystems of this approach. Therefore, researchers proposed
various hand-crafted features to interpret EMG signals. However, the
performance of conventional assistive devices is still unsatisfactory. In this
paper, we propose a deep learning approach to control prosthetic hands with raw
EMG signals. We use a novel deep convolutional neural network to eschew the
feature-engineering step. Removing the feature extraction and feature
description is an important step toward the paradigm of end-to-end
optimization. Fine-tuning and personalization are additional advantages of our
approach. The proposed approach is implemented in Python with TensorFlow deep
learning library, and it runs in real-time in general-purpose graphics
processing units of NVIDIA Jetson TX2 developer kit. Our results demonstrate
the ability of our system to predict fingers position from raw EMG signals. We
anticipate our EMG-based control system to be a starting point to design more
sophisticated prosthetic hands. For example, a pressure measurement unit can be
added to transfer the perception of the environment to the user. Furthermore,
our system can be modified for other prosthetic devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09937</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09937</id><created>2019-09-22</created><authors><author><keyname>Zhang</keyname><forenames>Jiaqi</forenames></author><author><keyname>You</keyname><forenames>Keyou</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author></authors><title>Distributed Conjugate Gradient Tracking for Resource Allocation in
  Unbalanced Networks</title><categories>eess.SP cs.DC</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a distributed conjugate gradient tracking algorithm
(DCGT) to solve resource allocation problems in a possibly unbalanced network,
where each node of the network computes its optimal resource via interacting
only with its neighboring nodes. Our key idea is the novel use of the
celebrated $\mathcal{A}\mathcal{B}$ algorithm to the dual of the resource
allocation problem. To study the convergence of DCGT, we first establish the
sublinear convergence of $\mathcal{A}\mathcal{B}$ for non-convex objective
functions, which advances the existing results on $\mathcal{A}\mathcal{B}$ as
they require the strong-convexity of objective functions. Then we show that
DCGT converges linearly for strongly convex and Lipschitz smooth objective
functions, and sublinearly without the Lipschitz smoothness. Finally,
simulation results validate that DCGT outperforms state-of-the-art algorithms
in distributed resource allocation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09939</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09939</id><created>2019-09-22</created><authors><author><keyname>Xu</keyname><forenames>Zhe</forenames></author><author><keyname>Zegers</keyname><forenames>Federico M.</forenames></author><author><keyname>Wu</keyname><forenames>Bo</forenames></author><author><keyname>Dixon</keyname><forenames>Warren</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Controller Synthesis for Multi-Agent Systems With Intermittent
  Communication: A Metric Temporal Logic Approach</title><categories>eess.SY cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a controller synthesis approach for a multi-agent system
(MAS) with intermittent communication. We adopt a leader-follower scheme, where
a mobile leader with absolute position sensors switches among a set of
followers without absolute position sensors to provide each follower with
intermittent state information.We model the MAS as a switched system. The
followers are to asymptotically reach a predetermined consensus state. To
guarantee the stability of the switched system and the consensus of the
followers, we derive maximum and minimal dwell-time conditions to constrain the
intervals between consecutive time instants at which the leader should provide
state information to the same follower. Furthermore, the leader needs to
satisfy practical constraints such as charging its battery and staying in
specific regions of interest. Both the maximum and minimum dwell-time
conditions and these practical constraints can be expressed by metric temporal
logic (MTL) specifications. We iteratively compute the optimal control inputs
such that the leader satisfies the MTL specifications, while guaranteeing
stability and consensus of the followers. We implement the proposed method on a
case study with three mobile robots as the followers and one quadrotor as the
leader.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09974</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.09974</id><created>2019-09-22</created><authors><author><keyname>Oeldorf</keyname><forenames>Cedric</forenames></author><author><keyname>Spanakis</keyname><forenames>Gerasimos</forenames></author></authors><title>LoGANv2: Conditional Style-Based Logo Generation with Generative
  Adversarial Networks</title><categories>cs.LG cs.CV eess.IV</categories><comments>accepted for poster presentation at ICMLA 2019, data+code available:
  https://github.com/cedricoeldorf/ConditionalStyleGAN</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domains such as logo synthesis, in which the data has a high degree of
multi-modality, still pose a challenge for generative adversarial networks
(GANs). Recent research shows that progressive training (ProGAN) and mapping
network extensions (StyleGAN) enable both increased training stability for
higher dimensional problems and better feature separation within the embedded
latent space. However, these architectures leave limited control over shaping
the output of the network, which is an undesirable trait in the case of logo
synthesis. This paper explores a conditional extension to the StyleGAN
architecture with the aim of firstly, improving on the low resolution results
of previous research and, secondly, increasing the controllability of the
output through the use of synthetic class-conditions. Furthermore, methods of
extracting such class conditions are explored with a focus on the human
interpretability, where the challenge lies in the fact that, by nature, visual
logo characteristics are hard to define. The introduced conditional style-based
generator architecture is trained on the extracted class-conditions in two
experiments and studied relative to the performance of an unconditional model.
Results show that, whilst the unconditional model more closely matches the
training distribution, high quality conditions enabled the embedding of finer
details onto the latent space, leading to more diverse output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10033</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10033</id><created>2019-09-22</created><authors><author><keyname>Chremos</keyname><forenames>Ioannis Vasileios</forenames></author><author><keyname>Beaver</keyname><forenames>Logan</forenames></author><author><keyname>Malikopoulos</keyname><forenames>Andreas</forenames></author></authors><title>A Game-Theoretic Analysis of the Social Impact of Connected and
  Automated Vehicles</title><categories>cs.GT cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the much-anticipated deployment of connected and
automated vehicles (CAVs) in society by modeling and analyzing the
social-mobility dilemma in a game-theoretic approach. We formulate this dilemma
as a normal-form game by constructing an intuitive payoff function inspired by
the socially beneficial outcomes of a mobility system consisting of CAVs. We
show that the game is equivalent to the Prisoner's dilemma which implies that
the rational collective decision is the opposite of the socially optimum (e.g.,
Tragedy of the Commons). To tackle this phenomenon, we present two different
approaches, i.e., one with a preference structure and the other with
institutional arrangements. In the first approach, we implement a social
mechanism that enforces players to non-CAV travel and derive a lower bound of
players that leads to an equilibrium of non-CAV traveling. In the second
approach, we investigate the possibility of players bargaining to create an
institution that enforces non-CAV travel. We show that as the number of players
increases, the incentive ratio of non-CAV travel over CAV-travel tends to zero.
We also performed a numerical study for the latter approach demonstrating the
effectiveness of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10036</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10036</id><created>2019-09-22</created><authors><author><keyname>Tohidi</keyname><forenames>Seyed Shahabaldin</forenames></author><author><keyname>Yildiz</keyname><forenames>Yildiray</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author></authors><title>Model Reference Adaptive Control Allocation for Constrained Systems with
  Guaranteed Closed Loop Stability</title><categories>eess.SY cs.SY math.OC</categories><comments>19 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an adaptive control allocation approach for uncertain
over-actuated systems with actuator saturation. The proposed method does not
require uncertainty estimation or a persistent excitation assumption. Using the
element-wise non-symmetric projection algorithm, the adaptive parameters are
restricted to satisfy certain optimality conditions leading to overall closed
loop system stability. Furthermore, a sliding mode controller with a
time-varying sliding surface, working in tandem with the adaptive control
allocation, is proposed to guarantee the outer loop stability and reference
tracking in the presence of control allocation errors and disturbances.
Simulation results are provided, where the Aerodata Model in Research
Environment is used as an over-actuated system with actuator saturation, to
demonstrate the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10051</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10051</id><created>2019-09-22</created><updated>2019-11-23</updated><authors><author><keyname>Haghrah</keyname><forenames>Amir Arslan</forenames></author><author><keyname>Ghaemi</keyname><forenames>Sehraneh</forenames></author></authors><title>PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems</title><categories>eess.SY cs.MS cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fuzzy logic is an accepted and well-developed approach for constructing
verbal models. Fuzzy based methods are getting more popular, while the
engineers deal with more daily life tasks. This paper presents a new Python
toolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing software
tools is an important issue for facilitating the practical use of theoretical
results. There are limited tools for implementing IT2FLSs in Python. The
developed PyIT2FLS is providing a set of tools for fast and easy modeling of
fuzzy systems. This paper includes a brief description of how developed toolkit
can be used. Also, three examples are given showing the usage of the developed
toolkit for simulating IT2FLSs. First, a simple rule-based system is developed
and it's codes are presented in the paper. The second example is the prediction
of the Mackey-Glass chaotic time series using IT2FLS. In this example, the
Particle Swarm Optimization (PSO) algorithm is used for determining system
parameters while minimizing the mean square error. In the last example, an
IT2FPID is designed and used for controlling a linear time-delay system. The
code for the examples are available on toolkit's GitHub page:
\url{https://github.com/Haghrah/PyIT2FLS}. The simulations and their results
confirm the ability of the developed toolkit to be used in a wide range of the
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10070</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10070</id><created>2019-09-22</created><updated>2019-09-25</updated><authors><author><keyname>Khatana</keyname><forenames>Vivek</forenames></author><author><keyname>Saraswat</keyname><forenames>Govind</forenames></author><author><keyname>Patel</keyname><forenames>Sourav</forenames></author><author><keyname>Salapaka</keyname><forenames>Murti V.</forenames></author></authors><title>Gradient-Consensus Method for Distributed Optimization in Directed
  Multi-Agent Networks</title><categories>eess.SY cs.MA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, a distributed optimization problem for minimizing a sum,
$\sum_{i=1}^n f_i$, of convex objective functions, $f_i,$ is addressed. Here
each function $f_i$ is a function of $n$ variables, private to agent $i$ which
defines the agent's objective. Agents can only communicate locally with
neighbors defined by a communication network topology. These $f_i$'s are
assumed to be Lipschitz-differentiable convex functions. For solving this
optimization problem, we develop a novel distributed algorithm, which we term
as the gradient-consensus method. The gradient-consensus scheme uses a
finite-time terminated consensus protocol called $\rho$-consensus, which allows
each local estimate to be $\rho$-close to each other at every iteration. The
parameter $\rho$ is a fixed constant which can be determined independently of
the network size or topology. It is shown that the estimate of the optimal
solution at any local agent $i$ converges geometrically to the optimal solution
within $O(\rho)$ where $\rho$ can be chosen to be arbitrarily small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10074</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10074</id><created>2019-09-22</created><updated>2019-10-01</updated><authors><author><keyname>Alonso</keyname><forenames>Carmen Amo</forenames></author><author><keyname>Matni</keyname><forenames>Nikolai</forenames></author></authors><title>Distributed and Localized Model Predictive Control via System Level
  Synthesis</title><categories>math.OC cs.SY eess.SY</categories><comments>Extended version of ACC 2020 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the Distributed and Localized Model Predictive Control (DLMPC)
algorithm for large-scale structured linear systems, wherein only local state
and model information needs to be exchanged between subsystems for the
computation and implementation of control actions. We use the System Level
Synthesis (SLS) framework to reformulate the MPC problem as an optimization
problem over closed loop system responses, and show that this allows us to
naturally impose localized communication constraints between sub-controllers,
such that only local state and system model information needs to be exchanged
for both computation and implementation of closed loop MPC control policies. In
particular, we show that the structure of the resulting optimization problem
can be exploited to develop an Alternating Direction Method of Multipliers
(ADMM) based algorithm that allows for distributed and localized computation of
control decisions. Moreover, our approach can accommodate constraints and
objective functions that couple the behavior of different subsystems, so long
as the coupled systems are able to communicate directly with each other,
allowing for a broader class of MPC problems to be solved via distributed
optimization. We conclude with numerical simulations to demonstrate the
usefulness of our method, and in particular, we demonstrate that the
computational complexity of the subproblems solved by each subsystem in DLMPC
is independent of the size of the global system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10091</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10091</id><created>2019-09-22</created><authors><author><keyname>Jain</keyname><forenames>Karan P.</forenames></author><author><keyname>Mueller</keyname><forenames>Mark W.</forenames></author></authors><title>Flying batteries: In-flight battery switching to increase multirotor
  flight time</title><categories>eess.SY cs.RO cs.SY</categories><comments>Paper submitted to RA-L with ICRA-2020 on 2019-09-10. Paper info: 7
  pages (6 content + 1 references), 8 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to increase the flight time of a multirotor via
mid-air docking and in-flight battery switching. A main quadcopter flying using
a primary battery has a docking platform attached to it. A 'flying battery' - a
small quadcopter carrying a secondary battery - is equipped with docking legs
that can mate with the main quadcopter's platform. Connectors between the legs
and the platform establish electrical contact on docking, and enable power
transfer from the secondary battery to the main quadcopter. A custom-designed
circuit allows arbitrary switching between the primary battery and secondary
battery. We demonstrate the concept in a flight experiment involving repeated
docking, battery switching, and undocking. The experiment increases the flight
time of the main quadcopter by a factor of 4.7x compared to solo flight, and
2.2x a theoretical limit for that given multirotor. Importantly, this increase
in flight time is not associated with a large increase in overall vehicle mass
or size, leaving the main quadcopter in fundamentally the same safety class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10093</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10093</id><created>2019-09-22</created><authors><author><keyname>Ghosh</keyname><forenames>Ramen</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author><author><keyname>Shorten</keyname><forenames>Robert</forenames></author></authors><title>Iterated Piecewise-Stationary Random Functions</title><categories>math.PR cs.MA cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the study of uncertain dynamical systems, iterated random functions
are a key tool. There, one samples a family of functions according to a
stationary distribution. Here, we introduce an extension, where one sample
functions according to a time-varying distribution over the family of
functions. For such iterated piecewise-stationary random functions on Polish
spaces, we prove a number of results, including a bound on the tracking error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10104</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10104</id><created>2019-09-22</created><authors><author><keyname>Taherkhani</keyname><forenames>Nima</forenames></author><author><keyname>Apalak</keyname><forenames>Merve</forenames></author><author><keyname>Kiasaleh</keyname><forenames>Kamran</forenames></author></authors><title>Analysis and Comparison of the LDPC and Reed Solomon Encodings in
  Mitigating the Impact of Clipping Noise in OFDM-Based VLC</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear error-correcting codes are known to be well suited for battling
and correcting the burst errors caused by noise in the wireless data
transmission system. However, different types of codes offer different decoding
and burst-error-correcting capabilities. This paper compares the
Low-Density-Parity Check (LDPC) and Reed Solomon (RS) encoding schemes in
battling and correcting the burst error caused by the clipping distortion
occurred due to the dynamic range constraints in an Orthogonal Frequency
Division Multiplexing (OFDM) based Visible Light Communication (VLC). The
unipolar conversion applied to the output of the multiplexer in this system
results in a clipping noise which distorts the data symbols on the subcarriers
in OFDM block. Considering that such distortion impacts the data symbol on each
subcarrier differently, RS and LDP are used to encode the data block before
being modulated for mapping the OFDM block. In order to control the extreme
value of the output of the multiplexer, the transmitter applies puncturing to
the generated codeword before mapping OFDM subcarriers, leaving the
corresponding subcarriers of the punctured symbols empty. This will lead to the
reduction of clipping events in the optical front-end and will mitigate the
impact of nonlinear distortion on the modulated symbols for the occupied
subcarriers. The redundancy in the codeword generated by the encoder is used
not only to control the clipping probability by shortening the number of active
subcarriers but also for the reconstruction of the original codeword and
correction of the errors caused by channel noise. This work investigates the
ability of LDCP and RS encoders in battling the effects of clipping noise in
the frequency domain and compares their performances in improving the bit error
ratio (BER) performance of an OFDM-based VLC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10105</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10105</id><created>2019-09-22</created><authors><author><keyname>Bangar</keyname><forenames>Esha</forenames></author><author><keyname>Taherkhani</keyname><forenames>Nima</forenames></author><author><keyname>Kiasaleh</keyname><forenames>Kamran</forenames></author></authors><title>Sum Rate Capacity of MIMO HetNet Systems in the Presence of Channel
  Estimation Error</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the impact of channel estimation error (CEE) on the sum-rate
capacity of multiple-input-multiple-output (MIMO) heterogeneous networks
(HetNets) is investigated. It is assumed that the receiver is a linear minimum
mean-square (LMMS) receiver. The architecture is based on the deployment of
macro base stations with large antenna arrays and a secondary tier of small
cell base stations having fewer number of antenna arrays. The key contribution
of the paper is to highlight the noticeable impact of CEE on the sum-rate
capacity of macro-cells. Furthermore, it is shown that CEE has only marginal
impact on the sum-rate capacity of small cells. Simulations for the sum rate of
macro users versus that of the small cell users for time-division duplex (TDD)
are performed and the results are compared with the case when channel
estimation error is present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10114</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10114</id><created>2019-09-22</created><authors><author><keyname>Xu</keyname><forenames>Liangyuan</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Qian</keyname><forenames>Cheng</forenames></author></authors><title>Gridless Angular Domain Channel Estimation for mmWave Massive MIMO
  System With One-Bit Quantization Via Approximate Message Passing</title><categories>eess.SP cs.IT math.IT</categories><comments>Already accepted for publication by IEEE Globecom 2019 but not
  published yet</comments><journal-ref>IEEE Globecom 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a direction of arrival (DoA) and channel estimation algorithm for
the one-bit quantized millimeter-wave (mmWave) massive multiple-input
multiple-output (MIMO) system. By formulating the estimation problem as a noisy
one-bit compressed sensing problem, we propose a computationally efficient
gridless solution based on the expectation-maximization generalized approximate
message passing (EMGAMP) approach. The proposed algorithm does not need the
prior knowledge about the number of DoAs and outperforms the existing methods
in distinguishing extremely close DoAs for the case of one-bit quantization.
Both the DoAs and the channel coefficients are estimated for the case of
one-bit quantization. The simulation results show that the proposed algorithm
has effective estimation performances when the DoAs are very close to each
other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10136</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10136</id><created>2019-09-22</created><updated>2019-11-15</updated><authors><author><keyname>Gupta</keyname><forenames>Pravir Singh</forenames></author><author><keyname>Yuan</keyname><forenames>Xin</forenames></author><author><keyname>Choi</keyname><forenames>Gwan Seong</forenames></author></authors><title>DRCAS: Deep Restoration Network for Hardware Based Compressive
  Acquisition Scheme</title><categories>eess.IV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the power and performance improvement in image acquisition
devices by the use of CAS (Compressed Acquisition Scheme) and DNN (Deep Neural
Networks). Towards this end, we propose a novel image acquisition scheme HCAS
(Hardware based Compressed Acquisition Scheme) using hardware-based binning
(downsampling), bit truncation and JPEG compression and develop a deep learning
based reconstruction network for images acquired using the same. HCAS is
motivated by the fact that in-situ compression of raw data using binning and
bit truncation results in reduction in data traffic and power in the entire
downstream image processing pipeline and additional compression of processed
data using JPEG will help in storage/transmission of images. The combination of
in-situ compression with JPEG leads to high compression ratios, significant
power savings with further advantages of image acquisition simplification.
Bearing these concerns in mind, we propose DRCAS (Deep Restoration network for
hardware based Compressed Acquisition Scheme), which to our best knowledge, is
the first work proposed in the literature for restoration of images acquired
using acquisition scheme like HCAS. When compared with the CAS methods (bicubic
downsampling) used in super resolution tasks in literature, HCAS proposed in
this paper performs superior in terms of both compression ratio and being
hardware friendly. The restoration network DRCAS also perform superior than
state-of-the-art super resolution networks while being much smaller. Thus HCAS
and DRCAS technique will enable us to design much simpler and power efficient
image acquisition pipelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10137</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10137</id><created>2019-09-22</created><authors><author><keyname>Zhao</keyname><forenames>Yiyuan</forenames></author><author><keyname>Wang</keyname><forenames>Jianing</forenames></author><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Labadie</keyname><forenames>Robert F.</forenames></author><author><keyname>Dawant</keyname><forenames>Benoit M.</forenames></author><author><keyname>Noble</keyname><forenames>Jack H.</forenames></author></authors><title>Validation of image-guided cochlear implant programming techniques</title><categories>cs.CV cs.GL eess.IV q-bio.QM</categories><comments>37 pages, 12 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cochlear implants (CIs) are a standard treatment for patients who experience
severe to profound hearing loss. Recent studies have shown that hearing outcome
is correlated with intra-cochlear anatomy and electrode placement. Our group
has developed image-guided CI programming (IGCIP) techniques that use image
analysis methods to both segment the inner ear structures in pre- or
post-implantation CT images and localize the CI electrodes in post-implantation
CT images. This permits to assist audiologists with CI programming by
suggesting which among the contacts should be deactivated to reduce electrode
interaction that is known to affect outcomes. Clinical studies have shown that
IGCIP can improve hearing outcomes for CI recipients. However, the sensitivity
of IGCIP with respect to the accuracy of the two major steps: electrode
localization and intra-cochlear anatomy segmentation, is unknown. In this
article, we create a ground truth dataset with conventional CT and micro-CT
images of 35 temporal bone specimens to both rigorously characterize the
accuracy of these two steps and assess how inaccuracies in these steps affect
the overall results. Our study results show that when clinical pre- and
post-implantation CTs are available, IGCIP produces results that are comparable
to those obtained with the corresponding ground truth in 86.7% of the subjects
tested. When only post-implantation CTs are available, this number is 83.3%.
These results suggest that our current method is robust to errors in
segmentation and localization but also that it can be improved upon.
  Keywords: cochlear implant, ground truth, segmentation, validation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10153</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10153</id><created>2019-09-23</created><authors><author><keyname>Grupp</keyname><forenames>Robert</forenames></author><author><keyname>Chiang</keyname><forenames>Hsin-Hong</forenames></author><author><keyname>Otake</keyname><forenames>Yoshito</forenames></author><author><keyname>Murphy</keyname><forenames>Ryan</forenames></author><author><keyname>Gordon</keyname><forenames>Chad</forenames></author><author><keyname>Armand</keyname><forenames>Mehran</forenames></author><author><keyname>Taylor</keyname><forenames>Russell</forenames></author></authors><title>Smooth Extrapolation of Unknown Anatomy via Statistical Shape Models</title><categories>cs.CV eess.IV</categories><comments>SPIE Medical Imaging Conference 2015 Paper</comments><journal-ref>In Medical Imaging 2015: Image-Guided Procedures, Robotic
  Interventions, and Modeling 2015 Mar 18 (Vol. 9415, p. 941524). International
  Society for Optics and Photonics</journal-ref><doi>10.1117/12.2081310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several methods to perform extrapolation of unknown anatomy were evaluated.
The primary application is to enhance surgical procedures that may use partial
medical images or medical images of incomplete anatomy. Le Fort-based,
face-jaw-teeth transplant is one such procedure. From CT data of 36 skulls and
21 mandibles separate Statistical Shape Models of the anatomical surfaces were
created. Using the Statistical Shape Models, incomplete surfaces were projected
to obtain complete surface estimates. The surface estimates exhibit non-zero
error in regions where the true surface is known; it is desirable to keep the
true surface and seamlessly merge the estimated unknown surface. Existing
extrapolation techniques produce non-smooth transitions from the true surface
to the estimated surface, resulting in additional error and a less
aesthetically pleasing result. The three extrapolation techniques evaluated
were: copying and pasting of the surface estimate (non-smooth baseline), a
feathering between the patient surface and surface estimate, and an estimate
generated via a Thin Plate Spline trained from displacements between the
surface estimate and corresponding vertices of the known patient surface.
Feathering and Thin Plate Spline approaches both yielded smooth transitions.
However, feathering corrupted known vertex values. Leave-one-out analyses were
conducted, with 5% to 50% of known anatomy removed from the left-out patient
and estimated via the proposed approaches. The Thin Plate Spline approach
yielded smaller errors than the other two approaches, with an average vertex
error improvement of 1.46 mm and 1.38 mm for the skull and mandible
respectively, over the baseline approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10165</identifier>
 <datestamp>2019-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10165</id><created>2019-09-23</created><updated>2019-12-18</updated><authors><author><keyname>Yu</keyname><forenames>Liang</forenames></author><author><keyname>Xie</keyname><forenames>Weiwei</forenames></author><author><keyname>Xie</keyname><forenames>Di</forenames></author><author><keyname>Zou</keyname><forenames>Yulong</forenames></author><author><keyname>Zhang</keyname><forenames>Dengyin</forenames></author><author><keyname>Sun</keyname><forenames>Zhixin</forenames></author><author><keyname>Zhang</keyname><forenames>Linghua</forenames></author><author><keyname>Zhang</keyname><forenames>Yue</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author></authors><title>Deep Reinforcement Learning for Smart Home Energy Management</title><categories>eess.SY cs.SY</categories><comments>15 pages, 16 figures</comments><journal-ref>IEEE Internet of Things Journal, 2019</journal-ref><doi>10.1109/JIOT.2019.2957289</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate an energy cost minimization problem for a smart
home in the absence of a building thermal dynamics model with the consideration
of a comfortable temperature range. Due to the existence of model uncertainty,
parameter uncertainty (e.g., renewable generation output, non-shiftable power
demand, outdoor temperature, and electricity price) and temporally-coupled
operational constraints, it is very challenging to determine the optimal energy
management strategy for scheduling Heating, Ventilation, and Air Conditioning
(HVAC) systems and energy storage systems in the smart home. To address the
challenge, we first formulate the above problem as a Markov decision process,
and then propose an energy management strategy based on Deep Deterministic
Policy Gradients (DDPG). It is worth mentioning that the proposed strategy does
not require the prior knowledge of uncertain parameters and building thermal
dynamics model. Simulation results based on real-world traces demonstrate the
effectiveness and robustness of the proposed strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10169</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10169</id><created>2019-09-23</created><authors><author><keyname>Guo</keyname><forenames>Yuyu</forenames></author></authors><title>Deep Local Global Refinement Network for Stent Analysis in IVOCT Images</title><categories>eess.IV cs.CV</categories><comments>8 pages,5 figures, MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Implantation of stents into coronary arteries is a common treatment option
for patients with cardiovascular disease. Assessment of safety and efficacy of
the stent implantation occurs via manual visual inspection of the neointimal
coverage from intravascular optical coherence tomography (IVOCT) images.
However, such manual assessment requires the detection of thousands of strut
points within the stent. This is a challenging, tedious, and time-consuming
task because the strut points usually appear as small, irregular shaped objects
with inhomogeneous textures, and are often occluded by shadows, artifacts, and
vessel walls. Conventional methods based on textures, edge detection, or simple
classifiers for automated detection of strut points in IVOCT images have low
recall and precision as they are, unable to adequately represent the visual
features of the strut point for detection. In this study, we propose a
local-global refinement network to integrate local-patch content with global
content for strut points detection from IVOCT images. Our method densely
detects the potential strut points in local image patches and then refines them
according to global appearance constraints to reduce false positives. Our
experimental results on a clinical dataset of 7,000 IVOCT images demonstrated
that our method outperformed the state-of-the-art methods with a recall of 0.92
and precision of 0.91 for strut points detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10175</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10175</id><created>2019-09-23</created><authors><author><keyname>Jayathurathnage</keyname><forenames>Prasad</forenames></author><author><keyname>Dang</keyname><forenames>Xiaojie</forenames></author><author><keyname>Liu</keyname><forenames>Fu</forenames></author><author><keyname>Simovski</keyname><forenames>Constantin</forenames></author><author><keyname>Tretyakov</keyname><forenames>Sergei A.</forenames></author></authors><title>Omnidirectional Wireless Power Transfer with Automatic Power Flow
  Control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an omnidirectional wireless power transfer (WPT) system capable of
automatic power flow control using three orthogonal transmitter (Tx)-repeater
(Rp) pairs. The power drawn from each transmitter is automatically adjusted
depending on the mutual inductance between the receiver and the Tx-Rp pair. The
proposed approach enables the receiver to harvest almost uniform power with
high efficiency (90\%) regardless of its position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10179</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10179</id><created>2019-09-23</created><authors><author><keyname>Chang</keyname><forenames>Dong Eui</forenames></author></authors><title>Design of Globally Exponentially Convergent Continuous Observers for
  Velocity Bias and State for Systems on Real Matrix Groups</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose globally exponentially convergent continuous observers for
invariant kinematic systems on finite-dimensional matrix Lie groups. Such an
observer estimates, from measurements of landmarks, vectors and biased
velocity, both the system state and the unknown constant bias in velocity
measurement, where the state belongs to the state-space Lie group and the
velocity to the Lie algebra of the Lie group. The main technique is to embed a
given system defined on a matrix Lie group into Euclidean space and build
observers in the Euclidean space. The theory is illustrated with the special
Euclidean group in three dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10200</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10200</id><created>2019-09-23</created><updated>2019-10-22</updated><authors><author><keyname>Gupta</keyname><forenames>Chitralekha</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>Automatic Lyrics Alignment and Transcription in Polyphonic Music: Does
  Background Music Help?</title><categories>eess.AS cs.SD</categories><comments>Submitted to 45th International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2020)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background music affects lyrics intelligibility of singing vocals in a music
piece. Automatic lyrics alignment and transcription in polyphonic music are
challenging tasks because the singing vocals are corrupted by the background
music. In this work, we propose to learn music genre-specific characteristics
to train polyphonic acoustic models. We first compare several automatic speech
recognition pipelines for the application of lyrics transcription. We then
present the lyrics alignment and transcription performance of music-informed
acoustic models for the best-performing pipeline, and systematically study the
impact of music genre and language model on the performance. With such
genre-based approach, we explicitly model the music without removing it during
acoustic modeling. The proposed approach outperforms all competing systems in
the lyrics alignment and transcription tasks on several well-known polyphonic
test datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10219</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10219</id><created>2019-09-23</created><authors><author><keyname>Park</keyname><forenames>Jungwon</forenames></author><author><keyname>Kim</keyname><forenames>Junha</forenames></author><author><keyname>Jang</keyname><forenames>Inkyu</forenames></author><author><keyname>Kim</keyname><forenames>H. Jin</forenames></author></authors><title>Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee
  using Relative Bernstein Polynomial</title><categories>eess.SY cs.SY</categories><comments>7 pages, ICRA2020 under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new efficient algorithm which guarantees a solution for
a class of multi-agent trajectory planning problems in obstacle-dense
environments. Our algorithm combines the advantages of both grid-based and
optimization-based approaches, and generates safe, dynamically feasible
trajectories without suffering from an erroneous optimization setup such as
imposing infeasible collision constraints. We adopt a sequential optimization
method with \textit{dummy agents} to improve the scalability of the algorithm,
and utilize the convex hull property of Bernstein and relative Bernstein
polynomial to replace non-convex collision avoidance constraints to convex
ones. The proposed method can compute the trajectory for 64 agents on average
6.36 seconds with Intel Core i7-7700 @ 3.60GHz CPU and 16G RAM, and it reduces
more than $50\%$ of the objective cost compared to our previous work. We
validate the proposed algorithm through simulation and flight tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10246</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10246</id><created>2019-09-23</created><updated>2019-09-24</updated><authors><author><keyname>Verstraete</keyname><forenames>David</forenames></author><author><keyname>Droguett</keyname><forenames>Enrique</forenames></author><author><keyname>Modarres</keyname><forenames>Mohammad</forenames></author></authors><title>A deep adversarial approach based on multi-sensor fusion for remaining
  useful life prognostics</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-sensor systems are proliferating the asset management industry and by
proxy, the structural health management community. Asset managers are beginning
to require a prognostics and health management system to predict and assess
maintenance decisions. These systems handle big machinery data and multi-sensor
fusion and integrate remaining useful life prognostic capabilities. We
introduce a deep adversarial learning approach to damage prognostics. A
non-Markovian variational inference-based model incorporating an adversarial
training algorithm framework was developed. The proposed framework was applied
to a public multi-sensor data set of turbofan engines to demonstrate its
ability to predict remaining useful life. We find that using the deep
adversarial based approach results in higher performing remaining useful life
predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10254</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10254</id><created>2019-09-23</created><authors><author><keyname>Rau</keyname><forenames>Richard</forenames></author><author><keyname>Schweizer</keyname><forenames>Dieter</forenames></author><author><keyname>Vishnevskiy</keyname><forenames>Valery</forenames></author><author><keyname>Goksel</keyname><forenames>Orcun</forenames></author></authors><title>Ultrasound Aberration Correction based on Local Speed-of-Sound Map
  Estimation</title><categories>eess.IV eess.SP physics.med-ph</categories><comments>will be published in the proceedings of the IEEE International
  Ultrasonics Symposium (IUS) 2019</comments><journal-ref>2019 IEEE International Ultrasonics Symposium (IUS)</journal-ref><doi>10.1109/ULTSYM.2019.8926297</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For beamforming ultrasound (US) signals, typically a spatially constant
speed-of-sound (SoS) is assumed to calculate delays. As SoS in tissue may vary
relatively largely, this approximation may cause wavefront aberrations, thus
degrading effective imaging resolution. In the literature, corrections have
been proposed based on unidirectional SoS estimation or
computationally-expensive a posteriori phase rectification. In this paper we
demonstrate a direct delay correction approach for US beamforming, by
leveraging 2D spatial SoS distribution estimates from plane-wave imaging. We
show both in simulations and with ex vivo measurements that resolutions close
to the wavelength limit can be achieved using our proposed local SoS-adaptive
beamforming, yielding a lateral resolution improvement of 22% to 29% on tissue
samples with up to 3% SoS-contrast (45m/s). We verify that our method
accurately images absolute positions of tissue structures down to sub-pixel
resolution of a tenth of a wavelength, whereas a global SoS assumption leads to
artifactual localizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10275</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10275</id><created>2019-09-23</created><updated>2020-01-26</updated><authors><author><keyname>Zulfiqar</keyname><forenames>Umair</forenames></author><author><keyname>Sreeram</keyname><forenames>Victor</forenames></author><author><keyname>Du</keyname><forenames>Xin</forenames></author></authors><title>Time-limited pseudo-optimal H2-model order reduction</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model order reduction algorithm is presented that generates a reduced-order
model of the original high-order model, which ensures high-fidelity within the
desired time interval. The reduced model satisfies a subset of the first-order
optimality conditions for time-limited H2-model reduction problem. The
algorithm uses a computationally efficient Krylov subspace-based framework to
generate the reduced model, and it is applicable to large-scale systems. The
reduced-order model is parameterized to enforce a subset of the first-order
optimality conditions in an iteration-free way. We also propose an adaptive
framework of the algorithm, which ensures a monotonic decay in error
irrespective of the choice of interpolation points and tangential directions.
The efficacy of the algorithm is validated on benchmark model reduction
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10284</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10284</id><created>2019-09-23</created><authors><author><keyname>Lhachemi</keyname><forenames>Hugo</forenames></author><author><keyname>Prieur</keyname><forenames>Christophe</forenames></author><author><keyname>Tr&#xe9;lat</keyname><forenames>Emmanuel</forenames></author></authors><title>PI Regulation of a Reaction-Diffusion Equation with Delayed Boundary
  Control</title><categories>math.OC cs.SY eess.SY</categories><comments>Preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The general context of this work is the feedback control of an
infinite-dimensional system so that the closed-loop system satisfies a
fading-memory property and achieves the setpoint tracking of a given reference
signal. More specifically, this paper is concerned with the Proportional
Integral (PI) regulation control of the left Neumann trace of a one-dimensional
reaction-diffusion equation with a delayed right Dirichlet boundary control. In
this setting, the studied reaction-diffusion equation might be either open-loop
stable or unstable. The proposed control strategy goes as follows. First, a
finite-dimensional truncated model that captures the unstable dynamics of the
original infinite-dimensional system is obtained via spectral decomposition.
The truncated model is then augmented by an integral component on the tracking
error of the left Neumann trace. After resorting to the Artstein transformation
to handle the control input delay, the PI controller is designed by pole
shifting. Stability of the resulting closed-loop infinite-dimensional system,
consisting of the original reaction-diffusion equation with the PI controller,
is then established thanks to an adequate Lyapunov function. In the case of a
time-varying reference input and a time-varying distributed disturbance, our
stability result takes the form of an exponential Input-to-State Stability
(ISS) estimate with fading memory. Finally, another exponential ISS estimate
with fading memory is established for the tracking performance of the reference
signal by the system output. In particular, these results assess the setpoint
regulation of the left Neumann trace in the presence of distributed
perturbations that converge to a steady-state value and with a time-derivative
that converges to zero. Numerical simulations are carried out to illustrate the
efficiency of our control strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10286</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10286</id><created>2019-09-23</created><authors><author><keyname>Plessen</keyname><forenames>Mogens Graf</forenames></author></authors><title>GPU-accelerated Logistics Optimisation for Biomass Production with
  Multiple Simultaneous Harvesters Tours, Fields and Plants</title><categories>eess.SY cs.SY</categories><comments>11 pages, double column format, 4 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the context of biomass production this paper proposes a method for
logistics optimisation involving multiple tours to be executed simultaneously
by groups of harvesting units (HUs) and support units (SUs) to first harvest
biomass from multiple agricultural fields, before supplying the biomass to
multiple biogas plants (BPs) via shuttling SUs. This problem is relevant on a
larger scale in particular for contractors. This problem is complex since there
are three interconnected optimisation levels: (i) the assignment of BPs to
tours and the ordering of BPs assigned to each tour, (ii) the assignment of
fields to BPs and the ordering of fields assigned to each BP, and (iii)
determining the number of HUs and SUs assigned to each tour, whereby different
HUs and SUs may in general have different working rates and loading capacities.
The dimensions of the problem considered in this paper are inspired by a large
real-world scenario with 7 tours, 20 biogas plants, 1200 corn fields, 7 HUs and
a total of 42 SUs operated on an area of 80km$\times$80km. Both problem
modeling and a solution method are discussed. For the latter a GPU-accelerated
heuristic search algorithm is proposed. For the former an optimisation
criterion minimising both total accumulated path length and the maximum
completion time over all harvesters tours, an embedded local minimisation for
the assignment of SUs to tours, and demand fulfilment constraints for BPs are
discussed. In stochastic simulation experiments it is found that permitting
unconstrained assignment of any available field that a contractor services to
any available BP independent of their ownerships is crucial to attain maximum
path length savings and also to best balance and minimise uniform completion
times over all harvesters tours such that weather-dependent harvesting windows
can be exploited optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10293</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10293</id><created>2019-09-23</created><authors><author><keyname>Pavi&#x107;</keyname><forenames>I.</forenames></author><author><keyname>Pand&#x17e;i&#x107;</keyname><forenames>H.</forenames></author><author><keyname>Capuder</keyname><forenames>T.</forenames></author></authors><title>EV-based Smart E-mobility System -- Part I: Concept</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first of this two-paper series proposes and elaborates a concept of
electric vehicle (EV)-based e-mobility system. To this end, models designed to
reap the benefits of EVs' flexibility in the literature almost exclusively
consider charging stations as active players exploiting the EVs' flexibility.
Such stations are seen as static loads able to provide flexibility only when
EVs are connected to them. However, this standpoint suffers from two major
issues. First, the charging stations need to anticipate some important
parameters of the incoming EVs, e.g. time of arrival and departure,
state-of-energy of the EV's battery at arrival and the required state-of-energy
at its departure. Second, it observes the EVs only when they are connected to
these charging stations, thus overlooking the arbitrage and charging
opportunities when the EVs are connected to other charging stations. This paper
proposes a new viewpoint, where EVs are observed as dynamic movable storage
systems which can provide flexibility at any charging station. The paper
defines both systems, the existing one, where the flexibility is viewed from
the standpoint of charging stations, and the proposed one, where the
flexibility is viewed from the EVs' standpoint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10297</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10297</id><created>2019-09-23</created><authors><author><keyname>Pavi&#x107;</keyname><forenames>I.</forenames></author><author><keyname>Pand&#x17e;i&#x107;</keyname><forenames>H.</forenames></author><author><keyname>Capuder</keyname><forenames>T.</forenames></author></authors><title>EV-based Smart E-mobility System -- Part II: Formulation and Case Study</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second paper of a two-paper series on smart e-mobility. The
concept defined in the first paper is further elaborated and mathematically
formulated in here. A case study is conducted to evaluate the differences
between the proposed electric-vehicle-based and the existing
charging-station-based emobility systems. Each of the four issues identified in
the first paper are individually examined and omission of corresponding
constraints are analyzed and quantified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10302</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10302</id><created>2019-09-23</created><authors><author><keyname>Shechtman</keyname><forenames>Slava</forenames></author><author><keyname>Sorin</keyname><forenames>Alex</forenames></author></authors><title>Sequence to Sequence Neural Speech Synthesis with Prosody Modification
  Capabilities</title><categories>eess.AS cs.SD</categories><comments>published at 10th ISCA Speech Synthesis Workshop (SSW-10, 2019)</comments><journal-ref>Proc. 10th ISCA Speech Synthesis Workshop, 275-280 (2019)</journal-ref><doi>10.21437/SSW.2019-49</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern sequence to sequence neural TTS systems provide close to natural
speech quality. Such systems usually comprise a network converting
linguistic/phonetic features sequence to an acoustic features sequence,
cascaded with a neural vocoder. The generated speech prosody (i.e. phoneme
durations, pitch and loudness) is implicitly present in the acoustic features,
being mixed with spectral information. Although the speech sounds natural, its
prosody realization is randomly chosen and cannot be easily altered. The
prosody control becomes an even more difficult task if no prosodic labeling is
present in the training data. Recently, much progress has been achieved in
unsupervised speaking style learning and generation, however human inspection
is still required after the training for discovery and interpretation of the
speaking styles learned by the system. In this work we introduce a fully
automatic method that makes the system aware of the prosody and enables
sentence-wise speaking pace and expressiveness control on a continuous scale.
While being useful by itself in many applications, the proposed prosody control
can also improve the overall quality and expressiveness of the synthesized
speech, as demonstrated by subjective listening evaluations. We also propose a
novel augmented attention mechanism, that facilitates better pace control
sensitivity and faster attention convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10327</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10327</id><created>2019-09-23</created><authors><author><keyname>Khirirat</keyname><forenames>Sarit</forenames></author><author><keyname>Magn&#xfa;sson</keyname><forenames>Sindri</forenames></author><author><keyname>Johansson</keyname><forenames>Mikael</forenames></author></authors><title>Compressed Gradient Methods with Hessian-Aided Error Compensation</title><categories>eess.SP math.OC</categories><comments>13 pages, 1 table, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of big data has caused a dramatic shift in the operating regime
for optimization algorithms. The performance bottleneck, which used to be
computations, is now often communications. Several gradient compression
techniques have been proposed to reduce the communication load at the price of
a loss in solution accuracy. Recently, it has been shown how compression errors
can be compensated for in the optimization algorithm to improve the solution
accuracy. Even though convergence guarantees for error-compensated algorithms
have been established, there is very limited theoretical support for
quantifying the observed improvements in solution accuracy. In this paper, we
show that Hessian-aided error compensation, unlike other existing schemes,
avoids the accumulation of compression errors on quadratic problems. We also
present strong convergence guarantees of Hessian-based error compensation for
stochastic gradient descent. Our numerical experiments highlight the benefits
of Hessian-based error compensation, and demonstrate that similar convergence
improvements are attained when only a diagonal Hessian approximation is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10333</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10333</id><created>2019-09-19</created><authors><author><keyname>Sengupta</keyname><forenames>Debleena</forenames></author></authors><title>Deep learning architectures for automated image segmentation</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image segmentation is widely used in a variety of computer vision tasks, such
as object localization and recognition, boundary detection, and medical
imaging. This thesis proposes deep learning architectures to improve automatic
object localization and boundary delineation for salient object segmentation in
natural images and for 2D medical image segmentation. First, we propose and
evaluate a novel dilated dense encoder-decoder architecture with a custom
dilated spatial pyramid pooling block to accurately localize and delineate
boundaries for salient object segmentation. The dilation offers better spatial
understanding and the dense connectivity preserves features learned at
shallower levels of the network for better localization. Tested on three
publicly available datasets, our architecture outperforms the state-of-the-art
for one and is very competitive on the other two. Second, we propose and
evaluate a custom 2D dilated dense UNet architecture for accurate lesion
localization and segmentation in medical images. This architecture can be
utilized as a stand-alone segmentation framework or used as a rich feature
extracting backbone to aid other models in medical image segmentation. Our
architecture outperforms all baseline models for accurate lesion localization
and segmentation on a new dataset. We furthermore explore the main
considerations that should be taken into account for 3D medical image
segmentation, among them preprocessing techniques and specialized loss
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10341</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10341</id><created>2019-09-23</created><authors><author><keyname>Durall</keyname><forenames>Ricard</forenames></author><author><keyname>Pfreundt</keyname><forenames>Franz-Josef</forenames></author><author><keyname>K&#xf6;the</keyname><forenames>Ullrich</forenames></author><author><keyname>Keuper</keyname><forenames>Janis</forenames></author></authors><title>Object Segmentation using Pixel-wise Adversarial Loss</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent deep learning based approaches have shown remarkable success on object
segmentation tasks. However, there is still room for further improvement.
Inspired by generative adversarial networks, we present a generic end-to-end
adversarial approach, which can be combined with a wide range of existing
semantic segmentation networks to improve their segmentation performance. The
key element of our method is to replace the commonly used binary adversarial
loss with a high resolution pixel-wise loss. In addition, we train our
generator employing stochastic weight averaging fashion, which further enhances
the predicted output label maps leading to state-of-the-art results. We show,
that this combination of pixel-wise adversarial training and weight averaging
leads to significant and consistent gains in segmentation performance, compared
to the baseline models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10342</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10342</id><created>2019-09-23</created><authors><author><keyname>Luijten</keyname><forenames>Ben</forenames></author><author><keyname>Cohen</keyname><forenames>Regev</forenames></author><author><keyname>de Bruijn</keyname><forenames>Frederik J.</forenames></author><author><keyname>Schmeitz</keyname><forenames>Harold A. W.</forenames></author><author><keyname>Mischi</keyname><forenames>Massimo</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>van Sloun</keyname><forenames>Ruud J. G.</forenames></author></authors><title>Adaptive Ultrasound Beamforming using Deep Learning</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biomedical imaging is unequivocally dependent on the ability to reconstruct
interpretable and high-quality images from acquired sensor data. This
reconstruction process is pivotal across many applications, spanning from
magnetic resonance imaging to ultrasound imaging. While advanced data-adaptive
reconstruction methods can recover much higher image quality than traditional
approaches, their implementation often poses a high computational burden. In
ultrasound imaging, this burden is significant, especially when striving for
low-cost systems, and has motivated the development of high-resolution and
high-contrast adaptive beamforming methods. Here we show that deep neural
networks that adopt the algorithmic structure and constraints of adaptive
signal processing techniques can efficiently learn to perform fast high-quality
ultrasound beamforming using very little training data. We apply our technique
to two distinct ultrasound acquisition strategies (plane wave, and synthetic
aperture), and demonstrate that high image quality can be maintained when
measuring at low data-rates, using undersampled array designs. Beyond
biomedical imaging, we expect that the proposed deep~learning based adaptive
processing framework can benefit a variety of array and signal processing
applications, in particular when data-efficiency and robustness are of
importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10383</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10383</id><created>2019-09-16</created><authors><author><keyname>Du</keyname><forenames>Sijun</forenames></author></authors><title>Analysis on One-Stage SSHC Rectifier for Piezoelectric Vibration Energy
  Harvesting</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conventional SSHI (synchronized switch harvesting on inductor) has been
believed to be one of the most efficient interface circuits for piezoelectric
vibration energy harvesting systems. It employs an inductor and the resulting
RLC loop to synchronously invert the charge across the piezoelectric material
to avoid charge and energy loss due to charging its internal capacitor ($C_P$).
The performance of the SSHI circuit greatly depends on the inductor and a large
inductor is often needed; hence significantly increases the volume of the
system. An efficient interface circuit using a synchronous charge inversion
technique, named as SSHC, was proposed recently. The SSHC rectifier utilizes
capacitors, instead of inductors, to flip the voltage across the harvester. For
a one-stage SSHC rectifier, one single intermediate capacitor ($C_T$) is
employed to temporarily store charge flowed from $C_P$ and inversely charge
$C_P$ to perform the charge inversion. In previous studies, the voltage flip
efficiency achieves 1/3 when $C_T = C_P$. This paper presents that the voltage
flip efficiency can be further increased to approach 1/2 if $C_T$ is chosen to
be much larger than $C_P$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10407</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10407</id><created>2019-09-23</created><authors><author><keyname>Gogate</keyname><forenames>Mandar</forenames></author><author><keyname>Dashtipour</keyname><forenames>Kia</forenames></author><author><keyname>Adeel</keyname><forenames>Ahsan</forenames></author><author><keyname>Hussain</keyname><forenames>Amir</forenames></author></authors><title>CochleaNet: A Robust Language-independent Audio-Visual Model for Speech
  Enhancement</title><categories>cs.SD cs.CV cs.LG eess.AS</categories><comments>34 pages, 11 figures, Submitted to Information Fusion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noisy situations cause huge problems for suffers of hearing loss as hearing
aids often make the signal more audible but do not always restore the
intelligibility. In noisy settings, humans routinely exploit the audio-visual
(AV) nature of the speech to selectively suppress the background noise and to
focus on the target speaker. In this paper, we present a causal, language,
noise and speaker independent AV deep neural network (DNN) architecture for
speech enhancement (SE). The model exploits the noisy acoustic cues and noise
robust visual cues to focus on the desired speaker and improve the speech
intelligibility. To evaluate the proposed SE framework a first of its kind AV
binaural speech corpus, called ASPIRE, is recorded in real noisy environments
including cafeteria and restaurant. We demonstrate superior performance of our
approach in terms of objective measures and subjective listening tests over the
state-of-the-art SE approaches as well as recent DNN based SE models. In
addition, our work challenges a popular belief that a scarcity of
multi-language large vocabulary AV corpus and wide variety of noises is a major
bottleneck to build a robust language, speaker and noise independent SE
systems. We show that a model trained on synthetic mixture of Grid corpus (with
33 speakers and a small English vocabulary) and ChiME 3 Noises (consisting of
only bus, pedestrian, cafeteria, and street noises) generalise well not only on
large vocabulary corpora but also on completely unrelated languages (such as
Mandarin), wide variety of speakers and noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10443</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10443</id><created>2019-09-23</created><authors><author><keyname>Grupp</keyname><forenames>Robert</forenames></author><author><keyname>Armand</keyname><forenames>Mehran</forenames></author><author><keyname>Taylor</keyname><forenames>Russell</forenames></author></authors><title>Patch-Based Image Similarity for Intraoperative 2D/3D Pelvis
  Registration During Periacetabular Osteotomy</title><categories>cs.CV eess.IV</categories><comments>Presented at MICCAI CLIP Workshop 2018</comments><journal-ref>In OR 2.0 Context-Aware Operating Theaters, Computer Assisted
  Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis
  2018 Sep 16 (pp. 153-163). Springer, Cham</journal-ref><doi>10.1007/978-3-030-01201-4_17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periacetabular osteotomy is a challenging surgical procedure for treating
developmental hip dysplasia, providing greater coverage of the femoral head via
relocation of a patient's acetabulum. Since fluoroscopic imaging is frequently
used in the surgical workflow, computer-assisted X-Ray navigation of osteotomes
and the relocated acetabular fragment should be feasible. We use
intensity-based 2D/3D registration to estimate the pelvis pose with respect to
fluoroscopic images, recover relative poses of multiple views, and triangulate
landmarks which may be used for navigation. Existing similarity metrics are
unable to consistently account for the inherent mismatch between the
preoperative intact pelvis, and the intraoperative reality of a fractured
pelvis. To mitigate the effect of this mismatch, we continuously estimate the
relevance of each pixel to solving the registration and use these values as
weightings in a patch-based similarity metric. Limiting computation to randomly
selected subsets of patches results in faster runtimes than existing
patch-based methods. A simulation study was conducted with random fragment
shapes, relocations, and fluoroscopic views, and the proposed method achieved a
1.7 mm mean triangulation error over all landmarks, compared to mean errors of
3 mm and 2.8 mm for the non-patched and image-intensity-variance-weighted patch
similarity metrics, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10452</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10452</id><created>2019-09-23</created><authors><author><keyname>Grupp</keyname><forenames>Robert</forenames></author><author><keyname>Otake</keyname><forenames>Yoshito</forenames></author><author><keyname>Murphy</keyname><forenames>Ryan</forenames></author><author><keyname>Parvizi</keyname><forenames>Javad</forenames></author><author><keyname>Armand</keyname><forenames>Mehran</forenames></author><author><keyname>Taylor</keyname><forenames>Russell</forenames></author></authors><title>Pelvis Surface Estimation From Partial CT for Computer-Aided Pelvic
  Osteotomies</title><categories>cs.CV eess.IV</categories><comments>CAOS 2015 Extended Paper</comments><journal-ref>In Orthopaedic Proceedings 2016 Feb (Vol. 98, No. SUPP_5, pp.
  55-55). The British Editorial Society of Bone &amp; Joint Surgery</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-aided surgical systems commonly use preoperative CT scans when
performing pelvic osteotomies for intraoperative navigation. These systems have
the potential to improve the safety and accuracy of pelvic osteotomies,
however, exposing the patient to radiation is a significant drawback. In order
to reduce radiation exposure, we propose a new smooth extrapolation method
leveraging a partial pelvis CT and a statistical shape model (SSM) of the full
pelvis in order to estimate a patient's complete pelvis. A SSM of normal,
complete, female pelvis anatomy was created and evaluated from 42 subjects. A
leave-one-out test was performed to characterise the inherent generalisation
capability of the SSM. An additional leave-one-out test was conducted to
measure performance of the smooth extrapolation method and an existing
&quot;cut-and-paste&quot; extrapolation method. Unknown anatomy was simulated by keeping
the axial slices of the patient's acetabulum intact and varying the amount of
the superior iliac crest retained; from 0% to 15% of the total pelvis extent.
The smooth technique showed an average improvement over the cut-and-paste
method of 1.31 mm and 3.61 mm, in RMS and maximum surface error, respectively.
With 5% of the iliac crest retained, the smoothly estimated surface had an RMS
surface error of 2.21 mm, an improvement of 1.25 mm when retaining none of the
iliac crest. This anatomical estimation method creates the possibility of a
patient and surgeon benefiting from the use of a CAS system and simultaneously
reducing the patient's radiation exposure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10461</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10461</id><created>2019-09-18</created><updated>2019-12-03</updated><authors><author><keyname>Fioretto</keyname><forenames>Ferdinando</forenames></author><author><keyname>Mak</keyname><forenames>Terrence W. K.</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames></author></authors><title>Predicting AC Optimal Power Flows: Combining Deep Learning and
  Lagrangian Dual Methods</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><comments>A version of this paper appears in AAAI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Optimal Power Flow (OPF) problem is a fundamental building block for the
optimization of electrical power systems. It is nonlinear and nonconvex and
computes the generator setpoints for power and voltage, given a set of load
demands. It is often needed to be solved repeatedly under various conditions,
either in real-time or in large-scale studies. This need is further exacerbated
by the increasing stochasticity of power systems due to renewable energy
sources in front and behind the meter. To address these challenges, this paper
presents a deep learning approach to the OPF. The learning model exploits the
information available in the prior states of the system (which is commonly
available in practical applications), as well as a dual Lagrangian method to
satisfy the physical and engineering constraints present in the OPF. The
proposed model is evaluated on a large collection of realistic power systems.
The experimental results show that its predictions are highly accurate with
average errors as low as 0.2%. Additionally, the proposed approach is shown to
improve the accuracy of widely adopted OPF linear DC approximation by at least
two orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10462</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10462</id><created>2019-09-19</created><authors><author><keyname>Sarieddeen</keyname><forenames>Hadi</forenames></author><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Next Generation Terahertz Communications: A Rendezvous of Sensing,
  Imaging and Localization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Terahertz (THz)-band communications are celebrated as a key enabling
technology for next-generation wireless systems that promise to integrate a
wide range of data-demanding and delay-sensitive applications. Following recent
advancements in optical, electronic and plasmonic transceiver design,
integrated, adaptive and efficient THz systems are no longer far-fetched. In
this paper, we present a progressive vision on how the traditional THz gap will
transform into a THz rush over the next few years. We opine that the
breakthrough that the THz-band will introduce is not solely driven by the
achievable high data rates, but more profoundly by the interaction between THz
sensing, imaging, and localization applications. We first detail the
peculiarities of each of these applications at the THz band. Then, we
illustrate how their coalescence results in enhanced environment-aware system
performance in beyond-5G use cases. We further discuss the implementation
aspects of this merging of applications in the context of shared and dedicated
resource allocation, and we raise some health and privacy concerns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10472</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10472</id><created>2019-09-23</created><authors><author><keyname>Espitia</keyname><forenames>Nicolas</forenames></author><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author></authors><title>Event-triggered boundary control of constant-parameter
  reaction-diffusion PDEs: a small-gain approach</title><categories>eess.SY cs.SY math.OC</categories><comments>10 pages, to be submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with an event-triggered boundary control of
constant-parameters reaction-diffusion PDE systems. The approach relies on the
emulation of backstepping control along with a suitable triggering condition
which establishes the time instants at which the control value needs to be
sampled/updated. In this paper, it is shown that under the proposed
event-triggered boundary control, there exists a minimal dwell-time
(independent of the initial condition) between two triggering times and
furthermore the well-posedness and global exponential stability are guaranteed.
The analysis follows small-gain arguments and builds on recent papers on
sampled-data control for this kind of PDE. A simulation example is presented to
validate the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10475</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10475</id><created>2019-09-23</created><authors><author><keyname>Master</keyname><forenames>Jade</forenames></author><author><keyname>Patterson</keyname><forenames>Evan</forenames></author><author><keyname>Yousfi</keyname><forenames>Shahin</forenames></author><author><keyname>Canedo</keyname><forenames>Arquimedes</forenames></author></authors><title>String Diagrams for Assembly Planning</title><categories>cs.RO cs.SY eess.SY</categories><comments>6 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assembly planning is a difficult problem for companies. Many disciplines such
as design, planning, scheduling, and manufacturing execution need to be
carefully engineered and coordinated to create successful product assembly
plans. Recent research in the field of design for assembly has proposed new
methodologies to design product structures in such a way that their assembly is
easier. However, present assembly planning approaches lack the engineering tool
support to capture all the constraints associated to assembly planning in a
unified manner. This paper proposes CompositionalPlanning, a string diagram
based framework for assembly planning. In the proposed framework, string
diagrams and their compositional properties serve as the foundation for an
engineering tool where CAD designs interact with planning and scheduling
algorithms to automatically create high-quality assembly plans. These assembly
plans are then executed in simulation to measure their performance and to
visualize their key build characteristics. We demonstrate the versatility of
this approach in the LEGO assembly domain. We developed two reference LEGO CAD
models that are processed by CompositionalPlanning's algorithmic pipeline. We
compare sequential and parallel assembly plans in a Minecraft simulation and
show that the time-to-build performance can be optimized by our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10500</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10500</id><created>2019-09-23</created><updated>2019-09-26</updated><authors><author><keyname>Wang</keyname><forenames>Xue-She</forenames></author><author><keyname>Turner</keyname><forenames>James D.</forenames></author><author><keyname>Mann</keyname><forenames>Brian P.</forenames></author></authors><title>Constrained Attractor Selection Using Deep Reinforcement Learning</title><categories>eess.SY cs.LG cs.SY nlin.CD</categories><comments>12 pages, 5 figures. Correction: the action term 'a_t' in Eq. (2) and
  Eq. (4) was replaced by its absolute value '|a_t|'</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an approach for attractor selection in nonlinear
dynamical systems with constrained actuation. Attractor selection is achieved
using two different deep reinforcement learning methods: 1) the cross-entropy
method (CEM) and 2) the deep deterministic policy gradient (DDPG) method. The
framework and algorithms for applying these control methods are presented.
Experiments were performed on a Duffing oscillator as it is a classic nonlinear
dynamical system with multiple attractors. Both methods achieve attractor
selection under various control constraints. While these methods have nearly
identical success rates, the DDPG method has the advantages a high learning
rate, low performance variance, and offers a smooth control approach. This
experiment demonstrates the applicability of reinforcement learning to
constrained attractor selection problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10555</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10555</id><created>2019-09-23</created><authors><author><keyname>Qiu</keyname><forenames>Ziming</forenames></author><author><keyname>Nair</keyname><forenames>Nitin</forenames></author><author><keyname>Langerman</keyname><forenames>Jack</forenames></author><author><keyname>Aristizabal</keyname><forenames>Orlando</forenames></author><author><keyname>Mamou</keyname><forenames>Jonathan</forenames></author><author><keyname>Turnbull</keyname><forenames>Daniel H.</forenames></author><author><keyname>Ketterling</keyname><forenames>Jeffrey A.</forenames></author><author><keyname>Wang</keyname><forenames>Yao</forenames></author></authors><title>Automatic Mouse Embryo Brain Ventricle &amp; Body Segmentation and Mutant
  Classification From Ultrasound Data Using Deep Learning</title><categories>eess.IV cs.CV</categories><comments>4 pages, 6 figures, the 2019 IEEE International Ultrasonics Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-frequency ultrasound (HFU) is well suited for imaging embryonic mice in
vivo because it is non-invasive and real-time. Manual segmentation of the brain
ventricles (BVs) and whole body from 3D HFU images is time-consuming and
requires specialized training. This paper presents a deep-learning-based
segmentation pipeline which automates several time-consuming, repetitive tasks
currently performed to study genetic mutations in developing mouse embryos.
Namely, the pipeline accurately segments the BV and body regions in 3D HFU
images of mouse embryos, despite significant challenges due to position and
shape variation of the embryos, as well as imaging artifacts. Based on the BV
segmentation, a 3D convolutional neural network (CNN) is further trained to
detect embryos with the Engrailed-1 (En1) mutation. The algorithms achieve
0.896 and 0.925 Dice Similarity Coefficient (DSC) for BV and body segmentation,
respectively, and 95.8% accuracy on mutant classification. Through gradient
based interrogation and visualization of the trained classifier, it is
demonstrated that the model focuses on the morphological structures known to be
affected by the En1 mutation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10556</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10556</id><created>2019-09-23</created><authors><author><keyname>George</keyname><forenames>Jemin</forenames></author><author><keyname>Parayil</keyname><forenames>Anjaly</forenames></author><author><keyname>Bai</keyname><forenames>He</forenames></author></authors><title>Multi-Agent Coordination for Distributed Transmit Beamforming</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the formulation and analysis of a two time-scale
optimization algorithm for multi-agent coordination for the purpose of
distributed beamforming. Each agent is assumed to be randomly positioned with
respect to each other with random phase offsets and amplitudes. Agents are
tasked with coordinate among themselves to position themselves and adjust their
phase offset and amplitude such that they can construct a desired directed
beam. Here we propose a two time-scale optimization algorithm that consists of
a fast time-scale algorithm to solve for the amplitude and phase while a slow
time-scale algorithm to solve for the control required to re-position the
agents. The numerical results given here indicate that the proposed two
time-scale approach is able to reconstruct a desired beam pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10567</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10567</id><created>2019-09-23</created><authors><author><keyname>Xu</keyname><forenames>Jiachen</forenames></author><author><keyname>Grosse-Wentrup</keyname><forenames>Moritz</forenames></author><author><keyname>Jayaram</keyname><forenames>Vinay</forenames></author></authors><title>Tangent space spatial filters for interpretable and efficient Riemannian
  classification</title><categories>eess.SP cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods based on Riemannian geometry have proven themselves to be good models
for decoding in brain-computer interfacing (BCI). However, one major drawback
of these methods is that it is not possible to determine what aspect of the
signal the classifier is built on, leaving open the possibility that artifacts
drive classification performance. In areas where artifactual control is
problematic, specifically neurofeedback and BCIs in patient populations, this
has led people to continue to rely on spatial filters as a way of generating
features that are provably brain-related. Furthermore, these methods also
suffer from the curse of dimensionality and are almost infeasible in
high-density online BCI systems. To tackle these drawbacks, we introduce here a
method for computing spatial filters from any linear function in the Riemannian
tangent space, which allows for more efficient classification as well as the
removal of artifact sources from classifiers built on Riemannian methods. We
first prove a fundamental relationship between certain tangent spaces and
spatial filtering methods, including an explanation of common spatial patterns
within this framework, and then validate our proposed approach using an
open-access BCI analysis framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10568</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10568</id><created>2019-09-23</created><authors><author><keyname>Asaad</keyname><forenames>Isam</forenames></author><author><keyname>Chiha</keyname><forenames>Bilal</forenames></author></authors><title>Design of neural nonlinear PFC Controller to control speed of Autonomous
  Car</title><categories>eess.SY cs.SY</categories><comments>9 pages, 16 figures, Published with International Journal of Computer
  Science Trends and Technology (IJCST)</comments><journal-ref>International Journal of Computer Science Trends and Technology
  (IJCST) V7(3): Page(125-133) May-Jun 2019. ISSN: 2347-8578</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research, we are going to design a neural nonlinear predictive
functional controller (PFC) to achieve a reduced fuel consumption for a chosen
autonomous car walks according to a supplied speed trajectory on known roads.
We used a fitting neural network as a simple tool for modelling the car's
engine and control laws needed to calculate the suitable control commands
passed to the brakes and gas pedals' actuators. Independent model method and
constraints handling are used to provide controller robustness. We used MATLAB
Simulink and IPG CarMaker to design and test our PFC controller. The
performance of designed PFC controller is compared to the performance of a PI
controller which exists within IPG CarMaker simulator. Keywords :- Predictive
Functional Controller, Fuel Consumption, Neural Network, Independent Model,
Constraint Handling, PI Controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10582</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10582</id><created>2019-09-23</created><authors><author><keyname>Kurtz</keyname><forenames>Vince</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Kalman Filtering with Gaussian Processes Measurement Noise</title><categories>stat.ML cs.LG cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-world measurement noise in applications like robotics is often
correlated in time, but we typically assume i.i.d. Gaussian noise for
filtering. We propose general Gaussian Processes as a non-parametric model for
correlated measurement noise that is flexible enough to accurately reflect
correlation in time, yet simple enough to enable efficient computation. We show
that this model accurately reflects the measurement noise resulting from
vision-based Simultaneous Localization and Mapping (SLAM), and argue that it
provides a flexible means of modeling measurement noise for a wide variety of
sensor systems and perception algorithms. We then extend existing results for
Kalman filtering with autoregressive processes to more general Gaussian
Processes, and demonstrate the improved performance of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10583</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10583</id><created>2019-08-09</created><authors><author><keyname>Sarwar</keyname><forenames>Muhammad</forenames></author><author><keyname>Mehmood</keyname><forenames>Faisal</forenames></author><author><keyname>Abid</keyname><forenames>Muhammad</forenames></author><author><keyname>Khan</keyname><forenames>Abdul Qayyum</forenames></author><author><keyname>Gul</keyname><forenames>Sufi Tabassum</forenames></author><author><keyname>Khan</keyname><forenames>Adil Sarwar</forenames></author></authors><title>High Impedance Fault Detection and Isolation in Power Distribution
  Networks using Support Vector Machines</title><categories>eess.SY cs.SY eess.SP</categories><comments>16 pages, 19 figures, published in a journal</comments><journal-ref>Journal of King Saud University - Engineering Sciences, July 2019</journal-ref><doi>10.1016/j.jksues.2019.07.001</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper proposes an accurate High Impedance Fault (HIF) detection and
isolation scheme in a power distribution network. The proposed schemes utilize
the data available from voltage and current sensors. The technique employs
multiple algorithms consisting of Principal Component Analysis, Fisher
Discriminant Analysis, Binary and Multiclass Support Vector Machine for
detection and identification of the high impedance fault. These data driven
techniques have been tested on IEEE 13-node distribution network for detection
and identification of high impedance faults with broken and unbroken conductor.
Further, the robustness of machine learning techniques has also been analysed
by examining their performance with variation in loads for different faults.
Simulation results for different faults at various locations have shown that
proposed methods are fast and accurate in diagnosing high impedance faults.
Multiclass Support Vector Machine gives the best result to detect and locate
High Impedance Fault accurately. It ensures reliability, security and
dependability of the distribution network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10609</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10609</id><created>2019-09-23</created><authors><author><keyname>Rottleuthner</keyname><forenames>Michel</forenames></author><author><keyname>Schmidt</keyname><forenames>Thomas C.</forenames></author><author><keyname>W&#xe4;hlisch</keyname><forenames>Matthias</forenames></author></authors><title>Eco: A Hardware-Software Co-Design for In Situ Power Measurement on
  Low-end IoT Systems</title><categories>eess.SP cs.PF</categories><acm-class>B.8; C.4</acm-class><journal-ref>Proceedings of ENSsys 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-constrained sensor nodes can adaptively optimize their energy
consumption if a continuous measurement exists. This is of particular
importance in scenarios of high dynamics such as energy harvesting or adaptive
task scheduling. However, self-measuring of power consumption at reasonable
cost and complexity is unavailable as a generic system service. In this paper,
we present Eco, a hardware-software co-design enabling generic energy
management on IoT nodes. Eco is tailored to devices with limited resources and
thus targets most of the upcoming IoT scenarios. The proposed measurement
module combines commodity components with a common system interfaces to achieve
easy, flexible integration with various hardware platforms and the RIOT IoT
operating system. We thoroughly evaluate and compare accuracy and overhead. Our
findings indicate that our commodity design competes well with highly optimized
solutions, while being significantly more versatile. We employ Eco for energy
management on RIOT and validate its readiness for deployment in a five-week
field trial integrated with energy harvesting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10633</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10633</id><created>2019-09-23</created><authors><author><keyname>Wang</keyname><forenames>Xiaoqing</forenames></author><author><keyname>Rosenzweig</keyname><forenames>Sebastian</forenames></author><author><keyname>Scholand</keyname><forenames>Nick</forenames></author><author><keyname>Holme</keyname><forenames>H. Christian M.</forenames></author><author><keyname>Uecker</keyname><forenames>Martin</forenames></author></authors><title>Model-based Reconstruction for Simultaneous Multi-slice T1 Mapping using
  Single-shot Inversion-recovery Radial FLASH</title><categories>physics.med-ph eess.IV</categories><comments>Part of this work has been presented at the ISMRM Annual Conference
  2019 (Montreal)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop a simultaneous multi-slice (SMS) model-based
reconstruction method combined with inversion recovery (IR) radial SMS fast
low-angle shot (FLASH) sequences for accelerated multi-slice T1 mapping.
Methods: This work extends single-slice model-based reconstruction to SMS by
modeling the estimation of parameter maps from simultaneously acquired slices
and the respective coil sensitivities as a single nonlinear inverse problem.
This strategy enables an arbitrary choice of SMS acquisition in the partition
dimension. Two IR radial SMS sampling schemes with FLASH readout are
investigated. Validations have been performed on SMS phantom, human brain and
abdominal studies. Results: Phantom results confirm good T1 accuracy and
precision of the proposed SMS model-based reconstructions in comparison to the
single-slice IR references. In-vivo human brain studies show a better
performance of the SMS rotated golden-angle scheme than the SMS aligned one as
well as the conventional multi-slice acquisition using model-based
reconstructions. The former could achieve simultaneous 5-slice human brain T1
mapping or 3-slice abdominal T1 mapping within a single inversion recovery of 4
s. A full-brain T1 mapping with a resolution of $0.75 \times 0.75 \times 5$
mm$^{3}$ is then feasible within 1 minute. Conclusion: The extension of
single-slice model-based reconstruction for SMS data acquisitions was
implemented and demonstrated for efficient high-resolution multi-slice T1
mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10652</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10652</id><created>2019-09-23</created><authors><author><keyname>Zhu</keyname><forenames>Lingchen</forenames></author><author><keyname>Zhang</keyname><forenames>Tuanfeng</forenames></author></authors><title>Generating Geological Facies Models with Fidelity to Diversity and
  Statistics of Training Images using Improved Generative Adversarial Networks</title><categories>cs.LG eess.IV physics.comp-ph stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a methodology and workflow that overcome the limitations
of the conventional Generative Adversarial Networks (GANs) for geological
facies modeling. It attempts to improve the training stability and guarantee
the diversity of the generated geology through interpretable latent vectors.
The resulting samples are ensured to have the equal probability (or an unbiased
distribution) as from the training dataset. This is critical when applying GANs
to generate unbiased and representative geological models that can be further
used to facilitate objective uncertainty evaluation and optimal decision-making
in oil field exploration and development.
  We proposed and implemented a new variant of GANs called Info-WGAN for the
geological facies modeling that combines Information Maximizing Generative
Adversarial Network (InfoGAN) with Wasserstein distance and Gradient Penalty
(GP) for learning interpretable latent codes as well as generating stable and
unbiased distribution from the training data. Different from the original GAN
design, InfoGAN can use the training images with full, partial, or no labels to
perform disentanglement of the complex sedimentary types exhibited in the
training dataset to achieve the variety and diversity of the generated samples.
This is accomplished by adding additional categorical variables that provide
disentangled semantic representations besides the mere randomized latent vector
used in the original GANs. By such means, a regularization term is used to
maximize the mutual information between such latent categorical codes and the
generated geological facies in the loss function.
  Furthermore, the resulting unbiased sampling by Info-WGAN makes the data
conditioning much easier than the conventional GANs in geological modeling
because of the variety and diversity as well as the equal probability of the
unconditional sampling by the generator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10685</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10685</id><created>2019-09-23</created><updated>2019-10-06</updated><authors><author><keyname>Luo</keyname><forenames>Q.</forenames></author><author><keyname>Wang</keyname><forenames>H.</forenames></author></authors><title>Phase Retrieval via Smooth Amplitude Flow</title><categories>eess.SP cs.IT math.IT</categories><comments>18 pages, 6 figures, two referrences added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase retrieval (PR) is an inverse problem about recovering a signal from
phaseless linear measurements. This problem can be effectively solved by
minimizing a nonconvex amplitude-based loss function. However, this loss
function is non-smooth. To address the non-smoothness, a series of methods have
been proposed by adding truncating, reweighting and smoothing operations to
adjust the gradient or the loss function and achieved better performance. But
these operations bring about extra rules and parameters that need to be
carefully designed. Unlike previous works, we present a smooth amplitude flow
method (SAF) which minimizes a novel loss function, without additionally
modifying the gradient or the loss function during gradient descending. Such a
new heuristic can be regarded as a smooth version of the original non-smooth
amplitude-based loss function. We prove that SAF can converge geometrically to
a global optimal point via the gradient algorithm with an elaborate
initialization stage with a high probability. Substantial numerical tests
empirically illustrate that the proposed heuristic is significantly superior to
the original amplitude-based loss function and SAF also outperforms other
state-of-the-art methods in terms of the recovery rate and the converging
speed. Specially, it is numerically shown that SAF can stably recover the
original signal when number of measurements is smaller than the
information-theoretic limit for both the real and the complex Gaussian models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10690</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10690</id><created>2019-09-23</created><authors><author><keyname>Vianna</keyname><forenames>Vinicius Pavanelli</forenames></author><author><keyname>Junior</keyname><forenames>Luiz Otavio Murta</forenames></author></authors><title>Analysis of Generalized Entropies in Mutual Information Medical Image
  Registration</title><categories>eess.IV cs.CV</categories><comments>20 pages, 14 figures and 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mutual information (MI) is the standard method used in image registration and
the most studied one but can diverge and produce wrong results when used in an
automated manner. In this study we compared the results of the ITK Mattes MI
function, used in 3D Slicer and ITK derived software solutions, and our own
MICUDA Shannon and Tsallis MI functions under the translation, rotation and
scale transforms in a 3D mathematical space. This comparison allows to
understand why registration fails in some circumstances and how to produce a
more robust automated algorithm to register medical images. Since our
algorithms were designed to use GPU computations we also have a huge gain in
speed while improving the quality of registration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10692</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10692</id><created>2019-09-23</created><updated>2019-12-21</updated><authors><author><keyname>Wang</keyname><forenames>Hua</forenames></author><author><keyname>Su</keyname><forenames>Dewei</forenames></author><author><keyname>Liu</keyname><forenames>Chuangchuang</forenames></author><author><keyname>Jin</keyname><forenames>Longcun</forenames></author><author><keyname>Sun</keyname><forenames>Xianfang</forenames></author><author><keyname>Peng</keyname><forenames>Xinyi</forenames></author></authors><title>Deformable Non-local Network for Video Super-Resolution</title><categories>eess.IV cs.CV</categories><journal-ref>IEEE Access, vol. 7, pp. 177734-177744, 2019</journal-ref><doi>10.1109/ACCESS.2019.2958030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The video super-resolution (VSR) task aims to restore a high-resolution (HR)
video frame by using its corresponding low-resolution (LR) frame and multiple
neighboring frames. At present, many deep learning-based VSR methods rely on
optical flow to perform frame alignment. The final recovery results will be
greatly affected by the accuracy of optical flow. However, optical flow
estimation cannot be completely accurate, and there are always some errors. In
this paper, we propose a novel deformable non-local network (DNLN) which is a
non-optical-flow-based method. Specifically, we apply the deformable
convolution and improve its ability of adaptive alignment at the feature level.
Furthermore, we utilize a non-local structure to capture the global correlation
between the reference frame and the aligned neighboring frames, and
simultaneously enhance desired fine details in the aligned frames. To
reconstruct the final high-quality HR video frames, we use residual in residual
dense blocks to take full advantage of the hierarchical features. Experimental
results on benchmark datasets demonstrate that the proposed DNLN can achieve
state-of-the-art performance on VSR task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10695</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10695</id><created>2019-09-23</created><authors><author><keyname>Rouast</keyname><forenames>Philipp V.</forenames></author><author><keyname>Adam</keyname><forenames>Marc T. P.</forenames></author></authors><title>Learning deep representations for video-based intake gesture detection</title><categories>cs.CV cs.LG eess.IV</categories><comments>To be published in IEEE Journal of Biomedical and Health Informatics</comments><doi>10.1109/JBHI.2019.2942845</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automatic detection of individual intake gestures during eating occasions has
the potential to improve dietary monitoring and support dietary
recommendations. Existing studies typically make use of on-body solutions such
as inertial and audio sensors, while video is used as ground truth. Intake
gesture detection directly based on video has rarely been attempted. In this
study, we address this gap and show that deep learning architectures can
successfully be applied to the problem of video-based detection of intake
gestures. For this purpose, we collect and label video data of eating occasions
using 360-degree video of 102 participants. Applying state-of-the-art
approaches from video action recognition, our results show that (1) the best
model achieves an $F_1$ score of 0.858, (2) appearance features contribute more
than motion features, and (3) temporal context in form of multiple video frames
is essential for top model performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10696</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10696</id><created>2019-09-23</created><authors><author><keyname>Pradhan</keyname><forenames>Chandan</forenames></author><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>She</keyname><forenames>Changyang</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Computation Offloading for IoT in C-RAN: Optimization and Deep Learning</title><categories>cs.NI eess.SP</categories><comments>Submitted to a IEEE Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider computation offloading for Internet-of-things (IoT) applications
in multiple-input-multiple-output (MIMO) cloud-radio-access-network (C-RAN).
Due to the limited battery life and computational capability in the IoT devices
(IoTDs), the computational tasks of the IoTDs are offloaded to a MIMO C-RAN,
where a MIMO radio resource head (RRH) is connected to a baseband unit (BBU)
through a capacity-limited fronthaul link, facilitated by the spatial filtering
and uniform scalar quantization. We formulate a computation offloading
optimization problem to minimize the total transmit power of the IoTDs while
satisfying the latency requirement of the computational tasks, and find that
the problem is non-convex. To obtain a feasible solution, firstly the spatial
filtering matrix is locally optimized at the MIMO RRH. Subsequently, we
leverage the alternating optimization framework for joint optimization on the
residual variables at the BBU, where the baseband combiner is obtained in a
closed-form, the resource allocation sub-problem is solved through successive
inner convexification, and the number of quantization bits is obtained by a
line-search method. As a low-complexity approach, we deploy a supervised deep
learning method, which is trained with the solutions to our optimization
algorithm. Numerical results validate the effectiveness of the proposed
algorithm and the deep learning method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10726</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10726</id><created>2019-09-24</created><authors><author><keyname>Schmitz</keyname><forenames>R&#xfc;diger</forenames></author><author><keyname>Madesta</keyname><forenames>Frederic</forenames></author><author><keyname>Nielsen</keyname><forenames>Maximilian</forenames></author><author><keyname>Werner</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>R&#xf6;sch</keyname><forenames>Thomas</forenames></author></authors><title>Multi-scale fully convolutional neural networks for histopathology image
  segmentation: from nuclear aberrations to the global tissue architecture</title><categories>eess.IV cs.CV cs.LG q-bio.TO</categories><comments>This work is based upon and extends our PAIP 2019 challenge
  submission which has achieved top-10 results for both tasks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histopathologic diagnosis is dependent on simultaneous information from a
broad range of scales, ranging from nuclear aberrations ($\approx
\mathcal{O}(0.1 \mu m)$) over cellular structures ($\approx \mathcal{O}(10\mu
m)$) to the global tissue architecture ($\gtrapprox \mathcal{O}(1 mm)$).
Bearing in mind which information is employed by human pathologists, we
introduce and examine different strategies for the integration of multiple and
widely separate spatial scales into common U-Net-based architectures. Based on
this, we present a family of new, end-to-end trainable, multi-scale
multi-encoder fully-convolutional neural networks for human modus
operandi-inspired computer vision in histopathology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10730</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10730</id><created>2019-09-24</created><authors><author><keyname>Lu</keyname><forenames>Chao</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Wang</keyname><forenames>Kezhi</forenames></author></authors><title>Bit-level Optimized Neural Network for Multi-antenna Channel
  Quantization</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantized channel state information (CSI) plays a critical role in precoding
design which helps reap the merits of multiple-input multiple-output (MIMO)
technology. In order to reduce the overhead of CSI feedback, we propose a deep
learning based CSI quantization method by developing a joint convolutional
residual network (JCResNet) which benefits MIMO channel feature extraction and
recovery from the perspective of bit-level quantization performance.
Experiments show that our proposed method substantially improves the
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10774</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10774</id><created>2019-09-24</created><authors><author><keyname>Li</keyname><forenames>Biao</forenames></author><author><keyname>Liu</keyname><forenames>Jiabin</forenames></author><author><keyname>Wang</keyname><forenames>Bo</forenames></author><author><keyname>Qi</keyname><forenames>Zhiquan</forenames></author><author><keyname>Shi</keyname><forenames>Yong</forenames></author></authors><title>s-LWSR: Super Lightweight Super-Resolution Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning (DL) architectures for superresolution (SR) normally contain
tremendous parameters, which has been regarded as the crucial advantage for
obtaining satisfying performance. However, with the widespread use of mobile
phones for taking and retouching photos, this character greatly hampers the
deployment of DL-SR models on the mobile devices. To address this problem, in
this paper, we propose a super lightweight SR network: s-LWSR. There are mainly
three contributions in our work. Firstly, in order to efficiently abstract
features from the low resolution image, we build an information pool to mix
multi-level information from the first half part of the pipeline. Accordingly,
the information pool feeds the second half part with the combination of
hierarchical features from the previous layers. Secondly, we employ a
compression module to further decrease the size of parameters. Intensive
analysis confirms its capacity of trade-off between model complexity and
accuracy. Thirdly, by revealing the specific role of activation in deep models,
we remove several activation layers in our SR model to retain more information
for performance improvement. Extensive experiments show that our s-LWSR, with
limited parameters and operations, can achieve similar performance to other
cumbersome DL-SR methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10790</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10790</id><created>2019-09-24</created><authors><author><keyname>Huaulm&#xe9;</keyname><forenames>Arnaud</forenames></author><author><keyname>Voros</keyname><forenames>Sandrine</forenames></author><author><keyname>Reche</keyname><forenames>Fabian</forenames></author><author><keyname>Faucheron</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Moreau-Gaudry</keyname><forenames>Alexandre</forenames></author><author><keyname>Jannin</keyname><forenames>Pierre</forenames></author></authors><title>Offline identification of surgical deviations in laparoscopic rectopexy</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: A median of 14.4% of patient undergone at least one adverse event
during surgery and a third of them are preventable. The occurrence of adverse
events forces surgeons to implement corrective strategies and, thus, deviate
from the standard surgical process. Therefore, it is clear that the automatic
identification of adverse events is a major challenge for patient safety. In
this paper, we have proposed a method enabling us to identify such deviations.
We have focused on identifying surgeons' deviations from standard surgical
processes due to surgical events rather than anatomic specificities. This is
particularly challenging, given the high variability in typical surgical
procedure workflows. Methods: We have introduced a new approach designed to
automatically detect and distinguish surgical process deviations based on
multi-dimensional non-linear temporal scaling with a hidden semi-Markov model
using manual annotation of surgical processes. The approach was then evaluated
using cross-validation. Results: The best results have over 90% accuracy.
Recall and precision were superior at 70%. We have provided a detailed analysis
of the incorrectly-detected observations. Conclusion: Multi-dimensional
non-linear temporal scaling with a hidden semi-Markov model provides promising
results for detecting deviations. Our error analysis of the
incorrectly-detected observations offers different leads in order to further
improve our method. Significance: Our method demonstrated the feasibility of
automatically detecting surgical deviations that could be implemented for both
skill analysis and developing situation awareness-based computer-assisted
surgical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10811</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10811</id><created>2019-09-24</created><authors><author><keyname>Greer</keyname><forenames>Kieran</forenames></author></authors><title>Image Recognition using Region Creep</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new type of image classifier that uses a shallow
architecture with a very quick learning phase. The image is parsed into smaller
areas and each area is saved directly for a region, along with the related
output category. When a new image is presented, a direct match with each part
is made and the best matching areas returned. These areas can overlap with each
other and when moving from a region to its neighbours, there is likely to be
only small changes in the area image part. It would therefore be possible to
guess what the best image part is for one region by cumulating the results of
its neighbours. This is in fact an associative feature of the classifier that
can re-construct missing or noisy input by substituting the direct match with
what the region match suggests and is being called 'Region Creep'. As each area
stores the categories it belongs to, the image classification process sums this
to return a preferred category for the whole image. The classifier works mostly
at a local level and so to give it some type of global picture, rules are
added. These rules work at the whole image level and basically state that if
one set of pixels are present, another set should be removed or should also be
present. While the rules appear to be very specific, most of the construction
can be done automatically. Tests on a set of hand-written numbers have produced
state-of-the-art results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10837</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10837</id><created>2019-09-24</created><updated>2020-01-12</updated><authors><author><keyname>Zhou</keyname><forenames>Shibo</forenames></author><author><keyname>Chen</keyname><forenames>Ying</forenames></author><author><keyname>Ye</keyname><forenames>Qiang</forenames></author><author><keyname>Li</keyname><forenames>Jingxi</forenames></author></authors><title>Direct training based spiking convolutional neural networks for object
  recognition</title><categories>cs.CV cs.NE eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direct training based spiking neural networks (SNNs) have been paid a lot of
attention recently because of its high energy efficiency on emerging
neuromorphic hardware. However, due to the non-differentiability of the spiking
activity, most of the related SNNs still cannot achieve high object recognition
accuracy for the complicated dataset, such as CIFAR-10. Even though some of
them can reach the accuracy of 90%, the energy consumption in those networks is
very high. Considering this, we propose a direct supervised learning based
spiking convolutional neural networks (SCNNs) using temporal coding scheme in
this study, aiming to exploit minimum trainable parameters to recognize the
object in the image with high accuracy. The MNIST and CIFAR-10 datasets are
used to evaluate the performance of the proposed networks. For the MNIST
dataset, the proposed networks with noise input are able to reach the high
recognition accuracy (99.13%) as the other state-of-art models but use the much
less trainable parameters than them. For CIFAR-10 dataset, the proposed
networks with data augmentation step can reach the recognition accuracy of
80.49%., which is the state-of-art high accuracy in the field of direct
training based SNNs using temporal coding manner. In addition, the number of
trainable parameters used in such networks is much less than that in the
conversion based SCNNs reported in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10856</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10856</id><created>2019-09-24</created><updated>2019-09-24</updated><authors><author><keyname>Liu</keyname><forenames>Yiling</forenames></author><author><keyname>Liu</keyname><forenames>Qiegen</forenames></author><author><keyname>Zhang</keyname><forenames>Minghui</forenames></author><author><keyname>Yang</keyname><forenames>Qingxin</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author></authors><title>IFR-Net: Iterative Feature Refinement Network for Compressed Sensing MRI</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve the compressive sensing MRI (CS-MRI) approaches in terms of fine
structure loss under high acceleration factors, we have proposed an iterative
feature refinement model (IFR-CS), equipped with fixed transforms, to restore
the meaningful structures and details. Nevertheless, the proposed IFR-CS still
has some limitations, such as the selection of hyper-parameters, a lengthy
reconstruction time, and the fixed sparsifying transform. To alleviate these
issues, we unroll the iterative feature refinement procedures in IFR-CS to a
supervised model-driven network, dubbed IFR-Net. Equipped with training data
pairs, both regularization parameter and the utmost feature refinement operator
in IFR-CS become trainable. Additionally, inspired by the powerful
representation capability of convolutional neural network (CNN), CNN-based
inversion blocks are explored in the sparsity-promoting denoising module to
generalize the sparsity-enforcing operator. Extensive experiments on both
simulated and in vivo MR datasets have shown that the proposed network
possesses a strong capability to capture image details and preserve well the
structural information with fast reconstruction speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10861</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10861</id><created>2019-09-24</created><authors><author><keyname>Huang</keyname><forenames>Chao-Wei</forenames></author><author><keyname>Chen</keyname><forenames>Yun-Nung</forenames></author></authors><title>Learning ASR-Robust Contextualized Embeddings for Spoken Language
  Understanding</title><categories>cs.CL cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Employing pre-trained language models (LM) to extract contextualized word
representations has achieved state-of-the-art performance on various NLP tasks.
However, applying this technique to noisy transcripts generated by automatic
speech recognizer (ASR) is concerned. Therefore, this paper focuses on making
contextualized representations more ASR-robust. We propose a novel
confusion-aware fine-tuning method to mitigate the impact of ASR errors to
pre-trained LMs. Specifically, we fine-tune LMs to produce similar
representations for acoustically confusable words that are obtained from word
confusion networks (WCNs) produced by ASR. Experiments on the benchmark ATIS
dataset show that the proposed method significantly improves the performance of
spoken language understanding when performing on ASR transcripts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10865</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10865</id><created>2019-09-19</created><authors><author><keyname>Erb</keyname><forenames>Wolfgang</forenames></author></authors><title>Shapes of Uncertainty in Spectral Graph Theory</title><categories>eess.SP cs.NA math.NA</categories><comments>21 pages, 9 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a flexible framework for uncertainty principles in spectral graph
theory. In this framework, general filter functions modeling the spatial and
spectral localization of a graph signal can be incorporated. It merges several
existing uncertainty relations on graphs, among others the Landau-Pollak
principle describing the joint admissibility region of two projection
operators, and uncertainty relations based on spectral and spatial spreads.
Using theoretical and computational aspects of the numerical range of matrices,
we are able to characterize and illustrate the shapes of the uncertainty curves
and to study the space-frequency localization of signals inside the
admissibility regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10868</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10868</id><created>2019-09-18</created><updated>2020-01-31</updated><authors><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Yao</keyname><forenames>Lina</forenames></author><author><keyname>Dong</keyname><forenames>Manqing</forenames></author><author><keyname>Liu</keyname><forenames>Zhe</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Li</keyname><forenames>Yong</forenames></author></authors><title>Adversarial Representation Learning for Robust Patient-Independent
  Epileptic Seizure Detection</title><categories>eess.SP cs.LG</categories><comments>Accepted by the IEEE Journal of Biomedical and Health Informatics
  (J-BHI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Epilepsy is a chronic neurological disorder characterized by the
occurrence of spontaneous seizures, which affects about one percent of the
world's population. Most of the current seizure detection approaches strongly
rely on patient history records and thus fail in the patient-independent
situation of detecting the new patients. To overcome such limitation, we
propose a robust and explainable epileptic seizure detection model that
effectively learns from seizure states while eliminates the inter-patient
noises. Methods: A complex deep neural network model is proposed to learn the
pure seizure-specific representation from the raw non-invasive
electroencephalography (EEG) signals through adversarial training. Furthermore,
to enhance the explainability, we develop an attention mechanism to
automatically learn the importance of each EEG channels in the seizure
diagnosis procedure. Results: The proposed approach is evaluated over the
Temple University Hospital EEG (TUH EEG) database. The experimental results
illustrate that our model outperforms the competitive state-of-the-art
baselines with low latency. Moreover, the designed attention mechanism is
demonstrated ables to provide fine-grained information for pathological
analysis. Conclusion and significance: We propose an effective and efficient
patient-independent diagnosis approach of epileptic seizure based on raw EEG
signals without manually feature engineering, which is a step toward the
development of large-scale deployment for real-life use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10870</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10870</id><created>2019-09-18</created><authors><author><keyname>Eck</keyname><forenames>Bradley</forenames></author><author><keyname>Fusco</keyname><forenames>Francesco</forenames></author><author><keyname>Gormally</keyname><forenames>Robert</forenames></author><author><keyname>Purcell</keyname><forenames>Mark</forenames></author><author><keyname>Tirupathi</keyname><forenames>Seshu</forenames></author></authors><title>AI Modelling and Time-series Forecasting Systems for Trading Energy
  Flexibility in Distribution Grids</title><categories>eess.SP</categories><doi>10.1145/3307772.3330158</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate progress on the deployment of two sets of technologies to
support distribution grid operators integrating high shares of renewable energy
sources, based on a market for trading local energy flexibilities. An
artificial-intelligence (AI) grid modelling tool, based on probabilistic
graphs, predicts congestions and estimates the amount and location of energy
flexibility required to avoid such events. A scalable time-series forecasting
system delivers large numbers of short-term predictions of distributed energy
demand and generation. We discuss the deployment of the technologies at three
trial demonstration sites across Europe, in the context of a research project
carried out in a consortium with energy utilities, technology providers and
research institutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10873</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10873</id><created>2019-09-19</created><authors><author><keyname>Baumann</keyname><forenames>Dominik</forenames></author><author><keyname>Mager</keyname><forenames>Fabian</forenames></author><author><keyname>Jacob</keyname><forenames>Romain</forenames></author><author><keyname>Thiele</keyname><forenames>Lothar</forenames></author><author><keyname>Zimmerling</keyname><forenames>Marco</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Fast Feedback Control over Multi-hop Wireless Networks with Mode Changes
  and Stability Guarantees</title><categories>eess.SY cs.MA cs.SY</categories><comments>Accepted for publication in ACM Transactions on Cyber-Physical
  Systems. arXiv admin note: text overlap with arXiv:1804.08986</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Closing feedback loops fast and over long distances is key to emerging
cyber-physical applications; for example, robot motion control and swarm
coordination require update intervals of tens of milliseconds. Low-power
wireless communication technology is preferred for its low cost, small form
factor, and flexibility, especially if the devices support multi-hop
communication. Thus far, however, feedback control over multi-hop low-power
wireless networks has only been demonstrated for update intervals on the order
of seconds. To fill this gap, this paper presents a wireless embedded system
that supports dynamic mode changes and tames imperfections impairing control
performance (e.g., jitter and message loss), and a control design that exploits
the essential properties of this system to provably guarantee closed-loop
stability for physical processes with linear time-invariant dynamics in the
presence of mode changes. Using experiments on a cyber-physical testbed with 20
wireless devices and multiple cart-pole systems, we are the first to
demonstrate and evaluate feedback control and coordination with mode changes
over multi-hop networks for update intervals of 20 to 50 milliseconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10874</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10874</id><created>2019-09-22</created><authors><author><keyname>Safi</keyname><forenames>Mostafa</forenames></author><author><keyname>Dibaji</keyname><forenames>Seyed Mehran</forenames></author><author><keyname>Pirani</keyname><forenames>Mohammad</forenames></author></authors><title>Resilient Coordinated Movement of Connected Autonomous Vehicles</title><categories>cs.MA cs.CR cs.SY eess.SY</categories><comments>9 pages, 6 figures, 1 algorithm. arXiv admin note: text overlap with
  arXiv:1701.03430</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider coordinated movement of a network of vehicles
consisting a bounded number of malicious agents, that is, vehicles must reach
consensus in longitudinal position and a common predefined velocity. The
motions of vehicles are modeled by double-integrator dynamics and
communications over the network are asynchronous with delays. Each normal
vehicle updates its states by utilizing the information it receives from
vehicles in its vicinity. On the other hand, misbehaving vehicles make updates
arbitrarily and might threaten the consensus within the network by
intentionally changing their moving direction or broadcasting faulty
information in their neighborhood. We propose an asynchronous updating strategy
for normal vehicles, based on filtering extreme values received from
neighboring vehicles, to save them from being misguided by malicious vehicles.
We show that there exist topological constraints on the network in terms of
graph robustness under which the vehicles resiliently achieve coordinated
movement. Numerical simulations are provided to evaluate the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10913</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10913</id><created>2019-09-23</created><updated>2020-02-17</updated><authors><author><keyname>Massow</keyname><forenames>Kay</forenames></author><author><keyname>Radusch</keyname><forenames>Ilja</forenames></author><author><keyname>Shorten</keyname><forenames>Robert</forenames></author></authors><title>On Constant Distance Spacing Policies for Cooperative Adaptive Cruise
  Control</title><categories>eess.SY cs.SY</categories><comments>In preparation for submission to IEEE Transactions on Intelligent
  Transportation Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative Adaptive Cruise Control (CACC) systems are considered as key
potential enablers to improve driving safety and traffic efficiency. They allow
for automated vehicle following using wireless communication in addition to
onboard sensors. To achieve string stability in CACC platoons, constant time
headway (CTH) spacing policies have prevailed in research; namely, vehicle
interspacing grows with the speed. While constant distance headway (CDH)
spacing policies provide superior potential to increase traffic capacity than
CTH, a major drawback is a smaller safety margin at high velocities and string
stability cannot be achieved using a one-vehicle look-ahead communication. The
hypothesis of this work is to apply CDH only in few driving situations, when
traffic throughput is of highest importance and safety requirements can be met
due to comparably low velocities. As the most relevant situations where CDH
could be applied, we identify starting platoons at signalized intersections. In
this paper, we illustrate this idea. Specifically, we compare CTH with CDH
regarding its potential to increase the capacity of traffic lights. Starting
with the elementary situation of single traffic lights we expand our scope to
whole traffic networks including several thousand vehicles in simulation. Using
real world data to calibrate and validate vehicle dynamics simulation and
traffic simulation, the study discusses the most relevant working parameters of
CDH, CTH, and the traffic system in which both are applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10914</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10914</id><created>2019-09-23</created><authors><author><keyname>Xiao</keyname><forenames>Xuedou</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Taobin</forenames></author><author><keyname>Cao</keyname><forenames>Yang</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Qian</forenames></author></authors><title>Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs</title><categories>eess.SP cs.LG cs.MM stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in unmanned aerial vehicle (UAV) technology have
revolutionized a broad class of civil and military applications. However, the
designs of wireless technologies that enable real-time streaming of
high-definition video between UAVs and ground clients present a conundrum. Most
existing adaptive bitrate (ABR) algorithms are not optimized for the
air-to-ground links, which usually fluctuate dramatically due to the dynamic
flight states of the UAV. In this paper, we present SA-ABR, a new
sensor-augmented system that generates ABR video streaming algorithms with the
assistance of various kinds of inherent sensor data that are used to pilot
UAVs. By incorporating the inherent sensor data with network observations,
SA-ABR trains a deep reinforcement learning (DRL) model to extract salient
features from the flight state information and automatically learn an ABR
algorithm to adapt to the varying UAV channel capacity through the training
process. SA-ABR does not rely on any assumptions or models about UAV's flight
states or the environment, but instead, it makes decisions by exploiting
temporal properties of past throughput through the long short-term memory
(LSTM) to adapt itself to a wide range of highly dynamic environments. We have
implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare
SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the
results show that our system outperforms the best known existing ABR algorithm
by 21.4% in terms of the average quality of experience (QoE) reward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10922</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10922</id><created>2019-09-23</created><authors><author><keyname>Zhao</keyname><forenames>Yiyuan</forenames></author></authors><title>Automatic techniques for cochlear implant CT image analysis</title><categories>eess.IV cs.CV cs.GL</categories><comments>This is a preprint of Yiyuan Zhao's Ph.D. dissertation from
  Vanderbilt University, Nashville, TN, USA. Trivial formatting modifications
  have been made in the arxiv version for readability. Vanderbilt University
  Electronic These &amp; Dissertation (https://etd.library.vanderbilt.edu/) has the
  original submission on May 11 2018, and will be released on May 11 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goals of this dissertation are to fully automate the image processing
techniques needed in the post-operative stage of IGCIP and to perform a
thorough analysis of (a) the robustness of the automatic image processing
techniques used in IGCIP and (b) assess the sensitivity of the IGCIP process as
a whole to individual components. The automatic methods that have been
developed include the automatic localization of both closely- and
distantly-spaced CI electrode arrays in post-implantation CTs and the automatic
selection of electrode configurations based on the stimulation patterns.
Together with the existing automatic techniques developed for IGCIP, the
proposed automatic methods enable an end-to-end IGCIP process that takes pre-
and post-implantation CT images as input and produces a patient-customized
electrode configuration as output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10924</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10924</id><created>2019-09-24</created><authors><author><keyname>Wang</keyname><forenames>Pengwei</forenames></author><author><keyname>Wei</keyname><forenames>Liangchen</forenames></author><author><keyname>Cao</keyname><forenames>Yong</forenames></author><author><keyname>Xie</keyname><forenames>Jinghui</forenames></author><author><keyname>Cao</keyname><forenames>Yuji</forenames></author><author><keyname>Nie</keyname><forenames>Zaiqing</forenames></author></authors><title>Understanding Semantics from Speech Through Pre-training</title><categories>eess.AS cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end Spoken Language Understanding (SLU) is proposed to infer the
semantic meaning directly from audio features without intermediate text
representation. Although the acoustic model component of an end-to-end SLU
system can be pre-trained with Automatic Speech Recognition (ASR) targets, the
SLU component can only learn semantic features from limited task-specific
training data. In this paper, for the first time we propose to do large-scale
unsupervised pre-training for the SLU component of an end-to-end SLU system, so
that the SLU component may preserve semantic features from massive unlabeled
audio data. As the output of the acoustic model component, i.e. phoneme
posterior sequences, has much different characteristic from text sequences, we
propose a novel pre-training model called BERT-PLM, which stands for
Bidirectional Encoder Representations from Transformers through Permutation
Language Modeling. BERT-PLM trains the SLU component on unlabeled data through
a regression objective equivalent to the partial permutation language modeling
objective, while leverages full bi-directional context information with BERT
networks. The experiment results show that our approach out-perform the
state-of-the-art end-to-end systems with over 12.5% error reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10939</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10939</id><created>2019-09-24</created><authors><author><keyname>Borianne</keyname><forenames>Philippe</forenames><affiliation>UMR AMAP</affiliation></author><author><keyname>Borne</keyname><forenames>Frederic</forenames><affiliation>UMR AMAP</affiliation></author><author><keyname>Sarron</keyname><forenames>Julien</forenames><affiliation>EGCE</affiliation></author><author><keyname>Faye</keyname><forenames>Emile</forenames><affiliation>EGCE</affiliation></author></authors><title>Deep Mangoes: from fruit detection to cultivar identification in colour
  images of mango trees</title><categories>cs.CV eess.IV eess.SP</categories><proxy>ccsd</proxy><journal-ref>DISP'19 International Conference on Digital Image and Signal
  Processing, Apr 2019, Oxford, United Kingdom</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents results on the detection and identification mango fruits
from colour images of trees. We evaluate the behaviour and the performances of
the Faster R-CNN network to determine whether it is robust enough to &quot;detect
and classify&quot; fruits under particularly heterogeneous conditions in terms of
plant cultivars, plantation scheme, and visual information acquisition
contexts. The network is trained to distinguish the 'Kent', 'Keitt', and
&quot;Boucodiekhal&quot; mango cultivars from 3,000 representative labelled fruit
annotations. The validation set composed of about 7,000 annotations was then
tested with a confidence threshold of 0.7 and a Non-Maximal-Suppression
threshold of 0.25. With a F1-score of 0.90, the Faster R-CNN is well suitable
to the simple fruit detection in tiles of 500x500 pixels. We then combine a
multi-tiling approach with a Jaccard matrix to merge the different parts of
objects detected several times, and thus report the detections made at the tile
scale to the native 6,000x4,000 pixel size images. Nonetheless with a F1-score
of 0.56, the cultivar identification Faster R-CNN network presents some
limitations for simultaneously detecting the mango fruits and identifying their
respective cultivars. Despite the proven errors in fruit detection, the
cultivar identification rates of the detected mango fruits are in the order of
80%. The ideal solution could combine a Mask R-CNN for the image
pre-segmentation of trees and a double-stream Faster R-CNN for detecting the
mango fruits and identifying their respective cultivar to provide predictions
more relevant to users' expectations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10980</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10980</id><created>2019-09-20</created><authors><author><keyname>Shivakumar</keyname><forenames>Shreyas S.</forenames></author><author><keyname>Rodrigues</keyname><forenames>Neil</forenames></author><author><keyname>Zhou</keyname><forenames>Alex</forenames></author><author><keyname>Miller</keyname><forenames>Ian D.</forenames></author><author><keyname>Kumar</keyname><forenames>Vijay</forenames></author><author><keyname>Taylor</keyname><forenames>Camillo J.</forenames></author></authors><title>PST900: RGB-Thermal Calibration, Dataset and Segmentation Network</title><categories>cs.CV cs.RO eess.IV</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose long wave infrared (LWIR) imagery as a viable
supporting modality for semantic segmentation using learning-based techniques.
We first address the problem of RGB-thermal camera calibration by proposing a
passive calibration target and procedure that is both portable and easy to use.
Second, we present PST900, a dataset of 894 synchronized and calibrated RGB and
Thermal image pairs with per pixel human annotations across four distinct
classes from the DARPA Subterranean Challenge. Lastly, we propose a CNN
architecture for fast semantic segmentation that combines both RGB and Thermal
imagery in a way that leverages RGB imagery independently. We compare our
method against the state-of-the-art and show that our method outperforms them
in our dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10995</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10995</id><created>2019-09-24</created><updated>2019-09-25</updated><authors><author><keyname>Schlemper</keyname><forenames>Jo</forenames></author><author><keyname>Oksuz</keyname><forenames>Ilkay</forenames></author><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Duan</keyname><forenames>Jinming</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author><author><keyname>Schnabel</keyname><forenames>Julia A.</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph V.</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>dAUTOMAP: decomposing AUTOMAP to achieve scalability and enhance
  performance</title><categories>cs.LG eess.IV stat.ML</categories><comments>Presented at ISMRM 27th Annual Meeting &amp; Exhibition (Abstract #658)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AUTOMAP is a promising generalized reconstruction approach, however, it is
not scalable and hence the practicality is limited. We present dAUTOMAP, a
novel way for decomposing the domain transformation of AUTOMAP, making the
model scale linearly. We show dAUTOMAP outperforms AUTOMAP with significantly
fewer parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.10999</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.10999</id><created>2019-09-24</created><authors><author><keyname>Furieri</keyname><forenames>Luca</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author></authors><title>First Order Methods For Globally Optimal Distributed Controllers Beyond
  Quadratic Invariance</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the distributed Linear Quadratic Gaussian (LQG) control problem in
discrete-time and finite-horizon, where the controller depends linearly on the
history of the outputs and it is required to lie in a given subspace, e.g. to
possess a certain sparsity pattern. It is well-known that this problem can be
solved with convex programming within the Youla domain if and only if a
condition known as Quadratic Invariance (QI) holds. In this paper, we first
show that given QI sparsity constraints, one can directly descend the gradient
of the cost function within the domain of output-feedback controllers and
converge to a global optimum. Note that convergence is guaranteed despite
non-convexity of the cost function. Second, we characterize a class of Uniquely
Stationary (US) problems, for which first-order methods are guaranteed to
converge to a global optimum. We show that the class of US problems is strictly
larger than that of strongly QI problems and that it is not included in that of
QI problems. We refer to Figure 1 for details. Finally, we propose a tractable
test for the US property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11002</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11002</id><created>2019-09-12</created><authors><author><keyname>Amirabadi</keyname><forenames>M. A.</forenames></author></authors><title>A deep learning based solution for imperfect CSI problem in correlated
  FSO communication channel</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imperfect channel state information (CSI) at the receiver, which is due to
channel estimation error, is one of the main problems toward achieving optimum
detection. This paper presents a deep learning based structure for combating
this issue. In order to show the effect of using deep learning, the symbol
error rate of a simple free space optical (FSO) communication system is
simulated over correlated and un-correlated log-normal channel with write/
wrong CSI. Novelties and contributions of this paper, which are done for the
first in machine learning for FSO communication include considering deep
learning, considering Log-normal channel, considering correlated channel,
considering imperfect CSI. The proposed deep learning based structure is
compared with maximum likelihood detector, it is shown that in perfect CSI,
both perform the same (because maximum likelihood is optimum), but in imperfect
CSI, proposed deep learning based structure outperforms maximum likelihood in
channels with un-correlation or desired correlation lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11003</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11003</id><created>2019-09-12</created><authors><author><keyname>Amirabadi</keyname><forenames>M. A.</forenames></author></authors><title>Deep learning for channel estimation in FSO communication system</title><categories>eess.SP</categories><doi>10.1016/j.optcom.2019.124989</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfect channel estimation is very hard, time/ power consuming, and
expensive; so it is not preferred (e.g. in mobile) communication systems. This
paper seeks for new, cheap, low complexity, deep learning based solution.
Several new combinations of deep learning and conventional structures (in
different parts such as constellation shaper, channel estimator, and detector)
are presented investigated, and compared over all atmospheric turbulence
regimes from weak to strong (considering Gamma-Gamma atmospheric turbulence
model). Results indicate that deep learning could provide close enough
performance to the perfect channel estimation scheme, and it is immune to the
atmospheric turbulence variation. The proposed deep learning based solutions
are low cost, low complexity, with favorable performance. Accordingly, they are
recommended for channel estimation in mobile communication systems. Because
these system should deliver favorable, and cheap services to the costumers,
which use a small mobile as transceiver that needs to be cheap, low complexity
and low power consuming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11016</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11016</id><created>2019-09-24</created><authors><author><keyname>Issaid</keyname><forenames>Chaouki ben</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Efficient Estimation of the Left Tail of Bimodal Distributions with
  Applications to Underwater Optical Communication Systems</title><categories>stat.AP eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose efficient importance sampling estimators to
evaluate the outage probability of maximum ratio combining receivers over
turbulence-induced fadings in underwater wireless optical channels. We consider
two fading models: exponential-lognormal, and exponential-generalized Gamma.
The cross-entropy optimization method is used to determine the optimal biased
distribution. We show by simulations that the number of samples required by
importance sampling estimator is much less compared to naive Monte Carlo for
the same accuracy requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11024</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11024</id><created>2019-09-24</created><authors><author><keyname>Salehi</keyname><forenames>Farshid</forenames></author><author><keyname>Saraf</keyname><forenames>Parimal</forenames></author><author><keyname>Brahman</keyname><forenames>Azade</forenames></author><author><keyname>Tabrizi</keyname><forenames>Mehriar A.</forenames></author></authors><title>Evaluating the Impacts of Transmission Expansion on Sub-Synchronous
  Resonance Risk</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While transmission expansions are planned to have positive impact on
reliability of power grids, they could increase the risk and severity of some
of the detrimental incidents in power grid mainly by virtue of changing system
configuration, consequently electrical distance. This paper aims to evaluate
and quantify the impact of transmission expansion projects on Sub-Synchronous
Resonance (SSR) risk through a two-step approach utilizing outage count index
and Sub-synchronous damping index. A graph-theory based SSR screening tool is
introduced to quantify the outage count associated with all grid contingencies
which results in radial connection between renewable generation resources and
nearby series compensated lines. Moreover, a frequency-scan based damping
analysis is performed to assess the impact of transmission expansion on the
system damping in sub-synchronous frequency range. The proposed approach has
been utilized to evaluate the impact of recently-built transmission expansion
project on SSR risk in a portion of Electric Reliability Council of Texas
(ERCOT) grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11040</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11040</id><created>2019-09-24</created><updated>2019-10-14</updated><authors><author><keyname>Xie</keyname><forenames>Qian</forenames></author><author><keyname>Jin</keyname><forenames>Li</forenames></author></authors><title>Resilience of Dynamic Routing in the Face of Recurrent and Random
  Sensing Faults</title><categories>eess.SY cs.SY</categories><comments>17 pages, 4 figures, submitted to ACC 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feedback dynamic routing is a commonly used control strategy in
transportation systems. This class of control strategies rely on real-time
information about the traffic state in each link. However, such information may
not always be observable due to temporary sensing faults. In this article, we
consider dynamic routing over two parallel routes, where the sensing on each
link is subject to recurrent and random faults. The faults occur and clear
according to a finite-state Markov chain. When the sensing is faulty on a link,
the traffic state on that link appears to be zero to the controller. Building
on the theories of Markov processes and monotone dynamical systems, we derive
lower and upper bounds for the resilience score, i.e. the guaranteed throughput
of the network, in the face of sensing faults by establishing stability
conditions for the network. We use these results to study how a variety of key
parameters affect the resilience score of the network. The main conclusions
are: (i) Sensing faults can reduce throughput and destabilize a nominally
stable network; (ii) A higher failure rate does not necessarily reduce
throughput, and there may exist a worst rate that minimizes throughput; (iii)
The higher the correlation between the failure of two links, the larger the
throughput; (iv) A large difference in capacity between two links can result in
a drop in throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11046</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11046</id><created>2019-09-24</created><authors><author><keyname>Min</keyname><forenames>Youngjae</forenames></author><author><keyname>Park</keyname><forenames>Soon-Seo</forenames></author><author><keyname>Choi</keyname><forenames>Han-Lim</forenames></author></authors><title>Informative Planning of Mobile Sensor Networks in GPS-Denied
  Environments</title><categories>eess.SY cs.MA cs.SY stat.AP</categories><comments>14 pages, 10 figures, Accepted to 2020 AIAA SciTech: Guidance,
  Navigation, and Control (GN&amp;C)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem to plan mobile sensor networks for target
localization task in GPS-denied environments. Most researches on mobile sensor
networks assume that the states of the sensing agents are precisely known
during their missions, which is not feasible under the absence of external
infrastructures such as GPS. Thus, we propose a new algorithm to solve this
problem by: (i) estimating the states of the sensing agents in addition to the
target's through the combination of a particle filter (PF) and extended Kalman
filters (EKF) and (ii) involving the uncertainty of the states of the sensing
agents in planning the sensor networks based on the combined filters. This
approach does not require any additional internal/external sensors nor the
prior knowledge of the surrounding environments. We demonstrate the limitations
of prior works in GPS-denied environments and the improvements from the
proposed algorithm through Monte Carlo experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11062</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11062</id><created>2019-09-24</created><updated>2019-10-29</updated><authors><author><keyname>Hirn</keyname><forenames>Matthew</forenames></author><author><keyname>Little</keyname><forenames>Anna</forenames></author></authors><title>Wavelet invariants for statistically robust multi-reference alignment</title><categories>eess.SP math.ST stat.TH</categories><comments>53 pages, 8 figures</comments><msc-class>62</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a nonlinear, wavelet based signal representation that is
translation invariant and robust to both additive noise and random dilations.
Motivated by the multi-reference alignment problem and generalizations thereof,
we analyze the statistical properties of this representation given a large
number of independent corruptions of a target signal. We prove the nonlinear
wavelet based representation uniquely defines the power spectrum but allows for
an unbiasing procedure that cannot be directly applied to the power spectrum.
After unbiasing the representation to remove the effects of the additive noise
and random dilations, we recover an approximation of the power spectrum by
solving a convex optimization problem, and thus obtain the target signal up to
an unknown phase. Extensive numerical experiments demonstrate the statistical
robustness of this approximation procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11071</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11071</id><created>2019-09-24</created><authors><author><keyname>Paris</keyname><forenames>Aleix</forenames></author><author><keyname>Lopez</keyname><forenames>Brett T.</forenames></author><author><keyname>How</keyname><forenames>Jonathan P.</forenames></author></authors><title>Dynamic Landing of an Autonomous Quadrotor on a Moving Platform in
  Turbulent Wind Conditions</title><categories>eess.SY cs.SY</categories><comments>ICRA2020 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous landing on a moving platform presents unique challenges for
multirotor vehicles, including the need to accurately localize the platform,
fast trajectory planning, and precise/robust control. Previous works studied
this problem but most lack explicit consideration of the wind disturbance,
which typically leads to slow descents onto the platform. This work presents a
fully autonomous vision-based system that addresses these limitations by
tightly coupling the localization, planning, and control, thereby enabling fast
and accurate landing on a moving platform. The platform's position,
orientation, and velocity are estimated by an extended Kalman filter using
simulated GPS measurements when the quadrotor-platform distance is large, and
by a visual fiducial system when the platform is nearby. The landing trajectory
is computed online using receding horizon control and is followed by a boundary
layer sliding controller that provides tracking performance guarantees in the
presence of unknown, but bounded, disturbances. To improve the performance, the
characteristics of the turbulent conditions are accounted for in the
controller. The landing trajectory is fast, direct, and does not require
hovering over the platform, as is typical of most state-of-the-art approaches.
Simulations and hardware experiments are presented to validate the robustness
of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11076</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11076</id><created>2019-09-24</created><authors><author><keyname>Zheng</keyname><forenames>Yang</forenames></author><author><keyname>Sootla</keyname><forenames>Aivar</forenames></author><author><keyname>Papachristodoulou</keyname><forenames>Antonis</forenames></author></authors><title>Block Factor-width-two Matrices and Their Applications to Semidefinite
  and Sum-of-squares Optimization</title><categories>math.OC cs.SY eess.SY</categories><comments>23 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semidefinite and sum-of-squares (SOS) optimization are fundamental
computational tools in many areas, including linear and nonlinear systems
theory. However, the scale of problems that can be addressed reliably and
efficiently is still limited. In this paper, we introduce a new notion of block
factor-width-two matrices and build a new hierarchy of inner and outer
approximations of the cone of positive semidefinite (PSD) matrices. This notion
is a block extension of the standard factor-width two matrices, and allows for
an improved inner-approximation of the PSD cone. In the context of SOS
optimization, this leads to a block extension of the scaled diagonally dominant
sum-of-squares (SDSOS) polynomials. By varying a matrix partition, the notion
of block factor-width-two matrices can balance a trade-off between the
computation scalability and solution quality for solving semidefinite and SOS
optimization. Numerical experiments on large-scale instances confirm our
theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11081</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11081</id><created>2019-09-24</created><updated>2019-09-25</updated><authors><author><keyname>Ghosh</keyname><forenames>Arnab</forenames></author><author><keyname>Zhang</keyname><forenames>Richard</forenames></author><author><keyname>Dokania</keyname><forenames>Puneet K.</forenames></author><author><keyname>Wang</keyname><forenames>Oliver</forenames></author><author><keyname>Efros</keyname><forenames>Alexei A.</forenames></author><author><keyname>Torr</keyname><forenames>Philip H. S.</forenames></author><author><keyname>Shechtman</keyname><forenames>Eli</forenames></author></authors><title>Interactive Sketch &amp; Fill: Multiclass Sketch-to-Image Translation</title><categories>cs.CV cs.LG eess.IV</categories><comments>ICCV 2019, Video Avaiable at https://youtu.be/T9xtpAMUDps</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an interactive GAN-based sketch-to-image translation method that
helps novice users create images of simple objects. As the user starts to draw
a sketch of a desired object type, the network interactively recommends
plausible completions, and shows a corresponding synthesized image to the user.
This enables a feedback loop, where the user can edit their sketch based on the
network's recommendations, visualizing both the completed shape and final
rendered image while they draw. In order to use a single trained model across a
wide array of object classes, we introduce a gating-based approach for class
conditioning, which allows us to generate distinct classes without feature
mixing, from a single generator network. Video available at our website:
https://arnabgho.github.io/iSketchNFill/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11141</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11141</id><created>2019-09-24</created><authors><author><keyname>Zhang</keyname><forenames>Yuezhou</forenames></author><author><keyname>Yang</keyname><forenames>Zhicheng</forenames></author><author><keyname>Lan</keyname><forenames>Ke</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoli</forenames></author><author><keyname>Zhang</keyname><forenames>Zhengbo</forenames></author><author><keyname>Li</keyname><forenames>Peiyao</forenames></author><author><keyname>Cao</keyname><forenames>Desen</forenames></author><author><keyname>Zheng</keyname><forenames>Jiewen</forenames></author><author><keyname>Pan</keyname><forenames>Jianli</forenames></author></authors><title>Sleep Stage Classification Using Bidirectional LSTM in Wearable
  Multi-sensor Systems</title><categories>eess.SP</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the sleep quality and architecture is essential to human
being's health, which is usually represented using multiple sleep stages. A
standard sleep stage determination requires Electroencephalography (EEG)
signals during the expensive and labor-intensive Polysomnography (PSG) test. To
overcome this inconvenience, cardiorespiratory signals are proposed for the
same purpose because of the easy and comfortable acquisition by simplified
devices. In this paper, we leverage our low-cost wearable multi-sensor system
to acquire the cardiorespiratory signals from subjects. Three novel features
are designed during the feature extraction. We then apply a Bi-directional
Recurrent Neural Network architecture with Long Short-term Memory (BLSTM) to
predict the four-class sleep stages. Our prediction accuracy is 80.25% on a
large public dataset (417 subjects), and 80.75% on our 32 enrolled subjects,
respectively. Our results outperform the previous works which either used small
data sets and had the potential over-fitting issues, or used the conventional
machine learning methods on large data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11160</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11160</id><created>2019-09-24</created><updated>2019-09-28</updated><authors><author><keyname>Aslani</keyname><forenames>Rojin</forenames></author><author><keyname>Rasti</keyname><forenames>Mehdi</forenames></author><author><keyname>Khalili</keyname><forenames>Ata</forenames></author></authors><title>Energy Efficiency Maximization Via Joint Sub-Carrier Assignment and
  Power Control for OFDMA Full Duplex Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted by IEEE Transactions on Vehicular
  Technology</comments><doi>10.1109/TVT.2019.2944909</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop an energy efficient resource allocation scheme for
orthogonal frequency division multiple access (OFDMA) networks with in-band
full-duplex (IBFD) communication between the base station and user equipments
(UEs) considering a realistic self-interference (SI) model. Our primary aim is
to maximize the system energy efficiency (EE) through a joint power control and
sub-carrier assignment in both the downlink (DL) and uplink (UL), where the
quality of service requirements of the UEs in DL and UL are guaranteed. The
formulated problem is non-convex due to the non-linear fractional objective
function and the non-convex feasible set which is generally intractable. In
order to handle this difficulty, we first use fractional programming to
transform the fractional objective function to the subtractive form. Then, by
employing Dinkelbach method, we propose an iterative algorithm in which an
inner problem is solved in each iteration. Applying majorization-minimization
approximation, we make the inner problem convex. Also, by introducing a penalty
function to handle integer sub-carrier assignment variables, we propose an
iterative algorithm for addressing the inner problem. We show that our proposed
algorithm converges to the locally optimal solution which is also demonstrated
by our simulation results. In addition, simulation results show that by
applying the IBFD capability in OFDMA networks with efficient SI cancellation
techniques, our proposed resource allocation algorithm attains a 75% increase
in the EE as compared to the half-duplex system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11167</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11167</id><created>2019-09-24</created><authors><author><keyname>Chen</keyname><forenames>Liang</forenames></author><author><keyname>Bentley</keyname><forenames>Paul</forenames></author><author><keyname>Mori</keyname><forenames>Kensaku</forenames></author><author><keyname>Misawa</keyname><forenames>Kazunari</forenames></author><author><keyname>Fujiwara</keyname><forenames>Michitaka</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Intelligent image synthesis to attack a segmentation CNN using
  adversarial learning</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning approaches based on convolutional neural networks (CNNs) have
been successful in solving a number of problems in medical imaging, including
image segmentation. In recent years, it has been shown that CNNs are vulnerable
to attacks in which the input image is perturbed by relatively small amounts of
noise so that the CNN is no longer able to perform a segmentation of the
perturbed image with sufficient accuracy. Therefore, exploring methods on how
to attack CNN-based models as well as how to defend models against attacks have
become a popular topic as this also provides insights into the performance and
generalization abilities of CNNs. However, most of the existing work assumes
unrealistic attack models, i.e. the resulting attacks were specified in
advance. In this paper, we propose a novel approach for generating adversarial
examples to attack CNN-based segmentation models for medical images. Our
approach has three key features: 1) The generated adversarial examples exhibit
anatomical variations (in form of deformations) as well as appearance
perturbations; 2) The adversarial examples attack segmentation models so that
the Dice scores decrease by a pre-specified amount; 3) The attack is not
required to be specified beforehand. We have evaluated our approach on
CNN-based approaches for the multi-organ segmentation problem in 2D CT images.
We show that the proposed approach can be used to attack different CNN-based
segmentation models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11174</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11174</id><created>2019-08-05</created><authors><author><keyname>Kemal</keyname><forenames>Juned N.</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation></author><author><keyname>Marin-Palomo</keyname><forenames>Pablo</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation></author><author><keyname>Panapakkam</keyname><forenames>Vivek</forenames><affiliation>Centre de Nanosciences et de Nanotechnologies</affiliation></author><author><keyname>Trocha</keyname><forenames>Philipp</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation></author><author><keyname>Wolf</keyname><forenames>Stefan</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation></author><author><keyname>Merghem</keyname><forenames>Kamel</forenames><affiliation>Centre de Nanosciences et de Nanotechnologies</affiliation></author><author><keyname>Lelarge</keyname><forenames>Francois</forenames><affiliation>Almae Technologies, Marcoussis, France</affiliation></author><author><keyname>Ramdane</keyname><forenames>Abderrahim</forenames><affiliation>Centre de Nanosciences et de Nanotechnologies</affiliation></author><author><keyname>Randel</keyname><forenames>Sebastian</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation></author><author><keyname>Freude</keyname><forenames>Wolfgang</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation></author><author><keyname>Koos</keyname><forenames>Christian</forenames><affiliation>Institute of Photonics and Quantum Electronics</affiliation><affiliation>Institute of Microstructure Technology</affiliation></author></authors><title>Coherent WDM transmission using quantum-dash mode-locked laser diodes as
  multi-wavelength source and local oscillator</title><categories>physics.app-ph eess.SP physics.optics</categories><doi>10.1364/OE.27.031164</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum-dash (QD) mode-locked laser diodes (MLLD) lend themselves as
chip-scale frequency comb generators for highly scalable wavelength-division
multiplexing (WDM) links in future data-center, campus-area, or metropolitan
networks. Driven by a simple DC current, the devices generate flat broadband
frequency combs, containing tens of equidistant optical tones with line
spacings of tens of GHz. Here we show that QD-MLLDs can not only be used as
multi-wavelength light sources at a WDM transmitter, but also as
multi-wavelength local oscillators (LO) for parallel coherent reception. In our
experiments, we demonstrate transmission of an aggregate data rate of 4.1
Tbit/s (23x45 GBd PDM-QPSK) over 75 km standard single-mode fiber (SSMF). To
the best of our knowledge, this represents the first demonstration of a
coherent WDM link that relies on QD-MLLD both at the transmitter and the
receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11175</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11175</id><created>2019-08-06</created><authors><author><keyname>Shao</keyname><forenames>Wenyi</forenames></author></authors><title>Advances in Microwave Near-Field Imaging: Prototypes, Systems, and
  Applications</title><categories>physics.med-ph eess.SP physics.app-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A near-field microwave imaging system attempts to reveal the presence of an
object and/or an electrical property distribution by measuring the scattered
field from many positions surrounding the object. Over the past few decades,
both the hardware and software components of a near-field microwave imaging
system technology have attracted interest throughout the world. Due to
limitations of hardware technology (unavailability of data acquisition
apparatus), experimental microwave imaging is very challenging for the
pioneers. However, Probably due to the hardware cost, most of the studies
(operating at a few GHz) were still focused on software only. The feasibility
of using microwave approaches to image different types of objects have been
tested and verified by simulations in a variety of applications. Further, work
has been conducted on improving both quantitative and qualitative algorithms to
improve simulated reconstruction results. Nowadays, benefitting from the
hardware progress and reduction of their cost, researchers are eager to pursue
real experimental validations instead of simulations, and, more unique
prototypes and commercial systems have been built for various applications.
These prototypes and systems are a result of years of dedicated work and it is
important to review the advancements in developed prototype systems. The
article will provide an overview of the many of the systems designed from
different research groups throughout the world, for applications of near-field
microwave imaging. The article further outlines challenges faced in current
microwave near-field imaging, developmental tendencies of engineers and
scientists, and the future outlook.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11177</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11177</id><created>2019-08-21</created><authors><author><keyname>L&#xe4;ngkvist</keyname><forenames>Martin</forenames></author><author><keyname>Loutfi</keyname><forenames>Amy</forenames></author><author><keyname>Rangel</keyname><forenames>Igancio</forenames></author><author><keyname>Karlsson</keyname><forenames>Johnny</forenames></author><author><keyname>Brummer</keyname><forenames>Robert Jan</forenames></author></authors><title>Using infrared gas sensors in an in-vitro dynamic gut model for
  detecting short-chain fatty-acids: Technical Report</title><categories>physics.ins-det eess.SP</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short-chain fatty acids (SCFAs), including acetate, propionate and butyrate,
are organic fatty-acids that are produced when indigested carbohydrates are
fermented in the colon by gut-bacteria. Butyrate is especially considered a
beneficial compound in relation to gut health and the maintenance of colonic
homeostasis. Little is known about butyrate production and the current
measurement methods of fecal samples are not representative and there is a
strong unmet need to measure SCFAs in-vivo to further understand their role and
effect on colonic function in human gut health and disease. The general aim of
the project is to develop a novel sensor based on infrared technology that is
capable of online detecting short chain fatty acids (SCFA; e.g. acetate,
propionate and butyrate) and other small biomolecules (e.g. ammonium) produced
in bioreactors. Whereas currently such levels of small biomolecules are usually
not detected online due to practical constraints (sampling-analysis-processing
of data), reliable online detection could significantly decrease analysis
costs. Further, it would allow to perform online quality control of the
bioreactors and allow to e.g. detect deviating values at an early stage. Hence,
one can react much faster tackling certain problems which will further improve
the quality of each experiment. Using machine learning algorithms to process
the sensor signals, the results from testing in a so-called artificial gut
setup are described in this technical report.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11186</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11186</id><created>2019-09-22</created><updated>2019-12-29</updated><authors><author><keyname>Paganin</keyname><forenames>David M.</forenames></author><author><keyname>Sales</keyname><forenames>Morten</forenames></author><author><keyname>Kadletz</keyname><forenames>Peter M.</forenames></author><author><keyname>Kockelmann</keyname><forenames>Winfried</forenames></author><author><keyname>Beltran</keyname><forenames>Mario A.</forenames></author><author><keyname>Poulsen</keyname><forenames>Henning F.</forenames></author><author><keyname>Schmidt</keyname><forenames>S&#xf8;ren</forenames></author></authors><title>Effective brilliance amplification in neutron propagation-based phase
  contrast imaging</title><categories>eess.IV physics.app-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Propagation-based neutron phase-contrast tomography was demonstrated on an
insect sample, using the ISIS pulsed spallation source. In our proof-of-concept
low-fluence experiment the tomogram with Paganin-type phase-retrieval filter
applied exhibited an effective net boost of $23\pm 1$ in the signal-to-noise
ratio as compared to an attenuation-based tomogram, implying an effective boost
in neutron brilliance of well over two orders of magnitude. The phase-retrieval
filter applies to monochromatic as well as poly-energetic neutron beams.
Expressions are provided for the optimal phase-contrast geometry as well as
conditions for the validity of the method. The underpinning theory is derived
under the assumption of the sample being composed of a single material, but
this can be generalized. The effective boost in brilliance may be employed to
give reduced acquisition time, or may instead be used to keep exposure times
fixed while improving contrast and spatial resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11191</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11191</id><created>2019-09-24</created><authors><author><keyname>Pirmagomedov</keyname><forenames>Rustam</forenames></author><author><keyname>Koucheryavy</keyname><forenames>Yevgeni</forenames></author></authors><title>IoT Technologies for Augmented Human: a Survey</title><categories>cs.NI cs.MA eess.SP</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things (IoT) technology has delivered new enablers for improving
human abilities. These enablers promise an enhanced quality of life and
professional efficiency; however, the synthesis of IoT and human augmentation
technologies has also extended IoT-related challenges far beyond the current
scope. These potential challenges associated with IoT-empowered Augmented Human
(AH) have so far not been well-investigated. Thus, this article attempts to
introduce readers to AH concept as well as summarize notable research
challenges raised by such systems, in order to facilitate reader's further
interest in this topic. The article considers emerging IoT applications for
human augmentation, devices and design principles, connectivity demands, and
security aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11199</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11199</id><created>2019-09-24</created><updated>2019-10-01</updated><authors><author><keyname>Tang</keyname><forenames>Yu</forenames></author><author><keyname>Wen</keyname><forenames>Yining</forenames></author><author><keyname>Jin</keyname><forenames>Li</forenames></author></authors><title>Security Risk Analysis of the Shorter-Queue Routing Policy for Two
  Symmetric Servers</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we study the classical shortest queue problem under the
influence of malicious attacks, which is relevant to a variety of engineering
system including transportation, manufacturing, and communications. We consider
a homogeneous Poisson arrival process of jobs and two parallel exponential
servers with symmetric service rates. A system operator route incoming jobs to
the shorter queue; if the queues are equal, the job is routed randomly. A
malicious attacker is able to intercept the operator's routing instruction and
overwrite it with a randomly generated one. The operator is able to defend
individual jobs to ensure correct routing. Both attacking and defending induce
technological costs. The attacker's (resp. operator's) decision is the
probability of attacking (resp. defending) the routing of each job. We first
quantify the queuing cost for given strategy profiles by deriving a theoretical
upper bound for the cost. Then, we formulate a non-zero-sum attacker-defender
game, characterize the equilibria in multiple regimes, and quantify the
security risk. We find that the attacker's best strategy is either to attack
all jobs or not to attack, and the defender's strategy is strongly influenced
by the arrival rate of jobs. Finally, as a benchmark, we compare the security
risks of the feedback-controlled system to a corresponding open-loop system
with Bernoulli routing. We show that the shorter-queue policy has a higher
(resp. lower) security risk than the Bernoulli policy if the demand is lower
(resp. higher) than the service rate of one server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11200</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11200</id><created>2019-09-24</created><authors><author><keyname>Shi</keyname><forenames>Yanpei</forenames></author><author><keyname>Huang</keyname><forenames>Qiang</forenames></author><author><keyname>Hain</keyname><forenames>Thomas</forenames></author></authors><title>Improving Robustness In Speaker Identification Using A Two-Stage
  Attention Model</title><categories>eess.AS cs.AI cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel framework to tackle speaker recognition using a
two-stage attention model is proposed. In recent years, the use of deep neural
networks, such as time delay neural network (TDNN), and attention model have
boosted speaker recognition performance. However, it is still a challenging
task to tackle speaker recognition in severe acoustic environments. To build a
robust speaker recognition system against noise, we employ a two-stage
attention model and combine it with a TDNN model. In this framework, the
attention mechanism is used in two aspects: embedding space and temporal space.
The embedding attention model built in embedding space is to highlight the
importance of each embedding element by weighting them using self attention.
The frame attention model built in temporal space aims to find which frames are
significant for speaker recognition. To evaluate the effectiveness and
robustness of our approach, we use the TIMIT dataset and test our approach in
the condition of five kinds of noise and different signal-noise-ratios (SNRs).
In comparison with three strong baselines, CNN, TDNN and TDNN+attention, the
experimental results show that the use of our approach outperforms them in
different conditions. The correct recognition rate obtained using our approach
can still reach 49.1%, better than any baselines, even if the noise is Gaussian
white Noise and the SNR is 0dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11212</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11212</id><created>2019-09-24</created><authors><author><keyname>Ianni</keyname><forenames>Julianna D.</forenames></author><author><keyname>Soans</keyname><forenames>Rajath E.</forenames></author><author><keyname>Sankarapandian</keyname><forenames>Sivaramakrishnan</forenames></author><author><keyname>Chamarthi</keyname><forenames>Ramachandra Vikas</forenames></author><author><keyname>Ayyagari</keyname><forenames>Devi</forenames></author><author><keyname>Olsen</keyname><forenames>Thomas G.</forenames></author><author><keyname>Bonham</keyname><forenames>Michael J.</forenames></author><author><keyname>Stavish</keyname><forenames>Coleman C.</forenames></author><author><keyname>Motaparthi</keyname><forenames>Kiran</forenames></author><author><keyname>Cockerell</keyname><forenames>Clay J.</forenames></author><author><keyname>Feeser</keyname><forenames>Theresa A.</forenames></author><author><keyname>Lee</keyname><forenames>Jason B.</forenames></author></authors><title>Augmenting the Pathology Lab: An Intelligent Whole Slide Image
  Classification System for the Real World</title><categories>eess.IV cs.CV cs.LG q-bio.QM q-bio.TO</categories><comments>23 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard of care diagnostic procedure for suspected skin cancer is
microscopic examination of hematoxylin \&amp; eosin stained tissue by a
pathologist. Areas of high inter-pathologist discordance and rising biopsy
rates necessitate higher efficiency and diagnostic reproducibility. We present
and validate a deep learning system which classifies digitized dermatopathology
slides into 4 categories. The system is developed using 5,070 images from a
single lab, and tested on an uncurated set of 13,537 images from 3 test labs,
using whole slide scanners manufactured by 3 different vendors. The system's
use of deep-learning-based confidence scoring as a criterion to consider the
result as accurate yields an accuracy of up to 98\%, and makes it adoptable in
a real-world setting. Without confidence scoring, the system achieved an
accuracy of 78\%. We anticipate that our deep learning system will serve as a
foundation enabling faster diagnosis of skin cancer, identification of cases
for specialist review, and targeted diagnostic classifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11220</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11220</id><created>2019-09-24</created><authors><author><keyname>Essiambre</keyname><forenames>Ren&#xe9;-Jean</forenames></author><author><keyname>Ryf</keyname><forenames>Roland</forenames></author><author><keyname>van der Heide</keyname><forenames>Sjoerd</forenames></author><author><keyname>Bonetti</keyname><forenames>Juan I.</forenames></author><author><keyname>Huang</keyname><forenames>Hanzi</forenames></author><author><keyname>Kodialam</keyname><forenames>Murali</forenames></author><author><keyname>Garc&#xed;a-G&#xf3;mez</keyname><forenames>Francisco Javier</forenames></author><author><keyname>Burrows</keyname><forenames>Ellsworth C.</forenames></author><author><keyname>Alvarado-Zacarias</keyname><forenames>Juan C.</forenames></author><author><keyname>Amezcua-Correa</keyname><forenames>Rodrigo</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Fontaine</keyname><forenames>Nicolas K.</forenames></author><author><keyname>Chen</keyname><forenames>Haoshuo</forenames></author></authors><title>First Transmission of a 12D Format Across 3 Coupled Spatial Modes of a
  3-Core Coupled-Core Fiber at a Spectral Efficiency of 4 bits/s/Hz</title><categories>eess.SP</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the first transmission of a new twelve-dimensional modulation
format over a three-core coupled-core multicore fiber. The format occupies a
single time slot spread across all three linearly-coupled spatial modes and
shows improved MI and GMI after transmission compared to PDM-QPSK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11236</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11236</id><created>2019-09-24</created><updated>2020-02-05</updated><authors><author><keyname>Duisterhof</keyname><forenames>Bardienus P.</forenames></author><author><keyname>Krishnan</keyname><forenames>Srivatsan</forenames></author><author><keyname>Cruz</keyname><forenames>Jonathan J.</forenames></author><author><keyname>Banbury</keyname><forenames>Colby R.</forenames></author><author><keyname>Fu</keyname><forenames>William</forenames></author><author><keyname>Faust</keyname><forenames>Aleksandra</forenames></author><author><keyname>de Croon</keyname><forenames>Guido C. H. E.</forenames></author><author><keyname>Reddi</keyname><forenames>Vijay Janapa</forenames></author></authors><title>Learning to Seek: Deep Reinforcement Learning for Phototaxis of a Nano
  Drone in an Obstacle Field</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nano drones are uniquely equipped for fully autonomous applications due to
their agility, low cost, and small size. However, their constrained form factor
limits flight time, sensor payload, and compute capability. While visual
servoing of nano drones can achieve complex tasks, state of the art solutions
have significant impact on endurance and cost. The primary goal of our work is
to demonstrate phototaxis in an obstacle field, by adding only a lightweight
and low-cost light sensor to a nano drone. We deploy a deep reinforcement
learning model, capable of direct paths even with noisy sensor readings. By
carefully designing the network input, we feed features relevant to the agent
in finding the source, while reducing computational cost and enabling inference
up to 100 Hz onboard the nano drone. We verify our approach with simulation and
in-field testing on a Bitcraze CrazyFlie, achieving 94% success rate in
cluttered and randomized test environments. The policy demonstrates efficient
light seeking by reaching the goal in simulation in 65% fewer steps and with
60% shorter paths, compared to a baseline random walker algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11269</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11269</id><created>2019-09-24</created><authors><author><keyname>Seong</keyname><forenames>Si-Baek</forenames></author><author><keyname>Park</keyname><forenames>Hae-Jeong</forenames></author></authors><title>Automated identification of neural cells in the multi-photon images
  using deep-neural networks</title><categories>eess.IV cs.LG cs.SY eess.SY q-bio.NC</categories><comments>8 pages, 4 figures and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advancement of the neuroscientific imaging techniques has produced an
unprecedented size of neural cell imaging data, which calls for automated
processing. In particular, identification of cells from two photon images
demands segmentation of neural cells out of various materials and
classification of the segmented cells according to their cell types. To
automatically segment neural cells, we used U-Net model, followed by
classification of excitatory and inhibitory neurons and glia cells using a
transfer learning technique. For transfer learning, we tested three public
models of resnet18, resnet50 and inceptionv3, after replacing the fully
connected layer with that for three classes. The best classification
performance was found for the model with inceptionv3. The proposed application
of deep learning technique is expected to provide a critical way to cell
identification in the era of big neuroscience data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11281</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11281</id><created>2019-09-20</created><authors><author><keyname>Cisneros-Velarde</keyname><forenames>Pedro</forenames></author><author><keyname>Friedkin</keyname><forenames>Noah E.</forenames></author><author><keyname>Proskurnikov</keyname><forenames>Anton V.</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Structural Balance via Gradient Flows over Signed Graphs</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural balance is a classic property of signed graphs satisfying Heider's
seminal axioms. Mathematical sociologists have studied balance theory since its
inception in the 1040s. Recent research has focused on the development of
dynamic models explaining the emergence of structural balance. In this paper,
we introduce a novel class of parsimonious dynamic models for structural
balance based on an interpersonal influence process. Our proposed models are
gradient flows of an energy function, called the dissonance function, which
captures the cognitive dissonance arising from violations of Heider's axioms.
Thus, we build a new connection with the literature on energy landscape
minimization. This gradient flow characterization allows us to study the
transient and asymptotic behaviors of our model. We provide mathematical and
numerical results describing the critical points of the dissonance function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11286</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11286</id><created>2019-09-25</created><updated>2020-02-24</updated><authors><author><keyname>Wang</keyname><forenames>Ze</forenames></author><author><keyname>Cheng</keyname><forenames>Xiuyuan</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Qiu</keyname><forenames>Qiang</forenames></author></authors><title>Stochastic Conditional Generative Networks with Basis Decomposition</title><categories>cs.CV cs.LG eess.IV</categories><comments>Published as a conference paper at ICLR 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While generative adversarial networks (GANs) have revolutionized machine
learning, a number of open questions remain to fully understand them and
exploit their power. One of these questions is how to efficiently achieve
proper diversity and sampling of the multi-mode data space. To address this, we
introduce BasisGAN, a stochastic conditional multi-mode image generator. By
exploiting the observation that a convolutional filter can be well approximated
as a linear combination of a small set of basis elements, we learn a
plug-and-played basis generator to stochastically generate basis elements, with
just a few hundred of parameters, to fully embed stochasticity into
convolutional filters. By sampling basis elements instead of filters, we
dramatically reduce the cost of modeling the parameter space with no sacrifice
on either image diversity or fidelity. To illustrate this proposed
plug-and-play framework, we construct variants of BasisGAN based on
state-of-the-art conditional image generation networks, and train the networks
by simply plugging in a basis generator, without additional auxiliary
components, hyperparameters, or training objectives. The experimental success
is complemented with theoretical results indicating how the perturbations
introduced by the proposed sampling of basis elements can propagate to the
appearance of generated images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11289</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11289</id><created>2019-09-25</created><authors><author><keyname>Heisler</keyname><forenames>Morgan</forenames></author><author><keyname>Chan</keyname><forenames>Forson</forenames></author><author><keyname>Mammo</keyname><forenames>Zaid</forenames></author><author><keyname>Balaratnasingam</keyname><forenames>Chandrakumar</forenames></author><author><keyname>Prentasic</keyname><forenames>Pavle</forenames></author><author><keyname>Docherty</keyname><forenames>Gavin</forenames></author><author><keyname>Ju</keyname><forenames>MyeongJin</forenames></author><author><keyname>Rajapakse</keyname><forenames>Sanjeeva</forenames></author><author><keyname>Lee</keyname><forenames>Sieun</forenames></author><author><keyname>Merkur</keyname><forenames>Andrew</forenames></author><author><keyname>Kirker</keyname><forenames>Andrew</forenames></author><author><keyname>Albiani</keyname><forenames>David</forenames></author><author><keyname>Maberley</keyname><forenames>David</forenames></author><author><keyname>Freund</keyname><forenames>K. Bailey</forenames></author><author><keyname>Beg</keyname><forenames>Mirza Faisal</forenames></author><author><keyname>Loncaric</keyname><forenames>Sven</forenames></author><author><keyname>Sarunic</keyname><forenames>Marinko V.</forenames></author><author><keyname>Navajas</keyname><forenames>Eduardo V.</forenames></author></authors><title>Deep learning vessel segmentation and quantification of the foveal
  avascular zone using commercial and prototype OCT-A platforms</title><categories>eess.IV cs.CV cs.LG</categories><comments>22 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Automatic quantification of perifoveal vessel densities in optical coherence
tomography angiography (OCT-A) images face challenges such as variable intra-
and inter-image signal to noise ratios, projection artefacts from outer
vasculature layers, and motion artefacts. This study demonstrates the utility
of deep neural networks for automatic quantification of foveal avascular zone
(FAZ) parameters and perifoveal vessel density of OCT-A images in healthy and
diabetic eyes. OCT-A images of the foveal region were acquired using three
OCT-A systems: a 1060nm Swept Source (SS)-OCT prototype, RTVue XR Avanti
(Optovue Inc., Fremont, CA), and the ZEISS Angioplex (Carl Zeiss Meditec,
Dublin, CA). Automated segmentation was then performed using a deep neural
network. Four FAZ morphometric parameters (area, min/max diameter, and
eccentricity) and perifoveal vessel density were used as outcome measures. The
accuracy, sensitivity and specificity of the DNN vessel segmentations were
comparable across all three device platforms. No significant difference between
the means of the measurements from automated and manual segmentations were
found for any of the outcome measures on any system. The intraclass correlation
coefficient (ICC) was also good (&gt; 0.51) for all measurements. Automated deep
learning vessel segmentation of OCT-A may be suitable for both commercial and
research purposes for better quantification of the retinal circulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11305</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11305</id><created>2019-09-25</created><authors><author><keyname>Esswie</keyname><forenames>Ali A.</forenames></author><author><keyname>Pedersen</keyname><forenames>Klaus I.</forenames></author></authors><title>On the Ultra-Reliable and Low-Latency Communications in Flexible TDD/FDD
  5G Networks</title><categories>eess.SP</categories><journal-ref>IEEE Consumer Communications &amp; Networking Conference, 2020</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ultra-reliable and low-latency communication (URLLC) is the key driver of
the current 5G new radio standardization. URLLC encompasses sporadic and
small-payload transmissions that should be delivered within extremely tight
radio latency and reliability bounds, i.e., a radio latency of 1 ms with
99.999% success probability. However, such URLLC targets are further
challenging in the 5G dynamic time division duplexing (TDD) systems, due to the
switching between the uplink and downlink transmission opportunities and the
additional inter-cell cross-link interference (CLI). This paper presents a
system level analysis of the URLLC outage performance within the 5G new radio
flexible TDD systems. Specifically, we study the feasibility of the URLLC
outage targets compared to the case with the 5G frequency division duplexing
(FDD), and with numerous 5G design variants. The presented results therefore
offer valuable observations on the URLLC outage performance in such
deployments, and hence, introducing the state-of-the-art flexible-FDD
technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11306</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11306</id><created>2019-09-25</created><authors><author><keyname>Liu</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author></authors><title>Blind Channel Estimation and Data Detection with Unknown Modulation and
  Coding Scheme</title><categories>cs.IT eess.SP math.IT</categories><comments>45 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a complete blind receiver approach in an unknown
multipath fading channel, which has multiple tasks including blind channel
estimation, noise power estimation, modulation classification, channel coding
recognition, and data detection. Each of these tasks has been sufficiently
studied in the literature. However, to the best of our knowledge, this overall
problem has not been investigated previously. This paper is the first attempt
to address this overall problem jointly. We propose a complete blind receiver
approach that jointly estimates the unknown channel state information and noise
power, recognizes the unknown modulation and coding scheme, detects the data of
interest, and thus named BERD receiver. Another merit of the proposed BERD
receiver is that it can be implemented for both a single receiver and multiple
receivers, which ensures successful estimation, recognition, and detection for
such an extremely difficult problem. In addition, numerical results show the
performance of the proposed receiver in three folds: a) the BERD receiver
outperforms the linear minimum mean squared error (LMMSE) pilot-based channel
estimator by over 3.5 dB at the MSE of 0.01; b) the correct modulation/coding
recognition performance of the BERD receiver is within 0.3 dB as close to the
recognition benchmark when the perfect channel state information (CSI) is
available; c) the BERD receiver is within 0.5 dB at the bit error rate of 0.001
compared to the benchmark when the modulation, the channel coding, and the CSI
are perfectly known. Finally, the BERD receiver finds many applications in both
civilian and military scenarios, such as the interference cancelation in
spectrum sharing, real-time signal interception, and processing in electronic
warfare operations, automatic recognition of a detect signal in
software-defined radio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11308</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11308</id><created>2019-09-25</created><authors><author><keyname>Wu</keyname><forenames>Chunpeng</forenames></author><author><keyname>Wen</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Yiran</forenames></author><author><keyname>Li</keyname><forenames>Hai</forenames></author></authors><title>Conditional Transferring Features: Scaling GANs to Thousands of Classes
  with 30% Less High-quality Data for Training</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial network (GAN) has greatly improved the quality of
unsupervised image generation. Previous GAN-based methods often require a large
amount of high-quality training data while producing a small number (e.g.,
tens) of classes. This work aims to scale up GANs to thousands of classes
meanwhile reducing the use of high-quality data in training. We propose an
image generation method based on conditional transferring features, which can
capture pixel-level semantic changes when transforming low-quality images into
high-quality ones. Moreover, self-supervision learning is integrated into our
GAN architecture to provide more label-free semantic supervisory information
observed from the training data. As such, training our GAN architecture
requires much fewer high-quality images with a small number of additional
low-quality images. The experiments on CIFAR-10 and STL-10 show that even
removing 30% high-quality images from the training set, our method can still
outperform previous ones. The scalability on object classes has been
experimentally validated: our method with 30% fewer high-quality images obtains
the best quality in generating 1,000 ImageNet classes, as well as generating
all 3,755 classes of CASIA-HWDB1.0 Chinese handwriting characters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11314</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11314</id><created>2019-09-25</created><authors><author><keyname>Li</keyname><forenames>Hongyu</forenames></author><author><keyname>Liu</keyname><forenames>Rang</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Qian</forenames></author></authors><title>IRS-Enhanced Wideband MU-MISO-OFDM Communication Systems</title><categories>eess.SP</categories><comments>6 pages, 5 figures, submit to WCNC 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is considered as an enabling technology
for future wireless communication systems since it can intelligently change the
wireless environment to improve the communication performance. In this paper,
an IRS-enhanced wideband multiuser multi-input single-output orthogonal
frequency division multiplexing (MU-MISO-OFDM) system is investigated. We aim
to jointly design the transmit beamformer and the reflection of IRS to maximize
the average sum-rate over all subcarriers. With the aid of the relationship
between sum-rate maximization and mean square error (MSE) minimization, an
efficient joint beamformer and IRS design algorithm is developed. Simulation
results illustrate that the proposed algorithm can offer significant average
sum-rate enhancement, which confirms the effectiveness of the use of the IRS
for wideband wireless communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11315</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11315</id><created>2019-09-25</created><authors><author><keyname>Chowdhury</keyname><forenames>Mostafa Zaman</forenames></author><author><keyname>Shahjalal</keyname><forenames>Md.</forenames></author><author><keyname>Ahmed</keyname><forenames>Shakil</forenames></author><author><keyname>Jang</keyname><forenames>Yeong Min</forenames></author></authors><title>6G Wireless Communication Systems: Applications, Requirements,
  Technologies, Challenges, and Research Directions</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifth-generation (5G) communication, which has many more features than
fourth-generation communication, will be officially launched very soon. A new
paradigm of wireless communication, the sixth-generation (6G) system, with the
full support of artificial intelligence is expected to be deployed between 2027
and 2030. In beyond 5G, there are some fundamental issues, which need to be
addressed are higher system capacity, higher data rate, lower latency, and
improved quality of service (QoS) compared to 5G system. This paper presents
the vision of future 6G wireless communication and its network architecture. We
discuss the emerging technologies such as artificial intelligence, terahertz
communications, optical wireless technology, free space optic network,
blockchain, three-dimensional networking, quantum communications, unmanned
aerial vehicle, cell-free communications, integration of wireless information
and energy transfer, integration of sensing and communication, integration of
access-backhaul networks, dynamic network slicing, holographic beamforming, and
big data analytics that can assist the 6G architecture development in
guaranteeing the QoS. We present the expected applications with the
requirements and the possible technologies for 6G communication. We also
outline the possible challenges and research directions to reach this goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11321</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11321</id><created>2019-09-25</created><authors><author><keyname>Quan</keyname><forenames>Chun</forenames></author><author><keyname>Jang</keyname><forenames>Jun-Gi</forenames></author><author><keyname>Lee</keyname><forenames>Hyun Dong</forenames></author><author><keyname>Kang</keyname><forenames>U</forenames></author></authors><title>FALCON: Fast and Lightweight Convolution for Compressing and
  Accelerating CNN</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can we efficiently compress Convolutional Neural Networks (CNN) while
retaining their accuracy on classification tasks? A promising direction is
based on depthwise separable convolution which replaces a standard convolution
with a depthwise convolution and a pointwise convolution. However, previous
works based on depthwise separable convolution are limited since 1) they are
mostly heuristic approaches without a precise understanding of their relations
to standard convolution, and 2) their accuracies do not match that of the
standard convolution. In this paper, we propose FALCON, an accurate and
lightweight method for compressing CNN. FALCON is derived by interpreting
existing convolution methods based on depthwise separable convolution using
EHP, our proposed mathematical formulation to approximate the standard
convolution kernel. Such interpretation leads to developing a generalized
version rank-k FALCON which further improves the accuracy while sacrificing a
bit of compression and computation reduction rates. In addition, we propose
FALCON-branch by fitting FALCON into the previous state-of-the-art convolution
unit ShuffleUnitV2 which gives even better accuracy. Experiments show that
FALCON and FALCON-branch outperform 1) existing methods based on depthwise
separable convolution and 2) standard CNN models by up to 8x compression and 8x
computation reduction while ensuring similar accuracy. We also demonstrate that
rank-k FALCON provides even better accuracy than standard convolution in many
cases, while using a smaller number of parameters and floating-point
operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11358</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11358</id><created>2019-09-25</created><authors><author><keyname>Kumru</keyname><forenames>Murat</forenames></author><author><keyname>&#xd6;zkan</keyname><forenames>Emre</forenames></author></authors><title>Three-Dimensional Extended Object Tracking and Shape Learning Using
  Gaussian Processes</title><categories>eess.SP</categories><comments>13 pages, 13 figures, submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we investigate the problem of tracking objects with unknown
shapes using three-dimensional (3D) point cloud data. We propose a Gaussian
process-based model to jointly estimate object kinematics, including position,
velocity and orientation, together with the shape of the object in an online
fashion. We describe the unknown shape by a radial function in 3D, and induce a
correlation structure via a Gaussian process. Furthermore, we propose an
efficient algorithm to reduce the computational complexity of working with 3D
data. This is accomplished by casting the tracking problem into projection
planes which are attached to the object's local frame. The proposed methods
provide an analytical expression for the object shape together with confidence
intervals. The confidence intervals, which quantify the uncertainty in the
shape estimate, can later be used for solving the gating and association
problems inherent in object tracking. The performance of the methods is
demonstrated both on simulated and real data. The results are compared with an
existing random matrix model, which is commonly used for extended object
tracking in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11362</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11362</id><created>2019-09-25</created><authors><author><keyname>Wu</keyname><forenames>Xiaolong</forenames></author><author><keyname>Pradalier</keyname><forenames>Cedric</forenames></author></authors><title>Robust Semi-Direct Monocular Visual Odometry Using Edge and
  Illumination-Robust Cost</title><categories>cs.RO cs.CV eess.IV</categories><comments>6 pages, 6 figures, 2 tables, submitted to icra2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a monocular semi-direct visual odometry framework,
which is capable of exploiting the best attributes of edge features and local
photometric information for illumination-robust camera motion estimation and
scene reconstruction. In the tracking layer, the edge alignment error and image
gradient error are jointly optimized through a convergence-preserved
reweighting strategy, which not only preserves the property of illumination
invariance but also leads to larger convergence basin and higher tracking
accuracy compared with individual approaches. In the mapping layer, a fast
probabilistic 1D search strategy is proposed to locate the best photometrically
matched point along all geometrically possible edges, which enables real-time
edge point correspondence generation using merely high-frequency components of
the image. The resultant reprojection error is then used to substitute edge
alignment error for joint optimization in local bundle adjustment, avoiding the
partial observability issue of monocular edge mapping as well as improving the
stability of optimization. We present extensive analysis and evaluation of our
proposed system on synthetic and real-world benchmark datasets under the
influence of illumination changes and large camera motions, where our proposed
system outperforms current state-of-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11374</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11374</id><created>2019-09-25</created><authors><author><keyname>Nygate</keyname><forenames>Yoav N.</forenames></author><author><keyname>Levi</keyname><forenames>Mattan</forenames></author><author><keyname>Mirsky</keyname><forenames>Simcha K.</forenames></author><author><keyname>Turko</keyname><forenames>Nir A.</forenames></author><author><keyname>Rubin</keyname><forenames>Moran</forenames></author><author><keyname>Barnea</keyname><forenames>Itay</forenames></author><author><keyname>Dardikman-Yoffe</keyname><forenames>Gili</forenames></author><author><keyname>Shalev</keyname><forenames>Alon</forenames></author><author><keyname>Shaked</keyname><forenames>Natan T.</forenames></author></authors><title>HoloStain: Holographic virtual staining of individual biological cells</title><categories>physics.bio-ph eess.IV</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many medical and biological protocols for analyzing individual biological
cells involve morphological evaluation based on cell staining, designed to
enhance imaging contrast and enable clinicians and biologists to differentiate
between various cell organelles. However, cell staining is not always allowed
in certain medical procedures. In other cases, staining may be time consuming
or expensive to implement. Here, we present a new deep-learning approach,
called HoloStain, which converts images of isolated biological cells acquired
without staining by holographic microscopy to their virtually stained images.
We demonstrate this approach for human sperm cells, as there is a
well-established protocol and global standardization for characterizing the
morphology of stained human sperm cells for fertility evaluation, but, on the
other hand, staining might be cytotoxic and thus is not allowed during human in
vitro fertilization (IVF). We use deep convolutional Generative Adversarial
Networks (DCGANs) with training that is based on both the quantitative phase
images and two gradient phase images, all extracted from the digital holograms
of the stain-free cells, with the ground truth of bright-field images of the
same cells that subsequently underwent chemical staining. To validate the
quality of our virtual staining approach, an experienced embryologist analyzed
the unstained cells, the virtually stained cells, and the chemically stained
sperm cells several times in a blinded and randomized manner. We obtained a
5-fold recall (sensitivity) improvement in the analysis results. With the
introduction of simple holographic imaging methods in clinical settings, the
proposed method has a great potential to become a common practice in human IVF
procedures, as well as to significantly simplify and facilitate other cell
analyses and techniques such as imaging flow cytometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11379</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11379</id><created>2019-09-25</created><authors><author><keyname>Liu</keyname><forenames>Zilong</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author><author><keyname>Mheich</keyname><forenames>Zeina</forenames></author></authors><title>Power-Imbalanced Low-Density Signatures (LDS) From Eisenstein Numbers</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a special case of sparse code multiple access (SCMA), low-density
signatures based code-division multiple access (LDS-CDMA) was widely believed
to have worse error rate performance compared to SCMA. With the aid of
Eisenstein numbers, we present a novel class of LDS which can achieve error
rate performances comparable to that of SCMA in Rayleigh fading channels and
better performances in Gaussian channels. This is achieved by designing
power-imbalanced LDS such that variation of user powers can be seen both in
every chip window and the entire sequence window. As LDS-CDMA is more flexible
in terms of its backwards compatibility, our proposed LDS are a promising
sequence candidate for dynamic machine-type networks serving a wide range of
communication devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11391</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11391</id><created>2019-09-25</created><authors><author><keyname>Fujii</keyname><forenames>Kazuki</forenames></author><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Baba</keyname><forenames>Yukino</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>HumanGAN: generative adversarial network with human-based discriminator
  and its evaluation in speech perception modeling</title><categories>cs.SD cs.NE eess.AS</categories><comments>Submitted to IEEE ICASSP 2020</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose the HumanGAN, a generative adversarial network (GAN) incorporating
human perception as a discriminator. A basic GAN trains a generator to
represent a real-data distribution by fooling the discriminator that
distinguishes real and generated data. Therefore, the basic GAN cannot
represent the outside of a real-data distribution. In the case of speech
perception, humans can recognize not only human voices but also processed
(i.e., a non-existent human) voices as human voice. Such a human-acceptable
distribution is typically wider than a real-data one and cannot be modeled by
the basic GAN. To model the human-acceptable distribution, we formulate a
backpropagation-based generator training algorithm by regarding human
perception as a black-boxed discriminator. The training efficiently iterates
generator training by using a computer and discrimination by crowdsourcing. We
evaluate our HumanGAN in speech naturalness modeling and demonstrate that it
can represent a human-acceptable distribution that is wider than a real-data
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11430</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11430</id><created>2019-09-25</created><updated>2019-10-28</updated><authors><author><keyname>Cheng</keyname><forenames>Qiao</forenames></author><author><keyname>Fang</keyname><forenames>Meiyuan</forenames></author><author><keyname>Han</keyname><forenames>Yaqian</forenames></author><author><keyname>Huang</keyname><forenames>Jin</forenames></author><author><keyname>Duan</keyname><forenames>Yitao</forenames></author></authors><title>Breaking the Data Barrier: Towards Robust Speech Translation via
  Adversarial Stability Training</title><categories>cs.CL eess.AS</categories><comments>Accepted at the 16th International Workshop on Spoken Language
  Translation (IWSLT 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a pipeline speech translation system, automatic speech recognition (ASR)
system will transmit errors in recognition to the downstream machine
translation (MT) system. A standard machine translation system is usually
trained on parallel corpus composed of clean text and will perform poorly on
text with recognition noise, a gap well known in speech translation community.
In this paper, we propose a training architecture which aims at making a neural
machine translation model more robust against speech recognition errors. Our
approach addresses the encoder and the decoder simultaneously using adversarial
learning and data augmentation, respectively. Experimental results on IWSLT2018
speech translation task show that our approach can bridge the gap between the
ASR output and the MT input, outperforms the baseline by up to 2.83 BLEU on
noisy ASR output, while maintaining close performance on clean text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11451</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11451</id><created>2019-09-25</created><authors><author><keyname>Iwata</keyname><forenames>Geoffrey Z.</forenames></author><author><keyname>Hu</keyname><forenames>Yinan</forenames></author><author><keyname>Sander</keyname><forenames>Tilmann</forenames></author><author><keyname>Muthuraman</keyname><forenames>Muthuraman</forenames></author><author><keyname>Chirumamilla</keyname><forenames>Venkata Chaitanya</forenames></author><author><keyname>Groppa</keyname><forenames>Sergiu</forenames></author><author><keyname>Budker</keyname><forenames>Dmitry</forenames></author><author><keyname>Wickenbrock</keyname><forenames>Arne</forenames></author></authors><title>Biomagnetic signals recorded during transcranial magnetic stimulation
  (TMS)-evoked peripheral muscular activity</title><categories>q-bio.NC eess.SP physics.bio-ph</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transcranial magnetic stimulation (TMS) has widespread clinical applications
from diagnosis to treatment approaches. We combined TMS with non-contact
magnetic detection of TMS-evoked muscle activity in peripheral limbs to explore
a new diagnostic modality that enhances the utility of TMS as a clinical tool
by leveraging technological advances in magnetometry. We recorded measurements
inside of a hospital using an array of optically pumped magnetometers (OPMs)
inside a portable shield that encompasses only the forearm and hand of the
subject. We present magnetomyograms (MMG)s of TMS-evoked movement in a human
hand, together with a simultaneous surface electromyograph (EMG) and
electroencephalograph (EEG) data. The biomagnetic signals recorded in the MMG
provides detailed spatial and temporal information that is complementary to
that of the electric signal channels. Moreover, we identify features in the
magnetic recording beyond that of the EMG, at time points which we further
analyze in the EEG. This system demonstrates the value of biomagnetic signals
in TMS-based clinical approaches and widens its availability and practical
potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11479</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11479</id><created>2019-09-25</created><authors><author><keyname>van Garderen</keyname><forenames>Karin</forenames></author><author><keyname>van der Voort</keyname><forenames>Sebastian</forenames></author><author><keyname>Incekara</keyname><forenames>Fatih</forenames></author><author><keyname>Smits</keyname><forenames>Marion</forenames></author><author><keyname>Klein</keyname><forenames>Stefan</forenames></author></authors><title>Towards continuous learning for glioma segmentation with elastic weight
  consolidation</title><categories>eess.IV cs.CV</categories><report-no>MIDL/2019/ExtendedAbstract/Hkx_ry0NcN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  When finetuning a convolutional neural network (CNN) on data from a new
domain, catastrophic forgetting will reduce performance on the original
training data. Elastic Weight Consolidation (EWC) is a recent technique to
prevent this, which we evaluated while training and re-training a CNN to
segment glioma on two different datasets. The network was trained on the public
BraTS dataset and finetuned on an in-house dataset with non-enhancing low-grade
glioma. EWC was found to decrease catastrophic forgetting in this case, but was
also found to restrict adaptation to the new domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11497</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11497</id><created>2019-09-25</created><authors><author><keyname>Coffman</keyname><forenames>Austin</forenames></author><author><keyname>Cammardella</keyname><forenames>Neil</forenames></author><author><keyname>Barooah</keyname><forenames>Prabir</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author></authors><title>Aggregate capacity of TCLs with cycling constraints</title><categories>eess.SY cs.SY</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A flexible load can vary its power consumption to perform grid support
services. This flexibility is naturally limited by the Quality of Service (QoS)
requirements at the load. A widely examined class of flexible loads is
Thermostatically Controlled Loads (TCLs), which include air conditioners, water
heaters, and refrigerators. A TCL is designed to maintain a temperature within
a preset band, and the actuation to achieve this is on/off. Temperature,
cycling rate, and the energy bill are three main QoS metrics: exceeding the
temperature limits, frequent cycling between on and off, and a high energy bill
must be avoided.
  How the temperature constraint affects the capacity of an ensemble of TCLs to
provide grid support is a well studied problem. However, how the cycling
constraint effects the capacity is often neglected. In this work we present a
characterization of the capacity of a collection of TCLs that takes into
account not only temperature, but also cycling and energy constraints. Our
characterization of capacity is consistent with its most practical utility: a
grid authority can use this characterization to plan a reference signal that
the TCLs can track without violating any of their QoS constraints.
Additionally, the proposed characterization is independent of the algorithm
used to coordinate the TCLs (to provide grid support) and leads to a convex and
feasible optimization problem for the grid authority's reference planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11498</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11498</id><created>2019-09-25</created><updated>2019-09-27</updated><authors><author><keyname>Fu</keyname><forenames>Hao</forenames></author><author><keyname>Bian</keyname><forenames>Liheng</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author></authors><title>Non-imaging single-pixel sensing with optimized binary modulation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conventional high-level sensing techniques require high-fidelity images
as input to extract target features, which are produced by either complex
imaging hardware or high-complexity reconstruction algorithms. In this letter,
we propose single-pixel sensing (SPS) that performs high-level sensing directly
from coupled measurements of a single-pixel detector, without the conventional
image acquisition and reconstruction process. The technique consists of three
steps including binary light modulation that can be physically implemented at
$\sim$22kHz, single-pixel coupled detection owning wide working spectrum and
high signal-to-noise ratio, and end-to-end deep-learning based sensing that
reduces both hardware and software complexity. Besides, the binary modulation
is trained and optimized together with the sensing network, which ensures least
required measurements and optimal sensing accuracy. The effectiveness of SPS is
demonstrated on the classification task of handwritten MNIST dataset, and
96.68% classification accuracy at $\sim$1kHz is achieved. The reported
single-pixel sensing technique is a novel framework for highly efficient
machine intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11504</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11504</id><created>2019-09-25</created><authors><author><keyname>Yurt</keyname><forenames>Mahmut</forenames></author><author><keyname>Dar</keyname><forenames>Salman Ul Hassan</forenames></author><author><keyname>Erdem</keyname><forenames>Aykut</forenames></author><author><keyname>Erdem</keyname><forenames>Erkut</forenames></author><author><keyname>&#xc7;ukur</keyname><forenames>Tolga</forenames></author></authors><title>mustGAN: Multi-Stream Generative Adversarial Networks for MR Image
  Synthesis</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-contrast MRI protocols increase the level of morphological information
available for diagnosis. Yet, the number and quality of contrasts is limited in
practice by various factors including scan time and patient motion. Synthesis
of missing or corrupted contrasts can alleviate this limitation to improve
clinical utility. Common approaches for multi-contrast MRI involve either
one-to-one and many-to-one synthesis methods. One-to-one methods take as input
a single source contrast, and they learn a latent representation sensitive to
unique features of the source. Meanwhile, many-to-one methods receive multiple
distinct sources, and they learn a shared latent representation more sensitive
to common features across sources. For enhanced image synthesis, here we
propose a multi-stream approach that aggregates information across multiple
source images via a mixture of multiple one-to-one streams and a joint
many-to-one stream. The shared feature maps generated in the many-to-one stream
and the complementary feature maps generated in the one-to-one streams are
combined with a fusion block. The location of the fusion block is adaptively
modified to maximize task-specific performance. Qualitative and quantitative
assessments on T1-, T2-, PD-weighted and FLAIR images clearly demonstrate the
superior performance of the proposed method compared to previous
state-of-the-art one-to-one and many-to-one methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11508</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11508</id><created>2019-09-25</created><authors><author><keyname>Bhowmik</keyname><forenames>Neelanjan</forenames></author><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Gaus</keyname><forenames>Yona Falinie A.</forenames></author><author><keyname>Szarek</keyname><forenames>Marcin</forenames></author><author><keyname>Breckon</keyname><forenames>Toby P.</forenames></author></authors><title>The Good, the Bad and the Ugly: Evaluating Convolutional Neural Networks
  for Prohibited Item Detection Using Real and Synthetically Composited X-ray
  Imagery</title><categories>cs.CV cs.LG eess.IV</categories><journal-ref>In Proc. British Machine Vision Conference Workshops, BMVA, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting prohibited items in X-ray security imagery is pivotal in
maintaining border and transport security against a wide range of threat
profiles. Convolutional Neural Networks (CNN) with the support of a significant
volume of data have brought advancement in such automated prohibited object
detection and classification. However, collating such large volumes of X-ray
security imagery remains a significant challenge. This work opens up the
possibility of using synthetically composed imagery, avoiding the need to
collate such large volumes of hand-annotated real-world imagery. Here we
investigate the difference in detection performance achieved using real and
synthetic X-ray training imagery for CNN architecture detecting three exemplar
prohibited items, {Firearm, Firearm Parts, Knives}, within cluttered and
complex X-ray security baggage imagery. We achieve 0.88 of mean average
precision (mAP) with a Faster R-CNN and ResNet-101 CNN architecture for this
3-class object detection using real X-ray imagery. While the performance is
comparable with synthetically composited X-ray imagery (0.78 mAP), our extended
evaluation demonstrates both challenge and promise of using synthetically
composed images to diversify the X-ray security training imagery for automated
detection algorithm training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11538</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11538</id><created>2019-09-17</created><authors><author><keyname>Alizadeh</keyname><forenames>Ali</forenames></author><author><keyname>Moghadam</keyname><forenames>Majid</forenames></author><author><keyname>Bicer</keyname><forenames>Yunus</forenames></author><author><keyname>Ure</keyname><forenames>Nazim Kemal</forenames></author><author><keyname>Yavas</keyname><forenames>Ugur</forenames></author><author><keyname>Kurtulus</keyname><forenames>Can</forenames></author></authors><title>Automated Lane Change Decision Making using Deep Reinforcement Learning
  in Dynamic and Uncertain Highway Environment</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML</categories><comments>Accepted to IEEE Intelligent Transportation Systems Conference - ITSC
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous lane changing is a critical feature for advanced autonomous
driving systems, that involves several challenges such as uncertainty in other
driver's behaviors and the trade-off between safety and agility. In this work,
we develop a novel simulation environment that emulates these challenges and
train a deep reinforcement learning agent that yields consistent performance in
a variety of dynamic and uncertain traffic scenarios. Results show that the
proposed data-driven approach performs significantly better in noisy
environments compared to methods that rely solely on heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11549</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11549</id><created>2019-09-25</created><authors><author><keyname>Simon</keyname><forenames>Christian</forenames></author><author><keyname>Torcoli</keyname><forenames>Matteo</forenames></author><author><keyname>Paulus</keyname><forenames>Jouni</forenames></author></authors><title>MPEG-H Audio for Improving Accessibility in Broadcasting and Streaming</title><categories>eess.AS cs.SD</categories><comments>White Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Broadcasting and streaming services still suffer from various levels of
accessibility barriers for a significant portion of the population, limiting
the access to information and culture, and in the most severe cases limiting
the empowerment of people. This paper provides a brief overview of some of the
most common accessibility barriers encountered. It then gives a short
introduction to object-based audio (OBA) production and transport, focusing on
the aspects relevant for lowering accessibility barriers. MPEG-H Audio is used
as a concrete example of an OBA system already deployed. Two example cases
(dialog enhancement and audio description) are used to demonstrate in detail
the simplicity of producing MPEG-H Audio content providing improved
accessibility. Several other possibilities are outlined briefly. We show that
using OBA for broadcasting and streaming content allows offering several
accessibility features in a flexible manner, requiring only small changes to
the existing production workflow, assuming the receiver supports the
functionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11554</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11554</id><created>2019-09-25</created><authors><author><keyname>Lai</keyname><forenames>Chuan-Chi</forenames></author><author><keyname>Wang</keyname><forenames>Li-Chun</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Data-Driven 3D Placement of UAV Base Stations for Arbitrarily
  Distributed Crowds</title><categories>cs.NI cs.CC cs.DS eess.SP</categories><comments>6 pages, 3 figures, accepted by 2019 IEEE Global Communications
  Conference: Wireless Communications (Globecom2019 WC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider an Unmanned Aerial Vehicle (UAV)-assisted cellular
system which consists of multiple UAV base stations (BSs) cooperating the
terrestrial BSs. In such a heterogeneous network, for cellular operators, the
problem is how to determine the appropriate number, locations, and altitudes of
UAV-BSs to improve the system sumrate as well as satisfy the demands of
arbitrarily flash crowds on data rates. We propose a data-driven 3D placement
of UAV-BSs for providing an effective placement result with a feasible
computational cost. The proposed algorithm searches for the appropriate number,
location, coverage, and altitude of each UAV-BS in the serving area with the
maximized system sumrate in polynomial time so as to guarantee the minimum data
rate requirement of UE. The simulation results show that the proposed approach
can improve system sumrate in comparison with the case without UAV-BSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11555</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11555</id><created>2019-09-25</created><updated>2020-01-17</updated><authors><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Bedi</keyname><forenames>Amrit Singh</forenames></author><author><keyname>Rajawat</keyname><forenames>Ketan</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author></authors><title>Optimally Compressed Nonparametric Online Learning</title><categories>eess.SP cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Batch training of machine learning models based on neural networks is now
well established, whereas to date streaming methods are largely based on linear
models. To go beyond linear in the online setting, nonparametric methods are of
interest due to their universality and ability to stably incorporate new
information via convexity or Bayes' Rule. Unfortunately, when used online,
nonparametric methods suffer a &quot;curse of dimensionality&quot; which precludes their
use: their complexity scales at least with the time index. We survey online
compression tools which bring their memory under control and attain approximate
convergence. The asymptotic bias depends on a compression parameter that trades
off memory and accuracy. Further, the applications to robotics, communications,
economics, and power are discussed, as well as extensions to multi-agent
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11562</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11562</id><created>2019-09-25</created><authors><author><keyname>Qin</keyname><forenames>Zhijin</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangwei</forenames></author><author><keyname>Zhang</keyname><forenames>Lin</forenames></author><author><keyname>Gao</keyname><forenames>Yue</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>20 Years of Evolution from Cognitive to Intelligent Communications</title><categories>cs.NI cs.IT eess.SP math.IT</categories><comments>The paper has been accepted by IEEE Transactions on Cognitive
  Communications and Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been 20 years since the concept of cognitive radio (CR) was proposed,
which is an efficient approach to provide more access opportunities to connect
massive wireless devices. To improve the spectrum efficiency, CR enables
unlicensed usage of licensed spectrum resources. It has been regarded as the
key enabler for intelligent communications. In this article, we will provide an
overview on the intelligent communication in the past two decades to illustrate
the revolution of its capability from cognition to artificial intelligence
(AI). Particularly, this article starts from a comprehensive review of typical
spectrum sensing and sharing, followed by the recent achievements on the
AI-enabled intelligent radio. Moreover, research challenges in the future
intelligent communications will be discussed to show a path to the real
deployment of intelligent radio. After witnessing the glorious developments of
CR in the past 20 years, we try to provide readers a clear picture on how
intelligent radio could be further developed to smartly utilize the limited
spectrum resources as well as to optimally configure wireless devices in the
future communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11573</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11573</id><created>2019-09-25</created><authors><author><keyname>Nguyen</keyname><forenames>Thanh Thi</forenames></author><author><keyname>Nguyen</keyname><forenames>Cuong M.</forenames></author><author><keyname>Nguyen</keyname><forenames>Dung Tien</forenames></author><author><keyname>Nguyen</keyname><forenames>Duc Thanh</forenames></author><author><keyname>Nahavandi</keyname><forenames>Saeid</forenames></author></authors><title>Deep Learning for Deepfakes Creation and Detection</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has been successfully applied to solve various complex problems
ranging from big data analytics to computer vision and human-level control.
Deep learning advances however have also been employed to create software that
can cause threats to privacy, democracy and national security. One of those
deep learning-powered applications recently emerged is &quot;deepfake&quot;. Deepfake
algorithms can create fake images and videos that humans cannot distinguish
them from authentic ones. The proposal of technologies that can automatically
detect and assess the integrity of digital visual media is therefore
indispensable. This paper presents a survey of algorithms used to create
deepfakes and, more importantly, methods proposed to detect deepfakes in the
literature to date. We present extensive discussions on challenges, research
trends and directions related to deepfake technologies. By reviewing the
background of deepfakes and state-of-the-art deepfake detection methods, this
study provides a comprehensive overview of deepfake techniques and facilitates
the development of new and more robust methods to deal with the increasingly
challenging deepfakes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11591</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11591</id><created>2019-09-23</created><updated>2019-11-22</updated><authors><author><keyname>Yuan</keyname><forenames>Lim Zun</forenames></author><author><keyname>Hasanbeig</keyname><forenames>Mohammadhosein</forenames></author><author><keyname>Abate</keyname><forenames>Alessandro</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author></authors><title>Modular Deep Reinforcement Learning with Temporal Logic Specifications</title><categories>cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:1902.00778</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an actor-critic, model-free, and online Reinforcement Learning
(RL) framework for continuous-state continuous-action Markov Decision Processes
(MDPs) when the reward is highly sparse but encompasses a high-level temporal
structure. We represent this temporal structure by a finite-state machine and
construct an on-the-fly synchronised product with the MDP and the finite
machine. The temporal structure acts as a guide for the RL agent within the
product, where a modular Deep Deterministic Policy Gradient (DDPG) architecture
is proposed to generate a low-level control policy. We evaluate our framework
in a Mars rover experiment and we present the success rate of the synthesised
policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11598</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11598</id><created>2019-09-25</created><updated>2019-10-06</updated><authors><author><keyname>Peng</keyname><forenames>Haoran</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Lai</keyname><forenames>Chuan-Chi</forenames></author><author><keyname>Wang</keyname><forenames>Li-Chun</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>A Predictive On-Demand Placement of UAV Base Stations Using Echo State
  Network</title><categories>cs.NI cs.LG eess.SP</categories><comments>6 pages, 8 figures, accepted by 2019 IEEE/CIC International
  Conference on Communications in China (ICCC)</comments><doi>10.1109/ICCChina.2019.8855868</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The unmanned aerial vehicles base stations (UAV-BSs) have great potential in
being widely used in many dynamic application scenarios. In those scenarios,
the movements of served user equipments (UEs) are inevitable, so the UAV-BSs
needs to be re-positioned dynamically for providing seamless services. In this
paper, we propose a system framework consisting of UEs clustering, UAV-BS
placement, UEs trajectories prediction, and UAV-BS reposition matching scheme,
to serve the UEs seamlessly as well as minimize the energy cost of UAV-BSs'
reposition trajectories. An Echo State Network (ESN) based algorithm for
predicting the future trajectories of UEs and a Kuhn-Munkres-based algorithm
for finding the energy-efficient reposition trajectories of UAV-BSs is
designed, respectively. We conduct a simulation using a real open dataset for
performance validation. The simulation results indicate that the proposed
framework achieves high prediction accuracy and provides the energy-efficient
matching scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11607</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11607</id><created>2019-09-23</created><authors><author><keyname>Jayathurathnage</keyname><forenames>Prasad</forenames></author><author><keyname>Dang</keyname><forenames>Xiaojie</forenames></author><author><keyname>Tretyakov</keyname><forenames>Sergei A.</forenames></author><author><keyname>Simovski</keyname><forenames>Constantin</forenames></author></authors><title>Automatic Receiver Tracking and Power Channeling for Multi-Transmitter
  Wireless Power Transfer</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free positioning of receivers is one of the key requirements for many
wireless power transfer (WPT) applications, required from the end-user point of
view. However, realization of stable and effective wireless power transfer for
freely positioned receivers is technically challenging task because of the
requirement of complex control and tuning. In this paper, we propose a concept
of automatic receiver tracking and power channeling for multi-transmitter WPT
systems using uncoupled transmitter and uncoupled repeaters. Each
transmitter-repeater pair forms an independent power transfer channel providing
an effective link for the power flow from the transmitter to the receiver. The
proposed WPT system is capable of maintaining stable output power with constant
high efficiency regardless of the receiver position and without having any
active control or tuning. The proposed concept is numerically and
experimentally verified by using a four-transmitter WPT system in form of a
linear array. The experimental results show that the efficiency of the proposed
WPT system can reach 94.5\% with a variation less than 2\% against the receiver
position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11625</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11625</id><created>2019-09-25</created><authors><author><keyname>Singh</keyname><forenames>Ayush</forenames></author><author><keyname>Salehi</keyname><forenames>Seyed Sadegh Mohseni</forenames></author><author><keyname>Gholipour</keyname><forenames>Ali</forenames></author></authors><title>Deep Predictive Motion Tracking in Magnetic Resonance Imaging:
  Application to Fetal Imaging</title><categories>eess.IV cs.CV cs.LG</categories><comments>10 pages, 8 figures, and 2 tables</comments><acm-class>I.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fetal magnetic resonance imaging (MRI) is challenged by uncontrollable,
large, and irregular fetal movements. Fetal MRI is performed in a fully
interactive manner in which a technologist monitors motion to prescribe slices
in right angles with respect to the anatomy of interest. Current practice
involves repeated acquisitions to ensure diagnostic-quality images are
acquired; and the scans are retrospectively registered slice-by-slice to
reconstruct 3D images. Nonetheless, manual monitoring of 3D fetal motion based
on displayed 2D slices and navigation at the level of stacks-of-slices (instead
of slices) is sub-optimal and inefficient. The current process is highly
operator-dependent, requires extensive training, and significantly increases
the length of fetal MRI scans which makes them difficult for pregnant women,
and costly. With that motivation, we presented a new real-time image-based
motion tracking technique in MRI using deep learning that can significantly
improve state of the art. Through a combination of spatial and temporal
encoder-decoder networks, our system learns to predict 3D pose of the fetal
head based on dynamics of motion inferred directly from sequences of acquired
slices. Compared to recent works that estimate static 3D pose of the subject
from slices, our method learns to predict dynamics of 3D motion. We compared
our trained network on held-out test sets (including data with different
characteristics, e.g. different age ranges, and motion trajectories recorded
from volunteer subjects) with networks designed for estimation as well as
methods adopted to make predictions. The results of all estimation and
prediction tasks show that we achieved reliable motion tracking in fetal MRI.
This technique can be augmented with deep learning based fast anatomy
detection, segmentation, and image registration techniques to build real-time
motion tracking and navigation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11646</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11646</id><created>2019-09-25</created><updated>2019-09-26</updated><authors><author><keyname>Bi&#x144;kowski</keyname><forenames>Miko&#x142;aj</forenames></author><author><keyname>Donahue</keyname><forenames>Jeff</forenames></author><author><keyname>Dieleman</keyname><forenames>Sander</forenames></author><author><keyname>Clark</keyname><forenames>Aidan</forenames></author><author><keyname>Elsen</keyname><forenames>Erich</forenames></author><author><keyname>Casagrande</keyname><forenames>Norman</forenames></author><author><keyname>Cobo</keyname><forenames>Luis C.</forenames></author><author><keyname>Simonyan</keyname><forenames>Karen</forenames></author></authors><title>High Fidelity Speech Synthesis with Adversarial Networks</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks have seen rapid development in recent years
and have led to remarkable improvements in generative modelling of images.
However, their application in the audio domain has received limited attention,
and autoregressive models, such as WaveNet, remain the state of the art in
generative modelling of audio signals such as human speech. To address this
paucity, we introduce GAN-TTS, a Generative Adversarial Network for
Text-to-Speech. Our architecture is composed of a conditional feed-forward
generator producing raw speech audio, and an ensemble of discriminators which
operate on random windows of different sizes. The discriminators analyse the
audio both in terms of general realism, as well as how well the audio
corresponds to the utterance that should be pronounced. To measure the
performance of GAN-TTS, we employ both subjective human evaluation (MOS - Mean
Opinion Score), as well as novel quantitative metrics (Fr\'echet DeepSpeech
Distance and Kernel DeepSpeech Distance), which we find to be well correlated
with MOS. We show that GAN-TTS is capable of generating high-fidelity speech
with naturalness comparable to the state-of-the-art models, and unlike
autoregressive models, it is highly parallelisable thanks to an efficient
feed-forward generator. Listen to GAN-TTS reading this abstract at
https://storage.googleapis.com/deepmind-media/research/abstract.wav.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11699</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11699</id><created>2019-09-25</created><authors><author><keyname>Rosenberg</keyname><forenames>Andrew</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Ramabhadran</keyname><forenames>Bhuvana</forenames></author><author><keyname>Jia</keyname><forenames>Ye</forenames></author><author><keyname>Moreno</keyname><forenames>Pedro</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Wu</keyname><forenames>Zelin</forenames></author></authors><title>Speech Recognition with Augmented Synthesized Speech</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for publication at ASRU 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent success of the Tacotron speech synthesis architecture and its variants
in producing natural sounding multi-speaker synthesized speech has raised the
exciting possibility of replacing expensive, manually transcribed,
domain-specific, human speech that is used to train speech recognizers. The
multi-speaker speech synthesis architecture can learn latent embedding spaces
of prosody, speaker and style variations derived from input acoustic
representations thereby allowing for manipulation of the synthesized speech. In
this paper, we evaluate the feasibility of enhancing speech recognition
performance using speech synthesis using two corpora from different domains. We
explore algorithms to provide the necessary acoustic and lexical diversity
needed for robust speech recognition. Finally, we demonstrate the feasibility
of this approach as a data augmentation strategy for domain-transfer.
  We find that improvements to speech recognition performance is achievable by
augmenting training data with synthesized material. However, there remains a
substantial gap in performance between recognizers trained on human speech
those trained on synthesized speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11707</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11707</id><created>2019-09-25</created><authors><author><keyname>Yi</keyname><forenames>Yunjie</forenames></author><author><keyname>Gong</keyname><forenames>Guang</forenames></author></authors><title>Implementation of three LWC Schemes in the WiFi 4-Way Handshake with
  Software Defined Radio</title><categories>cs.CR eess.SP</categories><comments>NIST Lightweight Cryptography Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the implementation setup of the IEEE 802.1X 4-way
handshake mutual authentication and IEEE 802.11i amending protected
communication by using lightweight cryptography (LWC) schemes. The
cryptographic functions including message integrity check (MIC) code (or
equivalently message authentication code), key deviation function, and
authenticated encryption are implemented by each of three LWC schemes, i.e.,
ACE, SPIX, and WAGE, in three different types of microcontrollers: 8-bit
(Atmega128), 16-bit (MSP430f2013/MSP430f22370) and 32-bit (Cortex-m3lm3s9d96)
microcontrollers. Software defined radio (SDR), contained two Universal
Software Radio Peripheral (USRP) devices, is used to setup 802.11a physical
layer orthogonal frequency division multiplexing (OFDM) transmission systems
for the devices. We provide the experimental timing including cryptographic
operations, OFDM modulation and radio transmission in the air.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11711</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11711</id><created>2019-09-25</created><authors><author><keyname>Hou</keyname><forenames>Qingchun</forenames></author><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Du</keyname><forenames>Ershun</forenames></author><author><keyname>Miao</keyname><forenames>Miao</forenames></author><author><keyname>Peng</keyname><forenames>Fei</forenames></author><author><keyname>Kang</keyname><forenames>Chongqing</forenames></author></authors><title>Probabilistic duck curve in high PV penetration power system: Concept,
  modeling, and empirical analysis in China</title><categories>eess.SY cs.SY stat.AP</categories><doi>10.1016/j.apenergy.2019.03.067</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The high penetration of photovoltaic (PV) is reshaping the electricity
net-load curve and has a significant impact on power system operation and
planning. The concept of duck curve is widely used to describe the timing
imbalance between peak demand and PV generation. The traditional duck curve is
deterministic and only shows a single extreme or typical scenario during a day.
Thus, it cannot capture both the probability of that scenario and the
uncertainty of PV generation and loads. These weaknesses limit the application
of the duck curve on power system planning under high PV penetration. To
address this issue, the novel concepts of probabilistic duck curve (PDC) and
probabilistic ramp curve (PRC) are proposed to accurately model the uncertainty
and variability of electricity net load and ramp under high PV penetration. An
efficient method is presented for modeling PDC and PRC using kernel density
estimation, copula function, and dependent discrete convolution. Several
indices are designed to quantify the characteristics of the PDC and PRC. For
the application, we demonstrate how the PDC and PRC will benefit flexible
resource planning. Finally, an empirical study on the Qinghai provincial power
system of China validates the effectiveness of the presented method. The
results of PDC and PRC intuitively illustrate that the ramp demand and the
valley of net load face considerable uncertainty under high PV penetration. The
results of flexible resource planning indicate that retrofitting coal-fired
units has remarkable performance on enhancing the power system flexibility in
Qinghai. In average, reducing the minimal output of coal-fired units by 1 MW
will increase PV accommodation by over 4 MWh each day.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11721</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11721</id><created>2019-09-25</created><authors><author><keyname>Cong</keyname><forenames>Wenxiang</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaohua</forenames></author><author><keyname>Liu</keyname><forenames>Shaohua</forenames></author><author><keyname>Ning</keyname><forenames>Ruola</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>Deep-learning-based Breast CT for Radiation Dose Reduction</title><categories>physics.med-ph cs.CV eess.IV</categories><comments>7 pages, 4 figures</comments><doi>10.1117/12.2530234</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cone-beam breast computed tomography (CT) provides true 3D breast images with
isotropic resolution and high-contrast information, detecting calcifications as
small as a few hundred microns and revealing subtle tissue differences.
However, breast is highly sensitive to x-ray radiation. It is critically
important for healthcare to reduce radiation dose. Few-view cone-beam CT only
uses a fraction of x-ray projection data acquired by standard cone-beam breast
CT, enabling significant reduction of the radiation dose. However, insufficient
sampling data would cause severe streak artifacts in CT images reconstructed
using conventional methods. In this study, we propose a deep-learning-based
method to establish a residual neural network model for the image
reconstruction, which is applied for few-view breast CT to produce high quality
breast CT images. We respectively evaluate the deep-learning-based image
reconstruction using one third and one quarter of x-ray projection views of the
standard cone-beam breast CT. Based on clinical breast imaging dataset, we
perform a supervised learning to train the neural network from few-view CT
images to corresponding full-view CT images. Experimental results show that the
deep learning-based image reconstruction method allows few-view breast CT to
achieve a radiation dose &lt;6 mGy per cone-beam CT scan, which is a threshold set
by FDA for mammographic screening.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11727</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11727</id><created>2019-09-25</created><authors><author><keyname>Gurunath</keyname><forenames>Nishant</forenames></author><author><keyname>Rallabandi</keyname><forenames>Sai Krishna</forenames></author><author><keyname>Black</keyname><forenames>Alan</forenames></author></authors><title>Disentangling Speech and Non-Speech Components for Building Robust
  Acoustic Models from Found Data</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to build language technologies for majority of the languages, it is
important to leverage the resources available in public domain on the internet
- commonly referred to as `Found Data'. However, such data is characterized by
the presence of non-standard, non-trivial variations. For instance, speech
resources found on the internet have non-speech content, such as music.
Therefore, speech recognition and speech synthesis models need to be robust to
such variations. In this work, we present an analysis to show that it is
important to disentangle the latent causal factors of variation in the original
data to accomplish these tasks. Based on this, we present approaches to
disentangle such variations from the data using Latent Stochastic Models.
Specifically, we present a method to split the latent prior space into
continuous representations of dominant speech modes present in the magnitude
spectra of audio signals. We propose a completely unsupervised approach using
multinode latent space variational autoencoders (VAE). We show that the
constraints on the latent space of a VAE can be in-fact used to separate speech
and music, independent of the language of the speech. This paper also
analytically presents the requirement on the number of latent variables for the
task based on distribution of the speech data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11783</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11783</id><created>2019-09-25</created><authors><author><keyname>Tzoumas</keyname><forenames>Vasileios</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Robust and Adaptive Sequential Submodular Optimization</title><categories>math.OC cs.DM cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emerging applications of control, estimation, and machine learning, ranging
from target tracking to decentralized model fitting, pose resource constraints
that limit which of the available sensors, actuators, or data can be
simultaneously used across time. Therefore, many researchers have proposed
solutions within discrete optimization frameworks where the optimization is
performed over finite sets. By exploiting notions of discrete convexity, such
as submodularity, the researchers have been able to provide scalable algorithms
with provable suboptimality bounds. In this paper, we consider such problems
but in adversarial environments, where in every step a number of the chosen
elements in the optimization is removed due to failures/attacks. Specifically,
we consider for the first time a sequential version of the problem that allows
us to observe the failures and adapt, while the attacker also adapts to our
response. We call the novel problem Robust Sequential submodular Maximization
(RSM). Generally, the problem is computationally hard and no scalable algorithm
is known for its solution. However, in this paper we propose Robust and
Adaptive Maximization (RAM), the first scalable algorithm. RAM runs in an
online fashion, adapting in every step to the history of failures. Also, it
guarantees a near-optimal performance, even against any number of failures
among the used elements. Particularly, RAM has both provable per-instance a
priori bounds and tight and/or optimal a posteriori bounds. Finally, we
demonstrate RAM's near-optimality in simulations across various application
scenarios, along with its robustness against several failure types, from
worst-case to random.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11791</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11791</id><created>2019-09-25</created><authors><author><keyname>Mousavi</keyname><forenames>Sajad</forenames></author><author><keyname>Fotoohinasab</keyname><forenames>Atiyeh</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author></authors><title>Single-modal and Multi-modal False Arrhythmia Alarm Reduction using
  Attention-based Convolutional and Recurrent Neural Networks</title><categories>q-bio.QM cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a deep learning model that effectively suppresses the
false alarms in the intensive care units (ICUs) without ignoring the true
alarms using single- and multimodal biosignals. Most of the current work in the
literature are either rule-based methods, requiring prior knowledge of
arrhythmia analysis to build rules, or classical machine learning approaches,
depending on hand-engineered features. In this work, we apply convolutional
neural networks to automatically extract time-invariant features, an attention
mechanism to put more emphasis on the important regions of the input segmented
signal(s) that are more likely to contribute to an alarm, and long short-term
memory units to capture the temporal information presented in the signal
segments. We trained our method efficiently using a two-step training algorithm
(i.e., pre-training and fine-tuning the proposed network) on the dataset
provided by the PhysioNet computing in cardiology challenge 2015. The
evaluation results demonstrate that the proposed method obtains better results
compared to other existing algorithms for the false alarm reduction task in
ICUs. The proposed method achieves a sensitivity of 93.88% and a specificity of
92.05% for the alarm classification, considering three different signals. In
addition, our experiments for 5 separate alarm types leads significant results,
where we just consider a single-lead ECG (e.g., a sensitivity of 90.71%, a
specificity of 88.30%, an AUC of 89.51 for alarm type of Ventricular
Tachycardia arrhythmia)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11795</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11795</id><created>2019-09-25</created><authors><author><keyname>Schlemper</keyname><forenames>Jo</forenames></author><author><keyname>Duan</keyname><forenames>Jinming</forenames></author><author><keyname>Ouyang</keyname><forenames>Cheng</forenames></author><author><keyname>Qin</keyname><forenames>Chen</forenames></author><author><keyname>Caballero</keyname><forenames>Jose</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph V.</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Data consistency networks for (calibration-less) accelerated parallel MR
  image reconstruction</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Presented at ISMRM 27th Annual Meeting &amp; Exhibition (Abstract #4663)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present simple reconstruction networks for multi-coil data by extending
deep cascade of CNN's and exploiting the data consistency layer. In particular,
we propose two variants, where one is inspired by POCSENSE and the other is
calibration-less. We show that the proposed approaches are competitive relative
to the state of the art both quantitatively and qualitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11797</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11797</id><created>2019-09-25</created><authors><author><keyname>Paganin</keyname><forenames>David M.</forenames></author><author><keyname>Kozlov</keyname><forenames>Alexander</forenames></author><author><keyname>Gureyev</keyname><forenames>Timur E.</forenames></author></authors><title>Spatial resolution, noise and information in the computational-imaging
  era</title><categories>physics.optics eess.IV physics.app-ph physics.ins-det physics.pop-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging is an important means by which information is gathered regarding the
physical world. Spatial resolution and signal-to-noise ratio are underpinning
concepts. There is a paucity of rigorous definitions for these quantities,
which are general enough to be useful in a broad range of imaging problems,
while being also sufficiently specific to enable precise quantitative
evaluation of the relevant properties of imaging systems. This is particularly
true for many modern forms of imaging that include digital processing of the
acquired imaging data as an integral step leading to final images presented to
an end-user. Here, both the well-known historical definitions of spatial
resolution and some more recent approaches suitable for many forms of modern
computational imaging are discussed. An intrinsic duality of spatial resolution
and signal-to-noise exists in almost all types of imaging, with the related
uncertainty relationship determining a trade-off between the two quantities.
Examples are presented with applications to super-resolution imaging, inline
holography and ghost imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11798</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11798</id><created>2019-09-25</created><updated>2019-09-26</updated><authors><author><keyname>Chen</keyname><forenames>Yuxiao</forenames></author><author><keyname>Ahmadi</keyname><forenames>Mohamadreza</forenames></author><author><keyname>Ames</keyname><forenames>Aaron D.</forenames></author></authors><title>Optimal Safe Controller Synthesis: A Density Function Approach</title><categories>math.OC cs.SY eess.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the synthesis of optimal safe controllers based on
density functions. We present an algorithm for robust constrained optimal
control synthesis using the duality relationship between the density function
and the value function. The density function follows the Liouville equation and
is the dual of the value function, which satisfies Bellman's optimality
principle. Thanks to density functions, constraints over the distribution of
states, such as safety constraints, can be posed straightforwardly in an
optimal control problem. The constrained optimal control problem is then solved
with a primal-dual algorithm. This formulation is extended to the case with
external disturbances, and we show that the robust constrained optimal control
can be solved with a modified primal-dual algorithm. We apply this formulation
to the problem of finding the optimal safe controller that minimizes the
cumulative intervention. An adaptive cruise control (ACC) example is used to
demonstrate the efficacy of the proposed, wherein we compare the result of the
density function approach with the conventional control barrier function (CBF)
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11800</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11800</id><created>2019-09-25</created><authors><author><keyname>Shi</keyname><forenames>Yi</forenames></author><author><keyname>Davaslioglu</keyname><forenames>Kemal</forenames></author><author><keyname>Sagduyu</keyname><forenames>Yalin E.</forenames></author><author><keyname>Headley</keyname><forenames>William C.</forenames></author><author><keyname>Fowler</keyname><forenames>Michael</forenames></author><author><keyname>Green</keyname><forenames>Gilbert</forenames></author></authors><title>Deep Learning for RF Signal Classification in Unknown and Dynamic
  Spectrum Environments</title><categories>cs.NI cs.LG eess.SP</categories><comments>Accepted to IEEE International Symposium on Dynamic Spectrum Access
  Networks (DYSPAN) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic spectrum access (DSA) benefits from detection and classification of
interference sources including in-network users, out-network users, and jammers
that may all coexist in a wireless network. We present a deep learning based
signal (modulation) classification solution in a realistic wireless network
setting, where 1) signal types may change over time; 2) some signal types may
be unknown for which there is no training data; 3) signals may be spoofed such
as the smart jammers replaying other signal types; and 4) different signal
types may be superimposed due to the interference from concurrent
transmissions. For case 1, we apply continual learning and train a
Convolutional Neural Network (CNN) using an Elastic Weight Consolidation (EWC)
based loss. For case 2, we detect unknown signals via outlier detection applied
to the outputs of convolutional layers using Minimum Covariance Determinant
(MCD) and k-means clustering methods. For case 3, we extend the CNN structure
to capture phase shifts due to radio hardware effects to identify the spoofing
signal sources. For case 4, we apply blind source separation using Independent
Component Analysis (ICA) to separate interfering signals. We utilize the signal
classification results in a distributed scheduling protocol, where in-network
(secondary) users employ signal classification scores to make channel access
decisions and share the spectrum with each other while avoiding interference
with out-network (primary) users and jammers. Compared with benchmark
TDMA-based schemes, we show that distributed scheduling constructed upon signal
classification results provides major improvements to in-network user
throughput and out-network user success ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11806</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11806</id><created>2019-09-25</created><authors><author><keyname>Zhang</keyname><forenames>Zhi-Song</forenames></author><author><keyname>Zhu</keyname><forenames>Li-Chun</forenames></author><author><keyname>Tang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Xin-Yi</forenames></author></authors><title>Unit panel nodes detection by CNN on FAST reflector</title><categories>astro-ph.IM eess.IV</categories><comments>13 pages, 12 figures, 2 tables, CNN applied on FAST's reflector
  measurement; matches the published version in RAA</comments><journal-ref>Research in Astronomy and Astrophysics, Volume 19, Issue 1,
  article id. 011 (2019)</journal-ref><doi>10.1088/1674-4527/19/1/11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 500-meter Aperture Spherical Radio Telescope(FAST) has an active
reflector. During the observation, the reflector will be deformed into a
paraboloid of 300-meters. To improve its surface accuracy, we propose a scheme
for photogrammetry to measure the positions of 2226 nodes on the reflector. And
the way to detect the nodes in the photos is the key problem in photogrammetry.
This paper applies Convolutional Neural Network(CNN) with candidate regions to
detect the nodes in the photos. The experiment results show a high recognition
rate of 91.5%, which is much higher than the recognition rate of traditional
edge detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11812</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11812</id><created>2019-09-25</created><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author></authors><title>Differential Privacy for Evolving Almost-Periodic Datasets with
  Continual Linear Queries: Application to Energy Data Privacy</title><categories>cs.CR cs.IT cs.SY eess.SY math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For evolving datasets with continual reports, the composition rule for
differential privacy (DP) dictates that the scale of DP noise must grow
linearly with the number of the queries, or that the privacy budget must be
split equally between all the queries, so that the privacy budget across all
the queries remains bounded and consistent with the privacy guarantees. To
avoid this drawback of DP, we consider datasets containing almost periodic time
series, composed of periodic components and noisy variations on top that are
independent across periods. Our interest in these datasets is motivated by
that, for reporting on private periodic time series, we do not need to divide
the privacy budget across the entire, possibly infinite, horizon. Instead, for
periodic time series, we generate DP reports for the first period and report
the same DP reports periodically. In practice, however, exactly periodic time
series do not exist as the data always contains small variations due to random
or uncertain events. For instance, the energy consumption of a household may
repeat the same daily pattern with slight variations due to minor changes to
the habits of the individuals. The underlying periodic pattern is a function of
the private information of the households. It might be desired to protect the
privacy of households by not leaking information about the recurring patterns
while the individual daily variations are almost noise-like with little to no
privacy concerns (depending on the situation). Motivated by this, we define DP
for almost periodic datasets and develop a Laplace mechanism for responding to
linear queries. We provide statistical tools for testing the validity of almost
periodicity assumption. We use multiple energy datasets containing smart-meter
measurements of households to validate almost periodicity assumption. We
generate DP aggregate reports and investigate their utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11823</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11823</id><created>2019-09-25</created><updated>2019-09-26</updated><authors><author><keyname>Wang</keyname><forenames>L.</forenames></author><author><keyname>Fullmer</keyname><forenames>D.</forenames></author><author><keyname>Liu</keyname><forenames>F.</forenames></author><author><keyname>Morse</keyname><forenames>A. S.</forenames></author></authors><title>Distributed Control of Linear Multi-Channel Systems</title><categories>eess.SY cs.SY math.AG</categories><comments>7 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A solution is given to the basic distributed feedback control problem for a
multi-channel linear system assuming only that the system is jointly
controllable, jointly observable and has an associated neighbor graph which is
strongly connected. The solution is an observer-based control system which is
implemented in a distributed manner. Using these ideas, a solution is also
given to the distributed set-point control problem for a multi-channel linear
system in which each and every agent with access to the system is able to
independently adjust its controlled output to any desired set-point value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11839</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11839</id><created>2019-09-25</created><authors><author><keyname>Kassani</keyname><forenames>Sara Hosseinzadeh</forenames></author><author><keyname>Kassani</keyname><forenames>Peyman Hosseinzadeh</forenames></author><author><keyname>Wesolowski</keyname><forenames>Michal J.</forenames></author><author><keyname>Schneider</keyname><forenames>Kevin A.</forenames></author><author><keyname>Deters</keyname><forenames>Ralph</forenames></author></authors><title>Breast Cancer Diagnosis with Transfer Learning and Global Pooling</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breast cancer is one of the most common causes of cancer-related death in
women worldwide. Early and accurate diagnosis of breast cancer may
significantly increase the survival rate of patients. In this study, we aim to
develop a fully automatic, deep learning-based, method using descriptor
features extracted by Deep Convolutional Neural Network (DCNN) models and
pooling operation for the classification of hematoxylin and eosin stain (H&amp;E)
histological breast cancer images provided as a part of the International
Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on
BreAst Cancer Histology (BACH) Images. Different data augmentation methods are
applied to optimize the DCNN performance. We also investigated the efficacy of
different stain normalization methods as a pre-processing step. The proposed
network architecture using a pre-trained Xception model yields 92.50% average
classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11841</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11841</id><created>2019-09-25</created><authors><author><keyname>Foote</keyname><forenames>Markus D.</forenames><affiliation>Scientific Computing and Imaging Institute, Department of Biomedical Engineering, University of Utah</affiliation></author><author><keyname>Sabouri</keyname><forenames>Pouya</forenames><affiliation>University of Maryland School of Medicine, Baltimore, Maryland</affiliation></author><author><keyname>Sawant</keyname><forenames>Amit</forenames><affiliation>University of Maryland School of Medicine, Baltimore, Maryland</affiliation></author><author><keyname>Joshi</keyname><forenames>Sarang C.</forenames><affiliation>Scientific Computing and Imaging Institute, Department of Biomedical Engineering, University of Utah</affiliation></author></authors><title>Rank Constrained Diffeomorphic Density Motion Estimation for Respiratory
  Correlated Computed Tomography</title><categories>eess.IV stat.AP</categories><journal-ref>In: MFCA 2017. Lecture Notes in Computer Science, vol 10551.
  Springer, Cham</journal-ref><doi>10.1007/978-3-319-67675-3_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion estimation of organs in a sequence of images is important in numerous
medical imaging applications. The focus of this paper is the analysis of 4D
Respiratory Correlated Computed Tomography (RCCT) Imaging. It is hypothesized
that the quasi-periodic breathing induced motion of organs in the thorax can be
represented by deformations spanning a very low dimension subspace of the full
infinite dimensional space of diffeomorphic transformations. This paper
presents a novel motion estimation algorithm that includes the constraint for
low-rank motion between the different phases of the RCCT images. Low-rank
deformation solutions are necessary for the efficient statistical analysis and
improved treatment planning and delivery. Although the application focus of
this paper is RCCT the algorithm is quite general and applicable to various
motion estimation problems in medical imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11852</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11852</id><created>2019-09-25</created><authors><author><keyname>Zhong</keyname><forenames>Yaofeng Desmond</forenames></author><author><keyname>Leonard</keyname><forenames>Naomi Ehrich</forenames></author></authors><title>A Continuous Threshold Model of Cascade Dynamics</title><categories>math.OC cs.SY eess.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a continuous threshold model (CTM) of cascade dynamics for a
network of agents with real-valued activity levels that change continuously in
time. The model generalizes the linear threshold model (LTM) from the
literature, where an agent becomes active (adopts an innovation) if the
fraction of its neighbors that are active is above a threshold. With the CTM we
study the influence on cascades of heterogeneity in thresholds for a network
comprised of a chain of three clusters of agents, each distinguished by a
different threshold. The system is most sensitive to change as the dynamics
pass through a bifurcation point: if the bifurcation is supercritical the
response will be contained, while if the bifurcation is subcritical the
response will be a cascade. We show that there is a subcritical bifurcation,
thus a cascade, in response to an innovation if there is a large enough
disparity between the thresholds of sufficiently large clusters on either end
of the chain; otherwise the response will be contained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11854</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11854</id><created>2019-09-25</created><authors><author><keyname>Cetin</keyname><forenames>Irem</forenames></author><author><keyname>Sanroma</keyname><forenames>Gerard</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen E.</forenames></author><author><keyname>Napel</keyname><forenames>Sandy</forenames></author><author><keyname>Camara</keyname><forenames>Oscar</forenames></author><author><keyname>Ballester</keyname><forenames>Miguel-Angel Gonzalez</forenames></author><author><keyname>Lekadir</keyname><forenames>Karim</forenames></author></authors><title>A Radiomics Approach to Computer-Aided Diagnosis with Cardiac Cine-MRI</title><categories>eess.IV cs.LG stat.ML</categories><doi>10.1007/978-3-319-75541-0_9</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Use expert visualization or conventional clinical indices can lack accuracy
for borderline classications. Advanced statistical approaches based on
eigen-decomposition have been mostly concerned with shape and motion indices.
In this paper, we present a new approach to identify CVDs from cine-MRI by
estimating large pools of radiomic features (statistical, shape and textural
features) encoding relevant changes in anatomical and image characteristics due
to CVDs. The calculated cine-MRI radiomic features are assessed using
sequential forward feature selection to identify the most relevant ones for
given CVD classes (e.g. myocardial infarction, cardiomyopathy, abnormal right
ventricle). Finally, advanced machine learning is applied to suitably integrate
the selected radiomics for final multi-feature classification based on Support
Vector Machines (SVMs). The proposed technique was trained and cross-validated
using 100 cine-MRI cases corresponding to five different cardiac classes from
the ACDC MICCAI 2017 challenge
\footnote{https://www.creatis.insa-lyon.fr/Challenge/acdc/index.html}. All
cases were correctly classified in this preliminary study, indicating potential
of using large-scale radiomics for MRI-based diagnosis of CVDs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11856</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11856</id><created>2019-09-25</created><authors><author><keyname>Hui</keyname><forenames>Zheng</forenames></author><author><keyname>Gao</keyname><forenames>Xinbo</forenames></author><author><keyname>Yang</keyname><forenames>Yunchu</forenames></author><author><keyname>Wang</keyname><forenames>Xiumei</forenames></author></authors><title>Lightweight Image Super-Resolution with Information Multi-distillation
  Network</title><categories>eess.IV cs.CV cs.MM</categories><comments>To be appear in ACM Multimedia 2019, https://github.com/Zheng222/IMDN</comments><doi>10.1145/3343031.3351084</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, single image super-resolution (SISR) methods using deep
convolution neural network (CNN) have achieved impressive results. Thanks to
the powerful representation capabilities of the deep networks, numerous
previous ways can learn the complex non-linear mapping between low-resolution
(LR) image patches and their high-resolution (HR) versions. However, excessive
convolutions will limit the application of super-resolution technology in low
computing power devices. Besides, super-resolution of any arbitrary scale
factor is a critical issue in practical applications, which has not been well
solved in the previous approaches. To address these issues, we propose a
lightweight information multi-distillation network (IMDN) by constructing the
cascaded information multi-distillation blocks (IMDB), which contains
distillation and selective fusion parts. Specifically, the distillation module
extracts hierarchical features step-by-step, and fusion module aggregates them
according to the importance of candidate features, which is evaluated by the
proposed contrast-aware channel attention mechanism. To process real images
with any sizes, we develop an adaptive cropping strategy (ACS) to super-resolve
block-wise image patches using the same well-trained model. Extensive
experiments suggest that the proposed method performs favorably against the
state-of-the-art SR algorithms in term of visual quality, memory footprint, and
inference time. Code is available at \url{https://github.com/Zheng222/IMDN}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11866</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11866</id><created>2019-09-25</created><authors><author><keyname>Kassani</keyname><forenames>Sara Hosseinzadeh</forenames></author><author><keyname>kassani</keyname><forenames>Peyman Hosseinzadeh</forenames></author><author><keyname>Wesolowski</keyname><forenames>Michal J.</forenames></author><author><keyname>Schneider</keyname><forenames>Kevin A.</forenames></author><author><keyname>Deters</keyname><forenames>Ralph</forenames></author></authors><title>A Hybrid Deep Learning Architecture for Leukemic B-lymphoblast
  Classification</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic detection of leukemic B-lymphoblast cancer in microscopic images is
very challenging due to the complicated nature of histopathological structures.
To tackle this issue, an automatic and robust diagnostic system is required for
early detection and treatment. In this paper, an automated deep learning-based
method is proposed to distinguish between immature leukemic blasts and normal
cells. The proposed deep learning based hybrid method, which is enriched by
different data augmentation techniques, is able to extract high-level features
from input images. Results demonstrate that the proposed model yields better
prediction than individual models for Leukemic B-lymphoblast classification
with 96.17% overall accuracy, 95.17% sensitivity and 98.58% specificity. Fusing
the features extracted from intermediate layers, our approach has the potential
to improve the overall classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11870</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11870</id><created>2019-09-25</created><authors><author><keyname>Kassani</keyname><forenames>Sara Hosseinzadeh</forenames></author><author><keyname>Kassani</keyname><forenames>Peyman Hosseinzadeh</forenames></author><author><keyname>Wesolowski</keyname><forenames>Michal J.</forenames></author><author><keyname>Schneider</keyname><forenames>Kevin A.</forenames></author><author><keyname>Deters</keyname><forenames>Ralph</forenames></author></authors><title>Classification of Histopathological Biopsy Images Using Ensemble of Deep
  Learning Networks</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breast cancer is one of the leading causes of death across the world in
women. Early diagnosis of this type of cancer is critical for treatment and
patient care. Computer-aided detection (CAD) systems using convolutional neural
networks (CNN) could assist in the classification of abnormalities. In this
study, we proposed an ensemble deep learning-based approach for automatic
binary classification of breast histology images. The proposed ensemble model
adapts three pre-trained CNNs, namely VGG19, MobileNet, and DenseNet. The
ensemble model is used for the feature representation and extraction steps. The
extracted features are then fed into a multi-layer perceptron classifier to
carry out the classification task. Various pre-processing and CNN tuning
techniques such as stain-normalization, data augmentation, hyperparameter
tuning, and fine-tuning are used to train the model. The proposed method is
validated on four publicly available benchmark datasets, i.e., ICIAR, BreakHis,
PatchCamelyon, and Bioimaging. The proposed multi-model ensemble method obtains
better predictions than single classifiers and machine learning algorithms with
accuracies of 98.13%, 95.00%, 94.64% and 83.10% for BreakHis, ICIAR,
PatchCamelyon and Bioimaging datasets, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11875</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11875</id><created>2019-09-26</created><authors><author><keyname>Lim</keyname><forenames>Wei Yang Bryan</forenames></author><author><keyname>Luong</keyname><forenames>Nguyen Cong</forenames></author><author><keyname>Hoang</keyname><forenames>Dinh Thai</forenames></author><author><keyname>Jiao</keyname><forenames>Yutao</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Yang</keyname><forenames>Qiang</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author></authors><title>Federated Learning in Mobile Edge Networks: A Comprehensive Survey</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, mobile devices are equipped with increasingly advanced
sensing and computing capabilities. Coupled with advancements in Deep Learning
(DL), this opens up countless possibilities for meaningful applications.
Traditional Machine Learning (ML) approaches require the data to be centralized
in a cloud server. However, this results in critical issues related to
unacceptable latency and communication inefficiency. To this end, Mobile Edge
Computing (MEC) has been proposed to bring intelligence closer to the edge,
where data is produced. However, conventional enabling technologies for ML at
mobile edge networks still require personal data to be shared with external
parties, e.g., edge servers. Recently, in light of increasingly stringent data
privacy legislation and growing privacy concerns, the concept of Federated
Learning (FL) has been introduced. In FL, end devices use their local data to
train an ML model required by the server. The end devices then send the model
updates rather than raw data to the server for aggregation. FL can serve as an
enabling technology in mobile edge networks since it enables the collaborative
training of an ML model and also enables DL for mobile edge network
optimization. However, in a large-scale and complex mobile edge network,
heterogeneous devices with varying constraints are involved. This raises
challenges of communication costs, resource allocation, and privacy and
security in the implementation of FL at scale. In this survey, we begin with an
introduction to the background and fundamentals of FL. Then, we highlight the
aforementioned challenges of FL implementation and review existing solutions.
Furthermore, we present the applications of FL for mobile edge network
optimization. Finally, we discuss the important challenges, open issues and
future research directions in FL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11886</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11886</id><created>2019-09-26</created><authors><author><keyname>Jung</keyname><forenames>Youngmoon</forenames></author><author><keyname>Choi</keyname><forenames>Yeunju</forenames></author><author><keyname>Kim</keyname><forenames>Hoirin</forenames></author></authors><title>Self-Adaptive Soft Voice Activity Detection using Deep Neural Networks
  for Robust Speaker Verification</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Accepted at 2019 IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU 2019)</comments><journal-ref>Proc. of ASRU 2019, pp. 365-372</journal-ref><doi>10.1109/ASRU46091.2019.9003935</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice activity detection (VAD), which classifies frames as speech or
non-speech, is an important module in many speech applications including
speaker verification. In this paper, we propose a novel method, called
self-adaptive soft VAD, to incorporate a deep neural network (DNN)-based VAD
into a deep speaker embedding system. The proposed method is a combination of
the following two approaches. The first approach is soft VAD, which performs a
soft selection of frame-level features extracted from a speaker feature
extractor. The frame-level features are weighted by their corresponding speech
posteriors estimated from the DNN-based VAD, and then aggregated to generate a
speaker embedding. The second approach is self-adaptive VAD, which fine-tunes
the pre-trained VAD on the speaker verification data to reduce the domain
mismatch. Here, we introduce two unsupervised domain adaptation (DA) schemes,
namely speech posterior-based DA (SP-DA) and joint learning-based DA (JL-DA).
Experiments on a Korean speech database demonstrate that the verification
performance is improved significantly in real-world environments by using
self-adaptive soft VAD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11897</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11897</id><created>2019-09-26</created><authors><author><keyname>Zhao</keyname><forenames>Hongchao</forenames></author><author><keyname>Liu</keyname><forenames>Zhe</forenames></author><author><keyname>Li</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Zhou</keyname><forenames>Shunbo</forenames></author><author><keyname>Chen</keyname><forenames>Wen</forenames></author><author><keyname>Suo</keyname><forenames>Chuanzhe</forenames></author><author><keyname>Liu</keyname><forenames>Yun-Hui</forenames></author></authors><title>Modelling and Dynamic Tracking Control of Industrial Vehicles with
  Tractor-trailer Structure</title><categories>eess.SY cs.SY</categories><comments>This paper has been accepted for publication at the IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS), Macau,
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing works on control of tractor-trailers systems only consider the
kinematics model without taking dynamics into account. Also, most of them treat
the issue as a pure control theory problem whose solutions are difficult to
implement. This paper presents a trajectory tracking control approach for a
full-scale industrial tractor-trailers vehicle composed of a car-like tractor
and arbitrary number of passive full trailers. To deal with dynamic effects of
trailing units, a force sensor is innovatively installed at the connection
between the tractor and the first trailer to measure the forces acting on the
tractor. The tractor's dynamic model that explicitly accounts for the measured
forces is derived. A tracking controller that compensates the pulling/pushing
forces in real time and simultaneously drives the system onto desired
trajectories is proposed. The propulsion map between throttle opening and the
propulsion force is proposed to be modeled with a fifth-order polynomial. The
parameters are estimated by fitting experimental data, in order to provide
accurate driving force. Stability of the control algorithm is rigorously proved
by Lyapunov methods. Experiments of full-size vehicles are conducted to
validate the performance of the control approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11903</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11903</id><created>2019-09-26</created><authors><author><keyname>Stoean</keyname><forenames>Ruxandra</forenames></author><author><keyname>Iliescu</keyname><forenames>Dominic</forenames></author><author><keyname>Stoean</keyname><forenames>Catalin</forenames></author></authors><title>Segmentation of points of interest during fetal cardiac assesment in the
  first trimester from color Doppler ultrasound</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper puts forward an incipient study that uses a traditional
segmentation method based on Zernike moments for extracting significant
features from frames of fetal echocardiograms from first trimester color
Doppler examinations. A distance based approach is then used on the obtained
indicators to classify frames of three given categories that should be present
in a normal heart condition. The computational tool shows promise in supporting
the obstetrician in a rapid recognition of heart views during screening.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11909</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11909</id><created>2019-09-26</created><updated>2020-02-24</updated><authors><author><keyname>Liu</keyname><forenames>Chang-Le</forenames></author><author><keyname>Fu</keyname><forenames>Sze-Wei</forenames></author><author><keyname>Li</keyname><forenames>You-Jin</forenames></author><author><keyname>Huang</keyname><forenames>Jen-Wei</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author></authors><title>Multichannel Speech Enhancement by Raw Waveform-mapping using Fully
  Convolutional Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted to IEEE/ACM Transactions on Audio, Speech and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, waveform-mapping-based speech enhancement (SE) methods have
garnered significant attention. These methods generally use a deep learning
model to directly process and reconstruct speech waveforms. Because both the
input and output are in waveform format, the waveform-mapping-based SE methods
can overcome the distortion caused by imperfect phase estimation, which may be
encountered in spectral-mapping-based SE systems. So far, most
waveform-mapping-based SE methods have focused on single-channel tasks. In this
paper, we propose a novel fully convolutional network (FCN) with Sinc and
dilated convolutional layers (termed SDFCN) for multichannel SE that operates
in the time domain. We also propose an extended version of SDFCN, called the
residual SDFCN (termed rSDFCN). The proposed methods are evaluated on two
multichannel SE tasks, namely the dual-channel inner-ear microphones SE task
and the distributed microphones SE task. The experimental results confirm the
outstanding denoising capability of the proposed SE systems on both tasks and
the benefits of using the residual architecture on the overall SE performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11912</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11912</id><created>2019-09-26</created><authors><author><keyname>Wang</keyname><forenames>Natalie Yu-Hsien</forenames></author><author><keyname>Wang</keyname><forenames>Hsiao-Lan Sharon</forenames></author><author><keyname>Wang</keyname><forenames>Tao-Wei</forenames></author><author><keyname>Fu</keyname><forenames>Szu-Wei</forenames></author><author><keyname>Lu</keyname><forenames>Xugan</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author></authors><title>Improving the Intelligibility of Electric and Acoustic Stimulation
  Speech Using Fully Convolutional Networks Based Speech Enhancement</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combined electric and acoustic stimulation (EAS) has demonstrated better
speech recognition than conventional cochlear implant (CI) and yielded
satisfactory performance under quiet conditions. However, when noise signals
are involved, both the electric signal and the acoustic signal may be
distorted, thereby resulting in poor recognition performance. To suppress noise
effects, speech enhancement (SE) is a necessary unit in EAS devices. Recently,
a time-domain speech enhancement algorithm based on the fully convolutional
neural networks (FCN) with a short-time objective intelligibility (STOI)-based
objective function (termed FCN(S) in short) has received increasing attention
due to its simple structure and effectiveness of restoring clean speech signals
from noisy counterparts. With evidence showing the benefits of FCN(S) for
normal speech, this study sets out to assess its ability to improve the
intelligibility of EAS simulated speech. Objective evaluations and listening
tests were conducted to examine the performance of FCN(S) in improving the
speech intelligibility of normal and vocoded speech in noisy environments. The
experimental results show that, compared with the traditional minimum-mean
square-error SE method and the deep denoising autoencoder SE method, FCN(S) can
obtain better gain in the speech intelligibility for normal as well as vocoded
speech. This study, being the first to evaluate deep learning SE approaches for
EAS, confirms that FCN(S) is an effective SE approach that may potentially be
integrated into an EAS processor to benefit users in noisy environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11915</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11915</id><created>2019-09-26</created><authors><author><keyname>Nazki</keyname><forenames>Haseeb</forenames></author><author><keyname>Yoon</keyname><forenames>Sook</forenames></author><author><keyname>Fuentes</keyname><forenames>Alvaro</forenames></author><author><keyname>Park</keyname><forenames>Dong Sun</forenames></author></authors><title>Unsupervised Image Translation using Adversarial Networks for Improved
  Plant Disease Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>20 pages, 11 figures, 3 tables, article under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquisition of data in task-specific applications of machine learning like
plant disease recognition is a costly endeavor owing to the requirements of
professional human diligence and time constraints. In this paper, we present a
simple pipeline that uses GANs in an unsupervised image translation environment
to improve learning with respect to the data distribution in a plant disease
dataset, reducing the partiality introduced by acute class imbalance and hence
shifting the classification decision boundary towards better performance. The
empirical analysis of our method is demonstrated on a limited dataset of 2789
tomato plant disease images, highly corrupted with an imbalance in the 9
disease categories. First, we extend the state of the art for the GAN-based
image-to-image translation method by enhancing the perceptual quality of the
generated images and preserving the semantics. We introduce AR-GAN, where in
addition to the adversarial loss, our synthetic image generator optimizes on
Activation Reconstruction loss (ARL) function that optimizes feature
activations against the natural image. We present visually more compelling
synthetic images in comparison to most prominent existing models and evaluate
the performance of our GAN framework in terms of various datasets and metrics.
Second, we evaluate the performance of a baseline convolutional neural network
classifier for improved recognition using the resulting synthetic samples to
augment our training set and compare it with the classical data augmentation
scheme. We observe a significant improvement in classification accuracy (+5.2%)
using generated synthetic samples as compared to (+0.8%) increase using classic
augmentation in an equal class distribution environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11919</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11919</id><created>2019-09-26</created><authors><author><keyname>Tseng</keyname><forenames>Rung-Yu</forenames></author><author><keyname>Wang</keyname><forenames>Tao-Wei</forenames></author><author><keyname>Fu</keyname><forenames>Szu-Wei</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Lee</keyname><forenames>Chia-Ying</forenames></author></authors><title>Seeing Voices in Noise: A Study of Audiovisual-Enhanced Vocoded Speech
  Intelligibility in Cochlear Implant Simulation</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech perception is a key to verbal communication. For people with hearing
loss, the capability to recognize speech is restricted, particularly in the
noisy environment. This study aimed to understand the improvement for vocoded
speech intelligibility in cochlear implant (CI) simulation through two
potential methods: Speech Enhancement (SE) and Audiovisual Integration. A fully
convolutional neural network (FCN) using an intelligibility-oriented objective
function was recently proposed and proven to effectively facilitate the speech
intelligibility as an advanced SE approach. Furthermore, the audiovisual
integration is reported to supply better speech comprehension compared to
audio-only information. An experiment was designed to test speech
intelligibility using tone-vocoded speech in CI simulation with a group of
normal-hearing listeners. Experimental results confirmed the effectiveness of
the FCN-based SE and audiovisual integration and positively recommended these
two methods becoming a blended feature in a CI processor to increase the speech
intelligibility for CI users under noisy conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11936</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11936</id><created>2019-09-26</created><updated>2019-12-18</updated><authors><author><keyname>Zhou</keyname><forenames>Yukun</forenames></author><author><keyname>Chen</keyname><forenames>Zailiang</forenames></author><author><keyname>Shen</keyname><forenames>Hailan</forenames></author><author><keyname>Zheng</keyname><forenames>Xianxian</forenames></author><author><keyname>Zhao</keyname><forenames>Rongchang</forenames></author><author><keyname>Duan</keyname><forenames>Xuanchu</forenames></author></authors><title>A Refined Equilibrium Generative Adversarial Network for Retinal Vessel
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>12 pages, 8 figures, and 9 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Recognizing retinal vessel abnormity is vital to early diagnosis
of ophthalmological diseases and cardiovascular events. However, segmentation
results are highly influenced by elusive vessels, especially in low-contrast
background and lesion region. In this work, we present an end-to-end synthetic
neural network, containing a symmetric equilibrium generative adversarial
network (SEGAN), multi-scale features refine blocks (MSFRB), and attention
mechanism (AM) to enhance the performance on vessel segmentation. Method: The
proposed network is granted powerful multi-scale representation capability to
extract detail information. First, SEGAN constructs a symmetric adversarial
architecture, which forces generator to produce more realistic images with
local details. Second, MSFRB are devised to prevent high-resolution features
from being obscured, thereby merging multi-scale features better. Finally, the
AM is employed to encourage the network to concentrate on discriminative
features. Results: On public dataset DRIVE, STARE, CHASEDB1, and HRF, we
evaluate our network quantitatively and compare it with state-of-the-art works.
The ablation experiment shows that SEGAN, MSFRB, and AM both contribute to the
desirable performance. Conclusion: The proposed network outperforms the mature
methods and effectively functions in elusive vessels segmentation, achieving
highest scores in Sensitivity, G-Mean, Precision, and F1-Score while
maintaining the top level in other metrics. Significance: The appreciable
performance and computational efficiency offer great potential in clinical
retinal vessel segmentation application. Meanwhile, the network could be
utilized to extract detail information in other biomedical issues
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11937</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11937</id><created>2019-09-26</created><updated>2019-09-29</updated><authors><author><keyname>Wu</keyname><forenames>Huapeng</forenames></author><author><keyname>Zou</keyname><forenames>Zhengxia</forenames></author><author><keyname>Gui</keyname><forenames>Jie</forenames></author><author><keyname>Zeng</keyname><forenames>Wen-Jun</forenames></author><author><keyname>Ye</keyname><forenames>Jieping</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Liu</keyname><forenames>Hongyi</forenames></author><author><keyname>Wei</keyname><forenames>Zhihui</forenames></author></authors><title>Multi-grained Attention Networks for Single Image Super-Resolution</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Convolutional Neural Networks (CNN) have drawn great attention in image
super-resolution (SR). Recently, visual attention mechanism, which exploits
both of the feature importance and contextual cues, has been introduced to
image SR and proves to be effective to improve CNN-based SR performance. In
this paper, we make a thorough investigation on the attention mechanisms in a
SR model and shed light on how simple and effective improvements on these ideas
improve the state-of-the-arts. We further propose a unified approach called
&quot;multi-grained attention networks (MGAN)&quot; which fully exploits the advantages
of multi-scale and attention mechanisms in SR tasks. In our method, the
importance of each neuron is computed according to its surrounding regions in a
multi-grained fashion and then is used to adaptively re-scale the feature
responses. More importantly, the &quot;channel attention&quot; and &quot;spatial attention&quot;
strategies in previous methods can be essentially considered as two special
cases of our method. We also introduce multi-scale dense connections to extract
the image features at multiple scales and capture the features of different
layers through dense skip connections. Ablation studies on benchmark datasets
demonstrate the effectiveness of our method. In comparison with other
state-of-the-art SR methods, our method shows the superiority in terms of both
accuracy and model size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11953</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11953</id><created>2019-09-26</created><authors><author><keyname>Wan</keyname><forenames>Sheng</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Zhong</keyname><forenames>Ping</forenames></author><author><keyname>Pan</keyname><forenames>Shirui</forenames></author><author><keyname>Li</keyname><forenames>Guangyu</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author></authors><title>Hyperspectral Image Classification With Context-Aware Dynamic Graph
  Convolutional Network</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In hyperspectral image (HSI) classification, spatial context has demonstrated
its significance in achieving promising performance. However, conventional
spatial context-based methods simply assume that spatially neighboring pixels
should correspond to the same land-cover class, so they often fail to correctly
discover the contextual relations among pixels in complex situations, and thus
leading to imperfect classification results on some irregular or inhomogeneous
regions such as class boundaries. To address this deficiency, we develop a new
HSI classification method based on the recently proposed Graph Convolutional
Network (GCN), as it can flexibly encode the relations among arbitrarily
structured non-Euclidean data. Different from traditional GCN, there are two
novel strategies adopted by our method to further exploit the contextual
relations for accurate HSI classification. First, since the receptive field of
traditional GCN is often limited to fairly small neighborhood, we proposed to
capture long range contextual relations in HSI by performing successive graph
convolutions on a learned region-induced graph which is transformed from the
original 2D image grids. Second, we refine the graph edge weight and the
connective relationships among image regions by learning the improved adjacency
matrix and the 'edge filter', so that the graph can be gradually refined to
adapt to the representations generated by each graph convolutional layer. Such
updated graph will in turn result in accurate region representations, and vice
versa. The experiments carried out on three real-world benchmark datasets
demonstrate that the proposed method yields significant improvement in the
classification performance when compared with some state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11978</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11978</id><created>2019-09-26</created><updated>2019-12-08</updated><authors><author><keyname>Pasand</keyname><forenames>Mohammad Mahdi Share</forenames></author></authors><title>Luenberger-Type Cubic Observers for State Estimation of Linear Systems</title><categories>math.OC cs.SY eess.SY math.DS</categories><comments>13 pages, 89 figures, 0 table, 35 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new nonlinear observer for state estimation of linear
time invariant systems. The proposed observer contains a (nonlinear) cubic term
in its error dynamics. The proposed observer is shown to be capable of yielding
improved performance while possessing desired robustness properties. The use of
nonlinear observer with nonlinear error dynamics for linear systems distinguish
the proposed observer from existing literature. Convergence criteria,
robustness properties and observer based feedback control are addressed.
Simulation examples are included as well which show significant performance
improvement compared to linear observers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.11983</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.11983</id><created>2019-09-26</created><updated>2019-10-05</updated><authors><author><keyname>Wu</keyname><forenames>Qingbo</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Ngan</keyname><forenames>King N.</forenames></author><author><keyname>Li</keyname><forenames>Hongliang</forenames></author><author><keyname>Meng</keyname><forenames>Fanman</forenames></author><author><keyname>Xu</keyname><forenames>Linfeng</forenames></author></authors><title>Subjective and Objective De-raining Quality Assessment Towards Authentic
  Rain Image</title><categories>eess.IV cs.CV</categories><comments>In this revision, we add the comparison with our previous exploration
  towards the de-raining quality assessment in Ref. [16]. Some typos in Tables
  III and IV are corrected, where the missed minus signs are added back for
  some OU metrics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images acquired by outdoor vision systems easily suffer poor visibility and
annoying interference due to the rainy weather, which brings great challenge
for accurately understanding and describing the visual contents. Recent
researches have devoted great efforts on the task of rain removal for improving
the image visibility. However, there is very few exploration about the quality
assessment of de-rained image, even it is crucial for accurately measuring the
performance of various de-raining algorithms. In this paper, we first create a
de-raining quality assessment (DQA) database that collects 206 authentic rain
images and their de-rained versions produced by 6 representative single image
rain removal algorithms. Then, a subjective study is conducted on our DQA
database, which collects the subject-rated scores of all de-rained images. To
quantitatively measure the quality of de-rained image with non-uniform
artifacts, we propose a bi-directional feature embedding network (B-FEN) which
integrates the features of global perception and local difference together.
Experiments confirm that the proposed method significantly outperforms many
existing universal blind image quality assessment models. To help the research
towards perceptually preferred de-raining algorithm, we will publicly release
our DQA database and B-FEN source code on https://github.com/wqb-uestc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12005</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12005</id><created>2019-09-26</created><authors><author><keyname>Fetanat</keyname><forenames>Masoud</forenames></author><author><keyname>Stevens</keyname><forenames>Michael</forenames></author><author><keyname>Hayward</keyname><forenames>Christopher</forenames></author><author><keyname>Lovell</keyname><forenames>Nigel Hamilton</forenames></author></authors><title>A Physiological Control System for an Implantable Heart Pump that
  Accommodates for Interpatient and Intrapatient Variations</title><categories>eess.SY cs.SY eess.SP</categories><journal-ref>http://dx.doi.org/10.1109/TBME.2019.2932233</journal-ref><doi>10.1109/TBME.2019.2932233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Left ventricular assist devices (LVADs) can provide mechanical support for a
failing heart as bridge to transplant and destination therapy. Physiological
control systems for LVADs should be designed to respond to changes in
hemodynamic across a variety of clinical scenarios and patients by
automatically adjusting the heart pump speed. In this study, a novel adaptive
physiological control system for an implantable heart pump was developed to
respond to interpatient and intrapatient variations to maintain the
left-ventricle-end-diastolic-pressure (LVEDP) in the normal range of 3 to 15
mmHg to prevent ventricle suction and pulmonary congestion. A new algorithm was
also developed to detect LVEDP from pressure sensor measurement in real-time
mode. Model free adaptive control (MFAC) was employed to control the pump speed
via simulation of 100 different patient conditions in each of six different
patient scenarios, and compared to standard PID control. Controller performance
was tracked using the sum of the absolute error (SAE) between the desired and
measured LVEDP. The lower SAE on control tracking performance means the
measured LVEDP follows the desired LVEDP faster and with less amplitude
oscillations preventing ventricle suction and pulmonary congestion (mean and
standard deviation of SAE(mmHg) for all 600 simulations were 18813+-29345 and
24794+-28380 corresponding to MFAC and PID controller respectively). In four
out of six patient scenarios, MFAC control tracking performance was better than
the PID controller. This study shows the control performance can be guaranteed
across different patients and conditions when using MFAC over PID control,
which is a step towards clinical acceptance of these systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12024</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12024</id><created>2019-09-26</created><updated>2020-01-10</updated><authors><author><keyname>Kuger</keyname><forenames>Lars</forenames></author><author><keyname>Ichkov</keyname><forenames>Aleksandar</forenames></author><author><keyname>M&#xe4;h&#xf6;nen</keyname><forenames>Petri</forenames></author><author><keyname>Simi&#x107;</keyname><forenames>Ljiljana</forenames></author></authors><title>Urban Outdoor Measurement Study of Phased Antenna Array Impact on
  Millimeter-Wave Link Opportunities and Beam Misalignment</title><categories>eess.SP cs.NI</categories><comments>14 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exploiting multi-antenna technologies for robust beamsteering to overcome the
effects of blockage and beam misalignment is the key to providing seamless
multi-Gbps connectivity in millimeter-wave (mm-wave) networks. In this paper,
we present the first large-scale outdoor mm-wave measurement study using a
phased antenna array in a typical European town. We systematically collect
fine-grained 3D angle-of-arrival (AoA) and angle-of-departure (AoD) data,
totaling over 50,000 received signal strength measurements. We study the impact
of phased antenna arrays in terms of number of link opportunities, achievable
data rate and robustness under small-scale mobility, and compare this against
reference horn antenna measurements. Our results show a limited number of 2--4
link opportunities per receiver location, indicating that the mm-wave multipath
richness in a European town is surprisingly similar to that of dense urban
metropolises. The results for the phased antenna array reveal that significant
losses in estimated data rate occur for beam misalignments in the order of the
half-power beamwidth, with significant and irregular variations for larger
misalignments. By contrast, the loss for horn antennas is monotonically
increasing with the misalignment. Our results strongly suggest that the effect
of non-ideal phased antenna arrays must be explicitly considered in the design
of agile beamsteering algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12028</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12028</id><created>2019-09-26</created><authors><author><keyname>Yu</keyname><forenames>Ruoxi</forenames></author><author><keyname>Charreyron</keyname><forenames>Samuel L.</forenames></author><author><keyname>Boehler</keyname><forenames>Quentin</forenames></author><author><keyname>Weibel</keyname><forenames>Cameron</forenames></author><author><keyname>Poon</keyname><forenames>Carmen C. Y.</forenames></author><author><keyname>Nelson</keyname><forenames>Bradley J.</forenames></author></authors><title>Modeling Electromagnetic Navigation Systems for Medical Applications
  using Random Forests and Artificial Neural Networks</title><categories>eess.SY cs.LG cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Electromagnetic Navigation Systems (eMNS) can be used to control a variety of
multiscale devices within the human body for remote surgery. Accurate modeling
of the magnetic fields generated by the electromagnets of an eMNS is crucial
for the precise control of these devices. Existing methods assume a linear
behavior of these systems, leading to significant modeling errors within
nonlinear regions exhibited at higher magnetic fields. In this paper, we use a
random forest (RF) and an artificial neural network (ANN) to model the
nonlinear behavior of the magnetic fields generated by an eMNS. Both machine
learning methods outperformed the state-of-the-art linear multipole
electromagnet method (LMEM). The RF and the ANN model reduced the root mean
squared error of the LMEM when predicting the field magnitude by around 40% and
80%, respectively, over the entire current range of the eMNS. At high current
regions, especially between 30 and 35 A, the field-magnitude RMSE improvement
of the ANN model over the LMEM was over 35 mT. This study demonstrates the
feasibility of using machine learning methods to model an eMNS for medical
applications, and its ability to account for complex nonlinear behavior at high
currents. The use of machine learning thus shows promise for improving surgical
procedures that use magnetic navigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12035</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12035</id><created>2019-09-26</created><updated>2019-09-27</updated><authors><author><keyname>Ebada</keyname><forenames>Moustafa</forenames></author><author><keyname>Cammerer</keyname><forenames>Sebastian</forenames></author><author><keyname>Elkelesh</keyname><forenames>Ahmed</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>Deep Learning-based Polar Code Design</title><categories>cs.IT cs.LG eess.SP math.IT stat.ML</categories><comments>Allerton2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce a deep learning-based polar code construction
algorithm. The core idea is to represent the information/frozen bit indices of
a polar code as a binary vector which can be interpreted as trainable weights
of a neural network (NN). For this, we demonstrate how this binary vector can
be relaxed to a soft-valued vector, facilitating the learning process through
gradient descent and enabling an efficient code construction. We further show
how different polar code design constraints (e.g., code rate) can be taken into
account by means of careful binary-to-soft and soft-to-binary conversions,
along with rate-adjustment after each learning iteration. Besides its
conceptual simplicity, this approach benefits from having the
&quot;decoder-in-the-loop&quot;, i.e., the nature of the decoder is inherently taken into
consideration while learning (designing) the polar code. We show results for
belief propagation (BP) decoding over both AWGN and Rayleigh fading channels
with considerable performance gains over state-of-the-art construction schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12037</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12037</id><created>2019-09-26</created><authors><author><keyname>Wang</keyname><forenames>Jianqiang</forenames></author><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author><author><keyname>Chen</keyname><forenames>Tong</forenames></author><author><keyname>Liu</keyname><forenames>Haojie</forenames></author><author><keyname>Shen</keyname><forenames>Qiu</forenames></author></authors><title>Learned Point Cloud Geometry Compression</title><categories>cs.CV eess.IV</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel end-to-end Learned Point Cloud Geometry
Compression (a.k.a., Learned-PCGC) framework, to efficiently compress the point
cloud geometry (PCG) using deep neural networks (DNN) based variational
autoencoders (VAE). In our approach, PCG is first voxelized, scaled and
partitioned into non-overlapped 3D cubes, which is then fed into stacked 3D
convolutions for compact latent feature and hyperprior generation. Hyperpriors
are used to improve the conditional probability modeling of latent features. A
weighted binary cross-entropy (WBCE) loss is applied in training while an
adaptive thresholding is used in inference to remove unnecessary voxels and
reduce the distortion. Objectively, our method exceeds the geometry-based point
cloud compression (G-PCC) algorithm standardized by well-known Moving Picture
Experts Group (MPEG) with a significant performance margin, e.g., at least 60%
BD-Rate (Bjontegaard Delta Rate) gains, using common test datasets.
Subjectively, our method has presented better visual quality with smoother
surface reconstruction and appealing details, in comparison to all existing
MPEG standard compliant PCC methods. Our method requires about 2.5MB parameters
in total, which is a fairly small size for practical implementation, even on
embedded platform. Additional ablation studies analyze a variety of aspects
(e.g., cube size, kernels, etc) to explore the application potentials of our
learned-PCGC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12047</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12047</id><created>2019-09-26</created><updated>2019-09-27</updated><authors><author><keyname>Argus</keyname><forenames>Max</forenames></author><author><keyname>Schaefer-Prokop</keyname><forenames>Cornelia</forenames></author><author><keyname>Lynch</keyname><forenames>David A.</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author></authors><title>Function Follows Form: Regression from Complete Thoracic Computed
  Tomography Scans</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of morbidity
and mortality. While COPD diagnosis is based on lung function tests, early
stages and progression of different aspects of the disease can be visible and
quantitatively assessed on computed tomography (CT) scans. Many studies have
been published that quantify imaging biomarkers related to COPD. In this paper
we present a convolutional neural network that directly computes visual
emphysema scores and predicts the outcome of lung function tests for 195 CT
scans from the COPDGene study. Contrary to previous work, the proposed method
does not encode any specific prior knowledge about what to quantify, but it is
trained end-to-end with a set of 1424 CT scans for which the output parameters
were available. The network provided state-of-the-art results for these tasks:
Visual emphysema scores are comparable to those assessed by trained human
observers; COPD diagnosis from estimated lung function reaches an area under
the ROC curve of 0.94, outperforming prior art. The method is easily
generalizable to other situations where information from whole scans needs to
be summarized in single quantities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12065</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12065</id><created>2019-09-26</created><updated>2019-10-03</updated><authors><author><keyname>Lema</keyname><forenames>Gebrehiwet Gebrekrstos</forenames></author><author><keyname>Hailu</keyname><forenames>Dawit Hadush</forenames></author></authors><title>Feasibility study of antenna synthesis using hyper beamforming</title><categories>eess.SP</categories><doi>10.1016/j.heliyon.2019.e01230</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Wireless communication requires an effective antenna synthesis that
characterizes adequate infrastructures to provide the broader bandwidth and
reduced interference. Antenna design with minimal signal degradation, optimal
gain directive main beam to sustain minimal loss has been a hot issue among
many communication engineers for several years. In this paper, the effects of
eccentricity of the antenna, element-spacing, number of elliptical rings and
number of elements are evaluated. For efficient antenna synthesis, deep Side
Lobe Level (SLL) reduction and superior directivity are critical. We have also
studied the significance of hyper beamforming in Elliptical Cylindrical Antenna
Array (ECAA) in comparison to the geometric configuration of the antenna
parameters (eccentricity of the antenna, element-spacing, number of elliptical
rings and number of elements). The hyper beam exponent has resulted in flexible
pattern synthesis while simultaneously reducing the side lobe of the proposed
antenna array, thus decreasing the SLL and increasing directivity that are
vital for wideband applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12077</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12077</id><created>2019-09-26</created><updated>2020-02-20</updated><authors><author><keyname>Zhong</keyname><forenames>Yaofeng Desmond</forenames></author><author><keyname>Dey</keyname><forenames>Biswadip</forenames></author><author><keyname>Chakraborty</keyname><forenames>Amit</forenames></author></authors><title>Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control</title><categories>cs.LG cs.SY eess.SY physics.comp-ph stat.ML</categories><journal-ref>International Conference on Learning Representations (ICLR 2020);
  https://openreview.net/forum?id=ryxmb1rKDS</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning
framework which can infer the dynamics of a physical system, given by an
ordinary differential equation (ODE), from observed state trajectories. To
achieve better generalization with fewer training samples, SymODEN incorporates
appropriate inductive bias by designing the associated computation graph in a
physics-informed manner. In particular, we enforce Hamiltonian dynamics with
control to learn the underlying dynamics in a transparent way, which can then
be leveraged to draw insight about relevant physical aspects of the system,
such as mass and potential energy. In addition, we propose a parametrization
which can enforce this Hamiltonian formalism even when the generalized
coordinate data is embedded in a high-dimensional space or we can only access
velocity data instead of generalized momentum. This framework, by offering
interpretable, physically-consistent models for physical systems, opens up new
possibilities for synthesizing model-based control strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12083</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12083</id><created>2019-09-26</created><authors><author><keyname>Coviello</keyname><forenames>L.</forenames></author><author><keyname>Cristoforetti</keyname><forenames>M.</forenames></author><author><keyname>Jurman</keyname><forenames>G.</forenames></author><author><keyname>Furlanello</keyname><forenames>C.</forenames></author></authors><title>In-field grape berries counting for yield estimation using dilated CNNs</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital technologies ignited a revolution in the agrifood domain known as
precision agriculture: a main question for enabling precision agriculture at
scale is if accurate product quality control can be made available at minimal
cost, leveraging existing technologies and agronomists' skills. As a
contribution along this direction we demonstrate a tool for accurate fruit
yield estimation from smartphone cameras, by adapting Deep Learning algorithms
originally developed for crowd counting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12111</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12111</id><created>2019-09-26</created><authors><author><keyname>Zhou</keyname><forenames>Jianhang</forenames></author><author><keyname>Zeng</keyname><forenames>Shaoning</forenames></author><author><keyname>Zhang</keyname><forenames>Bob</forenames></author></authors><title>Two-stage Image Classification Supervised by a Single Teacher Single
  Student Model</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by 30th British Machine Vision Conference (BMVC2019)</comments><report-no>#155</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-stage strategy has been widely used in image classification. However,
these methods barely take the classification criteria of the first stage into
consideration in the second prediction stage. In this paper, we propose a novel
two-stage representation method (TSR), and convert it to a Single-Teacher
Single-Student (STSS) problem in our two-stage image classification framework.
We seek the nearest neighbours of the test sample to choose candidate target
classes. Meanwhile, the first stage classifier is formulated as the teacher,
which holds the classification scores. The samples of the candidate classes are
utilized to learn a student classifier based on L2-minimization in the second
stage. The student will be supervised by the teacher classifier, which approves
the student only if it obtains a higher score. In actuality, the proposed
framework generates a stronger classifier by staging two weaker classifiers in
a novel way. The experiments conducted on several face and object databases
show that our proposed framework is effective and outperforms multiple popular
classification methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12116</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12116</id><created>2019-09-25</created><updated>2020-02-03</updated><authors><author><keyname>Sim</keyname><forenames>Byeongsu</forenames></author><author><keyname>Oh</keyname><forenames>Gyutaek</forenames></author><author><keyname>Kim</keyname><forenames>Jeongsol</forenames></author><author><keyname>Jung</keyname><forenames>Chanyong</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The penalized least squares (PLS) is a classic method to inverse problems,
where a regularization term is added to stabilize the solution. Optimal
transport (OT) is another mathematical framework for computer vision tasks that
provides means to transport one measure to another at minimal cost. The
cycle-consistent generative adversarial network (cycleGAN) is a recent
extension of GAN to learn target distributions with less mode collapsing
behavior. Although similar in that no supervised training is required, the
algorithms look different, so the mathematical relationship between these
approaches is not clear. In this article, we provide an important advance to
unveil the missing link. Specifically, we reveal that a cycleGAN architecture
is originated from formulating a dual OT problem, by using the consistency
constraint of PLS as a regularization term in the primal OT problem. This
suggests that cycleGAN can be considered stochastic generalization of classical
PLS approaches. Our derivation is so general that various types of cycleGAN
architectures can be easily derived by merely changing the transport cost. As
proofs of concept, we provide three distinct cycleGAN architecture for various
biomedical imaging problems, such as accelerated magnetic resonance imaging
(MRI), super-resolution microscopy, and low-dose x-ray computed tomography
(CT). Experimental results confirm the efficacy and the flexibility of the
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12120</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12120</id><created>2019-09-24</created><authors><author><keyname>Balevi</keyname><forenames>Eren</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Autoencoder-Based Error Correction Coding for One-Bit Quantization</title><categories>cs.IT cs.LG eess.SP math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel deep learning-based error correction coding
scheme for AWGN channels under the constraint of one-bit quantization in the
receivers. Specifically, it is first shown that the optimum error correction
code that minimizes the probability of bit error can be obtained by perfectly
training a special autoencoder, in which &quot;perfectly&quot; refers to converging the
global minima. However, perfect training is not possible in most cases. To
approach the performance of a perfectly trained autoencoder with a suboptimum
training, we propose utilizing turbo codes as an implicit regularization, i.e.,
using a concatenation of a turbo code and an autoencoder. It is empirically
shown that this design gives nearly the same performance as to the
hypothetically perfectly trained autoencoder, and we also provide a theoretical
proof of why that is so. The proposed coding method is as bandwidth efficient
as the integrated (outer) turbo code, since the autoencoder exploits the excess
bandwidth from pulse shaping and packs signals more intelligently thanks to
sparsity in neural networks. Our results show that the proposed coding scheme
at finite block lengths outperforms conventional turbo codes even for QPSK
modulation. Furthermore, the proposed coding method can make one-bit
quantization operational even for 16-QAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12122</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12122</id><created>2019-09-24</created><authors><author><keyname>Hatalis</keyname><forenames>Kostas</forenames></author><author><keyname>Lamadrid</keyname><forenames>Alberto J.</forenames></author><author><keyname>Scheinberg</keyname><forenames>Katya</forenames></author><author><keyname>Kishore</keyname><forenames>Shalinee</forenames></author></authors><title>A Novel Smoothed Loss and Penalty Function for Noncrossing Composite
  Quantile Estimation via Deep Neural Networks</title><categories>eess.SP cs.LG</categories><comments>12 pages, IEEE Transactions Journal format. arXiv admin note:
  substantial text overlap with arXiv:1710.01720</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty analysis in the form of probabilistic forecasting can
significantly improve decision making processes in the smart power grid when
integrating renewable energy sources such as wind. Whereas point forecasting
provides a single expected value, probabilistic forecasts provide more
information in the form of quantiles, prediction intervals, or full predictive
densities. Traditionally quantile regression is applied for such forecasting
and recently quantile regression neural networks have become popular for
weather and renewable energy forecasting. However, one major shortcoming of
composite quantile estimation in neural networks is the quantile crossover
problem. This paper analyzes the effectiveness of a novel smoothed loss and
penalty function for neural network architectures to prevent the quantile
crossover problem. Its efficacy is examined on the wind power forecasting
problem. A numerical case study is conducted using publicly available wind data
from the Global Energy Forecasting Competition 2014. Multiple quantiles are
estimated to form 10\%, to 90\% prediction intervals which are evaluated using
a quantile score and reliability measures. Benchmark models such as the
persistence and climatology distributions, multiple quantile regression, and
support vector quantile regression are used for comparison where results
demonstrate the proposed approach leads to improved performance while
preventing the problem of overlapping quantile estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12155</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12155</id><created>2019-09-25</created><authors><author><keyname>Sivaganesh</keyname><forenames>G.</forenames></author><author><keyname>Arulgnanam</keyname><forenames>A.</forenames></author><author><keyname>Seethalakshmi</keyname><forenames>A. N.</forenames></author></authors><title>Generalized analytical solutions for secure transmission of signals
  using a simple communication scheme with numerical and experimental
  confirmation</title><categories>eess.SP nlin.CD</categories><comments>23 pages, 10 figures</comments><msc-class>34C15</msc-class><journal-ref>Chinese Journal of Physics (2019)</journal-ref><doi>10.1016/j.cjph.2019.10.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel explicit analytical solution is reported for the transmission and
recovery of information signals using a simple communication scheme. Analytical
solutions are obtained for the normalized state equations of coupled
second-order chaotic transmitter and receiver systems embedding the information
signal. The analytical solution of the difference system obtained from the
state equations of the transmitter and receiver systems has been identified as
a measure of the recovered information signal which is transmitted securely by
chaotic masking. The analytical solutions are used to reveal the nature of
synchronization and the enhancement of the amplitude of recovered information
signal. The difference signal of the coupled state variables indicating the
recovered information signal obtained through numerical simulations is
presented to validate the analytical results. The electronic circuit
experimental results are presented to confirm the analytical and numerical
results of the communication scheme discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12160</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12160</id><created>2019-09-26</created><authors><author><keyname>Dia</keyname><forenames>Mohamad</forenames></author><author><keyname>Savary</keyname><forenames>Elodie</forenames></author><author><keyname>Melchior</keyname><forenames>Martin</forenames></author><author><keyname>Courbin</keyname><forenames>Frederic</forenames></author></authors><title>Galaxy Image Simulation Using Progressive GANs</title><categories>cs.LG astro-ph.GA eess.IV stat.ML</categories><comments>Submitted to the Astronomical Data Analysis Software &amp; Systems
  Conference (ADASS), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we provide an efficient and realistic data-driven approach to
simulate astronomical images using deep generative models from machine
learning. Our solution is based on a variant of the generative adversarial
network (GAN) with progressive training methodology and Wasserstein cost
function. The proposed solution generates naturalistic images of galaxies that
show complex structures and high diversity, which suggests that data-driven
simulations using machine learning can replace many of the expensive
model-driven methods used in astronomical data processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12170</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12170</id><created>2019-09-26</created><authors><author><keyname>Kaushik</keyname><forenames>Aryan</forenames></author><author><keyname>Tsinos</keyname><forenames>Christos</forenames></author><author><keyname>Vlachos</keyname><forenames>Evangelos</forenames></author><author><keyname>Thompson</keyname><forenames>John</forenames></author></authors><title>Energy Efficient ADC Bit Allocation and Hybrid Combining for Millimeter
  Wave MIMO Systems</title><categories>eess.SP</categories><journal-ref>2019 IEEE Global Communications Conference (GLOBECOM)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low resolution analog-to-digital converters (ADCs) can be employed to improve
the energy efficiency (EE) of a wireless receiver since the power consumption
of each ADC is exponentially related to its sampling resolution and the
hardware complexity. In this paper, we aim to jointly optimize the sampling
resolution, i.e., the number of ADC bits, and analog/digital hybrid combiner
matrices which provides highly energy efficient solutions for millimeter wave
multiple-input multiple output systems. A novel decomposition of the hybrid
combiner to three parts is introduced: the analog combiner matrix, the bit
resolution matrix and the baseband combiner matrix. The unknown matrices are
computed as the solution to a matrix factorization problem where the optimal,
fully digital combiner is approximated by the product of these matrices. An
efficient solution based on the alternating direction method of multipliers is
proposed to solve this problem. The simulation results show that the proposed
solution achieves high EE performance when compared with existing benchmark
techniques that use fixed ADC resolutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12202</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12202</id><created>2019-09-26</created><authors><author><keyname>Padoan</keyname><forenames>Alberto</forenames></author><author><keyname>Forni</keyname><forenames>Fulvio</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author></authors><title>The $\mathcal{H}_{\infty,p}$ norm as the differential
  $\mathcal{L}_{2,p}$ gain of a $p$-dominant system</title><categories>math.OC cs.SY eess.SY</categories><comments>6 pages, 3 figures, 58th IEEE Conf. Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The differential $\mathcal{L}_{2,p}$ gain of a linear, time-invariant,
$p$-dominant system is shown to coincide with the $\mathcal{H}_{\infty,p}$ norm
of its transfer function $G$, defined as the essential supremum of the absolute
value of $G$ over a vertical strip in the complex plane such that $p$ poles of
$G$ lie to right of the strip. The close analogy between the
$\mathcal{H}_{\infty,p}$ norm and the classical $\mathcal{H}_{\infty}$ norm
suggests that robust dominance of linear systems can be studied along the same
lines as robust stability. This property can be exploited in the analysis and
design of nonlinear uncertain systems that can be decomposed as the feedback
interconnection of a linear, time-invariant system with bounded gain
uncertainties or nonlinearities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12208</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12208</id><created>2019-09-26</created><authors><author><keyname>Zorila</keyname><forenames>Catalin</forenames></author><author><keyname>Boeddeker</keyname><forenames>Christoph</forenames></author><author><keyname>Doddipatla</keyname><forenames>Rama</forenames></author><author><keyname>Haeb-Umbach</keyname><forenames>Reinhold</forenames></author></authors><title>An Investigation into the Effectiveness of Enhancement in ASR Training
  and Test for CHiME-5 Dinner Party Transcription</title><categories>cs.CL eess.AS</categories><comments>Accepted for ASRU 2019</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the strong modeling power of neural network acoustic models, speech
enhancement has been shown to deliver additional word error rate improvements
if multi-channel data is available. However, there has been a longstanding
debate whether enhancement should also be carried out on the ASR training data.
In an extensive experimental evaluation on the acoustically very challenging
CHiME-5 dinner party data we show that: (i) cleaning up the training data can
lead to substantial error rate reductions, and (ii) enhancement in training is
advisable as long as enhancement in test is at least as strong as in training.
This approach stands in contrast and delivers larger gains than the common
strategy reported in the literature to augment the training database with
additional artificially degraded speech. Together with an acoustic model
topology consisting of initial CNN layers followed by factorized TDNN layers we
achieve with 41.6% and 43.2% WER on the DEV and EVAL test sets, respectively, a
new single-system state-of-the-art result on the CHiME-5 data. This is a 8%
relative improvement compared to the best word error rate published so far for
a speech recognizer without system combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12216</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12216</id><created>2019-09-26</created><authors><author><keyname>Flaspohler</keyname><forenames>Genevieve</forenames></author><author><keyname>Preston</keyname><forenames>Victoria</forenames></author><author><keyname>Michel</keyname><forenames>Anna P. M.</forenames></author><author><keyname>Girdhar</keyname><forenames>Yogesh</forenames></author><author><keyname>Roy</keyname><forenames>Nicholas</forenames></author></authors><title>Information-Guided Robotic Maximum Seek-and-Sample in Partially
  Observable Continuous Environments</title><categories>cs.RO cs.SY eess.SY</categories><comments>8 pages, 8 figures, To appear in the proceedings of IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS) 2019 Macau</comments><journal-ref>IEEE Robotics and Automation Letters (RA-L) 2019</journal-ref><doi>10.1109/LRA.2019.2929997</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present PLUMES, a planner to localizing and collecting samples at the
global maximum of an a priori unknown and partially observable continuous
environment. The &quot;maximum-seek-and-sample&quot; (MSS) problem is pervasive in the
environmental and earth sciences. Experts want to collect scientifically
valuable samples at an environmental maximum (e.g., an oil-spill source), but
do not have prior knowledge about the phenomenon's distribution. We formulate
the MSS problem as a partially-observable Markov decision process (POMDP) with
continuous state and observation spaces, and a sparse reward signal. To solve
the MSS POMDP, PLUMES uses an information-theoretic reward heuristic with
continous-observation Monte Carlo Tree Search to efficiently localize and
sample from the global maximum. In simulation and field experiments, PLUMES
collects more scientifically valuable samples than state-of-the-art planners in
a diverse set of environments, with various platforms, sensors, and challenging
real-world conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12217</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12217</id><created>2019-09-26</created><authors><author><keyname>Asli</keyname><forenames>AE. Niaraki</forenames></author><author><keyname>Jannesari</keyname><forenames>A.</forenames></author></authors><title>A Simulation of UAV Power Optimization via Reinforcement Learning</title><categories>eess.SP cs.AI cs.LG</categories><comments>9 Pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates a reinforcement learning approach to the optimization
of power consumption in a UAV system in a simplified data collection task.
Here, the architecture consists of two common reinforcement learning
algorithms, Q-learning and Sarsa, which are implemented through a combination
of robot operating system (ROS) and Gazebo. The effect of wind as an
influential factor was simulated. The implemented algorithm resulted in
reasonable adjustment of UAV actions to the wind field in order to minimize its
power consumption during task completion over the domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12224</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12224</id><created>2019-09-26</created><updated>2019-10-01</updated><authors><author><keyname>Liu</keyname><forenames>Wen</forenames></author><author><keyname>Piao</keyname><forenames>Zhixin</forenames></author><author><keyname>Min</keyname><forenames>Jie</forenames></author><author><keyname>Luo</keyname><forenames>Wenhan</forenames></author><author><keyname>Ma</keyname><forenames>Lin</forenames></author><author><keyname>Gao</keyname><forenames>Shenghua</forenames></author></authors><title>Liquid Warping GAN: A Unified Framework for Human Motion Imitation,
  Appearance Transfer and Novel View Synthesis</title><categories>cs.CV cs.LG eess.IV</categories><comments>accepted by ICCV2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the human motion imitation, appearance transfer, and novel view
synthesis within a unified framework, which means that the model once being
trained can be used to handle all these tasks. The existing task-specific
methods mainly use 2D keypoints (pose) to estimate the human body structure.
However, they only expresses the position information with no abilities to
characterize the personalized shape of the individual person and model the
limbs rotations. In this paper, we propose to use a 3D body mesh recovery
module to disentangle the pose and shape, which can not only model the joint
location and rotation but also characterize the personalized body shape. To
preserve the source information, such as texture, style, color, and face
identity, we propose a Liquid Warping GAN with Liquid Warping Block (LWB) that
propagates the source information in both image and feature spaces, and
synthesizes an image with respect to the reference. Specifically, the source
features are extracted by a denoising convolutional auto-encoder for
characterizing the source identity well. Furthermore, our proposed method is
able to support a more flexible warping from multiple sources. In addition, we
build a new dataset, namely Impersonator (iPER) dataset, for the evaluation of
human motion imitation, appearance transfer, and novel view synthesis.
Extensive experiments demonstrate the effectiveness of our method in several
aspects, such as robustness in occlusion case and preserving face identity,
shape consistency and clothes details. All codes and datasets are available on
https://svip-lab.github.io/project/impersonator.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12232</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12232</id><created>2019-09-19</created><authors><author><keyname>Bayerl</keyname><forenames>Sebastian P.</forenames></author><author><keyname>Riedhammer</keyname><forenames>Korbinian</forenames></author></authors><title>A Comparison of Hybrid and End-to-End Models for Syllable Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS stat.ML</categories><comments>22th International Conference of Text, Speech and Dialogue TSD2019</comments><doi>10.1007/978-3-030-27947-9_30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a comparison of a traditional hybrid speech recognition
system (kaldi using WFST and TDNN with lattice-free MMI) and a lexicon-free
end-to-end (TensorFlow implementation of multi-layer LSTM with CTC training)
models for German syllable recognition on the Verbmobil corpus. The results
show that explicitly modeling prior knowledge is still valuable in building
recognition systems. With a strong language model (LM) based on syllables, the
structured approach significantly outperforms the end-to-end model. The best
word error rate (WER) regarding syllables was achieved using kaldi with a
4-gram LM, modeling all syllables observed in the training set. It achieved
10.0% WER w.r.t. the syllables, compared to the end-to-end approach where the
best WER was 27.53%. The work presented here has implications for building
future recognition systems that operate independent of a large vocabulary, as
typically used in a tasks such as recognition of syllabic or agglutinative
languages, out-of-vocabulary techniques, keyword search indexing and medical
speech processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12240</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12240</id><created>2019-09-26</created><authors><author><keyname>Termehchi</keyname><forenames>Atefeh.</forenames></author><author><keyname>Rasti</keyname><forenames>Mehdi.</forenames></author></authors><title>Power-efficient Sampling Time and Resource Allocation in Cyber Physical
  Systems with Industrial Application</title><categories>cs.NI eess.SP</categories><comments>7 pages,8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cyber Physical Systems (CPSs) are the result of convergence of computation,
networking, and control of physical process. In this paper, we consider an
industrial CPS consisting of several control plants and Rate Constrained (RC)
users that communicate via a single cell OFDMA network. The problem of jointly
determining the sampling instant of each control plant and allocating power and
sub-carrier, in the CPS, is formulated. The problem is a multi objective
optimization with aims of determining the next maximum allowable sampling
instant of each control plant and minimizing the power consumption in uplink
and downlink, considering the dynamics and desired performance of control
plants, the quality of service requirement of RC users, power and sub-carrier
constraints. To solve the multi objective optimization problem, a novel
approach is proposed which decomposes the optimization problem into two smaller
loosely coupled problems. we show the effectiveness of the proposed approach
through simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12254</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12254</id><created>2019-09-26</created><authors><author><keyname>Riera-Palou</keyname><forenames>Felip</forenames></author><author><keyname>Femenias</keyname><forenames>Guillem</forenames></author></authors><title>Decentralization Issues in Cell-free Massive MIMO Networks with
  Zero-Forcing Precoding</title><categories>eess.SP</categories><comments>Presented at 57th IEEE Annual Allerton Conference on Communication,
  Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cell-free massive MIMO (CF-M-MIMO) systems represent an evolution of the
classical cellular architecture that has dominated the mobile landscape for
decades. In CF-M-MIMO, a central processing unit (CPU) controls a multitude of
access points (APs) that are irregularly scattered throughout the coverage area
effectively becoming a fully distributed implementation of the M-MIMO
technology. As such, it inherits many of the key properties that have made
M-MIMO one of the physical layer pillars of 5G systems while opening the door
to new features not available in M-MIMO. Among the latest is the possibility of
performing the precoding at the CPU (centralized) or at the APs (distributed)
with the former known to offer much better performance at the cost of having to
collect all the relevant channel state information (CSI) at the CPU. Realistic
deployments of cell-free systems are likely to require more than one CPU when
the area to be covered is large, thus a critical issue that needs to be solved
is how these multiple CPUs should be interconnected. This paper analyzes and
proposes designs for different degrees of interconnectivity among the CPUs for
the specific case of centralized zero-forcing precoding. Results show that a
modest form of CPU interconnection can boost very significantly the max-min
rate performance so prevalent in CF-M-MIMO architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12268</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12268</id><created>2019-09-26</created><authors><author><keyname>Zhan</keyname><forenames>Huixin</forenames></author><author><keyname>Cao</keyname><forenames>Yongcan</forenames></author></authors><title>Relationship Explainable Multi-objective Reinforcement Learning with
  Semantic Explainability Generation</title><categories>eess.SY cs.LG cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving multi-objective optimization problems is important in various
applications where users are interested in obtaining optimal policies subject
to multiple, yet often conflicting objectives. A typical approach to obtain
optimal policies is to first construct a loss function that is based on the
scalarization of individual objectives, and then find the optimal policy that
minimizes the loss. However, optimizing the scalarized (and weighted) loss does
not necessarily provide guarantee of high performance on each possibly
conflicting objective because it is challenging to assign the right weights
without knowing the relationship among these objectives. Moreover, the
effectiveness of these gradient descent algorithms is limited by the agent's
ability to explain their decisions and actions to human users. The purpose of
this study is two-fold. First, we propose a vector value function based
multi-objective reinforcement learning (V2f-MORL) approach that seeks to
quantify the inter-objective relationship via reinforcement learning (RL) when
the impact of one objective on others is unknown a prior. In particular, we
construct one actor and multiple critics that can co-learn the policy and
inter-objective relationship matrix (IORM), quantifying the impact of
objectives on each other, in an iterative way. Second, we provide a semantic
representation that can uncover the trade-off of decision policies made by
users to reconcile conflicting objectives based on the proposed V2f-MORL
approach for the explainability of the generated behaviors subject to given
optimization objectives. We demonstrate the effectiveness of the proposed
approach via a MuJoCo based robotics case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12274</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12274</id><created>2019-09-26</created><authors><author><keyname>Kurdila</keyname><forenames>Andrew J.</forenames></author><author><keyname>Guo</keyname><forenames>Jia</forenames></author><author><keyname>Paruchuri</keyname><forenames>Sai Tej</forenames></author><author><keyname>Bobade</keyname><forenames>Parag</forenames></author></authors><title>Persistence of Excitation in Reproducing Kernel Hilbert Spaces, Positive
  Limit Sets, and Smooth Manifolds</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the relationship between the positive limit sets of
continuous semiflows and the newly introduced definition of persistently
excited (PE) sets and associated subspaces of reproducing kernel Hilbert (RKH)
spaces. It is shown that if the RKH space contains a rich collection of cut-off
functions, persistently excited sets are contained as subsets of the positive
limit set of the semiflow. The paper demonstrates how the new PE condition can
be used to guarantee convergence of function estimates in the RKH space
embedding method for adaptive estimation. In particular, the paper is applied
to uncertain ODE systems with positive limit sets given by certain types of
smooth manifolds, and it establishes convergence of adaptive function estimates
over the manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12286</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12286</id><created>2019-09-26</created><authors><author><keyname>Nazari</keyname><forenames>Mostafa</forenames></author><author><keyname>Shiri</keyname><forenames>Isaac</forenames></author><author><keyname>Hajianfar</keyname><forenames>Ghasem</forenames></author><author><keyname>Oveisi</keyname><forenames>Niki</forenames></author><author><keyname>Abdollahi</keyname><forenames>Hamid</forenames></author><author><keyname>Deevband</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Oveisi</keyname><forenames>Mehrdad</forenames></author></authors><title>Non-Invasive Fuhrman Grading of Clear Cell Renal Cell Carcinoma Using
  Computed Tomography Radiomics Features and Machine Learning</title><categories>physics.med-ph eess.IV q-bio.TO</categories><comments>20 Pages, 2 Figures, 4 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To identify optimal classification methods for computed tomography
(CT) radiomics-based preoperative prediction of clear cells renal cell
carcinoma (ccRCC) grade. Methods and material: Seventy one ccRCC patients were
included in the study. Three image preprocessing techniques (Laplacian of
Gaussian, wavelet filter, and discretization of the intensity values) were
applied on tumor volumes. In total, 2530 radiomics features (tumor shape and
size, intensity statistics, and texture) were extracted from each segmented
tumor volume. Univariate analysis was performed to assess the association of
each feature with the histological condition. In the case of multivariate
analysis, the following was implemented: three feature selection including the
least absolute shrinkage and selection operator (LASSO), students t-test and
minimum Redundancy Maximum Relevance (mRMR) algorithms. These selected features
were then used to construct three classification models (SVM, random forest,
and logistic regression) to discriminate the high from low-grade ccRCC at
nephrectomy. Lastly, multivariate model performance was evaluated on the
bootstrapped validation cohort using the area under receiver operating
characteristic curve (AUC). Results: Univariate analysis demonstrated that
among different image sets, 128 bin discretized images have statistically
significant different (q-value &lt; 0.05) texture parameters with a mean of AUC
0.74 (q-value &lt; 0.05). The three ML-based classifier shows proficient
discrimination of the high from low-grade ccRCC. The AUC was 0.78 in logistic
regression, 0.62 in random forest, and 0.83 in SVM model, respectively.
Conclusion: Radiomics features can be a useful and promising non-invasive
method for preoperative evaluation of ccRCC Fuhrman grades. Key words: RCC,
Radiomics, Machine Learning, Computed Tomography
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12288</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12288</id><created>2019-09-26</created><authors><author><keyname>Liu</keyname><forenames>Guangyi</forenames></author><author><keyname>Salehi</keyname><forenames>Seyedmohammad</forenames></author><author><keyname>Bala</keyname><forenames>Erdem</forenames></author><author><keyname>Shen</keyname><forenames>Chien-Chung</forenames></author><author><keyname>Cimini</keyname><forenames>Leonard J.</forenames></author></authors><title>Communication-Constrained Routing and Traffic Control for Autonomous
  Vehicles</title><categories>eess.SY cs.NI cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous vehicles (AV) is an advanced technology that can bring
convenience, improve the road-network throughput, and reduce traffic accidents.
To enable higher levels of automation (LoA), massive amounts of sensory data
need to be uploaded to the network for processing, and then, maneuvering
decisions must be returned to the AV. Furthermore, passengers might have a
higher transmission rate demands for various data-hungry and delay-sensitive
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12289</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12289</id><created>2019-09-26</created><updated>2019-10-02</updated><authors><author><keyname>Dou</keyname><forenames>Qingyun</forenames></author><author><keyname>Lu</keyname><forenames>Yiting</forenames></author><author><keyname>Efiong</keyname><forenames>Joshua</forenames></author><author><keyname>Gales</keyname><forenames>Mark J. F.</forenames></author></authors><title>Attention Forcing for Sequence-to-sequence Model Training</title><categories>cs.LG cs.CL eess.AS stat.ML</categories><comments>11 pages, 4 figures, conference</comments><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Auto-regressive sequence-to-sequence models with attention mechanism have
achieved state-of-the-art performance in many tasks such as machine translation
and speech synthesis. These models can be difficult to train. The standard
approach, teacher forcing, guides a model with reference output history during
training. The problem is that the model is unlikely to recover from its
mistakes during inference, where the reference output is replaced by generated
output. Several approaches deal with this problem, largely by guiding the model
with generated output history. To make training stable, these approaches often
require a heuristic schedule or an auxiliary classifier. This paper introduces
attention forcing, which guides the model with generated output history and
reference attention. This approach can train the model to recover from its
mistakes, in a stable fashion, without the need for a schedule or a classifier.
In addition, it allows the model to generate output sequences aligned with the
references, which can be important for cascaded systems like many speech
synthesis systems. Experiments on speech synthesis show that attention forcing
yields significant performance gain. Experiments on machine translation show
that for tasks where various re-orderings of the output are valid, guiding the
model with generated output history is challenging, while guiding the model
with reference attention is beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12314</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12314</id><created>2019-09-26</created><authors><author><keyname>Salazar-Colores</keyname><forenames>Sebasti&#xe1;n</forenames></author><author><keyname>Alberto-Moreno</keyname><forenames>Hugo</forenames></author><author><keyname>Flores</keyname><forenames>Gerardo</forenames></author><author><keyname>Ortiz-Echeverri</keyname><forenames>C&#xe9;sar Javier</forenames></author></authors><title>Laparoscopy Surgery CO2 Removal via Generative Adversary Network and
  Dark Channel Prior</title><categories>physics.med-ph eess.IV</categories><comments>in Spanish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Laparoscopic surgery uses a thin tube with a camera called a laparoscope,
which is inserted into the abdomen through a small incision in the skin during
surgery. This allows to a surgeon to see inside of the body without causing
significant injury to the patient. These characteristics make laparoscopy a
widely used technique. In laparoscopic surgery, image quality can be severely
degraded by surgical smoke caused by the use of tissue dissection tools which
reduces the visibility of the observed organs and tissues. This lack of
visibility increases the possibility of errors and surgery time with the
consequences that this may have on the patient's health. In this paper, we
introduce a novel hybrid approach for computational smoke removal which is
based on the combination of a widely dehazing method used: the dark channel
prior (DCP) and a pixel-to-pixel neural network approach: Generative Adversary
Network (GAN). The experimental results have proven that the proposed method
achieves a better performance than the individual results of the DCP and GAN in
terms of restoration quality, obtaining a PSNR value of 25 and SSIM index of
0.88 over a test set of synthetic images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12321</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12321</id><created>2019-09-26</created><authors><author><keyname>Bloch</keyname><forenames>Anthony</forenames></author><author><keyname>Camarinha</keyname><forenames>Margarida</forenames></author><author><keyname>Colombo</keyname><forenames>Leonardo</forenames></author></authors><title>Variational point-obstacle avoidance on Riemannian manifolds</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter we study variational obstacle avoidance problems on complete
Riemannian manifolds. The problem consists of minimizing an energy functional
depending on the velocity, covariant acceleration and a repulsive potential
function used to avoid a static obstacle on the manifold, among a set of
admissible curves. We derive the dynamical equations for extrema of the
variational problem, in particular on compact connected Lie groups and
Riemannian symmetric spaces. Numerical examples are presented to illustrate the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12342</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12342</id><created>2019-09-26</created><authors><author><keyname>Kuo</keyname><forenames>Han-Wen</forenames></author><author><keyname>Dorfi</keyname><forenames>Anna E.</forenames></author><author><keyname>Esposito</keyname><forenames>Daniel V.</forenames></author><author><keyname>Wright</keyname><forenames>John N.</forenames></author></authors><title>Compressed Sensing Microscopy with Scanning Line Probes</title><categories>eess.IV cs.CV eess.SP</categories><comments>15 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In applications of scanning probe microscopy, images are acquired by raster
scanning a point probe across a sample. Viewed from the perspective of
compressed sensing (CS), this pointwise sampling scheme is inefficient,
especially when the target image is structured. While replacing point
measurements with delocalized, incoherent measurements has the potential to
yield order-of-magnitude improvements in scan time, implementing the
delocalized measurements of CS theory is challenging. In this paper we study a
partially delocalized probe construction, in which the point probe is replaced
with a continuous line, creating a sensor which essentially acquires line
integrals of the target image. We show through simulations, rudimentary
theoretical analysis, and experiments, that these line measurements can image
sparse samples far more efficiently than traditional point measurements,
provided the local features in the sample are enough separated. Despite this
promise, practical reconstruction from line measurements poses additional
difficulties: the measurements are partially coherent, and real measurements
exhibit nonidealities. We show how to overcome these limitations using natural
strategies (reweighting to cope with coherence, blind calibration for
nonidealities), culminating in an end-to-end demonstration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12346</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12346</id><created>2019-09-26</created><authors><author><keyname>Zheng</keyname><forenames>Yang</forenames></author><author><keyname>Furieri</keyname><forenames>Luca</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author><author><keyname>Li</keyname><forenames>Na</forenames></author></authors><title>On the Parameterization of Stabilizing Controllers using Closed-loop
  Responses</title><categories>math.OC cs.SY eess.SY</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of parameterizing all internally
stabilizing controllers for strictly proper linear time-invariant (LTI) systems
using closed-loop responses. It is known that the set of internally stabilizing
controllers $\mathcal{C}_{\text{stab}}$ is non-convex, but it admits a convex
representation using certain closed-loop maps. A classical result is the Youla
parameterization, and two recent notions are the system-level parameterization
(SLP) and input-output parameterization (IOP). This paper further examines all
possible parameterizations of $\mathcal{C}_{\text{stab}}$ using certain
closed-loop responses. Our main idea is to revisit the external transfer matrix
characterization of internal stability, which uncovers that only four groups of
stable closed-loop transfer matrices are equivalent to internal stability: one
of them is used in SLP, another one is a classical result and is used in IOP,
and the other two are new, leading to two new parameterizations for
$\mathcal{C}_{\text{stab}}$. All these four parameterizations are convex in
term of the respectively introduced parameters, allowing us to use convex
optimization for controller synthesis. These results contribute to a more
complete picture of the notion of \emph{closed-loop convexity} for
parameterizing $\mathcal{C}_{\text{stab}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12349</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12349</id><created>2019-09-26</created><authors><author><keyname>Ellman</keyname><forenames>Douglas</forenames></author><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author></authors><title>Model Predictive Control-Based Battery Scheduling and Incentives to
  Manipulate Demand Response Baselines</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study operations of a battery energy storage system under a baseline-based
demand response (DR) program with an uncertain schedule of DR events.
Baseline-based DR programs may provide undesired incentives to inflate baseline
consumption in non-event days, in order to increase &quot;apparent&quot; DR reduction in
event days and secure higher DR payments. Our goal is to identify and quantify
such incentives. To understand customer decisions, we formulate the problem of
determining hourly battery charging and discharge schedules to minimize
expected net costs, defined as energy purchase costs minus energy export
rebates and DR payments, over a sufficiently long time horizon (e.g., a year).
The complexity of this stochastic optimization problem grows exponentially with
the time horizon considered. To obtain computationally tractable solutions, we
propose using multistage model predictive control with scenario sampling.
Numerical results indicate that our solutions are near optimal (e.g., within 3%
from the optimum in the test cases). Finally, we apply our solutions to study
an example residential customer with solar photovoltaic and battery systems
participating in a typical existing baseline-based DR program. Results reveal
that over 66% of the average apparent load reduction during DR events could
result from inflation of baseline consumption during non-event days.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12361</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12361</id><created>2019-09-26</created><authors><author><keyname>Pozzi</keyname><forenames>Andrea</forenames></author><author><keyname>Torchio</keyname><forenames>Marcello</forenames></author><author><keyname>Braatz</keyname><forenames>Richard D.</forenames></author><author><keyname>Raimondo</keyname><forenames>Davide M.</forenames></author></authors><title>Optimal Charging of an Electric Vehicle Battery Pack: A Real-Time
  Sensitivity-Based MPC approach</title><categories>eess.SY cs.SY</categories><comments>Will be submitted to Journal of Power Sources</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lithium-ion battery packs are usually composed of hundreds of cells arranged
in series and parallel connections. The proper functioning of these complex
devices requires suitable Battery Management Systems (BMSs). Advanced BMSs rely
on mathematical models to assure safety and high performance. While many
approaches have been proposed for the management of single cells, the control
of multiple cells has been less investigated and usually relies on simplified
models such as equivalent circuit models. This paper addresses the management
of a battery pack in which each cell is explicitly modelled as the Single
Particle Model with electrolyte and thermal dynamics. A nonlinear Model
Predictive Control (MPC) is presented for optimally charging the battery pack
while taking voltage and temperature limits on each cell into account. Since
the computational cost of nonlinear MPC grows significantly with the complexity
of the underlying model, a sensitivity-based MPC (sMPC) is proposed, in which
the model adopted is obtained by linearizing the dynamics along a nominal
trajectory that is updated over time. The resulting sMPC optimizations are
quadratic programs which can be solved in real-time even for large battery
packs (e.g. fully electric motorbike with 156 cells) while achieving the same
performance of the nonlinear MPC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12388</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12388</id><created>2019-08-12</created><authors><author><keyname>Omer</keyname><forenames>Ala Eldin</forenames></author><author><keyname>Shaker</keyname><forenames>George</forenames></author><author><keyname>Safavi-Naeini</keyname><forenames>Safieddin</forenames></author></authors><title>Glucose Levels Sensing using Whispering Gallery Modes at mm-Wave Band</title><categories>physics.app-ph eess.SP</categories><comments>4 pages, 4 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, an integrated low-cost and complexity mm-wave structure of
Whispering Gallery Mode (WGM) is proposed for sensing the glucose levels in
mimicking aquatic solutions of concentrations similar to type 2 diabetics. The
bio-sensor is composed of a curved dielectric waveguide coupled to a dielectric
disc resonator that is loaded with the glucose sample under test. The intense
WGM field induced towards the boundary of the DDR is exploited to detect the
slight variations in the dielectric properties of different glucose levels via
tracing the variations in the magnitude of the transmission coefficient S_{21}
in the mm-wave frequency band (49-70 GHz). The WGM resonator shows a high
sensitivity performance (0.025-0.077 dB/(mg/dL)) at the lower-order modes
WGH_{600} and WGH_{700} as demonstrated by simulations in a 3D full-wave EM
solver (Ansys HFSS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12392</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12392</id><created>2019-09-25</created><updated>2019-11-26</updated><authors><author><keyname>Belmekki</keyname><forenames>Baha Eddine Youcef</forenames></author><author><keyname>Hamza</keyname><forenames>Abdelkrim</forenames></author><author><keyname>Escrig</keyname><forenames>Beno&#xee;t</forenames></author></authors><title>Non-Orthogonal Multiple Access Performance for Millimeter Wave in
  Vehicular Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1904.11022,
  arXiv:1909.01989</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we study the performance of millimeter wave (mmWave) vehicular
communications (VCs) using non-orthogonal multiple access scheme (NOMA) at road
intersections, since there areas are more prone to accidents. We study the case
when the intersection involves two perpendicular lanes, we then extend the
study to an intersection with several lanes. The transmission occurs between a
source, and two destinations. The transmission experiences interference
originated from a set of vehicles that are distributed as a Poisson point
process (PPP). Our analysis includes the effects of blockage from buildings and
vehicles at intersections. Closed form outage probability expressions are
obtained. We show that as the nodes reach the intersection, the outage
probability increases. Counter-intuitively, we show that the non line of sigh
(NLOS) scenario has a better performance than the line of sigh (LOS) scenario.
Finally, we compare the performance of mmWave NOMA with OMA, and we show that
NOMA offers a significant improvement over OMA mmWave vehicular networks. The
analysis is verified by Monte-Carlo simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12408</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12408</id><created>2019-09-26</created><updated>2020-02-06</updated><authors><author><keyname>Shangguan</keyname><forenames>Yuan</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Liang</keyname><forenames>Qiao</forenames></author><author><keyname>Alvarez</keyname><forenames>Raziel</forenames></author><author><keyname>McGraw</keyname><forenames>Ian</forenames></author></authors><title>Optimizing Speech Recognition For The Edge</title><categories>cs.CL cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While most deployed speech recognition systems today still run on servers, we
are in the midst of a transition towards deployments on edge devices. This leap
to the edge is powered by the progression from traditional speech recognition
pipelines to end-to-end (E2E) neural architectures, and the parallel
development of more efficient neural network topologies and optimization
techniques. Thus, we are now able to create highly accurate speech recognizers
that are both small and fast enough to execute on typical mobile devices. In
this paper, we begin with a baseline RNN-Transducer architecture comprised of
Long Short-Term Memory (LSTM) layers. We then experiment with a variety of more
computationally efficient layer types, as well as apply optimization techniques
like neural connection pruning and parameter quantization to construct a small,
high quality, on-device speech recognizer that is an order of magnitude smaller
than the baseline system without any optimizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12415</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12415</id><created>2019-09-26</created><authors><author><keyname>Li</keyname><forenames>Jinyu</forenames></author><author><keyname>Zhao</keyname><forenames>Rui</forenames></author><author><keyname>Hu</keyname><forenames>Hu</forenames></author><author><keyname>Gong</keyname><forenames>Yifan</forenames></author></authors><title>Improving RNN Transducer Modeling for End-to-End Speech Recognition</title><categories>cs.CL eess.AS</categories><comments>Accepted by IEEE ASRU workshop, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last few years, an emerging trend in automatic speech recognition
research is the study of end-to-end (E2E) systems. Connectionist Temporal
Classification (CTC), Attention Encoder-Decoder (AED), and RNN Transducer
(RNN-T) are the most popular three methods. Among these three methods, RNN-T
has the advantages to do online streaming which is challenging to AED and it
doesn't have CTC's frame-independence assumption. In this paper, we improve the
RNN-T training in two aspects. First, we optimize the training algorithm of
RNN-T to reduce the memory consumption so that we can have larger training
minibatch for faster training speed. Second, we propose better model structures
so that we obtain RNN-T models with the very good accuracy but small footprint.
Trained with 30 thousand hours anonymized and transcribed Microsoft production
data, the best RNN-T model with even smaller model size (216 Megabytes)
achieves up-to 11.8% relative word error rate (WER) reduction from the baseline
RNN-T model. This best RNN-T model is significantly better than the device
hybrid model with similar size by achieving up-to 15.0% relative WER reduction,
and obtains similar WERs as the server hybrid model of 5120 Megabytes in size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12436</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12436</id><created>2019-09-26</created><authors><author><keyname>Marjaninejad</keyname><forenames>Ali</forenames></author><author><keyname>Tan</keyname><forenames>Jie</forenames></author><author><keyname>Valero-Cuevas</keyname><forenames>Francisco J.</forenames></author></authors><title>Autonomous Control of a Tendon-driven Robotic Limb with Elastic Elements
  Reveals that Added Elasticity can Enhance Learning</title><categories>cs.RO cs.SY eess.SY physics.bio-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive elastic elements can contribute to stability, energetic efficiency,
and impact absorption in both biological and robotic systems. They also add
dynamical complexity which makes them more challenging to model and control.
The impact of this added complexity to autonomous learning has not been
thoroughly explored. This is especially relevant to tendon-driven limbs whose
cables and tendons are inevitably elastic. Here, we explored the efficacy of
autonomous learning and control on a simulated bio-plausible tendon-driven leg
across different tendon stiffness values. We demonstrate that increasing
stiffness of the simulated muscles can require more iterations for the inverse
map to converge but can then perform more accurately, especially in discrete
tasks. Moreover, the system is robust to subsequent changes in muscle
stiffnesses and can adapt on-the-go within 5 attempts. Lastly, we test the
system for the functional task of locomotion, and found similar effects of
muscle stiffness to learning and performance. Given that a range of stiffness
values led to improved learning and maximized performance, we conclude the
robot bodies and autonomous controllers---at least for tendon-driven
systems---can be co-developed to take advantage of elastic elements.
Importantly, this opens also the door to development efforts that recapitulate
the beneficial aspects of the co-evolution of brains and bodies in vertebrates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12444</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12444</id><created>2019-09-26</created><updated>2020-01-02</updated><authors><author><keyname>Secer</keyname><forenames>Gorkem</forenames></author><author><keyname>Cinar</keyname><forenames>Ali Levent</forenames></author></authors><title>A Momentum-Based Foot Placement Strategy for Stable Postural Control of
  Robotic Spring-Mass Running with Point Feet</title><categories>cs.RO cs.SY eess.SY</categories><comments>The second author disagree with putting our manuscripts up on arxiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A long-standing argument in model-based control of locomotion is about the
level of complexity that a model should have to define a behavior such as
running. Even though goldilocks model based on biomechanical evidence is often
sought, it is unclear what complexity level qualifies to be such a model. This
dilemma deepens further for bipedal robotic running with point feet, since
these robots are underactuated, while tracking center-of-mass (COM)
trajectories defined by the spring-loaded inverted pendulum (SLIP) model of
running allocates all control inputs, leaving angular coordinates of the
robot's trunk uncontrolled. Existing work in the literature approach this
problem either by trading off COM trajectories against upright trunk posture
during stance or by adopting more detailed models that include effects of trunk
angular dynamics. In this paper, we present a new approach based on modifying
foot placement targets of the SLIP model. Theoretical analysis and numerical
results show that the proposed approach outperforms these traditional
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12448</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12448</id><created>2019-09-26</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Amini</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Song</keyname><forenames>Ziyou</forenames></author><author><keyname>Sun</keyname><forenames>Jing</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author></authors><title>Combined Energy and Comfort Optimization of Air Conditioning System in
  Connected and Automated Vehicles</title><categories>eess.SY cs.SY math.OC</categories><comments>ASME 2019 Dynamic Systems and Control Conference (DSCC), October
  8--11, Park City, Utah, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a combined energy and comfort optimization (CECO)
strategy for the air conditioning (A/C) system of the connected and automated
vehicles (CAVs). By leveraging the weather and traffic predictions enabled by
the emerging CAV technologies, the proposed strategy is able to minimize the
A/C system energy consumption while maintaining the occupant thermal comfort
(OTC) within the comfort constraints, where the comfort is quantified by a
modified predictive mean vote (PMV) model adapted for an automotive
application. A general CECO problem is formulated and addressed using model
predictive control (MPC) and weather/traffic previews. Depending on the ways of
exploiting the preview information and enforcing the OTC constraint, different
MPCs are developed based on solving different variations of the general CECO
problem. The CECO-based MPCs are then tested in simulation using an automotive
A/C system simulation model (CoolSim) as the virtual testbed. The simulation
results show that, over SC03 driving cycle, the proposed CECO-based MPCs
outperform the baseline cabin temperature tracking controller, reducing the A/C
system energy consumption by up to 7.6%, while achieving better OTC according
to the PMV-based metrics. This energy saving in A/C system translates to 3.1%
vehicle fuel economy improvement. The trade-off between energy efficiency and
OTC for different control scenarios is also highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12452</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12452</id><created>2019-09-26</created><authors><author><keyname>Hashemi</keyname><forenames>Navid</forenames></author><author><keyname>Ruths</keyname><forenames>Justin</forenames></author></authors><title>Gain Design via LMIs to Minimize the Impact of Stealthy Attacks</title><categories>eess.SY cs.SY</categories><journal-ref>2020 American Control Conference (ACC)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The goal of this paper is to design the gain matrices for estimate-based
feedback to minimize the impact that falsified sensor measurements can have on
the state of a stochastic linear time invariant system. Here we consider
attackers that stay stealthy, by raising no alarms, to a chi-squared anomaly
detector, thereby restricting the set of attack inputs within an ellipsoidal
set. We design linear matrix inequalities (LMIs) to find a tight outer
ellipsoidal bound on the convex set of states reachable due to the stealthy
inputs (and noise). Subsequently considering the controller and estimator gains
as design variables requires further linearization to maintain the LMI
structure. Without a competing performance criterion, the solution of this gain
design is the trivial uncoupling of the feedback loop (setting either gain to
zero). Here we consider - and convexify - an output constrained covariance
(OCC) $\|H\|_2$ gain constraint on the non-attacked system. Through additional
tricks to linearize the combination of these LMI constraints, we propose an
iterative algorithm whose core is a combined convex optimization problem to
minimize the state reachable set due to the attacker while ensuring a small
enough $\|H\|_2$ gain during nominal operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12458</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12458</id><created>2019-09-26</created><authors><author><keyname>Preiswerk</keyname><forenames>Frank</forenames></author><author><keyname>Brinker</keyname><forenames>Spencer T.</forenames></author><author><keyname>McDannold</keyname><forenames>Nathan J.</forenames></author><author><keyname>Mariano</keyname><forenames>Timothy Y.</forenames></author></authors><title>Open-source neuronavigation for multimodal non-invasive brain
  stimulation using 3D Slicer</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, non-invasive neuro-modulation methods such as Focused
Ultrasound (FUS) have gained popularity. The aim of this work is to introduce
the use of existing open-source technology for surgical navigation to the field
of multimodal non-invasive brain stimulation. Unlike homegrown and commercial
systems, the use of well-documented, well maintained, and freely available
open-source components minimizes the learning curve, maximizes technology
transfer outcome, and fosters reproducible science for complex, guided
neuromodulation systems. The described system significantly lowers the entry
bar to clinical research and experimentation in the field of non-invasive brain
stimulation. Our contribution is two-fold. First, a high-level overview of the
components of the descried system is given in this manuscript. Second, all
files are made available online, with a comprehensive step-by-step manual,
quickly allowing researchers to build a custom system. A spatial accuracy of
0.93 mm was found through validation using a robotic positioning system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12472</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12472</id><created>2019-09-26</created><authors><author><keyname>Luo</keyname><forenames>Ruisen</forenames></author><author><keyname>Hu</keyname><forenames>Tao</forenames></author><author><keyname>Tang</keyname><forenames>Zuodong</forenames></author><author><keyname>Wang</keyname><forenames>Chen</forenames></author><author><keyname>Gong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Tu</keyname><forenames>Haiyan</forenames></author></authors><title>A Radio Signal Modulation Recognition Algorithm Based on Residual
  Networks and Attention Mechanisms</title><categories>eess.SP cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To solve the problem of inaccurate recognition of types of communication
signal modulation, a RNN neural network recognition algorithm combining
residual block network with attention mechanism is proposed. In this method, 10
kinds of communication signals with Gaussian white noise are generated from
standard data sets, such as MASK, MPSK, MFSK, OFDM, 16QAM, AM and FM. Based on
the original RNN neural network, residual block network is added to solve the
problem of gradient disappearance caused by deep network layers. Attention
mechanism is added to the network to accelerate the gradient descent. In the
experiment, 16QAM, 2FSK and 4FSK are used as actual samples, IQ data frames of
signals are used as input, and the RNN neural network combined with residual
block network and attention mechanism is trained. The final recognition results
show that the average recognition rate of real-time signals is over 93%. The
network has high robustness and good use value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12489</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12489</id><created>2019-09-27</created><authors><author><keyname>Paudel</keyname><forenames>Uttam</forenames></author><author><keyname>Luengo-Kovac</keyname><forenames>Marta</forenames></author><author><keyname>Pilawa</keyname><forenames>Jacob</forenames></author><author><keyname>Shaw</keyname><forenames>T. Justin</forenames></author><author><keyname>Valley</keyname><forenames>George C.</forenames></author></authors><title>Classification of time-domain waveforms using a speckle-based optical
  reservoir computer</title><categories>physics.optics eess.SP</categories><report-no>Optics Express Vol. 28, Issue 2, pp. 1225-1237 (2020)</report-no><doi>10.1364/OE.379264</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reservoir computing is a recurrent machine learning framework that expands
the dimensionality of a problem by mapping an input signal into a
higher-dimension reservoir space that can capture and predict features of
complex, non-linear temporal dynamics. Here, we report on a bulk optical
demonstration of an analog reservoir computer using speckles generated by
propagating a laser beam modulated with a spatial light modulator through a
multimode waveguide. We demonstrate that the hardware can successfully perform
a multivariate audio classification task performed using the Japanese vowel
speakers public data set. We perform full wave optical calculations of this
architecture implemented in a chip-scale platform using an SiO2 waveguide and
demonstrate that it performs as well as a fully numerical implementation of
reservoir computing. As all the optical components used in the experiment can
be fabricated using a commercial photonic integrated circuit foundry, our
result demonstrates a framework for building a scalable, chip-scale, reservoir
computer capable of performing optical signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12506</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12506</id><created>2019-09-27</created><authors><author><keyname>Renganathan</keyname><forenames>Venkatraman</forenames></author><author><keyname>Hashemi</keyname><forenames>Navid</forenames></author><author><keyname>Ruths</keyname><forenames>Justin</forenames></author><author><keyname>Summers</keyname><forenames>Tyler H.</forenames></author></authors><title>Distributionally Robust Tuning of Anomaly Detectors in Cyber-Physical
  Systems with Stealthy Attacks</title><categories>eess.SY cs.SY</categories><journal-ref>2020 Annual American Control Conference (ACC)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Designing resilient control strategies for mitigating stealthy attacks is a
crucial task in emerging cyber-physical systems. In the design of anomaly
detectors, it is common to assume Gaussian noise models to maintain
tractability; however, this assumption can lead the actual false alarm rate to
be significantly higher than expected. We propose a distributionally robust
anomaly detector for noise distributions in moment-based ambiguity sets. We
design a detection threshold that guarantees that the actual false alarm rate
is upper bounded by the desired one by using generalized Chebyshev
inequalities. Furthermore, we highlight an important trade-off between the
worst-case false alarm rate and the potential impact of a stealthy attacker by
efficiently computing an outer ellipsoidal bound for the attack-reachable
states corresponding to the distributionally robust detector threshold. We
illustrate this trade-off with a numerical example and compare the proposed
approach with a traditional chi-squared detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12511</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12511</id><created>2019-09-27</created><updated>2019-09-29</updated><authors><author><keyname>Caluya</keyname><forenames>Kenneth F.</forenames></author><author><keyname>Halder</keyname><forenames>Abhishek</forenames></author></authors><title>Finite Horizon Density Steering for Multi-input State Feedback
  Linearizable Systems</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the feedback synthesis problem for steering the joint
state density or ensemble subject to multi-input state feedback linearizable
dynamics. This problem is of interest to many practical applications including
that of dynamically shaping a robotic swarm. Our results here show that it is
possible to exploit the structural nonlinearities to derive the feedback
controllers steering the joint density from a prescribed shape to another while
minimizing the expected control effort to do so. The developments herein build
on our previous work, and extend the theory of the Schr\&quot;{o}dinger bridge
problem subject to feedback linearizable dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12520</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12520</id><created>2019-09-27</created><authors><author><keyname>Sinha</keyname><forenames>Subhrajit</forenames></author><author><keyname>Nandanoori</keyname><forenames>Sai Pushpak</forenames></author><author><keyname>Yeung</keyname><forenames>Enoch</forenames></author></authors><title>Online Learning of Dynamical Systems: An Operator Theoretic Approach</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide an algorithm for online computation of Koopman
operator in real-time using streaming data. In recent years, there has been an
increased interest in data-driven analysis of dynamical systems, with operator
theoretic techniques being the most popular. Existing algorithms, like Dynamic
Mode Decomposition (DMD) and Extended Dynamic Mode Decomposition (EDMD), use
the entire data set for computation of the Koopman operator. However, many real
life applications like power system analysis, biological systems, building
systems etc. requires the real-time computation and updating of the Koopman
operator, as new data streams in. In this paper, we propose an iterative
algorithm for online computation of Koopman operator such that at each time
step the Koopman operator is updated incrementally. In particular, we propose a
Recursive Extended Dynamic Decomposition (rEDMD) algorithm for computation of
Koopman operator from streaming data. Further, we test the algorithm in three
different dynamical systems, namely, a linear system, a nonlinear system and a
system governed by a Partial Differential Equation (PDE) and illustrate the
computational efficiency of the iterative algorithm over the existing DMD and
EDMD algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12525</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12525</id><created>2019-09-27</created><updated>2019-10-13</updated><authors><author><keyname>Sinha</keyname><forenames>Ashish</forenames></author><author><keyname>Sugawara</keyname><forenames>Yohei</forenames></author><author><keyname>Hirano</keyname><forenames>Yuichiro</forenames></author></authors><title>GA-GAN: CT reconstruction from Biplanar DRRs using GAN with Guided
  Attention</title><categories>eess.IV cs.CV cs.LG</categories><comments>4 pages, 4 figures, NeurIPS workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This work investigates the use of guided attention in the reconstruction of
CTvolumes from biplanar DRRs. We try to improve the visual image quality of the
CT reconstruction using Guided Attention based GANs (GA-GAN). We also consider
the use of Vector Quantization (VQ) for the CT reconstruction so that the
memory usage can be reduced, maintaining the same visual image quality. To the
best of our knowledge no work has been done before that explores the Vector
Quantization for this purpose. Although our findings show that our approaches
outperform the previous works, still there is a lot of room for improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12529</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12529</id><created>2019-09-27</created><authors><author><keyname>Chowdhury</keyname><forenames>AFM Kamal</forenames></author><author><keyname>Kern</keyname><forenames>Jordan</forenames></author><author><keyname>Dang</keyname><forenames>Thanh Duc</forenames></author><author><keyname>Galelli</keyname><forenames>Stefano</forenames></author></authors><title>PowNet: a power systems analysis model for large-scale water-energy
  nexus studies</title><categories>physics.geo-ph eess.SP physics.soc-ph</categories><comments>22 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  PowNet is a free modelling tool for simulating the Unit Commitment / Economic
Dispatch of large-scale power systems. PowNet is specifically conceived for
applications in the water-energy nexus domain, which investigate the impact of
water availability on electricity supply. To this purpose, PowNet is equipped
with features that guarantee accuracy, reusability, and computational
efficiency over large spatial and temporal domains. Specifically, the model (i)
accounts for the techno-economic constraints of both generating units and
transmission networks, (ii) can be easily coupled with models that estimate the
status of generating units as a function of the climatic conditions, and (iii)
explicitly includes import/export nodes, which are often found in cross-border
systems. PowNet is implemented in Python and runs with the help of any standard
optimization solver (e.g., Gurobi, CPLEX). Its functionality is demonstrated on
the Cambodian power system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12537</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12537</id><created>2019-09-27</created><updated>2019-12-03</updated><authors><author><keyname>Richard</keyname><forenames>Hugo</forenames></author><author><keyname>Martin</keyname><forenames>Lucas</forenames></author><author><keyname>Pinho</keyname><forenames>Ana Lu&#x131;sa</forenames></author><author><keyname>Pillow</keyname><forenames>Jonathan</forenames></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames></author></authors><title>Fast shared response model for fMRI data</title><categories>cs.CV cs.LG eess.IV q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The shared response model provides a simple but effective framework to
analyse fMRI data of subjects exposed to naturalistic stimuli. However when the
number of subjects or runs is large, fitting the model requires a large amount
of memory and computational power, which limits its use in practice. In this
work, we introduce the FastSRM algorithm that relies on an intermediate
atlas-based representation. It provides considerable speed-up in time and
memory usage, hence it allows easy and fast large-scale analysis of
naturalistic-stimulus fMRI data. Using four different datasets, we show that
our method matches the performance of the original SRM algorithm while being
about 5x faster and 20x to 40x more memory efficient. Based on this
contribution, we use FastSRM to predict age from movie watching data on the
CamCAN sample. Besides delivering accurate predictions (mean absolute error of
7.5 years), FastSRM extracts topographic patterns that are predictive of age,
demonstrating that brain activity during free perception reflects age.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12561</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12561</id><created>2019-09-27</created><updated>2019-12-25</updated><authors><author><keyname>Li</keyname><forenames>Yongqiang</forenames></author><author><keyname>Lu</keyname><forenames>Chaolun</forenames></author><author><keyname>Hou</keyname><forenames>Zhongsheng</forenames></author><author><keyname>Feng</keyname><forenames>Yuanjing</forenames></author></authors><title>Data-Driven Robust Stabilization with RobustDomain of Attraction
  Estimate for Nonlinear Discrete-Time Systems</title><categories>eess.SY cs.SY</categories><comments>6 pages, 3 figures, preprint submitted to Automatica (Accept
  provisionally)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear robust control is pursued by overcoming the drawback of linear
robust control that it ignores available information about existing
nonlinearities and the resulting controllers may be too conservative,
especially when the nonlinearities are significant. However, most existing
nonlinear robust control approaches just consider the affine nonlinear nominal
model and thereby ignore available information about existing non-affine
nonlinearities. When the general nonlinear nominal model is considered, the
robust domain of attraction (RDOA) of closed-loops requires extensive
investigation because it is hard to achieve the global stabilization. In this
paper, we propose a new nonlinear robust control method based on Lyapunov
function to stabilize a discrete-time uncertain system and to estimate the RDOA
of closed-loops. First, a sufficient condition for robust stabilization of all
plants in a plant set and estimation of the RDOA of all closed-loops is
proposed. Then, to tackle the non-affine nonlinearities, a data-driven method
of estimating the robust negative-definite domains (RNDD) is presented, and
based on it the estimation of the RDOA of closed-loops and the resulting
controller design are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12567</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12567</id><created>2019-09-27</created><updated>2019-12-16</updated><authors><author><keyname>Vu</keyname><forenames>Tung T.</forenames></author><author><keyname>Ngo</keyname><forenames>Duy T.</forenames></author><author><keyname>Tran</keyname><forenames>Nguyen H.</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Dao</keyname><forenames>Minh N.</forenames></author><author><keyname>Middleton</keyname><forenames>Richard H.</forenames></author></authors><title>Cell-Free Massive MIMO for Wireless Federated Learning</title><categories>eess.SP cs.IT math.IT</categories><comments>The paper was submitted for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel scheme for cell-free massive multiple-input
multiple-output (CFmMIMO) networks to support any federated learning (FL)
framework. This scheme allows each instead of all the iterations of the FL
framework to happen in a large-scale coherence time to guarantee a stable
operation of an FL process. To show how to optimize the FL performance using
this proposed scheme, we consider an existing FL framework as an example and
target FL training time minimization for this framework. An optimization
problem is then formulated to jointly optimize the local accuracy, transmit
power, data rate, and users' processing frequency. This mixed-timescale
stochastic nonconvex problem captures the complex interactions among the
training time, and transmission and computation of training updates of one FL
process. By employing the online successive convex approximation approach, we
develop a new algorithm to solve the formulated problem with proven convergence
to the neighbourhood of its stationary points. Our numerical results confirm
that the presented joint design reduces the training time by up to $55\%$ over
baseline approaches. They also show that CFmMIMO here requires the lowest
training time for FL processes compared with cell-free time-division multiple
access massive MIMO and collocated massive MIMO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12583</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12583</id><created>2019-09-27</created><authors><author><keyname>Morovic</keyname><forenames>Jan</forenames></author></authors><title>Color continuity along the journey from ideas to objects</title><categories>cs.GR eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human endeavor has involved making choices about color and looking for ways
to color objects since the dawn of civilization. While it has been the
exclusive domain of artists and craftspeople for millennia, the last century
has seen the introduction of a scientific basis to color communication. The
ultimate goal of this development is for color communication to happen
seamlessly and in a transparent way. There are however two categories of
challenges here: first, understanding and quantifying color needs and
expectation and second, developing control mechanisms that deliver the desired
color. In this paper a review will be presented of the color needs in
end-to-end color journeys, from initial concept to final colored object and an
overview of recent developments in color printing will follow. Topics like
imaging pipelines (including the recently-introduced HP Pixel Control), the
ease of use of color workflows (including HP Smart Color Tools), the handling
of brand or corporate identity colors (via HP Professional PANTONE Emulation)
and the measurement of color difference under specific viewing arrangements
(i.e., the dENS metric for viewing samples without separation) will be
addressed. Finally, a series of challenges for the future will be set out, so
that their solution can be approached by both academic and industrial
communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12594</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12594</id><created>2019-09-27</created><authors><author><keyname>Ahar</keyname><forenames>Ayyoub</forenames></author><author><keyname>Chlipala</keyname><forenames>Maksymilian</forenames></author><author><keyname>Birnbaum</keyname><forenames>Tobias</forenames></author><author><keyname>Zaperty</keyname><forenames>Weronika</forenames></author><author><keyname>Symeonidou</keyname><forenames>Athanasia</forenames></author><author><keyname>Kozacki</keyname><forenames>Tomasz</forenames></author><author><keyname>Kujawinska</keyname><forenames>Malgorzata</forenames></author><author><keyname>Schelkens</keyname><forenames>Peter</forenames></author></authors><title>Suitability Analysis of Holographic vs Light Field and 2D Displays for
  Subjective Quality Assessment of Fourier Holograms</title><categories>eess.IV eess.SP</categories><comments>This paper consists of 15 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Visual quality assessment of digital holograms is facing many challenges.
Main difficulties are related to the limited spatial resolution and angular
field of view of holographic displays in combination with the complexity of
steering and operating them for such tasks. Alternatively, non-holographic
displays - and in particular light-field displays - can be utilized to
visualize the numerically reconstructed content of a digital hologram. However,
their suitability as alternative for holographic displays has not been
validated. In this research, we have investigated this issue via a set of
comprehensive experiments. We used Fourier holographic principle to acquire a
diverse set of holograms, which were either computer-generated from point
clouds or optically recorded from real macroscopic objects. A final public data
set comprising 96 holograms was created using three compression methods which
encoded the holograms at four bit-depths. Three separate subjective-tests were
conducted using a holographic display, a light field display and a 2D display.
For these subjective experiments, a double stimulus, multi-perspective,
multi-depth subjective testing methodology was designed and implemented. The
tests show that the non-holographic displays indicate a higher sensitivity to
artifacts than the holographic display, though at the same time it is
demonstrated they are highly correlated. This indicates that the numerically
reconstructed holograms rendered on a light field or 2D display have a high
predictive value for the perceived quality on holographic display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12667</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12667</id><created>2019-09-27</created><authors><author><keyname>Yi</keyname><forenames>Ji Hyun</forenames></author><author><keyname>Cherkaoui</keyname><forenames>Rachid</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Optimal Siting and Sizing of Energy Storage Systems in Active
  Distribution Networks to achieve their Dispatchability</title><categories>eess.SY cs.SY</categories><comments>8 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper presents a method for the optimal siting and sizing of energy
storage systems (ESSs) to be installed into active distribution networks (ADNs)
to achieve their dispatchability. The problem formulation accounts for the
uncertainty inherent to the stochastic nature of distributed energy sources and
loads. Thanks to the operation of ESSs, the main optimization objective is to
minimize the dispatch error, which accounts for the mismatch between the
realization and prediction of the power profile at the ADN connecting point to
the upper layer grid, while respecting the grid voltages and ampacity
constraints. The proposed formulation relies on the so-called Augmented Relaxed
Optimal Power Flow (AR-OPF) method. It expresses a convex full AC optimal power
flow problem that is proven to provide a global optimal and exact solution in
the case of radial power grids. The AR-OPF is coupled with the proposed
dispatching control resulting in a two-level optimization problem. In the first
block, the location and size of the ESSs are decided along with the dispatch
error reduction rate, which determines the capability of the allocated ESSs to
reduce the dispatch error. Then, in the second block, the adequacy of the ESS
allocations and the feasibility of the grid operating points are verified
through operating scenarios employing the Benders decomposition technique.
Consequently, the optimal size and site of the ESSs are adjusted. To validate
the proposed method, extensive simulations are conducted on a real Swiss ADN of
55 nodes hosting a large amount of stochastic PV generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12681</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12681</id><created>2019-09-27</created><updated>2019-09-30</updated><authors><author><keyname>Yue</keyname><forenames>Xianghu</forenames></author><author><keyname>Lee</keyname><forenames>Grandee</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Deng</keyname><forenames>Fang</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>End-to-End Code-Switching ASR for Low-Resourced Language Pairs</title><categories>cs.CL eess.AS</categories><comments>Accepted for publication at IEEE ASRU Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the significant progress in end-to-end (E2E) automatic speech
recognition (ASR), E2E ASR for low resourced code-switching (CS) speech has not
been well studied. In this work, we describe an E2E ASR pipeline for the
recognition of CS speech in which a low-resourced language is mixed with a high
resourced language. Low-resourcedness in acoustic data hinders the performance
of E2E ASR systems more severely than the conventional ASR systems.~To mitigate
this problem in the transcription of archives with code-switching Frisian-Dutch
speech, we integrate a designated decoding scheme and perform rescoring with
neural network-based language models to enable better utilization of the
available textual resources. We first incorporate a multi-graph decoding
approach which creates parallel search spaces for each monolingual and mixed
recognition tasks to maximize the utilization of the textual resources from
each language. Further, language model rescoring is performed using a recurrent
neural network pre-trained with cross-lingual embedding and further adapted
with the limited amount of in-domain CS text. The ASR experiments demonstrate
the effectiveness of the described techniques in improving the recognition
performance of an E2E CS ASR system in a low-resourced scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12695</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12695</id><created>2019-09-27</created><updated>2019-10-10</updated><authors><author><keyname>Ly</keyname><forenames>Minh Hoang</forenames></author><author><keyname>Dinh</keyname><forenames>Thinh Quang</forenames></author><author><keyname>Kha</keyname><forenames>Ha Hoang</forenames></author></authors><title>Joint Optimization of Execution Latency and Energy Consumption for
  Mobile Edge Computing with Data Compression and Task Allocation</title><categories>eess.SP cs.IT math.IT</categories><comments>ISEE 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the mobile edge offloading scenario consisting of
one mobile device (MD) with multiple independent tasks and various remote edge
devices. In order to save energy, the user's device can offload the tasks to
available access points for edge computing. Data compression is applied to
reduce offloaded data size prior to wireless transmission to minimize the
execution latency. The problem of jointly optimizing the task allocation
decision and the data compression ratio to minimize the total tasks' execution
latency and the MD's energy consumption concurrently is proposed. We show that
the design problem is a non-convex optimization one but it can be transformed
into a convex one through a semidefinite relaxation (SDR) based approach.
Numerical simulations demonstrate the outperformance of the proposed scheme
compared to the benchmark one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12699</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12699</id><created>2019-09-27</created><authors><author><keyname>Adapa</keyname><forenames>Sainath</forenames></author></authors><title>Urban Sound Tagging using Convolutional Neural Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a framework for environmental sound classification
in a low-data context (less than 100 labeled examples per class). We show that
using pre-trained image classification models along with the usage of data
augmentation techniques results in higher performance over alternative
approaches. We applied this system to the task of Urban Sound Tagging, part of
the DCASE 2019. The objective was to label different sources of noise from raw
audio data. A modified form of MobileNetV2, a convolutional neural network
(CNN) model was trained to classify both coarse and fine tags jointly. The
proposed model uses log-scaled Mel-spectrogram as the representation format for
the audio data. Mixup, Random erasing, scaling, and shifting are used as data
augmentation techniques. A second model that uses scaled labels was built to
account for human errors in the annotations. The proposed model achieved the
first rank on the leaderboard with Micro-AUPRC values of 0.751 and 0.860 on
fine and coarse tags, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12725</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12725</id><created>2019-09-27</created><authors><author><keyname>Nobre</keyname><forenames>Isabela Cunha Maia</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Optimized Quantization in Distributed Graph Signal Filtering</title><categories>eess.SP</categories><comments>11 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed graph signal processing algorithms require the network nodes to
communicate by exchanging messages in order to achieve a common objective.
These messages have a finite precision in realistic networks, which may
necessitate to implement message quantization. Quantization, in turn, may
generate distortion and performance penalty in the distributed processing
tasks. This paper proposes a novel method for distributed graph filtering that
minimizes the error due to message quantization without compromising the
communication costs. It first bounds the exchanged messages and then allocates
a limited bit budget in an optimized way to the different messages and network
nodes. In particular, our novel quantization algorithm adapts to both the
network topology and the message importance in a distributed processing task.
Our results show that the proposed method is effective in minimizing the error
due to quantization and that it permits to outperform baseline distributed
algorithms when the bit budget is limited. They further show that errors
produced in nodes with high eccentricity or in the first steps of the
distributed algorithm contribute more to the global error. Also, sparse and
irregular graphs require more irregular bit distribution. Our method provides
one of the first quantization solutions for distributed graph processing, which
is able to adapt to the target task, the graph properties and the communication
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12743</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12743</id><created>2019-09-27</created><authors><author><keyname>Bahmanyar</keyname><forenames>Reza</forenames></author><author><keyname>Vig</keyname><forenames>Elenora</forenames></author><author><keyname>Reinartz</keyname><forenames>Peter</forenames></author></authors><title>MRCNet: Crowd Counting and Density Map Estimation in Aerial and Ground
  Imagery</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><journal-ref>BMVC Workshop on Object Detection and Recognition for Security
  Screenin (BMVC-ODRSS) 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spite of the many advantages of aerial imagery for crowd monitoring and
management at mass events, datasets of aerial images of crowds are still
lacking in the field. As a remedy, in this work we introduce a novel crowd
dataset, the DLR Aerial Crowd Dataset (DLR-ACD), which is composed of 33 large
aerial images acquired from 16 flight campaigns over mass events with 226,291
persons annotated. To the best of our knowledge, DLR-ACD is the first aerial
crowd dataset and will be released publicly. To tackle the problem of accurate
crowd counting and density map estimation in aerial images of crowds, this work
also proposes a new encoder-decoder convolutional neural network, the so-called
Multi-Resolution Crowd Network MRCNet. The encoder is based on the VGG-16
network and the decoder is composed of a set of bilinear upsampling and
convolutional layers. Using two losses, one at an earlier level and another at
the last level of the decoder, MRCNet estimates crowd counts and
high-resolution crowd density maps as two different but interrelated tasks. In
addition, MRCNet utilizes contextual and detailed local information by
combining high- and low-level features through a number of lateral connections
inspired by the Feature Pyramid Network (FPN) technique. We evaluated MRCNet on
the proposed DLR-ACD dataset as well as on the ShanghaiTech dataset, a
CCTV-based crowd counting benchmark. The results demonstrate that MRCNet
outperforms the state-of-the-art crowd counting methods in estimating the crowd
counts and density maps for both aerial and CCTV-based images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12763</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12763</id><created>2019-09-27</created><authors><author><keyname>Guo</keyname><forenames>Yi</forenames></author><author><keyname>Zhou</keyname><forenames>Xinyang</forenames></author><author><keyname>Zhao</keyname><forenames>Changhong</forenames></author><author><keyname>Chen</keyname><forenames>Yue</forenames></author><author><keyname>Summers</keyname><forenames>Tyler</forenames></author><author><keyname>Chen</keyname><forenames>Lijun</forenames></author></authors><title>Solving Optimal Power Flow for Distribution Networks with State
  Estimation Feedback</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm to solve an optimal power flow (OPF) problem with
state estimation (SE) feedback for distribution networks with limited sensor
allocation for system monitoring. The framework integrates state estimation
into traditional optimal power flow. Instead of physically monitoring all
states, here we consider an estimation algorithm acting as a feedback loop
within an online gradient-based OPF controller to monitor and feed-in the
real-time information. The estimation algorithm reduces uncertainty on
unmeasured grid states based on a few appropriate online state measurements and
noisy &quot;pseudo-measurements&quot;. We analytically investigate the convergence of the
proposed algorithm. The numerical results demonstrate that this approach is
more robust to large pseudo measurement variability and inherent sensor noise
in comparison to the other frameworks without SE feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12765</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12765</id><created>2019-09-27</created><authors><author><keyname>K&#xf6;hler</keyname><forenames>Johannes</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Matthias A.</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>A nonlinear model predictive control framework using reference generic
  terminal ingredients</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a quasi infinite horizon nonlinear model predictive
control (MPC) scheme for tracking of generic reference trajectories. This
scheme is applicable to nonlinear systems, which are locally incrementally
stabilizable. For such systems, we provide a reference generic offline
procedure to compute an incrementally stabilizing feedback with a continuously
parameterized quadratic quasi infinite horizon terminal cost. As a result we
get a nonlinear reference tracking MPC scheme with a valid terminal cost for
general reachable reference trajectories without increasing the online
computational complexity. As a corollary, the terminal cost can also be used to
design nonlinear MPC schemes that reliably operate under online changing
conditions, including unreachable reference signals. The practicality of this
approach is demonstrated with a benchmark example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12777</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12777</id><created>2019-09-26</created><authors><author><keyname>Rahmati</keyname><forenames>Ali</forenames></author><author><keyname>Hosseinalipour</keyname><forenames>Seyyedali</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>He</keyname><forenames>Xiaofan</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author><author><keyname>Bhuyan</keyname><forenames>Arupjyoti</forenames></author></authors><title>Dynamic Interference Management for UAV-Assisted Wireless Networks</title><categories>eess.SP cs.MA</categories><comments>12 pages, 13 figures. arXiv admin note: substantial text overlap with
  arXiv:1904.07781</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deployment of unmanned aerial vehicles (UAVs) is proliferating as they
are effective, flexible and cost-efficient devices for a variety of
applications ranging from natural disaster recovery to delivery of goods. We
investigate a transmission mechanism aiming to improve the data rate between a
base station (BS) and a user equipment through deploying multiple relaying
UAVs. We consider the effect of interference, which is incurred by the nodes of
another established communication network. Our primary goal is to design the 3D
trajectories and power allocation for the UAVs to maximize the data flow while
the interference constraint is met. The UAVs can reconfigure their locations to
evade the unintended/intended interference caused by reckless/smart
interferers. We also consider the scenario in which smart jammers chase the
UAVs to degrade the communication quality. In this case, we investigate the
problem from the perspective of both UAV network and smart jammers. An
alternating-maximization approach is proposed to address the joint 3D
trajectory design and power allocation problem. We handle the 3D trajectory
design by resorting to spectral graph theory and subsequently address the power
allocation through convex optimization techniques. Finally, we demonstrate the
efficacy of our proposed method through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12780</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12780</id><created>2019-09-27</created><updated>2019-11-18</updated><authors><author><keyname>Meishvili</keyname><forenames>Givi</forenames></author><author><keyname>Jenni</keyname><forenames>Simon</forenames></author><author><keyname>Favaro</keyname><forenames>Paolo</forenames></author></authors><title>Learning to Have an Ear for Face Super-Resolution</title><categories>cs.CV eess.AS eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method to use both audio and a low-resolution image to
perform extreme face super-resolution (a 16x increase of the input size). When
the resolution of the input image is very low (e.g., 8x8 pixels), the loss of
information is so dire that important details of the original identity have
been lost and audio can aid the recovery of a plausible high-resolution image.
In fact, audio carries information about facial attributes, such as gender and
age. Moreover, if an audio track belongs to an identity in a known training
set, such audio might even help to restore the original identity. Towards this
goal, we propose a model and a training procedure to extract information about
the face of a person from her audio track and to combine it with the
information extracted from her low-resolution image, which relates more to pose
and colors of the face. We demonstrate that the combination of these two inputs
yields high-resolution images that better capture the correct attributes of the
face. In particular, we show experimentally that audio can assist in recovering
attributes such as the gender, the age and the identity, and thus improve the
correctness of the image reconstruction process. Our procedure does not make
use of human annotation and thus can be easily trained with existing video
datasets. Moreover, we show that our model builds a factorized representation
of images and audio as it allows one to mix low-resolution images and audio
from different videos and to generate realistic faces with semantically
meaningful combinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12810</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12810</id><created>2019-09-27</created><authors><author><keyname>Ademola-Idowu</keyname><forenames>Atinuke</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author></authors><title>Frequency Stability Using Inverter Power Control in Low-Inertia Power
  Systems</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to IEEE Transaction on Power Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electrical grid is evolving from a network consisting of mostly
synchronous machines to a mixture of synchronous machines and inverter-based
resources such as wind, solar, and energy storage. This transformation has led
to a decrease in mechanical inertia, which necessitate a need for the new
resources to provide frequency responses by controlling their inverter
interfaces. In this paper we proposed a new strategy based on model predictive
control to determine the the optimal active-power set-point for inverters in
the event of a disturbance in the system. In contrast to existing methods, our
framework explicitly takes the hard constraints in power and energy into
account. We show that it is also robust to measurement noise and limited
communications by using an observer to estimate the model mismatches in
real-time. We demonstrate that our proposed controller significantly
outperforms an optimally tuned virtual synchronous machine on standard IEEE
9-bus and 39-bus systems under a number of scenarios. In turn, this implies
optimized inverter-based resources can provide better frequency responses
compared to conventional synchronous machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12864</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12864</id><created>2019-09-27</created><updated>2019-10-04</updated><authors><author><keyname>Min</keyname><forenames>Hancheng</forenames></author><author><keyname>Paganini</keyname><forenames>Fernando</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Accurate Reduced Order Models for Coherent Synchronous Generators</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel framework to approximate the aggregate frequency
dynamics of coherent synchronous generators. By leveraging recent results on
dynamics concentration of tightly connected networks, we develop a hierarchy of
reduced order models --based on frequency weighted balanced truncation-- that
accurately approximate the aggregate system response. Our results outperform
existing aggregation techniques and can be shown to monotonically improve the
approximation as the hierarchy order increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12894</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12894</id><created>2019-09-27</created><authors><author><keyname>Hatalis</keyname><forenames>Kostas</forenames></author><author><keyname>Venkitasubramaniam</keyname><forenames>Parv</forenames></author><author><keyname>Kishore</keyname><forenames>Shalinee</forenames></author></authors><title>Modeling and Detection of Future Cyber-Enabled DSM Data Attacks using
  Supervised Learning</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demand-Side Management (DSM) is a vital tool that can be used to ensure power
system reliability and stability. In future smart grids, certain portions of a
customers load usage could be under automatic control with a cyber-enabled DSM
program which selectively schedules loads as a function of electricity prices
to improve power balance and grid stability. In such a case, the security of
DSM cyberinfrastructure will be critical as advanced metering infrastructure,
and communication systems are susceptible to hacking, cyber-attacks. Such
attacks, in the form of data injection, can manipulate customer load profiles
and cause metering chaos and energy losses in the grid. These attacks are also
exacerbated by the feedback mechanism between load management on the consumer
side and dynamic price schemes by independent system operators. This work
provides a novel methodology for modeling and simulating the nonlinear
relationship between load management and real-time pricing. We then investigate
the behavior of such a feedback loop under intentional cyber-attacks using our
feedback model. We simulate and examine load-price data under different levels
of DSM participation with three types of additive attacks: ramp, sudden, and
point attacks. We apply change point and supervised learning methods for
detection of DSM attacks. Results conclude that while higher levels of DSM
participation can exacerbate attacks they also lead to better detection of such
attacks. Further analysis of results shows that point attacks are the hardest
to detect and supervised learning methods produce results on par or better than
sequential detectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12897</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12897</id><created>2019-09-27</created><authors><author><keyname>Gulec</keyname><forenames>Fatih</forenames></author><author><keyname>Atakan</keyname><forenames>Baris</forenames></author></authors><title>Distance Estimation Methods for a Practical Macroscale Molecular
  Communication System</title><categories>eess.SP</categories><comments>33 pages, 22 figures, submitted to Nano Communication Networks
  journal (Elsevier)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate estimation of the distance between the transmitter (TX) and the
receiver (RX) in molecular communication (MC) systems can provide faster and
more reliable communication. Existing theoretical models in the literature are
not suitable for distance estimation in a practical scenario. Furthermore,
deriving an analytical model is not easy due to effects such as boundary
conditions in the diffusion process, the initial velocity of the molecules and
unsteady flows. Therefore, five different practical methods comprising three
novel data analysis based methods and two supervised machine learning (ML)
methods, Multivariate Linear Regression (MLR) and Neural Network Regression
(NNR), are proposed for distance estimation at the RX side. In order to apply
the ML methods, a macroscale practical MC system, which consists of an electric
sprayer without a fan, alcohol molecules, an alcohol sensor and a
microcontroller, is established, and the received signals are recorded. A
feature extraction algorithm is proposed to utilize the measured signals as the
inputs in ML methods. The numerical results show that the ML methods outperform
the data analysis based methods in the root mean square error sense with the
cost of complexity. Moreover, the peak time based estimation, which is one of
the proposed data analysis based methods, yields better results with respect to
the other proposed four methods, as the distance increases. Given the
experimental data and fluid dynamics theory, a possible trajectory of the
molecules between the TX and RX is given. Our findings show that distance
estimation performance is jointly affected by unsteady flows and the
non-linearity of the sensor. According to our findings based on fluid dynamics,
it is evaluated that fluid dynamics should be taken into account for more
accurate parameter estimation in practical macroscale MC systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12898</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12898</id><created>2019-09-27</created><authors><author><keyname>Ghasemi</keyname><forenames>Mahsa</forenames></author><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Vikalo</keyname><forenames>Haris</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Identifying Low-Dimensional Structures in Markov Chains: A Nonnegative
  Matrix Factorization Approach</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variety of queries about stochastic systems boil down to study of Markov
chains and their properties. If the Markov chain is large, as is typically true
for discretized continuous spaces, such analysis may be computationally
intractable. Nevertheless, in many scenarios, Markov chains have underlying
structural properties that allow them to admit a low-dimensional
representation. For instance, the transition matrix associated with the model
may be low-rank and hence, representable in a lower-dimensional space. We
consider the problem of learning low-dimensional representations for
large-scale Markov chains. To that end, we formulate the task of representation
learning as that of mapping the state space of the model to a low-dimensional
state space, referred to as the kernel space. The kernel space contains a set
of meta states which are desired to be representative of only a small subset of
original states. To promote this structural property, we constrain the number
of nonzero entries of the mappings between the state space and the kernel
space. By imposing the desired characteristics of the structured
representation, we cast the problem as the task of nonnegative matrix
factorization. To compute the solution, we propose an efficient block
coordinate gradient descent and theoretically analyze its convergence
properties. Our extensive simulation results demonstrate the efficacy of the
proposed algorithm in terms of the quality of the low-dimensional
representation as well as its computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12901</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12901</id><created>2019-09-15</created><authors><author><keyname>Wang</keyname><forenames>Feifan</forenames></author><author><keyname>Jiang</keyname><forenames>Runzhou</forenames></author><author><keyname>Zheng</keyname><forenames>Liqin</forenames></author><author><keyname>Biswal</keyname><forenames>Bharat</forenames></author><author><keyname>Meng</keyname><forenames>Chun</forenames></author></authors><title>Brain-wise Tumor Segmentation and Patient Overall Survival Prediction</title><categories>eess.IV cs.CV</categories><comments>10 pages, 5 figures, 2 tables, pre-proceedings paper for Multimodal
  Brain Tumor Segmentation Challenge 2019 [BraTS
  2019](https://www.med.upenn.edu/cbica/brats2019.html)</comments><msc-class>68T45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Past few years have witnessed the prevalence of deep learning in many
application scenarios, among which is medical image processing. Diagnosis and
treatment of brain tumors require a delicate segmentation of brain tumors as a
prerequisite. However, such kind of work conventionally costs cerebral surgeons
a lot of precious time. Computer vision techniques could provide surgeons a
relief from the tedious marking procedure. In this paper, a 3D U-net based deep
learning model has been trained with the help of brain-wise normalization and
patching strategies for the brain tumor segmentation task in BraTS 2019
competition. Dice coefficients for enhancing tumor, tumor core, and the whole
tumor are 0.737, 0.807 and 0.894 respectively on validation dataset.
Furthermore, numerical features extracted from predicted tumor labels have been
used for the overall survival days prediction task. The prediction accuracy on
validation dataset is 0.448.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12912</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12912</id><created>2019-09-16</created><authors><author><keyname>Pacheco</keyname><forenames>Andre G. C.</forenames></author><author><keyname>Krohling</keyname><forenames>Renato A.</forenames></author></authors><title>The impact of patient clinical information on automated skin cancer
  detection</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><doi>10.1016/j.compbiomed.2019.103545</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skin cancer is one of the most common types of cancer around the world. For
this reason, over the past years, different approaches have been proposed to
assist detect it. Nonetheless, most of them are based only on dermoscopy images
and do not take into account the patient clinical information. In this work,
first, we present a new dataset that contains clinical images, acquired from
smartphones, and patient clinical information of the skin lesions. Next, we
introduce a straightforward approach to combine the clinical data and the
images using different well-known deep learning models. These models are
applied to the presented dataset using only the images and combining them with
the patient clinical information. We present a comprehensive study to show the
impact of the clinical data on the final predictions. The results obtained by
combining both sets of information show a general improvement of around 7% in
the balanced accuracy for all models. In addition, the statistical test
indicates significant differences between the models with and without
considering both data. The improvement achieved shows the potential of using
patient clinical information in skin cancer detection and indicates that this
piece of information is important to leverage skin cancer detection systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12917</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12917</id><created>2019-09-20</created><authors><author><keyname>Agarwal</keyname><forenames>Preeti</forenames></author><author><keyname>Alam</keyname><forenames>Mansaf</forenames></author></authors><title>A Lightweight Deep Learning Model for Human Activity Recognition on Edge
  Devices</title><categories>eess.SP cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human Activity Recognition (HAR) using wearable and mobile sensors has gained
momentum in last few years, in various fields, such as, healthcare,
surveillance, education, entertainment. Nowadays, Edge Computing has emerged to
reduce communication latency and network traffic.Edge devices are resource
constrained devices and cannot support high computation. In literature, various
models have been developed for HAR. In recent years, deep learning algorithms
have shown high performance in HAR, but these algorithms require lot of
computation making them inefficient to be deployed on edge devices. This paper,
proposes a Lightweight Deep Learning Model for HAR requiring less computational
power, making it suitable to be deployed on edge devices. The performance of
proposed model is tested on the participants six daily activities data. Results
show that the proposed model outperforms many of the existing machine learning
and deep learning techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12922</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12922</id><created>2019-09-16</created><authors><author><keyname>Li</keyname><forenames>Zeju</forenames></author><author><keyname>Li</keyname><forenames>Han</forenames></author><author><keyname>Han</keyname><forenames>Hu</forenames></author><author><keyname>Shi</keyname><forenames>Gonglei</forenames></author><author><keyname>Wang</keyname><forenames>Jiannan</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author></authors><title>Encoding CT Anatomy Knowledge for Unpaired Chest X-ray Image
  Decomposition</title><categories>eess.IV cs.CV</categories><comments>9 pages with 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although chest X-ray (CXR) offers a 2D projection with overlapped anatomies,
it is widely used for clinical diagnosis. There is clinical evidence supporting
that decomposing an X-ray image into different components (e.g., bone, lung and
soft tissue) improves diagnostic value. We hereby propose a decomposition
generative adversarial network (DecGAN) to anatomically decompose a CXR image
but with unpaired data. We leverage the anatomy knowledge embedded in CT, which
features a 3D volume with clearly visible anatomies. Our key idea is to embed
CT priori decomposition knowledge into the latent space of unpaired CXR
autoencoder. Specifically, we train DecGAN with a decomposition loss,
adversarial losses, cycle-consistency losses and a mask loss to guarantee that
the decomposed results of the latent space preserve realistic body structures.
Extensive experiments demonstrate that DecGAN provides superior unsupervised
CXR bone suppression results and the feasibility of modulating CXR components
by latent space disentanglement. Furthermore, we illustrate the diagnostic
value of DecGAN and demonstrate that it outperforms the state-of-the-art
approaches in terms of predicting 11 out of 14 common lung diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12923</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12923</id><created>2019-09-15</created><authors><author><keyname>L&#xf3;pez-Espejo</keyname><forenames>Iv&#xe1;n</forenames></author></authors><title>End-to-End Deep Residual Learning with Dilated Convolutions for
  Myocardial Infarction Detection and Localization</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, I investigate the use of end-to-end deep residual learning
with dilated convolutions for myocardial infarction (MI) detection and
localization from electrocardiogram (ECG) signals. Although deep residual
learning has already been applied to MI detection and localization, I propose a
more accurate system that distinguishes among a higher number (i.e., six) of MI
locations. Inspired by speech waveform processing with neural networks, I found
a more robust front-end than directly arranging the multi-lead ECG signal into
an input matrix consisting of the use of a single one-dimensional convolutional
layer per ECG lead to extract a pseudo-time-frequency representation and create
a compact and discriminative input feature volume. As a result, I end up with a
system achieving an MI detection and localization accuracy of 99.99% on the
well-known Physikalisch-Technische Bundesanstalt (PTB) database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12927</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12927</id><created>2019-09-19</created><authors><author><keyname>Alshemali</keyname><forenames>Basemah</forenames></author><author><keyname>Graham</keyname><forenames>Alta</forenames></author><author><keyname>Kalita</keyname><forenames>Jugal</forenames></author></authors><title>Toward Robust Image Classification</title><categories>cs.CV cs.LG eess.IV</categories><comments>2019 Intelligent Systems Conference, pp 483-489</comments><journal-ref>Intelligent Systems and Applications. IntelliSys 2019. Advances in
  Intelligent Systems and Computing, vol 1038. Springer, Cham</journal-ref><doi>10.1007/978-3-030-29513-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks are frequently used for image classification, but can be
vulnerable to misclassification caused by adversarial images. Attempts to make
neural network image classification more robust have included variations on
preprocessing (cropping, applying noise, blurring), adversarial training, and
dropout randomization. In this paper, we implemented a model for adversarial
detection based on a combination of two of these techniques: dropout
randomization with preprocessing applied to images within a given Bayesian
uncertainty. We evaluated our model on the MNIST dataset, using adversarial
images generated using Fast Gradient Sign Method (FGSM), Jacobian-based
Saliency Map Attack (JSMA) and Basic Iterative Method (BIM) attacks. Our model
achieved an average adversarial image detection accuracy of 97%, with an
average image classification accuracy, after discarding images flagged as
adversarial, of 99%. Our average detection accuracy exceeded that of recent
papers using similar techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12937</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12937</id><created>2019-09-18</created><authors><author><keyname>Ajith</keyname><forenames>Meenu</forenames></author><author><keyname>Mart&#xed;nez-Ram&#xf3;n</keyname><forenames>Manel</forenames></author></authors><title>Unsupervised Segmentation of Fire and Smoke from Infra-Red Videos</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a vision-based fire and smoke segmentation system which
use spatial, temporal and motion information to extract the desired regions
from the video frames. The fusion of information is done using multiple
features such as optical flow, divergence and intensity values. These features
extracted from the images are used to segment the pixels into different classes
in an unsupervised way. A comparative analysis is done by using multiple
clustering algorithms for segmentation. Here the Markov Random Field performs
more accurately than other segmentation algorithms since it characterizes the
spatial interactions of pixels using a finite number of parameters. It builds a
probabilistic image model that selects the most likely labeling using the
maximum a posteriori (MAP) estimation. This unsupervised approach is tested on
various images and achieves a frame-wise fire detection rate of 95.39%. Hence
this method can be used for early detection of fire in real-time and it can be
incorporated into an indoor or outdoor surveillance system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12948</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12948</id><created>2019-09-21</created><authors><author><keyname>K.</keyname><forenames>Vivekraj V.</forenames></author><author><keyname>Sen</keyname><forenames>Debashis</forenames></author><author><keyname>Raman</keyname><forenames>Balasubramanian</forenames></author></authors><title>Video Skimming: Taxonomy and Comprehensive Survey</title><categories>cs.CV eess.IV</categories><journal-ref>ACM Computing Surveys (CSUR), Volume 52, Issue 5, 2019</journal-ref><doi>10.1145/3347712</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Video skimming, also known as dynamic video summarization, generates a
temporally abridged version of a given video. Skimming can be achieved by
identifying significant components either in uni-modal or multi-modal features
extracted from the video. Being dynamic in nature, video skimming, through
temporal connectivity, allows better understanding of the video from its
summary. Having this obvious advantage, recently, video skimming has drawn the
focus of many researchers benefiting from the easy availability of the required
computing resources. In this paper, we provide a comprehensive survey on video
skimming focusing on the substantial amount of literature from the past decade.
We present a taxonomy of video skimming approaches, and discuss their evolution
highlighting key advances. We also provide a study on the components required
for the evaluation of a video skimming performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12959</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12959</id><created>2019-09-27</created><updated>2019-11-23</updated><authors><author><keyname>Wei</keyname><forenames>Jason W.</forenames></author><author><keyname>Suriawinata</keyname><forenames>Arief A.</forenames></author><author><keyname>Vaickus</keyname><forenames>Louis J.</forenames></author><author><keyname>Ren</keyname><forenames>Bing</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoying</forenames></author><author><keyname>Lisovsky</keyname><forenames>Mikhail</forenames></author><author><keyname>Tomita</keyname><forenames>Naofumi</forenames></author><author><keyname>Abdollahi</keyname><forenames>Behnaz</forenames></author><author><keyname>Kim</keyname><forenames>Adam S.</forenames></author><author><keyname>Snover</keyname><forenames>Dale C.</forenames></author><author><keyname>Baron</keyname><forenames>John A.</forenames></author><author><keyname>Barry</keyname><forenames>Elizabeth L.</forenames></author><author><keyname>Hassanpour</keyname><forenames>Saeed</forenames></author></authors><title>Deep neural networks for automated classification of colorectal polyps
  on histopathology slides: A multi-institutional evaluation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histological classification of colorectal polyps plays a critical role in
both screening for colorectal cancer and care of affected patients. An accurate
and automated algorithm for the classification of colorectal polyps on
digitized histopathology slides could benefit clinicians and patients. Evaluate
the performance and assess the generalizability of a deep neural network for
colorectal polyp classification on histopathology slide images using a
multi-institutional dataset. In this study, we developed a deep neural network
for classification of four major colorectal polyp types, tubular adenoma,
tubulovillous/villous adenoma, hyperplastic polyp, and sessile serrated
adenoma, based on digitized histopathology slides from our institution,
Dartmouth-Hitchcock Medical Center (DHMC), in New Hampshire. We evaluated the
deep neural network on an internal dataset of 157 histopathology slide images
from DHMC, as well as on an external dataset of 238 histopathology slide images
from 24 different institutions spanning 13 states in the United States. We
measured accuracy, sensitivity, and specificity of our model in this evaluation
and compared its performance to local pathologists' diagnoses at the
point-of-care retrieved from corresponding pathology laboratories. For the
internal evaluation, the deep neural network had a mean accuracy of 93.5% (95%
CI 89.6%-97.4%), compared with local pathologists' accuracy of 91.4% (95% CI
87.0%-95.8%). On the external test set, the deep neural network achieved an
accuracy of 87.0% (95% CI 82.7%-91.3%), comparable with local pathologists'
accuracy of 86.6% (95% CI 82.3%-90.9%). If confirmed in clinical settings, our
model could assist pathologists by improving the diagnostic efficiency,
reproducibility, and accuracy of colorectal cancer screenings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12962</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12962</id><created>2019-09-27</created><updated>2019-11-26</updated><authors><author><keyname>Li</keyname><forenames>Yuezun</forenames></author><author><keyname>Yang</keyname><forenames>Xin</forenames></author><author><keyname>Sun</keyname><forenames>Pu</forenames></author><author><keyname>Qi</keyname><forenames>Honggang</forenames></author><author><keyname>Lyu</keyname><forenames>Siwei</forenames></author></authors><title>Celeb-DF: A New Dataset for DeepFake Forensics</title><categories>cs.CR cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AI-synthesized face swapping videos, commonly known as the DeepFakes, have
become an emerging problem recently. Correspondingly, there is an increasing
interest in developing algorithms that can detect them. However, existing
dataset of DeepFake videos suffer from low visual quality and abundant
artifacts that do not reflect the reality of DeepFake videos circulated on the
Internet. In this work, we present a new DeepFake dataset, Celeb-DF, for the
development and evaluation of DeepFake detection algorithms. The Celeb-DF
dataset is generated using a refined synthesis algorithm that reduces the
visual artifacts observed in existing datasets. Based on the Celeb-DF dataset,
we also benchmark existing DeepFake detection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12967</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12967</id><created>2019-09-27</created><authors><author><keyname>Lin</keyname><forenames>Yuan</forenames></author><author><keyname>McPhee</keyname><forenames>John</forenames></author><author><keyname>Azad</keyname><forenames>Nasser L.</forenames></author></authors><title>Decision-Making and Control for Freeway On-Ramp Merging Using Deep
  Reinforcement Learning</title><categories>eess.SY cs.SY</categories><comments>Submitted to 2020 American Control Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies high-speed on-ramp merging decision-making and control for
an automated vehicle using deep reinforcement learning (DRL). We consider no
vehicle-to-everything (V2X) wireless communication and the merging vehicle
relies on its own sensors to obtain the states of other vehicles and the road
information to merge from on-ramp to the main road. We consider the states of
five vehicles as the environment state of the reinforcement learning training
framework: the merging vehicle, and two preceding and two following vehicles
within the sensing range of the merging vehicle when it is or is projected on
the main road. The control action of the reinforcement learning training
framework is the acceleration command for the merging vehicle. We use Deep
Deterministic Policy Gradient (DDPG) as the DRL algorithm for continuous
control, assuming there exists an optimal deterministic policy to match the
state to the action. The DRL rewards encourage merging midway between two
main-road vehicles with the same speed as the first preceding one, and penalize
hard braking, stops, and collisions. When testing the trained policy, we
observed 1 collision out of 16975 testing episodes (0.006% collision rate). By
analyzing the merging vehicle's behaviors, we found that it learned human-like
behaviors such as slowing down to merge behind or speeding up to merge ahead a
main-road vehicle. For the only collision case, we found that the merging
vehicle kept shifting between slowing down and speeding up, suggesting that it
might be trapped at a bifurcation state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12972</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12972</id><created>2019-09-27</created><authors><author><keyname>Dubosarskii</keyname><forenames>Gleb</forenames></author><author><keyname>Primak</keyname><forenames>Serguei</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author></authors><title>Stochastic Geometry of Network of Randomly Distributed Moving Vehicles
  on a Highway</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Vehicular ad-hoc networks (VANETs) have become an extensively studied topic
in contemporary research. One of the fundamental problems that has arisen in
such research is understanding the network statistical properties, such as the
cluster number distribution and the cluster size distribution. In this paper,
we analyze these characteristics in the case in which vehicles are located on a
straight road. Assuming the Rayleigh fading model and a probabilistic model of
intervehicle distance, we derive probabilistic distributions of the
aforementioned connectivity characteristics, as well as distributions of the
biggest cluster and the number of disconnected vehicles. All of the results are
confirmed by simulations carried out for the realistic values of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12973</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12973</id><created>2019-09-27</created><authors><author><keyname>Dubosarskii</keyname><forenames>Gleb</forenames></author><author><keyname>Primak</keyname><forenames>Serguei</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author></authors><title>Evolution of Vehicle Network on a Highway</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One of the challenges related to the investigation of vehicular networks is
associated with predicting a network state regarding both short-term and
long-term network evolutionary changes. This paper analyzes a case in which
vehicles are located on a straight road, and the connectivity state between two
consecutive cars is determined by the Markov chain model with two states. The
transition probabilities of the considered model are explicitly expressed in
terms of known parameters of the network using the Wang-Moayery model. Within
the presented model, the network evolution is described in terms of
determinative parameters, such as average link duration, average cluster
lifetime, and a clusters' existence probability between two fixed moments of
time. In support of the theoretically obtained probabilistic distributions, the
results of numerical simulations are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12980</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12980</id><created>2019-09-27</created><authors><author><keyname>Zhu</keyname><forenames>Yu</forenames></author><author><keyname>Iglesias</keyname><forenames>Fernando J.</forenames></author><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Segarra</keyname><forenames>Santiago</forenames></author></authors><title>Estimating Network Processes via Blind Identification of Multiple Graph
  Filters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of jointly estimating multiple network
processes driven by a common unknown input, thus effectively generalizing the
classical blind multi-channel identification problem to graphs. More precisely,
we model network processes as graph filters and consider the observation of
multiple graph signals corresponding to outputs of different filters defined on
a common graph and driven by the same input. Assuming that the underlying graph
is known and the input is unknown, our goal is to recover the specifications of
the network processes, namely the coefficients of the graph filters, only
relying on the observation of the outputs. Being generated by the same input,
these outputs are intimately related and we leverage this relationship for our
estimation purposes. Two settings are considered, one where the orders of the
filters are known and another one where they are not known. For the former
setting, we present a least-squares approach and provide conditions for
recovery. For the latter scenario, we propose a sparse recovery algorithm with
theoretical performance guarantees. Numerical experiments illustrate the
effectiveness of the proposed algorithms, the influence of different parameter
settings on the estimation performance, and the validity of our theoretical
claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12983</identifier>
 <datestamp>2019-11-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12983</id><created>2019-09-27</created><authors><author><keyname>Michelini</keyname><forenames>Pablo Navarrete</forenames></author><author><keyname>Chen</keyname><forenames>Wenbin</forenames></author><author><keyname>Liu</keyname><forenames>Hanwen</forenames></author><author><keyname>Zhu</keyname><forenames>Dan</forenames></author></authors><title>MGBPv2: Scaling Up Multi-Grid Back-Projection Networks</title><categories>eess.IV cs.CV cs.LG</categories><comments>In ICCV 2019 Workshops. Winner of Perceptual track in AIM Extreme
  Super-Resolution Challenge 2019. Code available at
  https://github.com/pnavarre/mgbpv2</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Here, we describe our solution for the AIM-2019 Extreme Super-Resolution
Challenge, where we won the 1st place in terms of perceptual quality (MOS)
similar to the ground truth and achieved the 5th place in terms of
high-fidelity (PSNR). To tackle this challenge, we introduce the second
generation of MultiGrid BackProjection networks (MGBPv2) whose major
modifications make the system scalable and more general than its predecessor.
It combines the scalability of the multigrid algorithm and the performance of
iterative backprojections. In its original form, MGBP is limited to a small
number of parameters due to a strongly recursive structure. In MGBPv2, we make
full use of the multigrid recursion from the beginning of the network; we allow
different parameters in every module of the network; we simplify the main
modules; and finally, we allow adjustments of the number of network features
based on the scale of operation. For inference tasks, we introduce an
overlapping patch approach to further allow processing of very large images
(e.g. 8K). Our training strategies make use of a multiscale loss, combining
distortion and/or perception losses on the output as well as downscaled output
images. The final system can balance between high quality and high performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12985</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12985</id><created>2019-09-27</created><authors><author><keyname>Eroglu</keyname><forenames>Yusuf</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Adaptive Kalman Tracking for Indoor Visible Light Positioning</title><categories>eess.SP</categories><comments>Accepted to be presented in IEEE Military Commun. Conf. (MILCOM),
  2019, Norfolk, VA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) utilizes light-emitting diodes (LEDs) to
transmit wireless data. A VLC network can also be used to localize mobile users
in indoor environments, where the global positioning system (GPS) signals are
weak. However, the line-of-sight (LOS) links of mobile VLC devices can be
blocked easily, which decreases the accuracy of localization. In this paper, we
study tracking a VLC user when the availability of VLC access point (AP) link
changes over the user's route. We propose a localization method for a single
available AP and use known estimation methods when a larger number of APs are
available. Tracking mobile users with Kalman filter can increase the accuracy
of the positioning, but the generic Kalman filter does not consider instant
changes in the measurement method. In order to include this information in the
position estimation, we implement an adaptive Kalman filter by modifying the
filter parameters based on the availability of APs to the user. Simulation
results show that the implemented method decreases the root-mean-square error
(RMSE) of the localization down to 30%-50% of the original estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12992</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12992</id><created>2019-09-27</created><authors><author><keyname>Mhaske</keyname><forenames>Swapnil</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Aziz</keyname><forenames>Ahsan</forenames></author></authors><title>A Blockage Model for the Open Area Mm-wave Device-to-Device Environment</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant portion of the 5th generation of wireless networks will operate
in the mm-wave bands. One of the several challenges associated with mm-wave
propagation is to overcome shadowing due to signal blockage caused by
environmental objects. Particularly susceptible are nodes in a device-to-device
network that typically operate at low power and in a blockage prone environment
such as crowded open areas. In this work, we provide an insight into the effect
of blockages on the signal quality for an open area device-to-device scenario.
We propose a blockage model based on the homogeneous Poisson Point Process. The
model provides the average signal attenuation as a soft metric that quantifies
the extent of blockage. This not only indicates whether the signal is blocked
but also measures how much the signal is attenuated due to one or more
blockers. The analytical results are confirmed with the help of Monte Carlo
simulations for real-world blocker placement in the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12999</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.12999</id><created>2019-09-27</created><authors><author><keyname>Cao</keyname><forenames>Xiaozhi</forenames></author><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>Zhang</keyname><forenames>Zijing</forenames></author><author><keyname>Iyer</keyname><forenames>Siddharth Srinivasan</forenames></author><author><keyname>Wang</keyname><forenames>Kang</forenames></author><author><keyname>He</keyname><forenames>Hongjian</forenames></author><author><keyname>Liu</keyname><forenames>Huafeng</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Zhong</keyname><forenames>Jianhui</forenames></author><author><keyname>Bilgic</keyname><forenames>Berkin</forenames></author></authors><title>T2-BUDA-gSlider: rapid high isotropic resolution T2 mapping with
  blip-up/down acquisition, generalized SLIce Dithered Enhanced Resolution and
  subspace reconstruction</title><categories>physics.med-ph eess.IV</categories><comments>30 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To obtain rapid high isotropic-resolution T2 maps with whole-brain
coverage and high geometric fidelity. Methods: A T2 blip-up/down acquisition
with generalized Slice-dithered enhanced resolution (T2-BUDA-gSlider) is
proposed. An RF-encoded multi-slab SE-EPI acquisition with variable TEs was
developed to obtain high SNR efficiency with reduced TR. This was combined with
an interleaved 2-shot acquisition using blipup/down phase encoding. An
estimated field map was incorporated into the joint multishot EPI
reconstruction with a structured low rank constraint to achieve distortion-free
and robust reconstruction for each slab without navigation. A Bloch simulated
subspace shuffling model was integrated into gSlider reconstruction and
utilized for T2 quantification. To further accelerate the acquisition and
enable shorter TEs to be sampled, partial Fourier sampling and simultaneous
multi-slab encoding were also combined with the proposed method. Results: In
vivo results demonstrated that the T2 values estimated by proposed method were
consistent with gold standard spin-echo acquisition. Compared to the reference
3D-FSE images, distortion caused by off-resonance and eddy current effects were
effectively mitigated. On patients with mesial temporal lobe epilepsy,
increased T2 values in hippocampal sclerosis regions were detected. Conclusion:
BUDA-gSlider SE-EPI acquisition and shuffling-gSlider joint reconstruction
enabled distortion-free whole-brain T2 mapping in 63 seconds at 1 mm isotropic
resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13033</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13033</id><created>2019-09-28</created><authors><author><keyname>Wang</keyname><forenames>Ruigang</forenames></author><author><keyname>Manchester</keyname><forenames>Ian R.</forenames></author></authors><title>Continuous-time Dynamic Realization for Nonlinear Stabilization via
  Control Contraction Metrics</title><categories>eess.SY cs.SY math.OC</categories><comments>submitted to ACC2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear stabilization using control contraction metric (CCM) method usually
involves an online optimization problem to compute a minimal geodesic (a
shortest path) between pair of states, which is not desirable for real-time
applications. This paper introduces a continuous-time dynamic realization which
distributes the computational cost of the optimization problem over the time
domain. The basic idea is to force the internal state of the dynamic controller
to converge to a geodesic using covariant derivative information. A numerical
example illustrates the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13037</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13037</id><created>2019-09-28</created><authors><author><keyname>Tian</keyname><forenames>Zhengkun</forenames></author><author><keyname>Yi</keyname><forenames>Jiangyan</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author><author><keyname>Bai</keyname><forenames>Ye</forenames></author><author><keyname>Wen</keyname><forenames>Zhengqi</forenames></author></authors><title>Self-Attention Transducers for End-to-End Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><journal-ref>Proc. Interspeech 2019, 4395-4399</journal-ref><doi>10.21437/Interspeech.2019-2203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural network transducers (RNN-T) have been successfully applied
in end-to-end speech recognition. However, the recurrent structure makes it
difficult for parallelization . In this paper, we propose a self-attention
transducer (SA-T) for speech recognition. RNNs are replaced with self-attention
blocks, which are powerful to model long-term dependencies inside sequences and
able to be efficiently parallelized. Furthermore, a path-aware regularization
is proposed to assist SA-T to learn alignments and improve the performance.
Additionally, a chunk-flow mechanism is utilized to achieve online decoding.
All experiments are conducted on a Mandarin Chinese dataset AISHELL-1. The
results demonstrate that our proposed approach achieves a 21.3% relative
reduction in character error rate compared with the baseline RNN-T. In
addition, the SA-T with chunk-flow mechanism can perform online decoding with
only a little degradation of the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13040</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13040</id><created>2019-09-28</created><authors><author><keyname>Huo</keyname><forenames>Yiming</forenames></author><author><keyname>Lu</keyname><forenames>Franklin</forenames></author><author><keyname>Wu</keyname><forenames>Felix</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author></authors><title>Multi-Beam Multi-Stream Communications for 5G and Beyond Mobile User
  Equipment and UAV Proof of Concept Designs</title><categories>eess.SP</categories><comments>5 pages, 7 figures. Accepted for publication at the 90th IEEE
  Vehicular Technology Conference (IEEE VTC2019-Fall), Honolulu, Hawaii, USA.
  It works!</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave), massive multiple-input multiple-output (MIMO), are
expected to play a crucial role for 5G and beyond cellular and next-generation
wireless local area network (WLAN) communications. Moreover, unmanned aerial
vehicles (UAVs) are also considered as an important component of
next-generation networks. In this paper, we propose and present a mmWave
distributed phased-arrays (DPA) architecture and proof-of-concept (PoC) designs
for user equipment (UE) and unmanned aerial vehicles (UAVs) which will be used
in 5G/Beyond 5G wireless communication networks. Through enabling a
multi-stream multi-beam communication mode, the UE PoC achieves a peak downlink
speed of more than 4 Gbps with optimized thermal distribution performance.
Furthermore, based on the DPA topology, the UAV aerial base station (ABS)
prototype is designed and demonstrates for the first time an aggregated peak
downlink data rate of 2.2 Gbps in the real-world field tests supporting
multi-user (MU) application scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13051</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13051</id><created>2019-09-28</created><authors><author><keyname>Cheng</keyname><forenames>Ming</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author><author><keyname>Asif</keyname><forenames>M. Salman</forenames></author><author><keyname>Xu</keyname><forenames>Yiling</forenames></author><author><keyname>Liu</keyname><forenames>Haojie</forenames></author><author><keyname>Bao</keyname><forenames>Wenbo</forenames></author><author><keyname>Sun</keyname><forenames>Jun</forenames></author></authors><title>A Dual Camera System for High Spatiotemporal Resolution Video
  Acquisition</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a dual camera system for high spatiotemporal resolution
(HSTR) video acquisition, where one camera shoots a video with high spatial
resolution and low frame rate (HSR-LFR) and another one captures a low spatial
resolution and high frame rate (LSR-HFR) video. Our main goal is to combine
videos from LSR-HFR and HSR-LFR cameras to create an HSTR video. We propose an
end-to-end learning framework, AWnet, mainly consisting of a FlowNet and a
FusionNet that learn an adaptive weighting function in pixel domain to combine
inputs in a frame recurrent fashion. To improve the reconstruction quality for
cameras used in reality, we also introduce noise regularization under the same
framework. Our method has demonstrated noticeable performance gains in terms of
both objective PSNR measurement in simulation with different publicly available
video and light-field datasets and subjective evaluation with real data
captured by dual iPhone 7 and Grasshopper3 cameras. Ablation studies are
further conducted to investigate and explore various aspects (such as noise
regularization, camera parallax, exposure time, multiscale synthesis, etc) of
our system to fully understand its capability for potential applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13055</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13055</id><created>2019-09-28</created><updated>2019-12-06</updated><authors><author><keyname>Nguyen</keyname><forenames>Duc Tam</forenames></author><author><keyname>Dax</keyname><forenames>Maximilian</forenames></author><author><keyname>Mummadi</keyname><forenames>Chaithanya Kumar</forenames></author><author><keyname>Ngo</keyname><forenames>Thi Phuong Nhung</forenames></author><author><keyname>Nguyen</keyname><forenames>Thi Hoai Phuong</forenames></author><author><keyname>Lou</keyname><forenames>Zhongyu</forenames></author><author><keyname>Brox</keyname><forenames>Thomas</forenames></author></authors><title>DeepUSPS: Deep Robust Unsupervised Saliency Prediction With
  Self-Supervision</title><categories>cs.CV cs.LG eess.IV</categories><comments>NeuRIPS-2019 (Vancouver, Canada): camera ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural network (DNN) based salient object detection in images based on
high-quality labels is expensive. Alternative unsupervised approaches rely on
careful selection of multiple handcrafted saliency methods to generate noisy
pseudo-ground-truth labels. In this work, we propose a two-stage mechanism for
robust unsupervised object saliency prediction, where the first stage involves
refinement of the noisy pseudo labels generated from different handcrafted
methods. Each handcrafted method is substituted by a deep network that learns
to generate the pseudo labels. These labels are refined incrementally in
multiple iterations via our proposed self-supervision technique. In the second
stage, the refined labels produced from multiple networks representing multiple
saliency methods are used to train the actual saliency detection network. We
show that this self-learning procedure outperforms all the existing
unsupervised methods over different datasets. Results are even comparable to
those of fully-supervised state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13070</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13070</id><created>2019-09-28</created><updated>2019-10-29</updated><authors><author><keyname>Shahin</keyname><forenames>Ismail</forenames></author><author><keyname>Nassif</keyname><forenames>Ali Bou</forenames></author></authors><title>Emirati-Accented Speaker Identification in Stressful Talking Conditions</title><categories>cs.SD cs.CL eess.AS</categories><comments>6 pages, this work has been accepted in The International Conference
  on Electrical and Computing Technologies and Applications, 2019 (ICECTA 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research is dedicated to improving text-independent Emirati-accented
speaker identification performance in stressful talking conditions using three
distinct classifiers: First-Order Hidden Markov Models (HMM1s), Second-Order
Hidden Markov Models (HMM2s), and Third-Order Hidden Markov Models (HMM3s). The
database that has been used in this work was collected from 25 per gender
Emirati native speakers uttering eight widespread Emirati sentences in each of
neutral, shouted, slow, loud, soft, and fast talking conditions. The extracted
features of the captured database are called Mel-Frequency Cepstral
Coefficients (MFCCs). Based on HMM1s, HMM2s, and HMM3s, average
Emirati-accented speaker identification accuracy in stressful conditions is
58.6%, 61.1%, and 65.0%, respectively. The achieved average speaker
identification accuracy in stressful conditions based on HMM3s is so similar to
that attained in subjective assessment by human listeners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13085</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13085</id><created>2019-09-28</created><authors><author><keyname>Zhang</keyname><forenames>Chunjie</forenames></author><author><keyname>Su</keyname><forenames>Yang</forenames></author><author><keyname>Hu</keyname><forenames>Siyi</forenames></author><author><keyname>Jin</keyname><forenames>Kai</forenames></author><author><keyname>Jie</keyname><forenames>Yuhan</forenames></author><author><keyname>Li</keyname><forenames>Wenshi</forenames></author><author><keyname>Nathan</keyname><forenames>Arokia</forenames></author><author><keyname>Ma</keyname><forenames>Hanbin</forenames></author></authors><title>An impedance sensing platform for monitoring heterogeneous connectivity
  and diagnostics in lab-on-a-chip systems</title><categories>eess.SY cs.SY physics.ins-det</categories><comments>5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable hardware connectivity is vital in heterogeneous integrated systems.
For example, in digital microfluidics lab-on-a-chip systems, there are hundreds
of physical connections required between a micro-electro-mechanical fabricated
device and the driving system that can be remotely located on a
printed-circuit-board. Unfortunately, the connection reliability cannot be
checked or monitored by vision-based detection methods that are commonly used
in the semiconductor industry. Therefore, a sensing platform that can be
seamlessly integrated into existing digital microfluidics systems and provide
real-time monitoring of multi-connectivity is highly desired. Here, we report
an impedance sensing platform that can provide fast detection of a single
physical connection in timescales of milli-seconds. Once connectivity is
established, the same set-up can be used to determine droplet location. The
sensing system can be scaled up to support multiple channels or applied to
other heterogeneously integrated systems that require real-time monitoring and
diagnostics of multi-connectivity systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13101</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13101</id><created>2019-09-28</created><authors><author><keyname>Abraham</keyname><forenames>Julisa Bana</forenames></author></authors><title>Plasmodium Detection Using Simple CNN and Clustered GLCM Features</title><categories>eess.IV cs.CV</categories><comments>5 Pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malaria is a serious disease caused by the Plasmodium parasite that
transmitted through the bite of a female Anopheles mosquito and invades human
erythrocytes. Malaria must be recognized precisely in order to treat the
patient in time and to prevent further spread of infection. The standard
diagnostic technique using microscopic examination is inefficient, the quality
of the diagnosis depends on the quality of blood smears and experience of
microscopists in classifying and counting infected and non-infected cells.
Convolutional Neural Networks (CNN) is one of deep learning class that able to
automate feature engineering and learn effective features that could be very
effective in diagnosing malaria. This study proposes an intelligent system
based on simple CNN for detecting malaria parasites through images of thin
blood smears. The CNN model obtained high sensitivity of 97% and relatively
high PPV of 81%. This study also proposes a false positive reduction method
using feature clustering extracted from the gray level co-occurrence matrix
(GLCM) from the Region of Interests (ROIs). Adding the GLCM feature can
significantly reduce false positives. However, this technique requires manual
set up of silhouette and euclidean distance limits to ensure cluster quality,
so it does not adversely affect sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13119</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13119</id><created>2019-09-28</created><authors><author><keyname>Wu</keyname><forenames>Jin</forenames></author></authors><title>Unified Attitude Determination Problem from Vector Observations and
  Hand-eye Measurements</title><categories>eess.SY cs.SY</categories><comments>Submitted to IEEE Transactions on Aerospace and Electronic Systems</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The hand-eye measurements have recently been proven to be very efficient for
spacecraft attitude determination relative to an ellipsoidal asteroid. However,
recent method does not guarantee full attitude observability for all
conditions. This paper refines this problem by taking the vector observations
into account so that the accuracy and robustness of the spacecraft attitude
estimation can be improved. The vector observations come from many sources
including visual perspective geometry, optical navigation and point clouds that
frequently occur in aerospace electronic systems. Completely closed-form
solutions along with their uncertainty descriptions are presented for the
proposed problem. Experiments using our simulated dataset and real-world
spacecraft measurements from NASA dawn spacecraft verify the effectiveness and
superiority of the derived solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13122</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13122</id><created>2019-09-28</created><authors><author><keyname>Chremos</keyname><forenames>Ioannis Vasileios</forenames></author><author><keyname>Malikopoulos</keyname><forenames>Andreas</forenames></author></authors><title>Social Resource Allocation in a Mobility System with Connected and
  Automated Vehicles: A Mechanism Design Problem</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the social resource allocation in an emerging
mobility system consisting of connected and automated vehicles (CAVs) using
mechanism design. CAVs provide the most intriguing opportunity for enabling
travelers to better monitor mobility system conditions and make better
decisions. However, this new reality will influence travelers'
tendency-of-travel and might give rise to rebound effects, e.g., increased
vehicles' miles traveled. We propose a mechanism design formulation that
provides an efficient social resource allocation. Our focus is on the
socio-technical aspect of the problem. By designing appropriate incentives we
seek to prevent potential rebound effects. In particular, we consider an
economically inspired mechanism with the intention to influence the impact of
the travelers' decision-making on the well-being of an emerging mobility
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13132</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13132</id><created>2019-09-28</created><authors><author><keyname>Chen</keyname><forenames>Yue</forenames></author><author><keyname>Bernstein</keyname><forenames>Andrey</forenames></author><author><keyname>Devraj</keyname><forenames>Adithya</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author></authors><title>Model-Free Primal-Dual Methods for Network Optimization with Application
  to Real-Time Optimal Power Flow</title><categories>math.OC cs.SY eess.SY</categories><comments>10 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the problem of real-time optimization of networked
systems and develops online algorithms that steer the system towards the
optimal trajectory without explicit knowledge of the system model. The problem
is modeled as a dynamic optimization problem with time-varying performance
objectives and engineering constraints. The design of the algorithms leverages
the online zero-order primal-dual projected-gradient method. In particular, the
primal step that involves the gradient of the objective function (and hence
requires networked systems model) is replaced by its zero-order approximation
with two function evaluations using a deterministic perturbation signal. The
evaluations are performed using the measurements of the system output, hence
giving rise to a feedback interconnection, with the optimization algorithm
serving as a feedback controller. The paper provides some insights on the
stability and tracking properties of this interconnection. Finally, the paper
applies this methodology to a real-time optimal power flow problem in power
systems, and shows its efficacy on the IEEE 37-node distribution test feeder
for reference power tracking and voltage regulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13139</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13139</id><created>2019-09-28</created><authors><author><keyname>Trindade</keyname><forenames>Alessandro</forenames></author><author><keyname>Cordeiro</keyname><forenames>Lucas</forenames></author></authors><title>Optimal Sizing of Stand-alone Solar PV Systems via Automated Formal
  Synthesis</title><categories>eess.SY cs.FL cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There exist various methods and tools to size solar photovoltaic systems;
however, these tools rely on simulations, which do not cover all aspects of the
design space during the search for optimal solution. In prior studies in
optimal sizing, the focus was always on criteria or objectives. Here, we
present a new sound and automated approach to obtain optimal sizing using an
unprecedented program synthesis. Our variant of counterexample guided inductive
synthesis (CEGIS) approach has two phases linking the technical and cost
analysis: first we synthesize a feasible candidate based on power reliability,
but that may not achieve the lowest cost; second, the candidate is then
verified iteratively with a lower bound cost via symbolic model checking. If
the verification step does not fail, the lower bound is adjusted; and if it
fails, a counterexample provides the optimal solution. Experimental results
using seven case studies and commercial equipment data show that our synthesis
method can produce within an acceptable run-time the optimal system sizing. We
also present a comparative with a specialized simulation tool over real
photovoltaic systems to show the effectiveness of our approach, which can
provide a more detailed and accurate solution than that simulation tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13166</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13166</id><created>2019-09-28</created><authors><author><keyname>Mehranian</keyname><forenames>Abolfazl</forenames></author><author><keyname>McGinnity</keyname><forenames>Colm J.</forenames></author><author><keyname>Neji</keyname><forenames>Radhouene</forenames></author><author><keyname>Prieto</keyname><forenames>Claudia</forenames></author><author><keyname>Hammers</keyname><forenames>Alexander</forenames></author><author><keyname>De Vita</keyname><forenames>Enrico</forenames></author><author><keyname>Reader</keyname><forenames>Andrew J.</forenames></author></authors><title>Motion-corrected and high-resolution anatomically-assisted (MOCHA)
  reconstruction of arterial spin labelling MRI</title><categories>physics.med-ph eess.IV</categories><comments>Original paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model-based reconstruction framework is proposed for MOtion-Corrected and
High-resolution anatomically-Assisted (MOCHA) reconstruction of ASL data. In
this framework, all low-resolution ASL control-label pairs are used to
reconstruct a single high-resolution cerebral blood flow (CBF) map, corrected
for rigid motion, point-spread-function (PSF) blurring and partial-volume
effect (PVE).Six volunteers were recruited for CBF imaging using PCASL
labelling, 2-shot 3D-GRASE sequences and high-resolution T1-weighted MRI. For
two volunteers, high-resolution scans with double and triple resolution in the
partition direction were additionally collected. Simulations were designed for
evaluations against a high-resolution ground-truth CBF map, including a
simulated hyper-perfused lesion and hyper/hypo-perfusion abnormalities. MOCHA
was compared to standard reconstruction and a 3D linear regression (3DLR) PVE
correction method and was further evaluated for acquisitions with reduced
control-label pairs and k-space undersampling. MOCHA reconstructions of
low-resolution ASL data showed enhanced image quality particularly in the
partition direction. In simulations, both MOCHA and 3DLR provided more accurate
CBF maps than the standard reconstruction, however MOCHA resulted in the lowest
errors and well delineated the abnormalities. MOCHA reconstruction of
standard-resolution in-vivo data showed good agreement with higher-resolution
scans requiring 4x and 9x longer acquisitions. MOCHA was found to be robust for
4x-accelerated ASL acquisitions, achieved by reduced control-label pairs or
k-space undersampling. Conclusion: MOCHA reconstruction reduces PVE by direct
reconstruction of CBF maps in the high-resolution space of the corresponding
anatomical image, incorporating motion correction and PSF modelling. Following
further evaluation, MOCHA should promote the clinical application of ASL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13170</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13170</id><created>2019-09-28</created><authors><author><keyname>Tasoujian</keyname><forenames>Shahin</forenames></author><author><keyname>Salavati</keyname><forenames>Saeed</forenames></author><author><keyname>Franchek</keyname><forenames>Matthew</forenames></author><author><keyname>Grigoriadis</keyname><forenames>Karolos</forenames></author></authors><title>Robust delay-dependent LPV output-feedback blood pressure control with
  real-time Bayesian estimation</title><categories>eess.SY cs.SY</categories><comments>12 pages, 14 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean arterial blood pressure (MAP) dynamics estimation and its automated
regulation could benefit the clinical and emergency resuscitation of critical
patients. In order to address the variability and complexity of the MAP
response of a patient to vasoactive drug infusion, a parameter-varying model
with a varying time delay is considered to describe the MAP dynamics in
response to drugs. The estimation of the varying parameters and the delay is
performed via a Bayesian-based multiple-model square root cubature Kalman
filtering approach. The estimation results validate the effectiveness of the
proposed random-walk dynamics identification method using collected animal
experiment data. Following the estimation algorithm, an automated drug delivery
scheme to regulate the MAP response of the patient is carried out via
time-delay linear parameter-varying (LPV) control techniques. In this regard,
an LPV gain-scheduled output-feedback controller is designed to meet the MAP
response requirements of tracking a desired reference MAP target and guarantee
robustness against norm-bounded uncertainties and disturbances. In this
context, parameter-dependent Lyapunov-Krasovskii functionals are used to derive
sufficient conditions for the robust stabilization of a general LPV system with
an arbitrarily varying time delay and the results are provided in a convex
linear matrix inequality (LMI) constraint framework. Finally, to evaluate the
performance of the proposed MAP regulation approach, closed-loop simulations
are conducted and the results confirm the effectiveness of the proposed control
method against various simulated clinical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13172</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13172</id><created>2019-09-28</created><authors><author><keyname>Tabak</keyname><forenames>Gizem</forenames></author><author><keyname>Yang</keyname><forenames>Sijung</forenames></author><author><keyname>Miller</keyname><forenames>Rita</forenames></author><author><keyname>Oelze</keyname><forenames>Michael</forenames></author><author><keyname>Singer</keyname><forenames>Andrew</forenames></author></authors><title>Video-Capable Ultrasonic Wireless Communications through Biological
  Tissues</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless implanted medical devices (IMDs) provide ease and comfort to an
increasing number of patients and physicians. Currently, radiofrequency
electromagnetic waves are the most commonly used method for communicating
wirelessly with IMDs. However, due to the restrictions on the available
bandwidth and the employable power, data rates of RF-based IMDs are limited to
267 kbps. Considering standard definition video streaming requiring 1.2 mbps
and high definition requiring 3 mbps bitrates, it is not possible to use such
devices for high data rate communication applications such as video streaming.
In this work, an alternative method that utilizes ultrasonic waves for IMDs to
relay information at high data rates is introduced. Advanced signal processing
and communications techniques are tailored to realize the full potential of the
ultrasonic channel through biological tissues. Consequently, the experiments
demonstrate that video-capable data rates can be achieved with mm-sized
transducers communicating through water, ex vivo beef liver, ex vivo pork chop
and in vivo rabbit abdomen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13244</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13244</id><created>2019-09-29</created><updated>2019-10-29</updated><authors><author><keyname>Shahin</keyname><forenames>Ismail</forenames></author><author><keyname>Nassif</keyname><forenames>Ali Bou</forenames></author></authors><title>Speaker Verification in Emotional Talking Environments based on
  Third-Order Circular Suprasegmental Hidden Markov Model</title><categories>cs.SD eess.AS</categories><comments>6 pages, accepted in The International Conference on Electrical and
  Computing Technologies and Applications, 2019 (ICECTA 2019). arXiv admin
  note: text overlap with arXiv:1903.09803</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker verification accuracy in emotional talking environments is not high
as it is in neutral ones. This work aims at accepting or rejecting the claimed
speaker using his/her voice in emotional environments based on the Third-Order
Circular Suprasegmental Hidden Markov Model (CSPHMM3) as a classifier. An
Emirati-accented (Arabic) speech database with Mel-Frequency Cepstral
Coefficients as the extracted features has been used to evaluate our work. Our
results demonstrate that speaker verification accuracy based on CSPHMM3 is
greater than that based on the state-of-the-art classifiers and models such as
Gaussian Mixture Model (GMM), Support Vector Machine (SVM), and Vector
Quantization (VQ).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13265</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13265</id><created>2019-09-29</created><authors><author><keyname>Tu</keyname><forenames>Fangwen</forenames></author><author><keyname>Ge</keyname><forenames>Shuzhi Sam</forenames></author><author><keyname>Choo</keyname><forenames>Yoo Sang</forenames></author><author><keyname>Hang</keyname><forenames>Chang Chieh</forenames></author></authors><title>Adaptive Control for Marine Vessels Against Harsh Environmental
  Variation</title><categories>cs.NE cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, robust control with sea state observer and dynamic thrust
allocation is proposed for the Dynamic Positioning (DP) of an accommodation
vessel in the presence of unknown hydrodynamic force variation and the input
time delay. In order to overcome the huge force variation due to the adjoining
Floating Production Storage and Offloading (FPSO) and accommodation vessel, a
novel sea state observer is designed. The sea observer can effectively monitor
the variation of the drift wave-induced force on the vessel and activate Neural
Network (NN) compensator in the controller when large wave force is identified.
Moreover, the wind drag coefficients can be adaptively approximated in the sea
observer so that a feedforward control can be achieved. Based on this, a robust
constrained control is developed to guarantee a safe operation. The time delay
inside the control input is also considered. Dynamic thrust allocation module
is presented to distribute the generalized control input among azimuth
thrusters. Under the proposed sea observer and control, the boundedness of all
the closed-loop signals are demonstrated via rigorous Lyapunov analysis. A set
of simulation studies are conducted to verify the effectiveness of the proposed
control scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13273</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13273</id><created>2019-09-29</created><updated>2019-10-03</updated><authors><author><keyname>Yang</keyname><forenames>Yuwen</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Qian</keyname><forenames>Cheng</forenames></author><author><keyname>Liao</keyname><forenames>Guisheng</forenames></author></authors><title>Model-aided Deep Neural Network for Source Number Detection</title><categories>cs.IT cs.LG eess.SP math.IT</categories><doi>10.1109/LSP.2019.2957673</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source number detection is a critical problem in array signal processing.
Conventional model-driven methods e.g., Akaikes information criterion (AIC) and
minimum description length (MDL), suffer from severe performance degradation
when the number of snapshots is small or the signal-to-noise ratio (SNR) is
low. In this paper, we exploit the model-aided based deep neural network (DNN)
to estimate the source number. Specifically, we first propose the eigenvalue
based regression network (ERNet) and classification network (ECNet) to estimate
the number of non-coherent sources, where the eigenvalues of the received
signal covariance matrix and the source number are used as the input and the
supervise label of the networks, respectively. Then, we extend the ERNet and
ECNet for estimating the number of coherent sources, where the forward-backward
spatial smoothing (FBSS) scheme is adopted to improve the performance of ERNet
and ECNet. Numerical results demonstrate the outstanding performance of ERNet
and ECNet over the conventional AIC and MDL methods as well as their excellent
generalization capability, which also shows their great potentials for
practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13287</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13287</id><created>2019-09-29</created><authors><author><keyname>Luo</keyname><forenames>Jing</forenames></author><author><keyname>Yang</keyname><forenames>Xinyu</forenames></author><author><keyname>Ji</keyname><forenames>Shulei</forenames></author><author><keyname>Li</keyname><forenames>Juan</forenames></author></authors><title>MG-VAE: Deep Chinese Folk Songs Generation with Specific Regional Style</title><categories>cs.MM cs.SD eess.AS</categories><comments>Accepted by the 7th Conference on Sound and Music Technology, 2019,
  Harbin, China</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Regional style in Chinese folk songs is a rich treasure that can be used for
ethnic music creation and folk culture research. In this paper, we propose
MG-VAE, a music generative model based on VAE (Variational Auto-Encoder) that
is capable of capturing specific music style and generating novel tunes for
Chinese folk songs (Min Ge) in a manipulatable way. Specifically, we
disentangle the latent space of VAE into four parts in an adversarial training
way to control the information of pitch and rhythm sequence, as well as of
music style and content. In detail, two classifiers are used to separate style
and content latent space, and temporal supervision is utilized to disentangle
the pitch and rhythm sequence. The experimental results show that the
disentanglement is successful and our model is able to create novel folk songs
with controllable regional styles. To our best knowledge, this is the first
study on applying deep generative model and adversarial training for Chinese
music generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13294</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13294</id><created>2019-09-29</created><authors><author><keyname>Xu</keyname><forenames>Zhe</forenames></author><author><keyname>Yazdani</keyname><forenames>Kasra</forenames></author><author><keyname>Hale</keyname><forenames>Matthew T.</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Differentially Private Controller Synthesis With Metric Temporal Logic
  Specifications</title><categories>eess.SY cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy is an important concern in various multiagent systems in which data
collected from the agents are sensitive. We propose a differentially private
controller synthesis approach for multi-agent systems subject to high-level
specifications expressed in metric temporal logic (MTL). We consider a setting
where each agent sends data to a cloud (computing station) through a set of
local hubs and the cloud is responsible for computing the control inputs of the
agents. Specifically, each agent adds privacy noise (e.g., Gaussian noise)
point-wise in time to its own outputs before sharing them with a local hub.
Each local hub runs a Kalman filter to estimate the state of the corresponding
agent and periodically sends such state estimates to the cloud. The cloud
computes the optimal inputs for each agent subject to an MTL specification.
While guaranteeing differential privacy of each agent, the controller is also
synthesized to ensure a probabilistic guarantee for satisfying the MTL
specification.We provide an implementation of the proposed method on a
simulation case study with two Baxter-On-Wheels robots as the agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13296</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13296</id><created>2019-09-29</created><updated>2020-01-23</updated><authors><author><keyname>L'Erario</keyname><forenames>Giuseppe</forenames></author><author><keyname>Fiorio</keyname><forenames>Luca</forenames></author><author><keyname>Nava</keyname><forenames>Gabriele</forenames></author><author><keyname>Bergonti</keyname><forenames>Fabio</forenames></author><author><keyname>Mohamed</keyname><forenames>Hosameldin Awadalla Omer</forenames></author><author><keyname>Traversaro</keyname><forenames>Silvio</forenames></author><author><keyname>Pucci</keyname><forenames>Daniele</forenames></author></authors><title>Modeling, Identification and Control of Model Jet Engines for Jet
  Powered Robotics</title><categories>cs.RO cs.SY eess.SY</categories><comments>8 pages, 12 figures, submitted to RA-L and ICRA</comments><doi>10.1109/LRA.2020.2970572</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper contributes towards the modeling, identification, and control of
model jet engines. We propose a nonlinear, second order model in order to
capture the model jet engines governing dynamics. The model structure is
identified by applying sparse identification of nonlinear dynamics, and then
the parameters of the model are found via gray-box identification procedures.
Once the model has been identified, we approached the control of the model jet
engine by designing two control laws. The first one is based on the classical
Feedback Linearization technique while the second one on the Sliding Mode
control. The overall methodology has been verified by modeling, identifying and
controlling two model jet engines, i.e. P100-RX and P220-RXi developed by
JetCat, which provide a maximum thrust of 100 N and 220 N, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13299</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13299</id><created>2019-09-29</created><authors><author><keyname>Cao</keyname><forenames>Yice</forenames></author><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Liang</keyname><forenames>Wenkai</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>Pixel-Wise PolSAR Image Classification via a Novel Complex-Valued Deep
  Fully Convolutional Network</title><categories>eess.IV cs.CV</categories><comments>17 pages, 12 figures, first submission on May 20th, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although complex-valued (CV) neural networks have shown better classification
results compared to their real-valued (RV) counterparts for polarimetric
synthetic aperture radar (PolSAR) classification, the extension of pixel-level
RV networks to the complex domain has not yet thoroughly examined. This paper
presents a novel complex-valued deep fully convolutional neural network
(CV-FCN) designed for PolSAR image classification. Specifically, CV-FCN uses
PolSAR CV data that includes the phase information and utilizes the deep FCN
architecture that performs pixel-level labeling. It integrates the feature
extraction module and the classification module in a united framework.
Technically, for the particularity of PolSAR data, a dedicated complex-valued
weight initialization scheme is defined to initialize CV-FCN. It considers the
distribution of polarization data to conduct CV-FCN training from scratch in an
efficient and fast manner. CV-FCN employs a complex
downsampling-then-upsampling scheme to extract dense features. To enrich
discriminative information, multi-level CV features that retain more
polarization information are extracted via the complex downsampling scheme.
Then, a complex upsampling scheme is proposed to predict dense CV labeling. It
employs complex max-unpooling layers to greatly capture more spatial
information for better robustness to speckle noise. In addition, to achieve
faster convergence and obtain more precise classification results, a novel
average cross-entropy loss function is derived for CV-FCN optimization.
Experiments on real PolSAR datasets demonstrate that CV-FCN achieves better
classification performance than other state-of-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13318</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13318</id><created>2019-09-29</created><authors><author><keyname>Arish</keyname><forenames>S</forenames></author><author><keyname>Sharma</keyname><forenames>R. K.</forenames></author></authors><title>Run-time reconfigurable multi-precision floating point multiplier design
  for high speed, low-power applications</title><categories>cs.AR eess.SP</categories><journal-ref>2015 2nd International Conference on Signal Processing and
  Integrated Networks (SPIN)</journal-ref><doi>10.1109/SPIN.2015.7095315</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Floating point multiplication is one of the crucial operations in many
application domains such as image processing, signal processing etc. But every
application requires different working features. Some need high precision, some
need low power consumption, low latency etc. But IEEE-754 format is not really
flexible for these specifications and also design is complex. Optimal run-time
reconfigurable hardware implementations may need the use of custom
floating-point formats that do not necessarily follow IEEE specified sizes. In
this paper, we present a run-time-reconfigurable floating point multiplier
implemented on FPGA with custom floating point format for different
applications. This floating point multiplier can have 6 modes of operations
depending on the accuracy or application requirement. With the use of optimal
design with custom IPs (Intellectual Properties), a better implementation is
done by truncating the inputs before multiplication. And a combination of
Karatsuba algorithm and Urdhva-Tiryagbhyam algorithm (Vedic Mathematics) is
used to implement unsigned binary multiplier. This further increases the
efficiency of the multiplier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13332</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13332</id><created>2019-09-29</created><authors><author><keyname>Tomashenko</keyname><forenames>Natalia</forenames></author><author><keyname>Caubriere</keyname><forenames>Antoine</forenames></author><author><keyname>Esteve</keyname><forenames>Yannick</forenames></author><author><keyname>Laurent</keyname><forenames>Antoine</forenames></author><author><keyname>Morin</keyname><forenames>Emmanuel</forenames></author></authors><title>Recent Advances in End-to-End Spoken Language Understanding</title><categories>cs.CL eess.AS</categories><journal-ref>Statistical Language and Speech Processing. SLSP 2019</journal-ref><doi>10.1007/978-3-030-31372-2_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates spoken language understanding (SLU) systems in the
scenario when the semantic information is extracted directly from the speech
signal by means of a single end-to-end neural network model. Two SLU tasks are
considered: named entity recognition (NER) and semantic slot filling (SF). For
these tasks, in order to improve the model performance, we explore various
techniques including speaker adaptation, a modification of the connectionist
temporal classification (CTC) training criterion, and sequential pretraining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13342</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13342</id><created>2019-09-29</created><authors><author><keyname>Tai</keyname><forenames>Ching-Lun</forenames></author><author><keyname>Su</keyname><forenames>Borching</forenames></author><author><keyname>Jia</keyname><forenames>Cai</forenames></author></authors><title>Interference-Precancelled Pilot Design for LMMSE Channel Estimation of
  GFDM</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 6 figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized frequency division multiplexing (GFDM) is a promising candidate
waveform for next-generation wireless communication systems. However, GFDM
channel estimation is still challenging due to the inherent interference. In
this paper, we formulate a pilot design framework with linear minimum mean
square error (LMMSE) channel estimation for GFDM, and propose a novel pilot
design to achieve interference precancellation during pilot generation with the
fixed transmit sample values at selected frequency bins. Numerical results
demonstrate that the proposed method reduces the channel estimation mean square
error and the symbol error rate (SER) in high signal-to-noise ratio (SNR)
regions, compared with the conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13355</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13355</id><created>2019-09-29</created><authors><author><keyname>Lei</keyname><forenames>Eric</forenames></author><author><keyname>Casta&#xf1;eda</keyname><forenames>Oscar</forenames></author><author><keyname>Tirkkonen</keyname><forenames>Olav</forenames></author><author><keyname>Goldstein</keyname><forenames>Tom</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Siamese Neural Networks for Wireless Positioning and Channel Charting</title><categories>cs.LG cs.IT eess.SP math.IT stat.ML</categories><comments>Presented at Allerton 2019; 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks have been proposed recently for positioning and channel
charting of user equipments (UEs) in wireless systems. Both of these approaches
process channel state information (CSI) that is acquired at a multi-antenna
base-station in order to learn a function that maps CSI to location
information. CSI-based positioning using deep neural networks requires a
dataset that contains both CSI and associated location information. Channel
charting (CC) only requires CSI information to extract relative position
information. Since CC builds on dimensionality reduction, it can be implemented
using autoencoders. In this paper, we propose a unified architecture based on
Siamese networks that can be used for supervised UE positioning and
unsupervised channel charting. In addition, our framework enables
semisupervised positioning, where only a small set of location information is
available during training. We use simulations to demonstrate that Siamese
networks achieve similar or better performance than existing positioning and CC
approaches with a single, unified neural network architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13369</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13369</id><created>2019-09-29</created><authors><author><keyname>Sinha</keyname><forenames>Subhrajit</forenames></author><author><keyname>Vaidya</keyname><forenames>Umesh</forenames></author><author><keyname>Yeung</keyname><forenames>Enoch</forenames></author></authors><title>Information Transfer in Dynamical Systems and Optimal Placement of
  Actuators and Sensors for Control of Non-equilibrium Dynamics</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop the concept of information transfer between the
Borel-measurable sets for a dynamical system described by a measurable space
and a non-singular transformation. The concept is based on how Shannon entropy
is transferred between the measurable sets, as the dynamical system evolves. We
show that the proposed definition of information transfer satisfies the usual
notions of information transfer and causality, namely, zero transfer and
transfer asymmetry. Furthermore, we show how the information transfer measure
can be used to classify ergodicity and mixing. We also develop the
computational methods for information transfer computation and apply the
framework for optimal placements of actuators and sensors for control of
non-equilibrium dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13387</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13387</id><created>2019-09-29</created><updated>2019-09-30</updated><authors><author><keyname>Luo</keyname><forenames>Yi</forenames></author><author><keyname>Ceolini</keyname><forenames>Enea</forenames></author><author><keyname>Han</keyname><forenames>Cong</forenames></author><author><keyname>Liu</keyname><forenames>Shih-Chii</forenames></author><author><keyname>Mesgarani</keyname><forenames>Nima</forenames></author></authors><title>FaSNet: Low-latency Adaptive Beamforming for Multi-microphone Audio
  Processing</title><categories>eess.AS cs.LG cs.SD eess.SP</categories><comments>Accepted to ASRU 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Beamforming has been extensively investigated for multi-channel audio
processing tasks. Recently, learning-based beamforming methods, sometimes
called \textit{neural beamformers}, have achieved significant improvements in
both signal quality (e.g. signal-to-noise ratio (SNR)) and speech recognition
(e.g. word error rate (WER)). Such systems are generally non-causal and require
a large context for robust estimation of inter-channel features, which is
impractical in applications requiring low-latency responses. In this paper, we
propose filter-and-sum network (FaSNet), a time-domain, filter-based
beamforming approach suitable for low-latency scenarios. FaSNet has a two-stage
system design that first learns frame-level time-domain adaptive beamforming
filters for a selected reference channel, and then calculate the filters for
all remaining channels. The filtered outputs at all channels are summed to
generate the final output. Experiments show that despite its small model size,
FaSNet is able to outperform several traditional oracle beamformers with
respect to scale-invariant signal-to-noise ratio (SI-SNR) in reverberant speech
enhancement and separation tasks. Moreover, when trained with a
frequency-domain objective function on the CHiME-3 dataset, FaSNet achieves
14.3\% relative word error rate reduction (RWERR) compared with the baseline
model. These results show the efficacy of FaSNet particularly in reverberant
and noisy signal conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13398</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13398</id><created>2019-09-29</created><updated>2019-10-01</updated><authors><author><keyname>Romero</keyname><forenames>Orlando</forenames></author><author><keyname>Chatterjee</keyname><forenames>Sarthak</forenames></author><author><keyname>Pequito</keyname><forenames>S&#xe9;rgio</forenames></author></authors><title>Fractional-Order Model Predictive Control for Neurophysiological
  Cyber-Physical Systems: A Case Study using Transcranial Magnetic Stimulation</title><categories>math.OC cs.SY eess.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractional-order dynamical systems are used to describe processes that
exhibit temporal long-term memory and power-law dependence of trajectories.
There has been evidence that complex neurophysiological signals like
electroencephalogram (EEG) can be modeled by fractional-order systems. In this
work, we propose a model-based approach for closed-loop Transcranial Magnetic
Stimulation (TMS) to regulate brain activity through EEG data. More precisely,
we propose a model predictive control (MPC) approach with an underlying
fractional-order system (FOS) predictive model. Furthermore, MPC offers, by
design, an additional layer of robustness to compensate for system-model
mismatch, which the more traditional strategies lack. To establish the
potential of our framework, we focus on epileptic seizure mitigation by
computational simulation of our proposed strategy upon seizure-like events. We
conclude by empirically analyzing the effectiveness of our method, and compare
it with event-triggered open-loop strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13420</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13420</id><created>2019-09-29</created><authors><author><keyname>Zhang</keyname><forenames>Qiao</forenames></author><author><keyname>Chen</keyname><forenames>Chang</forenames></author><author><keyname>Chen</keyname><forenames>Weidong</forenames></author><author><keyname>Ding</keyname><forenames>Jun</forenames></author><author><keyname>Zhang</keyname><forenames>Hualiang</forenames></author></authors><title>Novel Balanced Single/Dual-band Bandpass Filters Based on Circular Patch
  Resonator</title><categories>eess.SY cs.SY</categories><comments>10 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach for designing the single-band and dual-band balanced bandpass
filters (BPFs) based on the circular patch resonator is proposed in this work.
By modifying the output balanced ports of the balanced BPFs to inhibit or
transport TM31 mode of the circular patch resonator under the differential-mode
(DM) excitation, a single-band or dual-band balanced BPF can realized. As the
odd modes could be restrained under the common-mode (CM) excitation, the
balanced BPFs could achieve high CM suppression in the DM passbands. Meanwhile,
several perturbing ways are introduced to improve the performance of the
balanced BPFs. Specifically, perturbation vias are introduced to disturb the
electric field distribution to improve the CM suppression in the DM passbands,
and slots are cut on the circular patch resonators to perturb the current
distribution to modify the second DM passband of the dual-band balanced BPF.
Furthermore, the proposed single-band and dual-band balanced BPFs are
fabricated and characterized. Good agreement can be achieved between the
simulated and measured results of the fabricated balanced BPFs, which validates
the feasibility of the proposed design method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13429</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13429</id><created>2019-09-29</created><authors><author><keyname>Polar</keyname><forenames>Andrew</forenames></author><author><keyname>Poluektov</keyname><forenames>Michael</forenames></author></authors><title>Canonical block-oriented model</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The block-oriented models are usually based on linear dynamic and non-linear
static blocks that are connected in various sequential/parallel ways. Some
particular configurations of the involved blocks result in the well-known
Hammerstein, Wiener, Hammerstein-Wiener and generalised Hammerstein models. The
Urysohn model is a lesser-known model; it is represented by a single non-linear
dynamic block and can be approximated by a number of parallel Hammerstein
blocks. In this paper, it is shown that any block-oriented model can be
adequately replaced by a single Urysohn block followed by a single static
non-linear block. Furthermore, a method of the so-called non-parametric
identification of such object is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13447</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13447</id><created>2019-09-30</created><authors><author><keyname>Van Segbroeck</keyname><forenames>Maarten</forenames></author><author><keyname>Zaid</keyname><forenames>Ahmed</forenames></author><author><keyname>Kutsenko</keyname><forenames>Ksenia</forenames></author><author><keyname>Huerta</keyname><forenames>Cirenia</forenames></author><author><keyname>Nguyen</keyname><forenames>Tinh</forenames></author><author><keyname>Luo</keyname><forenames>Xuewen</forenames></author><author><keyname>Hoffmeister</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Trmal</keyname><forenames>Jan</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author><author><keyname>Maas</keyname><forenames>Roland</forenames></author></authors><title>DiPCo -- Dinner Party Corpus</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a speech data corpus that simulates a &quot;dinner party&quot; scenario
taking place in an everyday home environment. The corpus was created by
recording multiple groups of four Amazon employee volunteers having a natural
conversation in English around a dining table. The participants were recorded
by a single-channel close-talk microphone and by five far-field 7-microphone
array devices positioned at different locations in the recording room. The
dataset contains the audio recordings and human labeled transcripts of a total
of 10 sessions with a duration between 15 and 45 minutes. The corpus was
created to advance in the field of noise robust and distant speech processing
and is intended to serve as a public research and benchmarking data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13453</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13453</id><created>2019-09-30</created><authors><author><keyname>Du</keyname><forenames>Sijun</forenames></author></authors><title>Performance Analysis of SSHC Rectifiers used in Ultrasonic Wireless
  Power Transfer</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One of the key design considerations for biomedical implants is to minimize
the system volume while achieving high performance. An attractive approach to
power biomedical implants is to use wireless power transfer (WPT) with
ultrasound. To receive the ultrasonic energy, a piezoelectric transducer is
implemented, which is designed to have the resonance frequency at the frequency
of the ultrasonic wave. To extract the received energy from the transducer, an
energy rectification circuit is typically required. The commonly used rectifier
is called a synchronized switch harvesting on inductor (SSHI) rectifier, which
employs an inductor to increase the energy efficiency. However, the employment
of inductor limits the system miniaturization since it usually needs to be
around 1's mH. The synchronized switch harvesting on capacitors (SSHC)
rectifier was recently proposed to be used on vibration energy harvesting and
this architecture achieves inductor-less fully integrated design. In a
vibration energy harvesting system, the piezoelectric transducer usually has
large inherent capacitance and low resonant frequency. But the piezoelectric
transducer used in ultrasonic WPT typically has very small capacitance and much
higher resonant frequency. In this paper, the performance of a SSHC rectifier
used in ultrasonic WPT is analyzed. The analysis covers system size and
performance. Based on the analysis, this paper presents an important design
consideration on designing a SSHC rectifier to be used in ultrasonic WPT, which
is the allowed maximal ON resistance in the capacitor-to-capacitor charging
loop in function of the transducer capacitance, transducer resonant frequency
and the number of SSHC stages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13455</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13455</id><created>2019-09-30</created><authors><author><keyname>Liu</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Ding</keyname><forenames>Guohui</forenames></author><author><keyname>Chen</keyname><forenames>Lijun</forenames></author><author><keyname>Yeung</keyname><forenames>Enoch</forenames></author></authors><title>Towards Scalable Koopman Operator Learning: Convergence Rates and A
  Distributed Learning Algorithm</title><categories>eess.SP cs.LG</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an alternating optimization algorithm to the
nonconvex Koopman operator learning problem for nonlinear dynamic systems. We
show that the proposed algorithm will converge to a critical point with rate
$O(1/T)$ or $O(\frac{1}{\log T})$ under some mild assumptions. To handle the
high dimensional nonlinear dynamical systems, we present the first-ever
distributed Koopman operator learning algorithm. We show that the distributed
Koopman operator learning has the same convergence properties as a centralized
Koopman operator learning problem, in the absence of optimal tracker, so long
as the basis functions satisfy a set of state-based decomposition conditions.
Experiments are provided to complement our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13473</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13473</id><created>2019-09-30</created><updated>2019-10-14</updated><authors><author><keyname>Bujarbaruah</keyname><forenames>Monimoy</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaojing</forenames></author><author><keyname>Tanaskovic</keyname><forenames>Marko</forenames></author><author><keyname>Borrelli</keyname><forenames>Francesco</forenames></author></authors><title>Adaptive MPC under Time Varying Uncertainty: Robust and Stochastic</title><categories>eess.SY cs.SY</categories><comments>Submitted as a technical note to IEEE TAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of formulating an adaptive Model Predictive
Control strategy for constrained uncertain systems. We consider a linear
system, in presence of bounded time varying additive uncertainty. The
uncertainty is decoupled as the sum of a process noise with known bounds, and a
time varying offset that we wish to identify. The time varying offset
uncertainty is assumed unknown point-wise in time. Its domain, called the
Feasible Parameter Set, and its maximum rate of change are known to the control
designer. As new data becomes available, we refine the Feasible Parameter Set
with a Set Membership Method based approach, using the known bounds on process
noise. We consider two separate cases of robust and probabilistic constraints
on system states, with hard constraints on actuator inputs. In both cases, we
robustly satisfy the imposed constraints for all possible values of the offset
uncertainty in the Feasible Parameter Set. By imposing adequate terminal
conditions, we prove recursive feasibility and stability of the proposed
algorithms. The efficacy of the proposed robust and stochastic Adaptive MPC
algorithms is illustrated with detailed numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13480</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13480</id><created>2019-09-30</created><authors><author><keyname>Kamada</keyname><forenames>Shin</forenames></author><author><keyname>Ichimura</keyname><forenames>Takumi</forenames></author></authors><title>A Video Recognition Method by using Adaptive Structural Learning of Long
  Short Term Memory based Deep Belief Network</title><categories>cs.NE cs.CV eess.IV</categories><comments>6 pages, 7 figures, IEEE 11th International Workshop on Computational
  Intelligence and Applications (IWCIA2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning builds deep architectures such as multi-layered artificial
neural networks to effectively represent multiple features of input patterns.
The adaptive structural learning method of Deep Belief Network (DBN) can
realize a high classification capability while searching the optimal network
structure during the training. The method can find the optimal number of hidden
neurons of a Restricted Boltzmann Machine (RBM) by neuron
generation-annihilation algorithm to train the given input data, and then it
can make a new layer in DBN by the layer generation algorithm to actualize a
deep data representation. Moreover, the learning algorithm of Adaptive RBM and
Adaptive DBN was extended to the time-series analysis by using the idea of LSTM
(Long Short Term Memory). In this paper, our proposed prediction method was
applied to Moving MNIST, which is a benchmark data set for video recognition.
We challenge to reveal the power of our proposed method in the video
recognition research field, since video includes rich source of visual
information. Compared with the LSTM model, our method showed higher prediction
performance (more than 90% predication accuracy for test data).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13482</identifier>
 <datestamp>2020-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13482</id><created>2019-09-30</created><updated>2020-02-05</updated><authors><author><keyname>Ong</keyname><forenames>Frank</forenames></author><author><keyname>Zhu</keyname><forenames>Xucheng</forenames></author><author><keyname>Cheng</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Johnson</keyname><forenames>Kevin M.</forenames></author><author><keyname>Larson</keyname><forenames>Peder E. Z.</forenames></author><author><keyname>Vasanawala</keyname><forenames>Shreyas S.</forenames></author><author><keyname>Lustig</keyname><forenames>Michael</forenames></author></authors><title>Extreme MRI: Large-Scale Volumetric Dynamic Imaging from Continuous
  Non-Gated Acquisitions</title><categories>physics.med-ph eess.IV</categories><comments>Accepted to Magnetic Resonance in Medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop a framework to reconstruct large-scale volumetric dynamic
MRI from rapid continuous and non-gated acquisitions, with applications to
pulmonary and dynamic contrast enhanced (DCE) imaging.
  Theory and Methods: The problem considered here requires recovering
hundred-gigabytes of dynamic volumetric image data from a few gigabytes of
k-space data, acquired continuously over several minutes. This reconstruction
is vastly under-determined, heavily stressing computing resources as well as
memory management and storage. To overcome these challenges, we leverage
intrinsic three dimensional (3D) trajectories, such as 3D radial and 3D cones,
with ordering that incoherently cover time and k-space over the entire
acquisition. We then propose two innovations: (1) A compressed representation
using multi-scale low rank matrix factorization that constrains the
reconstruction problem, and reduces its memory footprint. (2) Stochastic
optimization to reduce computation, improve memory locality, and minimize
communications between threads and processors. We demonstrate the feasibility
of the proposed method on DCE imaging acquired with a golden-angle ordered 3D
cones trajectory and pulmonary imaging acquired with a bit-reversed ordered 3D
radial trajectory. We compare it with &quot;soft-gated&quot; dynamic reconstruction for
DCE and respiratory resolved reconstruction for pulmonary imaging.
  Results: The proposed technique shows transient dynamics that are not seen in
gating based methods. When applied to datasets with irregular, or
non-repetitive motions, the proposed method displays sharper image features.
  Conclusion: We demonstrated a method that can reconstruct massive 3D dynamic
image series in the extreme undersampling and extreme computation setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13519</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13519</id><created>2019-09-30</created><authors><author><keyname>Yoshimura</keyname><forenames>Sho</forenames></author><author><keyname>Inoue</keyname><forenames>Masaki</forenames></author></authors><title>Trajectory Planning of Weakly Supervised Aircraft</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel framework of air traffic management (ATM).
The framework is in particular characterized by the trajectory planning of
weakly supervised aircraft; the air traffic control (ATC) does not completely
determine the trajectory of each aircraft unlike conventional planning methods,
but determines allowable safe sets of trajectories. ATC requests pilots to
select their own trajectories from the sets, and the pilots determine ones by
pursuing their own aims. For example, the selection can be based on pilot
preferences and airline strategies. This two stage ATM system contributes to
simultaneously achieve the both objectives of the ATC and pilots such as fuel
cost minimization under safety management. The effectiveness of the proposed
ATM system is demonstrated in a simulation using actual air traffic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13524</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13524</id><created>2019-09-30</created><authors><author><keyname>Gao</keyname><forenames>Qing</forenames></author><author><keyname>Zhang</keyname><forenames>Guofeng</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>An Improved Quantum Projection Filter</title><categories>quant-ph cs.SY eess.SY math.OC</categories><comments>11 pages, 1 figure, submitted for publication. Comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work extends the previous quantum projection filtering scheme in [Gao
Q., Zhang G., &amp; Petersen I. R. (2019). An exponential quantum projection filter
for open quantum systems. \emph{Automatica}, 99, 59-68.], by adding an
optimality analysis result. A reformulation of the quantum projection filter is
derived by minimizing the truncated Stratonovich stochastic Taylor expansion of
the difference between the true quantum trajectory and its approximation on a
lower-dimensional submanifold through quantum information geometric techniques.
Simulation results for a qubit example demonstrate better approximation
performance for the new quantum projection filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13537</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13537</id><created>2019-09-30</created><authors><author><keyname>Rownicka</keyname><forenames>Joanna</forenames></author><author><keyname>Bell</keyname><forenames>Peter</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Embeddings for DNN speaker adaptive training</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted at ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the use of embeddings for speaker-adaptive
training of DNNs (DNN-SAT) focusing on a small amount of adaptation data per
speaker. DNN-SAT can be viewed as learning a mapping from each embedding to
transformation parameters that are applied to the shared parameters of the DNN.
We investigate different approaches to applying these transformations, and find
that with a good training strategy, a multi-layer adaptation network applied to
all hidden layers is no more effective than a single linear layer acting on the
embeddings to transform the input features. In the second part of our work, we
evaluate different embeddings (i-vectors, x-vectors and deep CNN embeddings) in
an additional speaker recognition task in order to gain insight into what
should characterize an embedding for DNN-SAT. We find the performance for
speaker recognition of a given representation is not correlated with its ASR
performance; in fact, ability to capture more speech attributes than just
speaker identity was the most important characteristic of the embeddings for
efficient DNN-SAT ASR. Our best models achieved relative WER gains of 4% and 9%
over DNN baselines using speaker-level cepstral mean normalisation (CMN), and a
fully speaker-independent model, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13551</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13551</id><created>2019-09-30</created><authors><author><keyname>Agrawal</keyname><forenames>Kshitij</forenames></author><author><keyname>Subramanian</keyname><forenames>Anbumani</forenames></author></authors><title>Enhancing Object Detection in Adverse Conditions using Thermal Imaging</title><categories>cs.CV cs.RO eess.IV</categories><comments>IROS 2019 Workshop on Towards Cognitive Vehicles</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous driving relies on deriving understanding of objects and scenes
through images. These images are often captured by sensors in the visible
spectrum. For improved detection capabilities we propose the use of thermal
sensors to augment the vision capabilities of an autonomous vehicle. In this
paper, we present our investigations on the fusion of visible and thermal
spectrum images using a publicly available dataset, and use it to analyze the
performance of object recognition on other known driving datasets. We present
an comparison of object detection in night time imagery and qualitatively
demonstrate that thermal images significantly improve detection accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13587</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13587</id><created>2019-09-30</created><authors><author><keyname>Noor-A-Rahim</keyname><forenames>Md.</forenames></author><author><keyname>Liu</keyname><forenames>Zilong</forenames></author><author><keyname>Lee</keyname><forenames>Haeyoung</forenames></author><author><keyname>Ali</keyname><forenames>G. G. Md. Nawaz</forenames></author><author><keyname>Pesch</keyname><forenames>Dirk</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author></authors><title>A Survey on Resource Allocation in Vehicular Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular networks, an enabling technology for Intelligent Transportation
System (ITS), smart cities, and autonomous driving, can deliver numerous
on-board data services, e.g., road-safety, easy navigation, traffic efficiency,
comfort driving, infotainment, etc. Providing satisfactory quality of service
(QoS) in vehicular networks, however, is a challenging task due to a number of
limiting factors such as hostile wireless channels (e.g., high mobility or
asynchronous transmissions), increasingly fragmented and congested spectrum,
hardware imperfections, and explosive growth of vehicular communication
devices. Therefore, it is highly desirable to allocate and utilize the
available wireless network resources in an ultra-efficient manner. In this
paper, we present a comprehensive survey on resource allocation (RA) schemes
for a range of vehicular network technologies including dedicated short range
communications (DSRC) and cellular based vehicular networks. We discuss the
challenges and opportunities for resource allocations in modern vehicular
networks and outline a number of promising future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13609</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13609</id><created>2019-09-30</created><authors><author><keyname>Maity</keyname><forenames>Dipankar</forenames></author><author><keyname>Tsiotras</keyname><forenames>Panagiotis</forenames></author></authors><title>Optimal Controller and Quantizer Selection for Partially Observable
  Linear-Quadratic-Gaussian Systems</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In networked control systems, often the sensory signals are quantized before
being transmitted to the controller.Consequently, performance is affected by
the coarseness of this quantization process. Modern communication technologies
allow users to obtain resolution-varying quantized measurements based on the
prices paid. In this paper,we consider optimal controller synthesis of a
partially observed Quantized-Feedback Linear-Quadratic-Gaussian (QF-LQG)
system, where the measurements are to be quantized before being sent to the
controller. The system is presented with several choices of quantizers, along
with the cost of using each quantizer. The objective is to jointly select the
quantizers and the controller that would maintain an optimal balance between
control performance and quantization cost. Under the assumption of quantizing
the innovation signal, this problem can be decoupled into two optimization
problems: one for optimal controller synthesis, and the other for optimal
quantizer selection. We show that, similarly to the classical LQG problem, the
optimal controller synthesis subproblem is characterized by Riccati equations.
On the other hand, the optimal quantizer selection policy is found offline by
solving a linear program (LP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13622</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13622</id><created>2019-08-20</created><authors><author><keyname>Xu</keyname><forenames>Nan</forenames></author><author><keyname>Ki</keyname><forenames>Wing-Hung</forenames></author></authors><title>Investigation of On-Chip Inductors for Fully Integrated DC-DC Converters</title><categories>physics.app-ph eess.SP</categories><comments>Submitted to IEEE APCCAS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On-silicon inductors using a bulk 0.18 {\mu}m CMOS process have been
designed. By shunting different metal layers in parallel, inductor values and
quality factors were simulated. Selected inductors were then employed in two
open-loop buck converters for comparison: the first used an off-chip discrete
diode, and the second used an on-chip active diode. All inductors and
converters were sent for fabrication. The fabricated inductors were then
measured to have values more than 250 nH over a wide range of frequency,
validating the simulation results. The buck converters were switched at 30 MHz
with a fixed duty ratio of 0.5, to generate an output voltage of 1.2 V from an
input voltage of 2.4 V. The peak efficiency was measured to be 69.1% for a
light load current of 12.9 mA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13640</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13640</id><created>2019-09-26</created><authors><author><keyname>Hamghalam</keyname><forenames>Mohammad</forenames></author><author><keyname>Lei</keyname><forenames>Baiying</forenames></author><author><keyname>Wang</keyname><forenames>Tianfu</forenames></author></authors><title>Brain Tumor Synthetic Segmentation in 3D Multimodal MRI Scans</title><categories>eess.IV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The magnetic resonance (MR) analysis of brain tumors is widely used for
diagnosis and examination of tumor subregions. The overlapping area among the
intensity distribution of healthy, enhancing, non-enhancing, and edema region
makes the automatic segmentation a challenging task. Here, we show that a
convolutional neural network trained on high-contrast images can transform
intensity distribution of brain lesion in its internal subregions.
Specifically, generative adversarial network (GAN) is extended to synthesize
high-contrast images. A comparison of these synthetic images and real images of
brain tumor tissue in MR scans showed significant segmentation improvement and
decreased the number of real channels for segmentation. The synthetic images
are used as a substitute for real channels and can bypass real modalities in
the multimodal brain tumor segmentation framework. Segmentation results on
BraTS 2019 dataset demonstrate that our proposed approach can efficiently
segment the tumor areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13665</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13665</id><created>2019-09-24</created><authors><author><keyname>Ianconescu</keyname><forenames>Reuven</forenames></author><author><keyname>Vulfin</keyname><forenames>Vladimir</forenames></author></authors><title>Free space transmission lines in receiving antenna operation</title><categories>physics.class-ph eess.SP</categories><comments>17 pages, 30 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work derives exact expressions for the voltage and current induced into
a two conductors non isolated transmission lines by an incident plane wave. The
methodology is to use the transmission line radiating properties to derive
scattering matrices and make use of reciprocity to derive the response to the
incident wave. The analysis is in the frequency domain and it considers
transmission lines of any small electric cross section, incident by a plane
wave from any incident direction and any polarisation. The analytic results are
validated by successful comparison with ANSYS commercial software simulation
results, and compatible with other published results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13669</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13669</id><created>2019-09-22</created><authors><author><keyname>Barwey</keyname><forenames>Shivam</forenames></author><author><keyname>Hassanaly</keyname><forenames>Malik</forenames></author><author><keyname>Raman</keyname><forenames>Venkat</forenames></author><author><keyname>Steinberg</keyname><forenames>Adam</forenames></author></authors><title>Using machine learning to construct velocity fields from OH-PLIF images</title><categories>physics.flu-dyn cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work utilizes data-driven methods to morph a series of time-resolved
experimental OH-PLIF images into corresponding three-component planar PIV
fields in the closed domain of a premixed swirl combustor. The task is carried
out with a fully convolutional network, which is a type of convolutional neural
network (CNN) used in many applications in machine learning, alongside an
existing experimental dataset which consists of simultaneous OH-PLIF and PIV
measurements in both attached and detached flame regimes. Two types of models
are compared: 1) a global CNN which is trained using images from the entire
domain, and 2) a set of local CNNs, which are trained only on individual
sections of the domain. The locally trained models show improvement in creating
mappings in the detached regime over the global models. A comparison between
model performance in attached and detached regimes shows that the CNNs are much
more accurate across the board in creating velocity fields for attached flames.
Inclusion of time history in the PLIF input resulted in small noticeable
improvement on average, which could imply a greater physical role of
instantaneous spatial correlations in the decoding process over temporal
dependencies from the perspective of the CNN. Additionally, the performance of
local models trained to produce mappings in one section of the domain is tested
on other, unexplored sections of the domain. Interestingly, local CNN
performance on unseen domain regions revealed the models' ability to utilize
symmetry and antisymmetry in the velocity field. Ultimately, this work shows
the powerful ability of the CNN to decode the three-dimensional PIV fields from
input OH-PLIF images, providing a potential groundwork for a very useful tool
for experimental configurations in which accessibility of forms of simultaneous
measurements are limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13673</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13673</id><created>2019-09-30</created><authors><author><keyname>Wu</keyname><forenames>Fang-Jing</forenames></author><author><keyname>Solmaz</keyname><forenames>G&#xfc;rkan</forenames></author></authors><title>CrowdEstimator: Approximating Crowd Sizes with Multi-modal Data for
  Internet-of-Things Services</title><categories>eess.SY cs.NI cs.SY</categories><comments>This work was funded by the joint project collaborations between NEC
  New Zealand and NEC Laboratories Europe and between NEC Laboratories Europe
  GmbH and Technische Universitat Dortmund, and has been partially funded by
  the European Union's Horizon 2020 Programme under Grant Agreement No.
  CNECT-ICT-643943 FIESTA-IoT: Federated Interoperable Semantic IoT Testbeds
  and Applications. Proc. of ACM MobiSys'18, 2018</comments><doi>10.1145/3210240.3210320</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowd mobility has been paid attention for the Internet-of-things (IoT)
applications. This paper addresses the crowd estimation problem and builds an
IoT service to share the crowd estimation results across different systems. The
crowd estimation problem is to approximate the crowd size in a targeted area
using the observed information (e.g., Wi-Fi data). This paper exploits Wi-Fi
probe request packets (&quot;Wi-Fi probes&quot; for short) broadcasted by mobile devices
to solve this problem. However, using only Wi-Fi probes to estimate the crowd
size may result in inaccurate results due to various environmental
uncertainties which may lead to crowd overestimation or underestimation.
Moreover, the ground-truth is unavailable because the coverage of Wi-Fi signals
is time-varying and invisible. This paper introduces auxiliary sensors,
stereoscopic cameras, to collect the near ground-truth at a specified
calibration choke point. Two calibration algorithms are proposed to solve the
crowd estimation problem. The key idea is to calibrate the Wi-Fi-only crowd
estimation based on the correlations between the two types of data modalities.
Then, to share the calibrated results across systems required by different
stakeholders, our system is integrated with the FIWARE-based IoT platform. To
verify the proposed system, we have launched an indoor pilot study in the
Wellington Railway Station and an outdoor pilot study in the Christchurch
Re:START Mall in New Zealand. The large-scale pilot studies show that
stereoscopic cameras can reach minimum accuracy of 85\% and high precision
detection for providing the near ground-truth. The proposed calibration
algorithms reduce estimation errors by 43.68% on average compared to the
Wi-Fi-only approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13690</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13690</id><created>2019-09-26</created><authors><author><keyname>Hada</keyname><forenames>Suryabhan Singh</forenames></author><author><keyname>Carreira-Perpi&#xf1;&#xe1;n</keyname><forenames>Miguel &#xc1;.</forenames></author></authors><title>Style Transfer by Rigid Alignment in Neural Net Feature Space</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>15 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arbitrary style transfer is an important problem in computer vision that aims
to transfer style patterns from an arbitrary style image to a given content
image. However, current methods either rely on slow iterative optimization or
fast pre-determined feature transformation, but at the cost of compromised
visual quality of the styled image; especially, distorted content structure. In
this work, we present an effective and efficient approach for arbitrary style
transfer that seamlessly transfers style patterns as well as keep content
structure intact in the styled image. We achieve this by aligning style
features to content features using rigid alignment; thus modifying style
features, unlike the existing methods that do the opposite. We demonstrate the
effectiveness of the proposed approach by generating high-quality stylized
images and compare the results with the current state-of-the-art techniques for
arbitrary style transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13692</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13692</id><created>2019-09-30</created><authors><author><keyname>Polak</keyname><forenames>Daniel</forenames></author><author><keyname>Chatnuntawech</keyname><forenames>Itthi</forenames></author><author><keyname>Yoon</keyname><forenames>Jaeyeon</forenames></author><author><keyname>Iyer</keyname><forenames>Siddharth Srinivasan</forenames></author><author><keyname>Lee</keyname><forenames>Jongho</forenames></author><author><keyname>Bachert</keyname><forenames>Peter</forenames></author><author><keyname>Adalsteinsson</keyname><forenames>Elfar</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Bilgic</keyname><forenames>Berkin</forenames></author></authors><title>Nonlinear Dipole Inversion (NDI) enables Quantitative Susceptibility
  Mapping (QSM) without parameter tuning</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Nonlinear Dipole Inversion (NDI) for high-quality Quantitative
Susceptibility Mapping (QSM) without regularization tuning, while matching the
image quality of state-of-the-art reconstruction techniques. In addition to
avoiding over-smoothing that these techniques often suffer from, we also
obviate the need for parameter selection. NDI is flexible enough to allow for
reconstruction from an arbitrary number of head orientations, and outperforms
COSMOS even when using as few as 1-direction data. This is made possible by a
nonlinear forward-model that uses the magnitude as an effective prior, for
which we derived a simple gradient descent update rule. We synergistically
combine this physics-model with a Variational Network (VN) to leverage the
power of deep learning in the VaNDI algorithm. This technique adopts the simple
gradient descent rule from NDI and learns the network parameters during
training, hence requires no additional parameter tuning. Further, we evaluate
NDI at 7T using highly accelerated Wave-CAIPI acquisitions at 0.5 mm isotropic
resolution and demonstrate high-quality QSM from as few as 2-direction data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13695</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13695</id><created>2019-09-30</created><authors><author><keyname>Wang</keyname><forenames>Linlin</forenames></author><author><keyname>Wang</keyname><forenames>Yu</forenames></author><author><keyname>Gales</keyname><forenames>Mark J. F.</forenames></author></authors><title>Non-native Speaker Verification for Spoken Language Assessment</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic spoken language assessment systems are becoming more popular in
order to handle increasing interests in second language learning. One challenge
for these systems is to detect malpractice. Malpractice can take a range of
forms, this paper focuses on detecting when a candidate attempts to impersonate
another in a speaking test. This form of malpractice is closely related to
speaker verification, but applied in the specific domain of spoken language
assessment. Advanced speaker verification systems, which leverage deep-learning
approaches to extract speaker representations, have been successfully applied
to a range of native speaker verification tasks. These systems are explored for
non-native spoken English data in this paper. The data used for speaker
enrolment and verification is mainly taken from the BULATS test, which assesses
English language skills for business. Performance of systems trained on
relatively limited amounts of BULATS data, and standard large speaker
verification corpora, is compared. Experimental results on large-scale test
sets with millions of trials show that the best performance is achieved by
adapting the imported model to non-native data. Breakdown of impostor trials
across different first languages (L1s) and grades is analysed, which shows that
inter-L1 impostors are more challenging for speaker verification systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13720</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13720</id><created>2019-09-30</created><updated>2019-10-02</updated><authors><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>On Incentive Compatibility in Dynamic Mechanism Design With Exit Option
  in a Markovian Environment</title><categories>math.DS cs.SY econ.TH eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies dynamic mechanism design in a quasilinear Markovian
environment and analyzes a direct mechanism model of a principal-agent
framework in which the agent is allowed to exit at any period. We consider that
the agent's private information, referred to as state, evolves over time. The
agent makes decisions of whether to stop or continue and what to report at each
period. The principal, on the other hand, chooses decision rules consisting of
an allocation rule and a set of payment rules to maximize her ex-ante expected
payoff. In order to influence the agent's stopping decision, one of the
terminal payment rules is posted-price, i.e., it depends only on the realized
stopping time of the agent. We define the incentive compatibility in this
dynamic environment in terms of Bellman equations, which is then simplified by
establishing a one-shot deviation principle. Given the optimality of the
stopping rule, a sufficient condition for incentive compatibility is obtained
by constructing the state-dependent payment rules in terms of a set of
functions parameterized by the allocation rule. A necessary condition is
derived from envelope theorem, which explicitly formulates the state-dependent
payment rules in terms of allocation rules. A class of monotone environment is
considered to characterize the optimal stopping by a threshold rule. The
posted-price payment rules are then pinned down in terms of the allocation rule
and the threshold function up to a constant. The incentive compatibility
constraints restrict the design of the posted-price payment rule by a regular
condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13730</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13730</id><created>2019-09-30</created><updated>2019-10-01</updated><authors><author><keyname>Chekanov</keyname><forenames>Mikhail</forenames></author><author><keyname>Shipitko</keyname><forenames>Oleg</forenames></author></authors><title>X-ray and Visible Spectra Circular Motion Images Dataset</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the collections of images of the same rotating plastic object made
in X-ray and visible spectra. Both parts of the dataset contain 400 images. The
images are maid every 0.5 degrees of the object axial rotation. The collection
of images is designed for evaluation of the performance of circular motion
estimation algorithms as well as for the study of X-ray nature influence on the
image analysis algorithms such as keypoints detection and description. The
dataset is available at https://github.com/Visillect/xvcm-dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13751</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13751</id><created>2019-09-27</created><authors><author><keyname>Kundal</keyname><forenames>Shubham</forenames></author><author><keyname>Lohiya</keyname><forenames>Raunak</forenames></author><author><keyname>Bansal</keyname><forenames>Hritik</forenames></author><author><keyname>Johri</keyname><forenames>Shreya</forenames></author><author><keyname>Sarwal</keyname><forenames>Varuni</forenames></author><author><keyname>Shah</keyname><forenames>Kushal</forenames></author></authors><title>Computational prediction of replication sites in DNA sequences using
  complex number representation</title><categories>q-bio.GN eess.SP</categories><comments>4 Figures, 1 Table. arXiv admin note: substantial text overlap with
  arXiv:1701.00707</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational prediction of origin of replication (ORI) has been of great
interest in bioinformatics and several methods including GC-skew,
auto-correlation etc. have been explored in the past. In this paper, we have
extended the auto-correlation method to predict ORI location with much higher
resolution for prokaryotes and eukaryotes, which can be very helpful in
experimental validation of the computational predictions. The proposed complex
correlation method (iCorr) converts the genome sequence into a sequence of
complex numbers by mapping the nucleotides to {+1,-1,+i,-i} instead of {+1,-1}
used in the auto-correlation method (here, i is square root of -1). Thus, the
iCorr method exploits the complete spatial information about the positions of
all the four nucleotides unlike the earlier auto-correlation method which uses
the positional information of only one nucleotide. Also, the earlier
auto-correlation method required visual inspection of the obtained graphs to
identify the location of origin of replication. The proposed iCorr method does
away with this need and is able to identify the origin location simply by
picking the peak in the iCorr graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13759</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13759</id><created>2019-09-30</created><authors><author><keyname>Fainberg</keyname><forenames>Joachim</forenames></author><author><keyname>Klejch</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>Loweimi</keyname><forenames>Erfan</forenames></author><author><keyname>Bell</keyname><forenames>Peter</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Acoustic Model Adaptation from Raw Waveforms with SincNet</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted to IEEE ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Raw waveform acoustic modelling has recently gained interest due to neural
networks' ability to learn feature extraction, and the potential for finding
better representations for a given scenario than hand-crafted features. SincNet
has been proposed to reduce the number of parameters required in raw-waveform
modelling, by restricting the filter functions, rather than having to learn
every tap of each filter. We study the adaptation of the SincNet filter
parameters from adults' to children's speech, and show that the
parameterisation of the SincNet layer is well suited for adaptation in
practice: we can efficiently adapt with a very small number of parameters,
producing error rates comparable to techniques using orders of magnitude more
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13775</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13775</id><created>2019-09-26</created><authors><author><keyname>Goudard</keyname><forenames>Vincent</forenames><affiliation>SU</affiliation></author></authors><title>Ephemeral instruments</title><categories>cs.HC cs.SD eess.AS</categories><comments>New Interfaces for Musical Expression, Jun 2019, Porto-Alegre, Brazil</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article questions the notion of ephemerality of digital musical
instruments (DMI). Longevity is generally regarded as a valuable quality that
good design criteria should help to achieve. However, the nature of the tools,
of the performance conditions and of the music itself may lead to think of
ephemerality as an intrinsic modality of the existence of DMIs. In particular,
the conditions of contemporary musical production suggest that contextual
adaptations of instrumental devices beyond the monolithic unity of classical
instruments should be considered. The first two parts of this article analyse
various reasons to reassess the issue of longevity and ephemerality. The last
two sections attempt to propose an articulation of these two aspects to inform
both the design of the DMI and their learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13780</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13780</id><created>2019-09-26</created><authors><author><keyname>Saint-Drenan</keyname><forenames>Yves-Marie</forenames></author><author><keyname>Besseau</keyname><forenames>Romain</forenames></author><author><keyname>Jansen</keyname><forenames>Malte</forenames></author><author><keyname>Staffell</keyname><forenames>Iain</forenames></author><author><keyname>Troccoli</keyname><forenames>Alberto</forenames></author><author><keyname>Dubus</keyname><forenames>Laurent</forenames></author><author><keyname>Schmidt</keyname><forenames>Johannes</forenames></author><author><keyname>Gruber</keyname><forenames>Katharina</forenames></author><author><keyname>Sim&#xf5;es</keyname><forenames>Sofia G.</forenames></author><author><keyname>Heier</keyname><forenames>Siegfried</forenames></author></authors><title>A parametric model for wind turbine power curves incorporating
  environmental conditions</title><categories>eess.SP physics.app-ph</categories><comments>preprint submitted to Renewable Energy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wind turbine's power curve relates its power production to the wind speed
it experiences. The typical shape of a power curve is well known and has been
studied extensively; however, the power curves of individual turbine models can
vary widely from one another. This is due to both the technical features of the
turbine (power density, cut-in and cut-out speeds, limits on rotational speed
and aerodynamic efficiency), and environmental factors (turbulence intensity,
air density, wind shear and wind veer). Data on individual power curves are
often proprietary and only available through commercial databases.
  We therefore develop an open-source model which can generate the power curve
of any turbine, adapted to the specific conditions of any site. This can employ
one of six parametric models advanced in the literature, and accounts for the
eleven variables mentioned above. The model is described, the impact of each
technical and environmental feature is examined, and it is then validated
against the manufacturer power curves of 91 turbine models. Versions of the
model are made available in MATLAB, R and Python code for the community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13783</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13783</id><created>2019-09-30</created><authors><author><keyname>Pinto</keyname><forenames>Samuel C.</forenames></author><author><keyname>Andersson</keyname><forenames>Sean B.</forenames></author><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Cassandras</keyname><forenames>Christos G.</forenames></author></authors><title>Optimal Periodic Multi-Agent Persistent Monitoring of a Finite Set of
  Targets with Uncertain States</title><categories>eess.SY cs.SY</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of persistently monitoring a finite set of targets
with internal states that evolve with linear stochastic dynamics using a finite
set of mobile agents. We approach the problem from the infinite-horizon
perspective, looking for periodic movement schedules for the agents. Under
linear dynamics and some standard assumptions on the noise distribution, the
optimal estimator is a Kalman-Bucy filter and the mean estimation error is a
function of its covariance matrix, which evolves as a differential Riccati
equation. It is shown that when the agents are constrained to move only over a
line and they can see at most one target at a time, the movement policy that
minimizes the mean estimation error over time is such that the agent is always
either moving with maximum speed or dwelling at a fixed position. This type of
trajectory can be fully defined by a finite set of parameters. For periodic
trajectories, under some observability conditions, the estimation error
converges to a steady state condition and the stochastic gradient estimate of
the cost with respect to the trajectory parameters of each agent and the global
period can be explicitly computed using Infinitesimal Perturbation Analysis. A
gradient-descent approach is used to compute locally optimal parameters. This
approach allows us to deal with a very long persistent monitoring horizon using
a small number of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13784</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13784</id><created>2019-09-27</created><authors><author><keyname>Tan</keyname><forenames>Reuben</forenames></author><author><keyname>Xu</keyname><forenames>Huijuan</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author><author><keyname>Plummer</keyname><forenames>Bryan A.</forenames></author></authors><title>wMAN: Weakly-supervised Moment Alignment Network for Text-based Video
  Segment Retrieval</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a video and a sentence, the goal of weakly-supervised video moment
retrieval is to locate the video segment which is described by the sentence
without having access to temporal annotations during training. Instead, a model
must learn how to identify the correct segment (i.e. moment) when only being
provided with video-sentence pairs. Thus, an inherent challenge is
automatically inferring the latent correspondence between visual and language
representations. To facilitate this alignment, we propose our Weakly-supervised
Moment Alignment Network (wMAN) which exploits a multi-level co-attention
mechanism to learn richer multimodal representations. The aforementioned
mechanism is comprised of a Frame-By-Word interaction module as well as a novel
Word-Conditioned Visual Graph (WCVG). Our approach also incorporates a novel
application of positional encodings, commonly used in Transformers, to learn
visual-semantic representations that contain contextual information of their
relative positions in the temporal sequence through iterative message-passing.
Comprehensive experiments on the DiDeMo and Charades-STA datasets demonstrate
the effectiveness of our learned representations: our combined wMAN model not
only outperforms the state-of-the-art weakly-supervised method by a significant
margin but also does better than strongly-supervised state-of-the-art methods
on some metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13790</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13790</id><created>2019-09-30</created><authors><author><keyname>Constantin</keyname><forenames>Stefan</forenames></author><author><keyname>Niehues</keyname><forenames>Jan</forenames></author><author><keyname>Waibel</keyname><forenames>Alex</forenames></author></authors><title>Incremental processing of noisy user utterances in the spoken language
  understanding task</title><categories>cs.CL cs.SD eess.AS</categories><comments>10 pages, 3 figures, 7 tables, forthcoming in W-NUT 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The state-of-the-art neural network architectures make it possible to create
spoken language understanding systems with high quality and fast processing
time. One major challenge for real-world applications is the high latency of
these systems caused by triggered actions with high executions times. If an
action can be separated into subactions, the reaction time of the systems can
be improved through incremental processing of the user utterance and starting
subactions while the utterance is still being uttered. In this work, we present
a model-agnostic method to achieve high quality in processing incrementally
produced partial utterances. Based on clean and noisy versions of the ATIS
dataset, we show how to create datasets with our method to create low-latency
natural language understanding components. We get improvements of up to 47.91
absolute percentage points in the metric F1-score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13817</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13817</id><created>2019-09-30</created><authors><author><keyname>Nguyen</keyname><forenames>Thanh Huy</forenames></author><author><keyname>Daniel</keyname><forenames>Sylvie</forenames></author><author><keyname>Gueriot</keyname><forenames>Didier</forenames></author><author><keyname>Sintes</keyname><forenames>Christophe</forenames></author><author><keyname>Caillec</keyname><forenames>Jean-Marc Le</forenames></author></authors><title>Coarse-to-Fine Registration of Airborne LiDAR Data and Optical Imagery
  on Urban Scenes</title><categories>eess.IV cs.CV</categories><comments>17 pages, 12 figures. Submitted to IEEE TGRS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications based on synergistic integration of optical imagery and LiDAR
data are receiving a growing interest from the remote sensing community.
However, a misaligned integration between these datasets may fail to fully
profit the potential of both sensors. In this regard, an optimum fusion of
optical imagery and LiDAR data requires an accurate registration. This is a
complex problem since a versatile solution is still missing, especially when
considering the context where data are collected at different times, from
different platforms, under different acquisition configurations. This paper
presents a coarse-to-fine registration method of aerial/satellite optical
imagery with airborne LiDAR data acquired in such context. Firstly, a coarse
registration involves extracting and matching of buildings from LiDAR data and
optical imagery. Then, a Mutual Information-based fine registration is carried
out. It involves a super-resolution approach applied to LiDAR data, and a local
approach of transformation model estimation. The proposed method succeeds at
overcoming the challenges associated with the aforementioned difficult context.
Considering the experimented airborne LiDAR (2011) and orthorectified aerial
imagery (2016) datasets, their spatial shift is reduced by 48.15% after the
proposed coarse registration. Moreover, the incompatibility of size and spatial
resolution is addressed by the mentioned super-resolution. Finally, a high
accuracy of dataset alignment is also achieved, highlighted by a 40-cm error
based on a check-point assessment and a 64-cm error based on a check-pair-line
assessment. These promising results enable further research for a complete
versatile fusion methodology between airborne LiDAR and optical imagery data in
this challenging context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13834</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13834</id><created>2019-09-12</created><authors><author><keyname>Zhang</keyname><forenames>Wen</forenames></author><author><keyname>Wang</keyname><forenames>Yalin</forenames></author></authors><title>Geometric Brain Surface Network For Brain Cortical Parcellation</title><categories>eess.IV cs.CV cs.LG</categories><comments>8 pages</comments><journal-ref>GLMI in Conjunction with MICCAI 2019</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A large number of surface-based analyses on brain imaging data adopt some
specific brain atlases to better assess structural and functional changes in
one or more brain regions. In these analyses, it is necessary to obtain an
anatomically correct surface parcellation scheme in an individual brain by
referring to the given atlas. Traditional ways to accomplish this goal are
through a designed surface-based registration or hand-crafted surface features,
although both of them are time-consuming. A recent deep learning approach
depends on a regular spherical parameterization of the mesh, which is
computationally prohibitive in some cases and may also demand further
post-processing to refine the network output. Therefore, an accurate and
fully-automatic cortical surface parcellation scheme directly working on the
original brain surfaces would be highly advantageous. In this study, we propose
an end-to-end deep brain cortical parcellation network, called \textbf{DBPN}.
Through intrinsic and extrinsic graph convolution kernels, DBPN dynamically
deciphers neighborhood graph topology around each vertex and encodes the
deciphered knowledge into node features. Eventually, a non-linear mapping
between the node features and parcellation labels is constructed. Our model is
a two-stage deep network which contains a coarse parcellation network with a
U-shape structure and a refinement network to fine-tune the coarse results. We
evaluate our model in a large public dataset and our work achieves superior
performance than state-of-the-art baseline methods in both accuracy and
efficiency
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13863</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.13863</id><created>2019-09-30</created><authors><author><keyname>Bulat</keyname><forenames>Adrian</forenames></author><author><keyname>Tzimiropoulos</keyname><forenames>Georgios</forenames></author></authors><title>XNOR-Net++: Improved Binary Neural Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted to BMVC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an improved training algorithm for binary neural networks
in which both weights and activations are binary numbers. A key but fairly
overlooked feature of the current state-of-the-art method of XNOR-Net is the
use of analytically calculated real-valued scaling factors for re-weighting the
output of binary convolutions. We argue that analytic calculation of these
factors is sub-optimal. Instead, in this work, we make the following
contributions: (a) we propose to fuse the activation and weight scaling factors
into a single one that is learned discriminatively via backpropagation. (b)
More importantly, we explore several ways of constructing the shape of the
scale factors while keeping the computational budget fixed. (c) We empirically
measure the accuracy of our approximations and show that they are significantly
more accurate than the analytically calculated one. (d) We show that our
approach significantly outperforms XNOR-Net within the same computational
budget when tested on the challenging task of ImageNet classification, offering
up to 6\% accuracy gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00046</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00046</id><created>2019-09-30</created><authors><author><keyname>Makkapati</keyname><forenames>Venkata Ramana</forenames></author><author><keyname>Maity</keyname><forenames>Dipankar</forenames></author><author><keyname>Dor</keyname><forenames>Mehregan</forenames></author><author><keyname>Tsiotras</keyname><forenames>Panagiotis</forenames></author></authors><title>C-DOC: Co-State Desensitized Optimal Control</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, co-states are used to develop a framework that desensitizes
the optimal cost. A general formulation for an optimal control problem with
fixed final time is considered. The proposed scheme involves elevating the
parameters of interest into states, and further augmenting the co-state
equations of the optimal control problem to the dynamical model. A running cost
that penalizes the co-states of the targeted parameters is then added to the
original cost function. The solution obtained by minimizing the augmented cost
yields a control which reduces the dispersion of the original cost with respect
to parametric variations. The relationship between co-states and the cost-to-go
function, for any given control law, is established substantiating the
approach. Numerical examples and Monte-Carlo simulations that demonstrate the
proposed scheme are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00060</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00060</id><created>2019-09-30</created><authors><author><keyname>He</keyname><forenames>Jiguang</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Kong</keyname><forenames>Long</forenames></author><author><keyname>Silv&#xe9;n</keyname><forenames>Olli</forenames></author><author><keyname>Juntti</keyname><forenames>Markku</forenames></author></authors><title>Large Intelligent Surface for Positioning in Millimeter Wave MIMO
  Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 5 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) multiple-input multiple-output (MIMO) system for the
fifth generation (5G) cellular communications can also enable single-anchor
positioning and object tracking due to its large bandwidth and inherently high
angular resolution. In this paper, we introduce the newly invented concept,
large intelligent surface (LIS), to mmWave positioning systems, study the
theoretical performance bounds (i.e., Cram\'er-Rao lower bounds) for
positioning, and evaluate the impact of the number of LIS elements and the
value of phase shifters on the position estimation accuracy compared to the
conventional scheme with one direct link and one non-line-of-sight path. It is
verified that better performance can be achieved with a LIS from the
theoretical analyses and numerical study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00064</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00064</id><created>2019-09-30</created><authors><author><keyname>Khairullah</keyname><forenames>Shawkat Sabah</forenames></author></authors><title>A Self-Healing Hardware Architecture for Safety-Critical Digital
  Embedded Devices</title><categories>cs.OH eess.SP</categories><comments>7 pages, 4 figures, 2 tables</comments><journal-ref>International Journal of Innovative Research in Computer and
  Communication Engineering 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Embedded Devices of next-generation safety-critical industrial
automation systems require high levels of survivability and resilience against
the hardware and software failure. One of the concepts for achieving this
requirement is the design of resilient and survivable digital embedded systems.
In the last two decades, development of self-healing digital systems based on
molecular and cellular biology have received attention for the design of robust
digital systems. However, many of these approaches have not been architected
from the outset with safety in mind, nor have they been targeted for the
applications of automation community where a significant need exists. This
paper presents a new self-healing hardware architecture, inspired from the way
nature responds, defends and heals: the stem cells in the immune system of
living organisms, the life cycle of the living cell, and the pathway from
Deoxyribonucleic acid (DNA) to protein. The proposed architecture is
integrating cellular-based biological concepts, traditional fault tolerance
techniques, and operational schematics for the international standard IEC
61131-3 to facilitate adoption in the automation industry and safety-critical
applications. To date, two industrial applications have been mapped on the
proposed architecture, which are capable of tolerating a significant number of
faults that can stem from harsh environmental changes and external disturbances
and we believe the nexus of its concepts can positively impact the next
generation of critical systems in the automation industry
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00067</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00067</id><created>2019-09-30</created><authors><author><keyname>Stephenson</keyname><forenames>Cory</forenames></author><author><keyname>Keskin</keyname><forenames>Gokce</forenames></author><author><keyname>Thomas</keyname><forenames>Anil</forenames></author><author><keyname>Elibol</keyname><forenames>Oguz H.</forenames></author></authors><title>Semi-supervised voice conversion with amortized variational inference</title><categories>stat.ML cs.LG eess.AS</categories><comments>Accepted for publication at Interspeech 2019</comments><journal-ref>Proc. Interspeech 2019 (2019): 729-733</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce a semi-supervised approach to the voice conversion
problem, in which speech from a source speaker is converted into speech of a
target speaker. The proposed method makes use of both parallel and non-parallel
utterances from the source and target simultaneously during training. This
approach can be used to extend existing parallel data voice conversion systems
such that they can be trained with semi-supervision. We show that incorporating
semi-supervision improves the voice conversion performance compared to fully
supervised training when the number of parallel utterances is limited as in
many practical applications. Additionally, we find that increasing the number
non-parallel utterances used in training continues to improve performance when
the amount of parallel training data is held constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00071</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00071</id><created>2019-09-30</created><authors><author><keyname>Grigorescu</keyname><forenames>Irina</forenames></author><author><keyname>Cordero-Grande</keyname><forenames>Lucilio</forenames></author><author><keyname>Edwards</keyname><forenames>A David</forenames></author><author><keyname>Hajnal</keyname><forenames>Jo</forenames></author><author><keyname>Modat</keyname><forenames>Marc</forenames></author><author><keyname>Deprez</keyname><forenames>Maria</forenames></author></authors><title>Interpretable Convolutional Neural Networks for Preterm Birth
  Classification</title><categories>eess.IV</categories><report-no>MIDL/2019/ExtendedAbstract/SyevkEaEcE</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The use of convolutional neural networks (CNNs) for classification tasks has
become dominant in various medical imaging applications. At the same time,
recent advances in interpretable machine learning techniques have shown great
potential in explaining classifiers' decisions. Layer-wise relevance
propagation (LRP) has been introduced as one of these novel methods that aim to
provide visual interpretation for the network's decisions. In this work we
propose the application of 3D CNNs with LRP for the first time for neonatal
T2-weighted magnetic resonance imaging (MRI) data analysis. Through LRP, the
decisions of our trained classifier are transformed into heatmaps indicating
each voxel's relevance for the outcome of the decision. Our resulting LRP
heatmaps reveal anatomically plausible features in distinguishing preterm
neonates from term ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00087</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00087</id><created>2019-09-18</created><authors><author><keyname>Jiang</keyname><forenames>Longsheng</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author></authors><title>Respect Your Emotion: Human-Multi-Robot Teaming based on Regret Decision
  Model</title><categories>cs.AI cs.HC cs.SY eess.SY</categories><comments>8 pages, 4 figures, conference</comments><journal-ref>IEEE 15th International Conference on Automation Science and
  Engineering (CASE), Vancouver, BC, Canada, August 22-26, 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Often, when modeling human decision-making behaviors in the context of
human-robot teaming, the emotion aspect of human is ignored. Nevertheless, the
influence of emotion, in some cases, is not only undeniable but beneficial.
This work studies the human-like characteristics brought by regret emotion in
one-human-multi-robot teaming for the application of domain search. In such
application, the task management load is outsourced to the robots to reduce the
human's workload, freeing the human to do more important work. The regret
decision model is first used by each robot for deciding whether to request
human service, then is extended for optimally queuing the requests from
multiple robots. For the movement of the robots in the domain search, we
designed a path planning algorithm based on dynamic programming for each robot.
The simulation shows that the human-like characteristics, namely, risk-seeking
and risk-aversion, indeed bring some appealing effects for balancing the
workload and performance in the human-multi-robot team.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00092</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00092</id><created>2019-09-30</created><authors><author><keyname>Zhang</keyname><forenames>Jiayi</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Yang</keyname><forenames>Hong</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author></authors><title>Multiple Antenna Technologies for Beyond 5G</title><categories>cs.IT eess.SP math.IT</categories><comments>47 pages, guest editor-authored tutorial paper submitted to IEEE JSAC
  special issue on Multiple Antenna Technologies for Beyond 5G</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple antenna technologies have attracted large research interest for
several decades and have gradually made their way into mainstream communication
systems. Two main benefits are adaptive beamforming gains and spatial
multiplexing, leading to high data rates per user and per cell, especially when
large antenna arrays are used. Now that multiple antenna technology has become
a key component of the fifth-generation (5G) networks, it is time for the
research community to look for new multiple antenna applications to meet the
immensely higher data rate, reliability, and traffic demands in the beyond 5G
era. We need radically new approaches to achieve orders-of-magnitude
improvements in these metrics and this will be connected to large technical
challenges, many of which are yet to be identified. In this survey paper, we
present a survey of three new multiple antenna related research directions that
might play a key role in beyond 5G networks: Cell-free massive multiple-input
multiple-output (MIMO), beamspace massive MIMO, and intelligent reflecting
surfaces. More specifically, the fundamental motivation and key characteristics
of these new technologies are introduced. Recent technical progress is also
presented. Finally, we provide a list of other prospective future research
directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00095</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00095</id><created>2019-09-27</created><updated>2020-02-15</updated><authors><author><keyname>Fadnavis</keyname><forenames>Shreyas</forenames></author><author><keyname>Farooq</keyname><forenames>Hamza</forenames></author><author><keyname>Afzali</keyname><forenames>Maryam</forenames></author><author><keyname>Lenglet</keyname><forenames>Christoph</forenames></author><author><keyname>Georgiou</keyname><forenames>Tryphon</forenames></author><author><keyname>Cheng</keyname><forenames>Hu</forenames></author><author><keyname>Newman</keyname><forenames>Sharlene</forenames></author><author><keyname>Ahmed</keyname><forenames>Shahnawaz</forenames></author><author><keyname>Henriques</keyname><forenames>Rafael Neto</forenames></author><author><keyname>Peterson</keyname><forenames>Eric</forenames></author><author><keyname>Koudoro</keyname><forenames>Serge</forenames></author><author><keyname>Rokem</keyname><forenames>Ariel</forenames></author><author><keyname>Garyfallidis</keyname><forenames>Eleftherios</forenames></author></authors><title>Fitting IVIM with Variable Projection and Simplicial Optimization</title><categories>eess.IV cs.CV q-bio.QM stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fitting multi-exponential models to Diffusion MRI (dMRI) data has always been
challenging due to various underlying complexities. In this work, we introduce
a novel and robust fitting framework for the standard two-compartment IVIM
microstructural model. This framework provides a significant improvement over
the existing methods and helps estimate the associated diffusion and perfusion
parameters of IVIM in an automatic manner. As a part of this work we provide
capabilities to switch between more advanced global optimization methods such
as simplicial homology (SH) and differential evolution (DE). Our experiments
show that the results obtained from this simultaneous fitting procedure
disentangle the model parameters in a reduced subspace. The proposed framework
extends the seminal work originated in the MIX framework, with improved
procedures for multi-stage fitting. This framework has been made available as
an open-source Python implementation and disseminated to the community through
the DIPY project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00099</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00099</id><created>2019-09-17</created><updated>2019-10-02</updated><authors><author><keyname>Ding</keyname><forenames>Wenhao</forenames></author><author><keyname>Xu</keyname><forenames>Mengdi</forenames></author><author><keyname>Zhao</keyname><forenames>Ding</forenames></author></authors><title>CMTS: Conditional Multiple Trajectory Synthesizer for Generating
  Safety-critical Driving Scenarios</title><categories>cs.LG cs.CV cs.RO eess.IV stat.ML</categories><comments>Submitted to ICRA 2020, 8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Naturalistic driving trajectories are crucial for the performance of
autonomous driving algorithms. However, most of the data is collected in safe
scenarios leading to the duplication of trajectories which are easy to be
handled by currently developed algorithms. When considering safety, testing
algorithms in near-miss scenarios that rarely show up in off-the-shelf datasets
is a vital part of the evaluation. As a remedy, we propose a near-miss data
synthesizing framework based on Variational Bayesian methods and term it as
Conditional Multiple Trajectory Synthesizer (CMTS). We leverage a generative
model conditioned on road maps to bridge safe and collision driving data by
representing their distribution in the latent space. By sampling from the
near-miss distribution, we can synthesize safety-critical data crucial for
understanding traffic scenarios but not shown in neither the original dataset
nor the collision dataset. Our experimental results demonstrate that the
augmented dataset covers more kinds of driving scenarios, especially the
near-miss ones, which help improve the trajectory prediction accuracy and the
capability of dealing with risky driving scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00101</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00101</id><created>2019-09-13</created><authors><author><keyname>Toubeh</keyname><forenames>Maymoonah</forenames></author><author><keyname>Tokekar</keyname><forenames>Pratap</forenames></author></authors><title>Risk-Aware Planning by Confidence Estimation using Deep Learning-Based
  Perception</title><categories>cs.LG cs.AI cs.CV cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes the use of Bayesian approximations of uncertainty from
deep learning in a robot planner, showing that this produces more cautious
actions in safety-critical scenarios. The case study investigated is motivated
by a setup where an aerial robot acts as a &quot;scout&quot; for a ground robot. This is
useful when the below area is unknown or dangerous, with applications in space
exploration, military, or search-and-rescue. Images taken from the aerial view
are used to provide a less obstructed map to guide the navigation of the robot
on the ground. Experiments are conducted using a deep learning semantic image
segmentation, followed by a path planner based on the resulting cost map, to
provide an empirical analysis of the proposed method. A comparison with similar
approaches is presented to portray the usefulness of certain techniques, or
variations within a technique, in similar experimental settings. The method is
analyzed to assess the impact of variations in the uncertainty extraction, as
well as the absence of an uncertainty metric, on the overall system with the
use of a defined metric which measures surprise to the planner. The analysis is
performed on multiple datasets, showing a similar trend of lower surprise when
uncertainty information is incorporated in the planning, given threshold values
of the hyperparameters in the uncertainty extraction have been met. We find
that taking uncertainty into account leads to paths that could be 18% less
risky on an average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00107</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00107</id><created>2019-09-30</created><authors><author><keyname>Wang</keyname><forenames>Tixian</forenames></author><author><keyname>Taghvaei</keyname><forenames>Amirhossein</forenames></author><author><keyname>Mehta</keyname><forenames>Prashant G.</forenames></author></authors><title>Q-learning for POMDP: An application to learning locomotion gaits</title><categories>eess.SY cs.SY</categories><comments>8 pages, 6 figures, 58th IEEE Conference on Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a Q-learning framework for learning optimal locomotion
gaits in robotic systems modeled as coupled rigid bodies. Inspired by
prevalence of periodic gaits in bio-locomotion, an open loop periodic input is
assumed to (say) affect a nominal gait. The learning problem is to learn a new
(modified) gait by using only partial noisy measurements of the state. The
objective of learning is to maximize a given reward modeled as an objective
function in optimal control settings. The proposed control architecture has
three main components: (i) Phase modeling of dynamics by a single phase
variable; (ii) A coupled oscillator feedback particle filter to represent the
posterior distribution of the phase conditioned in the sensory measurements;
and (iii) A Q-learning algorithm to learn the approximate optimal control law.
The architecture is illustrated with the aid of a planar two-body system. The
performance of the learning is demonstrated in a simulation environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00116</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00116</id><created>2019-09-30</created><updated>2019-10-09</updated><authors><author><keyname>Xu</keyname><forenames>Yuanlu</forenames></author><author><keyname>Zhu</keyname><forenames>Song-Chun</forenames></author><author><keyname>Tung</keyname><forenames>Tony</forenames></author></authors><title>DenseRaC: Joint 3D Pose and Shape Estimation by Dense Render-and-Compare</title><categories>cs.CV cs.LG eess.IV</categories><comments>11 pages, 8 figures, International Conference on Computer Vision
  (ICCV) 2019, Oral Presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present DenseRaC, a novel end-to-end framework for jointly estimating 3D
human pose and body shape from a monocular RGB image. Our two-step framework
takes the body pixel-to-surface correspondence map (i.e., IUV map) as proxy
representation and then performs estimation of parameterized human pose and
shape. Specifically, given an estimated IUV map, we develop a deep neural
network optimizing 3D body reconstruction losses and further integrating a
render-and-compare scheme to minimize differences between the input and the
rendered output, i.e., dense body landmarks, body part masks, and adversarial
priors. To boost learning, we further construct a large-scale synthetic dataset
(MOCA) utilizing web-crawled Mocap sequences, 3D scans and animations. The
generated data covers diversified camera views, human actions and body shapes,
and is paired with full ground truth. Our model jointly learns to represent the
3D human body from hybrid datasets, mitigating the problem of unpaired training
data. Our experiments show that DenseRaC obtains superior performance against
state of the art on public benchmarks of various humanrelated tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00132</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00132</id><created>2019-09-30</created><authors><author><keyname>Duarte</keyname><forenames>Kevin</forenames></author><author><keyname>Rawat</keyname><forenames>Yogesh S</forenames></author><author><keyname>Shah</keyname><forenames>Mubarak</forenames></author></authors><title>CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule
  Routing</title><categories>cs.CV eess.IV</categories><comments>8 pages, 6 figures, ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose a capsule-based approach for semi-supervised video
object segmentation. Current video object segmentation methods are frame-based
and often require optical flow to capture temporal consistency across frames
which can be difficult to compute. To this end, we propose a video based
capsule network, CapsuleVOS, which can segment several frames at once
conditioned on a reference frame and segmentation mask. This conditioning is
performed through a novel routing algorithm for attention-based efficient
capsule selection. We address two challenging issues in video object
segmentation: 1) segmentation of small objects and 2) occlusion of objects
across time. The issue of segmenting small objects is addressed with a zooming
module which allows the network to process small spatial regions of the video.
Apart from this, the framework utilizes a novel memory module based on
recurrent networks which helps in tracking objects when they move out of frame
or are occluded. The network is trained end-to-end and we demonstrate its
effectiveness on two benchmark video object segmentation datasets; it
outperforms current offline approaches on the Youtube-VOS dataset while having
a run-time that is almost twice as fast as competing methods. The code is
publicly available at https://github.com/KevinDuarte/CapsuleVOS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00153</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00153</id><created>2019-09-30</created><authors><author><keyname>Liu</keyname><forenames>Xiwei</forenames></author><author><keyname>Li</keyname><forenames>Zihan</forenames></author></authors><title>Finite time anti-synchronization of complex-valued neural networks with
  bounded asynchronous time-varying delays</title><categories>eess.SY cs.SY math.DS</categories><comments>7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we studied the finite time anti-synchronization of
master-slave coupled complex-valued neural networks (CVNNs) with bounded
asynchronous time-varying delays. With the decomposing technique and the
generalized $\{\xi,\infty\}$-norm, several criteria for ensuring the
finite-time anti-synchronization are obtained. The whole anti-synchronization
process can be divided into two parts: first, the norm of each error state
component will change from initial values to $1$ in finite time, then from $1$
to $0$ in fixed time. Therefore, the whole time is finite. Finally, one typical
numerical example is presented to demonstrate the correctness of our obtained
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00166</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00166</id><created>2019-09-30</created><authors><author><keyname>Pan</keyname><forenames>Siqi</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Rodrigo A.</forenames></author><author><keyname>Welsh</keyname><forenames>James S.</forenames></author><author><keyname>Rojas</keyname><forenames>Cristian R.</forenames></author></authors><title>Consistency Analysis of the Simplified Refined Instrumental Variable
  Method for Continuous-time Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyse the consistency of the Simplified Refined
Instrumental Variable method for Continuous-time systems (SRIVC). It is well
known that the intersample behaviour of the input signal influences the quality
and accuracy of the results when estimating and simulating continuous-time
models. Here, we present a comprehensive analysis on the consistency of the
SRIVC estimator while taking into account the intersample behaviour of the
input signal. The main result of the paper shows that, under some mild
conditions, the SRIVC estimator is generically consistent. We also describe
some conditions when consistency is not achieved, which is important from a
practical standpoint. The theoretical results are supported by simulation
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00170</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00170</id><created>2019-09-30</created><authors><author><keyname>Gal</keyname><forenames>Raviv</forenames></author><author><keyname>Haber</keyname><forenames>Eldad</forenames></author><author><keyname>Irwin</keyname><forenames>Brian</forenames></author><author><keyname>Saleh</keyname><forenames>Bilal</forenames></author><author><keyname>Ziv</keyname><forenames>Avi</forenames></author></authors><title>How To Catch A Lion In The Desert -- On The Solution Of The Coverage
  Directed Generation (CDG) Problem</title><categories>math.OC cs.SY eess.SY</categories><comments>23 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The testing and verification of a complex hardware or software system, such
as modern integrated circuits (ICs) found in everything from smartphones to
servers, can be a difficult process. One of the most difficult and
time-consuming tasks a verification team faces is reaching coverage closure, or
hitting all events in the coverage space. Coverage-directed-generation (CDG),
or the automatic generation of tests that can hit hard-to-hit coverage events,
and thus provide coverage closure, holds the potential to save verification
teams significant simulation resources and time. In this paper, we propose a
new approach to the CDG problem by formulating the CDG problem as a noisy
derivative free optimization (DFO) problem. However, this formulation is
complicated by the fact that derivatives of the objective function are
unavailable, and the objective function evaluations are corrupted by noise. We
solve this noisy optimization problem by utilizing techniques from direct
optimization coupled with a robust noise estimator, and by leveraging
techniques from inverse problems to estimate the gradient of the noisy
objective function. We demonstrate the efficiency and reliability of this new
approach through numerical experiments with an abstract model of part of IBM's
NorthStar processor, a superscalar in-order processor designed for servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00183</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00183</id><created>2019-09-30</created><authors><author><keyname>Karimian</keyname><forenames>Arman</forenames></author><author><keyname>Tron</keyname><forenames>Roberto</forenames></author></authors><title>Bearing-Only Consensus and Formation Control under Directed Topologies</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problems of bearing-only consensus and formation control,
where each agent can only measure the relative bearings of its neighbors and
relative distances are not available. We provide stability results for the
Filippov solutions of two gradient-descent laws from non-smooth Lyapunov
functions in the context of differential inclusion. For the consensus and
formation control problems with undirected sensing topologies, we prove
finite-time and asymptotic convergence of the proposed non-smooth gradient
flows. For the directed consensus problem, we prove asymptotic convergence
using a different non-smooth Lyapunov function given that the sensing graph has
a globally reachable node. Finally, For the directed formation control problem
we prove asymptotic convergence for directed cycles and directed acyclic graphs
and also introduce a new notion of bearing persistence which guarantees
convergence to the desired bearings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00185</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00185</id><created>2019-09-30</created><authors><author><keyname>Guo</keyname><forenames>Jiaming</forenames></author><author><keyname>Qiu</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Xiang</forenames></author><author><keyname>Zhao</keyname><forenames>Xuandong</forenames></author><author><keyname>Guo</keyname><forenames>Ning</forenames></author><author><keyname>Li</keyname><forenames>Quanzheng</forenames></author></authors><title>Predicting Alzheimer's Disease by Hierarchical Graph Convolution from
  Positron Emission Tomography Imaging</title><categories>cs.LG eess.IV stat.ML</categories><comments>Jiaming Guo, Wei Qiu and Xiang Li contribute equally to this work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging-based early diagnosis of Alzheimer Disease (AD) has become an
effective approach, especially by using nuclear medicine imaging techniques
such as Positron Emission Topography (PET). In various literature it has been
found that PET images can be better modeled as signals (e.g. uptake of
florbetapir) defined on a network (non-Euclidean) structure which is governed
by its underlying graph patterns of pathological progression and metabolic
connectivity. In order to effectively apply deep learning framework for PET
image analysis to overcome its limitation on Euclidean grid, we develop a
solution for 3D PET image representation and analysis under a generalized,
graph-based CNN architecture (PETNet), which analyzes PET signals defined on a
group-wise inferred graph structure. Computations in PETNet are defined in
non-Euclidean, graph (network) domain, as it performs feature extraction by
convolution operations on spectral-filtered signals on the graph and pooling
operations based on hierarchical graph clustering. Effectiveness of the PETNet
is evaluated on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset,
which shows improved performance over both deep learning and other machine
learning-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00199</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00199</id><created>2019-10-01</created><authors><author><keyname>Viviano</keyname><forenames>Joseph D.</forenames></author><author><keyname>Simpson</keyname><forenames>Becks</forenames></author><author><keyname>Dutil</keyname><forenames>Francis</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Cohen</keyname><forenames>Joseph Paul</forenames></author></authors><title>Underwhelming Generalization Improvements From Controlling Feature
  Attribution</title><categories>cs.CV cs.LG eess.IV</categories><comments>14 pages, 9 figures, code in paper (github link)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Overfitting is a common issue in machine learning, which can arise when the
model learns to predict class membership using convenient but
spuriously-correlated image features instead of the true image features that
denote a class. These are typically visualized using saliency maps. In some
object classification tasks such as for medical images, one may have some
images with masks, indicating a region of interest, i.e., which part of the
image contains the most relevant information for the classification. We
describe a simple method for taking advantage of such auxiliary labels, by
training networks to ignore the distracting features which may be extracted
outside of the region of interest, on the training images for which such masks
are available. This mask information is only used during training and has an
impact on generalization accuracy in a dataset-dependent way. We observe an
underwhelming relationship between controlling saliency maps and improving
generalization performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00208</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00208</id><created>2019-10-01</created><authors><author><keyname>Kuang</keyname><forenames>Sen</forenames></author><author><keyname>Guan</keyname><forenames>Xiaoke</forenames></author><author><keyname>Dong</keyname><forenames>Daoyi</forenames></author></authors><title>Finite-time stabilization control of quantum systems</title><categories>quant-ph cs.SY eess.SY</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a non-smooth control scheme to achieve finite-time
convergence to an eigenstate of the internal Hamiltonian of a given closed
quantum system. First, we define finite-time stability for quantum systems, and
then present a Lyapunov stability criterion to identify the finite-time
stability of quantum systems. Second, we propose a new non-smooth control law
for two-level quantum systems by selecting a distance between quantum states as
a Lyapunov function and using the Lyapunov stability theory, and prove the
existence and uniqueness of solutions of the quantum system under the action of
the non-smooth controller in the framework of Bloch vectors. Further, an
equivalent transformation is made for the system model and the control target
by expressing quantum states in terms of complex exponentials, and the
finite-time stability of the system is proved by combining the finite-time
Lyapunov stability criterion with the homogeneity theorem. Finally, we perform
numerical simulations on a spin-1/2 particle system and demonstrate the
effectiveness of the finite-time stabilization control scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00211</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00211</id><created>2019-10-01</created><authors><author><keyname>Meisheri</keyname><forenames>Hardik</forenames></author><author><keyname>Baniwal</keyname><forenames>Vinita</forenames></author><author><keyname>Sultana</keyname><forenames>Nazneen N</forenames></author><author><keyname>Ravindran</keyname><forenames>Balaraman</forenames></author><author><keyname>Khadilkar</keyname><forenames>Harshad</forenames></author></authors><title>Reinforcement Learning for Multi-Objective Optimization of Online
  Decisions in High-Dimensional Systems</title><categories>cs.AI cs.LG cs.SY eess.SY</categories><comments>22 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a purely data-driven solution to a class of sequential
decision-making problems with a large number of concurrent online decisions,
with applications to computing systems and operations research. We assume that
while the micro-level behaviour of the system can be broadly captured by
analytical expressions or simulation, the macro-level or emergent behaviour is
complicated by non-linearity, constraints, and stochasticity. If we represent
the set of concurrent decisions to be computed as a vector, each element of the
vector is assumed to be a continuous variable, and the number of such elements
is arbitrarily large and variable from one problem instance to another. We
first formulate the decision-making problem as a canonical reinforcement
learning (RL) problem, which can be solved using purely data-driven techniques.
We modify a standard approach known as advantage actor critic (A2C) to ensure
its suitability to the problem at hand, and compare its performance to that of
baseline approaches on the specific instance of a multi-product inventory
management task. The key modifications include a parallelised formulation of
the decision-making task, and a training procedure that explicitly recognises
the quantitative relationship between different decisions. We also present
experimental results probing the learned policies, and their robustness to
variations in the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00220</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00220</id><created>2019-10-01</created><authors><author><keyname>Gentile</keyname><forenames>Basilio</forenames></author><author><keyname>Paccagnan</keyname><forenames>Dario</forenames></author><author><keyname>Ogunsula</keyname><forenames>Bolutife</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>The Nash Equilibrium with Inertia in Population Games</title><categories>eess.SY cs.GT cs.SY</categories><comments>12 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the traditional game-theoretic set up, where agents select actions and
experience corresponding utilities, an equilibrium is a configuration where no
agent can improve their utility by unilaterally switching to a different
action. In this work, we introduce the novel notion of inertial Nash
equilibrium to account for the fact that, in many practical situations, action
changes do not come for free. Specifically, we consider a population game and
introduce the coefficients $c_{ij}$ describing the cost an agent incurs by
switching from action $i$ to action $j$. We define an inertial Nash equilibrium
as a distribution over the action space where no agent benefits in moving to a
different action, while taking into account the cost of this change. First, we
show that the set of inertial Nash equilibria contains all the Nash equilibria,
but is in general not convex. Second, we argue that classical algorithms for
computing Nash equilibria cannot be used in the presence of switching costs. We
then propose a natural better-response dynamics and prove its convergence to an
inertial Nash equilibrium. We apply our results to predict the drivers'
distribution of an on-demand ride-hailing platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00254</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00254</id><created>2019-10-01</created><updated>2019-10-31</updated><authors><author><keyname>Inaguma</keyname><forenames>Hirofumi</forenames></author><author><keyname>Duh</keyname><forenames>Kevin</forenames></author><author><keyname>Kawahara</keyname><forenames>Tatsuya</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Multilingual End-to-End Speech Translation</title><categories>cs.CL eess.AS</categories><comments>Accepted to ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a simple yet effective framework for multilingual
end-to-end speech translation (ST), in which speech utterances in source
languages are directly translated to the desired target languages with a
universal sequence-to-sequence architecture. While multilingual models have
shown to be useful for automatic speech recognition (ASR) and machine
translation (MT), this is the first time they are applied to the end-to-end ST
problem. We show the effectiveness of multilingual end-to-end ST in two
scenarios: one-to-many and many-to-many translations with publicly available
data. We experimentally confirm that multilingual end-to-end ST models
significantly outperform bilingual ones in both scenarios. The generalization
of multilingual training is also evaluated in a transfer learning scenario to a
very low-resource language pair. All of our codes and the database are publicly
available to encourage further research in this emergent multilingual ST topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00265</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00265</id><created>2019-10-01</created><authors><author><keyname>Rahim</keyname><forenames>Tariq</forenames></author><author><keyname>Usman</keyname><forenames>Muhammad Arslan</forenames></author><author><keyname>Shin</keyname><forenames>Soo Young</forenames></author></authors><title>A Survey on Contemporary Computer-Aided Tumor, Polyp, and Ulcer
  Detection Methods in Wireless Capsule Endoscopy Imaging</title><categories>eess.IV</categories><comments>74 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Wireless capsule endoscopy (WCE) is a process in which a patient swallows a
camera-embedded pill-shaped device that passes through the gastrointestinal
(GI) tract, captures and transmits images to an external receiver. WCE devices
are considered as a replacement of conventional endoscopy methods which are
usually painful and distressful for the patients. WCE devices produce over
60,000 images typically during their course of operation inside the GI tract.
These images need to be examined by expert physicians who attempt to identify
frames that contain inflammation / disease. It can be hectic for a physician to
go through such a large number of frames, hence computer-aided detection
methods are considered an efficient alternative. Various anomalies can take
place in the GI tract of a human being but the most important and common ones
and the aim of this survey are ulcers, polyps, and tumors. In this paper, we
have presented a survey of contemporary computer-aided detection methods that
take WCE images as input and classify those images in a diseased/abnormal or
disease-free/ normal image. We have considered methods that detect tumors,
polyps and ulcers, as these three diseases lie in the same category.
Furthermore bleeding inside the GI tract may be the symptoms of these diseases;
so an attempt is also made to enlighten the research work done for bleeding
detection inside WCE. Several studies have been included with in-depth detail
of their methodologies, findings, and conclusions. Also, we have attempted to
classify these methods based on their technical aspects. This paper also
includes a potential proposal for joint classification of aforementioned three
diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00266</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00266</id><created>2019-10-01</created><updated>2019-10-17</updated><authors><author><keyname>Coluccia</keyname><forenames>Angelo</forenames></author><author><keyname>Fascista</keyname><forenames>Alessio</forenames></author><author><keyname>Ricci</keyname><forenames>Giuseppe</forenames></author></authors><title>CFAR Feature Plane: a Novel Framework for the Analysis and Design of
  Radar Detectors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since Kelly's pioneering work on GLRT-based adaptive detection, many
solutions have been proposed to enhance either selectivity or robustness of
radar detectors to mismatched signals. In this paper such a problem is
addressed in a different space, called CFAR feature plane and given by a
suitable maximal invariant, where observed data are mapped to clusters that can
be analytically described. The characterization of the trajectories and shapes
of such clusters is provided and exploited for both analysis and design
purposes, also shedding new light on the behavior of several well-known
detectors. Novel linear and non-linear detectors are proposed with diversified
robust or selective behaviors, showing that through the proposed framework it
is not only possible to achieve the same performance of well-known receivers
obtained by a radically different design approach (namely GLRT), but also to
devise detectors with unprecedented behaviors: in particular, our results show
that the highest standard of selectivity can be achieved without sacrifying
neither detection power under matched conditions nor CFAR property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00272</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00272</id><created>2019-10-01</created><updated>2020-02-19</updated><authors><author><keyname>St-Jean</keyname><forenames>Samuel</forenames></author><author><keyname>Viergever</keyname><forenames>Max A.</forenames></author><author><keyname>Leemans</keyname><forenames>Alexander</forenames></author></authors><title>Harmonization of diffusion MRI datasets with adaptive dictionary
  learning</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>v4: Peer review round 2 v3: Peer reviewed version v2: Fix minor text
  issue + add supp materials v1: To be submitted to Neuroimage</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion magnetic resonance imaging is a noninvasive imaging technique that
can indirectly infer the microstructure of tissues and provide metrics which
are subject to normal variability across subjects. Potentially abnormal values
or features may yield essential information to support analysis of controls and
patients cohorts, but subtle confounds affecting diffusion MRI, such as those
due to difference in scanning protocols or hardware, can lead to systematic
errors which could be mistaken for purely biologically driven variations
amongst subjects. In this work, we propose a new harmonization algorithm based
on adaptive dictionary learning to mitigate the unwanted variability caused by
different scanner hardware while preserving the natural biological variability
present in the data. Overcomplete dictionaries, which are learned automatically
from the data and do not require paired samples, are then used to reconstruct
the data from a different scanner, removing variability present in the source
scanner in the process. We use the publicly available database from an
international challenge to evaluate the method, which was acquired on three
different scanners and with two different protocols, and propose a new mapping
towards a scanner-agnostic space. Results show that the effect size of the four
studied diffusion metrics is preserved while removing variability attributable
to the scanner. Experiments with alterations using a free water compartment,
which is not simulated in the training data, shows that the effect size induced
by the alterations is also preserved after harmonization. The algorithm is
freely available and could help multicenter studies in pooling their data,
while removing scanner specific confounds, and increase statistical power in
the process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00330</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00330</id><created>2019-10-01</created><authors><author><keyname>Zargarbashi</keyname><forenames>S. Soroush Haj</forenames></author><author><keyname>Babaali</keyname><forenames>Bagher</forenames></author></authors><title>A Multi-Modal Feature Embedding Approach to Diagnose Alzheimer Disease
  from Spoken Language</title><categories>cs.LG cs.CL eess.AS stat.ML</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introduction: Alzheimer's disease is a type of dementia in which early
diagnosis plays a major rule in the quality of treatment. Among new works in
the diagnosis of Alzheimer's disease, there are many of them analyzing the
voice stream acoustically, syntactically or both. The mostly used tools to
perform these analysis usually include machine learning techniques. Objective:
Designing an automatic machine learning based diagnosis system will help in the
procedure of early detection. Also, systems, using noninvasive data are
preferable. Methods: We used are classification system based on spoken
language. We use three (statistical and neural) approaches to classify audio
signals from spoken language into two classes of dementia and control. Result:
This work designs a multi-modal feature embedding on the spoken language audio
signal using three approaches; N-gram, i-vector, and x-vector. The evaluation
of the system is done on the cookie picture description task from Pitt Corpus
dementia bank with the accuracy of 83:6
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00341</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00341</id><created>2019-10-01</created><authors><author><keyname>Jung</keyname><forenames>Myunghun</forenames></author><author><keyname>Lim</keyname><forenames>Hyungjun</forenames></author><author><keyname>Goo</keyname><forenames>Jahyun</forenames></author><author><keyname>Jung</keyname><forenames>Youngmoon</forenames></author><author><keyname>Kim</keyname><forenames>Hoirin</forenames></author></authors><title>Additional Shared Decoder on Siamese Multi-view Encoders for Learning
  Acoustic Word Embeddings</title><categories>eess.AS cs.IR cs.LG cs.SD stat.ML</categories><comments>Accepted at 2019 IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic word embeddings --- fixed-dimensional vector representations of
arbitrary-length words --- have attracted increasing interest in
query-by-example spoken term detection. Recently, on the fact that the
orthography of text labels partly reflects the phonetic similarity between the
words' pronunciation, a multi-view approach has been introduced that jointly
learns acoustic and text embeddings. It showed that it is possible to learn
discriminative embeddings by designing the objective which takes text labels as
well as word segments. In this paper, we propose a network architecture that
expands the multi-view approach by combining the Siamese multi-view encoders
with a shared decoder network to maximize the effect of the relationship
between acoustic and text embeddings in embedding space. Discriminatively
trained with multi-view triplet loss and decoding loss, our proposed approach
achieves better performance on acoustic word discrimination task with the WSJ
dataset, resulting in 11.1% relative improvement in average precision. We also
present experimental results on cross-view word discrimination and word level
speech recognition tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00377</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00377</id><created>2019-10-01</created><authors><author><keyname>Salomon</keyname><forenames>Andre</forenames></author><author><keyname>Andreyev</keyname><forenames>Andriy</forenames></author><author><keyname>Goedicke</keyname><forenames>Andreas</forenames></author></authors><title>Information-Adaptive Denoising for Iterative PET Reconstruction</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative accuracy and thus diagnostic precision in Emission Tomography is
impaired by the inherent random characteristics of the data acquisition leading
to statistical image noise. Edge preserving spatial variation regularized
iterative image reconstruction approaches require case-specific control
parameter adaptation for optimized contrast-vs-noise tradeoff. For MLEM
reconstruction, we propose and evaluate iRDF which automatically adapts RDP
edge preservation parameters according to local image noise and PET data
characteristics. In order to distinguish between clustered noise spots and
small tumors, we introduce hot-spot artifact correction. The proposed method
was evaluated using NEMA IQ phantom data as well as clinical patient data.
After initial iRDF base parameter tuning, results showed that iRDF maintained
similar image quality regardless of statistics without requiring manual
parameter tuning, in contrast to e.g. RDP. With NEMA-IQ phantom data, local
image variance was reduced to ~33%, while contrast of small spheres could be
mostly preserved compared to nonregularized OSEM. Using a quarter of the
originally acquired list-mode data, a noise decreased to ~22% while SUV-max has
been reduced to ~75% of OSEM-based results. NEMA phantom and clinical data
showed improved signal-recovery-to-noise ratios, leading to an overall ~3 times
higher feature detectability especially in small lesions. Finally, the
processed examples illustrate the effectiveness of the proposed hot-pixel
artefact correction. The proposed auto-adaptive iRDF regularization
demonstrates high potential to reduce the burden of prior parameter tuning. It
realizes a trade-off between feature contrast and image noise on both local and
global scale. According to increased noise robustness at different count
statistics, iRDF can be considered an interesting alternative especially for
low-dose PET imaging applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00388</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00388</id><created>2019-10-01</created><authors><author><keyname>Lopez-Rios</keyname><forenames>R.</forenames></author><author><keyname>Javid</keyname><forenames>U. A.</forenames></author><author><keyname>Lin</keyname><forenames>Q.</forenames></author></authors><title>Orbital-angular-momentum free-space optical communication via the
  azimuthal phase-shift</title><categories>physics.optics eess.SP</categories><comments>21 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free-space optical communication using the orbital angular momentum (OAM) of
light has garnered significant interest lately due to the potentially vast
bandwidth intrinsic to the infinite Hilbert space of OAM modes. Unfortunately,
OAM light beams suffer from serious distortions due to atmospheric turbulence
(AT) that has become a dominant factor limiting the advance of OAM-based
free-space communication. Here we propose and demonstrate a free-space
communication scheme---using OAM beams and their azimuthal-mode phase-shift for
keying (OAM-APSK)---which is resilient to AT-induced distortions. Combined with
a digital holographic mode sorting (DHMS) technique, the proposed approach is
able to achieve high signal-to-noise ratios and to maintain low modal
crosstalk, even for extremely strong turbulence conditions, with magnitudes
significantly beyond existing AT mitigation methods. The demonstrated OAM-APSK
and DHMS schemes may now open up a great avenue for OAM-based free-space
optical communication that could elegantly resolve the long-standing challenge
imposed by atmospheric turbulence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00390</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00390</id><created>2019-09-30</created><authors><author><keyname>Vilov</keyname><forenames>Sergey</forenames></author><author><keyname>Arnal</keyname><forenames>Bastien</forenames></author><author><keyname>Hojman</keyname><forenames>Eliel</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Katz</keyname><forenames>Ori</forenames></author><author><keyname>Bossy</keyname><forenames>Emmanuel</forenames></author></authors><title>Super-resolution photoacoustic and ultrasound imaging with sparse arrays</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has previously been demonstrated that model-based reconstruction methods
relying on a priori knowledge of the imaging point spread function (PSF)
coupled to sparsity priors on the object to image can provide super-resolution
in photoacoustic (PA) or in ultrasound (US) imaging. Here, we experimentally
show that such reconstruction also leads to super-resolution in both PA and US
imaging with arrays having much less elements than used conventionally (sparse
arrays). As a proof of concept, we obtained super-resolution PA and US
cross-sectional images of microfluidic channels with only 8 elements of a
128-elements linear array using a reconstruction approach based on a linear
propagation forward model and assuming sparsity of the imaged structure.
Although the microchannels appear indistinguishable in the conventional
delay-and-sum images obtained with all the 128 transducer elements, the applied
sparsity-constrained model-based reconstruction provides super-resolution with
down to only 8 elements. We also report simulation results showing that the
minimal number of transducer elements required to obtain a correct
reconstruction is fundamentally limited by the signal-to-noise ratio. The
proposed method can be straigthforwardly applied to any transducer geometry,
including 2D sparse arrays for 3D super-resolution PA and US imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00420</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00420</id><created>2019-09-29</created><authors><author><keyname>Cheng</keyname><forenames>Qian</forenames></author><author><keyname>Wang</keyname><forenames>Shilian</forenames></author><author><keyname>Fusco</keyname><forenames>Vincent</forenames></author><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Gu</keyname><forenames>Chao</forenames></author></authors><title>Physical-Layer Security for Frequency Diverse Array Based Directional
  Modulation in Fluctuating Two-Ray Fading Channels</title><categories>eess.SP</categories><comments>14 pages, 14 figures. arXiv admin note: text overlap with
  arXiv:1908.04633</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The frequency diverse array (FDA) based directional modulation (DM)
technology plays an important role in the implementation of the physical-layer
security (PLS) transmission of 5G and beyond communication system. In order to
meet the tremendous increase in mobile data traffic, a new design consuming
less memory for the FDA-DM-based PLS transmission is urgently demanded. In this
paper, an analytical symmetrical multi-carrier FDA model is proposed in three
dimensions, namely, range, azimuth angle, and elevation angle, which differs
from the conventional analytical approach with only range and azimuth angle
considered. Then, a single-point (SP) artificial noise (AN) aided FDA-DM scheme
is proposed, which reduces memory consumption of FDA-DM systems significantly
compared with the conventional zero-forcing (ZF) and singular value
decomposition (SVD) approaches. Moreover, the PLS performance of the proposed
low-memory-consumption FDA-DM scheme is analyzed in fluctuating two-ray (FTR)
fading channels for the first time, including bit error rate (BER), secrecy
rate (SR), and secrecy outage probability (SOP). More importantly, the
closed-form expressions for the lower bound of the average SR and the upper
bound of the SOP are derived, respectively. The effectiveness of the analytical
expressions is verified by numerical simulations. This work opens a way to
lower the memory requirements for the DM-based PLS transmission of 5G and
beyond communication system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00424</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00424</id><created>2019-09-30</created><authors><author><keyname>Gogate</keyname><forenames>Mandar</forenames></author><author><keyname>Adeel</keyname><forenames>Ahsan</forenames></author><author><keyname>Dashtipour</keyname><forenames>Kia</forenames></author><author><keyname>Derleth</keyname><forenames>Peter</forenames></author><author><keyname>Hussain</keyname><forenames>Amir</forenames></author></authors><title>AV Speech Enhancement Challenge using a Real Noisy Corpus</title><categories>cs.SD cs.LG eess.AS</categories><comments>arXiv admin note: substantial text overlap with arXiv:1909.10407</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents, a first of its kind, audio-visual (AV) speech enhacement
challenge in real-noisy settings. A detailed description of the AV challenge, a
novel real noisy AV corpus (ASPIRE), benchmark speech enhancement task, and
baseline performance results are outlined. The latter are based on training a
deep neural architecture on a synthetic mixture of Grid corpus and ChiME3
noises (consisting of bus, pedestrian, cafe, and street noises) and testing on
the ASPIRE corpus. Subjective evaluations of five different speech enhancement
algorithms (including SEAGN, spectrum subtraction (SS) , log-minimum
mean-square error (LMMSE), audio-only CochleaNet, and AV CochleaNet) are
presented as baseline results. The aim of the multi-modal challenge is to
provide a timely opportunity for comprehensive evaluation of novel AV speech
enhancement algorithms, using our new benchmark, real-noisy AV corpus and
specified performance metrics. This will promote AV speech processing research
globally, stimulate new ground-breaking multi-modal approaches, and attract
interest from companies, academics and researchers working in AV speech
technologies and applications. We encourage participants (through a challenge
website sign-up) from both the speech and hearing research communities, to
benefit from their complementary approaches to AV speech in noise processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00443</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00443</id><created>2019-10-01</created><authors><author><keyname>Traub</keyname><forenames>Manuel</forenames></author><author><keyname>Stegmaier</keyname><forenames>Johannes</forenames></author></authors><title>Towards Automatic Embryo Staging in 3D+T Microscopy Images using
  Convolutional Neural Networks and PointNets</title><categories>eess.IV cs.CV q-bio.CB</categories><comments>5 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic analyses and comparisons of different stages of embryonic
development largely depend on a highly accurate spatio-temporal alignment of
the investigated data sets. In this contribution, we compare multiple
approaches to perform automatic staging of developing embryos that were imaged
with time-resolved 3D light-sheet microscopy. The methods comprise image-based
convolutional neural networks as well as an approach based on the PointNet
architecture that directly operates on 3D point clouds of detected cell nuclei
centroids. The proof-of-concept experiments with four wild-type zebrafish
embryos render both approaches suitable for automatic staging with average
deviations of 0.45 - 0.57 hours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00461</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00461</id><created>2019-10-01</created><authors><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author></authors><title>Low-Resolution Limited-Feedback NOMA for mmWave Communications</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spectrum-efficient millimeter-wave (mmWave) communications has recently
attracted much attention as a viable solution to spectrum crunch problem. In
this work, we propose a novel non-orthogonal multiple access (NOMA) framework,
which makes use of the directional propagation characteristics of mmWave
communications so as to improve the spectral efficiency through non-orthogonal
signaling. In particular, we consider one-bit quantized angle information as a
limited yet effective feedback scheme describing the channel quality of user
equipment (UE) in mmWave bands. The UE pairs for NOMA transmission are then
established using not only the one-bit distance feedback as a classical
approach, but also the one-bit angle feedback. The proposed strategy is
therefore referred to as two-bit NOMA. We also propose a novel hybrid strategy,
called combined NOMA, for the circumstances with no UE pair through two-bit
NOMA. Whenever no UE pair is available through any NOMA strategy, we resort to
single user transmission (SUT) with proper UE selection schemes. The hybrid
sum-rate performance is also analyzed thoroughly with the respective outage and
rate expressions. The numerical results verify that the proposed strategy
outperforms one-bit NOMA schemes with either angle- or distance-only feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00463</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00463</id><created>2019-10-01</created><authors><author><keyname>Kok</keyname><forenames>Manon</forenames></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas B.</forenames></author></authors><title>A Fast and Robust Algorithm for Orientation Estimation using Inertial
  Sensors</title><categories>eess.SP cs.RO cs.SY eess.SY</categories><comments>9 pages, 2 figures</comments><journal-ref>IEEE Signal Processing Letters, 2019</journal-ref><doi>10.1109/LSP.2019.2943995</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel algorithm for online, real-time orientation estimation.
Our algorithm integrates gyroscope data and corrects the resulting orientation
estimate for integration drift using accelerometer and magnetometer data. This
correction is computed, at each time instance, using a single gradient descent
step with fixed step length. This fixed step length results in robustness
against model errors, e.g. caused by large accelerations or by short-term
magnetic field disturbances, which we numerically illustrate using Monte Carlo
simulations. Our algorithm estimates a three-dimensional update to the
orientation rather than the entire orientation itself. This reduces the
computational complexity by approximately 1/3 with respect to the state of the
art. It also improves the quality of the resulting estimates, specifically when
the orientation corrections are large. We illustrate the efficacy of the
algorithm using experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00496</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00496</id><created>2019-10-01</created><authors><author><keyname>Zhou</keyname><forenames>Yi</forenames></author><author><keyname>Tian</keyname><forenames>Xiaohai</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Das</keyname><forenames>Rohan Kumar</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>A Modularized Neural Network with Language-Specific Output Layers for
  Cross-lingual Voice Conversion</title><categories>eess.AS</categories><comments>Accepted for publication at IEEE ASRU Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a cross-lingual voice conversion framework that adopts a
modularized neural network. The modularized neural network has a common input
structure that is shared for both languages, and two separate output modules,
one for each language. The idea is motivated by the fact that phonetic systems
of languages are similar because humans share a common vocal production system,
but acoustic renderings, such as prosody and phonotactic, vary a lot from
language to language. The modularized neural network is trained to map Phonetic
PosteriorGram (PPG) to acoustic features for multiple speakers. It is
conditioned on a speaker i-vector to generate the desired target voice. We
validated the idea between English and Mandarin languages in objective and
subjective tests. In addition, mixed-lingual PPG derived from a unified
English-Mandarin acoustic model is proposed to capture the linguistic
information from both languages. It is found that our proposed modularized
neural network significantly outperforms the baseline approaches in terms of
speech quality and speaker individuality, and mixed-lingual PPG representation
further improves the conversion performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00497</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00497</id><created>2019-09-02</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Shuang</keyname><forenames>Ya</forenames></author><author><keyname>Ma</keyname><forenames>Qian</forenames></author><author><keyname>Li</keyname><forenames>Haoyang</forenames></author><author><keyname>Zhao</keyname><forenames>Hanting</forenames></author><author><keyname>Wei1</keyname><forenames>Menglin</forenames></author><author><keyname>Liu</keyname><forenames>Che</forenames></author><author><keyname>Hao</keyname><forenames>Chenglong</forenames></author><author><keyname>Qiu</keyname><forenames>Cheng-Wei</forenames></author><author><keyname>Cui</keyname><forenames>Tie Jun</forenames></author></authors><title>Intelligent Metasurface Imager and Recognizer</title><categories>physics.app-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is ever-increasingly demanded to remotely monitor people in daily life
using radio-frequency probing signals. However, conventional systems can hardly
be deployed in real-world settings since they typically require objects to
either deliberately cooperate or carry a wireless active device or
identification tag. To accomplish the complicated successive tasks using a
single device in real time, we propose a smart metasurface imager and
recognizer simultaneously, empowered by a network of artificial neural networks
(ANNs) for adaptively controlling data flow. Here, three ANNs are employed in
an integrated hierarchy: transforming measured microwave data into images of
whole human body; classifying the specifically designated spots (hand and
chest) within the whole image; and recognizing human hand signs instantly at
Wi-Fi frequency of 2.4 GHz. Instantaneous in-situ imaging of full scene and
adaptive recognition of hand signs and vital signs of multiple non-cooperative
people have been experimentally demonstrated. We also show that the proposed
intelligent metasurface system work well even when it is passively excited by
stray Wi-Fi signals that ubiquitously exist in our daily lives. The reported
strategy could open a new avenue for future smart cities, smart homes,
human-device interactive interfaces, healthy monitoring, and safety screening
free of visual privacy issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00498</identifier>
 <datestamp>2020-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00498</id><created>2019-09-28</created><updated>2020-01-29</updated><authors><author><keyname>Humayun</keyname><forenames>Ahmed Imtiaz</forenames></author><author><keyname>Ghaffarzadegan</keyname><forenames>Shabnam</forenames></author><author><keyname>Ansari</keyname><forenames>Md. Istiaq</forenames></author><author><keyname>Feng</keyname><forenames>Zhe</forenames></author><author><keyname>Hasan</keyname><forenames>Taufiq</forenames></author></authors><title>Towards Domain Invariant Heart Sound Abnormality Detection using
  Learnable Filterbanks</title><categories>eess.SP</categories><comments>Copyright 2020 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiac auscultation is the most practiced non-invasive and cost-effective
procedure for the early diagnosis of heart diseases. While machine learning
based systems can aid in automatically screening patients, the robustness of
these systems is affected by numerous factors including the stethoscope/sensor,
environment, and data collection protocol. This paper studies the adverse
effect of domain variability on heart sound abnormality detection and develops
strategies to address this problem. Methods: We propose a novel Convolutional
Neural Network (CNN) layer, consisting of time-convolutional (tConv) units,
that emulate Finite Impulse Response (FIR) filters. The filter coefficients can
be updated via backpropagation and be stacked in the front-end of the network
as a learnable filterbank. Results: On publicly available multi-domain
datasets, the proposed method surpasses the top-scoring systems found in the
literature for heart sound abnormality detection (a binary classification
task). We utilized sensitivity, specificity, F-1 score and Macc (average of
sensitivity and specificity) as performance metrics. Our systems achieved
relative improvements of up to 11.84% in terms of MAcc, compared to
state-of-the-art methods. Conclusion: The results demonstrate the effectiveness
of the proposed learnable filterbank CNN architecture in achieving robustness
towards sensor/domain variability in PCG signals. Significance: The proposed
methods pave the way for deploying automated cardiac screening systems in
diversified and underserved communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00499</identifier>
 <datestamp>2019-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00499</id><created>2019-09-27</created><updated>2019-11-05</updated><authors><author><keyname>Gao</keyname><forenames>Wen-Biao</forenames></author><author><keyname>Li</keyname><forenames>Bing-Zhao</forenames></author></authors><title>Uncertainty principles for the short-time linear canonical transform of
  complex signals</title><categories>eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The short-time linear canonical transform (STLCT) can be identified as a
generalization of the short-time Fourier transform (STFT). It is a novel
time-frequency analysis tool. In this paper, we generalize some different
uncertainty principles for the STLCT of complex signals. Firstly, one
uncertainty principle for the STLCT of complex signals in time and frequency
domains is derived. Secondly, the uncertainty principle for the STLCT of
complex signals in two STLCT domains is obtained. Finally, the uncertainty
principle for the two conditional standard deviations of the spectrogram
associated with the STLCT is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00500</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00500</id><created>2019-09-29</created><authors><author><keyname>Gy&#xf6;ri</keyname><forenames>Alexey</forenames></author><author><keyname>Niederau</keyname><forenames>Mathis</forenames></author><author><keyname>Zeller</keyname><forenames>Violett</forenames></author><author><keyname>Stich</keyname><forenames>Volker</forenames></author></authors><title>Evaluation of Deep Learning-based prediction models in Microgrids</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is crucial today that economies harness renewable energies and integrate
them into the existing grid. Conventionally, energy has been generated based on
forecasts of peak and low demands. Renewable energy can neither be produced on
demand nor stored efficiently. Thus, the aim of this paper is to evaluate Deep
Learning-based forecasts of energy consumption to align energy consumption with
renewable energy production. Using a dataset from a use-case related to
landfill leachate management, multiple prediction models were used to forecast
energy demand.The results were validated based on the same dataset from the
recycling industry. Shallow models showed the lowest Mean Absolute Percentage
Error (MAPE), significantly outperforming a persistence baseline for both,
long-term (30 days), mid-term (7 days) and short-term (1 day) forecasts. A
potential decrease of up to 23% in peak energy demand was found that could lead
to a reduction of 3,091 kg in CO2-emissions per year. Our approach requires low
finanacial investments for energy-management hardware, making it suitable for
usage in Small and Medium sized Enterprises (SMEs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00501</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00501</id><created>2019-09-30</created><authors><author><keyname>Lin</keyname><forenames>Yi</forenames></author><author><keyname>Duill</keyname><forenames>Se&#xe1;n &#xd3;</forenames></author><author><keyname>Smyth</keyname><forenames>Frank</forenames></author><author><keyname>Williams</keyname><forenames>Skip</forenames></author><author><keyname>Savchenkov</keyname><forenames>Anatoliy</forenames></author><author><keyname>Barry</keyname><forenames>Liam P.</forenames></author></authors><title>Generation of Spectrally-Efficient Superchannel Using Optical Frequency
  Comb Referencing and Active Demultiplexing</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generate multiple optical carriers with ultra-low phase noise, over a
useable bandwidth of 160 GHz, from an externally injected gain-switched comb
source with exceptional low linewidth below 10 Hz. We show successful
transmission of 17 demultiplexed channels using 64-quadrature amplitude
modulation signals at 5 GBaud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00510</identifier>
 <datestamp>2020-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00510</id><created>2019-10-01</created><updated>2020-01-22</updated><authors><author><keyname>Sala&#xfc;n</keyname><forenames>Lou</forenames></author><author><keyname>Coupechoux</keyname><forenames>Marceau</forenames></author><author><keyname>Chen</keyname><forenames>Chung Shue</forenames></author></authors><title>Joint Subcarrier and Power Allocation in NOMA: Optimal and Approximate
  Algorithms</title><categories>math.OC cs.CC cs.DS eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) is a promising technology to increase
the spectral efficiency and enable massive connectivity in 5G and future
wireless networks. In contrast to orthogonal schemes, such as OFDMA, NOMA
multiplexes several users on the same frequency and time resource. Joint
subcarrier and power allocation problems (JSPA) in NOMA are NP-hard to solve in
general. In this family of problems, we consider the weighted sum-rate (WSR)
objective function as it can achieve various tradeoffs between sum-rate
performance and user fairness. Because of JSPA's intractability, a common
approach in the literature is to solve separately the power control and
subcarrier allocation (also known as user selection) problems, therefore
achieving sub-optimal result. In this work, we first improve the computational
complexity of existing single-carrier power control and user selection schemes.
These improved procedures are then used as basic building blocks to design new
algorithms, namely Opt-JSPA, $\varepsilon$-JSPA and Grad-JSPA. Opt-JSPA
computes an optimal solution with lower complexity than current optimal schemes
in the literature. It can be used as a benchmark for optimal WSR performance in
simulations. However, its pseudo-polynomial time complexity remains impractical
for real-world systems with low latency requirements. To further reduce the
complexity, we propose a fully polynomial-time approximation scheme called
$\varepsilon$-JSPA. Since, no approximation has been studied in the literature,
$\varepsilon$-JSPA stands out by allowing to control a tight trade-off between
performance guarantee and complexity. Finally, Grad-JSPA is a heuristic based
on gradient descent. Numerical results show that it achieves near-optimal WSR
with much lower complexity than existing optimal methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00529</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00529</id><created>2019-10-01</created><updated>2019-10-25</updated><authors><author><keyname>Wagstaff</keyname><forenames>Brandon</forenames></author><author><keyname>Peretroukhin</keyname><forenames>Valentin</forenames></author><author><keyname>Kelly</keyname><forenames>Jonathan</forenames></author></authors><title>Robust Data-Driven Zero-Velocity Detection for Foot-Mounted Inertial
  Navigation</title><categories>cs.RO eess.SP</categories><comments>In IEEE Sensors Journal, 10 pages</comments><doi>10.1109/JSEN.2019.2944412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two novel techniques for detecting zero-velocity events to improve
foot-mounted inertial navigation. Our first technique augments a classical
zero-velocity detector by incorporating a motion classifier that adaptively
updates the detector's threshold parameter. Our second technique uses a long
short-term memory (LSTM) recurrent neural network to classify zero-velocity
events from raw inertial data, in contrast to the majority of zero-velocity
detection methods that rely on basic statistical hypothesis testing. We
demonstrate that both of our proposed detectors achieve higher accuracies than
existing detectors for trajectories including walking, running, and
stair-climbing motions. Additionally, we present a straightforward data
augmentation method that is able to extend the LSTM-based model to different
inertial sensors without the need to collect new training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00537</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00537</id><created>2019-10-01</created><authors><author><keyname>S&#xe6;tre</keyname><forenames>Christian Fredrik</forenames></author><author><keyname>Shiriaev</keyname><forenames>Anton</forenames></author><author><keyname>Pchelkin</keyname><forenames>Stepan</forenames></author><author><keyname>Chemori</keyname><forenames>Ahmed</forenames></author></authors><title>Excessive Transverse Coordinates for Orbital Stabilization of
  (Underactuated) Mechanical Systems</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to ECC2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transverse linearization is a useful tool for the design of feedback
controllers that orbitally stabilizes (periodic) motions of mechanical systems.
Yet, in an n-dimensional state-space, this requires knowledge of a set of (n-1)
independent transverse coordinates, which at times can be difficult to find and
whose definitions might vary for different motions (trajectories). Motivated by
this, we present in this paper a generic choice of excessive transverse
coordinates defined in terms of a particular parameterization of the motion and
a projection operator recovering the &quot;position&quot; along the orbit. We present a
constructive procedure for obtaining the corresponding excessive transverse
linearization and state a sufficient condition for the existence of a feedback
controller rendering the desired trajectory (locally) asymptotically orbitally
stable. The approach is demonstrated through numerical simulation by
stabilizing oscillations around the unstable upright position of the
underactuated cart-pendulum system, in which a novel motion planning approach
based on virtual constraints is utilized for trajectory generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00540</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00540</id><created>2019-10-01</created><updated>2020-01-02</updated><authors><author><keyname>Cordero-Grande</keyname><forenames>Lucilio</forenames></author><author><keyname>Ferrazzi</keyname><forenames>Giulio</forenames></author><author><keyname>Teixeira</keyname><forenames>Rui Pedro A. G.</forenames></author><author><keyname>O'Muircheartaigh</keyname><forenames>Jonathan</forenames></author><author><keyname>Price</keyname><forenames>Anthony N.</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph V.</forenames></author></authors><title>Motion corrected MRI with DISORDER: Distributed and Incoherent Sample
  Orders for Reconstruction Deblurring using Encoding Redundancy</title><categories>physics.med-ph eess.IV</categories><comments>22 pages, 9 figures, 1 table, accepted in Magnetic Resonance in
  Medicine</comments><msc-class>65F20</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Purpose: To enable rigid-body motion tolerant parallel volumetric magnetic
resonance imaging by retrospective head motion correction on a variety of
spatio-temporal scales and imaging sequences. Theory and methods: Tolerance
against rigid-body motion is based on distributed and incoherent sampling
orders for boosting a joint retrospective motion estimation and reconstruction
framework. Motion resilience stems from the encoding redundancy in the data, as
generally provided by the coil array. Hence, it does not require external
sensors, navigators or training data, so the methodology is readily applicable
to sequences using 3D encodings. Results: Simulations are performed showing
full inter-shot corrections for usual levels of in-vivo motion, large number of
shots, standard levels of noise and moderate acceleration factors. Feasibility
of inter- and intra-shot corrections is shown under controlled motion in-vivo.
Practical efficacy is illustrated by high quality results in most corrupted of
208 volumes from a series of 26 clinical pediatric examinations collected using
standard protocols. Conclusion: The proposed framework addresses the rigid
motion problem in volumetric anatomical brain scans with sufficient encoding
redundancy which has enabled reliable pediatric examinations without sedation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00555</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00555</id><created>2019-10-01</created><authors><author><keyname>Taylor</keyname><forenames>Andrew J.</forenames></author><author><keyname>Ames</keyname><forenames>Aaron D.</forenames></author></authors><title>Adaptive Safety with Control Barrier Functions</title><categories>eess.SY cs.SY</categories><comments>8 pages, 2 figures, submitted to 2020 IEEE American Control
  Conference (ACC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive Control Lyapunov Functions (aCLFs) were introduced 20 years ago, and
provided a Lyapunov-based methodology for stabilizing systems with parameter
uncertainty. The goal of this paper is to revisit this classic formulation in
the context of safety-critical control. This will motivate a variant of aCLFs
in the context of safety: adaptive Control Barrier Functions (aCBFs). Our
proposed approach adaptively achieves safety by keeping the systems state
within a safe set even in the presence of parametric model uncertainty. We
unify aCLFs and aCBFs into a single control methodology for systems with
uncertain parameters in the context of a Quadratic Program (QP) based
framework. We validate the ability of this unified framework to achieve
stability and safety in an adaptive cruise control (ACC) simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00556</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00556</id><created>2019-10-01</created><authors><author><keyname>Fablet</keyname><forenames>Ronan</forenames></author><author><keyname>Drumetz</keyname><forenames>Lucas</forenames></author><author><keyname>Rousseau</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>End-to-end learning of energy-based representations for
  irregularly-sampled signals and images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For numerous domains, including for instance earth observation, medical
imaging, astrophysics,..., available image and signal datasets often involve
irregular space-time sampling patterns and large missing data rates. These
sampling properties may be critical to apply state-of-the-art learning-based
(e.g., auto-encoders, CNNs,...), fully benefit from the available large-scale
observations and reach breakthroughs in the reconstruction and identification
of processes of interest. In this paper, we address the end-to-end learning of
representations of signals, images and image sequences from irregularly-sampled
data, i.e. when the training data involved missing data. From an analogy to
Bayesian formulation, we consider energy-based representations. Two energy
forms are investigated: one derived from auto-encoders and one relating to
Gibbs priors. The learning stage of these energy-based representations (or
priors) involve a joint interpolation issue, which amounts to solving an energy
minimization problem under observation constraints. Using a
neural-network-based implementation of the considered energy forms, we can
state an end-to-end learning scheme from irregularly-sampled data. We
demonstrate the relevance of the proposed representations for different
case-studies: namely, multivariate time series, 2D images and image sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00557</identifier>
 <datestamp>2019-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00557</id><created>2019-10-01</created><updated>2019-10-04</updated><authors><author><keyname>Zhao</keyname><forenames>Sheng</forenames></author><author><keyname>Radhakrishna</keyname><forenames>Ujwal</forenames></author><author><keyname>Hanly</keyname><forenames>Steve</forenames></author><author><keyname>Ma</keyname><forenames>Jianguo</forenames></author><author><keyname>Lang</keyname><forenames>Jeffrey H</forenames></author><author><keyname>Buss</keyname><forenames>Dennis</forenames></author></authors><title>Co-optimization of a piezoelectric energy harvesting system for
  broadband operation</title><categories>eess.SP physics.app-ph</categories><journal-ref>PowerMEMS 2018, Dec 2018, Daytona Beach, United States</journal-ref><doi>10.1088/1742-6596/1407/1/012010</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The goal of this research is to increase the bandwidth (BW) over which
substantial energy can be harvested using a piezoelectric energy harvester
(PEH). The key innovation is the use of bias-flip (BF) electronics at the
output of a PEH having a large electromechanical coupling coefficient
$\kappa_{e}^{2}$. For a PEH with large $\kappa_{e}^{2}$, the open-circuit
resonance frequency $f_{oc}$ is substantially larger than the short-circuit
resonance frequency $f_{sc}$. Over the intervening range, the reactive part of
the conjugate matched load impedance is small, and can be approximated using BF
electronics in which the BF voltage is sufficiently small and the BF losses are
small. This results in a large BW over which substantial energy can be
harvested. Experimental results using a commercially available PEH are
presented to demonstrate this concept. Design guidelines are provided for
achieving PEHs having increased $\kappa_{e}^{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00565</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00565</id><created>2019-10-01</created><authors><author><keyname>Ghorbani</keyname><forenames>Shahram</forenames></author><author><keyname>Khorram</keyname><forenames>Soheil</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Domain Expansion in DNN-based Acoustic Models for Robust Speech
  Recognition</title><categories>eess.AS cs.CL cs.LG</categories><comments>Accepted at ASRU, 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Training acoustic models with sequentially incoming data -- while both
leveraging new data and avoiding the forgetting effect-- is an essential
obstacle to achieving human intelligence level in speech recognition. An
obvious approach to leverage data from a new domain (e.g., new accented speech)
is to first generate a comprehensive dataset of all domains, by combining all
available data, and then use this dataset to retrain the acoustic models.
However, as the amount of training data grows, storing and retraining on such a
large-scale dataset becomes practically impossible. To deal with this problem,
in this study, we study several domain expansion techniques which exploit only
the data of the new domain to build a stronger model for all domains. These
techniques are aimed at learning the new domain with a minimal forgetting
effect (i.e., they maintain original model performance). These techniques
modify the adaptation procedure by imposing new constraints including (1)
weight constraint adaptation (WCA): keeping the model parameters close to the
original model parameters; (2) elastic weight consolidation (EWC): slowing down
training for parameters that are important for previously established domains;
(3) soft KL-divergence (SKLD): restricting the KL-divergence between the
original and the adapted model output distributions; and (4) hybrid SKLD-EWC:
incorporating both SKLD and EWC constraints. We evaluate these techniques in an
accent adaptation task in which we adapt a deep neural network (DNN) acoustic
model trained with native English to three different English accents:
Australian, Hispanic, and Indian. The experimental results show that SKLD
significantly outperforms EWC, and EWC works better than WCA. The hybrid
SKLD-EWC technique results in the best overall performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00579</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00579</id><created>2019-09-30</created><updated>2019-10-06</updated><authors><author><keyname>Arfeen</keyname><forenames>Daiyaan</forenames></author><author><keyname>Zhang</keyname><forenames>Jesse</forenames></author></authors><title>Unsupervised Projection Networks for Generative Adversarial Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>6 Pages, 8 Figures, ICCV 2019 Workshop: Sensing, Understanding and
  Synthesizing Humans</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the use of unsupervised learning to train projection networks that
project onto the latent space of an already trained generator. We apply our
method to a trained StyleGAN, and use our projection network to perform image
super-resolution and clustering of images into semantically identifiable
groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00608</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00608</id><created>2019-10-01</created><authors><author><keyname>Anderson</keyname><forenames>Alejandro</forenames></author><author><keyname>D'Jorge</keyname><forenames>Agustina</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Alejandro H.</forenames></author><author><keyname>Ferramosca</keyname><forenames>Antonio</forenames></author><author><keyname>Actis</keyname><forenames>Marcelo</forenames></author></authors><title>MPC for tracking with maximum domain of attraction</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel set-based model predictive control for tracking,
with the largest domain of attraction. The formulation - which consists of a
single optimization problem - shows a dual behavior: one operating inside the
maximal controllable set to the feasible equilibrium set, and the other
operating at the $N$-controllable set to the same equilibrium set. Based on
some finite-time convergence results, global stability of the resulting
closed-loop is proved, while recursive feasibility is ensured for any change of
the set point. The properties and advantages of the controller have been tested
on simulation models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00618</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00618</id><created>2019-10-01</created><authors><author><keyname>Bauza</keyname><forenames>Maria</forenames></author><author><keyname>Alet</keyname><forenames>Ferran</forenames></author><author><keyname>Lin</keyname><forenames>Yen-Chen</forenames></author><author><keyname>Lozano-Perez</keyname><forenames>Tomas</forenames></author><author><keyname>Kaelbling</keyname><forenames>Leslie P.</forenames></author><author><keyname>Isola</keyname><forenames>Phillip</forenames></author><author><keyname>Rodriguez</keyname><forenames>Alberto</forenames></author></authors><title>Omnipush: accurate, diverse, real-world dataset of pushing dynamics with
  RGB-D video</title><categories>cs.RO cs.CV cs.LG cs.SY eess.SY</categories><comments>IROS 2019, 8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pushing is a fundamental robotic skill. Existing work has shown how to
exploit models of pushing to achieve a variety of tasks, including grasping
under uncertainty, in-hand manipulation and clearing clutter. Such models,
however, are approximate, which limits their applicability.
  Learning-based methods can reason directly from raw sensory data with
accuracy, and have the potential to generalize to a wider diversity of
scenarios. However, developing and testing such methods requires rich-enough
datasets. In this paper we introduce Omnipush, a dataset with high variety of
planar pushing behavior.
  In particular, we provide 250 pushes for each of 250 objects, all recorded
with RGB-D and a high precision tracking system. The objects are constructed so
as to systematically explore key factors that affect pushing --the shape of the
object and its mass distribution-- which have not been broadly explored in
previous datasets, and allow to study generalization in model learning.
  Omnipush includes a benchmark for meta-learning dynamic models, which
requires algorithms that make good predictions and estimate their own
uncertainty. We also provide an RGB video prediction benchmark and propose
other relevant tasks that can be suited with this dataset.
  Data and code are available at
\url{https://web.mit.edu/mcube/omnipush-dataset/}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00650</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00650</id><created>2019-09-24</created><authors><author><keyname>Lu</keyname><forenames>Tieyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Xinlin</forenames></author><author><keyname>Huang</keyname><forenames>Yihui</forenames></author><author><keyname>Yang</keyname><forenames>Yonggui</forenames></author><author><keyname>Guo</keyname><forenames>Gang</forenames></author><author><keyname>Bao</keyname><forenames>Lijun</forenames></author><author><keyname>Huang</keyname><forenames>Feng</forenames></author><author><keyname>Guo</keyname><forenames>Di</forenames></author><author><keyname>Qu</keyname><forenames>Xiaobo</forenames></author></authors><title>pISTA-SENSE-ResNet for Parallel MRI Reconstruction</title><categories>eess.IV cs.CV cs.LG physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging has been widely applied in clinical diagnosis,
however, is limited by its long data acquisition time. Although imaging can be
accelerated by sparse sampling and parallel imaging, achieving promising
reconstruction images with a fast reconstruction speed remains a challenge.
Recently, deep learning approaches have attracted a lot of attention for its
encouraging reconstruction results but without a proper interpretability. In
this letter, to enable high-quality image reconstruction for the parallel
magnetic resonance imaging, we design the network structure from the
perspective of sparse iterative reconstruction and enhance it with the residual
structure. The experimental results of a public knee dataset show that compared
with the optimization-based method and the latest deep learning parallel
imaging methods, the proposed network has less error in reconstruction and is
more stable under different acceleration factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00652</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00652</id><created>2019-10-01</created><updated>2019-11-19</updated><authors><author><keyname>Bullock</keyname><forenames>Delia</forenames></author><author><keyname>Mangeni</keyname><forenames>Andrew</forenames></author><author><keyname>Wiesner-Hanks</keyname><forenames>Tyr</forenames></author><author><keyname>DeChant</keyname><forenames>Chad</forenames></author><author><keyname>Stewart</keyname><forenames>Ethan L.</forenames></author><author><keyname>Kaczmar</keyname><forenames>Nicholas</forenames></author><author><keyname>Kolkman</keyname><forenames>Judith M.</forenames></author><author><keyname>Nelson</keyname><forenames>Rebecca J.</forenames></author><author><keyname>Gore</keyname><forenames>Michael A.</forenames></author><author><keyname>Lipson</keyname><forenames>Hod</forenames></author></authors><title>Automated Weed Detection in Aerial Imagery with Context</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we demonstrate the ability to discriminate between cultivated
maize plant and grass or grass-like weed image segments using the context
surrounding the image segments. While convolutional neural networks have
brought state of the art accuracies within object detection, errors arise when
objects in different classes share similar features. This scenario often occurs
when objects in images are viewed at too small of a scale to discern distinct
differences in features, causing images to be incorrectly classified or
localized. To solve this problem, we will explore using context when
classifying image segments. This technique involves feeding a convolutional
neural network a central square image along with a border of its direct
surroundings at train and test times. This means that although images are
labelled at a smaller scale to preserve accurate localization, the network
classifies the images and learns features that include the wider context. We
demonstrate the benefits of this context technique in the object detection task
through a case study of grass (foxtail) and grass-like (yellow nutsedge) weed
detection in maize fields. In this standard situation, adding context alone
nearly halved the error of the neural network from 7.1% to 4.3%. After only one
epoch with context, the network also achieved a higher accuracy than the
network without context did after 50 epochs. The benefits of using the context
technique are likely to particularly evident in agricultural contexts in which
parts (such as leaves) of several plants may appear similar when not taking
into account the context in which those parts appear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00653</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00653</id><created>2019-09-21</created><authors><author><keyname>Koubaa</keyname><forenames>Anis</forenames></author><author><keyname>Aldawood</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Saeed</keyname><forenames>Bassel</forenames></author><author><keyname>Hadid</keyname><forenames>Abdullatif</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohanned</forenames></author><author><keyname>Saad</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Alkhouja</keyname><forenames>Hesham</forenames></author><author><keyname>Alkanhal</keyname><forenames>Mohamed</forenames></author></authors><title>Smart Palm: An IoT Framework for Red Palm Weevil Early Detection</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Smart agriculture is an evolving trend in agriculture industry, where sensors
are embedded into plants to collect vital data and help in decision making to
ensure higher quality of crops and prevent pests, disease, and other possible
threats. In Saudi Arabia, growing palms is the most important agricultural
activity, and there is an increasing need to leverage smart agriculture
technology to improve the production of dates and prevent diseases. One of the
most critical diseases of palms if the red palm weevil, which is an insect that
causes a lot of damage to palm trees and can devast large areas of palm trees.
The most challenging problem is that the effect of the weevil is not visible by
humans until the palm reaches an advanced infestation state. For this reason,
there is a need to use advanced technology for early detection and prevention
of infestation propagation. In this project, we have developed am IoT based
smart palm monitoring prototype as a proof-of-concept that (1) allows to
monitor palms remotely using smart agriculture sensors, (2) contribute to the
early detection of red palm weevil. Users can use web/mobile application to
interact with their palm farms and help them in getting early detection of
possible infestations. We used Elm company IoT platform to interface between
the sensor layer and the user layer. In addition, we have collected data using
accelerometer sensors and we applied signal processing and statistical
techniques to analyze collected data and determine a fingerprint of the
infestation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00658</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00658</id><created>2019-10-01</created><authors><author><keyname>Huang</keyname><forenames>Chunde</forenames></author></authors><title>Binarized Gerchberg Saxton Algorithm for Hologram Generation Using a
  Digital Micromirror Device</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a modified Gerchberg Saxton algorithm for generating improved
robust binary hologram is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00662</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00662</id><created>2019-10-01</created><authors><author><keyname>Lee</keyname><forenames>Hao-Chih</forenames></author><author><keyname>Cherng</keyname><forenames>Sarah T</forenames></author><author><keyname>Miotto</keyname><forenames>Riccardo</forenames></author><author><keyname>Dudley</keyname><forenames>Joel T</forenames></author></authors><title>Enhancing high-content imaging for studying microtubule networks at
  large-scale</title><categories>eess.IV cs.LG stat.ML</categories><comments>accepted and presented in Machine Learning for Healthcare 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Given the crucial role of microtubules for cell survival, many researchers
have found success using microtubule-targeting agents in the search for
effective cancer therapeutics. Understanding microtubule responses to targeted
interventions requires that the microtubule network within cells can be
consistently observed across a large sample of images. However, fluorescence
noise sources captured simultaneously with biological signals while using
wide-field microscopes can obfuscate fine microtubule structures. Such
requirements are particularly challenging for high-throughput imaging, where
researchers must make decisions related to the trade-off between imaging
quality and speed. Here, we propose a computational framework to enhance the
quality of high-throughput imaging data to achieve fast speed and high quality
simultaneously. Using CycleGAN, we learn an image model from low-throughput,
high-resolution images to enhance features, such as microtubule networks in
high-throughput low-resolution images. We show that CycleGAN is effective in
identifying microtubules with 0.93+ AUC-ROC and that these results are robust
to different kinds of image noise. We further apply CycleGAN to quantify the
changes in microtubule density as a result of the application of drug
compounds, and show that the quantified responses correspond well with known
drug effects
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00672</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00672</id><created>2019-10-01</created><updated>2020-02-13</updated><authors><author><keyname>Lee</keyname><forenames>Hang Woon</forenames></author><author><keyname>Shimizu</keyname><forenames>Seiichi</forenames></author><author><keyname>Yoshikawa</keyname><forenames>Shoji</forenames></author><author><keyname>Ho</keyname><forenames>Koki</forenames></author></authors><title>Satellite Constellation Pattern Optimization for Complex Regional
  Coverage</title><categories>math.OC cs.SY eess.SY physics.space-ph</categories><comments>45 pages, 22 figures, submitted to Journal of Spacecraft and Rockets</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of regional coverage satellite constellations is on the rise, urging
the need for an optimal constellation design method for complex regional
coverage. Traditional constellations are often designed for continuous global
coverage, and the few existing regional constellation design methods lead to
suboptimal solutions for periodically time-varying or spatially-varying
regional coverage requirements. This paper introduces a new general approach to
design an optimal constellation pattern that satisfies such complex regional
coverage requirements. To this end, the circular convolution nature of the
repeating ground track orbit and common ground track constellation is
formalized. This formulation of the constellation pattern allows for linearity
in its design problem, i.e., multiple target areas and multiple
sub-constellations with different orbital characteristics can be simultaneously
optimized. This relationship is first used to derive a baseline constellation
pattern design method with the conventional assumption of symmetry. Next, a
novel method based on binary integer programming is developed, which aims to
optimally design a constellation pattern with the minimum number of satellites.
This binary integer programming method is shown to achieve optimal
constellation patterns for general problem settings that the baseline method
cannot achieve. Five illustrative examples are analyzed to demonstrate the
value of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00678</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00678</id><created>2019-10-01</created><authors><author><keyname>Zheng</keyname><forenames>Tianqi</forenames></author><author><keyname>Simpson-Porco</keyname><forenames>John</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Implicit Trajectory Planning for Feedback Linearizable Systems: A
  Time-varying Optimization Approach</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an optimization-based framework for joint real-time trajectory
planning and feedback control of feedback-linearizable systems. To achieve this
goal, we define a target trajectory as the optimal solution of a time-varying
optimization problem. In general, however, such trajectory may not be feasible
due to , e.g., nonholonomic constraints. To solve this problem, we design a
control law that generates feasible trajectories that asymptotically converge
to the target trajectory. More precisely, for systems that are (dynamic)
full-state linearizable, the proposed control law implicitly transforms the
nonlinear system into an optimization algorithm of sufficiently high order. We
prove global exponential convergence to the target trajectory for both the
optimization algorithm and the original system. We illustrate the effectiveness
of our proposed method on multi-target or multi-agent tracking problems with
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00681</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00681</id><created>2019-10-01</created><authors><author><keyname>Fridovich-Keil</keyname><forenames>David</forenames></author><author><keyname>Rubies-Royo</keyname><forenames>Vicenc</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire J.</forenames></author></authors><title>An Iterative Quadratic Method for General-Sum Differential Games with
  Feedback Linearizable Dynamics</title><categories>eess.SY cs.GT cs.MA cs.RO cs.SY</categories><comments>7 pages, 5 figures, submitted to International Conference on Robotics
  and Automation (2020)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative linear-quadratic (ILQ) methods are widely used in the nonlinear
optimal control community. Recent work has applied similar methodology in the
setting of multi-player general-sum differential games. Here, ILQ methods are
capable of finding local Nash equilibria in interactive motion planning
problems in real-time. As in most iterative procedures, however, this approach
can be sensitive to initial conditions and hyperparameter choices, which can
result in poor computational performance or even unsafe trajectories. In this
paper, we focus our attention on a broad class of dynamical systems which are
feedback linearizable, and exploit this structure to improve both algorithmic
reliability and runtime. We showcase our new algorithm in three distinct
traffic scenarios, and observe that in practice our method converges
significantly more often and more quickly than was possible without exploiting
the feedback linearizable structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00684</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00684</id><created>2019-10-01</created><authors><author><keyname>Xiong</keyname><forenames>Xiaobin</forenames></author><author><keyname>Ames</keyname><forenames>Aaron</forenames></author></authors><title>Orbit Characterization, Stabilization and Composition on 3D
  Underactuated Bipedal Walking via Hybrid Passive Linear Inverted Pendulum
  Model</title><categories>cs.RO cs.SY eess.SY</categories><comments>8 pages, 6 figures; To Appear In IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Hybrid passive Linear Inverted Pendulum (HLIP) model is proposed for
characterizing, stabilizing and composing periodic orbits for 3D underactuated
bipedal walking. Specifically, Period-1 (P1) and Period-2 (P2) orbits are
geometrically characterized in the state space of the H-LIP. Stepping
controllers are designed for global stabilization of the orbits. Valid ranges
of the gains and their optimality are derived. The optimal stepping controller
is used to create and stabilize the walking of bipedal robots. An actuated
Spring-loaded Inverted Pendulum (aSLIP) model and the underactuated robot
Cassie are used for illustration. Both the aSLIP walking with P1 or P2 orbits
and the Cassie walking with all 3D compositions of the P1 and P2 orbits can be
smoothly generated and stabilized from a stepping-in-place motion. This
approach provides a perspective and a methodology towards continuous gait
generation and stabilization for 3D underactuated walking robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00687</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00687</id><created>2019-10-01</created><authors><author><keyname>Xiong</keyname><forenames>Xiaobin</forenames></author><author><keyname>Ames</keyname><forenames>Aaron</forenames></author></authors><title>Motion Decoupling and Composition via Reduced Order Model Optimization
  for Dynamic Humanoid Walking with CLF-QP based Active Force Control</title><categories>cs.RO cs.SY eess.SY</categories><comments>7 pages, 5 figures; To Appear In IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, 3D humanoid walking is decoupled into periodic and
transitional motion, each of which is decoupled into planar walking in the
sagittal and lateral plane. Reduced order models (ROMs), i.e. actuated
Spring-loaded Inverted Pendulum (aSLIP) models and Hybrid-Linear Inverted
Pendulum (H-LIP) models, are utilized for motion generation on the desired
center of mass (COM) dynamics for each type of planar motion. The periodic
motion is planned via point foot (underactuated) ROMs for dynamic motion with
minimum ankle actuation, while the transitional motion is planned via
foot-actuated ROMs for fast and smooth transition. Composition of the planar
COM dynamics yields the desired COM dynamics in 3D, which is embedded on the
humanoid via control Lyapunov function based Quadratic programs (CLF-QPs).
Additionally, the ground reaction force profiles of the aSLIP walking are used
as desired references for ground contact forces in the CLF-QPs for smooth
domain transitions. The proposed framework is realized on a lower-limb
exoskeleton in simulation wherein different walking motions are achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00694</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00694</id><created>2019-10-01</created><authors><author><keyname>Chaudhary</keyname><forenames>Aayush K.</forenames></author><author><keyname>Kothari</keyname><forenames>Rakshit</forenames></author><author><keyname>Acharya</keyname><forenames>Manoj</forenames></author><author><keyname>Dangi</keyname><forenames>Shusil</forenames></author><author><keyname>Nair</keyname><forenames>Nitinraj</forenames></author><author><keyname>Bailey</keyname><forenames>Reynold</forenames></author><author><keyname>Kanan</keyname><forenames>Christopher</forenames></author><author><keyname>Diaz</keyname><forenames>Gabriel</forenames></author><author><keyname>Pelz</keyname><forenames>Jeff B.</forenames></author></authors><title>RITnet: Real-time Semantic Segmentation of the Eye for Gaze Tracking</title><categories>cs.CV eess.IV</categories><comments>This model is the winning submission for OpenEDS Semantic
  Segmentation Challenge for Eye images
  https://research.fb.com/programs/openeds-challenge/. To appear in ICCVW 2019.
  (&quot;Pre-trained models and source code are available
  https://bitbucket.org/eye-ush/ritnet/.&quot;)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate eye segmentation can improve eye-gaze estimation and support
interactive computing based on visual attention; however, existing eye
segmentation methods suffer from issues such as person-dependent accuracy, lack
of robustness, and an inability to be run in real-time. Here, we present the
RITnet model, which is a deep neural network that combines U-Net and DenseNet.
RITnet is under 1 MB and achieves 95.3\% accuracy on the 2019 OpenEDS Semantic
Segmentation challenge. Using a GeForce GTX 1080 Ti, RITnet tracks at $&gt;$
300Hz, enabling real-time gaze tracking applications. Pre-trained models and
source code are available https://bitbucket.org/eye-ush/ritnet/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00696</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00696</id><created>2019-10-01</created><authors><author><keyname>Carver</keyname><forenames>Eric</forenames></author><author><keyname>Dai</keyname><forenames>Zhenzhen</forenames></author><author><keyname>Liang</keyname><forenames>Evan</forenames></author><author><keyname>Snyder</keyname><forenames>James</forenames></author><author><keyname>Wen</keyname><forenames>Ning</forenames></author></authors><title>Improvement of Multiparametric MR Image Segmentation by Augmenting the
  Data with Generative Adversarial Networks for Glioma Patients</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every year thousands of patients are diagnosed with a glioma, a type of
malignant brain tumor. Physicians use MR images as a key tool in the diagnosis
and treatment of these patients. Neural networks show great potential to aid
physicians in the medical image analysis. This study investigates the use of
varying amounts of synthetic brain T1-weighted (T1), post-contrast T1-weighted
(T1Gd), T2-weighted (T2), and T2 Fluid Attenuated Inversion Recovery (FLAIR) MR
images created by a generative adversarial network to overcome the lack of
annotated medical image data in training separate 2D U-Nets to segment
enhancing tumor, peritumoral edema, and necrosis (non-enhancing tumor core)
regions on gliomas. These synthetic MR images were assessed quantitively
(SSIM=0.79) and qualitatively by a physician who found that the synthetic
images seem stronger for delineation of structural boundaries but struggle more
when gradient is significant, (e.g. edema signal in T2 modalities). Multiple 2D
U-Nets were trained with original BraTS data and differing subsets of a
quarter, half, three-quarters, and all synthetic MR images. There was not an
obvious correlation between the improvement of values of the metrics in
separate validation dataset for each structure and amount of synthetic data
added, there is a strong correlation between the amount of synthetic data added
and the number of best overall validation metrics. In summary, this study
showed ability to generate high quality synthetic Flair, T2, T1, and T1CE MR
images using the GAN. Using the synthetic MR images showed encouraging results
to improve the U-Net segmentation performance which has the potential to
address the scarcity of readily available medical images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00699</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00699</id><created>2019-10-01</created><updated>2019-10-18</updated><authors><author><keyname>Sarkale</keyname><forenames>Yugandhar</forenames></author><author><keyname>Nozhati</keyname><forenames>Saeed</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author><author><keyname>Ellingwood</keyname><forenames>Bruce R.</forenames></author></authors><title>Decision Automation for Electric Power Network Recovery</title><categories>cs.AI cs.SY eess.SY math.OC stat.AP stat.CO</categories><comments>Submitted to IEEE Transactions on Automation Science and Engineering
  (13 pages and 6 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Critical infrastructure systems such as electric power networks, water
networks, and transportation systems play a major role in the welfare of any
community. In the aftermath of disasters, their recovery is of paramount
importance; orderly and efficient recovery involves the assignment of limited
resources (a combination of human repair workers and machines) to repair
damaged infrastructure components. The decision maker must also deal with
uncertainty in the outcome of the resource-allocation actions during recovery.
The manual assignment of resources seldom is optimal despite the expertise of
the decision maker because of the large number of choices and uncertainties in
consequences of sequential decisions. This combinatorial assignment problem
under uncertainty is known to be \mbox{NP-hard}. We propose a novel decision
technique that addresses the massive number of decision choices for large-scale
real-world problems; in addition, our method also features an experiential
learning component that adaptively determines the utilization of the
computational resources based on the performance of a small number of choices.
Our framework is closed-loop, and naturally incorporates all the attractive
features of such a decision-making system. In contrast to myopic approaches,
which do not account for the future effects of the current choices, our
methodology has an anticipatory learning component that effectively
incorporates \emph{lookahead} into the solutions. To this end, we leverage the
theory of regression analysis, Markov decision processes (MDPs), multi-armed
bandits, and stochastic models of community damage from natural disasters to
develop a method for near-optimal recovery of communities. Our method
contributes to the general problem of MDPs with massive action spaces with
application to recovery of communities affected by hazards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00716</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00716</id><created>2019-10-01</created><authors><author><keyname>Han</keyname><forenames>Kyu J.</forenames></author><author><keyname>Prieto</keyname><forenames>Ramon</forenames></author><author><keyname>Wu</keyname><forenames>Kaixing</forenames></author><author><keyname>Ma</keyname><forenames>Tao</forenames></author></authors><title>State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention
  With Dilated 1D Convolutions</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-attention has been a huge success for many downstream tasks in NLP,
which led to exploration of applying self-attention to speech problems as well.
The efficacy of self-attention in speech applications, however, seems not fully
blown yet since it is challenging to handle highly correlated speech frames in
the context of self-attention. In this paper we propose a new neural network
model architecture, namely multi-stream self-attention, to address the issue
thus make the self-attention mechanism more effective for speech recognition.
The proposed model architecture consists of parallel streams of self-attention
encoders, and each stream has layers of 1D convolutions with dilated kernels
whose dilation rates are unique given stream, followed by a self-attention
layer. The self-attention mechanism in each stream pays attention to only one
resolution of input speech frames and the attentive computation can be more
efficient. In a later stage, outputs from all the streams are concatenated then
linearly projected to the final embedding. By stacking the proposed
multi-stream self-attention encoder blocks and rescoring the resultant lattices
with neural network language models, we achieve the word error rate of 2.2% on
the test-clean dataset of the LibriSpeech corpus, the best number reported thus
far on the dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00722</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00722</id><created>2019-10-01</created><authors><author><keyname>Sornapudi</keyname><forenames>Sudhir</forenames></author><author><keyname>Brown</keyname><forenames>G. T.</forenames></author><author><keyname>Xue</keyname><forenames>Zhiyun</forenames></author><author><keyname>Long</keyname><forenames>Rodney</forenames></author><author><keyname>Allen</keyname><forenames>Lisa</forenames></author><author><keyname>Antani</keyname><forenames>Sameer</forenames></author></authors><title>Comparing Deep Learning Models for Multi-cell Classification in
  Liquid-based Cervical Cytology Images</title><categories>eess.IV cs.CV</categories><comments>AMIA 2019 Annual Symposium, Washington DC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Liquid-based cytology (LBC) is a reliable automated technique for the
screening of Papanicolaou (Pap) smear data. It is an effective technique for
collecting a majority of the cervical cells and aiding cytopathologists in
locating abnormal cells. Most methods published in the research literature rely
on accurate cell segmentation as a prior, which remains challenging due to a
variety of factors, e.g., stain consistency, presence of clustered cells, etc.
We propose a method for automatic classification of cervical slide images
through generation of labeled cervical patch data and extracting deep
hierarchical features by fine-tuning convolution neural networks, as well as a
novel graph-based cell detection approach for cellular level evaluation. The
results show that the proposed pipeline can classify images of both single cell
and overlapping cells. The VGG-19 model is found to be the best at classifying
the cervical cytology patch data with 95 % accuracy under precision-recall
curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00726</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00726</id><created>2019-10-01</created><authors><author><keyname>Mittal</keyname><forenames>Gaurav</forenames></author><author><keyname>Wang</keyname><forenames>Baoyuan</forenames></author></authors><title>Animating Face using Disentangled Audio Representations</title><categories>cs.CV cs.LG eess.AS</categories><comments>Accepted at WACV 2020 (Winter conference on Applications of Computer
  Vision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All previous methods for audio-driven talking head generation assume the
input audio to be clean with a neutral tone. As we show empirically, one can
easily break these systems by simply adding certain background noise to the
utterance or changing its emotional tone (to such as sad). To make talking head
generation robust to such variations, we propose an explicit audio
representation learning framework that disentangles audio sequences into
various factors such as phonetic content, emotional tone, background noise and
others. We conduct experiments to validate that conditioned on disentangled
content representation, the generated mouth movement by our model is
significantly more accurate than previous approaches (without disentangled
learning) in the presence of noise and emotional variations. We further
demonstrate that our framework is compatible with current state-of-the-art
approaches by replacing their original audio learning component with ours. To
our best knowledge, this is the first work which improves the performance of
talking head generation from disentangled audio representation perspective,
which is important for many real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00756</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00756</id><created>2019-10-01</created><authors><author><keyname>Mirfarshbafan</keyname><forenames>Seyed Hadi</forenames></author><author><keyname>Gallyas-Sanhueza</keyname><forenames>Alexandra</forenames></author><author><keyname>Ghods</keyname><forenames>Ramina</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Beamspace Channel Estimation for Massive MIMO mmWave Systems: Algorithm
  and VLSI Design</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) communication in combination with massive multiuser
multiple-input multiple-output (MU-MIMO) enables high-bandwidth data
transmission to multiple users in the same time-frequency resource. The strong
path loss of wave propagation at such high frequencies necessitates accurate
channel state information to ensure reliable data transmission. We propose a
novel channel-estimation algorithm called BEAmspace CHannel EStimation
(BEACHES), which leverages the fact that wave propagation at mmWave frequencies
is predominantly directional. BEACHES adaptively denoises the channel vectors
in the beamspace domain using a nonparametric shrinkage procedure that relies
on Stein's unbiased risk estimator (SURE). Simulation results for line-of-sight
(LoS) and non-LoS mmWave channels reveal that BEACHES performs on par with
state-of-the-art channel estimation methods while requiring orders-of-magnitude
lower complexity. To demonstrate the effectiveness of BEACHES in practice, we
develop a very large-scale integration (VLSI) architecture and provide
field-programmable gate array (FPGA) implementation results. Our results show
that nonparametric channel estimation can be performed at high throughput and
in a hardware efficient manner for massive MU-MIMO mmWave systems with hundreds
of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00782</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00782</id><created>2019-10-02</created><authors><author><keyname>Yin</keyname><forenames>He</forenames></author><author><keyname>Bujarbaruah</keyname><forenames>Monimoy</forenames></author><author><keyname>Arcak</keyname><forenames>Murat</forenames></author><author><keyname>Packard</keyname><forenames>Andrew</forenames></author></authors><title>Optimization Based Planner Tracker Design for Safety Guarantees</title><categories>eess.SY cs.SY</categories><comments>Submitted to IEEE American Control Conference (ACC), Denver, CO, USA,
  July 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a safe-by-design approach to path planning and control for
nonlinear systems. The planner uses a low fidelity model of the plant to
compute reference trajectories by solving an MPC problem, while the plant being
controlled utilizes a feedback control law that tracks those trajectories with
an upper-bound on the tracking error. Our main goal is to allow for maximum
permissiveness (that is, room for constraint feasibility) of the planner, while
maintaining safety after accounting for the tracking error bound. We achieve
this by parametrizing the state and input constraints imposed on the planner
and deriving corresponding parametrized tracking control laws and tracking
error bounds, which are computed offline through Sum-of-Squares programming.
The parameters are then optimally chosen to maximize planner permissiveness,
while guaranteeing safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00783</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00783</id><created>2019-10-02</created><authors><author><keyname>Ding</keyname><forenames>Dongsheng</forenames></author><author><keyname>Jovanovi&#x107;</keyname><forenames>Mihailo R.</forenames></author></authors><title>Global exponential stability of primal-dual gradient flow dynamics based
  on the proximal augmented Lagrangian: A Lyapunov-based approach</title><categories>math.OC cs.LG cs.SY eess.SY</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a class of nonsmooth composite optimization problems with linear equality
constraints, we utilize a Lyapunov-based approach to establish the global
exponential stability of the primal-dual gradient flow dynamics based on the
proximal augmented Lagrangian. The result holds when the differentiable part of
the objective function is strongly convex with a Lipschitz continuous gradient;
the non-differentiable part is proper, lower semi-continuous, and convex; and
the matrix in the linear constraint is full row rank. Our quadratic Lyapunov
function generalizes recent result from strongly convex problems with either
affine equality or inequality constraints to a broader class of composite
optimization problems with nonsmooth regularizers and it provides a worst-case
lower bound of the exponential decay rate. Finally, we use computational
experiments to demonstrate that our convergence rate estimate is less
conservative than the existing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00785</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00785</id><created>2019-10-02</created><authors><author><keyname>Imran</keyname><forenames>Muhammad</forenames></author><author><keyname>Khan</keyname><forenames>Latif U.</forenames></author><author><keyname>Yaqoob</keyname><forenames>Ibrar</forenames></author><author><keyname>Ahmed</keyname><forenames>Ejaz</forenames></author><author><keyname>Qureshi</keyname><forenames>Muhammad Ahsan</forenames></author><author><keyname>Ahmed</keyname><forenames>Arif</forenames></author></authors><title>Energy Harvesting in 5G Networks: Taxonomy, Requirements, Challenges,
  and Future Directions</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consciousness of energy saving is increasing in fifth-generation (5G)
wireless networks due to the high energy consumption issue. Energy harvesting
technology is a possible appealing solution for ultimately prolonging the
lifetime of devices and networks. Although considerable research efforts have
been conducted in the context of using energy harvesting technology in 5G
wireless networks, these efforts are in their infancy, and a tutorial on this
topic is still lacking. This study aims to discuss the beneficial role of
energy harvesting technology in 5G networks. We categorize and classify the
literature available on energy harvesting in 5G networks by devising a taxonomy
based on energy sources; energy harvesting devices, phases, and models; energy
conversion methods, and energy propagation medium. The key requirements for
enabling energy harvesting in 5G networks are also outlined. Several core
research challenges that remain to be addressed are discussed. Furthermore,
future research directions are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00795</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00795</id><created>2019-10-02</created><updated>2019-10-05</updated><authors><author><keyname>Tjandra</keyname><forenames>Andros</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>Speech-to-speech Translation between Untranscribed Unknown Languages</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted in IEEE ASRU 2019. Web-page for more samples &amp; details:
  https://sp2code-translation-v1.netlify.com/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore a method for training speech-to-speech translation
tasks without any transcription or linguistic supervision. Our proposed method
consists of two steps: First, we train and generate discrete representation
with unsupervised term discovery with a discrete quantized autoencoder. Second,
we train a sequence-to-sequence model that directly maps the source language
speech to the target language's discrete representation. Our proposed method
can directly generate target speech without any auxiliary or pre-training steps
with a source or target transcription. To the best of our knowledge, this is
the first work that performed pure speech-to-speech translation between
untranscribed unknown languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00805</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00805</id><created>2019-10-02</created><updated>2019-11-20</updated><authors><author><keyname>Brugnoli</keyname><forenames>Emanuele</forenames></author><author><keyname>Toscano</keyname><forenames>Elena</forenames></author><author><keyname>Vetro</keyname><forenames>Calogero</forenames></author></authors><title>Iterative reconstruction of signals on graph</title><categories>math.NA cs.NA eess.SP</categories><comments>8 pages, 3 figures</comments><doi>10.1109/LSP.2019.2956670</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an iterative algorithm to interpolate graph signals from only a
partial set of samples. Our method is derived from the well known
Papoulis-Gerchberg algorithm by considering the optimal value of a constant
involved in the iteration step. Compared with existing graph signal
reconstruction algorithms, the proposed method achieves similar or better
performance both in terms of convergence rate and computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00821</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00821</id><created>2019-10-02</created><authors><author><keyname>De Handschutter</keyname><forenames>Pierre</forenames></author><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Vandaele</keyname><forenames>Arnaud</forenames></author><author><keyname>Siebert</keyname><forenames>Xavier</forenames></author></authors><title>Near-Convex Archetypal Analysis</title><categories>eess.SP cs.LG eess.IV stat.ML</categories><comments>10 pages, 3 figures</comments><doi>10.1109/LSP.2019.2957604</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonnegative matrix factorization (NMF) is a widely used linear dimensionality
reduction technique for nonnegative data. NMF requires that each data point is
approximated by a convex combination of basis elements. Archetypal analysis
(AA), also referred to as convex NMF, is a well-known NMF variant imposing that
the basis elements are themselves convex combinations of the data points. AA
has the advantage to be more interpretable than NMF because the basis elements
are directly constructed from the data points. However, it usually suffers from
a high data fitting error because the basis elements are constrained to be
contained in the convex cone of the data points. In this letter, we introduce
near-convex archetypal analysis (NCAA) which combines the advantages of both AA
and NMF. As for AA, the basis vectors are required to be linear combinations of
the data points and hence are easily interpretable. As for NMF, the additional
flexibility in choosing the basis elements allows NCAA to have a low data
fitting error. We show that NCAA compares favorably with a state-of-the-art
minimum-volume NMF method on synthetic datasets and on a real-world
hyperspectral image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00838</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00838</id><created>2019-10-02</created><authors><author><keyname>Duff</keyname><forenames>Igor Pontes</forenames></author><author><keyname>Goyal</keyname><forenames>Pawan</forenames></author><author><keyname>Benner</keyname><forenames>Peter</forenames></author></authors><title>Data-Driven Identification of Rayleigh-Damped Second-Order Systems</title><categories>math.OC cs.NA cs.SY eess.SY math.NA</categories><comments>16 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a data-driven approach to identify second-order
systems, having internal Rayleigh damping. This means that the damping matrix
is given as a linear combination of the mass and stiffness matrices. These
systems typically appear when performing various engineering studies, e.g.,
vibrational and structural analysis. In an experimental setup, the frequency
response of a system can be measured via various approaches, for instance, by
measuring the vibrations using an accelerometer. As a consequence, given
frequency samples, the identification of the underlying system relies on
rational approximation. To that aim, we propose an identification of the
corresponding second-order system, extending the Loewner framework for this
class of systems. The efficiency of the proposed method is demonstrated by
means of various numerical benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00849</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00849</id><created>2019-10-02</created><authors><author><keyname>Basile</keyname><forenames>Davide</forenames></author><author><keyname>ter Beek</keyname><forenames>Maurice H.</forenames></author><author><keyname>Pugliese</keyname><forenames>Rosario</forenames></author></authors><title>Synthesis of Orchestrations and Choreographies: Bridging the Gap between
  Supervisory Control and Coordination of Services</title><categories>eess.SY cs.DC cs.FL cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a number of contributions to bridging the gap between supervisory
control theory and coordination of services to explore the frontiers between
coordination and control systems. Firstly, we modify the classical synthesis
algorithm from supervisory control theory for obtaining the so-called most
permissive controller in order to synthesise orchestrations and choreographies
of service contracts formalised as contract automata. The key ingredient to
make this possible is a novel notion of controllability. Then, we present an
abstract parametric synthesis algorithm and show that it generalises the
classical synthesis as well as the orchestration and choreography syntheses.
Finally, through the novel abstract synthesis, we show that the concrete
syntheses are in a refinement order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00889</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00889</id><created>2019-10-02</created><authors><author><keyname>Vihman</keyname><forenames>Lauri</forenames></author><author><keyname>Kruusmaa</keyname><forenames>Maarja</forenames></author><author><keyname>Raik</keyname><forenames>Jaan</forenames></author></authors><title>Overview of Fault Tolerant Techniques in Underwater Sensor Networks</title><categories>eess.SY cs.OH cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor networks provide services to a broad range of applications ranging
from intelligence service surveillance to weather forecasting. Most of the
sensor networks are terrestrial, however much of our planet is covered by water
and Underwater Sensor Networks (USN) are an emerging research area. One of the
unavoidable increasing challenge for modern technology is tolerating faults -
accepting that hardware is imperfect and cope with it. Fault tolerance may have
more impact underwater than in terrestrial environment as terrestrial
environment is more forgiving, reaching the malfunctioning devices for
replacement underwater is harder and may be more costly. Current paper is the
first to investigate fault tolerance, particularly cross layer fault tolerance,
in USN-s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00910</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00910</id><created>2019-10-02</created><updated>2020-01-28</updated><authors><author><keyname>Sy</keyname><forenames>Luke</forenames></author><author><keyname>Raitor</keyname><forenames>Michael</forenames></author><author><keyname>Del Rosario</keyname><forenames>Michael</forenames></author><author><keyname>Khamis</keyname><forenames>Heba</forenames></author><author><keyname>Kark</keyname><forenames>Lauren</forenames></author><author><keyname>Lovell</keyname><forenames>Nigel H.</forenames></author><author><keyname>Redmond</keyname><forenames>Stephen J.</forenames></author></authors><title>Estimating Lower Limb Kinematics using a Reduced Wearable Sensor Count</title><categories>cs.RO cs.SY eess.SY</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goal: This paper presents an algorithm for accurately estimating pelvis,
thigh, and shank kinematics during walking using only three wearable inertial
sensors. Methods: The algorithm makes novel use of a constrained Kalman filter
(CKF). The algorithm iterates through the prediction (kinematic equation),
measurement (pelvis position pseudo-measurements, zero velocity update,
flat-floor assumption, and covariance limiter), and constraint update
(formulation of hinged knee joints and ball-and-socket hip joints). Results:
Evaluation of the algorithm using an optical motion capture-based
sensor-to-segment calibration on nine participants ($7$ men and $2$ women,
weight $63.0 \pm 6.8$ kg, height $1.70 \pm 0.06$ m, age $24.6 \pm 3.9$ years
old), with no known gait or lower body biomechanical abnormalities, who walked
within a $4 \times 4$ m$^2$ capture area shows that it can track motion
relative to the mid-pelvis origin with mean position and orientation (no bias)
root-mean-square error (RMSE) of $5.21 \pm 1.3$ cm and $16.1 \pm 3.2^\circ$,
respectively. The sagittal knee and hip joint angle RMSEs (no bias) were $10.0
\pm 2.9^\circ$ and $9.9 \pm 3.2^\circ$, respectively, while the corresponding
correlation coefficient (CC) values were $0.87 \pm 0.08$ and $0.74 \pm 0.12$.
Conclusion: The CKF-based algorithm was able to track the 3D pose of the
pelvis, thigh, and shanks using only three inertial sensors worn on the pelvis
and shanks. Significance: Due to the Kalman-filter-based algorithm's low
computation cost and the relative convenience of using only three wearable
sensors, gait parameters can be computed in real-time and remotely for
long-term gait monitoring. Furthermore, the system can be used to inform
real-time gait assistive devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00913</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00913</id><created>2019-09-27</created><authors><author><keyname>Escolano</keyname><forenames>Miguel</forenames></author><author><keyname>Rodriguez</keyname><forenames>Jose Manuel</forenames></author><author><keyname>Orus</keyname><forenames>Javier</forenames></author><author><keyname>Laspalas</keyname><forenames>Manuel</forenames></author><author><keyname>Chiminelli</keyname><forenames>Agustin</forenames></author></authors><title>Predictive Control Based on Reduced Order Model for temperature
  homogeneity in a resin transfer molding tool for thermoset materials</title><categories>eess.SY cs.SY math.OC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Resin Transfer Molding (RTM), which has attracted much attention in the last
years for lightweight manufacturing, represents an important challenge in terms
of control technology. During the process, a resin fills the cavity where a
reinforcement fabric has previously been layered. This resin undergoes a
chemical reaction which is thermically activated. Therefore, assuring a proper
reaction requires a precise control of temperature in the entire mold cavity.
Three factors make this control problem especially hard: the coupling among the
large number of actuators and sensors, the variability of the test conditions
and the power limitations of the electric actuators which do not offer cooling
capability. The present work describes an optimized Model Predictive Control
(MPC) architecture capable of handling these difficulties and also achieving
the tight control requirements needed in the application. The thermal
distribution inside the mold cavity is included into the controller by a
simplified Reduced Order Model (ROM). This representation is obtained by data
from an experimentally validated Finite Element Model (FEM), using
AutoRegressive model with eXogenous terms (ARX) identification. In order to
maintain the simplicity of this linear representation, the time-varying model
parameters are estimated by using a perturbation observer. Additionally, the
performance of the basic algorithm is improved: firstly, an augmented observer
to estimate the temperature distribution of an extended spatial resolution; and
secondly, a symmetry condition in the calculation of the control commands. The
developed architectures have successfully been implemented in a RTM tool with
the fulfillment of the control requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00932</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00932</id><created>2019-10-01</created><updated>2019-12-07</updated><authors><author><keyname>Lin</keyname><forenames>Ji</forenames></author><author><keyname>Gan</keyname><forenames>Chuang</forenames></author><author><keyname>Han</keyname><forenames>Song</forenames></author></authors><title>Training Kinetics in 15 Minutes: Large-scale Distributed Training on
  Videos</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep video recognition is more computationally expensive than image
recognition, especially on large-scale datasets like Kinetics [1]. Therefore,
training scalability is essential to handle a large amount of videos. In this
paper, we study the factors that impact the training scalability of video
networks. We recognize three bottlenecks, including data loading (data movement
from disk to GPU), communication (data movement over networking), and
computation FLOPs. We propose three design guidelines to improve the
scalability: (1) fewer FLOPs and hardware-friendly operator to increase the
computation efficiency; (2) fewer input frames to reduce the data movement and
increase the data loading efficiency; (3) smaller model size to reduce the
networking traffic and increase the networking efficiency. With these
guidelines, we designed a new operator Temporal Shift Module (TSM) that is
efficient and scalable for distributed training. TSM model can achieve 1.8x
higher throughput compared to previous I3D models. We scale up the training of
the TSM model to 1,536 GPUs, with a mini-batch of 12,288 video clips/98,304
images, without losing the accuracy. With such hardware-aware model design, we
are able to scale up the training on Summit supercomputer and reduce the
training time on Kinetics dataset from 49 hours 55 minutes to 14 minutes 13
seconds, achieving a top-1 accuracy of 74.0%, which is 1.6x and 2.9x faster
than previous 3D video models with higher accuracy. The code and more details
can be found here: http://tsm-hanlab.mit.edu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00946</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00946</id><created>2019-10-02</created><authors><author><keyname>Wei</keyname><forenames>Zhiqiang</forenames></author></authors><title>Performance Analysis and Design of Non-orthogonal Multiple Access for
  Wireless Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>Thesis Submitted to The University of New South Wales</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, we study performance analysis and resource allocation designs
for non-orthogonal multiple access (NOMA) in wireless communication systems. In
contrast to conventional orthogonal multiple access (OMA) schemes, NOMA allows
multiple users to share the same degree of freedom via superposition coding and
the successive interference cancelation (SIC) decoding. Inspired by the solid
foundations from the information theory perspective, NOMA has rekindled the
interests of researchers as a benefit of the recent advancement in signal
processing and silicon technologies. However, comprehensive performance
analysis on NOMA and practical resource allocation designs to exploit potential
gains of NOMA in terms of spectral and energy efficiency have not been fully
studied and investigated in the literature. This thesis attempts to address
these problems by providing a unified performance analysis and a systematic
resource allocation design for NOMA in wireless communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00956</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00956</id><created>2019-10-02</created><authors><author><keyname>Chen</keyname><forenames>Yuhua</forenames></author><author><keyname>Shaw</keyname><forenames>Jaime L.</forenames></author><author><keyname>Xie</keyname><forenames>Yibin</forenames></author><author><keyname>Li</keyname><forenames>Debiao</forenames></author><author><keyname>Christodoulou</keyname><forenames>Anthony G.</forenames></author></authors><title>Deep learning within a priori temporal feature spaces for large-scale
  dynamic MR image reconstruction: Application to 5-D cardiac MR Multitasking</title><categories>eess.IV cs.CV</categories><comments>Early accepted by MICCAI 2019</comments><journal-ref>Medical Image Computing and Computer Assisted Intervention 2019 pp
  495-504</journal-ref><doi>10.1007/978-3-030-32245-8_55</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High spatiotemporal resolution dynamic magnetic resonance imaging (MRI) is a
powerful clinical tool for imaging moving structures as well as to reveal and
quantify other physical and physiological dynamics. The low speed of MRI
necessitates acceleration methods such as deep learning reconstruction from
under-sampled data. However, the massive size of many dynamic MRI problems
prevents deep learning networks from directly exploiting global temporal
relationships. In this work, we show that by applying deep neural networks
inside a priori calculated temporal feature spaces, we enable deep learning
reconstruction with global temporal modeling even for image sequences with
&gt;40,000 frames. One proposed variation of our approach using dilated
multi-level Densely Connected Network (mDCN) speeds up feature space coordinate
calculation by 3000x compared to conventional iterative methods, from 20
minutes to 0.39 seconds. Thus, the combination of low-rank tensor and deep
learning models not only makes large-scale dynamic MRI feasible but also
practical for routine clinical application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00959</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00959</id><created>2019-10-02</created><authors><author><keyname>Hou</keyname><forenames>Tianwei</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Song</keyname><forenames>Zhengyu</forenames></author><author><keyname>Sun</keyname><forenames>Xin</forenames></author><author><keyname>Chen</keyname><forenames>Yue</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>MIMO Assisted Networks Relying on Large Intelligent Surfaces: A
  Stochastic Geometry Model</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large intelligent surfaces (LISs) constitute a promising performance
enhancement for next-generation (NG) wireless networks in terms of enhancing
both their spectrum efficiency (SE) and energy efficiency (EE). Hence we
conceive a LIS-aided multiple-input multiple-output framework for providing
wireless services to randomly roaming users and analyze its performance by
utilizing stochastic geometry tools. As such, each user receives the superposed
signals reflected by multiple LISs. We aim for serving multiple users by
jointly designing the passive beamforming weight at the LISs and detection
weight vectors at the users. As a benefit, the intra-cell interference imposed
by the LISs can be suppressed. In an effort to evaluate the performance of the
proposed framework, we first derive new channel statistics for characterizing
the effective channel gains. Then, we derive closed-form expressions both for
the outage probability and for the ergodic rate of users. For gleaning further
insights, we investigate both the diversity orders of outage probability and
the high signal-to-noise (SNR) slopes of ergodic rate. We also derive the SE
and EE of the proposed framework. Our analytical results demonstrate that the
specific fading environments encountered between the LISs and users have almost
no impact on the diversity orders attainted. Numerical results are provided to
confirm that: i) the high-SNR slope of the proposed framework is one; and ii)
the SE and EE can be significantly enhanced by increasing the number of LISs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00963</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00963</id><created>2019-10-02</created><authors><author><keyname>Ramirez</keyname><forenames>David</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Age of Information with Finite Horizon and Partial Updates</title><categories>cs.IT cs.SY eess.SP eess.SY math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A resource-constrained system monitors a source of information by requesting
a finite number of updates subject to random transmission delays. An a priori
fixed update request policy is shown to minimize a polynomial penalty function
of the age of information over arbitrary time horizons. Partial updates,
compressed updates with reduced transmission and information content, in the
presented model are shown to incur an age penalty independent of the
compression. Finite horizons are shown to have better performance in terms of
second order statistic relative to infinite horizons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00968</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00968</id><created>2019-10-02</created><authors><author><keyname>Jung</keyname><forenames>Minchae</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>On the Optimality of Reconfigurable Intelligent Surfaces (RISs): Passive
  Beamforming, Modulation, and Resource Allocation</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconfigurable intelligent surfaces (RISs) have recently emerged as a
promising technology that can achieve high spectrum and energy efficiency for
future wireless networks by integrating a massive number of low-cost and
passive reflecting elements. An RIS can manipulate the properties of an
incident wave, such as the frequency, amplitude, and phase, and, then, reflect
this manipulated wave to a desired destination, without the need for complex
signal processing. In this paper, the asymptotic optimality of achievable rate
in a downlink RIS system is analyzed under a practical RIS environment with its
associated limitations. In particular, a passive beamformer that can achieve
the asymptotic optimal performance by controlling the incident wave properties
is designed, under a limited RIS control link and practical reflection
coefficients. In order to increase the achievable system sum-rate, a modulation
scheme that can be used in an RIS without interfering with existing users is
proposed and its average symbol error ratio is asymptotically derived.
Moreover, a new resource allocation algorithm that jointly considers user
scheduling and power control is designed, under consideration of the proposed
passive beamforming and modulation schemes. Simulation results show that the
proposed schemes are in close agreement with their upper bounds in presence of
a large number of RIS reflecting elements thereby verifying that the achievable
rate in practical RISs satisfies the asymptotic optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00984</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.00984</id><created>2019-10-02</created><updated>2019-10-04</updated><authors><author><keyname>Lin</keyname><forenames>Shanny</forenames></author><author><keyname>Zhu</keyname><forenames>Hao</forenames></author></authors><title>Enhancing the Spatio-Temporal Observability of Residential Loads</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enhancing the spatio-temporal observability of residential loads is crucial
for achieving secure and efficient operations in distribution systems with
increasing penetration of distributed energy resources (DERs). This paper
presents a joint inference framework for residential loads by leveraging the
real-time measurements from distribution-level sensors. Specifically, smart
meter data is available for almost every load with unfortunately low temporal
resolution, while distribution synchrophasor data is at very fast rates yet
available at limited locations. By combining these two types of data with
respective strengths, the problem is cast as a matrix recovery one with much
less number of observations than unknowns. To improve the recovery performance,
we introduce two regularization terms to promote a low rank plus sparse
structure of the load matrix via a difference transformation. Accordingly, the
recovery problem can be formulated as a convex optimization one which is
efficiently solvable. Numerical tests using real residential load data
demonstrate the effectiveness of our proposed approaches in identifying
appliance activities and recovering the PV output profiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01020</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01020</id><created>2019-09-28</created><authors><author><keyname>Tasoujian</keyname><forenames>Shahin</forenames></author><author><keyname>Grigoriadis</keyname><forenames>Karolos</forenames></author><author><keyname>Franchek</keyname><forenames>Matthew</forenames></author></authors><title>Delay-Dependent Output-Feedback Control for Blood Pressure Regulation
  Using LPV Techniques</title><categories>eess.SY cs.SY</categories><comments>10 Pages, 5 Figures, 1 Table. arXiv admin note: substantial text
  overlap with arXiv:1909.13170</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a delay-dependent parameter-varying control design
approach to address the automated blood pressure regulation problem in the
critical patient resuscitation using closed-loop administration of
vasopressors. The mean arterial pressure (MAP) response of a patient subject to
the intravenous vasoactive drug treatment is modeled as a linear
parameter-varying (LPV) model, where varying model parameters and varying
time-delay are considered as scheduling parameters of the system.
Parameter-dependent Lyapunov-Krasovskii functionals are used to design an
output-feedback dynamic controller to satisfy the closed-loop stability and
reference MAP tracking requirements. The synthesis conditions are formulated in
terms of Linear Matrix Inequalities (LMIs) that characterize the induced
$\mathcal{L}_2$-norm performance specification of the closed-loop system. The
main objectives of the proposed control method in the presence of limitations
posed by the time-varying model parameters and the large time-varying delay are
to track the MAP reference command and maintain the blood pressure within the
permissible range of commanded set-point, avoid undesirable overshoot and slow
response, and to provide a smooth drug injection. Finally, to evaluate the
performance of the proposed LPV blood pressure regulation approach, closed-loop
simulations are conducted and the results confirm the effectiveness of the
proposed control method against various simulated scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01022</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01022</id><created>2019-09-28</created><authors><author><keyname>Tasoujian</keyname><forenames>Shahin</forenames></author><author><keyname>Salavati</keyname><forenames>Saeed</forenames></author><author><keyname>Grigoriadis</keyname><forenames>Karolos</forenames></author><author><keyname>Franchek</keyname><forenames>Matthew</forenames></author></authors><title>Real-Time Cubature Kalman Filter Parameter Estimation of Blood Pressure
  Response Characteristics Under Vasoactive Drugs Administration</title><categories>eess.SY cs.SY eess.SP</categories><comments>8 Pages, 14 Figures, 2 Tables. arXiv admin note: text overlap with
  arXiv:1909.13170</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical modeling and real-time dynamics identification of the mean
arterial blood pressure (MAP) response of a patient to vasoactive drug infusion
can provide a reliable tool for automated drug administration and therefore,
reduce the emergency costs and significantly benefit the patient's MAP
regulation in an intensive care unit. To this end, a dynamic first-order linear
parameter-varying (LPV) model with varying parameters and varying input delay
is considered to capture the MAP response dynamics. Such a model effectively
addresses the complexity and the intra- and inter-patient variability of the
physiological response. We discretize the model and augment the state vector
with model parameters as unknown states of the system and a Bayesian-based
multiple-model square root cubature Kalman filtering (MMSRCKF) approach is
utilized to estimate the model time-varying parameters. Since, unlike the other
model parameters, the input delay cannot be captured by a random-walk process,
a multiple-model module with a posterior probability estimation is implemented
to provide the delay identification. Validation results confirm the
effectiveness of the proposed identification algorithm both in simulation
scenarios and also using animal experiment data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01028</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01028</id><created>2019-10-02</created><authors><author><keyname>Karanov</keyname><forenames>Boris</forenames></author><author><keyname>Liga</keyname><forenames>Gabriele</forenames></author><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Lavery</keyname><forenames>Domani&#xe7;</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author><author><keyname>Schmalen</keyname><forenames>Laurent</forenames></author></authors><title>Deep Learning for Communication over Dispersive Nonlinear Channels:
  Performance and Comparison with Classical Digital Signal Processing</title><categories>cs.IT eess.SP math.IT</categories><comments>Invited paper at Allerton 2019 Conference on Communication, Control
  and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply deep learning for communication over dispersive
channels with power detection, as encountered in low-cost optical intensity
modulation/direct detection (IM/DD) links. We consider an autoencoder based on
the recently proposed sliding window bidirectional recurrent neural network
(SBRNN) design to realize the transceiver for optical IM/DD communication. We
show that its performance can be improved by introducing a weighted sequence
estimation scheme at the receiver. Moreover, we perform bit-to-symbol mapping
optimization to reduce the bit-error rate (BER) of the system. Furthermore, we
carry out a detailed comparison with classical schemes based on pulse-amplitude
modulation and maximum likelihood sequence detection (MLSD). Our investigation
shows that for a reference 42\,Gb/s transmission, the SBRNN autoencoder
achieves a BER performance comparable to MLSD, when both systems account for
the same amount of memory. In contrast to MLSD, the SBRNN performance is
achieved without incurring a computational complexity exponentially growing
with the processed memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01032</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01032</id><created>2019-10-01</created><authors><author><keyname>Alavi</keyname><forenames>Seyer Amir</forenames></author><author><keyname>Javadipour</keyname><forenames>Mehrnaz</forenames></author><author><keyname>Mehran</keyname><forenames>Kamyar</forenames></author></authors><title>Microgrid Optimal State Estimation Over IoT Wireless Sensor Networks
  With Event-Based Measurements</title><categories>eess.SY cs.SY</categories><comments>Published in IECON 2019, Lisbon, Portugal. arXiv admin note: text
  overlap with arXiv:1906.00437</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In a microgrid, real-time state estimation has always been a challenge due to
several factors such as the complexity of computations, constraints of the
communication network and low inertia. In this paper, a real-time event-based
optimal linear state estimator is introduced, which uses the send-on-delta data
collection approach over wireless sensors networks and exhibits low computation
and communication resources cost. By employing the send-on-delta event-based
measurement strategy, the burden over the wireless sensor network is reduced
due to the transmission of events only when there is a significant variation in
the signals. The state estimator structure is developed based on the linear
Kalman filter with the additional steps for the centralized fusion of events
data and optimal reconstruction of signals by projection onto convex sets. Also
for the practical feasibility analysis, this paper developed an Internet of
things prototype platform based on LoRaWAN protocol that satisfies the
requirements of the proposed state estimator in a microgrid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01045</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01045</id><created>2019-10-02</created><authors><author><keyname>Naghnaeian</keyname><forenames>Mohammad</forenames></author><author><keyname>Voulgaris</keyname><forenames>Petros G.</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>A Youla Operator State-Space Framework for Stably Realizable Distributed
  Control</title><categories>math.OC cs.SY eess.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of distributed control synthesis. We seek
to find structured controllers that are stably realizable over the underlying
network. We address the problem using an operator form of discrete-time linear
systems. This allows for uniform treatment of various classes of linear
systems, e.g., Linear Time Invariant (LTI), Linear Time Varying (LTV), or
linear switched systems. We combine this operator representation for linear
systems with the classical Youla parameterization to characterize the set of
stably realizable controllers for a given network structure. Using this Youla
Operator State-Space (YOSS) framework, we show that if the structure satisfies
certain subspace like assumptions, then both stability and performance problems
can be formulated as convex optimization and more precisely as tractable
model-matching problems to any a priori accuracy. Furthermore, we show that the
structured controllers found from our approach can be stably realized over the
network and provide a generalized separation principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01050</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01050</id><created>2019-10-02</created><updated>2019-10-04</updated><authors><author><keyname>Varga</keyname><forenames>Domonkos</forenames></author></authors><title>Empirical evaluation of full-reference image quality metrics on MDID
  database</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this study, our goal is to give a comprehensive evaluation of 32
state-of-the-art FR-IQA metrics using the recently published MDID. This
database contains distorted images derived from a set of reference, pristine
images using random types and levels of distortions. Specifically, Gaussian
noise, Gaussian blur, contrast change, JPEG noise, and JPEG2000 noise were
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01059</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01059</id><created>2019-10-02</created><updated>2019-11-27</updated><authors><author><keyname>Jang</keyname><forenames>Hyeryung</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Gardner</keyname><forenames>Brian</forenames></author><author><keyname>Gr&#xfc;ning</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>An Introduction to Probabilistic Spiking Neural Networks: Probabilistic
  Models, Learning Rules, and Applications</title><categories>cs.LG cs.NE eess.SP stat.ML</categories><comments>Published in IEEE Signal Processing Magazine, Vol. 36, No. 6, pp.
  64-77 (subsumes arXiv:1812.03929), Author's Accepted Manuscript</comments><doi>10.1109/MSP.2019.2935234</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spiking neural networks (SNNs) are distributed trainable systems whose
computing elements, or neurons, are characterized by internal analog dynamics
and by digital and sparse synaptic communications. The sparsity of the synaptic
spiking inputs and the corresponding event-driven nature of neural processing
can be leveraged by energy-efficient hardware implementations, which can offer
significant energy reductions as compared to conventional artificial neural
networks (ANNs). The design of training algorithms lags behind the hardware
implementations. Most existing training algorithms for SNNs have been designed
either for biological plausibility or through conversion from pretrained ANNs
via rate encoding. This article provides an introduction to SNNs by focusing on
a probabilistic signal processing methodology that enables the direct
derivation of learning rules by leveraging the unique time-encoding
capabilities of SNNs. We adopt discrete-time probabilistic models for networked
spiking neurons and derive supervised and unsupervised learning rules from
first principles via variational inference. Examples and open research problems
are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01089</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01089</id><created>2019-10-02</created><updated>2019-10-20</updated><authors><author><keyname>Bello</keyname><forenames>Juan Luis Gonzalez</forenames></author><author><keyname>Kim</keyname><forenames>Munchurl</forenames></author></authors><title>Deep 3D Pan via adaptive &quot;t-shaped&quot; convolutions with global and local
  adaptive dilations</title><categories>eess.SP cs.CV eess.IV</categories><comments>Check our video at https://www.youtube.com/watch?v=o0b-e282Rt4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in deep learning have shown promising results in many
low-level vision tasks. However, solving the single-image-based view synthesis
is still an open problem. In particular, the generation of new images at
parallel camera views given a single input image is of great interest, as it
enables 3D visualization of the 2D input scenery. We propose a novel network
architecture to perform stereoscopic view synthesis at arbitrary camera
positions along the X-axis, or Deep 3D Pan, with &quot;t-shaped&quot; adaptive kernels
equipped with globally and locally adaptive dilations. Our proposed network
architecture, the monster-net, is devised with a novel &quot;t-shaped&quot; adaptive
kernel with globally and locally adaptive dilation, which can efficiently
incorporate global camera shift into and handle local 3D geometries of the
target image's pixels for the synthesis of naturally looking 3D panned views
when a 2-D input image is given. Extensive experiments were performed on the
KITTI, CityScapes and our VICLAB_STEREO indoors dataset to prove the efficacy
of our method. Our monster-net significantly outperforms the state-of-the-art
method, SOTA, by a large margin in all metrics of RMSE, PSNR, and SSIM. Our
proposed monster-net is capable of reconstructing more reliable image
structures in synthesized images with coherent geometry. Moreover, the
disparity information that can be extracted from the &quot;t-shaped&quot; kernel is much
more reliable than that of the SOTA for the unsupervised monocular depth
estimation task, confirming the effectiveness of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01091</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01091</id><created>2019-10-02</created><authors><author><keyname>Jung</keyname><forenames>Changhun</forenames></author><author><keyname>Abuhamad</keyname><forenames>Mohammed</forenames></author><author><keyname>Alikhanov</keyname><forenames>Jumabek</forenames></author><author><keyname>Mohaisen</keyname><forenames>Aziz</forenames></author><author><keyname>Han</keyname><forenames>Kyungja</forenames></author><author><keyname>Nyang</keyname><forenames>DaeHun</forenames></author></authors><title>W-Net: A CNN-based Architecture for White Blood Cells Image
  Classification</title><categories>eess.IV cs.CV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-aided methods for analyzing white blood cells (WBC) have become
widely popular due to the complexity of the manual process. Recent works have
shown highly accurate segmentation and detection of white blood cells from
microscopic blood images. However, the classification of the observed cells is
still a challenge and highly demanded as the distribution of the five types
reflects on the condition of the immune system. This work proposes W-Net, a
CNN-based method for WBC classification. We evaluate W-Net on a real-world
large-scale dataset, obtained from The Catholic University of Korea, that
includes 6,562 real images of the five WBC types. W-Net achieves an average
accuracy of 97%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01092</identifier>
 <datestamp>2020-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01092</id><created>2019-10-02</created><updated>2020-02-04</updated><authors><author><keyname>Manzanilla-Salazar</keyname><forenames>Orestes</forenames></author><author><keyname>Malandra</keyname><forenames>Filippo</forenames></author><author><keyname>Mellah</keyname><forenames>Hakim</forenames></author><author><keyname>Wette</keyname><forenames>Constant</forenames></author><author><keyname>Sanso</keyname><forenames>Brunilde</forenames></author></authors><title>A Machine Learning framework for Sleeping Cell Detection in a Smart-city
  IoT Telecommunications Infrastructure</title><categories>eess.SP cs.LG cs.NI</categories><comments>Submitted to the IEEE Access Journal</comments><msc-class>68M15, 94C12, 68T10</msc-class><acm-class>C.2.5; C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The smooth operation of largely deployed Internet of Things (IoT)
applications will depend on, among other things, effective infrastructure
failure detection. Access failures in wireless network Base Stations (BSs)
produce a phenomenon called &quot;sleeping cells&quot;, which can render a cell catatonic
without triggering any alarms or provoking immediate effects on cell
performance, making them difficult to discover. To detect this kind of failure,
we propose a Machine Learning (ML) framework based on the use of Key
Performance Indicator (KPI) statistics from the BS under study, as well as
those of the neighboring BSs with propensity to have their performance affected
by the failure. A simple way to define neighbors is to use adjacency in Voronoi
diagrams. In this paper, we propose a much more realistic approach based on the
nature of radio-propagation and the way devices choose the BS to which they
send access requests. We gather data from large-scale simulators that use real
location data for BSs and IoT devices and pose the detection problem as a
supervised binary classification problem. We measure the effects on the
detection performance by the size of time aggregations of the data, the level
of traffic and the parameters of the neighborhood definition. The Extra Trees
and Naive Bayes classifiers achieve Receiver Operating Characteristic (ROC)
Area Under the Curve (AUC) scores of 0.996 and 0.993, respectively, with False
Positive Rate (FPR) under 5 %. The proposed framework holds potential for other
pattern recognition tasks in smart-city wireless infrastructures, that would
enable the monitoring, prediction and improvement of the Quality of Service
(QoS) experienced by IoT applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01113</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01113</id><created>2019-10-01</created><authors><author><keyname>Leuschner</keyname><forenames>Johannes</forenames></author><author><keyname>Schmidt</keyname><forenames>Maximilian</forenames></author><author><keyname>Baguer</keyname><forenames>Daniel Otero</forenames></author><author><keyname>Maa&#xdf;</keyname><forenames>Peter</forenames></author></authors><title>The LoDoPaB-CT Dataset: A Benchmark Dataset for Low-Dose CT
  Reconstruction Methods</title><categories>eess.IV cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep Learning approaches for solving Inverse Problems in imaging have become
very effective and are demonstrated to be quite competitive in the field.
Comparing these approaches is a challenging task since they highly rely on the
data and the setup that is used for training. We provide a public dataset of
computed tomography images and simulated low-dose measurements suitable for
training this kind of methods. With the LoDoPaB-CT Dataset we aim to create a
benchmark that allows for a fair comparison. It contains over 40,000 scan
slices from around 800 patients selected from the LIDC/IDRI Database. In this
paper we describe how we processed the original slices and how we simulated the
measurements. We also include first baseline results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01150</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01150</id><created>2019-10-02</created><authors><author><keyname>Shen</keyname><forenames>Kai</forenames></author><author><keyname>Mcguirk</keyname><forenames>Anya</forenames></author><author><keyname>Liao</keyname><forenames>Yuwei</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Arin</forenames></author><author><keyname>Kakde</keyname><forenames>Deovrat</forenames></author></authors><title>Fault Detection Using Nonlinear Low-Dimensional Representation of Sensor
  Data</title><categories>eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor data analysis plays a key role in health assessment of critical
equipment. Such data are multivariate and exhibit nonlinear relationships. This
paper describes how one can exploit nonlinear dimension reduction techniques,
such as the t-distributed stochastic neighbor embedding (t-SNE) and kernel
principal component analysis (KPCA) for fault detection. We show that using
anomaly detection with low dimensional representations provides better
interpretability and is conducive to edge processing in IoT applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01176</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01176</id><created>2019-10-02</created><authors><author><keyname>Neu</keyname><forenames>Joachim</forenames></author><author><keyname>Co&#x15f;kun</keyname><forenames>Mustafa Cemil</forenames></author><author><keyname>Liva</keyname><forenames>Gianluigi</forenames></author></authors><title>Ternary Quantized Polar Code Decoders: Analysis and Design</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of short polar codes under successive cancellation (SC) and
SC list (SCL) decoding is analyzed for the case where the decoder messages are
coarsely quantized. This setting is of particular interest for applications
requiring low-complexity energy-efficient transceivers (e.g.,
internet-of-things or wireless sensor networks). We focus on the extreme case
where the decoder messages are quantized with 3 levels. We show how under SCL
decoding quantized log-likelihood ratios lead to a large inaccuracy in the
calculation of path metrics, resulting in considerable performance losses with
respect to an unquantized SCL decoder. We then introduce two novel techniques
which improve the performance of SCL decoding with coarse quantization. The
first technique consists of a modification of the final decision step of SCL
decoding, where the selected codeword is the one maximizing the
maximum-likelihood decoding metric within the final list. The second technique
relies on statistical knowledge about the reliability of the bit estimates,
obtained through a suitably modified density evolution analysis, to improve the
list construction phase, yielding a higher probability of having the
transmitted codeword in the list. The effectiveness of the two techniques is
demonstrated through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01189</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01189</id><created>2019-10-02</created><updated>2019-10-06</updated><authors><author><keyname>Muthirayan</keyname><forenames>Deepan</forenames></author><author><keyname>Nivison</keyname><forenames>Scott</forenames></author><author><keyname>Khargonekar</keyname><forenames>Pramod P.</forenames></author></authors><title>Improved Attention Models for Memory Augmented Neural Network Adaptive
  Controllers</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduced a {\it working memory} augmented adaptive controller in our
recent work. The controller uses attention to read from and write to the
working memory. Attention allows the controller to read specific information
that is relevant and update its working memory with information based on its
relevance. The retrieved information is used to modify the final control input
computed by the controller. We showed that this modification speeds up
learning. In the above work, we used a soft-attention mechanism for the
adaptive controller. Controllers that use soft attention or hard attention
mechanisms are limited either because they can forget the information or fail
to shift attention when the information they are reading becomes less relevant.
We propose an attention mechanism that comprises of (i) a hard attention
mechanism and additionally (ii) an attention reallocation mechanism. The
attention reallocation enables the controller to reallocate attention to a
different location when the relevance of the location it is reading from
diminishes. The reallocation also ensures that the information stored in the
memory before the shift in attention is retained which can be lost in both soft
and hard attention mechanisms. We illustrate through simulations that the
memory that uses the proposed attention mechanism stores a more accurate
representation of the variations in the hidden layer values of the neural
network (NN). Also, through detailed simulations of various scenarios for two
link robot and three link robot arm systems we illustrate the effectiveness of
the proposed attention mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01213</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01213</id><created>2019-09-27</created><authors><author><keyname>Zamzam</keyname><forenames>Ahmed</forenames></author><author><keyname>Baker</keyname><forenames>Kyri</forenames></author></authors><title>Learning Optimal Solutions for Extremely Fast AC Optimal Power Flow</title><categories>cs.LG cs.SY eess.SP eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop an online method that leverages machine learning to
obtain feasible solutions to the AC optimal power flow (OPF) problem with
negligible optimality gaps on extremely fast timescales (e.g., milliseconds),
bypassing solving an AC OPF altogether. This is motivated by the fact that as
the power grid experiences increasing amounts of renewable power generation,
controllable loads, and other inverter-interfaced devices, faster system
dynamics and quicker fluctuations in the power supply are likely to occur.
Currently, grid operators typically solve AC OPF every 15 minutes to determine
economic generator settings while ensuring grid constraints are satisfied. Due
to the computational challenges with solving this nonconvex problem, many
efforts have focused on linearizing or approximating the problem in order to
solve the AC OPF on faster timescales. However, many of these approximations
can be fairly poor representations of the actual system state and still require
solving an optimization problem, which can be time consuming for large
networks. In this work, we leverage historical data to learn a mapping between
the system loading and optimal generation values, enabling us to find
near-optimal and feasible AC OPF solutions on extremely fast timescales without
actually solving an optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01221</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01221</id><created>2019-10-02</created><authors><author><keyname>Wen</keyname><forenames>Bingyang</forenames></author><author><keyname>Aydore</keyname><forenames>Sergul</forenames></author></authors><title>ROMark: A Robust Watermarking System Using Adversarial Training</title><categories>cs.CV cs.MM eess.IV</categories><comments>5 pages, 1 figure, Machine Learning with Guarantees workshop at
  NeurIPS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability and easy access to digital communication increase the risk
of copyrighted material piracy. In order to detect illegal use or distribution
of data, digital watermarking has been proposed as a suitable tool. It protects
the copyright of digital content by embedding imperceptible information into
the data in the presence of an adversary. The goal of the adversary is to
remove the copyrighted content of the data. Therefore, an efficient
watermarking framework must be robust to multiple image-processing operations
known as attacks that can alter embedded copyright information. Another line of
research \textit{adversarial machine learning} also tackles with similar
problems to guarantee robustness to imperceptible perturbations of the input.
In this work, we propose to apply robust optimization from adversarial machine
learning to improve the robustness of a CNN-based watermarking framework. Our
experimental results on the COCO dataset show that the robustness of a
watermarking framework can be improved by utilizing robust optimization in
training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01234</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01234</id><created>2019-10-02</created><updated>2020-01-01</updated><authors><author><keyname>Mishra</keyname><forenames>Sakshi</forenames></author><author><keyname>Anderson</keyname><forenames>Kate</forenames></author><author><keyname>Miller</keyname><forenames>Brian</forenames></author><author><keyname>Boyer</keyname><forenames>Kyle</forenames></author><author><keyname>Warren</keyname><forenames>Adam</forenames></author></authors><title>Microgrid Resilience: A holistic approach for assessing threats,
  identifying vulnerabilities, and designing corresponding mitigation
  strategies</title><categories>eess.SY cs.SY eess.SP</categories><comments>24 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microgrids are being increasing deployed to improve the operational
flexibility, resilience, coordinated-energy management capabilities,
self-adequacy, and increased reliability of power systems. This strong market
growth is also driven by advances in power electronics, improved control
systems, and the rapidly falling price and increased adoption of distributed
energy generation technologies, like solar photovoltaics and storage. In the
event of grid outages, microgrids can provide a backup source of power;
providing resilience to the critical loads; however, this requires that the
microgrid itself is resilient to physical and cyber threats. Building highly
resilient microgrids requires a methodological assessment of potential threats,
identification of vulnerabilities, and design of mitigation strategies. This
paper provides a comprehensive review of threats, vulnerabilities, and
mitigation strategies and develops a definition for microgrid resilience. The
paper also develops a methodology for designing resilient microgrids by
considering how microgrid designers and site owners evaluate threats,
vulnerabilities, and consequences and choose the microgrid features required to
address these threats under different situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01242</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01242</id><created>2019-10-02</created><authors><author><keyname>Roth</keyname><forenames>Holger</forenames></author><author><keyname>Zhu</keyname><forenames>Wentao</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author><author><keyname>Xu</keyname><forenames>Ziyue</forenames></author><author><keyname>Xu</keyname><forenames>Daguang</forenames></author></authors><title>Cardiac Segmentation of LGE MRI with Noisy Labels</title><categories>eess.IV cs.CV</categories><comments>Accepted at the MICCAI Workshop Statistical Atlases and Computational
  Modeling of the Heart (STACOM), MS-CMRSeg 2019: Multi-sequence Cardiac MR
  Segmentation Challenge, Shenzen, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we attempt the segmentation of cardiac structures in late
gadolinium-enhanced (LGE) magnetic resonance images (MRI) using only minimal
supervision in a two-step approach. In the first step, we register a small set
of five LGE cardiac magnetic resonance (CMR) images with ground truth labels to
a set of 40 target LGE CMR images without annotation. Each manually annotated
ground truth provides labels of the myocardium and the left ventricle (LV) and
right ventricle (RV) cavities, which are used as atlases. After multi-atlas
label fusion by majority voting, we possess noisy labels for each of the
targeted LGE images. A second set of manual labels exists for 30 patients of
the target LGE CMR images, but are annotated on different MRI sequences (bSSFP
and T2-weighted). Again, we use multi-atlas label fusion with a consistency
constraint to further refine our noisy labels if additional annotations in
other modalities are available for a given patient. In the second step, we
train a deep convolutional network for semantic segmentation on the target data
while using data augmentation techniques to avoid over-fitting to the noisy
labels. After inference and simple post-processing, we achieve our final
segmentation for the targeted LGE CMR images, resulting in an average Dice of
0.890, 0.780, and 0.844 for LV cavity, LV myocardium, and RV cavity,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01262</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01262</id><created>2019-10-02</created><updated>2020-02-03</updated><authors><author><keyname>Wang</keyname><forenames>Xiaoqiang</forenames></author><author><keyname>Gu</keyname><forenames>Lejia</forenames></author><author><keyname>Lee</keyname><forenames>Joseph Heung-wing Joseph</forenames></author><author><keyname>Zhang</keyname><forenames>Guofeng</forenames></author></authors><title>Quantum tensor singular value decomposition with applications to
  recommendation systems</title><categories>quant-ph cs.LG cs.SY eess.SY math.OC</categories><comments>29 pages, 5 figure. Comments are welcome!</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a quantum singular value decomposition algorithm
for third-order tensors inspired by the classical algorithm of tensor singular
value decomposition (t-svd) and then extend it to order-$p$ tensors. It can be
proved that the quantum version of the t-svd for a third-order tensor
$\mathcal{A} \in \mathbb{R}^{N\times N \times N}$ achieves the complexity of
$\mathcal{O}(N{\rm polylog}(N))$, an exponential speedup compared with its
classical counterpart. As an application, we propose a quantum algorithm for
recommendation systems which incorporates the contextual situation of users to
the personalized recommendation. We provide recommendations varying with
contexts by measuring the output quantum state corresponding to an
approximation of this user's preferences. This algorithm runs in expected time
$\mathcal{O}(N{\rm polylog}(N){\rm poly}(k)),$ if every frontal slice of the
preference tensor has a good rank-$k$ approximation. At last, we provide a
quantum algorithm for tensor completion based on a different truncation method
which is tested to have a good performance in dynamic video completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01268</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01268</id><created>2019-10-02</created><authors><author><keyname>Lemay</keyname><forenames>Andr&#xe9;anne</forenames></author></authors><title>Kidney Recognition in CT Using YOLOv3</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Organ localization can be challenging considering the heterogeneity of
medical images and the biological diversity from one individual to another. The
contribution of this paper is to overview the performance of the object
detection model, YOLOv3, on kidney localization in 2D and in 3D from CT scans.
The model obtained a 0.851 Dice score in 2D and 0.742 in 3D. The SSD, a similar
state-of-the-art object detection model, showed similar scores on the test set.
YOLOv3 and SSD demonstrated the ability to detect kidneys on a wide variety of
CT scans including patients suffering from different renal conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01287</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01287</id><created>2019-10-02</created><authors><author><keyname>She</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Sandra Q.</forenames></author><author><keyname>Yu</keyname><forenames>Peiyu</forenames></author><author><keyname>Adelson</keyname><forenames>Edward</forenames></author></authors><title>Exoskeleton-covered soft finger with vision-based proprioception and
  exteroception</title><categories>cs.RO eess.IV</categories><comments>submitted to ICRA2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Soft robots offer significant advantages in adaptability, safety, and
dexterity compared to conventional rigid-body robots. However, it is
challenging to equip soft robots with accurate proprioception and exteroception
due to their high flexibility and elasticity. In this work, we develop a novel
exoskeleton-covered soft finger with embedded cameras and deep learning methods
that enable high-resolution proprioceptive sensing and rich tactile sensing. To
do so, we design features along the axial direction of the finger, which enable
high-resolution proprioceptive sensing, and incorporate a reflective ink
coating on the surface of the finger to enable rich tactile sensing. We design
a highly underactuated exoskeleton with a tendon-driven mechanism to actuate
the finger. Finally, we assemble 2 of the fingers together to form a robotic
gripper and successfully perform a bar stock classification task, which
requires both shape and tactile information. We train neural networks for
proprioception and shape (box versus cylinder) classification using data from
the embedded sensors. The proprioception CNN had over 99\% accuracy on our
testing set (all six joint angles were within 1$^\circ$ of error) and had an
average accumulative distance error of 0.77 mm during live testing, which is
better than human finger proprioception. These proposed techniques offer soft
robots the high-level ability to simultaneously perceive their proprioceptive
state and peripheral environment, providing potential solutions for soft robots
to solve everyday manipulation tasks. We believe the methods developed in this
work can be widely applied to different designs and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01289</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01289</id><created>2019-10-02</created><authors><author><keyname>Fan</keyname><forenames>Kai</forenames></author><author><keyname>Wang</keyname><forenames>Jiayi</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Chen</keyname><forenames>Boxing</forenames></author><author><keyname>Ge</keyname><forenames>Niyu</forenames></author></authors><title>Neural Zero-Inflated Quality Estimation Model For Automatic Speech
  Recognition System</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performances of automatic speech recognition (ASR) systems are usually
evaluated by the metric word error rate (WER) when the manually transcribed
data are provided, which are, however, expensively available in the real
scenario. In addition, the empirical distribution of WER for most ASR systems
usually tends to put a significant mass near zero, making it difficult to
simulate with a single continuous distribution. In order to address the two
issues of ASR quality estimation (QE), we propose a novel neural zero-inflated
model to predict the WER of the ASR result without transcripts. We design a
neural zero-inflated beta regression on top of a bidirectional transformer
language model conditional on speech features (speech-BERT). We adopt the
pre-training strategy of token level mask language modeling for speech-BERT as
well, and further fine-tune with our zero-inflated layer for the mixture of
discrete and continuous outputs. The experimental results show that our
approach achieves better performance on WER prediction in the metrics of
Pearson and MAE, compared with most existed quality estimation algorithms for
ASR or machine translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01294</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01294</id><created>2019-10-02</created><updated>2020-01-18</updated><authors><author><keyname>Nguyen</keyname><forenames>Hieu V.</forenames></author><author><keyname>Nguyen</keyname><forenames>Van-Dinh</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Sharma</keyname><forenames>Shree Krishna</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Shin</keyname><forenames>Oh-Soon</forenames></author></authors><title>On the Spectral and Energy Efficiencies of Full-Duplex Cell-Free Massive
  MIMO</title><categories>eess.SP</categories><comments>This paper was submitted for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-band full-duplex (FD) operation is practically more suited for short-range
communications such as WiFi and small-cell networks, due to its current
practical limitations on the self-interference cancellation. In addition,
cell-free massive multiple-input multiple-output (CF-mMIMO) is a new and
scalable version of MIMO networks, which is designed to bring service antennas
closer to end user equipments (UEs). To achieve higher spectral and energy
efficiencies (SE-EE) of a wireless network, it is of practical interest to
incorporate FD capability into CF-mMIMO systems to utilize their combined
benefits. We formulate a novel and comprehensive optimization problem for the
maximization of SE and EE in which power control, access point-UE (AP-UE)
association and AP selection are jointly optimized under a realistic power
consumption model, resulting in a difficult class of mixed-integer nonconvex
programming. To tackle the binary nature of the formulated problem, we propose
an efficient approach by exploiting a strong coupling between binary and
continuous variables, leading to a more tractable problem. In this regard, two
low-complexity transmission designs based on zero-forcing (ZF) are proposed.
Combining tools from inner approximation framework and Dinkelbach method, we
develop simple iterative algorithms with polynomial computational complexity in
each iteration and strong theoretical performance guaranteed. Furthermore,
towards a robust design for FD CF-mMIMO, a novel heap-based pilot assignment
algorithm is proposed to mitigate effects of pilot contamination. Numerical
results show that our proposed designs with realistic parameters significantly
outperform the well-known approaches (i.e., small-cell and collocated mMIMO) in
terms of the SE and EE. Notably, the proposed ZF designs require much less
execution time than the simple maximum ratio transmission/combining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01344</identifier>
 <datestamp>2020-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01344</id><created>2019-10-03</created><updated>2020-01-08</updated><authors><author><keyname>Zhou</keyname><forenames>Ting</forenames></author><author><keyname>Zhou</keyname><forenames>Kang</forenames></author><author><keyname>Yang</keyname><forenames>Jianlong</forenames></author><author><keyname>Fang</keyname><forenames>Liyang</forenames></author><author><keyname>Hu</keyname><forenames>Yan</forenames></author><author><keyname>Zhao</keyname><forenames>Yitian</forenames></author><author><keyname>Cheng</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Xiangping</forenames></author><author><keyname>Gao</keyname><forenames>Shenghua</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author></authors><title>Digital resolution enhancement in low transverse sampling optical
  coherence tomography angiography using deep learning</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical coherence tomography angiography (OCTA) requires high transverse
sampling density for visualizing retinal and choroidal capillaries. Low
transverse sampling causes resolution degradation, such as the angiograms in
wide-field OCTA. In this paper, we propose to address this problem using deep
learning. We conducted extensive experiments on converting the centrally
cropped 3 x 3 mm2 field of view (FOV) of the 8 x 8 mm2 foveal OCTA images (a
sampling density of 22.9 $\mu$m) to the native 3 x 3 mm2 en face OCTA images (a
sampling density of 12.2 $\mu$m). We employed a cycle-consistent adversarial
network architecture in this conversion. The quantitative analysis using the
perceptual similarity measures shows the generated OCTA images are closer to
the native 3 x 3 mm2 scans. Besides, the results show the proposed method could
also enhance signal-to-noise ratio. We further applied our method to enhance
diseased cases and calculate vascular biomarkers, which demonstrates its
generalization performance and clinical perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01350</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01350</id><created>2019-10-03</created><authors><author><keyname>Tiwari</keyname><forenames>Shashank</forenames></author><author><keyname>das</keyname><forenames>Suvra Sekhar</forenames></author><author><keyname>Rangamgari</keyname><forenames>Vivek</forenames></author></authors><title>Low Complexity LMMSE Receiver for OTFS</title><categories>cs.IT eess.SP math.IT</categories><comments>Accepted for Publication in IEEE Comm. Lett</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal time frequency space modulation is a two dimensional (2D)
delay-Doppler domain waveform. It uses inverse symplectic Fourier transform
(ISFFT) to spread the signal in time-frequency domain. To extract diversity
gain from 2D spreaded signal, advanced receivers are required. In this work, we
investigate a low complexity linear minimum mean square error receiver which
exploits sparsity and quasi-banded structure of matrices involved in the
demodulation process which results in a log-linear order of complexity without
any performance degradation of BER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01381</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01381</id><created>2019-10-03</created><authors><author><keyname>Abbasi</keyname><forenames>Naveed A.</forenames></author><author><keyname>Hariharan</keyname><forenames>Arjun</forenames></author><author><keyname>Nair</keyname><forenames>Arun Moni</forenames></author><author><keyname>Almaiman</keyname><forenames>Ahmed S.</forenames></author><author><keyname>Rottenberg</keyname><forenames>Fran&#xe7;ois B.</forenames></author><author><keyname>Willner</keyname><forenames>Alan E.</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Double Directional Channel Measurements for THz Communications in an
  Urban Environment</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While mm-wave systems are a mainstay for 5G communications, the inexorable
increase of data rate requirements and user densities will soon require the
exploration of next-generation technologies. Among these, Terahertz (THz) band
communication seems to be a promising direction due to availability of large
bandwidth in the electromagnetic spectrum in this frequency range, and the
ability to exploit its directional nature by directive antennas with small form
factors. The first step in the analysis of any communication system is the
analysis of the propagation channel, since it determines the fundamental
limitations it faces. While THz channels have been explored for indoor,
short-distance communications, the channels for {\em wireless access links in
outdoor environments} are largely unexplored. In this paper, we present the -
to our knowledge - first set of double-directional outdoor propagation channel
measurements for the THz band. Specifically, the measurements are done in the
141 - 148.5 GHz range, which is one of the frequency bands recently allocated
for THz research by the Federal Communication Commission (FCC). We employ
double directional channel sounding using a frequency domain sounding setup
based on RF-over-Fiber (RFoF) extensions for measurements over 100 m distance
in urban scenarios. An important result is the surprisingly large number of
directions (i.e., direction-of-arrival and direction-of-departure pairs) that
carry significant energy. More generally, our results suggest fundamental
parameters that can be used in future THz Band analysis and implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01426</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01426</id><created>2019-10-03</created><updated>2019-11-21</updated><authors><author><keyname>Meng</keyname><forenames>Nan</forenames></author><author><keyname>So</keyname><forenames>Hayden K. -H.</forenames></author><author><keyname>Sun</keyname><forenames>Xing</forenames></author><author><keyname>Lam</keyname><forenames>Edmund Y.</forenames></author></authors><title>High-dimensional Dense Residual Convolutional Neural Network for Light
  Field Reconstruction</title><categories>eess.IV cs.CV</categories><comments>14 pages. IEEE Transactions on Pattern Analysis and Machine
  Intelligence (2019)</comments><doi>10.1109/TPAMI.2019.2945027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of high-dimensional light field reconstruction and
develop a learning-based framework for spatial and angular super-resolution.
Many current approaches either require disparity clues or restore the spatial
and angular details separately. Such methods have difficulties with
non-Lambertian surfaces or occlusions. In contrast, we formulate light field
super-resolution (LFSR) as tensor restoration and develop a learning framework
based on a two-stage restoration with 4-dimensional (4D) convolution. This
allows our model to learn the features capturing the geometry information
encoded in multiple adjacent views. Such geometric features vary near the
occlusion regions and indicate the foreground object border. To train a
feasible network, we propose a novel normalization operation based on a group
of views in the feature maps, design a stage-wise loss function, and develop
the multi-range training strategy to further improve the performance.
Evaluations are conducted on a number of light field datasets including
real-world scenes, synthetic data, and microscope light fields. The proposed
method achieves superior performance and less execution time comparing with
other state-of-the-art schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01429</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01429</id><created>2019-10-03</created><authors><author><keyname>Wakaiki</keyname><forenames>Masashi</forenames></author><author><keyname>Yamamoto</keyname><forenames>Yutaka</forenames></author></authors><title>Stability Analysis of Perturbed Infinite-dimensional Sampled-data
  Systems</title><categories>math.OC cs.SY eess.SY</categories><comments>15 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the stability analysis of infinite-dimensional
sampled-data systems under unbounded perturbations. We present two classes of
unbounded perturbations preserving the exponential stability of sampled-data
systems. To this end, we investigate the continuity of strongly continuous
semigroups with respect to their generators, considering the uniform operator
topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01461</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01461</id><created>2019-10-03</created><updated>2019-11-25</updated><authors><author><keyname>Nagarsheth</keyname><forenames>Shaival Hemant</forenames></author><author><keyname>Sharma</keyname><forenames>Shambhu Nath</forenames></author></authors><title>RNGA for non-square multivariable control systems: properties and
  application</title><categories>math.OC cs.SY eess.SY</categories><comments>16 pages, 5 figures, 3 tables</comments><msc-class>93A14-Decentralized system, 15A09-Matrix inversion, generalized
  inverses, 93C35-Multivariable systems</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Relative Gain Array (RGA) and Relative Normalized Gain Array (RNGA) have
received considerable attention for square systems. In this paper RNGA with the
column-major, for non-square multivariable systems is introduced. RNGA of the
paper has a row-column inequality, i.e. the number of rows is less than the
number of columns. Unlike the conventional RGA, the RNGA loop pairing criteria
of the paper considers both steady-state as well as transient information for
the assessment of control-loop interactions. The RNGA for square systems is
extended for non-square multivariable systems by thoroughly deriving its
supporting properties. The RNGA method is applied to a non-square multivariable
radiator laboratory test setup for loop pairing. Closed-loop results arising
from the RNGA-based loop pairing are depicted in the paper. The lacuna of the
conventional RGA loop pairing has been overcome by the application of the
developed RNGA of this paper. The results unfold the effectiveness of RNGA over
RGA for non-square multivariable systems to have minimum interactions and
better control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01463</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01463</id><created>2019-10-01</created><updated>2019-10-03</updated><authors><author><keyname>Cheuk</keyname><forenames>Kin Wai</forenames></author><author><keyname>T.</keyname><forenames>Balamurali B.</forenames></author><author><keyname>Roig</keyname><forenames>Gemma</forenames></author><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author></authors><title>Latent space representation for multi-target speaker detection and
  identification with a sparse dataset using Triplet neural networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted for ASRU 2019</comments><msc-class>68T10, 68Txx</msc-class><journal-ref>Proceedings of IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU 2019). Singapore. 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach to tackle the speaker recognition problem using
Triplet Neural Networks. Currently, the $i$-vector representation with
probabilistic linear discriminant analysis (PLDA) is the most commonly used
technique to solve this problem, due to high classification accuracy with a
relatively short computation time. In this paper, we explore a neural network
approach, namely Triplet Neural Networks (TNNs), to built a latent space for
different classifiers to solve the Multi-Target Speaker Detection and
Identification Challenge Evaluation 2018 (MCE 2018) dataset. This training set
contains $i$-vectors from 3,631 speakers, with only 3 samples for each speaker,
thus making speaker recognition a challenging task. When using the train and
development set for training both the TNN and baseline model (i.e., similarity
evaluation directly on the $i$-vector representation), our proposed model
outperforms the baseline by 23%. When reducing the training data to only using
the train set, our method results in 309 confusions for the Multi-target
speaker identification task, which is 46% better than the baseline model. These
results show that the representational power of TNNs is especially evident when
training on small datasets with few instances available per class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01479</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01479</id><created>2019-10-01</created><authors><author><keyname>Kaushik</keyname><forenames>Aryan</forenames></author><author><keyname>Vlachos</keyname><forenames>Evangelos</forenames></author><author><keyname>Tsinos</keyname><forenames>Christos</forenames></author><author><keyname>Thompson</keyname><forenames>John</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author></authors><title>Joint Bit Allocation and Hybrid Beamforming Optimization for Energy
  Efficient Millimeter Wave MIMO Systems</title><categories>eess.SP</categories><comments>30 pages, 10 figures, submitted to IEEE Journal on Selected Areas in
  Communications. arXiv admin note: text overlap with arXiv:1909.12170</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim to design highly energy efficient end-to-end
communication for millimeter wave multiple-input multiple-output systems. This
is done by jointly optimizing the digital-to-analog converter
(DAC)/analog-to-digital converter (ADC) bit resolutions and hybrid beamforming
matrices. The novel decomposition of the hybrid precoder and the hybrid
combiner to three parts is introduced at the transmitter (TX) and the receiver
(RX), respectively, representing the analog precoder/combiner matrix, the
DAC/ADC bit resolution matrix and the baseband precoder/combiner matrix. The
unknown matrices are computed as a solution to the matrix factorization problem
where the optimal fully digital precoder or combiner is approximated by the
product of these matrices. A novel and efficient solution based on the
alternating direction method of multipliers is proposed to solve these problems
at both the TX and the RX. The simulation results show that the proposed
solution, where the DAC/ADC bit allocation is dynamic during operation,
achieves higher energy efficiency when compared with existing benchmark
techniques that use fixed DAC/ADC bit resolutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01480</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01480</id><created>2019-10-03</created><authors><author><keyname>Liu</keyname><forenames>Yan</forenames></author><author><keyname>Ren</keyname><forenames>Wuwei</forenames></author><author><keyname>Ammari</keyname><forenames>Habib</forenames></author></authors><title>Robust reconstruction of fluorescence molecular tomography with an
  optimized illumination pattern</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence molecular tomography (FMT) is an emerging powerful tool for
biomedical research. There are two factors that influence FMT reconstruction
most effectively. The first one is the regularization techniques. Traditional
methods such as Tikhonov regularization suffer from low resolution and poor
signal to noise ratio. Therefore sparse regularization techniques have been
introduced to improve the reconstruction quality. The second factor is the
illumination pattern. A better illumination pattern ensures the quantity and
quality of the information content of the data set thus leading to better
reconstructions. In this work, we take advantage of the discrete formulation of
the forward problem to give a rigorous definition of an illumination pattern as
well as the admissible set of patterns. We add restrictions in the admissible
set as different types of regularizers to a discrepancy functional, generating
another inverse problem with the illumination pattern as unknown. Both inverse
problems of reconstructing the fluorescence distribution and finding the
optimal illumination pattern are solved by fast efficient iterative algorithms.
Numerical experiments have shown that with a suitable choice of the
regularization parameters the two-step approach converges to an optimal
illumination pattern quickly and the reconstruction result is improved
significantly, regardless of the initial illumination setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01488</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01488</id><created>2019-10-02</created><authors><author><keyname>Sampaio</keyname><forenames>Phillipe R.</forenames></author><author><keyname>Salvazet</keyname><forenames>Raphael</forenames></author><author><keyname>Mandel</keyname><forenames>Pierre</forenames></author><author><keyname>Becker</keyname><forenames>Gw&#xe9;na&#xeb;lle</forenames></author><author><keyname>Chenu</keyname><forenames>Damien</forenames></author></authors><title>Simulation and optimal control of heating and cooling systems: a case
  study of a commercial building</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an energy conservation measure that optimizes the planning of
heating and cooling systems for tertiary sector buildings is proposed. It
consists of a model-based predictive control approach that employs a grey-box
model built from the building data history and from weather condition data that
predicts the building heat load and indoor temperature. This model is then used
by heating and cooling optimization strategies that aim at reducing the total
energy consumption of the building in the next day while satisfying the desired
indoor thermal comfort constraint. The proposed optimization strategies do not
modify the regulation mode in place; rather, they send optimized set-points to
the building management system in order to reduce the energy consumption. We
applied our approach in a case study of a commercial building during heating
and cooling seasons and we show that it was able to yield up to 12% of energy
savings while having a mean power forecast error of 8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01493</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01493</id><created>2019-10-02</created><updated>2019-10-11</updated><authors><author><keyname>Le</keyname><forenames>Duc</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaohui</forenames></author><author><keyname>Zheng</keyname><forenames>Weiyi</forenames></author><author><keyname>F&#xfc;gen</keyname><forenames>Christian</forenames></author><author><keyname>Zweig</keyname><forenames>Geoffrey</forenames></author><author><keyname>Seltzer</keyname><forenames>Michael L.</forenames></author></authors><title>From Senones to Chenones: Tied Context-Dependent Graphemes for Hybrid
  Speech Recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>To appear at ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an implicit assumption that traditional hybrid approaches for
automatic speech recognition (ASR) cannot directly model graphemes and need to
rely on phonetic lexicons to get competitive performance, especially on English
which has poor grapheme-phoneme correspondence. In this work, we show for the
first time that, on English, hybrid ASR systems can in fact model graphemes
effectively by leveraging tied context-dependent graphemes, i.e., chenones. Our
chenone-based systems significantly outperform equivalent senone baselines by
4.5% to 11.1% relative on three different English datasets. Our results on
Librispeech are state-of-the-art compared to other hybrid approaches and
competitive with previously published end-to-end numbers. Further analysis
shows that chenones can better utilize powerful acoustic models and large
training data, and require context- and position-dependent modeling to work
well. Chenone-based systems also outperform senone baselines on proper noun and
rare word recognition, an area where the latter is traditionally thought to
have an advantage. Our work provides an alternative for end-to-end ASR and
establishes that hybrid systems can be improved by dropping the reliance on
phonetic knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01520</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01520</id><created>2019-10-03</created><authors><author><keyname>Battisti</keyname><forenames>Federica</forenames></author><author><keyname>Bernieri</keyname><forenames>Giuseppe</forenames></author><author><keyname>Carli</keyname><forenames>Marco</forenames></author><author><keyname>Lopardo</keyname><forenames>Michela</forenames></author><author><keyname>Pascucci</keyname><forenames>Federica</forenames></author></authors><title>Detecting integrity attacks in IoT-based Cyber Physical Systems: a case
  study on Hydra testbed</title><categories>eess.SY cs.SY</categories><doi>10.1109/GIOTS.2018.8534437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things paradigm improves the classical information sharing
scheme. However, it has increased the need for granting the security of the
connected systems. In the industrial field, the problem becomes more complex
due to the need of protecting a large attack surface while granting the
availability of the system and the real time response to the presence of
threats. In this contribution, we deal with the injection of tampered data into
the communication channel to affect the physical system. The proposed approach
relies on designing a secure control system by coding the output matrices
according to a secret pattern. This pattern is created by using the Fibonacci
p-sequences, numeric sequence depending on a key. The proposed method is
validated on the Hydra testbed, emulating the industrial control network of a
water distribution system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01524</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01524</id><created>2019-10-01</created><authors><author><keyname>Balayla</keyname><forenames>Jacques</forenames></author></authors><title>The Fourier Evaluation of Tracings and Acidosis in Labor: the FETAL
  Technique</title><categories>physics.med-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adequate fetal and neonatal development depend upon the presence of a normal
acid-base environment during pregnancy and the smooth transition from
intra-uterine to extra-uterine life. Current methods to assess fetal pH and
acid-base status are invasive and carry significant maternal and fetal risks.
Given these limitations, obstetrical care providers developed the electronic
fetal monitoring (EFM) system, a non-invasive tool, which evaluates
beat-to-beat fetal heart rate (FHR) patterns in order to predict fetal
oxygenation status in real-time. Every year, about 85 percent of the
approximately 4 million live births in the United States are evaluated using
EFM. Unfortunately, though there is ample physiological evidence that FHR
patterns are inextricably linked to fetal acid-base status, the use of EFM has
not been shown to reliably predict neonatal pH, nor has it reduced the
incidence of adverse perinatal outcomes, including long-term neurological
morbidity and cerebral palsy (CP). The poor specificity associated with the
current interpretation of the EFM therefore leads to a paradox we have
henceforth defined as the Obstetrical Paradox. In this study, we develop and
seek to determine whether a novel, non-invasive method known as the FETAL
technique (Fourier Evaluation of Tracings and Acidosis in Labor), which applies
the Fourier Transform to EFM tracings and determines the spectral frequency
distributions of the FHR, improves the assessment of the fetal pH in real time.
We hypothesize that the improvement in the sensitivity and specificity of the
EFM with the use of the FETAL technique will lead to a significant reduction in
the rate of neonatal hypoxic injury and in the rate of caesarean deliveries for
suspected fetal distress. The implications of a successful application of the
FETAL technique would have paradigm-shifting consequences in the provision of
modern obstetrical care.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01544</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01544</id><created>2019-10-03</created><updated>2020-02-07</updated><authors><author><keyname>Osama</keyname><forenames>Muhammad</forenames></author><author><keyname>Zachariah</keyname><forenames>Dave</forenames></author><author><keyname>Stoica</keyname><forenames>Peter</forenames></author></authors><title>Robust Risk Minimization for Statistical Learning</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general statistical learning problem where an unknown fraction
of the training data is corrupted. We develop a robust learning method that
only requires specifying an upper bound on the corrupted data fraction. The
method minimizes a risk function defined by a non-parametric distribution with
unknown probability weights. We derive and analyse the optimal weights and show
how they provide robustness against corrupted data. Furthermore, we give a
computationally efficient coordinate descent algorithm to solve the risk
minimization problem. We demonstrate the wide range applicability of the
method, including regression, classification, unsupervised learning and classic
parameter estimation, with state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01569</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01569</id><created>2019-10-03</created><updated>2019-11-24</updated><authors><author><keyname>Radnosrati</keyname><forenames>Kamiar</forenames></author><author><keyname>Hendeby</keyname><forenames>Gustaf</forenames></author><author><keyname>Gustafsson</keyname><forenames>Fredrik</forenames></author></authors><title>Exploring Positive Noise in Estimation Theory</title><categories>eess.SP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of a deterministic quantity observed in non-Gaussian additive
noise is explored via order statistics approach. More specifically, we study
the estimation problem when measurement noises either have positive supports or
follow a mixture of normal and uniform distribution. This is a problem of great
interest specially in cellular positioning systems where the wireless signal is
prone to multiple sources of noises which generally have a positive support.
Multiple noise distributions are investigated and, if possible, minimum
variance unbiased (MVU) estimators are derived. In case of uniform, exponential
and Rayleigh noise distributions, unbiased estimators without any knowledge of
the hyper parameters of the noise distributions are also given. For each noise
distribution, the proposed order statistic-based estimator's performance, in
terms of mean squared error, is compared to the best linear unbiased estimator
(BLUE), as a function of sample size, in a simulation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01573</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01573</id><created>2019-10-03</created><authors><author><keyname>Zhang</keyname><forenames>Shuowen</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Capacity Characterization for Intelligent Reflecting Surface Aided MIMO
  Communication</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is a promising solution to enhance the
wireless communication capacity both cost-effectively and energy-efficiently,
by properly altering the signal propagation via tuning a large number of
passive reflecting units. In this paper, we aim to characterize the fundamental
capacity limit of IRS-aided point-to-point multiple-input multiple-output
(MIMO) communication systems with multi-antenna transmitter and receiver in
general, by jointly optimizing the IRS reflection coefficients and the MIMO
transmit covariance matrix. First, we consider narrowband transmission under
frequency-flat fading channels, and develop an efficient alternating
optimization algorithm to find a locally optimal solution by iteratively
optimizing the transmit covariance matrix or one of the reflection coefficients
with the others being fixed. Next, we consider capacity maximization for
broadband transmission in a general MIMO orthogonal frequency division
multiplexing (OFDM) system under frequency-selective fading channels, where
transmit covariance matrices can be optimized for different subcarriers while
only one common set of IRS reflection coefficients can be designed to cater to
all subcarriers. To tackle this more challenging problem, we propose a new
alternating optimization algorithm based on convex relaxation to find a
high-quality suboptimal solution. Numerical results show that our proposed
algorithms achieve substantially increased capacity compared to traditional
MIMO channels without the IRS, and also outperform various benchmark schemes.
In particular, it is shown that with the proposed algorithms, various key
parameters of the IRS-aided MIMO channel such as channel total power, rank, and
condition number can be significantly improved for capacity enhancement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01588</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01588</id><created>2019-10-03</created><authors><author><keyname>Pareek</keyname><forenames>Parikshit</forenames></author><author><keyname>Nguyen</keyname><forenames>Hung D.</forenames></author></authors><title>Probabilistic Robust Small-Signal Stability Framework using Gaussian
  Process Learning</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While most power system small-signal stability assessments rely on the
reduced Jacobian, which depends non-linearly on the states, uncertain operating
points introduce nontrivial hurdles in certifying the system's stability. In
this paper, a novel probabilistic robust small-signal stability (PRS) framework
is developed for a power system based on Gaussian process (GP) learning. The
proposed PRS assessment provides a robust stability certificate for a state
subspace, such as that specified by the error bounds of the state estimation,
with a given probability. With such a PRS certificate, all inner points of the
concerned subspace will be stable with at least the corresponding confidence
level. To this end, the behavior of the critical eigenvalue of the reduced
Jacobian with state points in a state subspace is learned using GP. The
proposed PRS certificate along with the Subspace-based Search and
Confidence-based Search mechanisms constitute a holistic framework catering to
all scenarios. The proposed framework is a powerful approach to assess the
stability under uncertainty because it does not require input uncertainty
distributions and other state-specific input-to-output approximations. Further,
the critical eigenvalue behavior in a state subspace is analyzed using an upper
bound of the eigenvalue variations and their inferences are discussed in
detail. The results on three-machine nine-bus WSCC system show that the
proposed certificate can find the robust stable state subspace with a given
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01601</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01601</id><created>2019-10-03</created><authors><author><keyname>Khandel</keyname><forenames>Pooya</forenames></author><author><keyname>Rassafi</keyname><forenames>Amir Hossein</forenames></author><author><keyname>Pourahmadi</keyname><forenames>Vahid</forenames></author><author><keyname>Sharifian</keyname><forenames>Saeed</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author></authors><title>SensorDrop: A Reinforcement Learning Framework for Communication
  Overhead Reduction on the Edge</title><categories>cs.NI cs.LG eess.SP</categories><comments>8 pages, 9 figures, Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In IoT solutions, it is usually desirable to collect data from a large number
of distributed IoT sensors at a central node in the cloud for further
processing. One of the main design challenges of such solutions is the high
communication overhead between the sensors and the central node (especially for
multimedia data). In this paper, we aim to reduce the communication overhead
and propose a method that is able to determine which sensors should send their
data to the central node and which to drop data. The idea is that some sensors
may have data which are correlated with others and some may have data that are
not essential for the operation to be performed at the central node. As such
decisions are application dependent and may change over time, they should be
learned during the operation of the system, for that we propose a method based
on Advantage Actor-Critic (A2C) reinforcement learning which gradually learns
which sensor's data is cost-effective to be sent to the central node. The
proposed approach has been evaluated on a multi-view multi-camera dataset, and
we observe a significant reduction in communication overhead with marginal
degradation in object classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01624</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01624</id><created>2019-10-03</created><updated>2020-01-30</updated><authors><author><keyname>Venzke</keyname><forenames>Andreas</forenames></author><author><keyname>Chatzivasileiadis</keyname><forenames>Spyros</forenames></author></authors><title>Verification of Neural Network Behaviour: Formal Guarantees for Power
  System Applications</title><categories>eess.SY cs.LG cs.SY eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents for the first time, to our knowledge, a framework for
verifying neural network behavior in power system applications. Up to this
moment, neural networks have been applied in power systems as a black-box; this
has presented a major barrier for their adoption in practice. Developing a
rigorous framework based on mixed integer linear programming, our methods can
determine the range of inputs that neural networks classify as safe or unsafe,
and are able to systematically identify adversarial examples. Such methods have
the potential to build the missing trust of power system operators on neural
networks, and unlock a series of new applications in power systems. This paper
presents the framework, methods to assess and improve neural network robustness
in power systems, and addresses concerns related to scalability and accuracy.
We demonstrate our methods on the IEEE 9-bus, 14-bus, and 162-bus systems,
treating both N-1 security and small-signal stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01629</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01629</id><created>2019-10-03</created><authors><author><keyname>Da Costa</keyname><forenames>Maxime Ferreira</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author></authors><title>On the Stable Resolution Limit of Total Variation Regularization for
  Spike Deconvolution</title><categories>cs.IT eess.SP math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stability of spike deconvolution, which aims at recovering point sources
from their convolution with a point spread function (PSF), is known to be
related to the separation between those sources. When the observations are
noisy, it is critical to ensure support stability, where the deconvolution does
not lead to spurious, or oppositely, missing estimates of the point sources. In
this paper, we study the resolution limit of stably recovering the support of
two closely located point sources using the Beurling-LASSO estimator, which is
a convex optimization approach based on total variation regularization. We
establish a sufficient separation criteria between the sources, depending only
on the PSF, above which the Beurling-LASSO estimator is guaranteed to return a
stable estimate of the point sources, with the same number of estimated
elements as of the ground truth. Our result highlights the impact of PSF on the
resolution limit in the noisy setting, which was not evident in previous
studies of the noiseless setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01634</identifier>
 <datestamp>2020-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01634</id><created>2019-10-03</created><updated>2020-01-29</updated><authors><author><keyname>Anirudh</keyname><forenames>Rushil</forenames></author><author><keyname>Kim</keyname><forenames>Hyojin</forenames></author><author><keyname>Thiagarajan</keyname><forenames>Jayaraman J.</forenames></author><author><keyname>Mohan</keyname><forenames>K. Aditya</forenames></author><author><keyname>Champley</keyname><forenames>Kyle M.</forenames></author></authors><title>Improving Limited Angle CT Reconstruction with a Robust GAN Prior</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>NeurIPS 2019 Workshop on Deep Inverse Problems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Limited angle CT reconstruction is an under-determined linear inverse problem
that requires appropriate regularization techniques to be solved. In this work
we study how pre-trained generative adversarial networks (GANs) can be used to
clean noisy, highly artifact laden reconstructions from conventional
techniques, by effectively projecting onto the inferred image manifold. In
particular, we use a robust version of the popularly used GAN prior for inverse
problems, based on a recent technique called corruption mimicking, that
significantly improves the reconstruction quality. The proposed approach
operates in the image space directly, as a result of which it does not need to
be trained or require access to the measurement model, is scanner agnostic, and
can work over a wide range of sensing scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01636</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01636</id><created>2019-10-03</created><authors><author><keyname>Chiaroni</keyname><forenames>Florent</forenames></author><author><keyname>Rahal</keyname><forenames>Mohamed-Cherif</forenames></author><author><keyname>Hueber</keyname><forenames>Nicolas</forenames></author><author><keyname>Dufaux</keyname><forenames>Frederic</forenames></author></authors><title>Self-supervised learning for autonomous vehicles perception: A
  conciliation between analytical and learning methods</title><categories>cs.CV cs.LG cs.RO eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article mainly aims at motivating more investigations on self-supervised
learning (SSL) perception techniques and their applications in autonomous
driving. Such approaches are of broad interest as they can improve analytical
methods performances, for example to perceive farther and more accurately
spatially or temporally. In the meantime, they can also reduce the need of
hand-labeled training data for learning methods, while offering the possibility
to update the learning models into an online process. This can help an
autonomous system to deal with unexpected changing conditions in the
ego-vehicle environment. In all, this article firstly highlights the analytical
and learning tools which may be interesting for improving or developping SSL
techniques. Then, it presents the insights and correlations between existing
autonomous driving perception SSL techniques, and some of their remaining
limitations opening up some future research perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01684</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01684</id><created>2019-10-03</created><authors><author><keyname>Jin</keyname><forenames>Kyong Hwan</forenames></author><author><keyname>Gupta</keyname><forenames>Harshit</forenames></author><author><keyname>Yerly</keyname><forenames>Jerome</forenames></author><author><keyname>Stuber</keyname><forenames>Matthias</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Time-Dependent Deep Image Prior for Dynamic MRI</title><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel unsupervised deep-learning-based algorithm to solve the
inverse problem found in dynamic magnetic resonance imaging (MRI). Our method
needs neither prior training nor additional data; in particular, it does not
require either electrocardiogram or spokes-reordering in the context of cardiac
images. It generalizes to sequences of images the recently introduced
deep-image-prior approach. The essence of the proposed algorithm is to proceed
in two steps to fit k-space synthetic measurements to sparsely acquired dynamic
MRI data. In the first step, we deploy a convolutional neural network (CNN)
driven by a sequence of low-dimensional latent variables to generate a dynamic
series of MRI images. In the second step, we submit the generated images to a
nonuniform fast Fourier transform that represents the forward model of the MRI
system. By manipulating the weights of the CNN, we fit our synthetic
measurements to the acquired MRI data. The corresponding images from the CNN
then provide the output of our system; their evolution through time is driven
by controlling the sequence of latent variables whose interpolation gives
access to the sub-frame---or even continuous---temporal control of
reconstructed dynamic images. We perform experiments on simulated and real
cardiac images of a fetus acquired through 5-spoke-based golden-angle
measurements. Our results show improvement over the current state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01709</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01709</id><created>2019-10-03</created><authors><author><keyname>Habib</keyname><forenames>Raza</forenames></author><author><keyname>Mariooryad</keyname><forenames>Soroosh</forenames></author><author><keyname>Shannon</keyname><forenames>Matt</forenames></author><author><keyname>Battenberg</keyname><forenames>Eric</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author><author><keyname>Stanton</keyname><forenames>Daisy</forenames></author><author><keyname>Kao</keyname><forenames>David</forenames></author><author><keyname>Bagby</keyname><forenames>Tom</forenames></author></authors><title>Semi-Supervised Generative Modeling for Controllable Speech Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel generative model that combines state-of-the-art neural
text-to-speech (TTS) with semi-supervised probabilistic latent variable models.
By providing partial supervision to some of the latent variables, we are able
to force them to take on consistent and interpretable purposes, which
previously hasn't been possible with purely unsupervised TTS models. We
demonstrate that our model is able to reliably discover and control important
but rarely labelled attributes of speech, such as affect and speaking rate,
with as little as 1% (30 minutes) supervision. Even at such low supervision
levels we do not observe a degradation of synthesis quality compared to a
state-of-the-art baseline. Audio samples are available on the web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01711</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01711</id><created>2019-10-03</created><authors><author><keyname>Takeda</keyname><forenames>Kazuki</forenames></author><author><keyname>Xu</keyname><forenames>Huilin</forenames></author><author><keyname>Kim</keyname><forenames>Taehyoung</forenames></author><author><keyname>Schober</keyname><forenames>Karol</forenames></author><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author></authors><title>Understanding the Heart of the 5G Air Interface: An Overview of Physical
  Downlink Control Channel for 5G New Radio (NR)</title><categories>cs.NI eess.SP</categories><comments>8 pages, 5 figures, 1 table, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New Radio (NR) is a new radio air interface developed by the 3rd Generation
Partnership Project (3GPP) for the fifth generation (5G) mobile communications
system. With great flexibility, scalability, and efficiency, 5G is expected to
address a wide range of use-cases including enhanced mobile broadband (eMBB),
ultra-reliable low-latency communications (URLLC), and massive machine type
communications (mMTC). The physical downlink control channel (PDCCH) in NR
carries Downlink Control Information (DCI). Understanding how PDCCH operates is
key to developing a good understanding of how information is communicated over
NR. This paper provides an overview of the 5G NR PDCCH by describing its
physical layer structure, monitoring mechanisms, beamforming operation, and the
carried information. We also share various design rationales that influence NR
standardization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01716</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01716</id><created>2019-10-03</created><updated>2019-12-12</updated><authors><author><keyname>Mode</keyname><forenames>Gautam Raj</forenames></author><author><keyname>Calyam</keyname><forenames>Prasad</forenames></author><author><keyname>Hoque</keyname><forenames>Khaza Anuarul</forenames></author></authors><title>False Data Injection Attacks in Internet of Things and Deep Learning
  enabled Predictive Analytics</title><categories>cs.LG cs.PF eess.SP stat.ML</categories><comments>extended version of the manuscript entitled &quot;Impact of False Data
  Injection Attacks on Deep Learning enabled Predictive Analytics&quot; accepted for
  publication in the IEEE NOMS 2020 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Industry 4.0 is the latest industrial revolution primarily merging automation
with advanced manufacturing to reduce direct human effort and resources.
Predictive maintenance (PdM) is an industry 4.0 solution, which facilitates
predicting faults in a component or a system powered by state-of-the-art
machine learning (ML) algorithms and the Internet-of-Things (IoT) sensors.
However, IoT sensors and deep learning (DL) algorithms, both are known for
their vulnerabilities to cyber-attacks. In the context of PdM systems, such
attacks can have catastrophic consequences as they are hard to detect due to
the nature of the attack. To date, the majority of the published literature
focuses on the accuracy of DL enabled PdM systems and often ignores the effect
of such attacks. In this paper, we demonstrate the effect of IoT sensor attacks
on a PdM system. At first, we use three state-of-the-art DL algorithms,
specifically, Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and
Convolutional Neural Network (CNN) for predicting the Remaining Useful Life
(RUL) of a turbofan engine using NASA's C-MAPSS dataset. The obtained results
show that the GRU-based PdM model outperforms some of the recent literature on
RUL prediction using the C-MAPSS dataset. Afterward, we model two different
types of false data injection attacks (FDIA) on turbofan engine sensor data and
evaluate their impact on CNN, LSTM, and GRU-based PdM systems. The obtained
results demonstrate that FDI attacks on even a few IoT sensors can strongly
defect the RUL prediction. However, the GRU-based PdM model performs better in
terms of accuracy and resiliency. Lastly, we perform a study on the GRU-based
PdM model using four different GRU networks with different sequence lengths.
Our experiments reveal an interesting relationship between the accuracy,
resiliency and sequence length for the GRU-based PdM models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01719</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01719</id><created>2019-10-03</created><authors><author><keyname>Rasheed</keyname><forenames>Adil</forenames></author><author><keyname>San</keyname><forenames>Omer</forenames></author><author><keyname>Kvamsdal</keyname><forenames>Trond</forenames></author></authors><title>Digital Twin: Values, Challenges and Enablers</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A digital twin can be defined as an adaptive model of a complex physical
system. Recent advances in computational pipelines, multiphysics solvers,
artificial intelligence, big data cybernetics, data processing and management
tools bring the promise of digital twins and their impact on society closer to
reality. Digital twinning is now an important and emerging trend in many
applications. Also referred to as a computational megamodel, device shadow,
mirrored system, avatar or a synchronized virtual prototype, there can be no
doubt that a digital twin plays a transformative role not only in how we design
and operate cyber-physical intelligent systems, but also in how we advance the
modularity of multi-disciplinary systems to tackle fundamental barriers not
addressed by the current, evolutionary modeling practices. In this work, we
review the recent status of methodologies and techniques related to the
construction of digital twins. Our aim is to provide a detailed coverage of the
current challenges and enabling technologies along with recommendations and
reflections for various stakeholders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01726</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01726</id><created>2019-10-03</created><authors><author><keyname>Chen</keyname><forenames>Jianhong</forenames></author><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Hao</keyname><forenames>Wenrui</forenames></author><author><keyname>Xu</keyname><forenames>Jinchao</forenames></author></authors><title>A machine learning method correlating pulse pressure wave data with
  pregnancy</title><categories>q-bio.QM cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pulse feeling, representing the tactile arterial palpation of the heartbeat,
has been widely used in traditional Chinese medicine (TCM) to diagnose various
diseases. The quantitative relationship between the pulse wave and health
conditions however has not been investigated in modern medicine. In this paper,
we explored the correlation between pulse pressure wave (PPW), rather than the
pulse key features in TCM, and pregnancy by using deep learning technology.
This computational approach shows that the accuracy of pregnancy detection by
the PPW is 84% with an AUC of 91%. Our study is a proof of concept of pulse
diagnosis and will also motivate further sophisticated investigations on pulse
waves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01736</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01736</id><created>2019-09-03</created><authors><author><keyname>Jiang</keyname><forenames>Bo</forenames></author><author><keyname>Wang</keyname><forenames>Leiling</forenames></author><author><keyname>Tang</keyname><forenames>Jin</forenames></author><author><keyname>Luo</keyname><forenames>Bin</forenames></author></authors><title>Context-Aware Graph Attention Networks</title><categories>cs.LG cs.SI eess.IV eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph Neural Networks (GNNs) have been widely studied for graph data
representation and learning. However, existing GNNs generally conduct
context-aware learning on node feature representation only which usually
ignores the learning of edge (weight) representation. In this paper, we propose
a novel unified GNN model, named Context-aware Adaptive Graph Attention Network
(CaGAT). CaGAT aims to learn a context-aware attention representation for each
graph edge by further exploiting the context relationships among different
edges. In particular, CaGAT conducts context-aware learning on both node
feature representation and edge (weight) representation simultaneously and
cooperatively in a unified manner which can boost their respective performance
in network training. We apply CaGAT on semi-supervised learning tasks.
Promising experimental results on several benchmark datasets demonstrate the
effectiveness and benefits of CaGAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01764</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01764</id><created>2019-10-03</created><updated>2019-11-19</updated><authors><author><keyname>Ambrus</keyname><forenames>Rares</forenames></author><author><keyname>Guizilini</keyname><forenames>Vitor</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Pillai</keyname><forenames>Sudeep</forenames></author><author><keyname>Gaidon</keyname><forenames>Adrien</forenames></author></authors><title>Two Stream Networks for Self-Supervised Ego-Motion Estimation</title><categories>cs.CV eess.IV</categories><comments>Conference on Robot Learning (CoRL 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning depth and camera ego-motion from raw unlabeled RGB video streams is
seeing exciting progress through self-supervision from strong geometric cues.
To leverage not only appearance but also scene geometry, we propose a novel
self-supervised two-stream network using RGB and inferred depth information for
accurate visual odometry. In addition, we introduce a sparsity-inducing data
augmentation policy for ego-motion learning that effectively regularizes the
pose network to enable stronger generalization performance. As a result, we
show that our proposed two-stream pose network achieves state-of-the-art
results among learning-based methods on the KITTI odometry benchmark, and is
especially suited for self-supervision at scale. Our experiments on a
large-scale urban driving dataset of 1 million frames indicate that the
performance of our proposed architecture does indeed scale progressively with
more data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01785</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01785</id><created>2019-10-03</created><authors><author><keyname>Han</keyname><forenames>Kyoungseok</forenames></author><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author><author><keyname>Girard</keyname><forenames>Anouck</forenames></author><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Filev</keyname><forenames>Dimitar</forenames></author><author><keyname>Dai</keyname><forenames>Edward</forenames></author></authors><title>Co-optimization of Speed and Gearshift Control for Battery Electric
  Vehicles Using Preview Information</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the co-optimization of speed and gearshift control for
battery electric vehicles using short-range traffic information. To achieve
greater electric motor efficiency, a multi-speed transmission is employed,
whose control involves discrete-valued gearshift signals. To overcome the
computational difficulties in solving the integrated speed-and-gearshift
optimal control problem that involves both continuous and discrete-valued
optimization variables, we propose a hierarchical procedure to decompose the
integrated hybrid problem into purely continuous and discrete sub-problems,
each of which can be efficiently solved. We show, by simulations in various
driving scenarios, that the co-optimization of speed and gearshift control
using our proposed hierarchical procedure can achieve greater energy efficiency
than other typical approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01791</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01791</id><created>2019-10-03</created><updated>2019-10-30</updated><authors><author><keyname>Lotfollahi</keyname><forenames>Mohammad</forenames></author><author><keyname>Naghipourfar</keyname><forenames>Mohsen</forenames></author><author><keyname>Theis</keyname><forenames>Fabian J.</forenames></author><author><keyname>Wolf</keyname><forenames>F. Alexander</forenames></author></authors><title>Conditional out-of-sample generation for unpaired data using trVAE</title><categories>cs.LG eess.IV q-bio.CB q-bio.GN stat.ML</categories><comments>Added reference to Johansson et al. (2016) and removed sentences from
  Lopez et al. (2018) in the background section (see acknowledgements)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While generative models have shown great success in generating
high-dimensional samples conditional on low-dimensional descriptors (learning
e.g. stroke thickness in MNIST, hair color in CelebA, or speaker identity in
Wavenet), their generation out-of-sample poses fundamental problems. The
conditional variational autoencoder (CVAE) as a simple conditional generative
model does not explicitly relate conditions during training and, hence, has no
incentive of learning a compact joint distribution across conditions. We
overcome this limitation by matching their distributions using maximum mean
discrepancy (MMD) in the decoder layer that follows the bottleneck. This
introduces a strong regularization both for reconstructing samples within the
same condition and for transforming samples across conditions, resulting in
much improved generalization. We refer to the architecture as
\emph{transformer} VAE (trVAE). Benchmarking trVAE on high-dimensional image
and tabular data, we demonstrate higher robustness and higher accuracy than
existing approaches. In particular, we show qualitatively improved predictions
for cellular perturbation response to treatment and disease based on
high-dimensional single-cell gene expression data, by tackling previously
problematic minority classes and multiple conditions. For generic tasks, we
improve Pearson correlations of high-dimensional estimated means and variances
with their ground truths from 0.89 to 0.97 and 0.75 to 0.87, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01794</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01794</id><created>2019-10-04</created><authors><author><keyname>Venzke</keyname><forenames>Andreas</forenames></author><author><keyname>Molzahn</keyname><forenames>Daniel K.</forenames></author><author><keyname>Chatzivasileiadis</keyname><forenames>Spyros</forenames></author></authors><title>Efficient Creation of Datasets for Data-Driven Power System Applications</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in data-driven methods have sparked renewed interest for
applications in power systems. Creating datasets for successful application of
these methods has proven to be very challenging, especially when considering
power system security. This paper proposes a computationally efficient method
to create datasets of secure and insecure operating points. We propose an
infeasibility certificate based on separating hyperplanes that can a-priori
characterize large parts of the input space as insecure, thus significantly
reducing both computation time and problem size. Our method can handle an order
of magnitude more control variables and creates balanced datasets of secure and
insecure operating points, which is essential for data-driven applications.
While we focus on N-1 security and uncertainty, our method can extend to
dynamic security. For PGLib-OPF networks up to 500 buses and up to 125 control
variables, we demonstrate drastic reductions in unclassified input space
volumes and computation time, create balanced datasets, and evaluate an
illustrative data-driven application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01796</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01796</id><created>2019-10-04</created><authors><author><keyname>Le</keyname><forenames>David</forenames></author><author><keyname>Alam</keyname><forenames>Minhaj</forenames></author><author><keyname>Yao</keyname><forenames>Cham</forenames></author><author><keyname>Lim</keyname><forenames>Jennifer I.</forenames></author><author><keyname>Chan</keyname><forenames>R. V. P.</forenames></author><author><keyname>Toslak</keyname><forenames>Devrim</forenames></author><author><keyname>Yao</keyname><forenames>Xincheng</forenames></author></authors><title>Transfer Learning for Automated OCTA Detection of Diabetic Retinopathy</title><categories>q-bio.QM eess.IV</categories><comments>20 pages, 4 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To test the feasibility of using deep learning for optical coherence
tomography angiography (OCTA) detection of diabetic retinopathy (DR). Methods:
A deep learning convolutional neural network (CNN) architecture VGG16 was
employed for this study. A transfer learning process was implemented to
re-train the CNN for robust OCTA classification. In order to demonstrate the
feasibility of using this method for artificial intelligence (AI) screening of
DR in clinical environments, the re-trained CNN was incorporated into a custom
developed GUI platform which can be readily operated by ophthalmic personnel.
Results: With last nine layers re-trained, CNN architecture achieved the best
performance for automated OCTA classification. The overall accuracy of the
re-trained classifier for differentiating healthy, NoDR, and NPDR was 87.27%,
with 83.76% sensitivity and 90.82% specificity. The AUC metrics for binary
classification of healthy, NoDR and DR were 0.97, 0.98 and 0.97, respectively.
The GUI platform enabled easy validation of the method for AI screening of DR
in a clinical environment. Conclusion: With a transfer leaning process to adopt
the early layers for simple feature analysis and to re-train the upper layers
for fine feature analysis, the CNN architecture VGG16 can be used for robust
OCTA classification of healthy, NoDR, and NPDR eyes. Translational Relevance:
OCTA can capture microvascular changes in early DR. A transfer learning process
enables robust implementation of convolutional neural network (CNN) for
automated OCTA classification of DR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01808</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01808</id><created>2019-10-04</created><authors><author><keyname>Sy</keyname><forenames>Luke</forenames></author><author><keyname>Lovell</keyname><forenames>Nigel H.</forenames></author><author><keyname>Redmond</keyname><forenames>Stephen J.</forenames></author></authors><title>Estimating Lower Limb Kinematics using a Lie Group Constrained EKF and a
  Reduced Wearable IMU Count</title><categories>cs.RO cs.SY eess.SY</categories><comments>8 pages, submitted to RA-L with ICRA option 2020. arXiv admin note:
  substantial text overlap with arXiv:1910.00910</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algorithm that makes novel use of Lie group
representation of position and orientation alongside a constrained extended
Kalman filter (CEKF) for accurately estimating pelvis, thigh, and shank
kinematics during walking using only three wearable inertial sensors. The
algorithm iterates through the prediction update (kinematic equation),
measurement update (pelvis height, zero velocity update, flat-floor assumption,
and covariance limiter), and constraint update (formulation of hinged knee
joints and ball-and-socket hip joints). Evaluation of the algorithm on nine
healthy subjects who walked freely within a $4 \times 4$ m$^3$ room shows that
it can track motion relative to the mid-pelvis origin with mean position and
orientation root-mean-square error of $5.75 \pm 1.4$ cm and $19.8 \pm
5.2^\circ$, respectively. The sagittal knee and hip joint angle correlation
coefficients were $0.88 \pm 0.1$ and $0.77 \pm 0.1$. This paper demonstrates an
application of Lie group representation for inertial motion capture.
Furthermore, the algorithm can compute gait parameters in real-time and, hence,
can be used to inform gait assistive devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01836</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01836</id><created>2019-10-04</created><authors><author><keyname>Papasotiriou</keyname><forenames>Evangelos N.</forenames></author><author><keyname>Boulogeorgos</keyname><forenames>Alexandros-Apostolos A.</forenames></author><author><keyname>Alexiou</keyname><forenames>Angeliki</forenames></author></authors><title>Ergodic capacity evaluation of wireless THz fiber extenders</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages, 2 figures, conference paper, Presented in WWRF, WG High
  Frequencies (mmWAVE and THz) Radio Communications Technologies, September
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on delivering quantified results for the evaluation of the
aggregated impact of stochastic antenna misalignment, multipath fading and
hardware imperfections on the terahertz (THz) wireless fiber extenders. In this
line, we present the appropriate signal model that accommodates the different
technical and environmental parameters. In particular, it takes into
consideration the antenna gains, the central frequency, the transmission range,
the environmental conditions, i.e. temperature, humidity and pressure, the
spatial jitter between the transmitter and receiver antennas, which results to
antenna misalignment, the intensity of hardware imperfections, and the
stochastic behavior of the wireless channel. Based on this model, we assess the
joint impact of antenna misalignment and multipath fading, by providing Monte
Carlo simulation results for the channels ergodic capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01860</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01860</id><created>2019-10-04</created><authors><author><keyname>Meshram</keyname><forenames>Rahul</forenames></author><author><keyname>Kaza</keyname><forenames>Kesav</forenames></author></authors><title>Online repeated posted price auctions with a demand side platform</title><categories>cs.GT cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an online ad network problem in which an ad exchange auctions ad
slots and intermediaries called demand side platforms (DSPs) buy these ad slots
for their clients (advertisers). An intermediary represents multiple
advertisers. Different types of ad slots are auctioned by the ad exchange,
e.g., video ad, banner ad etc. We study repeated posted price auctions for
homogeneous and heterogeneous items when there is an intermediary. In a posted
price auction, the auctioneer sets a fixed reserve price. The buyer can accept
the price and win the ad slot or reject the price.
  We analyze the system from the auctioneer's perspective and show that the
optimal reserve price is dynamic for heterogeneous items. We also investigate
system from intermediary's perspective and devise algorithms for scheduling
advertisers. Often the advertisers have budget constraints and impression
constraints. We formulate a revenue optimization problem at the intermediary
and also consider the problem of scheduling advertisers with budget and
impression constraints. Finally, we present a numerical study for the single
seller and advertiser model which considers various valuation distributions
such as uniform, exponential and lognormal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01869</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01869</id><created>2019-10-04</created><authors><author><keyname>Cholvi</keyname><forenames>Vicent</forenames></author><author><keyname>Echag&#xfc;e</keyname><forenames>Juan</forenames></author><author><keyname>Anta</keyname><forenames>Antonio Fern&#xe1;ndez</forenames></author><author><keyname>Caro</keyname><forenames>Christopher Thraves</forenames></author></authors><title>System Stability Under Adversarial Injection of Dependent Tasks</title><categories>cs.NI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a computational model of a distributed system
formed by a set of servers in which jobs, that are continuously arriving, have
to be executed. Every job is formed by a set of dependent tasks (i.~e., each
task may have to wait for others to be completed before it can be started),
each of which has to be executed in one of the servers. The arrival of jobs and
their properties is assumed to be controlled by a bounded adversary, whose only
restriction is that it cannot overload any server. This model is a non-trivial
generalization of the Adversarial Queuing Theory model of Borodin et al., and,
like that model, focuses on the stability of the system: whether the number of
jobs pending to be completed is bounded at all times. We show multiple results
of stability and instability for this adversarial model under different
combinations of the scheduling policy used at the servers, the arrival rate,
and the dependence between tasks in the jobs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01877</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01877</id><created>2019-10-04</created><authors><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Oksuz</keyname><forenames>Ilkay</forenames></author><author><keyname>Byrne</keyname><forenames>Nicholas</forenames></author><author><keyname>Zimmer</keyname><forenames>Veronika A.</forenames></author><author><keyname>Schnabel</keyname><forenames>Julia A.</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author></authors><title>A Topological Loss Function for Deep-Learning based Image Segmentation
  using Persistent Homology</title><categories>cs.CV eess.IV</categories><comments>12 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a method for training neural networks to perform image or volume
segmentation in which prior knowledge about the topology of the segmented
object can be explicitly provided and then incorporated into the training
process. By using the differentiable properties of persistent homology, a
concept used in topological data analysis, we can specify the desired topology
of segmented objects in terms of their Betti numbers and then drive the
proposed segmentations to contain the specified topological features.
Importantly this process does not require any ground-truth labels, just prior
knowledge of the topology of the structure being segmented. We demonstrate our
approach in three experiments. Firstly we create a synthetic task in which
handwritten MNIST digits are de-noised, and show that using this kind of
topological prior knowledge in the training of the network significantly
improves the quality of the de-noised digits. Secondly we perform an experiment
in which the task is segmenting the myocardium of the left ventricle from
cardiac magnetic resonance images. We show that the incorporation of the prior
knowledge of the topology of this anatomy improves the resulting segmentations
in terms of both the topological accuracy and the Dice coefficient. Thirdly, we
extend the method to 3D volumes and demonstrate its performance on the task of
segmenting the placenta from ultrasound data, again showing that incorporating
topological priors improves performance on this challenging task. We find that
embedding explicit prior knowledge in neural network segmentation tasks is most
beneficial when the segmentation task is especially challenging and that it can
be used in either a semi-supervised or post-processing context to extract a
useful training gradient from images without pixelwise labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01885</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01885</id><created>2019-10-04</created><authors><author><keyname>Boulogeorgos</keyname><forenames>Alexandros-Apostolos A.</forenames></author><author><keyname>Papasotiriou</keyname><forenames>Evangelos N.</forenames></author><author><keyname>Alexiou</keyname><forenames>Angeliki</forenames></author></authors><title>Analytical Performance Evaluation of THz Wireless Fiber Extenders</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 6 figures, IEEE PIMRC, September 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the theoretical framework for the performance evaluation
of terahertz (THz) wireless fiber extender in the presence of misalignment and
multipath fading. In more detail, after providing the appropriate system model
that incorporates the different operation, design, and environmental
parameters, such as the operation frequency, transceivers antenna gains, the
level of misalignment as well as the stochastic behavior of the channel, we
extract novel closed-form expressions for the ergodic capacity. These
expressions are expected to be used as useful tools for the analysis and design
of such systems. Moreover, several insightful scenarios are simulated. Their
results highlight the importance of taking into account the impact of
misalignment fading when analyzing the performance of the THz wireless fiber
extender.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01891</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01891</id><created>2019-10-04</created><authors><author><keyname>Neumann</keyname><forenames>Fabian</forenames></author><author><keyname>Brown</keyname><forenames>Tom</forenames></author></authors><title>The Near-Optimal Feasible Space of a Renewable Power System Model</title><categories>physics.soc-ph cs.SY eess.SY</categories><comments>Submitted to the 21st Power Systems Computation Conference (PSCC
  2020); 8 pages, 8 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models for long-term investment planning of the power system typically return
a single optimal solution per set of cost assumptions. However, typically there
are many near-optimal alternatives that stand out due to other attractive
properties like social acceptance. Understanding features that persist across
many cost-efficient alternatives enhances policy advice and acknowledges
structural model uncertainties. We apply the modeling-to-generate-alternatives
(MGA) methodology to systematically explore the near-optimal feasible space of
a completely renewable European electricity system model. While accounting for
complex spatio-temporal patterns, we allow simultaneous capacity expansion of
generation, storage and transmission infrastructure subject to linearized
multi-period optimal power flow. Many similarly costly, but technologically
diverse solutions exist. Already a cost deviation of 0.5% offers a large range
of possible investments. However, either offshore or onshore wind energy along
with some hydrogen storage and transmission network reinforcement are essential
to keep costs within 10% of the optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01896</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01896</id><created>2019-10-04</created><authors><author><keyname>Gaudio</keyname><forenames>Lorenzo</forenames></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Colavolpe</keyname><forenames>Giulio</forenames></author></authors><title>On the Effectiveness of OTFS for Joint Radar and Communication</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a joint radar estimation and communication system using
orthogonal time frequency space (OTFS) modulation. The scenario is motivated by
vehicular applications where a vehicle equipped with a mono-static radar wishes
to communicate data to its target receiver, while estimating parameters of
interest related to this receiver. In a point-to-point communication setting
over multi-path time-frequency selective channels, we study the joint radar and
communication system from two perspectives, i.e., the radar estimation at the
transmitter as well as the symbol detection at the receiver. For the radar
estimation part, we derive an efficient approximated Maximum Likelihood
algorithm and the corresponding Cram\'er- Rao lower bound for range and
velocity estimation. Numerical examples demonstrate that multi-carrier digital
formats such as OTFS can achieve as accurate radar estimation as
state-of-the-art radar waveforms such as frequency-modulated continuous wave
(FMCW). For the data detection part, we focus on separate detection and
decoding and consider a soft-output detector that exploits efficiently the
channel sparsity in the Doppler-delay domain. We quantify the detector
performance in terms of its pragmatic capacity, i.e. the achievable rate of the
channel induced by the signal constellation and the detector soft output.
Simulations show that the proposed scheme outperforms concurrent
state-of-the-art solutions. Overall, our work shows that a suitable digitally
modulated waveform enables to efficiently operate joint radar and communication
by achieving full information rate of the modulation and near-optimal radar
estimation performance. Furthermore, OTFS appears to be particularly suited to
the scope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01902</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01902</id><created>2019-10-04</created><authors><author><keyname>Gulamhussene</keyname><forenames>Gino</forenames></author><author><keyname>Joeres</keyname><forenames>Fabian</forenames></author><author><keyname>Rak</keyname><forenames>Marko</forenames></author><author><keyname>Pech</keyname><forenames>Maciej</forenames></author><author><keyname>Hansen</keyname><forenames>Christian</forenames></author></authors><title>4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>14 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: We aim to develop a robust 4D MRI method for large FOVs enabling the
extraction of irregular respiratory motion that is readily usable with all MRI
machines and thus applicable to support a wide range of interventional
settings.
  Method: We propose a 4D MRI reconstruction method to capture an arbitrary
number of breathing states. It uses template updates in navigator slices and
search regions for fast and robust vessel cross-section tracking. It captures
FOVs of 255 mm x 320 mm x 228 mm at a spatial resolution of 1.82 mm x 1.82 mm x
4mm and temporal resolution of 200ms. To validate the method, a total of 38 4D
MRIs of 13 healthy subjects were reconstructed. A quantitative evaluation of
the reconstruction rate and speed of both the new and baseline method was
performed. Additionally, a study with ten radiologists was conducted to assess
the subjective reconstruction quality of both methods.
  Results: Our results indicate improved mean reconstruction rates compared to
the baseline method (79.4\% vs. 45.5\%) and improved mean reconstruction times
(24s vs. 73s) per subject. Interventional radiologists perceive the
reconstruction quality of our method as higher compared to the baseline (262.5
points vs. 217.5 points, p=0.02).
  Conclusions: Template updates are an effective and efficient way to increase
4D MRI reconstruction rates and to achieve better reconstruction quality.
Search regions reduce reconstruction time. These improvements increase the
applicability of 4D MRI as base for seamless support of interventional image
guidance in percutaneous interventions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01903</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01903</id><created>2019-10-04</created><authors><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author></authors><title>Robust Output Feedback Stabilization of Multivariable Invertible
  Nonlinear Systems: A Feedback Linearization-Based Method</title><categories>eess.SY cs.SY</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note studies the robust output feedback stabilization problem of a class
of multi-input multi-output invertible nonlinear systems, for which an &quot;ideal&quot;
state feedback based on feedback linearization can be designed under certain
mild assumptions. By systematically designing a set of extended low-power
high-gain observers, we show that this &quot;ideal&quot; linearizing feedback law can be
approximately estimated, which provides a robust output feedback stabilizer
such that the origin of the resulting closed-loop system is semiglobally
asymptotically stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01918</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01918</id><created>2019-10-03</created><authors><author><keyname>Jafarzadeh</keyname><forenames>Mohsen</forenames></author><author><keyname>Tadesse</keyname><forenames>Yonas</forenames></author></authors><title>Convolutional Neural Networks for Speech Controlled Prosthetic Hands</title><categories>eess.SY cs.HC cs.LG cs.RO cs.SD cs.SY eess.AS</categories><comments>2019 First International Conference on Transdisciplinary AI
  (TransAI), Laguna Hills, California, USA, 2019, pp. 35-42</comments><msc-class>68T40</msc-class><acm-class>I.2</acm-class><journal-ref>2019 First International Conference on Transdisciplinary AI
  (TransAI)</journal-ref><doi>10.1109/TransAI46475.2019.00014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech recognition is one of the key topics in artificial intelligence, as it
is one of the most common forms of communication in humans. Researchers have
developed many speech-controlled prosthetic hands in the past decades,
utilizing conventional speech recognition systems that use a combination of
neural network and hidden Markov model. Recent advancements in general-purpose
graphics processing units (GPGPUs) enable intelligent devices to run deep
neural networks in real-time. Thus, state-of-the-art speech recognition systems
have rapidly shifted from the paradigm of composite subsystems optimization to
the paradigm of end-to-end optimization. However, a low-power embedded GPGPU
cannot run these speech recognition systems in real-time. In this paper, we
show the development of deep convolutional neural networks (CNN) for speech
control of prosthetic hands that run in real-time on a NVIDIA Jetson TX2
developer kit. First, the device captures and converts speech into 2D features
(like spectrogram). The CNN receives the 2D features and classifies the hand
gestures. Finally, the hand gesture classes are sent to the prosthetic hand
motion control system. The whole system is written in Python with Keras, a deep
learning library that has a TensorFlow backend. Our experiments on the CNN
demonstrate the 91% accuracy and 2ms running time of hand gestures (text
output) from speech commands, which can be used to control the prosthetic hands
in real-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01919</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01919</id><created>2019-10-02</created><authors><author><keyname>Zhan</keyname><forenames>Huixin</forenames></author><author><keyname>Cao</keyname><forenames>Yongcan</forenames></author></authors><title>Relationship Explainable Multi-objective Optimization Via Vector Value
  Function Based Reinforcement Learning</title><categories>eess.SY cs.LG cs.SY math.OC</categories><comments>COLT19 submission. arXiv admin note: substantial text overlap with
  arXiv:1909.12268</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving multi-objective optimization problems is important in various
applications where users are interested in obtaining optimal policies subject
to multiple, yet often conflicting objectives. A typical approach to obtain
optimal policies is to first construct a loss function that is based on the
scalarization of individual objectives, and then find the optimal policy that
minimizes the loss. However, optimizing the scalarized (and weighted) loss does
not necessarily provide a guarantee of high performance on each possibly
conflicting objective. In this paper, we propose a vector value based
reinforcement learning approach that seeks to explicitly learn the
inter-objective relationship and optimize multiple objectives based on the
learned relationship. In particular, the proposed method is to first define
relationship matrix, a mathematical representation of the inter-objective
relationship, and then create one actor and multiple critics that can co-learn
the relationship matrix and action selection. The proposed approach can
quantify the inter-objective relationship via reinforcement learning when the
impact of one objective on another is unknown a prior. We also provide rigorous
convergence analysis of the proposed approach and present a quantitative
evaluation of the approach based on two testing scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01948</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01948</id><created>2019-10-04</created><authors><author><keyname>Shamasundar</keyname><forenames>Bharath</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author></authors><title>A DNN Architecture for the Detection of Generalized Spatial Modulation
  Signals</title><categories>cs.IT eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of signal detection in generalized
spatial modulation (GSM) and explore the utility of the deep neural networks
(DNN) for the detection task. We propose a DNN architecture which uses small
sub-DNNs to detect the active antennas and the constellation symbols
transmitted by the active antennas. Under the assumption of i.i.d. additive
white Gaussian noise (AWGN), the proposed DNN detector achieves a performance
very close to that of maximum likelihood detector. We also analyze the
performance of the proposed detector under two conditions of practical
interest: $i)$ correlated noise across receive antennas (resulting from mutual
coupling, matching networks) and $ii)$ noise distribution deviating from the
standard AWGN model. The proposed DNN-based detector learns the deviations from
the standard model and achieves superior performance compared to that of
conventional maximum likelihood detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01967</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01967</id><created>2019-10-04</created><authors><author><keyname>Vieira</keyname><forenames>V.</forenames></author><author><keyname>Coelho</keyname><forenames>R.</forenames></author><author><keyname>Assis</keyname><forenames>F.</forenames></author></authors><title>Objective Human Affective Vocal Expression Detection and Automatic
  Classification with Stochastic Models and Learning Systems</title><categories>eess.AS</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper presents a widespread analysis of affective vocal expression
classification systems. In this study, state-of-the-art acoustic features are
compared to two novel affective vocal prints for the detection of emotional
states: the Hilbert-Huang-Hurst Coefficients (HHHC) and the vector of index of
non-stationarity (INS). HHHC is here proposed as a nonlinear vocal source
feature vector that represents the affective states according to their effects
on the speech production mechanism. Emotional states are highlighted by the
empirical mode decomposition (EMD) based method, which exploits the
non-stationarity of the affective acoustic variations. Hurst coefficients
(closely related to the excitation source) are then estimated from the
decomposition process to compose the feature vector. Additionally, the INS
vector is introduced as dynamic information to the HHHC feature. The proposed
features are evaluated in speech emotion classification experiments with three
databases in German and English languages. Three state-of-the-art acoustic
features are adopted as baseline. The $\alpha$-integrated Gaussian model
($\alpha$-GMM) is also introduced for the emotion representation and
classification. Its performance is compared to competing stochastic and machine
learning classifiers. Results demonstrate that HHHC leads to significant
classification improvement when compared to the baseline acoustic features.
Moreover, results also show that $\alpha$-GMM outperforms the competing
classification methods. Finally, HHHC and INS are also evaluated as
complementary features for the GeMAPS and eGeMAPS feature sets
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01968</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01968</id><created>2019-10-04</created><authors><author><keyname>Chiaroni</keyname><forenames>Florent</forenames></author><author><keyname>Khodabandelou</keyname><forenames>Ghazaleh</forenames></author><author><keyname>Rahal</keyname><forenames>Mohamed-Cherif</forenames></author><author><keyname>Hueber</keyname><forenames>Nicolas</forenames></author><author><keyname>Dufaux</keyname><forenames>Frederic</forenames></author></authors><title>Generating Relevant Counter-Examples from a Positive Unlabeled Dataset
  for Image Classification</title><categories>cs.CV cs.LG eess.IV</categories><comments>Submitted to Pattern Recognition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With surge of available but unlabeled data, Positive Unlabeled (PU) learning
is becoming a thriving challenge. This work deals with this demanding task for
which recent GAN-based PU approaches have demonstrated promising results.
Generative adversarial Networks (GANs) are not hampered by deterministic bias
or need for specific dimensionality. However, existing GAN-based PU approaches
also present some drawbacks such as sensitive dependence to prior knowledge, a
cumbersome architecture or first-stage overfitting. To settle these issues, we
propose to incorporate a biased PU risk within the standard GAN discriminator
loss function. In this manner, the discriminator is constrained to request the
generator to converge towards the unlabeled samples distribution while
diverging from the positive samples distribution. This enables the proposed
model, referred to as D-GAN, to exclusively learn the counter-examples
distribution without prior knowledge. Experiments demonstrate that our approach
outperforms state-of-the-art PU methods without prior by overcoming their
issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01983</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01983</id><created>2019-08-14</created><authors><author><keyname>Sanjarinia</keyname><forenames>Mohamad Saleh</forenames></author><author><keyname>Saadatmand</keyname><forenames>Sepehr</forenames></author><author><keyname>Shamsi</keyname><forenames>Pourya</forenames></author><author><keyname>Ferdowsi</keyname><forenames>Mehdi</forenames></author></authors><title>Analysis of Skin Effect in High Frequency Isolation Transformers</title><categories>physics.ins-det eess.SP physics.acc-ph</categories><comments>6 pages, 11 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a high frequency transformer with different conductors and
winding arrangements, at presence of eddy currents and skin effect, is studied.
By using different winding structures, and conductor types, such as circular,
square shaped, and foil wires, the skin effect in the windings is studied and
current density within the conductors at a high frequency of 20 MHz and a lower
frequency of 20 kHz are investigated using finite element method (FEM)
simulation. Moreover, magnetic field distribution in the transformers at 20 MHz
is obtained and displayed. Also, magnetizing inductance, leakage inductance and
AC winding resistance for all of the transformer types are found and compared,
and frequency response for the transformers are obtained and shown. Lastly,
based on the results, the skin effect increases the AC winding resistance and
decreases the leakage inductance as the frequency increases. Furthermore,
different winding arrangements, conductors, and transformer types show a wide
range of parasitic and loss behavior, which enable the designers to compromise
between various parameters in different applications, especially new fast
switches such as SiC and GaN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01990</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01990</id><created>2019-10-04</created><authors><author><keyname>Kopev</keyname><forenames>Daniel</forenames></author><author><keyname>Ali</keyname><forenames>Ahmed</forenames></author><author><keyname>Koychev</keyname><forenames>Ivan</forenames></author><author><keyname>Nakov</keyname><forenames>Preslav</forenames></author></authors><title>Detecting Deception in Political Debates Using Acoustic and Textual
  Features</title><categories>cs.CL cs.AI eess.AS</categories><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><journal-ref>ASRU-2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present work on deception detection, where, given a spoken claim, we aim
to predict its factuality. While previous work in the speech community has
relied on recordings from staged setups where people were asked to tell the
truth or to lie and their statements were recorded, here we use real-world
political debates. Thanks to the efforts of fact-checking organizations, it is
possible to obtain annotations for statements in the context of a political
discourse as true, half-true, or false. Starting with such data from the
CLEF-2018 CheckThat! Lab, which was limited to text, we performed alignment to
the corresponding videos, thus producing a multimodal dataset. We further
developed a multimodal deep-learning architecture for the task of deception
detection, which yielded sizable improvements over the state of the art for the
CLEF-2018 Lab task 2. Our experiments show that the use of the acoustic signal
consistently helped to improve the performance compared to using textual and
metadata features only, based on several different evaluation measures. We
release the new dataset to the research community, hoping to help advance the
overall field of multimodal deception detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01992</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01992</id><created>2019-10-04</created><updated>2019-10-09</updated><authors><author><keyname>Huang</keyname><forenames>Zhen</forenames></author><author><keyname>Ng</keyname><forenames>Tim</forenames></author><author><keyname>Liu</keyname><forenames>Leo</forenames></author><author><keyname>Mason</keyname><forenames>Henry</forenames></author><author><keyname>Zhuang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Liu</keyname><forenames>Daben</forenames></author></authors><title>SNDCNN: Self-normalizing deep CNNs with scaled exponential linear units
  for speech recognition</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very deep CNNs achieve state-of-the-art results in both computer vision and
speech recognition, but are difficult to train. The most popular way to train
very deep CNNs is to use shortcut connections (SC) together with batch
normalization (BN). Inspired by Self-Normalizing Neural Networks, we propose
the self-normalizing deep CNN (SNDCNN) based acoustic model topology, by
removing the SC/BN and replacing the typical RELU activations with scaled
exponential linear unit (SELU) in ResNet-50. SELU activations make the network
self-normalizing and remove the need for both shortcut connections and batch
normalization. Compared to ResNet-50, we can achieve the same or lower word
error rate (WER) while at the same time improving both training and inference
speed by 60%-80%. We also explore other model inference optimizations to
further reduce latency for production use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01997</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.01997</id><created>2019-10-04</created><updated>2020-02-14</updated><authors><author><keyname>Trabes</keyname><forenames>Emanuel</forenames></author><author><keyname>Gazzano</keyname><forenames>Julio Daniel Dondo</forenames></author><author><keyname>P&#xe1;ez</keyname><forenames>Carlos Federico Sosa</forenames></author></authors><title>Dense monocular Simultaneous Localization and Mapping by direct surfel
  optimization</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a novel approach for monocular dense Simultaneous
Localization and Mapping. The surface to be estimated is represented as a
piecewise planar surface, defined as a group of surfels each having as
parameters its position and normal. These parameters are then directly
estimated from the raw camera pixels measurements, by a Gauss-Newton iterative
process. As far as the authors know, this is the first time this approach is
used for monocular depth estimation. The representation of the surface as a
group of surfels has several advantages. It allows the recovery of robust and
accurate pixel depths, without the need to use a computationally demanding
depth regularization schema. This has the further advantage of avoiding the use
of a physically unlikely surface smoothness prior. New surfels can be correctly
initialized from the information present in nearby surfels, avoiding also the
need to use an expensive initialization routine commonly needed in Gauss-Newton
methods. The method was written in the GLSL shading language, allowing the
usage of GPGPU thus achieving real-time. The method was tested against several
datasets, showing both its depth and normal estimation correctness, and its
scene reconstruction quality. The results presented here showcase the
usefulness of the more physically grounded piecewise planar scene depth prior,
instead of the more commonly pixel depth independence and smoothness prior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02026</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02026</id><created>2019-10-04</created><authors><author><keyname>Casau</keyname><forenames>Pedro</forenames></author><author><keyname>Mayhew</keyname><forenames>Christopher G.</forenames></author><author><keyname>Sanfelice</keyname><forenames>Ricardo G.</forenames></author><author><keyname>Silvestre</keyname><forenames>Carlos</forenames></author></authors><title>Robust Global Exponential Stabilization on the $n$-Dimensional Sphere
  with Applications to Trajectory Tracking for Quadrotors</title><categories>eess.SY cs.SY</categories><journal-ref>Automatica, Volume 110 (2019)</journal-ref><doi>10.1016/j.automatica.2019.108534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we design a hybrid controller that globally exponentially
stabilizes a system evolving on the n-dimensional sphere, denoted by Sn. This
hybrid controller is induced by a synergistic collection of potential functions
on Sn. We propose a particular construction of this class of functions that
generates flows along geodesics of the sphere, providing convergence to the
desired reference with minimal path length. We show that the proposed strategy
is suitable to the exponential stabilization of a quadrotor vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02040</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02040</id><created>2019-09-26</created><authors><author><keyname>Lahcen</keyname><forenames>El Iysaouy</forenames></author><author><keyname>Bielskis</keyname><forenames>Edvardas</forenames></author><author><keyname>Mhammed</keyname><forenames>Lahbabi</forenames></author><author><keyname>Baskys</keyname><forenames>Algirdas</forenames></author><author><keyname>Abdelmajid</keyname><forenames>Oumnad</forenames></author></authors><title>Investigation of microinverter based on the twoswitch DC-DC flyback
  converter topology</title><categories>eess.SP</categories><comments>4 pages, Conference: The International Conference on Renewable Energy
  and Energy Efficiency FST Fez, November 8 &amp; 9, 2017</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The investigation results of the grid connected photovoltaic single stage
microinverter with a new topology are presented. The microinverter is based on
the couple of two-switch DC-DC flyback converters and has simple design. The
investigation results show that the analyzed microinverter is characterized by
the high efficiency and low total harmonic distortion of output voltage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02041</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02041</id><created>2019-09-26</created><authors><author><keyname>Iysaouy</keyname><forenames>Lahcen El</forenames></author><author><keyname>Lahbabi</keyname><forenames>Mhammed</forenames></author><author><keyname>Oumnad</keyname><forenames>Abdelmajid</forenames></author></authors><title>A Single Phase DC DC Microinverter with High efficiency and Harmonics
  Reduction using Passive Filters</title><categories>eess.SP</categories><comments>4 pages, Conference: EVF 2018 : International Symposium &quot; Energy &amp;
  City of the Future &quot;</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The photovoltaic microinverter based two-switch DC-DC flyback converters has
been investigated. The microinverter is characterized by the high performance
and simple design. The effect of CL and LCL low pass filter on Total Harmonics
Distortion (THD) of microinverter have been investigated. The results were
found for the cases when CL and LCL output low pass filters were applied. The
obtained results show that the efficiency and THD of the investigated
photovoltaic microinverter based on the LCL output low pass filter is lower as
compared to the case when the LC output low pass filter is utilized. The THD of
microinverter with both output low pass filters is less than 5% respect the
requirement of IEEE 1574-2014. Further, the LCL output low pass filter is used
the THD decreases by 1% compared to the CL low pass filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02046</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02046</id><created>2019-10-04</created><authors><author><keyname>P&#xe9;rez-Arancibia</keyname><forenames>Carlos</forenames></author><author><keyname>Turc</keyname><forenames>Catalin</forenames></author><author><keyname>Faria</keyname><forenames>Luiz</forenames></author><author><keyname>Sideris</keyname><forenames>Constantine</forenames></author></authors><title>Planewave density interpolation methods for the EFIE on simple and
  composite surfaces</title><categories>physics.comp-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an extension of the recently introduced planewave density
interpolation (PWDI) method to the electric field integral equation (EFIE)
formulation of problems of scattering and radiation by perfect electric
conducting (PEC) objects. Relying on Kirchhoff integral formula and local
interpolation of surface current densities that regularize the kernel
singularities, the PWDI method enables off- and on-surface EFIE operators to be
re-expressed in terms of integrands that are globally bounded (or even more
regular) over the whole domain of integration, regardless of the magnitude of
the distance between target and source points. Surface integrals resulting from
the application of the method-of-moments (MoM) using Rao-Wilton-Glisson (RWG)
basis functions, can then be directly and easily evaluated by means of
elementary quadrature rules irrespective of the singularity location. The
proposed technique can be applied to simple and composite surfaces comprising
two or more simply-connected overlapping components. The use of composite
surfaces can significantly simplify the geometric treatment of complex
structures, as the PWDI method enables the use of separate non-conformal meshes
for the discretization of each of the surface components that make up the
composite surface. A variety of examples, including multi-scale and intricate
structures, demonstrate the effectiveness of the proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02049</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02049</id><created>2019-10-03</created><authors><author><keyname>Guo</keyname><forenames>Rui</forenames></author><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author><author><keyname>Magnusson</keyname><forenames>Thor</forenames></author></authors><title>Midi Miner -- A Python library for tonal tension and track
  classification</title><categories>cs.SD cs.IR cs.LG eess.AS</categories><comments>2 pages. ISMIR - Late Breaking Demo, Delft, The Netherlands. November
  2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a Python library, called Midi Miner, that can calculate tonal
tension and classify different tracks. MIDI (Music Instrument Digital
Interface) is a hardware and software standard for communicating musical events
between digital music devices. It is often used for tasks such as music
representation, communication between devices, and even music generation [5].
Tension is an essential element of the music listening experience, which can
come from a number of musical features including timbre, loudness and harmony
[3]. Midi Miner provides a Python implementation for the tonal tension model
based on the spiral array [1] as presented by Herremans and Chew [4]. Midi
Miner also performs key estimation and includes a track classifier that can
disentangle melody, bass, and harmony tracks. Even though tracks are often
separated in MIDI files, the musical function of each track is not always
clear. The track classifier keeps the identified tracks and discards messy
tracks, which can enable further analysis and training tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02050</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02050</id><created>2019-10-02</created><authors><author><keyname>Cho</keyname><forenames>Junho</forenames></author><author><keyname>Chandrasekhar</keyname><forenames>Sethumadhavan</forenames></author><author><keyname>Sula</keyname><forenames>Erixhen</forenames></author><author><keyname>Olsson</keyname><forenames>Samuel</forenames></author><author><keyname>Burrows</keyname><forenames>Ellsworth</forenames></author><author><keyname>Raybon</keyname><forenames>Greg</forenames></author><author><keyname>Ryf</keyname><forenames>Roland</forenames></author><author><keyname>Fontaine</keyname><forenames>Nicolas</forenames></author><author><keyname>Antona</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Grubb</keyname><forenames>Steve</forenames></author><author><keyname>Winzer</keyname><forenames>Peter</forenames></author><author><keyname>Chraplyvy</keyname><forenames>Andrew</forenames></author></authors><title>Supply-Power-Constrained Cable Capacity Maximization Using Deep Neural
  Networks</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We experimentally achieve a 19% capacity gain per Watt of electrical supply
power in a 12-span link by eliminating gain flattening filters and optimizing
launch powers using machine learning by deep neural networks in a massively
parallel fiber context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02051</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02051</id><created>2019-10-02</created><authors><author><keyname>Zhou</keyname><forenames>M.</forenames><affiliation>Chongqing University of Posts and Telecommunications</affiliation></author><author><keyname>Li</keyname><forenames>X.</forenames><affiliation>Chongqing University of Posts and Telecommunications</affiliation></author><author><keyname>Wang</keyname><forenames>Y.</forenames><affiliation>Chongqing University of Posts and Telecommunications</affiliation></author><author><keyname>Ren</keyname><forenames>A.</forenames><affiliation>Chongqing University of Posts and Telecommunications</affiliation></author><author><keyname>Yang</keyname><forenames>X.</forenames><affiliation>Chongqing University of Posts and Telecommunications</affiliation></author></authors><title>WLAN Indoor Intrusion Detection Based on Deep Signal Feature Fusion and
  Minimized-MKMMD Transfer Learning</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor intrusion detection technology has been widely utilized in network
security monitoring, smart city, entertainment games, and other fields. Most
existing indoor intrusion detection methods directly exploit the Received
Signal Strength (RSS) data collected by Monitor Points (MPs) and do not
consider the instability of WLAN signals in the complex indoor environments. In
response to this urgent problem, this paper proposes a novel WLAN indoor
intrusion detection method based on deep signal feature fusion and Minimized
Multiple Kernel Maximum Mean Discrepancy (Minimized-MKMMD). Firstly, the
multi-branch deep convolutional neural network is used to conduct the
dimensionality reduction and feature fusion of the RSS data, and the tags are
obtained according to the features of the offline and online RSS fusion
features that are corresponding to the silence and intrusion states, and then
based on this, the source domain and target domain are constructed
respectively. Secondly, the optimal transfer matrix is constructed by
minimizing MKMMD. Thirdly, the transferred RSS data in the source domain is
utilized for training the classifiers that are applying in getting the
classification of the RSS fusion features in the target domain in the same
shared subspace. Finally, the intrusion detection of the target environment is
realized by iteratively updating the process above until the algorithm
converges. The experimental results show that the proposed method can
effectively improve the accuracy and robustness of the intrusion detection
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02052</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02052</id><created>2019-10-02</created><updated>2019-10-08</updated><authors><author><keyname>Saripalli</keyname><forenames>V. Ratna</forenames></author><author><keyname>Avinash</keyname><forenames>Gopal</forenames></author><author><keyname>Anderson</keyname><forenames>Charles W.</forenames></author></authors><title>AI Assisted Annotator using Reinforcement Learning</title><categories>eess.SP cs.AI cs.LG</categories><comments>8 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Healthcare data suffers from both noise and lack of ground truth. The cost of
data increases as it is cleaned and annotated in healthcare. Unlike other data
sets, medical data annotation, which is critical to accurate ground truth,
requires medical domain expertise for a better patient outcome. In this work,
we report on the use of reinforcement learning to mimic the decision making
process of annotators for medical events, to automate annotation and labelling.
The reinforcement agent learns to annotate alarm data based on annotations done
by an expert. Our method shows promising results on medical alarm data sets. We
trained DQN and A2C agents using the data from monitoring devices annotated by
an expert. Initial results from these RL agents learning the expert annotation
behavior are promising. The A2C agent performs better in terms of learning the
sparse events in a given state, thereby choosing more right actions compared to
DQN agent. To the best of our knowledge, this is the first reinforcement
learning application for the automation of medical events annotation, which has
far-reaching practical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02058</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02058</id><created>2019-10-04</created><authors><author><keyname>Frey</keyname><forenames>Markus</forenames></author><author><keyname>Nau</keyname><forenames>Matthias</forenames></author></authors><title>Memory efficient brain tumor segmentation using an
  autoencoder-regularized U-Net</title><categories>eess.IV cs.CV q-bio.NC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Early diagnosis and accurate segmentation of brain tumors are imperative for
successful treatment. Unfortunately, manual segmentation is time consuming,
costly and despite extensive human expertise often inaccurate. Here, we present
an MRI-based tumor segmentation framework using an autoencoder-regularized
3D-convolutional neural network. We trained the model on manually segmented
structural T1, T1ce, T2, and Flair MRI images of 335 patients with tumors of
variable severity, size and location. We then tested the model using
independent data of 125 patients and successfully segmented brain tumors into
three subregions: the tumor core (TC), the enhancing tumor (ET) and the whole
tumor (WT). We also explored several data augmentations and preprocessing steps
to improve segmentation performance. Importantly, our model was implemented on
a single NVIDIA GTX1060 graphics unit and hence optimizes tumor segmentation
for widely affordable hardware. In sum, we present a memory-efficient and
affordable solution to tumor segmentation to support the accurate diagnostics
of oncological brain pathologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02112</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02112</id><created>2019-10-04</created><authors><author><keyname>Shahab</keyname><forenames>Mohamad T.</forenames></author><author><keyname>Miller</keyname><forenames>Daniel E.</forenames></author></authors><title>A Convolution Bound Implies Tolerance to Time-variations and Unmodelled
  Dynamics</title><categories>math.OC cs.SY eess.SY</categories><comments>This is a preprint submitted to Systems and Control Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently it has been shown, in several settings, how to carry out adaptive
control for an LTI plant so that a convolution bound holds on the closed-loop
behavior; this, in turn, has been leveraged to prove robustness of the
closed-loop system to time-varying parameters and unmodelled dynamics. The goal
of this paper is to show that the same is true for a large class of
finite-dimensional, nonlinear plant and controller combinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02119</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02119</id><created>2019-10-04</created><authors><author><keyname>Yan</keyname><forenames>Hao</forenames></author><author><keyname>Paynabar</keyname><forenames>Kamran</forenames></author><author><keyname>Shi</keyname><forenames>Jianjun</forenames></author></authors><title>AKM$^2$D : An Adaptive Framework for Online Sensing and Anomaly
  Quantification</title><categories>stat.ML cs.LG eess.SP</categories><comments>Under review in IISE Transaction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In point-based sensing systems such as coordinate measuring machines (CMM)
and laser ultrasonics where complete sensing is impractical due to the high
sensing time and cost, adaptive sensing through a systematic exploration is
vital for online inspection and anomaly quantification. Most of the existing
sequential sampling methodologies focus on reducing the overall fitting error
for the entire sampling space. However, in many anomaly quantification
applications, the main goal is to estimate sparse anomalous regions in the
pixel-level accurately. In this paper, we develop a novel framework named
Adaptive Kernelized Maximum-Minimum Distance AKM$^2$D to speed up the
inspection and anomaly detection process through an intelligent sequential
sampling scheme integrated with fast estimation and detection. The proposed
method balances the sampling efforts between the space-filling sampling
(exploration) and focused sampling near the anomalous region (exploitation).
The proposed methodology is validated by conducting simulations and a case
study of anomaly detection in composite sheets using a guided wave test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02127</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02127</id><created>2019-10-04</created><authors><author><keyname>Remaggi</keyname><forenames>Luca</forenames></author><author><keyname>Jackson</keyname><forenames>Philip J. B.</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author></authors><title>Modeling the Comb Filter Effect and Interaural Coherence for Binaural
  Source Separation</title><categories>cs.SD eess.AS</categories><comments>IEEE Copyright. IEEE/ACM Transactions on Audio, Speech, and Language
  Processing, 2019</comments><doi>10.1109/TASLP.2019.2946043</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typical methods for binaural source separation consider only the direct sound
as the target signal in a mixture. However, in most scenarios, this assumption
limits the source separation performance. It is well known that the early
reflections interact with the direct sound, producing acoustic effects at the
listening position, e.g. the so-called comb filter effect. In this article, we
propose a novel source separation model, that utilizes both the direct sound
and the first early reflection information to model the comb filter effect.
This is done by observing the interaural phase difference obtained from the
time-frequency representation of binaural mixtures. Furthermore, a method is
proposed to model the interaural coherence of the signals. Including
information related to the sound multipath propagation, the performance of the
proposed separation method is improved with respect to the baselines that did
not use such information, as illustrated by using binaural recordings made in
four rooms, having different sizes and reverberation times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02130</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02130</id><created>2019-10-04</created><authors><author><keyname>Ghasemi</keyname><forenames>Mahsa</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Online Active Perception for Partially Observable Markov Decision
  Processes with Limited Budget</title><categories>cs.AI cs.SY eess.SY</categories><comments>Accepted for publication in Conference on Decision and Control (CDC)
  Proceedings, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active perception strategies enable an agent to selectively gather
information in a way to improve its performance. In applications in which the
agent does not have prior knowledge about the available information sources, it
is crucial to synthesize active perception strategies at runtime. We consider a
setting in which at runtime an agent is capable of gathering information under
a limited budget. We pose the problem in the context of partially observable
Markov decision processes. We propose a generalized greedy strategy that
selects a subset of information sources with near-optimality guarantees on
uncertainty reduction. Our theoretical analysis establishes that the proposed
active perception strategy achieves near-optimal performance in terms of
expected cumulative reward. We demonstrate the resulting strategies in
simulations on a robotic navigation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02131</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02131</id><created>2019-10-04</created><authors><author><keyname>Yang</keyname><forenames>Y.</forenames></author><author><keyname>Radhakrishna</keyname><forenames>U.</forenames></author><author><keyname>Ward</keyname><forenames>D.</forenames></author><author><keyname>Chandrakasan</keyname><forenames>A. P.</forenames></author><author><keyname>Lang</keyname><forenames>J. H.</forenames></author></authors><title>A Silicon MEMS EM vibration energy harvester</title><categories>physics.app-ph cs.SY eess.SP eess.SY</categories><comments>PowerMEMS 2018 conference</comments><doi>10.1088/1742-6596/1407/1/012022</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents an optimized silicon-MEMS electromagnetic vibration
energy harvester suitable for applications such as machine health monitoring.
The harvester comprises a DRIE-etched silicon suspension, and pick-and-place
N42 NdBFe magnets and copper coils, housed in a 3D-printed package. The
harvester is designed to operate near 50 Hz with 0.5-1 g vibrations using a
long-stroke suspension. Multi-domain harvester optimization results in an
open-circuit voltage of 1.7 V, a matched-load power output of 2.2 mW, and a
matched-load power-output density of 1.23 mW/cm3 at 1.1 g with a resonance
frequency of 76.3 Hz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02133</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02133</id><created>2019-10-04</created><authors><author><keyname>Iyer</keyname><forenames>Akshay</forenames></author><author><keyname>Dey</keyname><forenames>Biswadip</forenames></author><author><keyname>Dasgupta</keyname><forenames>Arindam</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Chakraborty</keyname><forenames>Amit</forenames></author></authors><title>A Conditional Generative Model for Predicting Material Microstructures
  from Processing Methods</title><categories>eess.IV cond-mat.mtrl-sci cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microstructures of a material form the bridge linking processing conditions -
which can be controlled, to the material property - which is the primary
interest in engineering applications. Thus a critical task in material design
is establishing the processing-structure relationship, which requires domain
expertise and techniques that can model the high-dimensional material
microstructure. This work proposes a deep learning based approach that models
the processing-structure relationship as a conditional image synthesis problem.
In particular, we develop an auxiliary classifier Wasserstein GAN with gradient
penalty (ACWGAN-GP) to synthesize microstructures under a given processing
condition. This approach is free of feature engineering, requires modest domain
knowledge and is applicable to a wide range of material systems. We demonstrate
this approach using the ultra high carbon steel (UHCS) database, where each
microstructure is annotated with a label describing the cooling method it was
subjected to. Our results show that ACWGAN-GP can synthesize high-quality
multiphase microstructures for a given cooling method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02138</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02138</id><created>2019-09-26</created><authors><author><keyname>Cai</keyname><forenames>Jiahong</forenames></author><author><keyname>Gao</keyname><forenames>Yuxuan</forenames></author><author><keyname>He</keyname><forenames>Xinyan</forenames></author><author><keyname>Chen</keyname><forenames>Huimiao</forenames></author></authors><title>A Method of EV Detour-to-Recharge Behavior Modeling and Charging Station
  Deployment</title><categories>cs.OH cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electric vehicles (EVs) are increasingly used in transportation. Worldwide
use of EVs, for their limited battery capacity, calls for effective planning of
EVs charging stations to enhance the efficiency of using EVs. This paper
provides a methodology of describing EV detouring behavior for recharging, and
based on this, we adopt the extra driving length caused by detouring and the
length of uncompleted route as the indicators of evaluating an EV charging
station deployment plan. In this way, we can simulate EV behavior based on
travel data from conventional cars. Then, a genetic algorithm (GA) based EV
charging station sitting optimization method is developed to obtain an
effective plan. A detailed case study based on a 100-node 203-branch
transportation network within a 30 km * 30 km region is included to test the
effectiveness of our method. Insights from our method may be applicable for
charging station planning in various transportation networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02142</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02142</id><created>2019-10-04</created><authors><author><keyname>Jiang</keyname><forenames>Hong</forenames></author><author><keyname>Ahn</keyname><forenames>Jong-Hoon</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoyang</forenames></author></authors><title>Lipschitz Learning for Signal Recovery</title><categories>cs.LG eess.SP math.OC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the recovery of signals from their observations, which are
samples of a transform of the signals rather than the signals themselves, by
using machine learning (ML). We will develop a theoretical framework to
characterize the signals that can be robustly recovered from their observations
by an ML algorithm, and establish a Lipschitz condition on signals and
observations that is both necessary and sufficient for the existence of a
robust recovery. We will compare the Lipschitz condition with the well-known
restricted isometry property of the sparse recovery of compressive sensing, and
show the former is more general and less restrictive. For linear observations,
our work also suggests an ML method in which the output space is reduced to the
lowest possible dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02155</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02155</id><created>2019-10-04</created><authors><author><keyname>Chehade</keyname><forenames>Abdallah</forenames></author><author><keyname>Shi</keyname><forenames>Zunya</forenames></author></authors><title>The Sparse Reverse of Principal Component Analysis for Fast Low-Rank
  Matrix Completion</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix completion constantly receives tremendous attention from many research
fields. It is commonly applied for recommender systems such as movie ratings,
computer vision such as image reconstruction or completion, multi-task learning
such as collaboratively modeling time-series trends of multiple sensors, and
many other applications. Matrix completion techniques are usually
computationally exhaustive and/or fail to capture the heterogeneity in the
data. For example, images usually contain a heterogeneous set of objects, and
thus it is a challenging task to reconstruct images with high levels of missing
data. In this paper, we propose the sparse reverse of principal component
analysis for matrix completion. The proposed approach maintains smoothness
across the matrix, produces accurate estimates of the missing data, converges
iteratively, and it is computationally tractable with a controllable upper
bound on the number of iterations until convergence. The accuracy of the
proposed technique is validated on natural images, movie ratings, and
multisensor data. It is also compared with common benchmark methods used for
matrix completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02157</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02157</id><created>2019-10-04</created><updated>2019-10-16</updated><authors><author><keyname>Chen</keyname><forenames>Xiao</forenames></author><author><keyname>Navidi</keyname><forenames>Thomas</forenames></author><author><keyname>Rajagopal</keyname><forenames>Ram</forenames></author></authors><title>Energy Resource Control via Privacy Preserving Data</title><categories>eess.SY cs.CY cs.SY</categories><comments>8 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Although the frequent monitoring of smart meters enables granular control
over energy resources, it also increases the risk of leakage of private
information such as income, home occupancy, and power consumption behavior that
can be inferred from the data by an adversary. We propose a method of releasing
modified smart meter data so specific private attributes are obscured while the
utility of the data for use in an energy resource controller is preserved. The
method achieves privatization by injecting noise conditional on the private
attribute through a linear filter learned via a minimax optimization. The
optimization contains the loss function of a classifier for the private
attribute, which we maximize, and the energy resource controller's objective
formulated as a canonical form optimization, which we minimize. We perform our
experiment on a dataset of household consumption with solar generation and
another from the Commission for Energy Regulation that contains household smart
meter data with sensitive attributes such as income and home occupancy. We
demonstrate that our method is able to significantly reduce the ability of an
adversary to classify the private attribute while maintaining a similar
objective value for an energy storage controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02165</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02165</id><created>2019-10-04</created><authors><author><keyname>Bhamidipati</keyname><forenames>Sriramya</forenames></author><author><keyname>Gao</keyname><forenames>Grace Xingxin</forenames></author></authors><title>SLAM-based Integrity Monitoring Using GPS and Fish-eye Camera</title><categories>cs.RO cs.CV eess.IV</categories><comments>32nd International Technical Meeting of the Satellite Division of the
  Institute of Navigation, ION GNSS+ 2019, Miami, FL, Sept 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urban navigation using GPS and fish-eye camera suffers from multipath effects
in GPS measurements and data association errors in pixel intensities across
image frames. We propose a Simultaneous Localization and Mapping (SLAM)-based
Integrity Monitoring (IM) algorithm to compute the position protection levels
while accounting for multiple faults in both GPS and vision. We perform graph
optimization using the sequential data of GPS pseudoranges, pixel intensities,
vehicle dynamics, and satellite ephemeris to simultaneously localize the
vehicle as well as the landmarks, namely GPS satellites and key image pixels in
the world frame. We estimate the fault mode vector by analyzing the temporal
correlation across the GPS measurement residuals and spatial correlation across
the vision intensity residuals. In particular, to detect and isolate the vision
faults, we developed a superpixel-based piecewise Random Sample Consensus
(RANSAC) technique to perform spatial voting across image pixels. For an
estimated fault mode, we compute the protection levels by applying worst-case
failure slope analysis to the linearized Graph-SLAM framework. We perform
ground vehicle experiments in the semi-urban area of Champaign, IL and have
demonstrated the successful detection and isolation of multiple faults. We also
validate tighter protection levels and lower localization errors achieved via
the proposed algorithm as compared to SLAM-based IM that utilizes only GPS
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02168</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02168</id><created>2019-10-04</created><updated>2019-10-29</updated><authors><author><keyname>Abad</keyname><forenames>Alberto</forenames></author><author><keyname>Bell</keyname><forenames>Peter</forenames></author><author><keyname>Carmantini</keyname><forenames>Andrea</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Cross lingual transfer learning for zero-resource domain adaptation</title><categories>eess.AS</categories><comments>Submitted to ICASSP 2020. Main updates wrt previous versions: same
  network config in all experiments, added Babel/Material LR target language
  experiments, added comparison with alternative/similar methods of
  cross-lingual adaptation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for zero-resource domain adaptation of DNN acoustic
models, for use in low-resource situations where the only in-language training
data available may be poorly matched to the intended target domain. Our method
uses a multi-lingual model in which several DNN layers are shared between
languages. This architecture enables domain adaptation transforms learned for
one well-resourced language to be applied to an entirely different low-resource
language. First, to develop the technique we use English as a well-resourced
language and take Spanish to mimic a low-resource language. Experiments in
domain adaptation between the conversational telephone speech (CTS) domain and
broadcast news (BN) domain demonstrate a 29% relative WER improvement on
Spanish BN test data by using only English adaptation data. Second, we
demonstrate the effectiveness of the method for low-resource languages with a
poor match to the well-resourced language. Even in this scenario, the proposed
method achieves relative WER improvements of 18-27% by using solely English
data for domain adaptation. Compared to other related approaches based on
multi-task and multi-condition training, the proposed method is able to better
exploit well-resource language data for improved acoustic modelling of the
low-resource target domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02175</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02175</id><created>2019-10-04</created><updated>2019-10-21</updated><authors><author><keyname>Rajan</keyname><forenames>Deepta</forenames></author><author><keyname>Beymer</keyname><forenames>David</forenames></author><author><keyname>Abedin</keyname><forenames>Shafiqul</forenames></author><author><keyname>Dehghan</keyname><forenames>Ehsan</forenames></author></authors><title>Pi-PE: A Pipeline for Pulmonary Embolism Detection using Sparsely
  Annotated 3D CT Images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>2019 NeurIPS ML4H (Proceedings of Machine Learning Research)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pulmonary embolisms (PE) are known to be one of the leading causes for
cardiac-related mortality. Due to inherent variabilities in how PE manifests
and the cumbersome nature of manual diagnosis, there is growing interest in
leveraging AI tools for detecting PE. In this paper, we build a two-stage
detection pipeline that is accurate, computationally efficient, robust to
variations in PE types and kernels used for CT reconstruction, and most
importantly, does not require dense annotations. Given the challenges in
acquiring expert annotations in large-scale datasets, our approach produces
state-of-the-art results with very sparse emboli contours (at 10mm slice
spacing), while using models with significantly lower number of parameters. We
achieve AUC scores of 0.94 on the validation set and 0.85 on the test set of
highly severe PEs. Using a large, real-world dataset characterized by complex
PE types and patients from multiple hospitals, we present an elaborate
empirical study and provide guidelines for designing highly generalizable
pipelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02185</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02185</id><created>2019-10-04</created><authors><author><keyname>Cao</keyname><forenames>Ruiming</forenames></author><author><keyname>Zhong</keyname><forenames>Xinran</forenames></author><author><keyname>Scalzo</keyname><forenames>Fabien</forenames></author><author><keyname>Raman</keyname><forenames>Steven</forenames></author><author><keyname>Sung</keyname><forenames>Kyung hyun</forenames></author></authors><title>Prostate cancer inference via weakly-supervised learning using a large
  collection of negative MRI</title><categories>eess.IV cs.LG q-bio.QM</categories><comments>6 pages, 5 figures, 2019 International Conference on Computer Vision
  - Visual Recognition for Medical Images Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in medical imaging techniques have led to significant
improvements in the management of prostate cancer (PCa). In particular,
multi-parametric MRI (mp-MRI) continues to gain clinical acceptance as the
preferred imaging technique for non-invasive detection and grading of PCa.
However, the machine learning-based diagnosis systems for PCa are often
constrained by the limited access to accurate lesion ground truth annotations
for training. The performance of the machine learning system is highly
dependable on both quality and quantity of lesion annotations associated with
histopathologic findings, resulting in limited scalability and clinical
validation. Here, we propose the baseline MRI model to alternatively learn the
appearance of mp-MRI using radiology-confirmed negative MRI cases via weakly
supervised learning. Since PCa lesions are case-specific and highly
heterogeneous, it is assumed to be challenging to synthesize PCa lesions using
the baseline MRI model, while it would be relatively easier to synthesize the
normal appearance in mp-MRI. We then utilize the baseline MRI model to infer
the pixel-wise suspiciousness of PCa by comparing the original and synthesized
MRI with two distance functions. We trained and validated the baseline MRI
model using 1,145 negative prostate mp-MRI scans. For evaluation, we used
separated 232 mp-MRI scans, consisting of both positive and negative MRI cases.
The 116 positive MRI scans were annotated by radiologists, confirmed with
post-surgical whole-gland specimens. The suspiciousness map was evaluated by
receiver operating characteristic (ROC) analysis for PCa lesions versus non-PCa
regions classification and free-response receiver operating characteristic
(FROC) analysis for PCa localization. Our proposed method achieved 0.84 area
under the ROC curve and 77.0% sensitivity at one false positive per patient in
FROC analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02193</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02193</id><created>2019-10-04</created><authors><author><keyname>Du</keyname><forenames>Zhe</forenames></author><author><keyname>Ozay</keyname><forenames>Necmiye</forenames></author><author><keyname>Balzano</keyname><forenames>Laura</forenames></author></authors><title>Mode Clustering for Markov Jump Systems</title><categories>eess.SY cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the problem of mode clustering in Markov jump
models. This model class consists of multiple dynamical modes with a switching
sequence that determines how the system switches between them over time. Under
different active modes, the observations can have different characteristics.
Given the observations only and without knowing the mode sequence, the goal is
to cluster the modes based on their transition distributions in the Markov
chain to find a reduced-rank Markov matrix that is embedded in the original
Markov chain. Our approach involves mode sequence estimation, mode clustering
and reduced-rank model estimation, where mode clustering is achieved by
applying the singular value decomposition and k-means. We show that, under
certain conditions, the clustering error can be bounded, and the reduced-rank
Markov chain is a good approximation to the original Markov chain. Through
simulations, we show the efficacy of our approach and the application of our
approach to real world scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02207</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02207</id><created>2019-10-05</created><authors><author><keyname>Chen</keyname><forenames>Peng</forenames></author><author><keyname>Cao</keyname><forenames>Zhenxin</forenames></author><author><keyname>Chen</keyname><forenames>Zhimin</forenames></author></authors><title>A New Atomic Norm for DOA Estimation With Gain-Phase Errors</title><categories>eess.SP</categories><comments>11 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The direction of arrival (DOA) estimation problem has been studied for
decades and is essential in the radar, wireless communications, and array
signal processing applications. In this paper, the DOA estimation problem in
the scenario with gain-phase errors is considered, and a sparse model is
formulated by exploiting the signal sparsity in the spatial domain. By
proposing a new atomic norm, an optimization method is formulated via deriving
a dual norm of the new atomic norm. Then, the corresponding semidefinite
program (SDP) is given to estimate the DOA efficiently, where the SDP is
obtained based on the Schur complement. Moreover, a regularization parameter is
obtained theoretically in the convex optimization problem. Simulation results
show that the proposed method outperforms the existing methods, including the
subspace-based and sparse-based methods in the scenario with gain-phase errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02219</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02219</id><created>2019-10-05</created><authors><author><keyname>Ayodeji</keyname><forenames>Abiodun</forenames></author><author><keyname>Liu</keyname><forenames>Yong-kuo</forenames></author></authors><title>Recurrent neural network based decision support system</title><categories>cs.NE cs.LG cs.SY eess.SY</categories><comments>conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decision Support Systems (DSS) in complex installations play a crucial role
in assisting operators in decision making during abnormal transients and
process disturbances, by actively displaying the status of the system and
recording events, time of occurrence and suggesting relevant actions. The
complexity and dynamics of complex systems require a careful selection of
suitable neural network architecture, so as to improve diagnostic accuracy. In
this work, we present a technique to develop a fault diagnostic decision
support using recurrent neural network and Principal Component Analysis (PCA).
We utilized the PCA method for noise filtering in the pre-diagnostic stage, and
evaluate the predictive capability of radial basis recurrent network on a
representative data derived from the simulation of a pressurized nuclear
reactor. The process was validated using data from different fault scenarios,
and the fault signatures were used as the input. The predictive outputs
required are the location and sizes of the faults. The result shows that the
radial basis network gives accurate predictions. Selected hyperparameters and
diagnostic results are also presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02220</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02220</id><created>2019-10-05</created><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author></authors><title>A Fundamental Bound on Performance of Non-Intrusive Load Monitoring with
  Application to Smart Meter Privacy</title><categories>eess.SP cs.SY eess.SY math.OC math.ST stat.AP stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the expected estimation error of non-intrusive load monitoring
algorithms is lower bounded by the trace of the inverse of the
cross-correlation matrix between the derivatives of the load profiles of the
appliances. We use this fundamental bound to develop privacy-preserving
policies. Particularly, we devise a load-scheduling policy by maximizing the
lower bound on the expected estimation error of non-intrusive load monitoring
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02235</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02235</id><created>2019-10-05</created><authors><author><keyname>Zhang</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Yixin</forenames></author><author><keyname>Hou</keyname><forenames>Feng</forenames></author><author><keyname>Yang</keyname><forenames>Jiawei</forenames></author><author><keyname>Xiong</keyname><forenames>Guangwei</forenames></author><author><keyname>Tian</keyname><forenames>Jiang</forenames></author><author><keyname>Zhong</keyname><forenames>Cheng</forenames></author></authors><title>Cascaded Volumetric Convolutional Network for Kidney Tumor Segmentation
  from CT volumes</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated segmentation of kidney and tumor from 3D CT scans is necessary for
the diagnosis, monitoring, and treatment planning of the disease. In this
paper, we describe a two-stage framework for kidney and tumor segmentation
based on 3D fully convolutional network (FCN). The first stage preliminarily
locate the kidney and cut off the irrelevant background to reduce class
imbalance and computation cost. Then the second stage precisely segment the
kidney and tumor on the cropped patch. The proposed method achieves 98.05% and
83.70% of Dice score on the validation set of MICCAI 2019 KiTS Challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02241</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02241</id><created>2019-10-05</created><authors><author><keyname>Zhuang</keyname><forenames>Xinrui</forenames></author><author><keyname>Li</keyname><forenames>Yuexiang</forenames></author><author><keyname>Hu</keyname><forenames>Yifan</forenames></author><author><keyname>Ma</keyname><forenames>Kai</forenames></author><author><keyname>Yang</keyname><forenames>Yujiu</forenames></author><author><keyname>Zheng</keyname><forenames>Yefeng</forenames></author></authors><title>Self-supervised Feature Learning for 3D Medical Images by Playing a
  Rubik's Cube</title><categories>cs.CV cs.LG eess.IV</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Witnessed the development of deep learning, increasing number of studies try
to build computer aided diagnosis systems for 3D volumetric medical data.
However, as the annotations of 3D medical data are difficult to acquire, the
number of annotated 3D medical images is often not enough to well train the
deep learning networks. The self-supervised learning deeply exploiting the
information of raw data is one of the potential solutions to loose the
requirement of training data. In this paper, we propose a self-supervised
learning framework for the volumetric medical images. A novel proxy task, i.e.,
Rubik's cube recovery, is formulated to pre-train 3D neural networks. The proxy
task involves two operations, i.e., cube rearrangement and cube rotation, which
enforce networks to learn translational and rotational invariant features from
raw 3D data. Compared to the train-from-scratch strategy, fine-tuning from the
pre-trained network leads to a better accuracy on various tasks, e.g., brain
hemorrhage classification and brain tumor segmentation. We show that our
self-supervised learning approach can substantially boost the accuracies of 3D
deep learning networks on the volumetric medical datasets without using extra
data. To our best knowledge, this is the first work focusing on the
self-supervised learning of 3D neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02285</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02285</id><created>2019-10-05</created><authors><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Xukun</forenames></author><author><keyname>Du</keyname><forenames>Peng</forenames></author><author><keyname>Lang</keyname><forenames>Guanjing</forenames></author><author><keyname>Xu</keyname><forenames>Min</forenames></author><author><keyname>Xu</keyname><forenames>Kaijin</forenames></author><author><keyname>Li</keyname><forenames>Lanjuan</forenames></author></authors><title>A Deep Learning System That Generates Quantitative CT Reports for
  Diagnosing Pulmonary Tuberculosis</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We developed a deep learning model-based system to automatically generate a
quantitative Computed Tomography (CT) diagnostic report for Pulmonary
Tuberculosis (PTB) cases.501 CT imaging datasets from 223 patients with active
PTB were collected, and another 501 cases from a healthy population served as
negative samples.2884 lesions of PTB were carefully labeled and classified
manually by professional radiologists.Three state-of-the-art 3D convolution
neural network (CNN) models were trained and evaluated in the inspection of PTB
CT images. Transfer learning method was also utilized during this process. The
best model was selected to annotate the spatial location of lesions and
classify them into miliary, infiltrative, caseous, tuberculoma and cavitary
types simultaneously.Then the Noisy-Or Bayesian function was used to generate
an overall infection probability.Finally, a quantitative diagnostic report was
exported.The results showed that the recall and precision rates, from the
perspective of a single lesion region of PTB, were 85.9% and 89.2%
respectively. The overall recall and precision rates,from the perspective of
one PTB case, were 98.7% and 93.7%, respectively. Moreover, the precision rate
of the PTB lesion type classification was 90.9%.The new method might serve as
an effective reference for decision making by clinical doctors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02300</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02300</id><created>2019-10-05</created><authors><author><keyname>Ibrahim</keyname><forenames>Ahmed</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author><author><keyname>Armada</keyname><forenames>Ana Garcia</forenames></author></authors><title>Bender's Decomposition for Optimization Design Problems in Communication
  Networks</title><categories>cs.NI eess.SP</categories><comments>Accepted in IEEE Network Magazine, Aug. 2019, Article No.:
  NETWORK-19-00414.R1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various types of communication networks are constantly emerging to improve
the connectivity services and facilitate the interconnection of various types
of devices. This involves the development of several technologies, such as
device-to-device communications, wireless sensor networks and vehicular
communications. The various services provided have heterogeneous requirements
on the quality metrics such as throughput, end-to-end latency and jitter.
Furthermore, different network technologies have inherently heterogeneous
restrictions on resources, e.g., power, interference management requirements,
computational capabilities, etc. As a result, different network operations such
as spectrum management, routing, power control and offloading need to be
performed differently. Mathematical optimization techniques have always been at
the heart of such design problems to formulate and propose computationally
efficient solution algorithms. One of the existing powerful techniques of
mathematical optimization is Benders decomposition (BD), which is the focus of
this article. Here, we briefly review different BD variants that have been
applied in various existing network types and different design problems. These
main variants are the classical, the combinatorial, the multi-stage, and the
generalized BD. We discuss compelling BD applications for various network types
including heterogeneous cellular networks, infrastructure wired wide area
networks, smart grids, wireless sensor networks, and wireless local area
networks. Mainly, our goal is to assist the readers in refining the motivation,
problem formulation, and methodology of this powerful optimization technique in
the context of future networks. We also discuss the BD challenges and the
prospective ways these can be addressed when applied to communication networks'
design problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02317</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02317</id><created>2019-10-05</created><authors><author><keyname>He</keyname><forenames>Binghan</forenames></author><author><keyname>Thomas</keyname><forenames>Gray C.</forenames></author><author><keyname>Sentis</keyname><forenames>Luis</forenames></author></authors><title>Robust Estimator-Based Safety Verification: A Vector Norm Approach</title><categories>math.OC cs.SY eess.SY</categories><comments>Submitted for publication in American Control Conference (ACC) 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of verifying safety constraint
satisfaction for single-input single-output systems with uncertain transfer
function coefficients. We propose a new type of barrier function based on a
vector norm. This type of barrier function has a measurable upper bound without
full state availability. An identifier-based estimator allows an exact bound
for the uncertainty-based component of the barrier function estimate. Assuming
that the system is safe initially allows an exponentially decreasing bound on
the error due to the estimator transient. Barrier function and estimator
synthesis is proposed as two convex sub-problems, exploiting linear matrix
inequalities. The barrier function controller combination is then used to
construct a safety backup controller. And we demonstrate the system in a
simulation of a 1 degree-of-freedom human-exoskeleton interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02323</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02323</id><created>2019-10-05</created><authors><author><keyname>Singhal</keyname><forenames>N. G.</forenames></author><author><keyname>Kwon</keyname><forenames>J.</forenames></author><author><keyname>Hedman</keyname><forenames>K. W.</forenames></author></authors><title>Generator Contingency Modeling in Electric Energy Markets: Derivation of
  Prices via Duality Theory</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional electric energy markets do not explicitly model generator
contingencies. To improve the representation of resources and to enhance the
modeling of uncertainty, existing markets are moving in the direction of
including generator contingencies and remedial action schemes within market
auction models explicitly. This research contributes to the market design realm
by providing detailed analysis of impending changes, it provides insightful
guidance in understanding the market implications, and it provides
recommendations on necessary changes to ensure a fair and transparent market
structure. A primal (and the corresponding dual) formulation that accounts for
the proposed changes to the auction model is provided to enable a theoretical
analysis of the anticipated changes including the effect on market prices,
settlements, and revenues. The derivation of the prices and the dual
formulation are based on leveraging duality theory from linear optimization
theory. A comparison to existing market structures is also included. The
primary impact of the proposed changes includes the addition of a new
congestion component within the traditional locational marginal price, which
reflects the influence of congestion during the post-contingency states for the
modeled critical generator contingencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02324</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02324</id><created>2019-10-05</created><authors><author><keyname>Ding</keyname><forenames>Yuan</forenames></author><author><keyname>Narbudowicz</keyname><forenames>Adam</forenames></author></authors><title>Can Frequency Diverse Array Prevent Wireless Eavesdropping in Range
  Domain?</title><categories>eess.SP</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the concept and recent development of exploiting frequency
diverse array (FDA) and its variants for the physical-layer wireless security
have been revisited and carefully examined. Following rigorous analytical
derivation and illustrative simulations, the authors argue that the
investigations performed in some recent works did not reveal one critical issue
facing the real-world applications, and system models established and used
before were based on an unrealistic assumption, i.e. that the legitimate and
eavesdropping users at different ranges sample the signal waveforms at the same
time instant. This misunderstanding results in conclusions that are misleading.
The authors aim to take the first step to divert research efforts and rectify
the previous problematic analyses. The authors prove that the FDA cannot secure
a free-space wireless transmission in range domain, because the previously
claimed 'secure reception region' propagates in range domain as time elapses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02325</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02325</id><created>2019-10-05</created><authors><author><keyname>Fan</keyname><forenames>David D.</forenames></author><author><keyname>Nguyen</keyname><forenames>Jennifer</forenames></author><author><keyname>Thakker</keyname><forenames>Rohan</forenames></author><author><keyname>Alatur</keyname><forenames>Nikhilesh</forenames></author><author><keyname>Agha-mohammadi</keyname><forenames>Ali-akbar</forenames></author><author><keyname>Theodorou</keyname><forenames>Evangelos A.</forenames></author></authors><title>Bayesian Learning-Based Adaptive Control for Safety Critical Systems</title><categories>eess.SY cs.LG cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has enjoyed much recent success, and applying state-of-the-art
model learning methods to controls is an exciting prospect. However, there is a
strong reluctance to use these methods on safety-critical systems, which have
constraints on safety, stability, and real-time performance. We propose a
framework which satisfies these constraints while allowing the use of deep
neural networks for learning model uncertainties. Central to our method is the
use of Bayesian model learning, which provides an avenue for maintaining
appropriate degrees of caution in the face of the unknown. In the proposed
approach, we develop an adaptive control framework leveraging the theory of
stochastic CLFs (Control Lypunov Functions) and stochastic CBFs (Control
Barrier Functions) along with tractable Bayesian model learning via Gaussian
Processes or Bayesian neural networks. Under reasonable assumptions, we
guarantee stability and safety while adapting to unknown dynamics with
probability 1. We demonstrate this architecture for high-speed terrestrial
mobility targeting potential applications in safety-critical high-speed Mars
rover missions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02338</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02338</id><created>2019-10-05</created><authors><author><keyname>Taghvaei</keyname><forenames>Amirhossein</forenames></author><author><keyname>Mehta</keyname><forenames>Prashant G.</forenames></author></authors><title>An Optimal Transport Formulation of the Ensemble Kalman Filter</title><categories>eess.SY cs.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controlled interacting particle systems such as the ensemble Kalman filter
(EnKF) and the feedback particle filter (FPF) are numerical algorithms to
approximate the solution of the nonlinear filtering problem in continuous time.
The distinguishing feature of these algorithms is that the Bayesian update step
is implemented using a feedback control law. It has been noted in the
literature that the control law is not unique. This is the main problem
addressed in this paper. To obtain a unique control law, the filtering problem
is formulated here as an optimal transportation problem. An explicit formula
for the (mean-field type) optimal control law is derived in the linear Gaussian
setting. Comparisons are made with the control laws for different types of EnKF
algorithms described in the literature. Via empirical approximation of the
mean-field control law, a finite-$N$ controlled interacting particle algorithm
is obtained. For this algorithm, the equations for empirical mean and
covariance are derived and shown to be identical to the Kalman filter. This
allows strong conclusions on convergence and error properties based on the
classical filter stability theory for the Kalman filter. It is shown that,
under certain technical conditions, the mean squared error (m.s.e.) converges
to zero even with a finite number of particles. A detailed propagation of chaos
analysis is carried out for the finite-$N$ algorithm. The analysis is used to
prove weak convergence of the empirical distribution as $N\rightarrow\infty$.
For a certain simplified filtering problem, analytical comparison of the m.s.e.
with the importance sampling-based algorithms is described. The analysis helps
explain the favorable scaling properties of the control-based algorithms
reported in several numerical studies in recent literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02349</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02349</id><created>2019-10-05</created><updated>2019-10-11</updated><authors><author><keyname>Shen</keyname><forenames>Xu</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaojing</forenames></author><author><keyname>Borrelli</keyname><forenames>Francesco</forenames></author></authors><title>Autonomous Parking of Vehicle Fleet in Tight Environments</title><categories>eess.SY cs.SY</categories><comments>Submitted to IEEE American Control Conference (ACC), Denver, CO, USA,
  July 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of autonomous parking of vehicle fleets is addressed in this
paper. We present a system-level modeling and control framework which allows
investigating different vehicle parking strategies while taking into account
path planning and collision avoidance. The proposed approach decouples the
problem into a centralized parking spot allocation and path generation, and a
decentralized collision avoidance control. This paper presents the hierarchical
framework and algorithmic details. Extensive simulations are used to assess
several allocation strategies in terms of total fleet parking time and queue
length. In particular, we describe how Braess's paradox can be observed for
parking vehicle fleets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02354</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02354</id><created>2019-10-05</created><updated>2019-11-18</updated><authors><author><keyname>Shen</keyname><forenames>Guangyu</forenames></author><author><keyname>Mao</keyname><forenames>Chengzhi</forenames></author><author><keyname>Yang</keyname><forenames>Junfeng</forenames></author><author><keyname>Ray</keyname><forenames>Baishakhi</forenames></author></authors><title>AdvSPADE: Realistic Unrestricted Attacks for Semantic Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the inherent robustness of segmentation models, traditional
norm-bounded attack methods show limited effect on such type of models. In this
paper, we focus on generating unrestricted adversarial examples for semantic
segmentation models. We demonstrate a simple and effective method to generate
unrestricted adversarial examples using conditional generative adversarial
networks (CGAN) without any hand-crafted metric. The na\&quot;ive implementation of
CGAN, however, yields inferior image quality and low attack success rate.
Instead, we leverage the SPADE (Spatially-adaptive denormalization) structure
with an additional loss item to generate effective adversarial attacks in a
single step. We validate our approach on the popular Cityscapes and ADE20K
datasets, and demonstrate that our synthetic adversarial examples are not only
realistic, but also improve the attack success rate by up to 41.0\% compared
with the state of the art adversarial attack methods including PGD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02374</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02374</id><created>2019-10-06</created><updated>2020-01-27</updated><authors><author><keyname>Zulfiqar</keyname><forenames>Umair</forenames></author><author><keyname>Sreeram</keyname><forenames>Victor</forenames></author><author><keyname>Du</keyname><forenames>Xin</forenames></author></authors><title>Frequency-Limited Pseudo-Optimal Rational Krylov Algorithm for Power
  System Reduction</title><categories>eess.SY cs.SY</categories><journal-ref>International Journal of Electrical Power &amp; Energy Systems, 118,
  p.105798 (2020)</journal-ref><doi>10.1016/j.ijepes.2019.105798</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, a computationally efficient frequency-limited model reduction
algorithm is presented for large-scale interconnected power systems. The
algorithm generates a reduced order model which not only preserves the
electromechanical modes of the original power system but also satisfies a
subset of the first-order optimality conditions for H2;! model reduction
problem within the desired frequency interval. The reduced-order model
accurately captures the oscillatory behavior of the original power system and
provides a good time- and frequency-domain accuracy. The proposed algorithm
enables fast simulation, analysis, and damping controller design for the
original large-scale power system. The efficacy of the proposed algorithm is
validated on benchmark power system examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02376</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02376</id><created>2019-10-06</created><authors><author><keyname>Ma</keyname><forenames>Wei</forenames></author><author><keyname>Qian</keyname><forenames>Sean</forenames></author></authors><title>High-Resolution Traffic Sensing with Autonomous Vehicles</title><categories>eess.SP cs.CY cs.LG</categories><comments>submitted to Transportation Research Part C: Emerging Technologies</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last decades have witnessed the breakthrough of autonomous vehicles
(AVs), and the perception capabilities of AVs have been dramatically improved.
Various sensors installed on AVs, including, but are not limited to, LiDAR,
radar, camera and stereovision, will be collecting massive data and perceiving
the surrounding traffic states continuously. In fact, a fleet of AVs can serve
as floating (or probe) sensors, which can be utilized to infer traffic
information while cruising around the roadway networks. In contrast,
conventional traffic sensing methods rely on fixed traffic sensors such as loop
detectors, cameras and microwave vehicle detectors. Due to the high cost of
conventional traffic sensors, traffic state data are usually obtained in a
low-frequency and sparse manner. In view of this, this paper leverages rich
data collected through AVs to propose the high-resolution traffic sensing
framework. The proposed framework estimates the fundamental traffic state
variables, namely, flow, density and speed in high spatio-temporal resolution,
and it is developed under different levels of AV perception capabilities and
low AV market penetration rate. The Next Generation Simulation (NGSIM) data is
adopted to examine the accuracy and robustness of the proposed framework.
Experimental results show that the proposed estimation framework achieves high
accuracy even with low AV market penetration rate. Sensitivity analysis
regarding AV penetration rate, sensor configuration, and perception accuracy
will also be studied. This study will help policymakers and private sectors
(e.g Uber, Waymo) to understand the values of AVs, especially the values of
massive data collected by AVs, in traffic operation and management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02380</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02380</id><created>2019-10-06</created><authors><author><keyname>Dobler</keyname><forenames>Gregory</forenames></author><author><keyname>Vani</keyname><forenames>Jordan</forenames></author><author><keyname>Dam</keyname><forenames>Trang Tran Linh</forenames></author></authors><title>Patterns of Urban Foot Traffic Dynamics</title><categories>physics.soc-ph cs.LG eess.SP stat.ML</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using publicly available traffic camera data in New York City, we quantify
time-dependent patterns in aggregate pedestrian foot traffic. These patterns
exhibit repeatable diurnal behaviors that differ for weekdays and weekends but
are broadly consistent across neighborhoods in the borough of Manhattan.
Weekday patterns contain a characteristic 3-peak structure with increased foot
traffic around 9:00am, 12:00-1:00pm, and 5:00pm aligned with the &quot;9-to-5&quot; work
day in which pedestrians are on the street during their morning commute, during
lunch hour, and then during their evening commute. Weekend days do not show a
peaked structure, but rather increase steadily until sunset. Our study period
of June 28, 2017 to September 11, 2017 contains two holidays, the 4th of July
and Labor Day, and their foot traffic patterns are quantitatively similar to
weekend days despite the fact that they fell on weekdays. Projecting all days
in our study period onto the weekday/weekend phase space (by regressing against
the average weekday and weekend day) we find that Friday foot traffic can be
represented as a mixture of both the 3-peak weekday structure and non-peaked
weekend structure. We also show that anomalies in the foot traffic patterns can
be used for detection of events and network-level disruptions. Finally, we show
that clustering of foot traffic time series generates associations between
cameras that are spatially aligned with Manhattan neighborhood boundaries
indicating that foot traffic dynamics encode information about neighborhood
character.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02381</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02381</id><created>2019-10-06</created><authors><author><keyname>Yushmanov</keyname><forenames>P.</forenames></author><author><keyname>Takizuka</keyname><forenames>T.</forenames></author><author><keyname>Riedel</keyname><forenames>K.</forenames></author><author><keyname>Kardaun</keyname><forenames>O.</forenames></author><author><keyname>Cordey</keyname><forenames>J.</forenames></author><author><keyname>Kaye</keyname><forenames>S.</forenames></author><author><keyname>Post</keyname><forenames>D.</forenames></author></authors><title>Scalings for Tokamak Energy Confinement</title><categories>physics.plasm-ph cs.SY eess.SY stat.AP stat.OT</categories><journal-ref>Nucl. Fusion 1990</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On the basis of an analysis of the ITER L-mode energy confinement database,
two new scaling expressions for tokamak L-mode energy confinement are proposed,
namely a power law scaling and an offset-linear scaling. The analysis indicates
that the present multiplicity of scaling expressions for the energy confinement
time TE in tokamaks (Goldston, Kaye, Odajima-Shimomura, Rebut-Lallia, etc.) is
due both to the lack of variation of a key parameter combination in the
database, fs = 0.32 R a^.75 k^ 5 ~ A a^.25 k^.5, and to variations in the
dependence of rE on the physical parameters among the different tokamaks in the
database. By combining multiples of fs and another factor, fq = 1.56 a^2 kB/R
Ip = qeng/3.2, which partially reflects the tokamak to tokamak variation of the
dependence of TE on q and therefore implicitly the dependence of TE on Ip and
n,., the two proposed confinement scaling expressions can be transformed to
forms very close to most of the common scaling expressions. To reduce the
multiplicity of the scalings for energy confinement, the database must be
improved by adding new data with significant variations in fs, and the physical
reasons for the tokamak to tokamak variation of some of the dependences of the
energy confinement time on tokamak parameters must be clarified
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02398</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02398</id><created>2019-10-06</created><authors><author><keyname>Cao</keyname><forenames>Yashuai</forenames></author><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author></authors><title>Intelligent Reflecting Surface Aided Multi-User Millimeter-Wave
  Communications for Coverage Enhancement</title><categories>eess.SP</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is envisioned as a promising solution
for controlling radio propagation environments in future wireless systems. In
this paper, IRS is exploited to extend the millimeter wave (mmW) signal
coverage to blind spots, thereby reducing power consumption whilst improving
communication performance. To merge IRS with mmW communications enjoying
gigabit data-rate, we introduce a distributed IRS aided mmW system to support
multi-user transmission. Taking into account the multi-user interference, we
study a joint active and passive beamforming problem for weighted sumrate
maximization. Then, an alternating iterative algorithm with closed-form
expressions is proposed to tackle the non-convex problem. Moreover, we design a
quantitative projection method for the IRS with discrete phase shifts. Finally,
the simulation results demonstrate that the distributed IRS can effectively
support multi-user mmW transmissions based on our proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02400</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02400</id><created>2019-10-06</created><authors><author><keyname>Yu</keyname><forenames>Yanghao</forenames></author><author><keyname>Hou</keyname><forenames>Qingchun</forenames></author><author><keyname>Ge</keyname><forenames>Yi</forenames></author><author><keyname>Liu</keyname><forenames>Guojing</forenames></author><author><keyname>Zhang</keyname><forenames>Ning</forenames></author></authors><title>A Linear LMP Model for Active and Reactive Power with Power Loss</title><categories>eess.SY cs.SY</categories><comments>6 pages, 6 figures, accepted by IEEE Sustainable Power &amp; Energy
  Conference (iSPEC2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pricing the reactive power is more necessary than ever before because of the
increasing challenge of renewable energy integration on reactive power balance
and voltage control. However, reactive power price is hard to be efficiently
calculated because of the non-linear nature of optimal AC power flow equation.
This paper proposes a linear model to calculate active and reactive power LMP
simultaneously considering power loss. Firstly, a linearized AC power flow
equation is proposed based on an augmented Generation Shift Distribution
Factors (GSDF) matrix. Secondly, a linearized LMP model is derived using GSDF
and loss factors. The formulation of LMP is further decomposed into four
components: energy, congestion, voltage limitation and power loss. Finally, an
iterate algorithm is proposed for calculating LMP with the proposed model. The
performance of the proposed model is validated by the IEEE-118 bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02411</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02411</id><created>2019-10-06</created><authors><author><keyname>Broad</keyname><forenames>Terence</forenames></author><author><keyname>Grierson</keyname><forenames>Mick</forenames></author></authors><title>Transforming the output of GANs by fine-tuning them with features from
  different datasets</title><categories>cs.LG cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this work we present a method for fine-tuning pre-trained GANs with
features from different datasets, resulting in the transformation of the output
distribution into a new distribution with novel characteristics. The weights of
the generator are updated using the weighted sum of the losses from a
cross-dataset classifier and the frozen weights of the pre-trained
discriminator. We discuss details of the technical implementation and share
some of the visual results from this training process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02449</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02449</id><created>2019-10-06</created><authors><author><keyname>Shao</keyname><forenames>Z.</forenames></author><author><keyname>Landau</keyname><forenames>L.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Investigation of Channel Estimation Techniques with 1-bit Quantization
  and Oversampling for Multiple-Antenna Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale multiple-antenna systems have been identified as a promising
technology for the next generation of wireless systems. However, by scaling up
the number of receive antennas the energy consumption will also increase. One
possible solution is to use low-resolution analog-to-digital converters at the
receiver. This paper considers large-scale multiple-antenna uplink systems with
1-bit analog-to-digital converters on each receive antenna. Since oversampling
can partially compensate for the information loss caused by the coarse
quantization, the received signals are firstly oversampled by a factor M. We
then propose a low-resolution aware linear minimum mean-squared error channel
estimator for 1-bit oversampled systems. Moreover, we characterize analytically
the performance of the proposed channel estimator by deriving an upper bound on
the Bayesian Cram\'er-Rao bound. Numerical results are provided to illustrate
the performance of the proposed channel estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02451</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02451</id><created>2019-10-06</created><authors><author><keyname>Stern</keyname><forenames>Maike Lorena</forenames></author><author><keyname>Schellenberger</keyname><forenames>Martin</forenames></author></authors><title>Fully Convolutional Networks for Chip-wise Defect Detection Employing
  Photoluminescence Images</title><categories>eess.IV cs.CV</categories><comments>14 pages, 12 figures</comments><acm-class>J.2; I.2.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient quality control is inevitable in the manufacturing of
light-emitting diodes (LEDs). Because defective LED chips may be traced back to
different causes, a time and cost-intensive electrical and optical contact
measurement is employed. Fast photoluminescence measurements, on the other
hand, are commonly used to detect wafer separation damages but also hold the
potential to enable an efficient detection of all kinds of defective LED chips.
On a photoluminescence image, every pixel corresponds to an LED chip's
brightness after photoexcitation, revealing performance information. But due to
unevenly distributed brightness values and varying defect patterns,
photoluminescence images are not yet employed for a comprehensive defect
detection. In this work, we show that fully convolutional networks can be used
for chip-wise defect detection, trained on a small data-set of
photoluminescence images. Pixel-wise labels allow us to classify each and every
chip as defective or not. Being measurement-based, labels are easy to procure
and our experiments show that existing discrepancies between training images
and labels do not hinder network training. Using weighted loss calculation, we
were able to equalize our highly unbalanced class categories. Due to the
consistent use of skip connections and residual shortcuts, our network is able
to predict a variety of structures, from extensive defect clusters up to single
defective LED chips.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02500</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02500</id><created>2019-10-06</created><authors><author><keyname>Devonport</keyname><forenames>Alex</forenames></author><author><keyname>Arcak</keyname><forenames>Murat</forenames></author></authors><title>Data-Driven Reachable Set Computation using Adaptive Gaussian Process
  Classification and Monte Carlo Methods</title><categories>eess.SY cs.SY</categories><comments>11 pages, 5 figures, 1 table. Preprint of a submission to IEEE
  American Control Conference 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two data-driven methods for estimating reachable sets with
probabilistic guarantees. Both methods make use of a probabilistic formulation
allowing for a formal definition of a data-driven reachable set approximation
that is correct in a probabilistic sense. The first method recasts the
reachability problem as a binary classification problem, using a Gaussian
process classifier to represent the reachable set. The quantified uncertainty
of the Gaussian process model allows for an adaptive approach to the selection
of new sample points. The second method uses a Monte Carlo sampling approach to
compute an interval-based approximation of the reachable set. This method comes
with a guarantee of probabilistic correctness, and an explicit bound on the
number of sample points needed to achieve a desired accuracy and confidence.
Each method is illustrated with a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02526</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02526</id><created>2019-10-06</created><authors><author><keyname>Zheng</keyname><forenames>Yucheng</forenames></author><author><keyname>Asif</keyname><forenames>M. Salman</forenames></author></authors><title>Joint Image and Depth Estimation with Mask-Based Lensless Cameras</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mask-based lensless cameras replace the lens of a conventional camera with a
customized mask. These cameras can potentially be very thin and even flexible.
Recently, it has been demonstrated that such mask-based cameras can recover
light intensity and depth information of a scene. Existing depth recovery
algorithms either assume that the scene consists of a small number of depth
planes or solve a sparse recovery problem over a large 3D volume. Both these
approaches fail to recover scene with large depth variations. In this paper, we
propose a new approach for depth estimation based on alternating gradient
descent algorithm that jointly estimates a continuous depth map and light
distribution of the unknown scene from its lensless measurements. The
computational complexity of the algorithm scales linearly with the spatial
dimension of the imaging system. We present simulation results on image and
depth reconstruction for a variety of 3D test scenes. A comparison between the
proposed algorithm and other method shows that our algorithm is faster and more
robust for natural scenes with a large range of depths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02533</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02533</id><created>2019-10-06</created><authors><author><keyname>Cao</keyname><forenames>Haoyuan</forenames></author><author><keyname>Yu</keyname><forenames>Shining</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author></authors><title>Compressed Video Action Recognition with Refined Motion Vector</title><categories>eess.IV</categories><comments>8 pages, 3 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although CNN has reached satisfactory performance in image-related tasks,
using CNN to process videos is much more challenging due to the enormous size
of raw video streams. In this work, we propose to use motion vectors and
residuals from modern video compression techniques to effectively learn the
representation of the raw frames and greatly remove the temporal redundancy,
giving a faster video processing model. Compressed Video Action
Recognition(CoViAR) has explored to directly use compressed video to train the
deep neural network, where the motion vectors were utilized to present temporal
information. However, motion vector is designed for minimizing video size where
precise motion information is not obligatory. Compared with optical flow,
motion vectors contain noisy and unreliable motion information. Inspired by the
mechanism of video compression codecs, we propose an approach to refine the
motion vectors where unreliable movement will be removed while temporal
information is largely reserved. We prove that replacing the original motion
vector with refined one and using the same network as CoViAR has achieved
state-of-art performance on the UCF-101 and HMDB-51 with negligible efficiency
degrades comparing with original CoViAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02534</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02534</id><created>2019-10-06</created><authors><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author></authors><title>Fundamental limits of distributed tracking</title><categories>cs.IT cs.SY eess.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following communication scenario. A Gauss-Markov source is
observed by $K$ isolated observers via independent AWGN channels, who causally
compress their observations to transmit to the decoder via noiseless
rate-constrained links. At each time instant, the decoder receives $K$ new
codewords from the observers, combines them with the past received codewords,
and produces a minimum mean-square error running estimate of the source. This
is a causal version of the Gaussian CEO problem. We determine the minimum
asymptotically achievable sum rate required to achieve a given mean-square
error, which is stated as an optimization problem over $K$ parameters. We give
an explicit expression for the symmetrical case, and compute the limit of the
sum rate as $K \to \infty$, which turns out to be finite and nontrivial.
Furthermore, using a suboptimal waterfilling allocation among the $K$
parameters, we explicitly bound the loss due to a lack of cooperation among the
observers; that bound is attained with equality in the symmetrical case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02544</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02544</id><created>2019-10-06</created><authors><author><keyname>Liu</keyname><forenames>Haotian</forenames></author><author><keyname>Xi</keyname><forenames>Lin</forenames></author><author><keyname>Zhao</keyname><forenames>Ying</forenames></author><author><keyname>Li</keyname><forenames>Zhixiang</forenames></author></authors><title>Using Deep Learning and Machine Learning to Detect Epileptic Seizure
  with Electroencephalography (EEG) Data</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prediction of epileptic seizure has always been extremely challenging in
medical domain. However, as the development of computer technology, the
application of machine learning introduced new ideas for seizure forecasting.
Applying machine learning model onto the predication of epileptic seizure could
help us obtain a better result and there have been plenty of scientists who
have been doing such works so that there are sufficient medical data provided
for researchers to do training of machine learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02546</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02546</id><created>2019-10-06</created><authors><author><keyname>Nguyen</keyname><forenames>Du</forenames></author></authors><title>A theorem of Kalman and minimal state-space realization of Vector
  Autoregressive Models</title><categories>math.ST cs.SY eess.SY math.AG q-fin.ST stat.TH</categories><msc-class>93C05, 93C35, 93E12, 62J05, 91B84, 62M10, 62N02, 14J60, 14L30,
  14M15, 62H20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a concept of $autoregressive$ (AR)state-space realization that
could be applied to all transfer functions $\boldsymbol{T}(L)$ with
$\boldsymbol{T}(0)$ invertible. We show that a theorem of Kalman implies each
Vector Autoregressive model (with exogenous variables) has a minimal
$AR$-state-space realization of form $\boldsymbol{y}_t =
\sum_{i=1}^p\boldsymbol{H}\boldsymbol{F}^{i-1}\boldsymbol{G}\boldsymbol{x}_{t-i}+\boldsymbol{\epsilon}_t$
where $\boldsymbol{F}$ is a nilpotent Jordan matrix and $\boldsymbol{H},
\boldsymbol{G}$ satisfy certain rank conditions. The case $VARX(1)$ corresponds
to reduced-rank regression. Similar to that case, for a fixed Jordan form
$\boldsymbol{F}$, $\boldsymbol{H}$ could be estimated by least square as a
function of $\boldsymbol{G}$. The likelihood function is a determinant ratio
generalizing the Rayleigh quotient. It is unchanged if $\boldsymbol{G}$ is
replaced by $\boldsymbol{S}\boldsymbol{G}$ for an invertible matrix
$\boldsymbol{S}$ commuting with $\boldsymbol{F}$. Using this invariant
property, the search space for maximum likelihood estimate could be constrained
to equivalent classes of matrices satisfying a number of orthogonal relations,
extending the results in reduced-rank analysis. Our results could be considered
a multi-lag canonical-correlation-analysis. The method considered here provides
a solution in the general case to the polynomial product regression model of
Velu et. al. We provide estimation examples. We also explore how the estimates
vary with different Jordan matrix configurations and discuss methods to select
a configuration. Our approach could provide an important dimensional reduction
technique with potential applications in time series analysis and linear system
identification. In the appendix, we link the reduced configuration space of
$\boldsymbol{G}$ with a geometric object called a vector bundle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02550</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02550</id><created>2019-10-06</created><updated>2019-10-14</updated><authors><author><keyname>Sajjan</keyname><forenames>Shreeyak S.</forenames></author><author><keyname>Moore</keyname><forenames>Matthew</forenames></author><author><keyname>Pan</keyname><forenames>Mike</forenames></author><author><keyname>Nagaraja</keyname><forenames>Ganesh</forenames></author><author><keyname>Lee</keyname><forenames>Johnny</forenames></author><author><keyname>Zeng</keyname><forenames>Andy</forenames></author><author><keyname>Song</keyname><forenames>Shuran</forenames></author></authors><title>ClearGrasp: 3D Shape Estimation of Transparent Objects for Manipulation</title><categories>cs.CV cs.RO eess.IV</categories><comments>Project Website: https://sites.google.com/view/cleargrasp, 13 pages,
  13 figures, submitted to ICRA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transparent objects are a common part of everyday life, yet they possess
unique visual properties that make them incredibly difficult for standard 3D
sensors to produce accurate depth estimates for. In many cases, they often
appear as noisy or distorted approximations of the surfaces that lie behind
them. To address these challenges, we present ClearGrasp -- a deep learning
approach for estimating accurate 3D geometry of transparent objects from a
single RGB-D image for robotic manipulation. Given a single RGB-D image of
transparent objects, ClearGrasp uses deep convolutional networks to infer
surface normals, masks of transparent surfaces, and occlusion boundaries. It
then uses these outputs to refine the initial depth estimates for all
transparent surfaces in the scene. To train and test ClearGrasp, we construct a
large-scale synthetic dataset of over 50,000 RGB-D images, as well as a
real-world test benchmark with 286 RGB-D images of transparent objects and
their ground truth geometries. The experiments demonstrate that ClearGrasp is
substantially better than monocular depth estimation baselines and is capable
of generalizing to real-world images and novel objects. We also demonstrate
that ClearGrasp can be applied out-of-the-box to improve grasping algorithms'
performance on transparent objects. Code, data, and benchmarks will be
released. Supplementary materials available on the project website:
https://sites.google.com/view/cleargrasp
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02556</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02556</id><created>2019-10-03</created><authors><author><keyname>Wang</keyname><forenames>Tixian</forenames></author><author><keyname>Taghvaei</keyname><forenames>Amirhossein</forenames></author><author><keyname>Mehta</keyname><forenames>Prashant G.</forenames></author></authors><title>Bio-inspired Learning of Sensorimotor Control for Locomotion</title><categories>eess.SY cs.SY</categories><comments>8 pages, 8 figures, submitted to The 2020 American Control
  Conference. arXiv admin note: text overlap with arXiv:1910.00107</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a bio-inspired central pattern generator (CPG)-type
architecture for learning optimal maneuvering control of periodic locomotory
gaits. The architecture is presented here with the aid of a snake robot model
problem involving planar locomotion of coupled rigid body systems. The maneuver
involves clockwise or counterclockwise turning from a nominally straight path.
The CPG circuit is realized as a coupled oscillator feedback particle filter.
The collective dynamics of the filter are used to approximate a posterior
distribution that is used to construct the optimal control input for
maneuvering the robot. A Q-learning algorithm is applied to learn the
approximate optimal control law. The issues surrounding the parametrization of
the Q-function are discussed. The theoretical results are illustrated with
numerics for a 5-link snake robot system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02564</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02564</id><created>2019-10-06</created><authors><author><keyname>Nunes</keyname><forenames>Manuel Serra</forenames></author><author><keyname>Dehban</keyname><forenames>Atabak</forenames></author><author><keyname>Moreno</keyname><forenames>Plinio</forenames></author><author><keyname>Santos-Victor</keyname><forenames>Jos&#xe9;</forenames></author></authors><title>Action-conditioned Benchmarking of Robotic Video Prediction Models: a
  Comparative Study</title><categories>cs.CV cs.RO eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A defining characteristic of intelligent systems is the ability to make
action decisions based on the anticipated outcomes. Video prediction systems
have been demonstrated as a solution for predicting how the future will unfold
visually, and thus, many models have been proposed that are capable of
predicting future frames based on a history of observed frames~(and sometimes
robot actions). However, a comprehensive method for determining the fitness of
different video prediction models at guiding the selection of actions is yet to
be developed. Current metrics assess video prediction models based on human
perception of frame quality. In contrast, we argue that if these systems are to
be used to guide action, necessarily, the actions the robot performs should be
encoded in the predicted frames. In this paper, we are proposing a new metric
to compare different video prediction models based on this argument. More
specifically, we propose an action inference system and quantitatively rank
different models based on how well we can infer the robot actions from the
predicted frames. Our extensive experiments show that models with high
perceptual scores can perform poorly in the proposed action inference tests and
thus, may not be suitable options to be used in robot planning systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02579</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02579</id><created>2019-10-06</created><authors><author><keyname>Hasan</keyname><forenames>Md Kamrul</forenames></author><author><keyname>Sakib</keyname><forenames>Nazmus</forenames></author><author><keyname>Field</keyname><forenames>Joshua</forenames></author><author><keyname>Love</keyname><forenames>Richard R.</forenames></author><author><keyname>Ahamed</keyname><forenames>Sheikh I.</forenames></author></authors><title>A Novel Technique of Noninvasive Hemoglobin Level Measurement Using HSV
  Value of Fingertip Image</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Over the last decade, smartphones have changed radically to support us with
mHealth technology, cloud computing, and machine learning algorithm. Having its
multifaceted facilities, we present a novel smartphone-based noninvasive
hemoglobin (Hb) level prediction model by analyzing hue, saturation and value
(HSV) of a fingertip video. Here, we collect 60 videos of 60 subjects from two
different locations: Blood Center of Wisconsin, USA and AmaderGram, Bangladesh.
We extract red, green, and blue (RGB) pixel intensities of selected images of
those videos captured by the smartphone camera with flash on. Then we convert
RGB values of selected video frames of a fingertip video into HSV color space
and we generate histogram values of these HSV pixel intensities. We average
these histogram values of a fingertip video and consider as an observation
against the gold standard Hb concentration. We generate two input feature
matrices based on observation of two different data sets. Partial Least Squares
(PLS) algorithm is applied on the input feature matrix. We observe R2=0.95 in
both data sets through our research. We analyze our data using Python OpenCV,
Matlab, and R statistics tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02593</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02593</id><created>2019-10-06</created><updated>2019-10-13</updated><authors><author><keyname>Han</keyname><forenames>Zhen</forenames></author><author><keyname>Dai</keyname><forenames>Enyan</forenames></author><author><keyname>Jia</keyname><forenames>Xu</forenames></author><author><keyname>Ren</keyname><forenames>Xiaoying</forenames></author><author><keyname>Chen</keyname><forenames>Shuaijun</forenames></author><author><keyname>Xu</keyname><forenames>Chunjing</forenames></author><author><keyname>Liu</keyname><forenames>Jianzhuang</forenames></author><author><keyname>Tian</keyname><forenames>Qi</forenames></author></authors><title>Unsupervised Image Super-Resolution with an Indirect Supervised Path</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of single image super-resolution (SISR) aims at reconstructing a
high-resolution (HR) image from a low-resolution (LR) image. Although
significant progress has been made by deep learning models, they are trained on
synthetic paired data in a supervised way and do not perform well on real data.
There are several attempts that directly apply unsupervised image translation
models to address such a problem. However, unsupervised low-level vision
problem poses more challenge on the accuracy of translation. In this work,we
propose a novel framework which is composed of two stages: 1) unsupervised
image translation between real LR images and synthetic LR images; 2) supervised
super-resolution from approximated real LR images to HR images. It takes the
synthetic LR images as a bridge and creates an indirect supervised path from
real LR images to HR images. Any existed deep learning based image
super-resolution model can be integrated into the second stage of the proposed
framework for further improvement. In addition it shows great flexibility in
balancing between distortion and perceptual quality under unsupervised setting.
The proposed method is evaluated on both NTIRE 2017 and 2018 challenge datasets
and achieves favorable performance against supervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02646</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02646</id><created>2019-10-07</created><updated>2019-10-08</updated><authors><author><keyname>Mukadam</keyname><forenames>Mustafa</forenames></author><author><keyname>Cheng</keyname><forenames>Ching-An</forenames></author><author><keyname>Fox</keyname><forenames>Dieter</forenames></author><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Ratliff</keyname><forenames>Nathan</forenames></author></authors><title>Riemannian Motion Policy Fusion through Learnable Lyapunov Function
  Reshaping</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY</categories><comments>Conference on Robot Learning (CoRL), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RMPflow is a recently proposed policy-fusion framework based on differential
geometry. While RMPflow has demonstrated promising performance, it requires the
user to provide sensible subtask policies as Riemannian motion policies (RMPs:
a motion policy and an importance matrix function), which can be a difficult
design problem in its own right. We propose RMPfusion, a variation of RMPflow,
to address this issue. RMPfusion supplements RMPflow with weight functions that
can hierarchically reshape the Lyapunov functions of the subtask RMPs according
to the current configuration of the robot and environment. This extra
flexibility can remedy imperfect subtask RMPs provided by the user, improving
the combined policy's performance. These weight functions can be learned by
back-propagation. Moreover, we prove that, under mild restrictions on the
weight functions, RMPfusion always yields a globally Lyapunov-stable motion
policy. This implies that we can treat RMPfusion as a structured policy class
in policy optimization that is guaranteed to generate stable policies, even
during the immature phase of learning. We demonstrate these properties of
RMPfusion in imitation learning experiments both in simulation and on a
real-world robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02672</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02672</id><created>2019-10-07</created><updated>2019-12-14</updated><authors><author><keyname>Qiu</keyname><forenames>Wei</forenames></author><author><keyname>Guo</keyname><forenames>Jiaming</forenames></author><author><keyname>Li</keyname><forenames>Xiang</forenames></author><author><keyname>Xu</keyname><forenames>Mengjia</forenames></author><author><keyname>Zhang</keyname><forenames>Mo</forenames></author><author><keyname>Guo</keyname><forenames>Ning</forenames></author><author><keyname>Li</keyname><forenames>Quanzheng</forenames></author></authors><title>Multi-label Detection and Classification of Red Blood Cells in
  Microscopic Images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Wei Qiu, Jiaming Guo and Xiang Li contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cell detection and cell type classification from biomedical images play an
important role for high-throughput imaging and various clinical application.
While classification of single cell sample can be performed with standard
computer vision and machine learning methods, analysis of multi-label samples
(region containing congregating cells) is more challenging, as separation of
individual cells can be difficult (e.g. touching cells) or even impossible
(e.g. overlapping cells). As multi-instance images are common in analyzing Red
Blood Cell (RBC) for Sickle Cell Disease (SCD) diagnosis, we develop and
implement a multi-instance cell detection and classification framework to
address this challenge. The framework firstly trains a region proposal model
based on Region-based Convolutional Network (RCNN) to obtain bounding-boxes of
regions potentially containing single or multiple cells from input microscopic
images, which are extracted as image patches. High-level image features are
then calculated from image patches through a pre-trained Convolutional Neural
Network (CNN) with ResNet-50 structure. Using these image features inputs, six
networks are then trained to make multi-label prediction of whether a given
patch contains cells belonging to a specific cell type. As the six networks are
trained with image patches consisting of both individual cells and
touching/overlapping cells, they can effectively recognize cell types that are
presented in multi-instance image samples. Finally, for the purpose of SCD
testing, we train another machine learning classifier to predict whether the
given image patch contains abnormal cell type based on outputs from the six
networks. Testing result of the proposed framework shows that it can achieve
good performance in automatic cell detection and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02692</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02692</id><created>2019-10-07</created><authors><author><keyname>Ma</keyname><forenames>Jingying</forenames></author><author><keyname>Du</keyname><forenames>Jinming</forenames></author><author><keyname>Zheng</keyname><forenames>Yuanshi</forenames></author></authors><title>Game-based coalescence over multi-agent systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalescence, as a kind of ubiquitous group behavior in the nature and
society, means that agents, companies or other substances keep consensus in
states and act as a whole. This paper considers coalescence for n rational
agents with distinct initial states. Considering the rationality and
intellectuality of the population, the coalescing process is described by a
bimatrix game which has the unique mixed strategy Nash equilibrium solution.
Since the process is not an independent stochastic process, it is difficult to
analyze the coalescing process. By using the first Borel-Cantelli Lemma, we
prove that all agents will coalesce into one group with probability one.
Moreover, the expected coalescence time is also evaluated. For the scenario
where payoff functions are power functions, we obtain the distribution and
expected value of coalescence time. Finally, simulation examples are provided
to validate the effectiveness of the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02696</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02696</id><created>2019-10-07</created><authors><author><keyname>Koolstra</keyname><forenames>Kirsten</forenames></author><author><keyname>B&#xf6;rnert</keyname><forenames>Peter</forenames></author><author><keyname>Lelieveldt</keyname><forenames>Boudewijn</forenames></author><author><keyname>Webb</keyname><forenames>Andrew</forenames></author><author><keyname>Dzyubachyk</keyname><forenames>Oleh</forenames></author></authors><title>Hierarchical stochastic neighbor embedding as a tool for visualizing the
  encoding capability of magnetic resonance fingerprinting dictionaries</title><categories>eess.IV cs.CV</categories><comments>12 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Magnetic Resonance Fingerprinting (MRF) the quality of the estimated
parameter maps depends on the encoding capability of the variable flip angle
train. In this work we show how the dimensionality reduction technique
Hierarchical Stochastic Neighbor Embedding (HSNE) can be used to obtain insight
into the encoding capability of different MRF sequences. Embedding
high-dimensional MRF dictionaries into a lower-dimensional space and
visualizing them with colors, being a surrogate for location in low-dimensional
space, provides a comprehensive overview of particular dictionaries and, in
addition, enables comparison of different sequences. Dictionaries for various
sequences and sequence lengths were compared to each other, and the effect of
transmit field variations on the encoding capability was assessed. Clear
differences in encoding capability were observed between different sequences,
and HSNE results accurately reflect those obtained from an MRF matching
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02702</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02702</id><created>2019-10-07</created><authors><author><keyname>Manakov</keyname><forenames>Ilja</forenames></author><author><keyname>Rohm</keyname><forenames>Markus</forenames></author><author><keyname>Kern</keyname><forenames>Christoph</forenames></author><author><keyname>Schworm</keyname><forenames>Benedikt</forenames></author><author><keyname>Kortuem</keyname><forenames>Karsten</forenames></author><author><keyname>Tresp</keyname><forenames>Volker</forenames></author></authors><title>Noise as Domain Shift: Denoising Medical Images by Unpaired Image
  Translation</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1007/978-3-030-33391-1_1</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We cast the problem of image denoising as a domain translation problem
between high and low noise domains. By modifying the cycleGAN model, we are
able to learn a mapping between these domains on unpaired retinal optical
coherence tomography images. In quantitative measurements and a qualitative
evaluation by ophthalmologists, we show how this approach outperforms other
established methods. The results indicate that the network differentiates
subtle changes in the level of noise in the image. Further investigation of the
model's feature maps reveals that it has learned to distinguish retinal layers
and other distinct regions of the images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02709</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02709</id><created>2019-10-07</created><authors><author><keyname>Alves</keyname><forenames>M.</forenames></author><author><keyname>Coelho</keyname><forenames>R.</forenames></author><author><keyname>Dranka</keyname><forenames>E.</forenames></author></authors><title>Effective Acoustic Energy Sensing Exploitation for Target Sources
  Localization in Urban Acoustic Scenes</title><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This letter proposes a new approach to improve the accuracy of the
Energy-based source localization methods in urban acoustic scenes. The proposed
acoustic energy sensing flow estimation (ESFE) uses the sensors signal
nonstationarity degree to determine the area with highest energy concentration
in the scenes. The ESFE is applied to different acoustic scenes and yields to
source localization accuracy improvement with computational complexity
reduction. The experiments results show that the proposed scheme leads to
significant improvement in source localization accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02710</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02710</id><created>2019-10-07</created><authors><author><keyname>Medina</keyname><forenames>C.</forenames></author><author><keyname>Coelho</keyname><forenames>R.</forenames></author></authors><title>Impulsive Noise Detection for Intelligibility and Quality Improvement of
  Speech Enhancement Methods Applied in Time-Domain</title><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This letter introduces a novel speech enhancement method in the Hilbert-Huang
Transform domain to mitigate the effects of acoustic impulsive noises. The
estimation and selection of noise components is based on the impulsiveness
index of decomposition modes. Speech enhancement experiments are conducted
considering five acoustic noises with different impulsiveness index and
non-stationarity degrees under various signal-to-noise ratios. Three speech
enhancement algorithms are adopted as baseline in the evaluation analysis
considering spectral and time domains. The proposed solution achieves the best
results in terms of objective quality measures and similar speech
intelligibility rates to the competitive methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02712</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02712</id><created>2019-10-07</created><authors><author><keyname>Zucatelli</keyname><forenames>G.</forenames></author><author><keyname>Coelho</keyname><forenames>R.</forenames></author></authors><title>Adaptive Reverberation Absorption using Non-stationary Masking
  Components Detection for Intelligibility Improvement</title><categories>eess.AS cs.SD</categories><doi>10.1109/LSP.2019.2950618</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This letter proposes a new time domain absorption approach designed to reduce
masking components of speech signals under noisy-reverberant conditions. In
this method, the non-stationarity of corrupted signal segments is used to
detect masking distortions based on a defined threshold. The nonstationarity is
objectively measured and is also adopted to determine the absorption procedure.
Additionally, no prior knowledge of speech statistics or of the room
information is required for this technique. Three intelligibility measures
(ESII, ASIIST, SRMRnorm) and a perceptual listening test are used for
evaluation. The experiments results show that the proposed scheme leads to a
higher intelligibility improvement when compared to competing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02713</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02713</id><created>2019-10-07</created><authors><author><keyname>Manakov</keyname><forenames>Ilja</forenames></author><author><keyname>Tresp</keyname><forenames>Volker</forenames></author></authors><title>Push it to the Limit: Discover Edge-Cases in Image Data with
  Autoencoders</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted as a workshop paper at MEDNeurIPS 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we focus on the problem of identifying semantic factors of
variation in large image datasets. By training a convolutional Autoencoder on
the image data, we create encodings, which describe each datapoint at a higher
level of abstraction than pixel-space. We then apply Principal Component
Analysis to the encodings to disentangle the factors of variation in the data.
Sorting the dataset according to the values of individual principal components,
we find that samples at the high and low ends of the distribution often share
specific semantic characteristics. We refer to these groups of samples as
semantic groups. When applied to real-world data, this method can help discover
unwanted edge-cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02717</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02717</id><created>2019-10-07</created><updated>2020-01-30</updated><authors><author><keyname>Giacomello</keyname><forenames>Edoardo</forenames></author><author><keyname>Loiacono</keyname><forenames>Daniele</forenames></author><author><keyname>Mainardi</keyname><forenames>Luca</forenames></author></authors><title>Brain MRI Tumor Segmentation with Adversarial Networks</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Learning is a promising approach to either automate or simplify several
tasks in the healthcare domain. In this work, we introduce SegAN-CAT, an
approach to brain tumor segmentation in Magnetic Resonance Images (MRI), based
on Adversarial Networks. In particular, we extend SegAN, successfully applied
to the same task in a previous work, in two respects: (i) we used a different
model input and (ii) we employed a modified loss function to train the model.
We tested our approach on two large datasets, made available by the Brain Tumor
Image Segmentation Benchmark (BraTS). First, we trained and tested some
segmentation models assuming the availability of all the major MRI contrast
modalities, i.e., T1-weighted, T1 weighted contrast-enhanced, T2-weighted, and
T2-FLAIR. However, as these four modalities are not always all available for
each patient, we also trained and tested four segmentation models that take as
input MRIs acquired only with a single contrast modality. Finally, we proposed
to apply transfer learning across different contrast modalities to improve the
performance of these single-modality models. Our results are promising and show
that not SegAN-CAT is able to outperform SegAN when all the four modalities are
available, but also that transfer learning can actually lead to better
performances when only a single modality is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02738</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02738</id><created>2019-10-07</created><authors><author><keyname>Islam</keyname><forenames>Bipul</forenames></author><author><keyname>Liu</keyname><forenames>Ji</forenames></author><author><keyname>Yezzi</keyname><forenames>Anthony</forenames></author><author><keyname>Sandhu</keyname><forenames>Romeil</forenames></author></authors><title>An Interactive Control Approach to 3D Shape Reconstruction</title><categories>cs.CV cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to accurately reconstruct the 3D facets of a scene is one of the
key problems in robotic vision. However, even with recent advances with machine
learning, there is no high-fidelity universal 3D reconstruction method for this
optimization problem as schemes often cater to specific image modalities and
are often biased by scene abnormalities. Simply put, there always remains an
information gap due to the dynamic nature of real-world scenarios. To this end,
we demonstrate a feedback control framework which invokes operator inputs (also
prone to errors) in order to augment existing reconstruction schemes. For
proof-of-concept, we choose a classical region-based stereoscopic
reconstruction approach and show how an ill-posed model can be augmented with
operator input to be much more robust to scene artifacts. We provide necessary
conditions for stability via Lyapunov analysis and perhaps more importantly, we
show that the stability depends on a notion of absolute curvature.
Mathematically, this aligns with previous work that has shown Ricci curvature
as proxy for functional robustness of dynamical networked systems. We conclude
with results that show how our method can improve standalone reconstruction
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02744</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02744</id><created>2019-10-07</created><updated>2019-10-13</updated><authors><author><keyname>Zhao</keyname><forenames>Dongwei</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Lin</keyname><forenames>Xiaojun</forenames></author></authors><title>Storage or No Storage: Duopoly Competition Between Renewable Energy
  Suppliers in a Local Energy Market</title><categories>eess.SY cs.GT cs.SY</categories><comments>This is the online appendix for the paper published in IEEE Journal
  on Selected Areas in Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the duopoly competition between renewable energy suppliers
with or without energy storage in a local energy market. The storage investment
brings the benefits of stabilizing renewable energy suppliers' outputs, but it
also leads to substantial investment costs as well as some surprising changes
in the market outcome. To study the equilibrium decisions of storage investment
in the renewable energy suppliers' competition, we model the interactions
between suppliers and consumers using a three-stage game-theoretic model. In
Stage I, at the beginning of the investment horizon, suppliers decide whether
to invest in storage. Once such decisions have been made, in the day-ahead
market of each day, suppliers decide on their bidding prices and quantities in
Stage II, based on which consumers decide the electricity quantity purchased
from each supplier in Stage III. In the real-time market, a supplier is
penalized if his actual generation falls short of his commitment. We
characterize a price-quantity competition equilibrium of Stage II, and we
further characterize a storage-investment equilibrium in Stage I incorporating
electricity-selling revenue and storage cost. Counter-intuitively, we show that
the uncertainty of renewable energy without storage investment can lead to
higher supplier profits compared with the stable generations with storage
investment due to the reduced market competition under random energy
generation. Simulations further illustrate results due to the market
competition. For example, a higher penalty for not meeting the commitment, a
higher storage cost, or a lower consumer demand can sometimes increase a
supplier's profit. We also show that although storage investment can increase a
supplier 's profit, the first-mover supplier who invests in storage may benefit
less than the free-rider competitor who chooses not to invest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02773</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02773</id><created>2019-10-04</created><authors><author><keyname>Chang</keyname><forenames>Taean</forenames></author><author><keyname>Shin</keyname><forenames>Seungwoo</forenames></author><author><keyname>Lee</keyname><forenames>Moosung</forenames></author><author><keyname>Park</keyname><forenames>YongKeun</forenames></author></authors><title>Computational Approach to Dark-Field Optical Diffraction Tomography</title><categories>eess.IV physics.bio-ph physics.optics</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The measurement of three-dimensional (3D) images and the analysis of
subcellular organelles are crucial for the study of the pathophysiology of
cells and tissues. Optical diffraction tomography (ODT) facilitates label-free
and quantitative imaging of live cells by reconstructing 3D refractive index
(RI) distributions. In many cases, however, the contrast in RI distributions is
not strong enough to effectively distinguish subcellular organelles in live
cells. To realize label-free and quantitative imaging of subcellular organelles
in unlabeled live cells with enhanced contrasts, we present a computational
approach using ODT. We demonstrate that the contrast of ODT can be enhanced via
spatial high-pass filtering in a 3D spatial frequency domain, and that it
yields theoretically equivalent results to physical dark-field illumination.
Without changing the optical instruments used in ODT, subcellular organelles in
live cells are clearly distinguished by applying a simple but effective
computational approach that is validated by comparison with 3D epifluorescence
images. We expect that the proposed method will satisfy the demand for
label-free organelle observations, and will be extended to fully utilize
complex information in 3D RI distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02785</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02785</id><created>2019-10-03</created><authors><author><keyname>Nguyen</keyname><forenames>Phuong Ha</forenames></author><author><keyname>Mahmood</keyname><forenames>Kaleel</forenames></author><author><keyname>Nguyen</keyname><forenames>Lam M.</forenames></author><author><keyname>Nguyen</keyname><forenames>Thanh</forenames></author><author><keyname>van Dijk</keyname><forenames>Marten</forenames></author></authors><title>BUZz: BUffer Zones for defending adversarial examples in image
  classification</title><categories>cs.LG cs.CR eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel defense against all existing gradient based adversarial
attacks on deep neural networks for image classification problems. Our defense
is based on a combination of deep neural networks and simple image
transformations. While straight forward in implementation, this defense yields
a unique security property which we term buffer zones. In this paper, we
formalize the concept of buffer zones. We argue that our defense based on
buffer zones is secure against state-of-the-art black box attacks. We are able
to achieve this security even when the adversary has access to the {\em entire}
original training data set and unlimited query access to the defense. We verify
our security claims through experimentation using FashionMNIST, CIFAR-10 and
CIFAR-100. We demonstrate $&lt;10\%$ attack success rate -- significantly lower
than what other well-known defenses offer -- at only a price of a 15-20\% drop
in clean accuracy. By using a new intuitive metric we explain why this
trade-off offers a significant improvement over prior work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02793</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02793</id><created>2019-10-07</created><authors><author><keyname>Ganesh</keyname><forenames>Madan Ravi</forenames></author><author><keyname>Hofesmann</keyname><forenames>Eric</forenames></author><author><keyname>Louis</keyname><forenames>Nathan</forenames></author><author><keyname>Corso</keyname><forenames>Jason</forenames></author></authors><title>ViP: Video Platform for PyTorch</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents the Video Platform for PyTorch (ViP), a deep
learning-based framework designed to handle and extend to any problem domain
based on videos. ViP supports (1) a single unified interface applicable to all
video problem domains, (2) quick prototyping of video models, (3) executing
large-batch operations with reduced memory consumption, and (4) easy and
reproducible experimental setups. ViP's core functionality is built with
flexibility and modularity in mind to allow for smooth data flow between
different parts of the platform and benchmarking against existing methods. In
providing a software platform that supports multiple video-based problem
domains, we allow for more cross-pollination of models, ideas and stronger
generalization in the video understanding research community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02844</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02844</id><created>2019-10-07</created><authors><author><keyname>Cheong</keyname><forenames>Haris</forenames></author><author><keyname>Devalla</keyname><forenames>Sripad Krishna</forenames></author><author><keyname>Pham</keyname><forenames>Tan Hung</forenames></author><author><keyname>Liang</keyname><forenames>Zhang</forenames></author><author><keyname>Tun</keyname><forenames>Tin Aung</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Perera</keyname><forenames>Shamira</forenames></author><author><keyname>Schmetterer</keyname><forenames>Leopold</forenames></author><author><keyname>Tin</keyname><forenames>Aung</forenames></author><author><keyname>Boote</keyname><forenames>Craig</forenames></author><author><keyname>Thiery</keyname><forenames>Alexandre H.</forenames></author><author><keyname>Girard</keyname><forenames>Michael J. A.</forenames></author></authors><title>DeshadowGAN: A Deep Learning Approach to Remove Shadows from Optical
  Coherence Tomography Images</title><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Purpose: To remove retinal shadows from optical coherence tomography (OCT)
images of the optic nerve head(ONH).
  Methods:2328 OCT images acquired through the center of the ONH using a
Spectralis OCT machine for both eyes of 13 subjects were used to train a
generative adversarial network (GAN) using a custom loss function. Image
quality was assessed qualitatively (for artifacts) and quantitatively using the
intralayer contrast: a measure of shadow visibility ranging from 0
(shadow-free) to 1 (strong shadow) and compared to compensated images. This was
computed in the Retinal Nerve Fiber Layer (RNFL), the Inner Plexiform Layer
(IPL), the Photoreceptor layer (PR) and the Retinal Pigment Epithelium (RPE)
layers.
  Results: Output images had improved intralayer contrast in all ONH tissue
layers. On average the intralayer contrast decreased by 33.7$\pm$6.81%,
28.8$\pm$10.4%, 35.9$\pm$13.0%, and43.0$\pm$19.5%for the RNFL, IPL, PR, and RPE
layers respectively, indicating successful shadow removal across all depths.
This compared to 70.3$\pm$22.7%, 33.9$\pm$11.5%, 47.0$\pm$11.2%,
26.7$\pm$19.0%for compensation. Output images were also free from artifacts
commonly observed with compensation.
  Conclusions: DeshadowGAN significantly corrected blood vessel shadows in OCT
images of the ONH. Our algorithm may be considered as a pre-processing step to
improve the performance of a wide range of algorithms including those currently
being used for OCT image segmentation, denoising, and classification.
  Translational Relevance: DeshadowGAN could be integrated to existing OCT
devices to improve the diagnosis and prognosis of ocular pathologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02860</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02860</id><created>2019-10-02</created><updated>2019-10-24</updated><authors><author><keyname>She</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Shaoxiong</forenames></author><author><keyname>Dong</keyname><forenames>Siyuan</forenames></author><author><keyname>Sunil</keyname><forenames>Neha</forenames></author><author><keyname>Rodriguez</keyname><forenames>Alberto</forenames></author><author><keyname>Adelson</keyname><forenames>Edward</forenames></author></authors><title>Cable Manipulation with a Tactile-Reactive Gripper</title><categories>cs.RO cs.SY eess.IV eess.SY</categories><comments>submitted to ICRA2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manipulation of flexible cables is relevant to both industrial and household
environments. In this paper, we develop a perception and control framework to
enable robots to accomplish the task of following a cable. We rely on a
vision-based tactile sensor, GelSight, to estimate the pose of the cable in the
grip as well as the friction forces during cable sliding. We decompose the
behavior of cable following into two tactile-based controllers: 1) Cable grip
controller, where a PD controller combined with a leaky integrator are
responsible for regulating the gripping force to maintain the frictional
sliding forces close to a suitable value; and 2) Cable pose controller, where
an LQR controller based on a learned linear model of the cable sliding dynamics
is in charge of keeping the cable centered and aligned on the fingertips to
prevent the cable from falling. This behavior is enabled by a designed reactive
gripper with force and position control capabilities fitted with GelSight-based
high resolution tactile sensors. With the proposed framework, we show that the
robot can follow one meter of cable in a random configuration from beginning to
end within 2-3 hand regrasps. We further demonstrate that the closed-loop
system adapts to cables with different materials and thicknesses, moving at
different target velocities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02900</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02900</id><created>2019-10-07</created><updated>2019-11-02</updated><authors><author><keyname>Alrabeiah</keyname><forenames>Muhammad</forenames></author><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author></authors><title>Deep Learning for mmWave Beam and Blockage Prediction Using Sub-6GHz
  Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Communications. The code files and
  datasets are available at http://www.deepmimo.net/DeepMIMO_applications.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the millimeter wave (mmWave) beams and blockages using sub-6GHz
channels has the potential of enabling mobility and reliability in scalable
mmWave systems. These gains attracted increasing interest in the last few
years. Prior work, however, has focused on extracting spatial channel
characteristics at the sub-6GHz band first and then use them to reduce the
mmWave beam training overhead. This approach has a number of limitations: (i)
It still requires a beam search at mmWave, (ii) its performance is sensitive to
the error associated with extracting the sub-6GHz channel characteristics, and
(iii) it does not normally account for the different dielectric properties at
the different bands. In this paper, we first prove that under certain
conditions, there exist mapping functions that can predict the optimal mmWave
beam and correct blockage status directly from the sub-6GHz channel, which
overcome the limitations in prior work. These mapping functions, however, are
hard to characterize analytically which motivates exploiting deep neural
network models to learn them. For that, we prove that a large enough neural
network can use the sub-6GHz channel to directly predict the optimal mmWave
beam and the correct blockage status with success probabilities that can be
made arbitrarily close to one. Then, we develop an efficient deep learning
model and empirically evaluate its beam/blockage prediction performance using
the publicly available dataset DeepMIMO. The results show that the proposed
solution can predict the mmWave blockages with more than 90$\%$ success
probability. Further, these results confirm the capability of the proposed deep
learning model in predicting the optimal mmWave beams and approaching the
optimal data rates, that assume perfect channel knowledge, while requiring no
beam training overhead...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02923</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02923</id><created>2019-10-07</created><authors><author><keyname>Budd</keyname><forenames>Samuel</forenames></author><author><keyname>Robinson</keyname><forenames>Emma C</forenames></author><author><keyname>Kainz</keyname><forenames>Bernhard</forenames></author></authors><title>A Survey on Active Learning and Human-in-the-Loop Deep Learning for
  Medical Image Analysis</title><categories>cs.LG cs.CV cs.HC eess.IV</categories><comments>submitted to Medical Image Analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully automatic deep learning has become the state-of-the-art technique for
many tasks including image acquisition, analysis and interpretation, and for
the extraction of clinically useful information for computer-aided detection,
diagnosis, treatment planning, intervention and therapy. However, the unique
challenges posed by medical image analysis suggest that retaining a human
end-user in any deep learning enabled system will be beneficial. In this review
we investigate the role that humans might play in the development and
deployment of deep learning enabled diagnostic applications and focus on
techniques that will retain a significant input from a human end user.
Human-in-the-Loop computing is an area that we see as increasingly important in
future research due to the safety-critical nature of working in the medical
domain. We evaluate four key areas that we consider vital for deep learning in
the clinical practice: (1) Active Learning - to choose the best data to
annotate for optimal model performance; (2) Interpretation and Refinement -
using iterative feedback to steer models to optima for a given prediction and
offering meaningful ways to interpret and respond to predictions; (3) Practical
considerations - developing full scale applications and the key considerations
that need to be made before deployment; (4) Related Areas - research fields
that will benefit human-in-the-loop computing as they evolve. We offer our
opinions on the most promising directions of research and how various aspects
of each area might be unified towards common goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02935</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02935</id><created>2019-10-07</created><authors><author><keyname>Gasimova</keyname><forenames>Aydan</forenames></author></authors><title>Automated Enriched Medical Concept Generation for Chest X-ray Images</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>MICCAI ML-CDS Workshop 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decision support tools that rely on supervised learning require large amounts
of expert annotations. Using past radiological reports obtained from hospital
archiving systems has many advantages as training data above manual
single-class labels: they are expert annotations available in large quantities,
covering a population-representative variety of pathologies, and they provide
additional context to pathology diagnoses, such as anatomical location and
severity. Learning to auto-generate such reports from images present many
challenges such as the difficulty in representing and generating long,
unstructured textual information, accounting for spelling errors and
repetition/redundancy, and the inconsistency across different annotators. We
therefore propose to first learn visually-informative medical concepts from raw
reports, and, using the concept predictions as image annotations, learn to
auto-generate structured reports directly from images. We validate our approach
on the OpenI [2] chest x-ray dataset, which consists of frontal and lateral
views of chest x-ray images, their corresponding raw textual reports and manual
medical subject heading (MeSH ) annotations made by radiologists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02951</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02951</id><created>2019-10-07</created><authors><author><keyname>Jin</keyname><forenames>Shihao</forenames></author><author><keyname>Savioli</keyname><forenames>Nicol&#xf2;</forenames></author><author><keyname>de Marvao</keyname><forenames>Antonio</forenames></author><author><keyname>Dawes</keyname><forenames>Timothy JW</forenames></author><author><keyname>Gandy</keyname><forenames>Axel</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author><author><keyname>O'Regan</keyname><forenames>Declan P</forenames></author></authors><title>Joint analysis of clinical risk factors and 4D cardiac motion for
  survival prediction using a hybrid deep learning network</title><categories>q-bio.QM cs.LG eess.IV stat.ML</categories><comments>4 pages, 2 figures</comments><journal-ref>NeurIPS 2019, Medical Imaging meets NIPS</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a novel approach is proposed for joint analysis of high
dimensional time-resolved cardiac motion features obtained from segmented
cardiac MRI and low dimensional clinical risk factors to improve survival
prediction in heart failure. Different methods are evaluated to find the
optimal way to insert conventional covariates into deep prediction networks.
Correlation analysis between autoencoder latent codes and covariate features is
used to examine how these predictors interact. We believe that similar
approaches could also be used to introduce knowledge of genetic variants to
such survival networks to improve outcome prediction by jointly analysing
cardiac motion traits with inheritable risk factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02953</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02953</id><created>2019-10-07</created><updated>2019-10-15</updated><authors><author><keyname>Zhang</keyname><forenames>Zhaoji</forenames></author><author><keyname>Li</keyname><forenames>Ying</forenames></author><author><keyname>Huang</keyname><forenames>Chongwen</forenames></author><author><keyname>Guo</keyname><forenames>Qinghua</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author></authors><title>DNN-Aided Block Sparse Bayesian Learning for User Activity Detection and
  Channel Estimation in Grant-Free Non-Orthogonal Random Access</title><categories>cs.IT eess.SP math.IT</categories><comments>12 pages, 7 figures, accepted by TVT</comments><journal-ref>pre-published in IEEE Transactions on Vehicular Technology, 2019</journal-ref><doi>10.1109/TVT.2019.2947214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the upcoming Internet-of-Things (IoT) era, the communication is often
featured by massive connection, sporadic transmission, and small-sized data
packets, which poses new requirements on the delay expectation and resource
allocation efficiency of the Random Access (RA) mechanisms of the IoT
communication stack. A grant-free non-orthogonal random access (NORA) system is
considered in this paper, which could simultaneously reduce the access delay
and support more Machine Type Communication (MTC) devices with limited
resources. In order to address the joint user activity detection (UAD) and
channel estimation (CE) problem in the grant-free NORA system, we propose a
deep neural network-aided message passing-based block sparse Bayesian learning
(DNN-MP-BSBL) algorithm. In the DNN-MP-BSBL algorithm, the iterative message
passing process is transferred from a factor graph to a deep neural network
(DNN). Weights are imposed on the messages in the DNN and trained to minimize
the estimation error. It is shown that the trained weights could alleviate the
convergence problem of the MP-BSBL algorithm, especially on crowded RA
scenarios. Simulation results show that the proposed DNN-MP-BSBL algorithm
could improve the UAD and CE accuracy with a smaller number of iterations,
indicating its advantages for low-latency grant-free NORA systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.02994</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.02994</id><created>2019-10-07</created><authors><author><keyname>Chen</keyname><forenames>Huishan</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author></authors><title>Stochastic Model Predictive Control of Autonomous Systems with
  Non-Gaussian Correlated Uncertainty</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many systems such as autonomous vehicles and quadrotors are subject to
parametric uncertainties and external disturbances. These uncertainties can
lead to undesired performance degradation and safety issues. Therefore, it is
important to design robust control strategies to safely regulate the dynamics
of a system. This paper presents a novel framework for chance-constrained
stochastic model predictive control of dynamic systems with non-Gaussian
correlated probabilistic uncertainties. We develop a new stochastic Galerkin
method to propagate the uncertainties using a new type of basis functions and
an optimization-based quadrature rule. This formulation can easily handle
non-Gaussian correlated uncertainties that are beyond the capability of
generalized polynomial chaos expansions. The new stochastic Galerkin
formulation enables us to convert a chance-constraint stochastic model
predictive control problem into a deterministic one. We verify our approach by
several stochastic control tasks, including obstacle avoidance, vehicle path
following, and quadrotor reference tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03003</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03003</id><created>2019-10-07</created><authors><author><keyname>Watson</keyname><forenames>Joe</forenames></author><author><keyname>Abdulsamad</keyname><forenames>Hany</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author></authors><title>Stochastic Optimal Control as Approximate Input Inference</title><categories>cs.LG cs.RO cs.SY eess.SY stat.ML</categories><comments>Conference on Robot Learning (CoRL 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal control of stochastic nonlinear dynamical systems is a major
challenge in the domain of robot learning. Given the intractability of the
global control problem, state-of-the-art algorithms focus on approximate
sequential optimization techniques, that heavily rely on heuristics for
regularization in order to achieve stable convergence. By building upon the
duality between inference and control, we develop the view of Optimal Control
as Input Estimation, devising a probabilistic stochastic optimal control
formulation that iteratively infers the optimal input distributions by
minimizing an upper bound of the control cost. Inference is performed through
Expectation Maximization and message passing on a probabilistic graphical model
of the dynamical system, and time-varying linear Gaussian feedback controllers
are extracted from the joint state-action distribution. This perspective
incorporates uncertainty quantification, effective initialization through
priors, and the principled regularization inherent to the Bayesian treatment.
Moreover, it can be shown that for deterministic linearized systems, our
framework derives the maximum entropy linear quadratic optimal control law. We
provide a complete and detailed derivation of our probabilistic approach and
highlight its advantages in comparison to other deterministic and probabilistic
solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03011</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03011</id><created>2019-10-03</created><authors><author><keyname>Nandanoori</keyname><forenames>Sai Pushpak</forenames></author><author><keyname>Sinha</keyname><forenames>Subhrajit</forenames></author><author><keyname>Yeung</keyname><forenames>Enoch</forenames></author></authors><title>Data-Driven Operator Theoretic Methods for Global Phase Space Learning</title><categories>math.DS cs.SY eess.SY math.SP</categories><comments>This version is currently under review in ACC 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose to apply the recently developed Koopman operator
techniques to explore the global phase space of a nonlinear system from
time-series data. In particular, we address the problem of identifying various
invariant subsets of a phase space from the spectral properties of the
associated Koopman operator constructed from time-series data. Moreover, in the
case when the system evolution is known locally in various invariant subspaces,
then a phase space stitching result is proposed that can be applied to identify
a global Koopman operator. A biological system, bistable toggle switch and a
second-order nonlinear system example are considered to illustrate the proposed
results. The construction of this global Koopman operator is very helpful in
experimental works as multiple experiments can't be run at the same time
starting from several initial conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03019</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03019</id><created>2019-10-04</created><updated>2020-01-15</updated><authors><author><keyname>Mateo-Garcia</keyname><forenames>Gonzalo</forenames></author><author><keyname>Oprea</keyname><forenames>Silviu</forenames></author><author><keyname>Smith</keyname><forenames>Lewis</forenames></author><author><keyname>Veitch-Michaelis</keyname><forenames>Josh</forenames></author><author><keyname>Schumann</keyname><forenames>Guy</forenames></author><author><keyname>Gal</keyname><forenames>Yarin</forenames></author><author><keyname>Baydin</keyname><forenames>At&#x131;l&#x131;m G&#xfc;ne&#x15f;</forenames></author><author><keyname>Backes</keyname><forenames>Dietmar</forenames></author></authors><title>Flood Detection On Low Cost Orbital Hardware</title><categories>eess.IV cs.LG stat.ML</categories><journal-ref>Artificial Intelligence for Humanitarian Assistance and Disaster
  Response Workshop, 33rd Conference on Neural Information Processing Systems
  (NeurIPS 2019), Vancouver, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Satellite imaging is a critical technology for monitoring and responding to
natural disasters such as flooding. Despite the capabilities of modern
satellites, there is still much to be desired from the perspective of first
response organisations like UNICEF. Two main challenges are rapid access to
data, and the ability to automatically identify flooded regions in images. We
describe a prototypical flood segmentation system, identifying cloud, water and
land, that could be deployed on a constellation of small satellites, performing
processing on board to reduce downlink bandwidth by 2 orders of magnitude. We
target PhiSat-1, part of the FSSCAT mission, which is planned to be launched by
the European Space Agency (ESA) near the start of 2020 as a proof of concept
for this new technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03020</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03020</id><created>2019-10-07</created><updated>2020-02-22</updated><authors><author><keyname>Singh</keyname><forenames>Manish K.</forenames></author><author><keyname>Taheri</keyname><forenames>Sina</forenames></author><author><keyname>Kekatos</keyname><forenames>Vassilis</forenames></author><author><keyname>Schneider</keyname><forenames>Kevin P.</forenames></author><author><keyname>Liu</keyname><forenames>Chen-Ching</forenames></author></authors><title>Joint Grid Topology Reconfiguration and Design of Watt-VAR Curves for
  DERs</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operators can now remotely control switches and update the control settings
for voltage regulators and distributed energy resources (DERs), thus unleashing
the network reconfiguration opportunities to improve efficiency. Aligned to
this direction, this work puts forth a comprehensive toolbox of optimization
models leveraging the control capabilities of smart grid assets. We put forth
detailed yet practical models to capture the operation of locally and remotely
controlled regulators, and customize the watt-var DER control curves complying
with the IEEE 1547.8 mandates. Maintaining radiality is a key requirement
germane to various feeder optimization tasks. This requirement is accomplished
here through an intuitive and provably correct formulation. The developed
toolbox is put into action to reconfigure a grid for minimizing losses using
real-world data on a benchmark feeder. The results corroborate that optimal
topologies vary across the day and coordinating DERs and regulators is critical
during periods of steep net load changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03023</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03023</id><created>2019-10-01</created><authors><author><keyname>Bai</keyname><forenames>Zeyu</forenames></author><author><keyname>Yang</keyname><forenames>Ruizhi</forenames></author><author><keyname>Liang</keyname><forenames>Youzhi</forenames></author></authors><title>Mental Task Classification Using Electroencephalogram Signal</title><categories>eess.SP cs.LG</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the classification problem on electroencephalogram (EEG)
data of mental tasks, using standard architecture of three-layer CNN, stacked
LSTM, stacked GRU. We further propose a novel classifier - a mixed LSTM model
with a CNN decoder. A hyperparameter optimization on CNN shows validation
accuracy of 72% and testing accuracy of 62%. The stacked LSTM and GRU models
with FFT preprocessing and downsampling on data achieve 55% and 51% testing
accuracy respectively. As for the mixed LSTM model with CNN decoder, validation
accuracy of 75% and testing accuracy of 70% are obtained. We believe the mixed
model is more robust and accurate than both CNN and LSTM individually, by using
the CNN layer as a decoder for following LSTM layers. The code is completed in
the framework of Pytorch and Keras. Results and code can be found at
https://github.com/theyou21/BigProject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03031</identifier>
 <datestamp>2020-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03031</id><created>2019-10-04</created><updated>2020-02-11</updated><authors><author><keyname>Jiang</keyname><forenames>Shaowei</forenames></author><author><keyname>Zhu</keyname><forenames>Jiakai</forenames></author><author><keyname>Song</keyname><forenames>Pengming</forenames></author><author><keyname>Guo</keyname><forenames>Chengfei</forenames></author><author><keyname>Bian</keyname><forenames>Zichao</forenames></author><author><keyname>Wang</keyname><forenames>Ruihai</forenames></author><author><keyname>Huang</keyname><forenames>Yikun</forenames></author><author><keyname>Wang</keyname><forenames>Shiyao</forenames></author><author><keyname>Zhang</keyname><forenames>He</forenames></author><author><keyname>Zheng</keyname><forenames>Guoan</forenames></author></authors><title>Wide-field, high-resolution lensless on-chip microscopy via near-field
  blind ptychographic modulation</title><categories>eess.IV physics.ins-det physics.optics</categories><doi>10.1039/C9LC01027K</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a novel lensless on-chip microscopy platform based on near-field
blind ptychographic modulation. In this platform, we place a thin diffuser in
between the object and the image sensor for light wave modulation. By blindly
scanning the unknown diffuser to different x-y positions, we acquire a sequence
of modulated intensity images for quantitative object recovery. Different from
previous ptychographic implementations, we employ a unit magnification
configuration with a Fresnel number of ~50,000, which is orders of magnitude
higher than previous ptychographic setups. The unit magnification configuration
allows us to have the entire sensor area, 6.4 mm by 4.6 mm, as the imaging
field of view. The ultra-high Fresnel number enables us to directly recover the
positional shift of the diffuser in the phase retrieval process, addressing the
positioning accuracy issue plagued in regular ptychographic experiments. In our
implementation, we use a low-cost, DIY scanning stage to perform blind diffuser
modulation. Precise mechanical scanning that is critical in conventional
ptychography experiments is no longer needed in our setup. We further employ an
up-sampling phase retrieval scheme to bypass the resolution limit set by the
imager pixel size and demonstrate a half-pitch resolution of 0.78 micron. We
validate the imaging performance via in vitro cell cultures, transparent and
stained tissue sections, and a thick biological sample. We show that the
recovered quantitative phase map can be used to perform effective cell
segmentation of the dense yeast culture. We also demonstrate 3D digital
refocusing of the thick biological sample based on the recovered wavefront. The
reported platform provides a cost-effective and turnkey solution for large
field-of-view, high-resolution, and quantitative on-chip microscopy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03045</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03045</id><created>2019-10-07</created><authors><author><keyname>Saavedra</keyname><forenames>Gabriel</forenames></author><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>Capacity increases obtained extending the transmission bandwidth in
  optical communication systems</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The potential benefits of extending the optical fibre transmission bandwidth
are studied. Even in the presence of Kerr nonlinearity and inter-channel
stimulated Raman scattering, increasing the usable optical fibre bandwidth
appears to be the most promising solution to increase system throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03048</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03048</id><created>2019-10-07</created><authors><author><keyname>Hague</keyname><forenames>David A.</forenames></author><author><keyname>Kuklinski</keyname><forenames>Parker S.</forenames></author></authors><title>Waveform Design using Multi-Tone Feedback Frequency Modulation</title><categories>eess.SP</categories><comments>2019 IEEE RadarConf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a waveform design method using Multi-Tone Feedback
Frequency Modulation (MT-FFM), a generalization of the single oscillator
feedback FM method developed by [Tomisawa, 1981]. The MT-FFM utilizes a
collection of $K$ harmonically related oscillators each governed by a design
parameter $z_k$ which are utilized as a discrete set of parameters that may be
modified to generate a richer set of modulation functions than in the single
oscillator case. The resulting modulation function is represented using a form
of Kapteyn series composed of Generalized Bessel Functions. This paper
describes the structure of the MT-FFM waveform, derives the Kapteyn series
representation of the waveform's modulation function, and demonstrates the
design method with a waveform design example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03074</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03074</id><created>2019-10-07</created><updated>2020-02-11</updated><authors><author><keyname>Chen</keyname><forenames>Meixu</forenames></author><author><keyname>Jin</keyname><forenames>Yize</forenames></author><author><keyname>Goodall</keyname><forenames>Todd</forenames></author><author><keyname>Yu</keyname><forenames>Xiangxu</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>Study of 3D Virtual Reality Picture Quality</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual Reality (VR) and its applications have attracted significant and
increasing attention. However, the requirements of much larger file sizes,
different storage formats, and immersive viewing conditions pose significant
challenges to the goals of acquiring, transmitting, compressing and displaying
high quality VR content. Towards meeting these challenges, it is important to
be able to understand the distortions that arise and that can affect the
perceived quality of displayed VR content. It is also important to develop ways
to automatically predict VR picture quality. Meeting these challenges requires
basic tools in the form of large, representative subjective VR quality
databases on which VR quality models can be developed and which can be used to
benchmark VR quality prediction algorithms. Towards making progress in this
direction, here we present the results of an immersive 3D subjective image
quality assessment study. In the study, 450 distorted images obtained from 15
pristine 3D VR images modified by 6 types of distortion of varying severities
were evaluated by 42 subjects in a controlled VR setting. Both the subject
ratings as well as eye tracking data were recorded and made available as part
of the new database, in hopes that the relationships between gaze direction and
perceived quality might be better understood. We also evaluated several
publicly available IQA models on the new database, and also report a
statistical evaluation of the performances of the compared IQA models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03084</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03084</id><created>2019-10-07</created><authors><author><keyname>Sali</keyname><forenames>Rasoul</forenames></author><author><keyname>Ehsan</keyname><forenames>Lubaina</forenames></author><author><keyname>Kowsari</keyname><forenames>Kamran</forenames></author><author><keyname>Khan</keyname><forenames>Marium</forenames></author><author><keyname>Moskaluk</keyname><forenames>Christopher A.</forenames></author><author><keyname>Syed</keyname><forenames>Sana</forenames></author><author><keyname>Brown</keyname><forenames>Donald E.</forenames></author></authors><title>CeliacNet: Celiac Disease Severity Diagnosis on Duodenal
  Histopathological Images Using Deep Residual Networks</title><categories>eess.IV cs.CV cs.LG q-bio.QM stat.ML</categories><comments>accepted at IEEE International Conference on Bioinformatics and
  Biomedicine (IEEE BIBM 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Celiac Disease (CD) is a chronic autoimmune disease that affects the small
intestine in genetically predisposed children and adults. Gluten exposure
triggers an inflammatory cascade which leads to compromised intestinal barrier
function. If this enteropathy is unrecognized, this can lead to anemia,
decreased bone density, and, in longstanding cases, intestinal cancer. The
prevalence of the disorder is 1% in the United States. An intestinal (duodenal)
biopsy is considered the &quot;gold standard&quot; for diagnosis. The mild CD might go
unnoticed due to non-specific clinical symptoms or mild histologic features. In
our current work, we trained a model based on deep residual networks to
diagnose CD severity using a histological scoring system called the modified
Marsh score. The proposed model was evaluated using an independent set of 120
whole slide images from 15 CD patients and achieved an AUC greater than 0.96 in
all classes. These results demonstrate the diagnostic power of the proposed
model for CD severity classification using histological images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03088</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03088</id><created>2019-09-30</created><authors><author><keyname>Zhan</keyname><forenames>Wei</forenames></author><author><keyname>Sun</keyname><forenames>Liting</forenames></author><author><keyname>Wang</keyname><forenames>Di</forenames></author><author><keyname>Shi</keyname><forenames>Haojie</forenames></author><author><keyname>Clausse</keyname><forenames>Aubrey</forenames></author><author><keyname>Naumann</keyname><forenames>Maximilian</forenames></author><author><keyname>Kummerle</keyname><forenames>Julius</forenames></author><author><keyname>Konigshof</keyname><forenames>Hendrik</forenames></author><author><keyname>Stiller</keyname><forenames>Christoph</forenames></author><author><keyname>de La Fortelle</keyname><forenames>Arnaud</forenames></author><author><keyname>Tomizuka</keyname><forenames>Masayoshi</forenames></author></authors><title>INTERACTION Dataset: An INTERnational, Adversarial and Cooperative
  moTION Dataset in Interactive Driving Scenarios with Semantic Maps</title><categories>cs.RO cs.CV cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Behavior-related research areas such as motion prediction/planning,
representation/imitation learning, behavior modeling/generation, and algorithm
testing, require support from high-quality motion datasets containing
interactive driving scenarios with different driving cultures. In this paper,
we present an INTERnational, Adversarial and Cooperative moTION dataset
(INTERACTION dataset) in interactive driving scenarios with semantic maps. Five
features of the dataset are highlighted. 1) The interactive driving scenarios
are diverse, including urban/highway/ramp merging and lane changes, roundabouts
with yield/stop signs, signalized intersections, intersections with
one/two/all-way stops, etc. 2) Motion data from different countries and
different continents are collected so that driving preferences and styles in
different cultures are naturally included. 3) The driving behavior is highly
interactive and complex with adversarial and cooperative motions of various
traffic participants. Highly complex behavior such as negotiations,
aggressive/irrational decisions and traffic rule violations are densely
contained in the dataset, while regular behavior can also be found from
cautious car-following, stop, left/right/U-turn to rational lane-change and
cycling and pedestrian crossing, etc. 4) The levels of criticality span wide,
from regular safe operations to dangerous, near-collision maneuvers. Real
collision, although relatively slight, is also included. 5) Maps with complete
semantic information are provided with physical layers, reference lines,
lanelet connections and traffic rules. The data is recorded from drones and
traffic cameras. Statistics of the dataset in terms of number of entities and
interaction density are also provided, along with some utilization examples in
a variety of behavior-related research areas. The dataset can be downloaded via
https://interaction-dataset.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03095</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03095</id><created>2019-10-07</created><authors><author><keyname>Hamza</keyname><forenames>Syed A.</forenames></author><author><keyname>Amin</keyname><forenames>Moeness G.</forenames></author></authors><title>Hybrid Sparse Array Beamforming Design for General Rank Signal Models</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2952052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers sparse array design for receive beamforming achieving
maximum signal-to-interference plus noise ratio (MaxSINR) for both single point
source and multiple point sources, operating in an interference active
environment. Unlike existing sparse design methods which either deal with
structured environment-independent or non-structured environment-dependent
arrays, our method is a hybrid approach and seeks a full augumentable array
that optimizes beamformer performance. This approach proves important for
limited aperture that constrains the number of possible uniform grid points for
sensor placements. The problem is formulated as quadratically constraint
quadratic program (QCQP), with the cost function penalized with weighted
l_1-norm squared of the beamformer weight vector. Simulation results are
presented to show the effectiveness of the proposed algorithms for array
configurability in the case of both single and general rank signal correlation
matrices. Performance comparisons among the proposed sparse array, the commonly
used uniform arrays, arrays obtained by other design methods, and arrays
designed without the augmentability constraint are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03102</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03102</id><created>2019-10-07</created><authors><author><keyname>Salem</keyname><forenames>Abdelhamid</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author></authors><title>Error Probability Analysis and Power Allocation for Interference
  Exploitation Over Rayleigh Fading Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the performance analysis of constructive interference
(CI) precoding technique in multi-user multiple-input multiple-output (MU-MIMO)
systems with a finite constellation phase-shift keying (PSK) input alphabet.
Firstly, analytical expressions for the moment generating function (MGF) and
the average of the received signal-to-noise-ratio (SNR) are derived. Then,
based on the derived MGF expression the average symbol error probability (SEP)
for the CI precoder with PSK signaling is calculated. In this regard, new exact
and very accurate asymptotic approximation for the average SEP are provided.
Building on the new performance analysis, different power allocation schemes
are considered to enhance the achieved SEP. In the first scheme, power
allocation based on minimizing the sum symbol error probabilities (Min-Sum) is
studied, while in the second scheme the power allocation based on minimizing
the maximum SEP (Min-Max) is investigated. Furthermore, new analytical
expressions of the throughput and power efficiency of the CI precoding in
MU-MIMO systems are also derived. The numerical results in this work
demonstrate that, the CI precoding outperforms the conventional interference
suppression precoding techniques with an up to 20dB gain in the transmit SNR in
terms of SEP, and up to 15dB gain in the transmit SNR in terms of the
throughput. In addition, the SEP-based power allocation schemes provide
additional up to 13dB gains in the transmit SNR compared to the conventional
equal power allocation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03115</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03115</id><created>2019-10-07</created><authors><author><keyname>K&#xf6;lsch</keyname><forenames>Lukas</forenames></author><author><keyname>Dupuis</keyname><forenames>Manuel</forenames></author><author><keyname>Bhatt</keyname><forenames>Kirtan</forenames></author><author><keyname>Krebs</keyname><forenames>Stefan</forenames></author><author><keyname>Hohmann</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Distributed Frequency Regulation for Heterogeneous Microgrids via Steady
  State Optimal Control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a model-based frequency controller for microgrids
with nonzero line resistances based on a port-Hamiltonian formulation of the
microgrid model and real-time dynamic pricing. The controller is applicable for
conventional generation with synchronous machines as well as for power
electronics interfaced sources and it is robust against power fluctuations from
uncontrollable loads or volatile regenerative sources. The price-based
formulation allows additional requirements such as active power sharing to be
met. The capability and effectiveness of our procedure is demonstrated by means
of an 18-node exemplary grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03159</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03159</id><created>2019-10-07</created><authors><author><keyname>Barry</keyname><forenames>Daniel</forenames></author><author><keyname>Shah</keyname><forenames>Munir</forenames></author><author><keyname>Keijsers</keyname><forenames>Merel</forenames></author><author><keyname>Khan</keyname><forenames>Humayun</forenames></author><author><keyname>Hopman</keyname><forenames>Banon</forenames></author></authors><title>xYOLO: A Model For Real-Time Object Detection In Humanoid Soccer On
  Low-End Hardware</title><categories>cs.CV cs.LG cs.RO eess.IV stat.ML</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the emergence of onboard vision processing for areas such as the
internet of things (IoT), edge computing and autonomous robots, there is
increasing demand for computationally efficient convolutional neural network
(CNN) models to perform real-time object detection on resource constraints
hardware devices. Tiny-YOLO is generally considered as one of the faster object
detectors for low-end devices and is the basis for our work. Our experiments on
this network have shown that Tiny-YOLO can achieve 0.14 frames per second(FPS)
on the Raspberry Pi 3 B, which is too slow for soccer playing autonomous
humanoid robots detecting goal and ball objects. In this paper we propose an
adaptation to the YOLO CNN model named xYOLO, that can achieve object detection
at a speed of 9.66 FPS on the Raspberry Pi 3 B. This is achieved by trading an
acceptable amount of accuracy, making the network approximately 70 times faster
than Tiny-YOLO. Greater inference speed-ups were also achieved on a desktop CPU
and GPU. Additionally we contribute an annotated Darknet dataset for goal and
ball detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03162</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03162</id><created>2019-10-07</created><authors><author><keyname>Chamanbaz</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Dabbene</keyname><forenames>Fabrizio</forenames></author><author><keyname>Bouffanais</keyname><forenames>Roland</forenames></author></authors><title>A Physics-Based Attack Detection Technique in Cyber-Physical Systems: A
  Model Predictive Control Co-Design Approach</title><categories>eess.SY cs.SY math.OC</categories><comments>Accepted for publication in the 2019 Australian &amp; New Zealand Control
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel approach to co-design controller and attack detector
for nonlinear cyber-physical systems affected by false data injection (FDI)
attack is proposed. We augment the model predictive controller with an
additional constraint requiring the future---in some steps ahead---trajectory
of the system to remain in some time-invariant neighborhood of a properly
designed reference trajectory. At any sampling time, we compare the real-time
trajectory of the system with the designed reference trajectory, and construct
a residual. The residual is then used in a nonparametric cumulative sum (CUSUM)
anomaly detector to uncover FDI attacks on input and measurement channels. The
effectiveness of the proposed approach is tested with a nonlinear model
regarding level control of coupled tanks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03169</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03169</id><created>2019-10-07</created><authors><author><keyname>Ho</keyname><forenames>Koki</forenames></author><author><keyname>Wang</keyname><forenames>Hai</forenames></author><author><keyname>DeTrempe</keyname><forenames>Paul A.</forenames></author><author><keyname>Jonchay</keyname><forenames>Tristan Sarton du</forenames></author><author><keyname>Tomita</keyname><forenames>Kento</forenames></author></authors><title>Semi-Analytical Model for Design and Analysis of On-Orbit Servicing
  Architecture</title><categories>cs.PF cs.SY eess.SY physics.space-ph</categories><comments>20 pages, 7 figures, Submitted to Journal of Spacecraft and Rockets</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robotic on-orbit servicing (OOS) is expected to be a key technology and
concept for future sustainable space exploration. This paper develops a
semi-analytical model for OOS systems analysis, responding to the growing needs
and ongoing trend of robotic OOS. An OOS infrastructure system is considered
whose goal is to provide responsive services to the random failures of a set of
customer modular satellites distributed in space (e.g., at the geosynchronous
equatorial orbit). The considered OOS architecture is comprised of a servicer
that travels and provides module-replacement services to the customer
satellites, an on-orbit depot to store the spares, and a series of launch
vehicles to replenish the depot. The OOS system performance is analyzed by
evaluating the mean waiting time before service completion for a given failure
and its relationship with the depot capacity. Leveraging the queueing theory
and inventory management methods, the developed semi-analytical model is
capable of analyzing the OOS system performance without relying on
computationally costly simulations. The effectiveness of the proposed model is
demonstrated using a case study compared with simulation results. This paper is
expected to provide a critical step to push the research frontier of
analytical/semi-analytical models development for complex space systems design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03182</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03182</id><created>2019-10-07</created><updated>2019-12-09</updated><authors><author><keyname>Nice</keyname><forenames>Kerry A.</forenames></author><author><keyname>Wijnands</keyname><forenames>Jasper S.</forenames></author><author><keyname>Middel</keyname><forenames>Ariane</forenames></author><author><keyname>Wang</keyname><forenames>Jingcheng</forenames></author><author><keyname>Qiu</keyname><forenames>Yiming</forenames></author><author><keyname>Zhao</keyname><forenames>Nan</forenames></author><author><keyname>Thompson</keyname><forenames>Jason</forenames></author><author><keyname>Aschwanden</keyname><forenames>Gideon D. P. A.</forenames></author><author><keyname>Zhao</keyname><forenames>Haifeng</forenames></author><author><keyname>Stevenson</keyname><forenames>Mark</forenames></author></authors><title>Sky pixel detection in outdoor imagery using an adaptive algorithm and
  machine learning</title><categories>cs.CV eess.IV</categories><comments>This revision accepted in Urban Climate. 17 pages, 12 figures</comments><doi>10.1016/j.uclim.2019.100572</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer vision techniques enable automated detection of sky pixels in
outdoor imagery. In urban climate, sky detection is an important first step in
gathering information about urban morphology and sky view factors. However,
obtaining accurate results remains challenging and becomes even more complex
using imagery captured under a variety of lighting and weather conditions.
  To address this problem, we present a new sky pixel detection system
demonstrated to produce accurate results using a wide range of outdoor imagery
types. Images are processed using a selection of mean-shift segmentation,
K-means clustering, and Sobel filters to mark sky pixels in the scene. The
algorithm for a specific image is chosen by a convolutional neural network,
trained with 25,000 images from the Skyfinder data set, reaching 82% accuracy
for the top three classes. This selection step allows the sky marking to follow
an adaptive process and to use different techniques and parameters to best suit
a particular image. An evaluation of fourteen different techniques and
parameter sets shows that no single technique can perform with high accuracy
across varied Skyfinder and Google Street View data sets. However, by using our
adaptive process, large increases in accuracy are observed. The resulting
system is shown to perform better than other published techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03188</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03188</id><created>2019-10-07</created><authors><author><keyname>K</keyname><forenames>Rahul-Vigneswaran</forenames></author><author><keyname>S</keyname><forenames>Sachin-Kumar</forenames></author><author><keyname>Mohan</keyname><forenames>Neethu</forenames></author><author><keyname>KP</keyname><forenames>Soman</forenames></author></authors><title>Dynamic Mode Decomposition based feature for Image Classification</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Selected for Spotlight presentation at TENCON 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Irrespective of the fact that Machine learning has produced groundbreaking
results, it demands an enormous amount of data in order to perform so. Even
though data production has been in its all-time high, almost all the data is
unlabelled, hence making them unsuitable for training the algorithms. This
paper proposes a novel method of extracting the features using Dynamic Mode
Decomposition (DMD). The experiment is performed using data samples from
Imagenet. The learning is done using SVM-linear, SVM-RBF, Random Kitchen Sink
approach (RKS). The results have shown that DMD features with RKS give
competing results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03191</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03191</id><created>2019-10-07</created><authors><author><keyname>Hancock</keyname><forenames>Matthew C</forenames></author><author><keyname>Magnan</keyname><forenames>Jerry F</forenames></author></authors><title>Lung nodule segmentation via level set machine learning</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung cancer has the highest mortality rate of all cancers in both men and
women. The algorithmic detection, characterization, and diagnosis of
abnormalities found in chest CT scan images can potentially aid radiologists by
providing additional medical information to consider in their assessment. Lung
nodule segmentation, i.e., the algorithmic delineation of the lung nodule
surface, is a fundamental component of an automated nodule analysis pipeline.
We introduce an extension of the vanilla level set image segmentation method
where the velocity function is learned from data via machine learning
regression methods, rather than manually designed. This mitigates the tedious
design process of the velocity term from the standard method. We apply the
method to image volumes of lung nodules from CT scans in the publicly available
LIDC dataset, obtaining an average intersection over union score of
0.7185($\pm$0.1114).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03210</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03210</id><created>2019-10-06</created><authors><author><keyname>Joshi</keyname><forenames>Anant A.</forenames></author><author><keyname>Bhatt</keyname><forenames>Maulik C.</forenames></author><author><keyname>Sinha</keyname><forenames>Arpita</forenames></author></authors><title>Modification of Hilbert's Space-Filling Curve to Avoid Obstacles: A
  Robotic Path-Planning Strategy</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of exploring a region using the Hilbert's
space-filling curve in the presence of obstacles. No prior knowledge of the
region being explored is assumed. An online algorithm is proposed which can
implement evasive strategies to avoid obstacles comprising a single or two
blocked unit squares placed side by side and successfully explore the entire
region. The strategies are specified by the change in the waypoint array which
robot going to follow. The fractal nature of the Hilbert's space-filling curve
has been exploited in proving the validity of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03255</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03255</id><created>2019-10-08</created><authors><author><keyname>Kim</keyname><forenames>Wonjun</forenames></author><author><keyname>Ji</keyname><forenames>Hyoungju</forenames></author><author><keyname>Shim</keyname><forenames>Byonghyo</forenames></author></authors><title>Channel aware sparse transmission for ultra low-latency communications
  in TDD systems</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Communications. Copyright 2019
  IEEE. Personal use of this material is permitted. Permission from IEEE must
  be obtained for all other uses</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Major goal of ultra reliable and low latency communication (URLLC) is to
reduce the latency down to a millisecond (ms) level while ensuring reliability
of the transmission. Since the current uplink transmission scheme requires a
complicated handshaking procedure to initiate the transmission, to meet this
stringent latency requirement is a challenge in wireless system design. In
particular, in the time division duplexing (TDD) systems, supporting the URLLC
is difficult since the mobile device has to wait until the transmit direction
is switched to the uplink. In this paper, we propose a new approach to support
a low latency access in TDD systems, called channel aware sparse transmission
(CAST). Key idea of the proposed scheme is to encode a grant signal in a form
of sparse vector. This together with the fact that the sensing mechanism
preserves the energy of the sparse vector allows us to use the compressed
sensing (CS) technique in CAST decoding. From the performance analysis and
numerical evaluations, we demonstrate that the proposed CAST scheme achieves a
significant reduction in access latency over the 4G LTE-TDD and 5G NR-TDD
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03273</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03273</id><created>2019-10-08</created><authors><author><keyname>Polak</keyname><forenames>Daniel</forenames></author><author><keyname>Cauley</keyname><forenames>Stephen</forenames></author><author><keyname>Bilgic</keyname><forenames>Berkin</forenames></author><author><keyname>Gong</keyname><forenames>Enhao</forenames></author><author><keyname>Bachert</keyname><forenames>Peter</forenames></author><author><keyname>Adalsteinsson</keyname><forenames>Elfar</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author></authors><title>Joint multi-contrast Variational Network reconstruction (jVN) with
  application to rapid 2D and 3D imaging</title><categories>eess.IV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To improve the image quality of highly accelerated multi-channel MRI
data by learning a joint variational network that reconstructs multiple
clinical contrasts jointly.
  Methods: Data from our multi-contrast acquisition was embedded into the
variational network architecture where shared anatomical information is
exchanged by mixing the input contrasts. Complementary k-space sampling across
imaging contrasts and Bunch-Phase/Wave-Encoding were used for data acquisition
to improve the reconstruction at high accelerations. At 3T, our joint
variational network approach across T1w, T2w and T2-FLAIR-weighted brain scans
was tested for retrospective under-sampling at R=6 (2D) and R=4x4 (3D)
acceleration. Prospective acceleration was also performed for 3D data where the
combined acquisition time for whole brain coverage at 1 mm isotropic resolution
across three contrasts was less than three minutes.
  Results: Across all test datasets, our joint multi-contrast network better
preserved fine anatomical details with reduced image-blurring when compared to
the corresponding single-contrast reconstructions. Improvement in image quality
was also obtained through complementary k-space sampling and
Bunch-Phase/Wave-Encoding where the synergistic combination yielded the overall
best performance as evidenced by exemplarily slices and quantitative error
metrics.
  Conclusion: By leveraging shared anatomical structures across the jointly
reconstructed scans, our joint multi-contrast approach learnt more efficient
regularizers which helped to retain natural image appearance and avoid
over-smoothing. When synergistically combined with advanced encoding
techniques, the performance was further improved, enabling up to R=16-fold
acceleration with good image quality. This should help pave the way to very
rapid high-resolution brain exams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03283</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03283</id><created>2019-10-08</created><updated>2019-11-21</updated><authors><author><keyname>Zhu</keyname><forenames>K.</forenames></author><author><keyname>Victoria</keyname><forenames>M.</forenames></author><author><keyname>Brown</keyname><forenames>T.</forenames></author><author><keyname>Andresen</keyname><forenames>G. B.</forenames></author><author><keyname>Greiner</keyname><forenames>M.</forenames></author></authors><title>Impact of climatic, technical and economic uncertainties on the optimal
  design of a coupled fossil-free electricity, heating and cooling system in
  Europe</title><categories>physics.soc-ph cs.SY eess.SY</categories><comments>The submitted version, with 15 pages, 17 figures and 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To limit the global temperature increase to 1.5 degrees Celsius, fossil-free
energy systems will be required eventually. To understand how such systems can
be designed, the current state-of-the-art is to apply techno-economical
optimisation modelling with high spatial and temporal resolution. This approach
relies on a number of climatic, technical and economic predictions that reach
multiple decades into the future. In this paper, we investigate how the design
of a fossil-free energy system for Europe is affected by changes in these
assumptions. In particular, the synergy among renewable generators,
power-to-heat converters, storage units, synthetic gas and transmission manage
to deliver an affordable net-zero emissions system. We find that levelised cost
of energy decreases due to heat savings, but not for global temperature
increases. In both cases, heat pumps become less favourable as surplus
electricity is more abundant for heating. Demand-side management through
buildings' thermal inertia could shape the heating demand, yet has modest
impact on the system configuration. Cost reductions of heat pumps impact
resistive heaters substantially, but not the opposite. Cheaper power-to-gas
could lower the need for thermal energy storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03320</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03320</id><created>2019-10-08</created><authors><author><keyname>Di Gangi</keyname><forenames>Mattia Antonino</forenames></author><author><keyname>Negri</keyname><forenames>Matteo</forenames></author><author><keyname>Turchi</keyname><forenames>Marco</forenames></author></authors><title>One-To-Many Multilingual End-to-end Speech Translation</title><categories>cs.CL eess.AS</categories><comments>8 pages, one figure, version accepted at ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, training end-to-end neural models for spoken language translation
(SLT) still has to confront with extreme data scarcity conditions. The existing
SLT parallel corpora are indeed orders of magnitude smaller than those
available for the closely related tasks of automatic speech recognition (ASR)
and machine translation (MT), which usually comprise tens of millions of
instances. To cope with data paucity, in this paper we explore the
effectiveness of transfer learning in end-to-end SLT by presenting a
multilingual approach to the task. Multilingual solutions are widely studied in
MT and usually rely on ``\textit{target forcing}'', in which multilingual
parallel data are combined to train a single model by prepending to the input
sequences a language token that specifies the target language. However, when
tested in speech translation, our experiments show that MT-like \textit{target
forcing}, used as is, is not effective in discriminating among the target
languages. Thus, we propose a variant that uses target-language embeddings to
shift the input representations in different portions of the space according to
the language, so to better support the production of output in the desired
target language. Our experiments on end-to-end SLT from English into six
languages show important improvements when translating into similar languages,
especially when these are supported by scarce data. Further improvements are
obtained when using English ASR data as an additional language (up to $+2.5$
BLEU points).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03334</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03334</id><created>2019-10-08</created><authors><author><keyname>Wei</keyname><forenames>Taoran</forenames></author><author><keyname>Cao</keyname><forenames>Danhua</forenames></author><author><keyname>Jiang</keyname><forenames>Xingru</forenames></author><author><keyname>Zheng</keyname><forenames>Caiyun</forenames></author><author><keyname>Liu</keyname><forenames>Lizhe</forenames></author></authors><title>Defective samples simulation through Neural Style Transfer for automatic
  surface defect segment</title><categories>cs.CV eess.IV</categories><comments>To be published in 2019 International Conference on Optical
  Instrument and Technology (OIT 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Owing to the lack of defect samples in industrial product quality inspection,
trained segmentation model tends to overfit when applied online. To address
this problem, we propose a defect sample simulation algorithm based on neural
style transfer. The simulation algorithm requires only a small number of defect
samples for training, and can efficiently generate simulation samples for
next-step segmentation task. In our work, we introduce a masked histogram
matching module to maintain color consistency of the generated area and the
true defect. To preserve the texture consistency with the surrounding pixels,
we take the fast style transfer algorithm to blend the generated area into the
background. At the same time, we also use the histogram loss to further improve
the quality of the generated image. Besides, we propose a novel structure of
segment net to make it more suitable for defect segmentation task. We train the
segment net with the real defect samples and the generated simulation samples
separately on the button datasets. The results show that the F1 score of the
model trained with only the generated simulation samples reaches 0.80, which is
better than the real sample result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03345</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03345</id><created>2019-10-08</created><authors><author><keyname>Rond&#xf3;n</keyname><forenames>Ra&#xfa;l</forenames></author><author><keyname>Mahmood</keyname><forenames>Aamir</forenames></author><author><keyname>Grimaldi</keyname><forenames>Simone</forenames></author><author><keyname>Gidlund</keyname><forenames>Mikael</forenames></author></authors><title>Understanding the Performance of Bluetooth Mesh: Reliability, Delay and
  Scalability Analysis</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article evaluates the quality-of-service performance and scalability of
the recently released Bluetooth Mesh protocol and provides general guidelines
on its use and configuration. Through extensive simulations, we analyzed the
impact of the configuration of all the different protocol's parameters on the
end-to-end reliability, delay, and scalability. In particular, we focused on
the structure of the packet broadcast process, which takes place in time
intervals known as \textit{Advertising Events} and \textit{Scanning Events}.
Results indicate a high degree of interdependence among all the different
timing parameters involved in both the scanning and the advertising processes
and show that the correct operation of the protocol greatly depends on the
compatibility between their configurations. We also demonstrated that
introducing randomization in these timing parameters, as well as varying the
duration of the \textit{Advertising Events}, reduces the drawbacks of the
flooding propagation mechanism implemented by the protocol. Using data
collected from a real office environment, we also studied the behavior of the
protocol in the presence of WLAN interference. It was shown that Bluetooth Mesh
is vulnerable to external interference, even when implementing the standardized
limitation of using only 3 out of the 40 Bluetooth Low Energy frequency
channels. We observed that the achievable average delay is relatively low, of
around 250~ms for over 10 hops under the worst simulated network conditions.
However, results proved that scalability is especially challenging for
Bluetooth Mesh since it is prone to broadcast storm, hindering the
communication reliability for denser deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03365</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03365</id><created>2019-10-08</created><authors><author><keyname>Pu</keyname><forenames>Wenqiang</forenames></author><author><keyname>Xiao</keyname><forenames>Jinjun</forenames></author><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>Overcoming DoF Limitation in Robust Beamforming: A Penalized
  Inequality-Constrained Approach</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known challenge in beamforming is how to optimally utilize the degrees
of freedom (DoF) of the array to design a robust beamformer, especially when
the array DoF is smaller than the number of sources in the environment. In this
paper, we leverage the tool of constrained convex optimization and propose a
penalized inequality-constrained minimum variance (P-ICMV) beamformer to
address this challenge. Specifically, we propose a beamformer with a
well-targeted objective function and inequality constraints to achieve the
design goals. The constraints on interferences penalize the maximum gain of the
beamformer at any interfering directions. This can efficiently mitigate the
total interference power regardless of whether the number of interfering
sources is less than the array DoF or not. Multiple robust constraints on the
target protection and interference suppression can be introduced to increase
the robustness of the beamformer against steering vector mismatch. By
integrating the noise reduction, interference suppression, and target
protection, the proposed formulation can efficiently obtain a robust beamformer
design while optimally trade off various design goals. When the array DoF is
fewer than the number of interferences, the proposed formulation can
effectively align the limited DoF to all of the sources to obtain the best
overall interference suppression. $\ $To numerically solve this problem, we
formulate the P-ICMV beamformer design as a convex second-order cone program
(SOCP) and propose a low complexity iterative algorithm based on the
alternating direction method of multipliers (ADMM). Three applications are
simulated to demonstrate the effectiveness of the proposed beamformer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03384</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03384</id><created>2019-10-08</created><authors><author><keyname>Ortmann</keyname><forenames>Lukas</forenames></author><author><keyname>Hauswirth</keyname><forenames>Adrian</forenames></author><author><keyname>Caduff</keyname><forenames>Ivo</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author><author><keyname>Bolognani</keyname><forenames>Saverio</forenames></author></authors><title>Experimental Validation of Feedback Optimization in Power Distribution
  Grids</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of controlling the voltage of a distribution feeder
using the reactive power capabilities of inverters. On a real distribution
grid, we compare local Volt/VAr droop control, as recommended in recent grid
codes, centralized dispatch based on optimal reactive power flow (OPF), and a
feedback optimization (FO) controller that we propose. The local droop control
yields suboptimal regulation, as predicted analytically. The OPF-based dispatch
strategy requires an accurate grid model and measurement of all loads on the
feeder in order to achieve proper voltage regulation. However, in the
experiment, the OPF-based strategy violates voltage constraints due to
inevitable model mismatch and uncertainties. Our proposed FO controller, on the
other hand, satisfies the constraints and does not require load measurements or
any grid state estimation. The only model knowledge needed is the sensitivity
of the voltages with respect to reactive power, which can be obtained from
data. As we show, an approximation of these sensitivities is also sufficient,
which makes the approach essentially model-free, easy to tune, compatible with
the current sensing and control infrastructure, and remarkably robust to
measurement noise. We expect these properties to be fundamental features of FO
for power systems and not specific to Volt/VAr regulation or to distribution
grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03388</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03388</id><created>2019-10-08</created><authors><author><keyname>Nguyen</keyname><forenames>Trung-Hien</forenames></author><author><keyname>Louveaux</keyname><forenames>Jerome</forenames></author><author><keyname>De Doncker</keyname><forenames>Philippe</forenames></author><author><keyname>Horlin</keyname><forenames>Francois</forenames></author></authors><title>Comments on &quot;Probabilities of Error for Adaptive Reception of M-Phase
  Signals&quot;</title><categories>eess.SP</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paper [1] derived the probability density function (PDF) of a sum of products
of two correlated complex Gaussian zero-mean random variables (RVs) that has
been applied to calculate the error probabilities of a \emph{M}-ary phase shift
keying (\emph{M}-PSK) system. We show that there exist some typos in the
computation and we provide the detailed derivation leading to the correct
expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03390</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03390</id><created>2019-10-08</created><updated>2020-01-18</updated><authors><author><keyname>Zamanipour</keyname><forenames>Makan</forenames></author></authors><title>A Survey on Deep-Learning based Techniques for Modeling and Estimation
  of MassiveMIMO Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>IEEE Journals</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  \textit{Why does the literature consider the channel-state-information (CSI)
as a 2/3-D image? What are the pros-and-cons of this consideration for
accuracy-complexity trade-off?} Next generations of wireless communications
require innumerable disciplines according to which a low-latency, low-traffic,
high-throughput, high spectral-efficiency and low energy-consumption are
guaranteed. Towards this end, the principle of massive multi-input multi-output
(MaMIMO) is emerging which is conveniently deployed for millimeter wave
(mmWave) bands. However, practical and realistic MaMIMO transceivers suffer
from a huge range of challenging bottlenecks in design the majority of which
belong to the issue of channel-estimation. Channel modeling and prediction in
MaMIMO particularly suffer from computational complexity due to a high number
of antenna sets and supported users. This complexity lies dominantly upon the
feedback-overhead which even degrades the pilot-data trade-off in the uplink
(UL)/downlink (DL) design. This comprehensive survey studies the novel
deep-learning (DLg) driven techniques recently proposed in the literature which
tackle the challenges discussed-above - which is for the first time. In
addition, we consequently propose 7 open trends e.g. in the context of the lack
of Q-learning in MaMIMO detection - for which we talk about a possible solution
to the saddle-point in the 2-D pilot-data axis for a \textit{Stackelberg game}
based scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03392</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03392</id><created>2019-10-08</created><authors><author><keyname>Ortmann</keyname><forenames>Lukas</forenames></author><author><keyname>Prostejovsky</keyname><forenames>Alexander</forenames></author><author><keyname>Heussen</keyname><forenames>Kai</forenames></author><author><keyname>Bolognani</keyname><forenames>Saverio</forenames></author></authors><title>Fully Distributed Peer-to-Peer Optimal Voltage Control with Minimal
  Model Requirements</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of optimal voltage control using reactive
power injected by inverters, aiming to keep voltages along a distribution grid
feeder within a desired range. Purely local voltage control cannot solve this
task under all circumstances and may even end up in detrimental control
decisions, which can be avoided by incorporating situation awareness of each
inverter's neighborhood. Therefore, we design a distributed control strategy
with the goal of identifying the minimal amount of data and model information
that need to be shared between controllers in order to solve this task. We
demonstrate that short-range peer-to-peer communication and knowledge of
electric distances between neighbouring controllers are sufficient. The
approach was implemented and tested on a $400$~V distribution feeder with
asynchronous communication channels in a synchronous optimization process,
confirming its viability on real-life systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03472</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03472</id><created>2019-10-08</created><authors><author><keyname>Weber</keyname><forenames>Maurice</forenames></author><author><keyname>Renggli</keyname><forenames>Cedric</forenames></author><author><keyname>Grabner</keyname><forenames>Helmut</forenames></author><author><keyname>Zhang</keyname><forenames>Ce</forenames></author></authors><title>Lossy Image Compression with Recurrent Neural Networks: from Human
  Perceived Visual Quality to Classification Accuracy</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have recently advanced the state-of-the-art in image
compression and surpassed many traditional compression algorithms. The training
of such networks involves carefully trading off entropy of the latent
representation against reconstruction quality. The term quality crucially
depends on the observer of the images which, in the vast majority of
literature, is assumed to be human. In this paper, we go beyond this notion of
quality and look at human visual perception and machine perception
simultaneously. To that end, we propose a family of loss functions that allows
to optimize deep image compression depending on the observer and to interpolate
between human perceived visual quality and classification accuracy. Our
experiments show that our proposed training objectives result in compression
systems that, when trained with machine friendly loss, preserve accuracy much
better than the traditional codecs BPG, WebP and JPEG, without requiring
fine-tuning of inference algorithms on decoded images and independent of the
classifier architecture. At the same time, when using the human friendly loss,
we achieve competitive performance in terms of MS-SSIM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03477</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03477</id><created>2019-10-08</created><authors><author><keyname>Chou</keyname><forenames>Glen</forenames></author><author><keyname>Ozay</keyname><forenames>Necmiye</forenames></author><author><keyname>Berenson</keyname><forenames>Dmitry</forenames></author></authors><title>Learning Parametric Constraints in High Dimensions from Demonstrations</title><categories>cs.RO cs.LG cs.SY eess.SY</categories><comments>3rd Conference on Robot Learning (CoRL 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a scalable algorithm for learning parametric constraints in high
dimensions from safe expert demonstrations. To reduce the ill-posedness of the
constraint recovery problem, our method uses hit-and-run sampling to generate
lower cost, and thus unsafe, trajectories. Both safe and unsafe trajectories
are used to obtain a representation of the unsafe set that is compatible with
the data by solving an integer program in that representation's parameter
space. Our method can either leverage a known parameterization or incrementally
grow a parameterization while remaining consistent with the data, and we
provide theoretical guarantees on the conservativeness of the recovered unsafe
set. We evaluate our method on high-dimensional constraints for
high-dimensional systems by learning constraints for 7-DOF arm, quadrotor, and
planar pushing examples, and show that our method outperforms baseline
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03493</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03493</id><created>2019-10-04</created><authors><author><keyname>De Stefani</keyname><forenames>Lorenzo</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>A Rademacher Complexity Based Method fo rControlling Power and
  Confidence Level in Adaptive Statistical Analysis</title><categories>eess.SP cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While standard statistical inference techniques and machine learning
generalization bounds assume that tests are run on data selected independently
of the hypotheses, practical data analysis and machine learning are usually
iterative and adaptive processes where the same holdout data is often used for
testing a sequence of hypotheses (or models), which may each depend on the
outcome of the previous tests on the same data. In this work, we present
RadaBound a rigorous, efficient and practical procedure for controlling the
generalization error when using a holdout sample for multiple adaptive testing.
Our solution is based on a new application of the Rademacher Complexity
generalization bounds, adapted to dependent tests. We demonstrate the
statistical power and practicality of our method through extensive simulations
and comparisons to alternative approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03516</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03516</id><created>2019-10-08</created><authors><author><keyname>Eller</keyname><forenames>Luke</forenames></author><author><keyname>Guerin</keyname><forenames>Theo</forenames></author><author><keyname>Huang</keyname><forenames>Baichuan</forenames></author><author><keyname>Warren</keyname><forenames>Garrett</forenames></author><author><keyname>Yang</keyname><forenames>Sophie</forenames></author><author><keyname>Roy</keyname><forenames>Josh</forenames></author><author><keyname>Tellex</keyname><forenames>Stefanie</forenames></author></authors><title>Advanced Autonomy on a Low-Cost Educational Drone Platform</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PiDrone is a quadrotor platform created to accompany an introductory robotics
course. Students build an autonomous flying robot from scratch and learn to
program it through assignments and projects. Existing educational robots do not
have significant autonomous capabilities, such as high-level planning and
mapping. We present a hardware and software framework for an autonomous aerial
robot, in which all software for autonomy can run onboard the drone,
implemented in Python. We present an Unscented Kalman Filter (UKF) for accurate
state estimation. Next, we present an implementation of Monte Carlo (MC)
Localization and FastSLAM for Simultaneous Localization and Mapping (SLAM). The
performance of UKF, localization, and SLAM is tested and compared to ground
truth, provided by a motion-capture system. Our evaluation demonstrates that
our autonomous educational framework runs quickly and accurately on a Raspberry
Pi in Python, making it ideal for use in educational settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03519</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03519</id><created>2019-10-08</created><authors><author><keyname>Farhadi</keyname><forenames>Masoud</forenames></author><author><keyname>Abapour</keyname><forenames>Mehdi</forenames></author></authors><title>Three Switch Three Phase Inverter With Improved DC Voltage Utilization</title><categories>eess.SY cs.SY eess.SP</categories><doi>10.1109/TIE.2018.2829680</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new DC-AC converter with a less number of semiconductor
switches and therefore gate drive and control circuit components. A salient
feature of this inverter is its pure sinusoidal line-to-line voltages with no
need for output filter. Also, the proposed inverter improves the voltage
utilization factor of the input dc supply compared to four-switch three-phase
inverter (first best topology in the literature from the number of switches
point of view) and standard six-switch inverter with sine PWM. The proposed
inverter is capable of operating with a wide range of output voltages from zero
to the full value of the dc input voltage by appropriately altering
instantaneous duty-cycle. For the first time to our knowledge, in this paper, a
three-phase universal inverter with only three power-switch has been proposed.
For the purpose of providing a good compromise between fast transient response
and stability, a model predictive controller is proposed. All the design
expressions have been derived. A comparison with other DC-AC converters is
given to show the merits of the proposed converter. Finally, satisfactory
circuit operation is confirmed by experimental results from a laboratory
prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03521</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03521</id><created>2019-10-08</created><authors><author><keyname>Farhadi</keyname><forenames>Masoud</forenames></author><author><keyname>Fard</keyname><forenames>Majid Tahmasbi</forenames></author><author><keyname>Abapour</keyname><forenames>Mehdi</forenames></author><author><keyname>Hagh</keyname><forenames>Mehrdad Tarafdar</forenames></author></authors><title>DC-AC Converter-Fed Induction Motor Drive With Fault-Tolerant Capability
  Under Open- and Short-Circuit Switch Failures</title><categories>eess.SY cs.SY eess.SP</categories><doi>10.1109/TPEL.2017.2683534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new fault tolerant dc-ac converter-fed induction motor drive
is proposed to maintain motor as close as possible to its desired normal
operation under open- and short-circuit switch failures. The operational
principles for fault detection and isolation schemes are provided. Two control
strategies including predictive control and voltage mode-controlled PWM with
integral-double-lead controller for two stage of the converter are presented in
conjunction with the elaborated discussion. The control strategy determines
appropriate switching states for continuous operation of the drive after a
fault. The proposed topology makes it possible to integrate the minimal
redundant hardware and full tolerance capability which is an important
advantage of the proposed topology. Moreover, the most important advantages of
the proposed topology are a fast response in a fault condition and low cost of
the converter in comparison with the evaluated topologies. A
Joule-integral-based method for selecting an appropriate rating of applied
fuses has been presented to provide a reliable fault-isolation operation. Also,
a comparison with currently available fault-tolerant dc-ac converters is given
to show the merits of the proposed topology. Finally, the experimental results
are presented to verify the validity of the theoretical analysis and industrial
feasibility of the proposed converter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03555</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03555</id><created>2019-10-08</created><authors><author><keyname>Farhadi</keyname><forenames>Masoud</forenames></author><author><keyname>Abapour</keyname><forenames>Mehdi</forenames></author><author><keyname>Sabahi</keyname><forenames>Mehran</forenames></author></authors><title>Failure analysis and reliability evaluation of modulation techniques for
  neutral point clamped inverters-A usage model approach</title><categories>eess.SY cs.SY</categories><doi>10.1016/j.engfailanal.2016.06.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up to now, many modulation techniques have been proposed for neutral point
clamped (NPC) inverters. In this paper, for the first time, a general
methodology is applied to calculate and compare the failure analysis and
reliability of NPC inverter with most commonly used control strategies. Also,
the mean time to failure (MTTF) of NPC inverter is derived for different
control strategies. It is demonstrated that the key feature of control
strategies in determining the reliability of inverter is their loss
distribution among the switches. The failure rate of components that is
relevant to this study and junction temperature calculation is developed, then
conduction losses and switching losses of switches for different control
strategies are calculated. Finally, the most reliable control strategy is
identified. Experimental results obtained have promptly justified the
theoretical analysis and outlined procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03557</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03557</id><created>2019-10-08</created><authors><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Agrawal</keyname><forenames>Aayushya</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Robust Online Simulation Framework for Grid Restoration Under Loss of
  SCADA</title><categories>eess.SY cs.SY</categories><comments>7 Pages. Manuscript submitted to Power System Computation Conference
  2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure and fast grid restoration from a collapsed state is increasingly
critical as blackouts are becoming a common occurrence around the globe.
Generally, the restoration of grid during a blackout is achieved with the help
of Supervisory Control and Data Acquisition System (SCADA) based central
control; however, with the threat of cyber-blackouts, this presumption of an
available and secure SCADA system is not valid. This is also true for grids in
developing countries as well as for many distribution grids that lack SCADA. In
this paper, we introduce an online framework for localized grid restoration
that validates and updates a pre-defined crank path in real-time based on the
vital grid states of voltages, currents and frequency. The proposed framework
maintains an online network topology of the localized grid that can
continuously sample measurements and update the grid model, thereby
circumventing SCADA based central control. In the results section we
demonstrate the efficacy of this framework for black start by ensuring a
feasible crank path with voltage and frequency within bounds, while further
assisting in synchronization of two disconnected sub-grids during the
re-energization process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03564</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03564</id><created>2019-10-08</created><authors><author><keyname>Buyukates</keyname><forenames>Baturalp</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Timely Distributed Computation with Stragglers</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a status update system in which the update packets need to be
processed to extract the embedded useful information. The source node sends the
acquired information to a computation unit (CU) which consists of a master node
and $n$ worker nodes. The master node distributes the received computation task
to the worker nodes. Upon computation, the master node aggregates the results
and sends them back to the source node to keep it \emph{updated}. We
investigate the age performance of uncoded and coded (repetition coded, MDS
coded, and multi-message MDS (MM-MDS) coded) schemes in the presence of
stragglers under i.i.d.~exponential transmission delays and i.i.d~shifted
exponential computation times. We show that asymptotically MM-MDS coded scheme
outperforms the other schemes. Furthermore, we characterize the optimal codes
such that the average age is minimized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03641</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03641</id><created>2019-10-08</created><authors><author><keyname>Li</keyname><forenames>Haoqi</forenames></author><author><keyname>Baucom</keyname><forenames>Brian</forenames></author><author><keyname>Georgiou</keyname><forenames>Panayiotis</forenames></author></authors><title>Linking emotions to behaviors through deep transfer learning</title><categories>cs.LG cs.CL cs.HC eess.AS</categories><comments>23 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human behavior refers to the way humans act and interact. Understanding human
behavior is a cornerstone of observational practice, especially in
psychotherapy. An important cue of behavior analysis is the dynamical changes
of emotions during the conversation. Domain experts integrate emotional
information in a highly nonlinear manner, thus, it is challenging to explicitly
quantify the relationship between emotions and behaviors. In this work, we
employ deep transfer learning to analyze their inferential capacity and
contextual importance. We first train a network to quantify emotions from
acoustic signals and then use information from the emotion recognition network
as features for behavior recognition. We treat this emotion-related information
as behavioral primitives and further train higher level layers towards behavior
quantification. Through our analysis, we find that emotion-related information
is an important cue for behavior recognition. Further, we investigate the
importance of emotional-context in the expression of behavior by constraining
(or not) the neural networks' contextual view of the data. This demonstrates
that the sequence of emotions is critical in behavior expression. To achieve
these frameworks we employ hybrid architectures of convolutional networks and
recurrent networks to extract emotion-related behavior primitives and
facilitate automatic behavior recognition from speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03662</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03662</id><created>2019-10-08</created><authors><author><keyname>Carreno</keyname><forenames>Ignacio Losada</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author><author><keyname>Zlotnik</keyname><forenames>Anatoly</forenames></author><author><keyname>Deka</keyname><forenames>Deepjyoti</forenames></author><author><keyname>Sundar</keyname><forenames>Kaarthik</forenames></author></authors><title>An Adversarial Model for Attack Vector Vulnerability Analysis on Power
  and Gas Delivery Operations</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power systems often rely on natural gas pipeline networks to supply fuel for
gas-fired generation. Market inefficiencies and a lack of formal coordination
between the wholesale power and gas delivery infrastructures may magnify the
broader impact of a cyber-attack on a natural gas pipeline. In this study we
present a model that can be used to quantify the impact of cyber-attacks on
electricity and gas delivery operations. We model activation of cyber-attack
vectors that attempt to gain access to pipeline gas compressor controls using a
continuous-time Markov chain over a state space based on the gas operator
Industrial Control System firewall zone partition. Our approach evaluates the
operating states and decision-making in the networks using physically realistic
and operationally representative models. We summarize these models, the
sequence of analyses used to quantify the impacts of a cyber-incident, and
propose a Monte Carlo simulation approach to quantify the resulting effect on
the reliability of the bulk power system by the increase in operational cost.
The methodology is applied to a case study of interacting power, gas, and cyber
test networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03687</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03687</id><created>2019-10-08</created><authors><author><keyname>Ma</keyname><forenames>Zixiao</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author><author><keyname>Yuan</keyname><forenames>Yuxuan</forenames></author></authors><title>An Improved Large-Signal Order Reduction Method of Microgrids with
  Stability and Accuracy Assessment</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel mathematical theorem that embeds the stability
and accuracy assessment into a large-signal order reduction (LSOR) method of
microgrids. Using the proposed method, the dynamic stability of full microgrid
models can be assessed by only leveraging their derived reduced-order models
and boundary layer models. In particular, when the reduced-order system is
input-to-state stable and the boundary layer system is uniformly globally
asymptotically stable, the original microgrids system is stable based on
several common growth conditions. In addition, we develop the conditions to
guarantee the accuracy of the reduced model. We show that the error between the
solutions of reduced and original models is bounded and convergent under such
conditions. Further, we provide the strict mathematical proof to illustrate
that the proposed order reduction method is generic and can be applied to
arbitrary dynamic systems. Simulation validation is conducted on microgrid
systems to show the effectiveness of proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03713</identifier>
 <datestamp>2019-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03713</id><created>2019-10-08</created><updated>2019-12-05</updated><authors><author><keyname>Pasini</keyname><forenames>Marco</forenames></author></authors><title>MelGAN-VC: Voice Conversion and Audio Style Transfer on arbitrarily long
  samples using Spectrograms</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional voice conversion methods rely on parallel recordings of multiple
speakers pronouncing the same sentences. For real-world applications however,
parallel data is rarely available. We propose MelGAN-VC, a voice conversion
method that relies on non-parallel speech data and is able to convert audio
signals of arbitrary length from a source voice to a target voice. We firstly
compute spectrograms from waveform data and then perform a domain translation
using a Generative Adversarial Network (GAN) architecture. An additional
siamese network helps preserving speech information in the translation process,
without sacrificing the ability to flexibly model the style of the target
speaker. We test our framework with a dataset of clean speech recordings, as
well as with a collection of noisy real-world speech examples. Finally, we
apply the same method to perform music style transfer, translating arbitrarily
long music samples from one genre to another, and showing that our framework is
flexible and can be used for audio manipulation applications different from
voice conversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03719</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03719</id><created>2019-10-08</created><authors><author><keyname>Nair</keyname><forenames>Siddharth H.</forenames></author><author><keyname>Bujarbaruah</keyname><forenames>Monimoy</forenames></author><author><keyname>Borrelli</keyname><forenames>Francesco</forenames></author></authors><title>Modeling of Dynamical Systems via Successive Graph Approximations</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a non-parametric technique for online modeling of
systems with unknown nonlinear Lipschitz dynamics. The key idea is to
successively utilize measurements to approximate the graph of the state-update
function using envelopes described by quadratic constraints. The proposed
approach is then demonstrated on two control applications: (i) computation of
tractable bounds for unmodeled dynamics, and (ii) computation of positive
invariant sets. We further highlight the efficacy of the proposed approach via
a detailed numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03720</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03720</id><created>2019-10-08</created><authors><author><keyname>Tabas</keyname><forenames>Daniel</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author></authors><title>Optimal L-Infinity Frequency Control in Microgrids Considering Actuator
  Saturation</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to PSCC 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inverter-connected resources can improve transient stability in low-inertia
grids by injecting active power to minimize system frequency deviations
following disturbances. In practice, most generation and load disturbances are
step changes and the engineering figure-of-merit is often the peak overshoot in
frequency resulting from these step disturbances. In addition, the
inverter-connected resources tend to saturate much more easily than
conventional synchronous machines. However, despite these challenges, standard
controller designs must deal with averaged quantities through $H_2$ or
$H_\infty$ norms and must account for saturation in ad hoc manners. In this
paper, we address these challenges by explicitly considering $L_\infty$ control
with saturation using a linear matrix inequality-based approach. We show that
this approach leads to significant improvements in stability performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03729</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03729</id><created>2019-10-08</created><updated>2019-10-12</updated><authors><author><keyname>Yu</keyname><forenames>Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaofan</forenames></author><author><keyname>Song</keyname><forenames>Lingjun</forenames></author><author><keyname>Jiang</keyname><forenames>Liren</forenames></author><author><keyname>Huang</keyname><forenames>Xiaodi</forenames></author><author><keyname>Chen</keyname><forenames>Wen</forenames></author><author><keyname>Zhang</keyname><forenames>Chenbin</forenames></author><author><keyname>Li</keyname><forenames>Jiahui</forenames></author><author><keyname>Yang</keyname><forenames>Jiji</forenames></author><author><keyname>Hu</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Duan</keyname><forenames>Qi</forenames></author><author><keyname>Chen</keyname><forenames>Wanyuan</forenames></author><author><keyname>He</keyname><forenames>Xianglei</forenames></author><author><keyname>Fan</keyname><forenames>Jinshuang</forenames></author><author><keyname>Jiang</keyname><forenames>Weihai</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author><author><keyname>Qiu</keyname><forenames>Chengmin</forenames></author><author><keyname>Gu</keyname><forenames>Minmin</forenames></author><author><keyname>Sun</keyname><forenames>Weiwei</forenames></author><author><keyname>Zhang</keyname><forenames>Yangqiong</forenames></author><author><keyname>Peng</keyname><forenames>Guangyin</forenames></author><author><keyname>Shen</keyname><forenames>Weiwei</forenames></author><author><keyname>Fu</keyname><forenames>Guohui</forenames></author></authors><title>Large-scale Gastric Cancer Screening and Localization Using Multi-task
  Deep Neural Network</title><categories>eess.IV cs.CV</categories><comments>under major revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gastric cancer is one of the most common cancers, which ranks third among the
leading causes of cancer death. Biopsy of gastric mucosal is a standard
procedure in gastric cancer screening test. However, manual pathological
inspection is labor-intensive and time-consuming. Besides, it is challenging
for an automated algorithm to locate the small lesion regions in the gigapixel
whole-slide image and make the decision correctly. To tackle these issues, we
collected large-scale whole-slide image dataset with detailed lesion region
annotation and designed a whole-slide image analyzing framework consisting of 3
networks which could not only determine the screen result but also present the
suspicious areas to the pathologist for reference. Experiments demonstrated
that our proposed framework achieves sensitivity of 97.05% and specificity of
92.72% in screening task and Dice coefficient of 0.8331 in segmentation task.
Furthermore, we tested our best model in real-world scenario on 10, 316
whole-slide images collected from 4 medical centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03734</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03734</id><created>2019-10-08</created><authors><author><keyname>Mamaghani</keyname><forenames>Baabak</forenames></author><author><keyname>Salvaggio</keyname><forenames>Carl</forenames></author></authors><title>Comparative study of panel and panelless-based reflectance conversion
  techniques for agricultural remote sensing</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Small unmanned aircraft systems (sUAS) have allowed for thousands of aerial
images to be captured at a moments notice. The simplicity and relative low cost
of flying a sUAS has provided remote sensing practitioners, both commercial and
academic, with a viable alternative to traditional remote sensing platforms
(airplanes and satellites). This paper is an expanded follow-up study to an
initial work. Three radiance-to-reflectance conversion methods were tested to
determine the optimal technique to use for converting raw digital count imagery
to reflectance maps. The first two methods utilized in-scene reflectance
conversion panels along with the empirical line method (ELM), while the final
method used an upward looking sensor that recorded the band-effective spectral
downwelling irradiance. The methods employed were 2-Point ELM, 1-point ELM, and
At-altitude Radiance Ratio (AARR). The average signed reflectance factor errors
produced by these methods on real sUAS imagery were: -0.005, -0.0028, and
-0.0244 respectively. These errors were produced across four altitudes (150,
225, 300 and 375ft), six targets (grass, asphalt, concrete, blue felt, green
felt and red felt), five spectral bands (blue, green, red, red edge and near
infrared), and three weather conditions (cloudy, partly cloudy and sunny).
Finally, data was simulated using the MODTRAN code to generate downwelling
irradiance and sensor reaching radiance to compute the theoretical results of
the AARR technique. A multitude of variables were varied for these simulations
(atmosphere, time, day, target, sensor height, and visibility), which resulted
in an overall theoretically achievable signed reflectance factor error of
0.0023.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03746</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03746</id><created>2019-10-08</created><updated>2019-10-23</updated><authors><author><keyname>Zheng</keyname><forenames>Ao</forenames></author><author><keyname>Gao</keyname><forenames>Hewei</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author><author><keyname>Xing</keyname><forenames>Yuxiang</forenames></author></authors><title>A cascaded dual-domain deep learning reconstruction method for sparsely
  spaced multidetector helical CT</title><categories>physics.med-ph cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Helical CT has been widely used in clinical diagnosis. Sparsely spaced
multidetector in z direction can increase the coverage of the detector provided
limited detector rows. It can speed up volumetric CT scan, lower the radiation
dose and reduce motion artifacts. However, it leads to insufficient data for
reconstruction. That means reconstructions from general analytical methods will
have severe artifacts. Iterative reconstruction methods might be able to deal
with this situation but with the cost of huge computational load. In this work,
we propose a cascaded dual-domain deep learning method that completes both data
transformation in projection domain and error reduction in image domain. First,
a convolutional neural network (CNN) in projection domain is constructed to
estimate missing helical projection data and converting helical projection data
to 2D fan-beam projection data. This step is to suppress helical artifacts and
reduce the following computational cost. Then, an analytical linear operator is
followed to transfer the data from projection domain to image domain. Finally,
an image domain CNN is added to improve image quality further. These three
steps work as an entirety and can be trained end to end. The overall network is
trained using a simulated lung CT dataset with Poisson noise from 25 patients.
We evaluate the trained network on another three patients and obtain very
encouraging results with both visual examination and quantitative comparison.
The resulting RRMSE is 6.56% and the SSIM is 99.60%. In addition, we test the
trained network on the lung CT dataset with different noise level and a new
dental CT dataset to demonstrate the generalization and robustness of our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03749</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03749</id><created>2019-10-08</created><authors><author><keyname>B&#xe9;jar</keyname><forenames>Benjam&#xed;n</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author><author><keyname>Vidal</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>The fastest $\ell_{1,\infty}$ prox in the west</title><categories>cs.LG eess.SP math.OC stat.ML</categories><comments>9 pages, 2 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proximal operators are of particular interest in optimization problems
dealing with non-smooth objectives because in many practical cases they lead to
optimization algorithms whose updates can be computed in closed form or very
efficiently. A well-known example is the proximal operator of the vector
$\ell_1$ norm, which is given by the soft-thresholding operator. In this paper
we study the proximal operator of the mixed $\ell_{1,\infty}$ matrix norm and
show that it can be computed in closed form by applying the well-known
soft-thresholding operator to each column of the matrix. However, unlike the
vector $\ell_1$ norm case where the threshold is constant, in the mixed
$\ell_{1,\infty}$ norm case each column of the matrix might require a different
threshold and all thresholds depend on the given matrix. We propose a general
iterative algorithm for computing these thresholds, as well as two efficient
implementations that further exploit easy to compute lower bounds for the mixed
norm of the optimal solution. Experiments on large-scale synthetic and real
data indicate that the proposed methods can be orders of magnitude faster than
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03759</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03759</id><created>2019-10-08</created><authors><author><keyname>Lu</keyname><forenames>Jingyi</forenames></author><author><keyname>Leong</keyname><forenames>Alex S.</forenames></author><author><keyname>Quevedo</keyname><forenames>Daniel E.</forenames></author></authors><title>An event-triggered transmission scheduling strategy for remote state
  estimation in the presence of an eavesdropper</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a remote state estimation problem in the presence of an
eavesdropper over packet dropping links. A smart sensor transmits its local
estimates to a legitimate remote estimator, in the course of which an
eavesdropper can randomly overhear the transmission. This problem has been well
studied for unstable dynamical systems, but seldom for stable systems. In this
paper, we target at stable and marginally stable systems and aim to design an
event-triggered scheduling strategy by minimizing the expected error covariance
at the remote estimator and keeping that at the eavesdropper above a
user-specified lower bound. To this end, we model the evolution of the error
covariance as an infinite recurrent Markov chain and develop a recurrence
relation to describe the stationary distribution of the state at the
eavesdropper. Monotonicity and convergence properties of the expected error
covariance are further investigated and employed to solve the optimization
problem. Numerical examples are provided to validate the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03768</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03768</id><created>2019-10-05</created><authors><author><keyname>Khodaei</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Candelino</keyname><forenames>Nicholas</forenames></author><author><keyname>Mehrvarz</keyname><forenames>Amin</forenames></author><author><keyname>Jalili</keyname><forenames>Nader</forenames></author></authors><title>Physiological Closed-Loop Control (PCLC) Systems: Review of a Modern
  Frontier in Automation</title><categories>eess.SY cs.SY q-bio.QM</categories><comments>39 pages, 13 figures</comments><doi>10.1109/ACCESS.2020.2968440</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past decade, there has been an unprecedented international focus on
improved quality and availability of medical care, which has reignited interest
in clinical automation and drawn researchers toward novel solutions in the
field of physiological closed-loop control systems (PCLCs). Today,
multidisciplinary groups of expert scientists, engineers, clinicians,
mathematicians, and policy-makers are combining their knowledge and experience
to develop both the next generation of PCLC-based medical equipment and a
collaborative commercial/academic infrastructure to support this rapidly
expanding frontier. In the following article, we provide a robust introduction
to the various aspects of this growing field motivated by the recent and
ongoing work supporting two leading technologies: the artificial pancreas (AP)
and automated anesthesia. Following a brief high-level overview of the main
concepts in automated therapy and some relevant tools from systems and control
theory, we explore -- separately -- the developments, challenges,
state-of-the-art, and probable directions for AP and automated anesthesia
systems. We then close the review with a consideration of the common lessons
gleaned from these ventures and the implications they present for future
investigations and adjacent research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03786</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03786</id><created>2019-10-09</created><authors><author><keyname>Ramazi</keyname><forenames>Pouria</forenames></author><author><keyname>Cao</keyname><forenames>Ming</forenames></author></authors><title>Global Convergence for Replicator Dynamics of Repeated Snowdrift Games</title><categories>math.DS cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand the emergence and sustainment of cooperative behavior in
interacting collectives, we perform global convergence analysis for replicator
dynamics of a large, well-mixed population of individuals playing a repeated
snowdrift game with four typical strategies, which are always cooperate (ALLC),
tit-for-tat (TFT), suspicious tit-for-tat (STFT) and always defect (ALLD). The
dynamical model is a three-dimensional ODE system that is parameterized by the
payoffs of the base game. Instead of routine searches for evolutionarily stable
strategies and sets, we expand our analysis to determining the asymptotic
behavior of solution trajectories starting from any initial state, and in
particular show that for the full range of payoffs, every trajectory of the
system converges to an equilibrium point. The convergence results highlight
three findings that are of particular importance for understanding the
cooperation mechanisms among self-interested agents playing repeated snowdrift
games. First, the inclusion of TFT- and STFT-players, the two types of
conditional strategy players in the game, increases the share of cooperators of
the overall population compared to the situation when the population consists
of only ALLC- and ALLD-players. This confirms findings in biology and sociology
that reciprocity may promote cooperation in social collective actions, such as
reducing traffic jams and division of labor, where each individual may gain
more to play the opposite of what her opponent chooses. Second, surprisingly
enough, regardless of the payoffs, there always exists a set of initial
conditions under which ALLC players do not vanish in the long run, which does
not hold for all the other three types of players. So an ALLC-player, although
perceived as the one that can be easily taken advantage of in snowdrift games,
has certain endurance in the long run.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03828</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03828</id><created>2019-10-09</created><authors><author><keyname>Nallapu</keyname><forenames>Ravi Teja</forenames></author><author><keyname>Thangavelautham</keyname><forenames>Jekan</forenames></author></authors><title>Towards End-To-End Design of Spacecraft Swarms for Small-Body
  Reconnaissance</title><categories>astro-ph.IM cs.SY eess.SY</categories><comments>12 pages, 13 figures, International Astronautical Congress 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploration of small bodies in the Solar System is a high priority
planetary science. Asteroids, comets, and planetary moons yield important
information about the evolution of the Solar System. Additionally, they could
provide resources for a future space economy. While much research has gone into
exploring asteroids and comets, dedicated spacecraft missions to planetary
moons are few and far between. There are three fundamental challenges of a
spacecraft mission to the planetary moons: The first challenge is that the
spheres of influence of most moons (except that of Earth) are small and, in
many cases, virtually absent. The second is that many moons are tidally locked
to their planets, which means that an observer on the planet will have an
entire hemisphere, which is always inaccessible. The third challenge is that at
a given time about half of the region will be in the Sun's shadow. Therefore, a
single spacecraft mission to observe the planetary moon cannot provide complete
coverage. Such a complex task can be solved using a swarm approach, where the
mapping task is delegated to multiple low-cost spacecraft. Clearly, the design
of a swarm mission for such a dynamic environment is challenging. For this
reason, we have proposed the Integrated Design Engineering &amp; Automation of
Swarms (IDEAS) software to perform automated end-to-end design of swarm
missions. Specifically, it will use a sub-module known as the Automated Swarm
Designer module to find optimal swarm configurations suited for a given
mission. In our previous work, we have developed the Automated Swarm Design
module to find swarm configurations for asteroid mapping operations. In this
work, we will evaluate the capability of the Automated Swarm module to design
missions to planetary moons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03829</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03829</id><created>2019-10-09</created><authors><author><keyname>Thangavelautham</keyname><forenames>Jekan</forenames></author><author><keyname>Chandra</keyname><forenames>Aman</forenames></author><author><keyname>Jensen</keyname><forenames>Erik</forenames></author></authors><title>Autonomous Multirobot Technologies for Mars Mining Base Construction and
  Operation</title><categories>cs.RO cs.SY eess.SY</categories><comments>15 pages, 17 figures, International Astronautical Congress 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beyond space exploration, the next critical step towards living and working
in space requires developing a space economy. One important challenge with this
space-economy is ensuring the low-cost transport of raw materials from one
gravity-well to another. The escape delta-v of 11.2 km/s from Earth makes this
proposition very expensive. Transporting materials from the Moon takes 2.4 km/s
and from Mars 5.0 km/s. Based on these factors, the Moon and Mars can become
colonies to export material into this space economy. One critical question is
what are the resources required to sustain a space economy? Water has been
identified as a critical resource both to sustain human-life but also for use
in propulsion, attitude-control, power, thermal storage and radiation
protection systems. Water may be obtained off-world through In-Situ Resource
Utilization (ISRU) in the course of human or robotic space exploration. Based
upon these important findings, we developed an energy model to determine the
feasibility of developing a mining base on Mars that mines and exports water
(transports water on a Mars escape trajectory). Our designs for a mining base
utilize renewable energy sources namely photovoltaics and solar-thermal
concentrators to provide power to construct the base, keep it operational and
export the water using a mass driver (electrodynamic railgun). Our studies
found the key to keeping the mining base simple and effective is to make it
robotic. Teams of robots (consisting of 100 infrastructure robots) would be
used to construct the entire base using locally available resources and fully
operate the base. This would decrease energy needs by 5-folds. Furthermore, the
base can be built 5-times faster using robotics and 3D printing. This shows
that automation and robotics is the key to making such a base technologically
feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03839</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03839</id><created>2019-10-09</created><authors><author><keyname>Wang</keyname><forenames>Yinglong</forenames></author><author><keyname>Zhang</keyname><forenames>Haokui</forenames></author><author><keyname>Liu</keyname><forenames>Yu</forenames></author><author><keyname>Shi</keyname><forenames>Qinfeng</forenames></author><author><keyname>Zeng</keyname><forenames>Bing</forenames></author></authors><title>Gradient Information Guided Deraining with A Novel Network and
  Adversarial Training</title><categories>cs.CV eess.IV</categories><comments>12 pages, 9 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, deep learning based methods have made significant progress
in rain-removing. However, the existing methods usually do not have good
generalization ability, which leads to the fact that almost all of existing
methods have a satisfied performance on removing a specific type of rain
streaks, but may have a relatively poor performance on other types of rain
streaks. In this paper, aiming at removing multiple types of rain streaks from
single images, we propose a novel deraining framework (GRASPP-GAN), which has
better generalization capacity. Specifically, a modified ResNet-18 which
extracts the deep features of rainy images and a revised ASPP structure which
adapts to the various shapes and sizes of rain streaks are composed together to
form the backbone of our deraining network. Taking the more prominent
characteristics of rain streaks in the gradient domain into consideration, a
gradient loss is introduced to help to supervise our deraining training
process, for which, a Sobel convolution layer is built to extract the gradient
information flexibly. To further boost the performance, an adversarial learning
scheme is employed for the first time to train the proposed network. Extensive
experiments on both real-world and synthetic datasets demonstrate that our
method outperforms the state-of-the-art deraining methods quantitatively and
qualitatively. In addition, without any modifications, our proposed framework
also achieves good visual performance on dehazing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03844</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03844</id><created>2019-10-09</created><updated>2019-10-27</updated><authors><author><keyname>Oh</keyname><forenames>Koog-Hwan</forenames></author><author><keyname>Fidan</keyname><forenames>Baris</forenames></author><author><keyname>Ahn</keyname><forenames>Hyo-Sung</forenames></author></authors><title>Edge Localization in Two Dimensional Space via Orientation Estimation</title><categories>eess.SY cs.SY</categories><comments>12 pages, 12 figures, Brief version of a paper named &quot;Distributed
  Bearing Vector Estimation in Multi-agent Networks&quot; submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the problem of estimating bearing vectors between the
agents in a two dimensional multi-agent network based on subtended angle
measurements, called edge localization problem. We propose an edge localization
graph to investigate the solvability of this problem and a distributed
estimation method via orientation estimation of virtual agents to solve the
problem. Under the proposed method, the estimated bearing vector exponentially
converges to the real one with a common bias if and only if the edge
localization graph has an oriented spanning tree. Furthermore, the estimated
variables exponentially converge to the true values if the edge localization
graph has an oriented spanning tree with a root knowing the bearing vector from
it to one of its neighbors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03865</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03865</id><created>2019-10-09</created><authors><author><keyname>Du</keyname><forenames>Yuqing</forenames></author><author><keyname>Yang</keyname><forenames>Sheng</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>High-Dimensional Stochastic Gradient Quantization for
  Communication-Efficient Edge Learning</title><categories>cs.IT cs.LG eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edge machine learning involves the deployment of learning algorithms at the
wireless network edge so as to leverage massive mobile data for enabling
intelligent applications. The mainstream edge learning approach, federated
learning, has been developed based on distributed gradient descent. Based on
the approach, stochastic gradients are computed at edge devices and then
transmitted to an edge server for updating a global AI model. Since each
stochastic gradient is typically high-dimensional (with millions to billions of
coefficients), communication overhead becomes a bottleneck for edge learning.
To address this issue, we propose in this work a novel framework of
hierarchical stochastic gradient quantization and study its effect on the
learning performance. First, the framework features a practical hierarchical
architecture for decomposing the stochastic gradient into its norm and
normalized block gradients, and efficiently quantizes them using a uniform
quantizer and a low-dimensional codebook on a Grassmann manifold, respectively.
Subsequently, the quantized normalized block gradients are scaled and cascaded
to yield the quantized normalized stochastic gradient using a so-called hinge
vector designed under the criterion of minimum distortion. The hinge vector is
also efficiently compressed using another low-dimensional Grassmannian
quantizer. The other feature of the framework is a bit-allocation scheme for
reducing the quantization error. The scheme determines the resolutions of the
low-dimensional quantizers in the proposed framework. The framework is proved
to guarantee model convergency by analyzing the convergence rate as a function
of the quantization bits. Furthermore, by simulation, our design is shown to
substantially reduce the communication overhead compared with the
state-of-the-art signSGD scheme, while both achieve similar learning
accuracies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03866</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03866</id><created>2019-10-09</created><authors><author><keyname>Henschel</keyname><forenames>Leonie</forenames></author><author><keyname>Conjeti</keyname><forenames>Sailesh</forenames></author><author><keyname>Estrada</keyname><forenames>Santiago</forenames></author><author><keyname>Diers</keyname><forenames>Kersten</forenames></author><author><keyname>Fischl</keyname><forenames>Bruce</forenames></author><author><keyname>Reuter</keyname><forenames>Martin</forenames></author></authors><title>FastSurfer -- A fast and accurate deep learning based neuroimaging
  pipeline</title><categories>eess.IV cs.CV q-bio.NC</categories><comments>Submitted to NeuroImage</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional neuroimage analysis pipelines involve computationally intensive,
time-consuming optimization steps, and thus, do not scale well to large cohort
studies with thousands or tens of thousands of individuals. In this work we
propose a fast and accurate deep learning based neuroimaging pipeline for the
automated processing of structural human brain MRI scans, including surface
reconstruction and cortical parcellation. To this end, we introduce an advanced
deep learning architecture capable of whole brain segmentation into 95 classes
in under 1 minute, mimicking FreeSurfer's anatomical segmentation and cortical
parcellation. The network architecture incorporates local and global
competition via competitive dense blocks and competitive skip pathways, as well
as multi-slice information aggregation that specifically tailor network
performance towards accurate segmentation of both cortical and sub-cortical
structures. Further, we perform fast cortical surface reconstruction and
thickness analysis by introducing a spectral spherical embedding and by
directly mapping the cortical labels from the image to the surface. This
approach provides a full FreeSurfer alternative for volumetric analysis (within
1 minute) and surface-based thickness analysis (within only around 1h run
time). For sustainability of this approach we perform extensive validation: we
assert high segmentation accuracy on several unseen datasets, measure
generalizability and demonstrate increased test-retest reliability, and
increased sensitivity to disease effects relative to traditional FreeSurfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03928</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03928</id><created>2019-10-08</created><authors><author><keyname>Zhao</keyname><forenames>Huangxuan</forenames></author><author><keyname>Ke</keyname><forenames>Ziwen</forenames></author><author><keyname>Chen</keyname><forenames>Ningbo</forenames></author><author><keyname>Li</keyname><forenames>Ke</forenames></author><author><keyname>Wang</keyname><forenames>Lidai</forenames></author><author><keyname>Gong</keyname><forenames>Xiaojing</forenames></author><author><keyname>Zheng</keyname><forenames>Wei</forenames></author><author><keyname>Song</keyname><forenames>Liang</forenames></author><author><keyname>Liu</keyname><forenames>Zhicheng</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author><author><keyname>Liu</keyname><forenames>Chengbo</forenames></author></authors><title>A New Deep Learning Method for Image Deblurring in Optical Microscopic
  Systems</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deconvolution is the most commonly used image processing method to remove the
blur caused by the point-spread-function (PSF) in optical imaging systems.
While this method has been successful in deblurring, it suffers from several
disadvantages including being slow, since it takes many iterations, suboptimal,
in cases where experimental operator chosen to represent PSF is not optimal. In
this paper, we are proposing a deep-learning-based deblurring method applicable
to optical microscopic imaging systems. We tested the proposed method in
database data, simulated data, and experimental data (include 2D optical
microscopic data and 3D photoacoustic microscopic data), all of which showed
much improved deblurred results compared to deconvolution. To quantify the
improved performance, we compared our results against several deconvolution
methods. Our results are better than conventional techniques and do not require
multiple iterations or pre-determined experimental operator. Our method has the
advantages of simple operation, short time to compute, good deblur results and
wide application in all types of optical microscopic imaging systems. The deep
learning approach opens up a new path for deblurring and can be applied in
various biomedical imaging fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03960</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03960</id><created>2019-10-09</created><authors><author><keyname>Ovchinnikov</keyname><forenames>Alexey</forenames></author><author><keyname>Pogudin</keyname><forenames>Gleb</forenames></author><author><keyname>Thompson</keyname><forenames>Peter</forenames></author></authors><title>Input-output equations and identifiability of linear ODE models</title><categories>math.DS cs.SC cs.SY eess.SY math.AC</categories><msc-class>12H05, 34A55, 92B05, 93C15, 93B25, 93B30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural identifiability is a property of a differential model with
parameters that allows for the parameters to be determined from the model
equations in the absence of noise. The method of input-output equations is one
method for verifying structural identifiability. This method stands out in its
importance because the additional insights it provides can be used to analyze
and improve models. However, its complete theoretical grounds and applicability
are still to be established. A subtlety and key for this method to work is
knowing if the coefficients of these equations are identifiable.
  In this paper, to address this, we prove identifiability of the coefficients
of input-output equations for types of differential models that often appear in
practice, such as linear models with one output and linear compartment models
in which, from each compartment, one can reach either a leak or an input. This
shows that checking identifiability via input-output equations for these models
is legitimate and, as we prove, that the field of identifiable functions is
generated by the coefficients of the input-output equations. For a linear
compartment model with an input and strongly connected graph, the field of all
identifiable functions is generated by the coefficients of the equations
obtained from the model just using Cramer's rule, as we show.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03980</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03980</id><created>2019-10-04</created><authors><author><keyname>Mariani</keyname><forenames>Andrea</forenames></author><author><keyname>Giorgetti</keyname><forenames>Andrea</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>Model Order Selection Based on Information Theoretic Criteria: Design of
  the Penalty</title><categories>stat.ML cs.LG eess.SP</categories><comments>11 pages, 8 figures, journal</comments><journal-ref>IEEE Trans. on Signal Processing, vol. 63, no. 11, pp. 2779-2789,
  June 2015</journal-ref><doi>10.1109/TSP.2015.2414900</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information theoretic criteria (ITC) have been widely adopted in engineering
and statistics for selecting, among an ordered set of candidate models, the one
that better fits the observed sample data. The selected model minimizes a
penalized likelihood metric, where the penalty is determined by the criterion
adopted. While rules for choosing a penalty that guarantees a consistent
estimate of the model order are known, theoretical tools for its design with
finite samples have never been provided in a general setting. In this paper, we
study model order selection for finite samples under a design perspective,
focusing on the generalized information criterion (GIC), which embraces the
most common ITC. The theory is general, and as case studies we consider: a) the
problem of estimating the number of signals embedded in additive white Gaussian
noise (AWGN) by using multiple sensors; b) model selection for the general
linear model (GLM), which includes e.g. the problem of estimating the number of
sinusoids in AWGN. The analysis reveals a trade-off between the probabilities
of overestimating and underestimating the order of the model. We then propose
to design the GIC penalty to minimize underestimation while keeping the
overestimation probability below a specified level. For the considered
problems, this method leads to analytical derivation of the optimal penalty for
a given sample size. A performance comparison between the penalty optimized GIC
and common AIC and BIC is provided, demonstrating the effectiveness of the
proposed design strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03986</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.03986</id><created>2019-10-09</created><authors><author><keyname>Aresta</keyname><forenames>Guilherme</forenames></author><author><keyname>Ferreira</keyname><forenames>Carlos</forenames></author><author><keyname>Pedrosa</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Ara&#xfa;jo</keyname><forenames>Teresa</forenames></author><author><keyname>Rebelo</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Negr&#xe3;o</keyname><forenames>Eduardo</forenames></author><author><keyname>Morgado</keyname><forenames>Margarida</forenames></author><author><keyname>Alves</keyname><forenames>Filipe</forenames></author><author><keyname>Cunha</keyname><forenames>Ant&#xf3;nio</forenames></author><author><keyname>Ramos</keyname><forenames>Isabel</forenames></author><author><keyname>Campilho</keyname><forenames>Aur&#xe9;lio</forenames></author></authors><title>Did you miss it? Automatic lung nodule detection combined with gaze
  information improves radiologists' screening performance</title><categories>eess.IV cs.CV</categories><comments>Submitted to IEEE Transactions on Biomedical Engineering (TBME)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Early diagnosis of lung cancer via computed tomography can significantly
reduce the morbidity and mortality rates associated with the pathology.
However, search lung nodules is a high complexity task, which affects the
success of screening programs. Whilst computer-aided detection systems can be
used as second observers, they may bias radiologists and introduce significant
time overheads. With this in mind, this study assesses the potential of using
gaze information for integrating automatic detection systems in the clinical
practice. For that purpose, 4 radiologists were asked to annotate 20 scans from
a public dataset while being monitored by an eye tracker device and an
automatic lung nodule detection system was developed. Our results show that
radiologists follow a similar search routine and tend to have lower fixation
periods in regions where finding errors occur. The overall detection
sensitivity of the specialists was 0.67$\pm$0.07, whereas the system achieved
0.69. Combining the annotations of one radiologist with the automatic system
significantly improves the detection performance to similar levels of two
annotators. Likewise, combining the findings of radiologist with the detection
algorithm only for low fixation regions still significantly improves the
detection sensitivity without increasing the number of false-positives. The
combination of the automatic system with the gaze information allows to
mitigate possible errors of the radiologist without some of the issues usually
associated with automatic detection system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04024</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04024</id><created>2019-10-09</created><updated>2019-10-29</updated><authors><author><keyname>Terzi</keyname><forenames>Enrico</forenames></author><author><keyname>Farina</keyname><forenames>Marcello</forenames></author><author><keyname>Scattolini</keyname><forenames>Riccardo</forenames></author></authors><title>Model predictive control design for dynamical systems learned by Long
  Short-Term Memory Networks</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the stability-related properties of Long Short-Term Memory
(LSTM) networks are analyzed, and their use as the model of the plant in the
design of Model Predictive Controllers (MPC) is investigated. First, sufficient
conditions guaranteeing Incremental Input-to-State stability (dISS) of LSTM are
derived, and it is shown that this property can be enforced during the training
of the network. Then, the design of an observer with guaranteed convergence of
the state estimate to the true one is addressed, the observer is then embedded
in a MPC scheme designed for the solution of the tracking problem. The
resulting closed-loop scheme is proved to be asymptotically stable. The
training algorithm and control scheme are tested numerically on the simulator
of a pH reactor, the reported results confirm the effectiveness of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04027</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04027</id><created>2019-10-09</created><authors><author><keyname>Jarus</keyname><forenames>Natasha</forenames></author><author><keyname>Sarvestani</keyname><forenames>Sahra Sedigh</forenames></author><author><keyname>Hurson</keyname><forenames>Ali R.</forenames></author></authors><title>Towards Refinement and Generalization of Reliability Models Based on
  Component States</title><categories>eess.SY cs.SY</categories><comments>To appear in proceedings of Resilience Week '19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex system design often proceeds in an iterative fashion, starting from a
high-level model and adding detail as the design matures. This process can be
assisted by metamodeling techniques that automate some model manipulations and
check for or eliminate modeling mistakes. Our work focuses on metamodeling
reliability models: we describe generalization and refinement operations for
these models. Generalization relaxes constraints that may be infeasible or
costly to evaluate; refinement adds further detail to produce a model that more
closely describes the desired system. We define these operations in terms of
operations on system constraints. To illustrate the proposed method, we relate
these constraints to a common Markov chain-based reliability modeling
formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04028</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04028</id><created>2019-10-04</created><authors><author><keyname>Hou</keyname><forenames>Qingchun</forenames></author><author><keyname>Yu</keyname><forenames>Yanghao</forenames></author><author><keyname>Du</keyname><forenames>Ershun</forenames></author><author><keyname>He</keyname><forenames>Hongjie</forenames></author><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Kang</keyname><forenames>Chongqing</forenames></author><author><keyname>Liu</keyname><forenames>Guojing</forenames></author><author><keyname>Zhu</keyname><forenames>Huan</forenames></author></authors><title>Embedding Lithium-ion Battery Scrapping Criterion and Degradation Model
  in Optimal Operation of Peak-shaving Energy Storage</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lithium-ion battery systems have been deployed in practical power system for
peak-shaving, demand response, and frequency regulation. The lithium-ion
battery is degrading while cycling and would be scrapped when the capacity is
reduced to a certain threshold (e.g. 80%). Such scrapping criterion may not
explore maximum benefit from the battery storage. In this paper, we propose a
novel scrapping criterion for peak-shaving energy storage based on battery
efficiency, time-of-use prices, and arbitrage benefit. Using this scrapping
criterion to determine the end of battery life, a new lithium-ion battery life
model with scrapping parameters is then derived. Embedded with the degradation
model, an optimal operation method for peak-shaving energy storage system is
presented. The results of case study show that the operation method could
maximize the benefits of peak-shaving energy storage while delaying battery
degradation. Compared with the traditional 80% capacity-based scrapping
criterion, the proposed efficiency-based scrapping criterion can improve
lifetime benefit of battery by 100%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04030</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04030</id><created>2019-10-09</created><authors><author><keyname>Singh</keyname><forenames>Malay</forenames></author><author><keyname>Kalaw</keyname><forenames>Emarene Mationg</forenames></author><author><keyname>Jie</keyname><forenames>Wang</forenames></author><author><keyname>Al-Shabi</keyname><forenames>Mundher</forenames></author><author><keyname>Wong</keyname><forenames>Chin Fong</forenames></author><author><keyname>Giron</keyname><forenames>Danilo Medina</forenames></author><author><keyname>Chong</keyname><forenames>Kian-Tai</forenames></author><author><keyname>Tan</keyname><forenames>Maxine</forenames></author><author><keyname>Zeng</keyname><forenames>Zeng</forenames></author><author><keyname>Lee</keyname><forenames>Hwee Kuan</forenames></author></authors><title>Cribriform pattern detection in prostate histopathological images using
  deep learning models</title><categories>eess.IV cs.CV</categories><comments>21 pages, 4 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Architecture, size, and shape of glands are most important patterns used by
pathologists for assessment of cancer malignancy in prostate histopathological
tissue slides. Varying structures of glands along with cumbersome manual
observations may result in subjective and inconsistent assessment. Cribriform
gland with irregular border is an important feature in Gleason pattern 4. We
propose using deep neural networks for cribriform pattern classification in
prostate histopathological images. $163708$ Hematoxylin and Eosin (H\&amp;E)
stained images were extracted from histopathologic tissue slides of $19$
patients with prostate cancer and annotated for cribriform patterns. Our
automated image classification system analyses the H\&amp;E images to classify them
as either `Cribriform' or `Non-cribriform'. Our system uses various deep
learning approaches and hand-crafted image pixel intensity-based features. We
present our results for cribriform pattern detection across various parameters
and configuration allowed by our system. The combination of fine-tuned deep
learning models outperformed the state-of-art nuclei feature based methods. Our
image classification system achieved the testing accuracy of $85.93~\pm~7.54$
(cross-validated) and $88.04~\pm~5.63$ ( additional unseen test set) across
three folds. In this paper, we present an annotated cribriform dataset along
with analysis of deep learning models and hand-crafted features for cribriform
pattern detection in prostate histopathological images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04033</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04033</id><created>2019-10-02</created><authors><author><keyname>Shishegar</keyname><forenames>Shadab</forenames></author><author><keyname>Duchesne</keyname><forenames>Sophie</forenames></author><author><keyname>Pelletier</keyname><forenames>Genevieve</forenames></author></authors><title>Predictive Real-Time Control Optimization of a Stormwater Management
  System</title><categories>eess.SY cs.SY</categories><comments>Presented at IEEE-ICCA 2019 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimization model of a stormwater pond is developed to improve the
performance of the system in terms of water quantity and quality. Nowadays,
stormwater management systems play an important role in mitigating the impacts
of urbanization on the natural hydrological cycle. These systems can be managed
in such a way that they meet smart city needs. An automated dynamically managed
system that can adapt itself to ever-changing environmental conditions can be
modeled using a mathematical optimization approach. Hence, a Predictive
Real-Time Control (PRTC) approach is proposed in this paper to optimize the
performance of stormwater management basins in terms of minimizing hydraulic
shocks during wet periods. Then some generalized rules are designed to control
the sedimentation of trapped water in the pond during dry periods to improve
the quality of water discharged to the receiving stream. The combination of
these two approaches provides a real-time improved performance in comparison to
the static strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04038</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04038</id><created>2019-09-09</created><authors><author><keyname>Smolyaninov</keyname><forenames>Igor I.</forenames></author><author><keyname>Balzano</keyname><forenames>Quirino</forenames></author><author><keyname>Young</keyname><forenames>Dendy</forenames></author></authors><title>Surface wave-based radio communication through conductive enclosures</title><categories>eess.SP physics.class-ph</categories><comments>8 pages, 8 figures</comments><journal-ref>PIER M 85, 21-28 (2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A surface wave antenna operating in the 2.4 GHz band and efficient for
launching surface electromagnetic waves at metal/dielectric interfaces is
presented. The antenna operation is based on the strong field enhancement at
the antenna tip, which results in efficient excitation of surface waves
propagating along nearby metal surfaces. Since surface electromagnetic waves
may efficiently tunnel through deeply subwavelength channels from inner to
outer metal/dielectric interface of a metal enclosure, this antenna is useful
for broadband radio communication through various conductive enclosures, such
as typical commercial Faraday cages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04044</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04044</id><created>2019-10-08</created><authors><author><keyname>Barlyaeva</keyname><forenames>Tatiana</forenames></author><author><keyname>Barata</keyname><forenames>Teresa</forenames></author><author><keyname>Morozova</keyname><forenames>Anna</forenames></author></authors><title>&quot;SCINDA-Iono&quot; toolbox for MATLAB: analysis of ionosphere scintillations</title><categories>astro-ph.IM astro-ph.SR eess.SP physics.space-ph</categories><comments>11 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we present a &quot;SCINDA-Iono&quot; toolbox for the MATLAB. This is a software to
analyze ionosphere scintillation indices provided by a SCINDA GNSS receiver.
The toolbox is developed in the MATLAB R2018b. This software allows to
preprocess the original data and analyze ionosphere scintillations on the
1-minute and 1-hour time scales both for averaged over all available satellites
values and separately for each receiver-satellite pair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04052</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04052</id><created>2019-10-09</created><authors><author><keyname>Zecchino</keyname><forenames>Antonio</forenames></author><author><keyname>Yuan</keyname><forenames>Zhao</forenames></author><author><keyname>Sossan</keyname><forenames>Fabrizio</forenames></author><author><keyname>Cherkaoui</keyname><forenames>Rachid</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Optimal Provision of Concurrent Primary Frequency and Local Voltage
  Control from a BESS Considering Variable Capability Curves: Modelling and
  Experimental Assessment</title><categories>eess.SY cs.SY</categories><comments>submitted to pscc2020, zhao.yuan@epfl.ch</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a control method for battery energy storage systems
(BESSs) to provide concurrent primary frequency and local voltage regulation
services. The actual variable active and reactive power capability of the
converter, along with the state-of-energy of the battery in the BESS, are
jointly considered by the optimal operating point calculation process within
the real-time control operation. The controller optimizes the provision of grid
services, considering the measured grid and battery statuses and predicting the
battery DC voltage as a function of the current trajectory using a
three-time-constant model (TTC). A computationally-efficient algorithm is
proposed to solve the formulated optimal control problem. Experimental tests
validate the proposed concepts and show the effectiveness of the employed
control framework on a commercial utility-scale 720 kVA/560 kWh BESS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04071</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04071</id><created>2019-10-09</created><updated>2019-11-25</updated><authors><author><keyname>Maier-Hein</keyname><forenames>Lena</forenames></author><author><keyname>Reinke</keyname><forenames>Annika</forenames></author><author><keyname>Kozubek</keyname><forenames>Michal</forenames></author><author><keyname>Martel</keyname><forenames>Anne L.</forenames></author><author><keyname>Arbel</keyname><forenames>Tal</forenames></author><author><keyname>Eisenmann</keyname><forenames>Matthias</forenames></author><author><keyname>Hanbuary</keyname><forenames>Allan</forenames></author><author><keyname>Jannin</keyname><forenames>Pierre</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Henning</forenames></author><author><keyname>Onogur</keyname><forenames>Sinan</forenames></author><author><keyname>Saez-Rodriguez</keyname><forenames>Julio</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author><author><keyname>Kopp-Schneider</keyname><forenames>Annette</forenames></author><author><keyname>Landman</keyname><forenames>Bennett</forenames></author></authors><title>BIAS: Transparent reporting of biomedical image analysis challenges</title><categories>cs.CV cs.CY eess.IV</categories><comments>4 Supplements: Suppl 1: Reviewer checklist Suppl 2: Gloassary Suppl
  3: Form for summarizing information on challenge organization Suppl 4:
  Structured description of a challenge design</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of biomedical image analysis challenges organized per year is
steadily increasing. These international competitions have the purpose of
benchmarking algorithms on common data sets, typically to identify the best
method for a given problem. Recent research, however, revealed that common
practice related to challenge reporting does not allow for adequate
interpretation and reproducibility of results. To address the discrepancy
between the impact of challenges and the quality (control), the Biomedical I
mage Analysis ChallengeS (BIAS) initiative developed a set of recommendations
for the reporting of challenges. The BIAS statement aims to improve the
transparency of the reporting of a biomedical image analysis challenge
regardless of field of application, image modality or task category assessed.
This article describes how the BIAS statement was developed and presents a
checklist which authors of biomedical image analysis challenges are encouraged
to include in their submission when giving a paper on a challenge into review.
The purpose of the checklist is to standardize and facilitate the review
process and raise interpretability and reproducibility of challenge results by
making relevant information explicit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04074</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04074</id><created>2019-10-09</created><authors><author><keyname>Deng</keyname><forenames>Xin</forenames></author><author><keyname>Yang</keyname><forenames>Ren</forenames></author><author><keyname>Xu</keyname><forenames>Mai</forenames></author><author><keyname>Dragotti</keyname><forenames>Pier Luigi</forenames></author></authors><title>Wavelet Domain Style Transfer for an Effective Perception-distortion
  Tradeoff in Single Image Super-Resolution</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In single image super-resolution (SISR), given a low-resolution (LR) image,
one wishes to find a high-resolution (HR) version of it which is both accurate
and photo-realistic. Recently, it has been shown that there exists a
fundamental tradeoff between low distortion and high perceptual quality, and
the generative adversarial network (GAN) is demonstrated to approach the
perception-distortion (PD) bound effectively. In this paper, we propose a novel
method based on wavelet domain style transfer (WDST), which achieves a better
PD tradeoff than the GAN based methods. Specifically, we propose to use 2D
stationary wavelet transform (SWT) to decompose one image into low-frequency
and high-frequency sub-bands. For the low-frequency sub-band, we improve its
objective quality through an enhancement network. For the high-frequency
sub-band, we propose to use WDST to effectively improve its perceptual quality.
By feat of the perfect reconstruction property of wavelets, these sub-bands can
be re-combined to obtain an image which has simultaneously high objective and
perceptual quality. The numerical results on various datasets show that our
method achieves the best trade-off between the distortion and perceptual
quality among the existing state-of-the-art SISR methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04076</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04076</id><created>2019-10-07</created><updated>2019-10-10</updated><authors><author><keyname>Kumar</keyname><forenames>Varun Ravi</forenames></author><author><keyname>Hiremath</keyname><forenames>Sandesh Athni</forenames></author><author><keyname>Milz</keyname><forenames>Stefan</forenames></author><author><keyname>Witt</keyname><forenames>Christian</forenames></author><author><keyname>Pinnard</keyname><forenames>Clement</forenames></author><author><keyname>Yogamani</keyname><forenames>Senthil</forenames></author><author><keyname>Mader</keyname><forenames>Patrick</forenames></author></authors><title>FisheyeDistanceNet: Self-Supervised Scale-Aware Distance Estimation
  using Monocular Fisheye Camera for Autonomous Driving</title><categories>cs.CV cs.LG cs.RO eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fisheye cameras are commonly used in applications like autonomous driving and
surveillance to provide a large field of view ($&gt;180^\circ$). However, they
come at the cost of strong non-linear distortion which require more complex
algorithms. In this paper, we explore Euclidean distance estimation on fisheye
cameras for automotive scenes. Obtaining accurate and dense depth supervision
is difficult in practice, but self-supervised learning approaches show
promising results and could potentially overcome the problem. We present a
novel self-supervised scale-aware framework for learning Euclidean distance and
ego-motion from raw monocular fisheye videos without applying rectification.
While it is possible to perform piece-wise linear approximation of fisheye
projection surface and apply standard rectilinear models, it has its own set of
issues like re-sampling distortion and discontinuities in transition regions.
To encourage further research in this area, we will release this dataset as
part of our WoodScape project \cite{yogamani2019woodscape}. We further
evaluated the proposed algorithm on the KITTI dataset and obtained
state-of-the-art results comparable to other self-supervised monocular methods.
Qualitative results on an unseen fisheye video demonstrate impressive
performance, see https://youtu.be/Sgq1WzoOmXg .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04081</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04081</id><created>2019-10-09</created><authors><author><keyname>Liu</keyname><forenames>Zhengchun</forenames></author><author><keyname>Bicer</keyname><forenames>Tekin</forenames></author><author><keyname>Kettimuthu</keyname><forenames>Rajkumar</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author></authors><title>Deep Learning Accelerated Light Source Experiments</title><categories>eess.IV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experimental protocols at synchrotron light sources typically process and
validate data only after an experiment has completed, which can lead to
undetected errors and cannot enable online steering. Real-time data analysis
can enable both detection of, and recovery from, errors, and optimization of
data acquisition. However, modern scientific instruments, such as detectors at
synchrotron light sources, can generate data at GBs/sec rates. Data processing
methods such as the widely used computational tomography usually require
considerable computational resources, and yield poor quality reconstructions in
the early stages of data acquisition when available views are sparse. We
describe here how a deep convolutional neural network can be integrated into
the real-time streaming tomography pipeline to enable better-quality images in
the early stages of data acquisition. Compared with conventional streaming
tomography processing, our method can significantly improve tomography image
quality, deliver comparable images using only 32% of the data needed for
conventional streaming processing, and save 68% experiment time for data
acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04099</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04099</id><created>2019-10-09</created><updated>2019-10-24</updated><authors><author><keyname>Zou</keyname><forenames>Chuhang</forenames></author><author><keyname>Su</keyname><forenames>Jheng-Wei</forenames></author><author><keyname>Peng</keyname><forenames>Chi-Han</forenames></author><author><keyname>Colburn</keyname><forenames>Alex</forenames></author><author><keyname>Shan</keyname><forenames>Qi</forenames></author><author><keyname>Wonka</keyname><forenames>Peter</forenames></author><author><keyname>Chu</keyname><forenames>Hung-Kuo</forenames></author><author><keyname>Hoiem</keyname><forenames>Derek</forenames></author></authors><title>3D Manhattan Room Layout Reconstruction from a Single 360 Image</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent approaches for predicting layouts from 360 panoramas produce excellent
results. These approaches build on a common framework consisting of three
steps: a pre-processing step based on edge-based alignment, prediction of
layout elements, and a post-processing step by fitting a 3D layout to the
layout elements. Until now, it has been difficult to compare the methods due to
multiple different design decisions, such as the encoding network (e.g. SegNet
or ResNet), type of elements predicted (e.g. corners, wall/floor boundaries, or
semantic segmentation), or method of fitting the 3D layout. To address this
challenge, we summarize and describe the common framework, the variants, and
the impact of the design decisions. For a complete evaluation, we also propose
extended annotations for the Matterport3D dataset, and introduce two
depth-based evaluation metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04105</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04105</id><created>2019-10-09</created><updated>2019-10-28</updated><authors><author><keyname>Romero</keyname><forenames>Francisco Perdigon</forenames></author><author><keyname>Montagnon</keyname><forenames>Emmanuel</forenames></author><author><keyname>Cerny</keyname><forenames>Milena</forenames></author><author><keyname>Cadrin-Ch&#xea;nevert</keyname><forenames>Alexandre</forenames></author><author><keyname>Trudel</keyname><forenames>Dominique</forenames></author><author><keyname>Nguyen</keyname><forenames>Bich</forenames></author><author><keyname>Mes-Masson</keyname><forenames>Anne-Marie</forenames></author><author><keyname>Vandenbroucke</keyname><forenames>Franck</forenames></author><author><keyname>Genevi&#xe8;ve</keyname><forenames>Soucy</forenames></author><author><keyname>Turcotte</keyname><forenames>Simon</forenames></author><author><keyname>Tang</keyname><forenames>An</forenames></author><author><keyname>Kadoury</keyname><forenames>Samuel</forenames></author></authors><title>Predictive Model for Assessment of Pathological Response of Colorectal
  Liver Metastases to Chemotherapy from CT Images</title><categories>eess.IV</categories><comments>problem with results session, numbers are incorrect</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a predictive deep learning model for assessment of
pathological response of colorectal liver metastases to chemotherapy from CT
images. We conducted a retrospective analysis of a prospectively maintained
database of patients who underwent partial hepatectomy or biopsy of colorectal
liver metastases. We introduce a novel variant of the Inception module that
includes instance normalization layers to accommodate for various contrast
agent timing and baseline examinations. The clinical Rubbia-Brandt tumor
regression grade (TRG) obtained from histopathology images of the resected
lesions was used as ground truth. For the most common TRG dichotomization, our
model achieves an AUC of 0.87 ${\pm}$ 0.03. The results show that the model is
able to establish a link between CT images and the pathological assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04154</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04154</id><created>2019-10-07</created><authors><author><keyname>Zhang</keyname><forenames>Zhaoji</forenames></author><author><keyname>Li</keyname><forenames>Ying</forenames></author><author><keyname>Huang</keyname><forenames>Chongwen</forenames></author><author><keyname>Guo</keyname><forenames>Qinghua</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author></authors><title>DNN-Aided Message Passing Based Block Sparse Bayesian Learning for Joint
  User Activity Detection and Channel Estimation</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 4 figures. arXiv admin note: substantial text overlap with
  arXiv:1910.02953</comments><journal-ref>presented at 2019 IEEE VTS Asia Pacific Wireless Communications
  Symposium (APWCS)</journal-ref><doi>10.1109/VTS-APWCS.2019.8851613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Faced with the massive connection, sporadic transmission, and small-sized
data packets in future cellular communication, a grant-free non-orthogonal
random access (NORA) system is considered in this paper, which could reduce the
access delay and support more devices. In order to address the joint user
activity detection (UAD) and channel estimation (CE) problem in the grant-free
NORA system, we propose a deep neural network-aided message passing-based block
sparse Bayesian learning (DNN-MP-BSBL) algorithm. In this algorithm, the
message passing process is transferred from a factor graph to a deep neural
network (DNN). Weights are imposed on the messages in the DNN and trained to
minimize the estimation error. It is shown that the weights could alleviate the
convergence problem of the MP-BSBL algorithm. Simulation results show that the
proposed DNN-MP-BSBL algorithm could improve the UAD and CE accuracy with a
smaller number of iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04193</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04193</id><created>2019-10-09</created><authors><author><keyname>Toledo</keyname><forenames>Jesus</forenames></author><author><keyname>Wu</keyname><forenames>Yongxin</forenames></author><author><keyname>Ramirez</keyname><forenames>Hector</forenames></author><author><keyname>Gorrec</keyname><forenames>Yann Le</forenames></author></authors><title>Observer-based boundary control of distributed port-Hamiltonian systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An observer based boundary controller for infinite-dimensional
port-Hamiltonian system defined on 1D spatial domains is proposed. The design
is based on an early-lumping approach in which a finite-dimensional
approximation of the infinite-dimensional system is used to design the observer
and the controller. The main contribution is a constructive method which
guarantees that the interconnection between the controller and the
infinite-dimensional system is asymptotically stable. A Timoshenko beam model
has been used to illustrate the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04237</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04237</id><created>2019-10-09</created><authors><author><keyname>Chowdhury</keyname><forenames>Md Moin Uddin</forenames></author><author><keyname>Maeng</keyname><forenames>Sung Joon</forenames></author><author><keyname>Bulut</keyname><forenames>Eyuphan</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>3D Trajectory Optimization in UAV-Assisted Cellular Networks Considering
  Antenna Radiation Pattern and Backhaul Constraint</title><categories>eess.SP</categories><comments>Submitted to IEEE Transaction on Aerospace and Electronic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the effects of three-dimensional (3D) antenna radiation
pattern and backhaul constraint on optimal 3D path planning problem of an
unmanned aerial vehicle (UAV), in interference prevalent downlink cellular
networks. We consider a cellular-connected UAV that is tasked to travel between
two locations within a fixed time and it can be used to improve the cellular
connectivity of ground users by acting as a relay. Since the antenna gain of a
cellular base station changes significantly with the UAV altitude, the UAV can
increase the signal quality in its backhaul link by changing its height over
the course of its mission. This problem is non-convex and thus, we explore the
dynamic programming technique to solve it. We show that the 3D optimal paths
can introduce significant network performance gain over the trajectories with
fixed UAV heights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04249</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04249</id><created>2019-10-09</created><authors><author><keyname>Fazlyab</keyname><forenames>Mahyar</forenames></author><author><keyname>Morari</keyname><forenames>Manfred</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Probabilistic Verification and Reachability Analysis of Neural Networks
  via Semidefinite Programming</title><categories>eess.SY cs.LG cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantifying the robustness of neural networks or verifying their safety
properties against input uncertainties or adversarial attacks have become an
important research area in learning-enabled systems. Most results concentrate
around the worst-case scenario where the input of the neural network is
perturbed within a norm-bounded uncertainty set. In this paper, we consider a
probabilistic setting in which the uncertainty is random with known first two
moments. In this context, we discuss two relevant problems: (i) probabilistic
safety verification, in which the goal is to find an upper bound on the
probability of violating a safety specification; and (ii) confidence ellipsoid
estimation, in which given a confidence ellipsoid for the input of the neural
network, our goal is to compute a confidence ellipsoid for the output. Due to
the presence of nonlinear activation functions, these two problems are very
difficult to solve exactly. To simplify the analysis, our main idea is to
abstract the nonlinear activation functions by a combination of affine and
quadratic constraints they impose on their input-output pairs. We then show
that the safety of the abstracted network, which is sufficient for the safety
of the original network, can be analyzed using semidefinite programming. We
illustrate the performance of our approach with numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04250</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04250</id><created>2019-10-07</created><authors><author><keyname>Mak</keyname><forenames>Terrence W. K.</forenames></author><author><keyname>Fioretto</keyname><forenames>Ferdinando</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames></author></authors><title>Privacy-Preserving Obfuscation for Distributed Power Systems</title><categories>math.OC cs.CR cs.MA cs.SY eess.SY</categories><comments>Total 10 pages: main body 8 pages, reference 1 page, appendix 2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of releasing privacy-preserving load data of
a decentralized operated power system. The paper focuses on data used to solve
Optimal Power Flow (OPF) problems and proposes a distributed algorithm that
complies with the notion of Differential Privacy, a strong privacy framework
used to bound the risk of re-identification. The problem is challenging since
the application of traditional differential privacy mechanisms to the load data
fundamentally changes the nature of the underlying optimization problem and
often leads to severe feasibility issues. The proposed differentially private
distributed algorithm is based on the Alternating Direction Method of
Multipliers (ADMM) and guarantees that the released privacy-preserving data
retains high fidelity and satisfies the AC power flow constraints. Experimental
results on a variety of OPF benchmarks demonstrate the effectiveness of the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04254</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04254</id><created>2019-10-09</created><updated>2019-11-29</updated><authors><author><keyname>Preuhs</keyname><forenames>Alexander</forenames></author><author><keyname>Manhart</keyname><forenames>Michael</forenames></author><author><keyname>Roser</keyname><forenames>Philipp</forenames></author><author><keyname>Stimpel</keyname><forenames>Bernhard</forenames></author><author><keyname>Syben</keyname><forenames>Christopher</forenames></author><author><keyname>Psychogios</keyname><forenames>Marios</forenames></author><author><keyname>Kowarschik</keyname><forenames>Markus</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Image Quality Assessment for Rigid Motion Compensation</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted at MedNeurips 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diagnostic stroke imaging with C-arm cone-beam computed tomography (CBCT)
enables reduction of time-to-therapy for endovascular procedures. However, the
prolonged acquisition time compared to helical CT increases the likelihood of
rigid patient motion. Rigid motion corrupts the geometry alignment assumed
during reconstruction, resulting in image blurring or streaking artifacts. To
reestablish the geometry, we estimate the motion trajectory by an autofocus
method guided by a neural network, which was trained to regress the
reprojection error, based on the image information of a reconstructed slice.
The network was trained with CBCT scans from 19 patients and evaluated using an
additional test patient. It adapts well to unseen motion amplitudes and
achieves superior results in a motion estimation benchmark compared to the
commonly used entropy-based method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04265</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04265</id><created>2019-10-09</created><updated>2019-10-15</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Jonchay</keyname><forenames>Tristan Sarton du</forenames></author><author><keyname>Hou</keyname><forenames>Linyi</forenames></author><author><keyname>Ho</keyname><forenames>Koki</forenames></author></authors><title>Multi-Fidelity Space Mission Planning and Infrastructure Design
  Framework for Space Resource Logistics</title><categories>math.OC cs.SY eess.SY</categories><comments>34 pages, 3 figures, presented at the AIAA Propulsion and Energy
  Forum 2019, submitted to the Journal of Spacecraft and Rockets</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To build a sustainable and affordable space transportation system for human
space exploration, the design and deployment of space infrastructures are
critical; one attractive and promising infrastructure system is the in-situ
resource utilization (ISRU) system. The design analysis and trade studies for
ISRU systems require the consideration of not only the design of the ISRU plant
itself but also other infrastructure systems (e.g., storage, power) and various
ISRU architecture options (e.g., resource, location, technology). This paper
proposes a system-level space infrastructure and its logistics design
optimization framework to perform architecture trade studies. A new space
infrastructure logistics optimization problem formulation is proposed that
considers infrastructure subsystems' internal interactions and their external
synergistic effects with space logistics simultaneously. Since the full-size
version of this proposed problem formulation can be computationally
prohibitive, a new multi-fidelity optimization formulation is developed by
varying the granularity of the commodity type definition over the network
graph; this multi-fidelity formulation can find an approximation solution to
the full-size problem computationally efficiently with little sacrifice in the
solution quality. The proposed problem formulation and method are applied to a
multi-mission lunar exploration campaign to demonstrate their values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04287</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04287</id><created>2019-10-09</created><authors><author><keyname>Tahir</keyname><forenames>Muhammad</forenames></author><author><keyname>Anwar</keyname><forenames>Saeed</forenames></author><author><keyname>Mian</keyname><forenames>Ajmal</forenames></author></authors><title>Deep localization of protein structures in fluorescence microscopy
  images</title><categories>cs.CV cs.LG eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Accurate localization of proteins from fluorescence microscopy images is a
challenging task due to the inter-class similarities and intra-class
disparities introducing grave concerns in addressing multi-class classification
problems. Conventional machine learning-based image prediction relies heavily
on pre-processing such as normalization and segmentation followed by
hand-crafted feature extraction before classification to identify useful and
informative as well as application specific features.We propose an end-to-end
Protein Localization Convolutional Neural Network (PLCNN) that classifies
protein localization images more accurately and reliably. PLCNN directly
processes raw imagery without involving any pre-processing steps and produces
outputs without any customization or parameter adjustment for a particular
dataset. The output of our approach is computed from probabilities produced by
the network. Experimental analysis is performed on five publicly available
benchmark datasets. PLCNN consistently outperformed the existing
state-of-the-art approaches from machine learning and deep architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04323</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04323</id><created>2019-10-09</created><authors><author><keyname>Liu</keyname><forenames>Rui</forenames></author><author><keyname>Zhu</keyname><forenames>Xichan</forenames></author><author><keyname>Liu</keyname><forenames>Lin</forenames></author><author><keyname>Wu</keyname><forenames>Biao</forenames></author><author><keyname>Ma</keyname><forenames>Zhixiong</forenames></author><author><keyname>Fei</keyname><forenames>Zhiwei</forenames></author><author><keyname>He</keyname><forenames>Jingwei</forenames></author></authors><title>Cooperative driving strategy based on naturalitic driving data and
  non-cooperative MPC</title><categories>eess.SY cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cooperative driving strategy is proposed, in which the dynamic driving
privilege assignment in real-time and the driving privilege gradual handover
are realized. The first issue in cooperative driving is the driving privilege
assignment based on the risk level. The risk assessment methods in 2 typical
dangerous scenarios are presented, i.e. the car-following scenario and the
cut-in scenario. The naturalistic driving data is used to study the behavior
characteristics of the driver. TTC (time to collosion) is defined as an obvious
risk measure, whereas the time before the host vehicle has to brake assuming
that the target vehicle is braking is defined as the potential risk measure,
i.e. the time margin (TM). A risk assessment algorithm is proposed based on the
obvious risk and potential risk. The naturalistic driving data are applied to
verify the effectiveness of the risk assessment algorithm. It is identified
that the risk assessment algorithm performs better than TTC in the ROC
(receiver operating characteristic). The second issue in cooperative driving is
the driving privilege gradual handover. The vehicle is jointly controlled by
the driver and automated driving system during the driving privilege gradual
handover. The non-cooperative MPC (model predictive control) is employed to
resolve the conflicts between the driver and automated driving system. It is
identified that the Nash equilibrium of the non-cooperative MPC can be achieved
by using a non-iterative method. The driving privilege gradual handover is
realized by using the confidence matrixes update. The simulation verification
shows that the the cooperative driving strategy can realize the gradual
handover of the driving privilege between the driver and automated system, and
the cooperative driving strategy can dynamically assige the driving privilege
in real-time according to the risk level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04330</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04330</id><created>2019-10-09</created><authors><author><keyname>Li</keyname><forenames>Shuaichao</forenames></author><author><keyname>Zhang</keyname><forenames>Wanqing</forenames></author><author><keyname>Cui</keyname><forenames>Ying</forenames></author><author><keyname>Cheng</keyname><forenames>Hei Victor</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Joint Design of Measurement Matrix and Sparse Support Recovery Method
  via Deep Auto-encoder</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 4 figures, to appear in IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2019.2945683</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse support recovery arises in many applications in communications and
signal processing. Existing methods tackle sparse support recovery problems for
a given measurement matrix, and cannot flexibly exploit the properties of
sparsity patterns for improving performance. In this letter, we propose a
data-driven approach to jointly design the measurement matrix and support
recovery method for complex sparse signals, using auto-encoder in deep
learning. The proposed architecture includes two components, an auto-encoder
and a hard thresholding module. The proposed auto-encoder successfully handles
complex signals using standard auto-encoder for real numbers. The proposed
approach can effectively exploit properties of sparsity patterns, and is
especially useful when these underlying properties do not have analytic models.
In addition, the proposed approach can achieve sparse support recovery with low
computational complexity. Experiments are conducted on an application ex-ample,
device activity detection in grant-free massive access for massive machine type
communications (mMTC). Numerical results show that the proposed approach
achieves significantly better performance with much less computation time than
classic methods, in the presence of extra structures in sparsity patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04331</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04331</id><created>2019-10-09</created><authors><author><keyname>Dou</keyname><forenames>Haoran</forenames></author><author><keyname>Yang</keyname><forenames>Xin</forenames></author><author><keyname>Qian</keyname><forenames>Jikuan</forenames></author><author><keyname>Xue</keyname><forenames>Wufeng</forenames></author><author><keyname>Qin</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xu</forenames></author><author><keyname>Yu</keyname><forenames>Lequan</forenames></author><author><keyname>Wang</keyname><forenames>Shujun</forenames></author><author><keyname>Xiong</keyname><forenames>Yi</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author><author><keyname>Ni</keyname><forenames>Dong</forenames></author></authors><title>Agent with Warm Start and Active Termination for Plane Localization in
  3D Ultrasound</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 5 figures, 1 table. Accepted by MICCAI 2019 (oral)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard plane localization is crucial for ultrasound (US) diagnosis. In
prenatal US, dozens of standard planes are manually acquired with a 2D probe.
It is time-consuming and operator-dependent. In comparison, 3D US containing
multiple standard planes in one shot has the inherent advantages of less
user-dependency and more efficiency. However, manual plane localization in US
volume is challenging due to the huge search space and large fetal posture
variation. In this study, we propose a novel reinforcement learning (RL)
framework to automatically localize fetal brain standard planes in 3D US. Our
contribution is two-fold. First, we equip the RL framework with a
landmark-aware alignment module to provide warm start and strong spatial bounds
for the agent actions, thus ensuring its effectiveness. Second, instead of
passively and empirically terminating the agent inference, we propose a
recurrent neural network based strategy for active termination of the agent's
interaction procedure. This improves both the accuracy and efficiency of the
localization system. Extensively validated on our in-house large dataset, our
approach achieves the accuracy of 3.4mm/9.6{\deg} and 2.7mm/9.1{\deg} for the
transcerebellar and transthalamic plane localization, respectively. Ourproposed
RL framework is general and has the potential to improve the efficiency and
standardization of US scanning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04332</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04332</id><created>2019-10-09</created><updated>2020-01-21</updated><authors><author><keyname>Lim</keyname><forenames>Michael H.</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire J.</forenames></author><author><keyname>Sunberg</keyname><forenames>Zachary N.</forenames></author></authors><title>Sparse tree search optimality guarantees in POMDPs with continuous
  observation spaces</title><categories>cs.LG cs.RO cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partially observable Markov decision processes (POMDPs) with continuous state
and observation spaces have powerful flexibility for representing real-world
decision and control problems but are notoriously difficult to solve. Recent
online sampling-based algorithms that use observation likelihood weighting have
shown unprecedented effectiveness in domains with continuous observation
spaces. However there has been no formal theoretical justification for this
technique. This work offers such a justification, proving that a simplified
algorithm, partially observable weighted sparse sampling (POWSS), will estimate
Q-values accurately with high probability and can be made to perform
arbitrarily near the optimal solution by increasing computational power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04350</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04350</id><created>2019-10-09</created><authors><author><keyname>Yin</keyname><forenames>Lu</forenames></author><author><keyname>Cao</keyname><forenames>Jiameng</forenames></author><author><keyname>Deng</keyname><forenames>Zhongliang</forenames></author><author><keyname>Ni</keyname><forenames>Qiang</forenames></author><author><keyname>Li</keyname><forenames>Song</forenames></author><author><keyname>Zheng</keyname><forenames>Xinyu</forenames></author><author><keyname>Wang</keyname><forenames>Hanhua</forenames></author></authors><title>Design and Performance Analysis of Multi-scale NOMA for 5G Positioning</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a feasibility study for a novel positioning-communication
integrated signal called Multi-Scale Non-Orthogonal Multiple Access (MS-NOMA)
for 5G positioning. One of the main differences between the MS-NOMA and the
traditional positioning signal is MS-NOMA supports configurable powers for
different positioning users (P-Users) to obtain better ranging accuracy and
signal coverage. Our major contributions are: Firstly, we present the MS-NOMA
signal and analyze the Bit Error Rate (BER) and ranging accuracy by deriving
their simple expressions. The results show the interaction between the
communication and positioning signals is rather limited, and it is feasible to
use the MS-NOMA signal to achieve high positioning accuracy. Secondly, for an
optimal positioning accuracy and signal coverage, we model the power allocation
problem for MS-NOMA signal as a convex optimization problem by satisfying the
QoS (Quality of Services) requirement and other constraints. Then, we propose a
novel Positioning-Communication Joint Power Allocation (PCJPA) algorithm which
allocates the powers of all P-Users iteratively. The theoretical and numerical
results show our proposed MS-NOMA signal has great improvements of
ranging/positioning accuracy than traditional PRS (Positioning Reference
Signal) in 5G, and improves the coverage dramatically which means more P-Users
could locate their positions without suffering the near-far effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04353</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04353</id><created>2019-10-09</created><authors><author><keyname>Gopi</keyname><forenames>Sarath</forenames></author><author><keyname>Kalyani</keyname><forenames>Sheetal</forenames></author></authors><title>An Optimized SLM for PAPR Reduction in Non-coherent OFDM-IM</title><categories>eess.SP</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose a peak-to-average power ratio (PAPR) efficient
non-coherent orthogonal frequency division multiplexing with index modulation
(OFDM-IM). It is shown that the non-coherent OFDM-IM design, which minimizes
PAPR, is a non-linear optimization problem. This can be visualized as the
optimization of the phase factor in selected mapping (SLM) technique. Further,
a special case is considered, where the inputs take only real values. We then
show how to approximately solve it using simple linear integer programming and
explicitly quantify the gap between the approximate and the optimal solutions.
A computationally efficient heuristic scheme is developed to obtain a
suboptimal solution of the integer optimization problem. Finally, our
simulation results indicate the merits of the proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04357</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04357</id><created>2019-10-09</created><authors><author><keyname>Huang</keyname><forenames>Xinyi</forenames></author><author><keyname>Jamonnak</keyname><forenames>Suphanut</forenames></author><author><keyname>Zhao</keyname><forenames>Ye</forenames></author><author><keyname>Wang</keyname><forenames>Boyu</forenames></author><author><keyname>Hoai</keyname><forenames>Minh</forenames></author><author><keyname>Yager</keyname><forenames>Kevin</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author></authors><title>Visual Understanding of Multiple Attributes Learning Model of X-Ray
  Scattering Images</title><categories>cs.LG cs.CV cs.HC eess.IV stat.ML</categories><comments>5 pages, 2 figures, ICCV conference co-held XAIC workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This extended abstract presents a visualization system, which is designed for
domain scientists to visually understand their deep learning model of
extracting multiple attributes in x-ray scattering images. The system focuses
on studying the model behaviors related to multiple structural attributes. It
allows users to explore the images in the feature space, the classification
output of different attributes, with respect to the actual attributes labelled
by domain scientists. Abundant interactions allow users to flexibly select
instance images, their clusters, and compare them visually in details. Two
preliminary case studies demonstrate its functionalities and usefulness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04378</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04378</id><created>2019-10-10</created><updated>2020-02-15</updated><authors><author><keyname>Bujarbaruah</keyname><forenames>Monimoy</forenames></author><author><keyname>Nair</keyname><forenames>Siddharth H.</forenames></author><author><keyname>Borrelli</keyname><forenames>Francesco</forenames></author></authors><title>A Semi-Definite Programming Approach to Robust Adaptive MPC under State
  Dependent Uncertainty</title><categories>eess.SY cs.SY math.OC</categories><comments>Accepted for European Control Conference (ECC), May 2020, Saint
  Petersburg, Russia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an Adaptive MPC framework for uncertain linear systems to achieve
robust satisfaction of state and input constraints. The uncertainty in the
system is assumed additive, state dependent, and globally Lipschitz with a
known Lipschitz constant. We use a non-parametric technique for online
identification of the system uncertainty by approximating its graph via
envelopes defined by quadratic constraints. At any given time, by solving a set
of convex optimization problems, the MPC controller guarantees robust
constraint satisfaction for the closed loop system for all possible values of
system uncertainty modeled by the envelope. The uncertainty envelope is refined
with data using Set Membership Methods. We highlight the efficacy of the
proposed framework via a detailed numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04379</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04379</id><created>2019-10-10</created><authors><author><keyname>Ali</keyname><forenames>T M Feroz</forenames></author></authors><title>Maneuvering, Multi-Target Tracking using Particle Filters</title><categories>eess.SP stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we develop tracking and estimation techniques relevant to
underwater targets. Particularly, we explore particle filtering techniques for
target tracking. It is a numerical approximation method for implementing a
recursive Bayesian estimation procedure. It does not require the assumptions of
linearity and Guassianity like the traditional Kalman filter based techniques
and is capable of handling non-Gaussian noise distributions and non-linearities
in the measurements as well as target dynamics. The performance of particle
filters is verified using simulations and compared with Extended Kalman Filter.
Particle filters can track multi-targets and highly maneuvering targets.
However, it has higher computational load. The efficient use of particle
filters for multi-target tracking using Independent Partition Particle Filter
(IPPF) and tracking highly maneuvering targets using Multiple Model Particle
Filter(MMPF) are also explored in this work. These techniques require only
smaller number of particles and help in reducing the computational cost. Data
association problem exists in multi-target tracking due to lack of information
at the observer about the proper association between the targets and the
received measurements. The problem becomes more involved when the targets move
much closer and there are clutter and missed target detections at the observer.
Monte Carlo Joint Probabilistic Data Association Filter (MCJPDAF) efficiently
solves data association for the mentioned situation. Due to the inability of
the standard MCJPDAF to track highly maneuvering targets, Monte Carlo Multiple
Model Joint Probabilistic Data Association Filter (MC-MMJPDAF) which combines
the technique of Multiple Model Particle Filter(MMPF) in the framework of
MC-JPDAF has been proposed. The simulation results shows the superiority of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04388</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04388</id><created>2019-10-10</created><authors><author><keyname>Mazzon</keyname><forenames>Luca</forenames></author><author><keyname>Koizumi</keyname><forenames>Yuma</forenames></author><author><keyname>Yasuda</keyname><forenames>Masahiro</forenames></author><author><keyname>Harada</keyname><forenames>Noboru</forenames></author></authors><title>First Order Ambisonics Domain Spatial Augmentation for DNN-based
  Direction of Arrival Estimation</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>5 pages, to appear in DCASE 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel data augmentation method for training
neural networks for Direction of Arrival (DOA) estimation. This method focuses
on expanding the representation of the DOA subspace of a dataset. Given some
input data, it applies a transformation to it in order to change its DOA
information and simulate new potentially unseen one. Such transformation, in
general, is a combination of a rotation and a reflection. It is possible to
apply such transformation due to a well-known property of First Order
Ambisonics (FOA). The same transformation is applied also to the labels, in
order to maintain consistency between input data and target labels. Three
methods with different level of generality are proposed for applying this
augmentation principle. Experiments are conducted on two different DOA
networks. Results of both experiments demonstrate the effectiveness of the
novel augmentation strategy by improving the DOA error by around 40%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04397</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04397</id><created>2019-10-10</created><authors><author><keyname>Byun</keyname><forenames>Junyoung</forenames></author><author><keyname>Shim</keyname><forenames>Kyujin</forenames></author><author><keyname>Kim</keyname><forenames>Changick</forenames></author></authors><title>BitNet: Learning-Based Bit-Depth Expansion</title><categories>eess.IV cs.CV</categories><comments>Accepted by ACCV 2018, Authors Byun and Shim contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit-depth is the number of bits for each color channel of a pixel in an
image. Although many modern displays support unprecedented higher bit-depth to
show more realistic and natural colors with a high dynamic range, most media
sources are still in bit-depth of 8 or lower. Since insufficient bit-depth may
generate annoying false contours or lose detailed visual appearance, bit-depth
expansion (BDE) from low bit-depth (LBD) images to high bit-depth (HBD) images
becomes more and more important. In this paper, we adopt a learning-based
approach for BDE and propose a novel CNN-based bit-depth expansion network
(BitNet) that can effectively remove false contours and restore visual details
at the same time. We have carefully designed our BitNet based on an
encoder-decoder architecture with dilated convolutions and a novel multi-scale
feature integration. We have performed various experiments with four different
datasets including MIT-Adobe FiveK, Kodak, ESPL v2, and TESTIMAGES, and our
proposed BitNet has achieved state-of-the-art performance in terms of PSNR and
SSIM among other existing BDE methods and famous CNN-based image processing
networks. Unlike previous methods that separately process each color channel,
we treat all RGB channels at once and have greatly improved color restoration.
In addition, our network has shown the fastest computational speed in near
real-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04402</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04402</id><created>2019-10-10</created><updated>2020-01-04</updated><authors><author><keyname>Borkar</keyname><forenames>Vivek S.</forenames></author><author><keyname>Choudhary</keyname><forenames>Shantanu</forenames></author><author><keyname>Gupta</keyname><forenames>Vaibhav Kumar</forenames></author><author><keyname>Kasbekar</keyname><forenames>Gaurav S.</forenames></author></authors><title>Scheduling in Wireless Networks with Spatial Reuse of Spectrum as
  Restless Bandits</title><categories>eess.SP cs.NI</categories><comments>Revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of scheduling packet transmissions with the aim of
minimizing the energy consumption and data transmission delay of users in a
wireless network in which spatial reuse of spectrum is employed. We approach
this problem using the theory of Whittle index for cost minimizing restless
bandits, which has been used to effectively solve problems in a variety of
applications. We design two Whittle index based policies the first by treating
the graph representing the network as a clique and the second based on
interference constraints derived from the original graph. We evaluate the
performance of these two policies via extensive simulations, in terms of
average cost and packets dropped, and show that they outperform the well-known
Slotted ALOHA and maximum weight scheduling algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04403</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04403</id><created>2019-10-10</created><authors><author><keyname>Xie</keyname><forenames>Lifeng</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author></authors><title>Common Throughput Maximization for UAV-Enabled Interference Channel with
  Wireless Powered Communications</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies an unmanned aerial vehicle (UAV)-enabled two-user
interference channel for wireless powered communication networks (WPCNs), in
which two UAVs wirelessly charge two low-power Internet-of-things (IoT)-devices
on the ground and collect information from them. We consider two scenarios when
both UAVs cooperate in energy transmission and/or information reception via
interference coordination and coordinated multi-point (CoMP), respectively. For
both scenarios, the UAVs' controllable mobility is exploited via trajectory
design to not only enhance the wireless power transfer (WPT) efficiency in the
downlink, but also mitigate the co-channel interference for wireless
information transfer (WIT) in the uplink. In particular, the objective is to
maximize the uplink common (minimum) throughput of the two IoT-devices over a
finite UAV mission period, by jointly optimizing the trajectories of both UAVs
and the downlink/uplink wireless resource allocation, subject to the maximum
flying speed and collision avoidance constraints at UAVs, as well as the
individual energy neutrality constraints at IoT-devices. Under both scenarios
of interference coordination and CoMP, we first obtain the optimal solutions to
the two common-rate maximization problems in well structures for the special
case with sufficiently long UAV mission duration. Next, we obtain high-quality
solutions for the practical case with finite UAV mission duration by using the
alternating optimization and successive convex approximation (SCA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04415</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04415</id><created>2019-10-10</created><authors><author><keyname>Yasuda</keyname><forenames>Masahiro</forenames></author><author><keyname>Koizumi</keyname><forenames>Yuma</forenames></author><author><keyname>Mazzon</keyname><forenames>Luca</forenames></author><author><keyname>Saito</keyname><forenames>Shoichiro</forenames></author><author><keyname>Uematsu</keyname><forenames>Hisashi</forenames></author></authors><title>DOA Estimation by DNN-based Denoising and Dereverberation from Sound
  Intensity Vector</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a direction of arrival (DOA) estimation method that combines
sound-intensity vector (IV)-based DOA estimation and DNN-based denoising and
dereverberation. Since the accuracy of IV-based DOA estimation degrades due to
environmental noise and reverberation, two DNNs are used to remove such effects
from the observed IVs. DOA is then estimated from the refined IVs based on the
physics of wave propagation. Experiments on an open dataset showed that the
average DOA error of the proposed method was 0.528 degrees, and it outperformed
a conventional IV-based and DNN-based DOA estimation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04435</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04435</id><created>2019-10-10</created><authors><author><keyname>Palmer</keyname><forenames>James E.</forenames></author><author><keyname>Hennessy</keyname><forenames>Brendan</forenames></author><author><keyname>Rutten</keyname><forenames>Mark</forenames></author><author><keyname>Merrett</keyname><forenames>David</forenames></author><author><keyname>Tingay</keyname><forenames>Steven</forenames></author><author><keyname>Kaplan</keyname><forenames>David</forenames></author><author><keyname>Tremblay</keyname><forenames>Steven</forenames></author><author><keyname>Ord</keyname><forenames>Stephen M.</forenames></author><author><keyname>Morgan</keyname><forenames>John</forenames></author><author><keyname>Wayth</keyname><forenames>Randall B.</forenames></author></authors><title>Surveillance of Space using Passive Radar and the Murchison Widefield
  Array</title><categories>eess.SP astro-ph.IM</categories><comments>Published in: 2017 IEEE Radar Conference (RadarConf) URL:
  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7944483&amp;isnumber=7944108</comments><journal-ref>J. E. Palmer et al., &quot;Surveillance of Space using passive radar
  and the Murchison Widefield Array,&quot; 2017 IEEE Radar Conference (RadarConf),
  Seattle, WA, 2017, pp. 1715-1720</journal-ref><doi>10.1109/RADAR.2017.7944483</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we build upon recent work in the radio astronomy community to
experimentally demonstrate the viability of passive radar for Space Situational
Awareness. Furthermore, we show that the six state parameters of objects in
orbit may be measured and used to perform orbit characterisation/estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04443</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04443</id><created>2019-10-10</created><authors><author><keyname>Stocco</keyname><forenames>Andrea</forenames></author><author><keyname>Weiss</keyname><forenames>Michael</forenames></author><author><keyname>Calzana</keyname><forenames>Marco</forenames></author><author><keyname>Tonella</keyname><forenames>Paolo</forenames></author></authors><title>Misbehaviour Prediction for Autonomous Driving Systems</title><categories>eess.SP</categories><comments>11 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep Neural Networks (DNNs) are the core component of modern autonomous
driving systems. To date, it is still unrealistic that a DNN will generalize
correctly in all driving conditions. Current testing techniques consist of
offline solutions that identify adversarial or corner cases for improving the
training phase, and little has been done for enabling online healing of
DNN-based vehicles. In this paper, we address the problem of estimating the
confidence of DNNs in response to unexpected execution contexts with the
purpose of predicting potential safety-critical misbehaviours such as out of
bound episodes or collisions. Our approach SelfOracle is based on a novel
concept of self-assessment oracle, which monitors the DNN confidence at
runtime, to predict unsupported driving scenarios in advance. SelfOracle uses
autoencoder and time-series-based anomaly detection to reconstruct the driving
scenarios seen by the car, and determine the confidence boundary of
normal/unsupported conditions. In our empirical assessment, we evaluated the
effectiveness of different variants of SelfOracle at predicting injected
anomalous driving contexts, using DNN models and simulation environment from
Udacity. Results show that, overall, SelfOracle can predict 77% misbehaviours,
up to 6 seconds in advance, outperforming the online input validation approach
of DeepRoad by a factor almost equal to 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04456</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04456</id><created>2019-10-10</created><authors><author><keyname>Sarasaen</keyname><forenames>Chompunuch</forenames></author><author><keyname>Chatterjee</keyname><forenames>Soumick</forenames></author><author><keyname>Breitkopf</keyname><forenames>Mario</forenames></author><author><keyname>Iuso</keyname><forenames>Domenico</forenames></author><author><keyname>Rose</keyname><forenames>Georg</forenames></author><author><keyname>Speck</keyname><forenames>Oliver</forenames></author></authors><title>Breathing deformation model -- application to multi-resolution abdominal
  MRI</title><categories>eess.IV cs.CV</categories><comments>2019 41st Annual International Conference of the IEEE Engineering in
  Medicine and Biology Society (EMBC)</comments><doi>10.1109/EMBC.2019.885770</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic MRI is a technique of acquiring a series of images continuously to
follow the physiological changes over time. However, such fast imaging results
in low resolution images. In this work, abdominal deformation model computed
from dynamic low resolution images have been applied to high resolution image,
acquired previously, to generate dynamic high resolution MRI. Dynamic low
resolution images were simulated into different breathing phases (inhale and
exhale). Then, the image registration between breathing time points was
performed using the B-spline SyN deformable model and using cross-correlation
as a similarity metric. The deformation model between different breathing
phases were estimated from highly undersampled data. This deformation model was
then applied to the high resolution images to obtain high resolution images of
different breathing phases. The results indicated that the deformation model
could be computed from relatively very low resolution images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04461</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04461</id><created>2019-10-10</created><authors><author><keyname>Liu</keyname><forenames>Shengying</forenames></author><author><keyname>Liu</keyname><forenames>Zhentao</forenames></author><author><keyname>Hu</keyname><forenames>Chenyu</forenames></author><author><keyname>Li</keyname><forenames>Enrong</forenames></author><author><keyname>Shen</keyname><forenames>Xia</forenames></author><author><keyname>Han</keyname><forenames>Shensheng</forenames></author></authors><title>Spectral ghost imaging camera with super-Rayleigh modulator</title><categories>physics.optics eess.IV</categories><comments>11 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A spectral camera based on ghost imaging via sparsity constraints (GISC)
acquires a spectral data-cube (x; y; {\lambda}) through a single exposure. The
noise immunity of the system is one of the important factors affecting the
quality of the reconstructed images, especially at low sampling rates.
Tailoring the intensity to generate super-Rayleigh speckle patterns which have
superior noise immunity may offer an effective route to promote the imaging
quality of GISC spectral camera. According to the structure of GISC spectral
camera, we proposed a universal method for generating super-Rayleigh speckle
patterns with customized intensity statistics based on the principle of
reversibility of light. Simulation and experimental results demonstrate that,
within a wide imaging spectral bandwidth, GISC spectral camera with
super-Rayleigh modulator not only has superior noise immunity, but also has
higher imaging quality at low sampling rates. This work will promote the
application of GISC spectral camera by improving the quality of imaging
results, especially in weak-light illumination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04463</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04463</id><created>2019-10-10</created><authors><author><keyname>Chehelcheraghi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Nakatani</keyname><forenames>Chie</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Cees</forenames></author></authors><title>Increasing the Detectability of Phase-Amplitude Coupling</title><categories>eess.SP q-bio.NC</categories><comments>24 Pages 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: In electrical brain signals such as Local Field Potential (LFP)
and Electroencephalogram (EEG), oscillations emerge as a result of neural
network activity. The oscillations extend over several frequency bands. Between
their dominant components, various couplings can be observed. Of these,
Phase-Amplitude Coupling (PAC) is intensively studied in relation to brain
function. In the time-frequency domain, however, PAC measurement faces a
dilemma in the choice of filter bandwidth. For a frequency m modulating a
frequency n, filters narrowly tuned around the latter frequency will miss the
modulatory components at frequencies n+m and n-m; wide band tuning will pass
increasing levels of noise. New Method: Our CFC measurement uses three
identical narrow band filters with center frequencies located on n-m, n, and
n+m. The method therefore is free from the bandwidth dilemma. Comparison with
Existing Method(s): The method was tested on diagnostic artificial signals
modeled on local field potentials and compared with four established PAC
detection algorithms. While the proposed method detected the simulated PAC in
high frequency resolution, the other methods detected with poor frequency
resolution, or completely missed the PAC. Conclusion: Using the proposed
triplet-filter banks instead of wideband filtering allows for high resolution
detection of PAC. Moreover, the method successfully detected PAC in wide range
of modulation frequency. Finally, bandwidth is not chosen subjectively in our
new method which makes the comparison of PAC more convenient among different
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04473</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04473</id><created>2019-10-10</created><authors><author><keyname>Takahama</keyname><forenames>Shusuke</forenames></author><author><keyname>Kurose</keyname><forenames>Yusuke</forenames></author><author><keyname>Mukuta</keyname><forenames>Yusuke</forenames></author><author><keyname>Abe</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Fukayama</keyname><forenames>Masashi</forenames></author><author><keyname>Yoshizawa</keyname><forenames>Akihiko</forenames></author><author><keyname>Kitagawa</keyname><forenames>Masanobu</forenames></author><author><keyname>Harada</keyname><forenames>Tatsuya</forenames></author></authors><title>Multi-Stage Pathological Image Classification using Semantic
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted to ICCV2019. ICCV paper version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histopathological image analysis is an essential process for the discovery of
diseases such as cancer. However, it is challenging to train CNN on whole slide
images (WSIs) of gigapixel resolution considering the available memory
capacity. Most of the previous works divide high resolution WSIs into small
image patches and separately input them into the model to classify it as a
tumor or a normal tissue. However, patch-based classification uses only
patch-scale local information but ignores the relationship between neighboring
patches. If we consider the relationship of neighboring patches and global
features, we can improve the classification performance. In this paper, we
propose a new model structure combining the patch-based classification model
and whole slide-scale segmentation model in order to improve the prediction
performance of automatic pathological diagnosis. We extract patch features from
the classification model and input them into the segmentation model to obtain a
whole slide tumor probability heatmap. The classification model considers
patch-scale local features, and the segmentation model can take global
information into account. We also propose a new optimization method that
retains gradient information and trains the model partially for end-to-end
learning with limited GPU memory capacity. We apply our method to the
tumor/normal prediction on WSIs and the classification performance is improved
compared with the conventional patch-based method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04476</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04476</id><created>2019-10-10</created><authors><author><keyname>Liu</keyname><forenames>Zhi-Song</forenames></author><author><keyname>Wang</keyname><forenames>Li-Wen</forenames></author><author><keyname>Li</keyname><forenames>Chu-Tak</forenames></author><author><keyname>Siu</keyname><forenames>Wan-Chi</forenames></author><author><keyname>Chan</keyname><forenames>Yui-Lam</forenames></author></authors><title>Image Super-Resolution via Attention based Back Projection Networks</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 7 figures, ABPN</comments><journal-ref>IEEE International Conference on Computer Vision 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning based image Super-Resolution (SR) has shown rapid development
due to its ability of big data digestion. Generally, deeper and wider networks
can extract richer feature maps and generate SR images with remarkable quality.
However, the more complex network we have, the more time consumption is
required for practical applications. It is important to have a simplified
network for efficient image SR. In this paper, we propose an Attention based
Back Projection Network (ABPN) for image super-resolution. Similar to some
recent works, we believe that the back projection mechanism can be further
developed for SR. Enhanced back projection blocks are suggested to iteratively
update low- and high-resolution feature residues. Inspired by recent studies on
attention models, we propose a Spatial Attention Block (SAB) to learn the
cross-correlation across features at different layers. Based on the assumption
that a good SR image should be close to the original LR image after
down-sampling. We propose a Refined Back Projection Block (RBPB) for final
reconstruction. Extensive experiments on some public and AIM2019 Image
Super-Resolution Challenge datasets show that the proposed ABPN can provide
state-of-the-art or even better performance in both quantitative and
qualitative measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04500</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04500</id><created>2019-10-10</created><authors><author><keyname>Lee</keyname><forenames>Mingu</forenames></author><author><keyname>Lee</keyname><forenames>Jinkyu</forenames></author><author><keyname>Jang</keyname><forenames>Hye Jin</forenames></author><author><keyname>Kim</keyname><forenames>Byeonggeun</forenames></author><author><keyname>Chang</keyname><forenames>Wonil</forenames></author><author><keyname>Hwang</keyname><forenames>Kyuwoong</forenames></author></authors><title>Orthogonality Constrained Multi-Head Attention For Keyword Spotting</title><categories>cs.LG eess.AS stat.ML</categories><comments>Accepted to ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-head attention mechanism is capable of learning various representations
from sequential data while paying attention to different subsequences, e.g.,
word-pieces or syllables in a spoken word. From the subsequences, it retrieves
richer information than a single-head attention which only summarizes the whole
sequence into one context vector. However, a naive use of the multi-head
attention does not guarantee such richness as the attention heads may have
positional and representational redundancy. In this paper, we propose a
regularization technique for multi-head attention mechanism in an end-to-end
neural keyword spotting system. Augmenting regularization terms which penalize
positional and contextual non-orthogonality between the attention heads
encourages to output different representations from separate subsequences,
which in turn enables leveraging structured information without explicit
sequence models such as hidden Markov models. In addition, intra-head
contextual non-orthogonality regularization encourages each attention head to
have similar representations across keyword examples, which helps
classification by reducing feature variability. The experimental results
demonstrate that the proposed regularization technique significantly improves
the keyword spotting performance for the keyword &quot;Hey Snapdragon&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04541</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04541</id><created>2019-10-10</created><authors><author><keyname>Shang</keyname><forenames>Yuwei</forenames></author><author><keyname>Wu</keyname><forenames>Wenchuan</forenames></author><author><keyname>Guo</keyname><forenames>Jianbo</forenames></author><author><keyname>Lv</keyname><forenames>Zhe</forenames></author><author><keyname>Ma</keyname><forenames>Zhao</forenames></author><author><keyname>Sheng</keyname><forenames>Wanxing</forenames></author><author><keyname>Chen</keyname><forenames>Ran</forenames></author></authors><title>Stochastic Dispatch of Energy Storage in Microgrids: A Reinforcement
  Learning Approach Incorporated with MCTS</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic dispatch (DD) of battery energy storage systems (BESSs) in
microgrids integrated with volatile energy resources is essentially a
multiperiod stochastic optimization problem (MSOP). Because the life span of a
BESS is significantly affected by its charging and discharging behaviors, its
lifecycle degradation costs should be incorporated into the DD model of BESSs,
which makes it non-convex. In general, this MSOP is intractable. To solve this
problem, we propose a reinforcement learning (RL) solution augmented with
Monte-Carlo tree search (MCTS) and domain knowledge expressed as dispatching
rules. In this solution, the Q-learning with function approximation is employed
as the basic learning architecture that allows multistep bootstrapping and
continuous policy learning. To improve the computation efficiency of randomized
multistep simulations, we employed the MCTS to estimate the expected maximum
action values. Moreover, we embedded a few dispatching rules in RL as
probabilistic logics to reduce infeasible action explorations, which can
improve the quality of the data-driven solution. Numerical test results show
the proposed algorithm outperforms other baseline RL algorithms in all cases
tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04560</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04560</id><created>2019-10-07</created><authors><author><keyname>Sandhu</keyname><forenames>Romeil</forenames></author><author><keyname>Liu</keyname><forenames>Ji</forenames></author></authors><title>Maxwells Demon: Controlling Entropy via Discrete Ricci Flow Over
  Networks</title><categories>eess.SY cs.SI cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose to utilize discrete graph Ricci flow to alter
network entropy through feedback control. Given such feedback input can reverse
entropic changes, we adapt the moniker of Maxwells Demon to motivate our
approach. In particular, it has been recently shown that Ricci curvature from
geometry is intrinsically connected to Boltzmann entropy as well as functional
robustness of networks or the ability to maintain functionality in the presence
of random fluctuations. From this, the discrete Ricci flow provides a natural
avenue to rewire a particular networks underlying geometry to improve
throughout and resilience. Due to the real-world setting for which one may be
interested in imposing nonlinear constraints amongst particular agents to
understand the network dynamic evolution, controlling discrete Ricci flow may
be necessary (e.g., we may seek to understand the entropic dynamics and
curvature flow between two networks as opposed to solely curvature shrinkage).
In turn, this can be formulated as a natural control problem for which we
employ feedback control towards discrete Ricci-based flow and show that under
certain discretization, namely Ollivier-Ricci curvature, one can show stability
via Lyapunov analysis. We conclude with preliminary results with remarks on
potential applications that will be a subject of future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04572</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04572</id><created>2019-10-09</created><authors><author><keyname>Wang</keyname><forenames>Mingfeng</forenames></author><author><keyname>Dong</keyname><forenames>Xin</forenames></author><author><keyname>Ba</keyname><forenames>Weiming</forenames></author><author><keyname>Mohammad</keyname><forenames>Abdelkhalick</forenames></author><author><keyname>Axinte</keyname><forenames>Dragos</forenames></author><author><keyname>Norton</keyname><forenames>Andy</forenames></author></authors><title>Design, Modelling and Validation of a Novel Extra Slender Continuum
  Robot for In-situ Inspection and Repair in Aeroengine</title><categories>cs.RO cs.SY eess.SY</categories><comments>11 pages, 12 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-situ aeroengine maintenance works are highly beneficial as it can
significantly reduce the current maintenance cycle which is extensive and
costly due to the disassembly requirement of engines from aircrafts. However,
navigating in/out via inspection ports and performing multi-axis movements with
end-effectors in constrained environments (e.g. combustion chamber) are fairly
challenging. A novel extra-slender (diameter-to-length ratio &lt;0.02) dual-stage
continuum robot (16 degree-of-freedom) is proposed to navigate in/out confined
environments and perform required configuration shapes for further repair
operations. Firstly, the robot design presents several innovative mechatronic
solutions: (i) dual-stage tendon-driven structure with bevelled disks to
perform required shapes and to provide selective stiffness for carrying high
payloads; (ii) various rigid-compliant combined joints to enable different
flexibility and stiffness in each stage; (iii) three commanding cables for each
2-DoF section to minimise the number of actuators with precise actuations.
Secondly, a segment-scaled piecewise-constant-curvature-theory based kinematic
model and a Kirchhoff-elastic-rod-theory based static model are established by
considering the applied forces/moments (friction, actuation, gravity and
external load), where the friction coefficient is modelled as a function of
bending angle. Finally, experiments were carried out to validate the proposed
static modelling and to evaluate the robot capabilities of performing the
predefined shape and stiffness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04573</identifier>
 <datestamp>2020-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04573</id><created>2019-10-09</created><updated>2020-01-09</updated><authors><author><keyname>Wurm</keyname><forenames>Jens</forenames></author><author><keyname>Bachler</keyname><forenames>Simon</forenames></author><author><keyname>Woittennek</keyname><forenames>Frank</forenames></author></authors><title>On delay-partial-differential and delay-differential thermal models for
  variable pipe flow</title><categories>eess.SY cs.SY physics.flu-dyn</categories><comments>27 Pages, 3 Tables, and 10 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new formulation of physical thermal models for variable plug flow through a
pipe is proposed. The derived model is based on a commonly used one-dimensional
distributed parameter model, which explicitly takes into account the heat
capacity of the jacket of the pipe. The main result of the present contribution
is the constitution of the equivalence of this model with a serial connection
of a pure delay or transport system and another partial differential equation
(PDE), subsequently called delay-partial-differential equation (DPDE)-model.
The means for obtaining the proposed model comprise operational calculus in the
Laplace domain as well as classical theory of characteristics. The
finite-dimensional approximation of the DPDE-model leads to a
delay-differential equation (DDE)-system, which can be seen as a generalization
of commonly used DDE-models consisting of a first-order low-pass filter subject
to an input delay. The proposed model is compared to several alternative models
in simulations and experimental studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04582</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04582</id><created>2019-10-10</created><authors><author><keyname>I.</keyname><forenames>M. Hadi Balaghi</forenames></author><author><keyname>Antunes</keyname><forenames>Duarte J.</forenames></author><author><keyname>Mamduhi</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Hirche</keyname><forenames>Sandra</forenames></author></authors><title>Decentralized LQ-Consistent Event-triggered Control over a Shared
  Contention-based Network</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a network of multiple independent stochastic linear systems where a
scheduler collocated with the output sensors of each system arbitrates data
transmissions to a corresponding remote controller through a shared
contention-based communication network. While the systems are independent,
their optimal controller design problem may generally become coupled, due to
network contention, if the schedulers trigger transmissions based on
state-dependent events. In this article we propose a class of probabilistic
admissible schedulers for which the optimal controllers with respect to local
standard LQG costs have the certainty equivalence property and can still be
designed decentrally. Then, two scheduling policies within this class are
introduced; a non-event-based and an event-based, where they both have an
easily adjustable triggering probability at every time-step. The main
contributions of this work are as follows: i)~proving that for each system, the
control loop with the event-based scheduler and its optimal controller
outperforms the control loop with the non-event-based scheduler and its
associated optimal controller; ii)~showing that for each system, the local
optimal state estimator for both scheduling policies follows a linear
iteration; i)~regulation of triggering probabilities of the schedulers by
maximizing a network utility function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04597</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04597</id><created>2019-10-10</created><authors><author><keyname>Glocker</keyname><forenames>Ben</forenames></author><author><keyname>Robinson</keyname><forenames>Robert</forenames></author><author><keyname>Castro</keyname><forenames>Daniel C.</forenames></author><author><keyname>Dou</keyname><forenames>Qi</forenames></author><author><keyname>Konukoglu</keyname><forenames>Ender</forenames></author></authors><title>Machine Learning with Multi-Site Imaging Data: An Empirical Study on the
  Impact of Scanner Effects</title><categories>eess.IV cs.CV cs.LG q-bio.NC</categories><comments>Presented at the Medical Imaging meets NeurIPS Workshop 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This is an empirical study to investigate the impact of scanner effects when
using machine learning on multi-site neuroimaging data. We utilize structural
T1-weighted brain MRI obtained from two different studies, Cam-CAN and UK
Biobank. For the purpose of our investigation, we construct a dataset
consisting of brain scans from 592 age- and sex-matched individuals, 296
subjects from each original study. Our results demonstrate that even after
careful pre-processing with state-of-the-art neuroimaging pipelines a
classifier can easily distinguish between the origin of the data with very high
accuracy. Our analysis on the example application of sex classification
suggests that current approaches to harmonize data are unable to remove
scanner-specific bias leading to overly optimistic performance estimates and
poor generalization. We conclude that multi-site data harmonization remains an
open challenge and particular care needs to be taken when using such data with
advanced machine learning methods for predictive modelling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04631</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04631</id><created>2019-10-10</created><authors><author><keyname>Kl&#xfc;gel</keyname><forenames>Markus</forenames></author><author><keyname>Mamduhi</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Ayan</keyname><forenames>Onur</forenames></author><author><keyname>Vilgelm</keyname><forenames>Mikhail</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author><author><keyname>Hirche</keyname><forenames>Sandra</forenames></author><author><keyname>Kellerer</keyname><forenames>Wolfgang</forenames></author></authors><title>Joint Cross-layer Optimization in Real-Time Networked Control Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networked control system (NCS) refer to a set of control loops that are
closed over a communication network. In this article, the joint operation of
control and networking for NCS is investigated wherein the network serves the
sensor-to-controller communication links for multiple stochastic linear
time-invariant (LTI) sub-systems. The sensors sample packets based on the
observed plant state, which they send over a shared multi-hop network. The
network has limited communication resources, which need to be assigned to
competing links to support proper control loop operation. In this set-up, we
formulate an optimization problem to minimize the weighted-sum
linear-quadratic-Gaussian (LQG) cost of all loops, taking into account the
admissible sampling, control, congestion control and scheduling policies. Under
some mild assumptions on the sampling frequencies of the control loops and the
communication network, we find the joint optimal solution to be given by a
certainty equivalence control with threshold-based sampling policy, as well as
a back-pressure type scheduler with a simple pass-through congestion control.
The interface between network and control loops is identified to be the buffer
state of the sensor node, which can be interpreted as network price for
sampling a packet from control perspective. We validate our theoretical claims
by simulating NCSs comprising of multiple LTI stochastic control loops
communicating over a two-hop cellular network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04649</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04649</id><created>2019-10-10</created><authors><author><keyname>Agrawal</keyname><forenames>Niharika</forenames></author><author><keyname>Garg</keyname><forenames>Sasha</forenames></author><author><keyname>Darak</keyname><forenames>S. J.</forenames></author><author><keyname>Bader</keyname><forenames>Faouzi</forenames></author></authors><title>Spectral Coexistence of LDACS and DME: Analysis via Hardware Software
  Co-Design in Presence of Real Channels and RF Impairments</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To meet the exponentially increasing air traffic, Lband (960-1164 MHz)
digital aeronautical communication system (LDACS) has been introduced. The
LDACS aims to exploit vacant spectrum between incumbent Distance Measuring
Equipment (DME) signals and envisioned to follow multi-carrier waveform
approach to support high-speed delay-sensitive multimedia services. This paper
deals with the design and implementation of end-to-end LDACS transceiver on
Zynq System on Chip (ZSoC) platform, consisting of FPGA as programmable logic
(PL) and ARM as processing system (PS). We consider orthogonal frequency
division multiplexing (OFDM) based LDACS and improve it further using windowing
and/or filtering. We propose hardware software co-design approach and analyze
various transceiver configurations by dividing it into PL and PS. We
demonstrate the flexibility offered by such co-design approach to choose the
configuration as well as word-length for a given area, delay and power
constraints. The transceiver is also integrated with the programmable analog
front-end to validate its functionality in the presence of various RF
impairments and wireless channels and interference specific to the LDACS
environment. To the best of our knowledge, this is the first ever in-depth
analysis of the performance of end-to-end LDACS transceiver concerning
parameters such as out-of-band attenuation, DME interference, bit-error-rate,
word-length, area, delay, and power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04656</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04656</id><created>2019-10-10</created><authors><author><keyname>Won</keyname><forenames>Myounggyu</forenames></author></authors><title>Intelligent Traffic Monitoring Systems for Vehicle Classification: A
  Survey</title><categories>cs.CY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A traffic monitoring system is an integral part of Intelligent Transportation
Systems (ITS). It is one of the critical transportation infrastructures that
transportation agencies invest a huge amount of money to collect and analyze
the traffic data to better utilize the roadway systems, improve the safety of
transportation, and establish future transportation plans. With recent advances
in MEMS, machine learning, and wireless communication technologies, numerous
innovative traffic monitoring systems have been developed. In this article, we
present a review of state-of-the-art traffic monitoring systems focusing on the
major functionality--vehicle classification. We organize various vehicle
classification systems, examine research issues and technical challenges, and
discuss hardware/software design, deployment experience, and system performance
of the vehicle classification systems. Finally, we discuss a number of critical
open problems and future research directions in an aim to provide valuable
resources to academia, industry, and government agencies for selecting
appropriate technologies for their traffic monitoring applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04681</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04681</id><created>2019-10-08</created><authors><author><keyname>Yoon</keyname><forenames>Seokchan</forenames></author><author><keyname>Lee</keyname><forenames>Hojun</forenames></author><author><keyname>Hong</keyname><forenames>Jin Hee</forenames></author><author><keyname>Lim</keyname><forenames>Yong-Sik</forenames></author><author><keyname>Choi</keyname><forenames>Wonshik</forenames></author></authors><title>Laser scanning reflection-matrix microscopy for label-free in vivo
  imaging of a mouse brain through an intact skull</title><categories>physics.bio-ph eess.IV physics.optics</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a laser scanning reflection-matrix microscopy combining the
scanning of laser focus and the wide-field mapping of the electric field of the
backscattered waves for eliminating higher-order aberrations even in the
presence of strong multiple light scattering noise. Unlike conventional
confocal laser scanning microscopy, we record the amplitude and phase maps of
reflected waves from the sample not only at the confocal pinhole, but also at
other non-confocal points. These additional measurements lead us to
constructing a time-resolved reflection matrix, with which the sample-induced
aberrations for the illumination and detection pathways are separately
identified and corrected. We realized in vivo reflectance imaging of myelinated
axons through an intact skull of a living mouse with the spatial resolution
close to the ideal diffraction limit. Furthermore, we demonstrated
near-diffraction-limited multiphoton imaging through an intact skull by
physically correcting the aberrations identified from the reflection matrix.
The proposed method is expected to extend the range of applications, where the
knowledge of the detailed microscopic information deep within biological
tissues is critical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04706</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04706</id><created>2019-10-10</created><authors><author><keyname>Pasandi</keyname><forenames>Venus</forenames></author><author><keyname>Dinale</keyname><forenames>Aiko</forenames></author><author><keyname>Keshmiri</keyname><forenames>Mehdi</forenames></author><author><keyname>Pucci</keyname><forenames>Daniele</forenames></author></authors><title>A Data Driven Vector Field Oscillator with Arbitrary Limit Cycle Shape</title><categories>nlin.AO cs.SY eess.SY math.DS</categories><comments>58th IEEE Conference on Decision and Control (CDC2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclic motions in vertebrates, including heart beating, breathing and
walking, are derived by a network of biological oscillators having fascinating
features such as entrainment, environment adaptation, and robustness. These
features encouraged engineers to use oscillators for generating cyclic motions.
To this end, it is crucial to have oscillators capable of characterizing any
periodic signal via a stable limit cycle. In this paper, we propose a
2-dimensional oscillator whose limit cycle can be matched to any periodic
signal depicting a non-self-intersecting curve in the state space. In
particular, the proposed oscillator is designed as an autonomous vector field
directed toward the desired limit cycle. To this purpose, the desired reference
signal is parameterized with respect to a state-dependent phase variable, then
the oscillator's states track the parameterized signal. We also present a state
transformation technique to bound the oscillator's output and its first time
derivative. The soundness of the proposed oscillator has been verified by
carrying out a few simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04718</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04718</id><created>2019-10-10</created><authors><author><keyname>Zino</keyname><forenames>Lorenzo</forenames></author><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author></authors><title>Fast Spread in Controlled Evolutionary Dynamics</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the spread of a novel state in a network in the presence of an
exogenous control. The controlled evolutionary dynamics model we study is a
non-homogeneous Markov process describing the evolution of the states of all
nodes in the network. Through a rigorous analysis of this system, we establish
upper and lower bounds on the expected time needed for the novel state to
replace the original one. Such bounds are in terms of the features of the
control policy (specifically, the set of nodes that can be controlled and its
energy) and of the network topology. Leveraging these results, we are able to
classify network structures depending on their controllability. Finally, we
propose a feedback control policy that, using little knowledge of the network
topology and of the system's evolution at a macroscopic level, allows for a
substantial speed up of the spreading process. All these theoretical results
are presented together with explanatory examples, for which Monte Carlo
simulations corroborate our analytical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04725</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04725</id><created>2019-10-10</created><authors><author><keyname>Jayatilaka</keyname><forenames>Gihan</forenames></author><author><keyname>Weligampola</keyname><forenames>Harshana</forenames></author><author><keyname>Sritharan</keyname><forenames>Suren</forenames></author><author><keyname>Pathmanathan</keyname><forenames>Pankayraj</forenames></author><author><keyname>Ragel</keyname><forenames>Roshan</forenames></author><author><keyname>Nawinne</keyname><forenames>Isuru</forenames></author></authors><title>Non-contact Infant Sleep Apnea Detection</title><categories>eess.SP cs.CV</categories><comments>Gihan Jayatilaka, Harshana Weligampola and Suren Sritharan are
  equally contributing authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sleep apnea is a breathing disorder where a person repeatedly stops breathing
in sleep. Early detection is crucial for infants because it might bring long
term adversities. The existing accurate detection mechanism (pulse oximetry) is
a skin contact measurement. The existing non-contact mechanisms (acoustics,
video processing) are not accurate enough. This paper presents a novel
algorithm for the detection of sleep apnea with video processing. The solution
is non-contact, accurate and lightweight enough to run on a single board
computer. The paper discusses the accuracy of the algorithm on real data,
advantages of the new algorithm, its limitations and suggests future
improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04739</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04739</id><created>2019-10-10</created><authors><author><keyname>Friedrich</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Cauchy</keyname><forenames>Benjamin</forenames></author><author><keyname>Hein</keyname><forenames>Andreas</forenames></author><author><keyname>Fudickar</keyname><forenames>Sebastian</forenames></author></authors><title>Transportation Mode Classification from Smartphone Sensors via a
  Long-Short-Term-Memory Network</title><categories>cs.LG eess.SP</categories><comments>5 pages, 6 figures, 2 tables, ubicomp19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces the architecture of a Long-Short-Term Memory network
for classifying transportation-modes via Smartphone data and evaluates its
accuracy. By using a Long-Short-Term-Memory Network with common preprocessing
steps such as normalisation for classification tasks a F1-Score accuracy of
63.68\% was achieved with an internal test dataset. We participated as Team
'GanbareAM' in the 'SHL recognition challenge'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04751</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04751</id><created>2019-10-10</created><updated>2019-10-23</updated><authors><author><keyname>Cheng</keyname><forenames>Bowen</forenames></author><author><keyname>Collins</keyname><forenames>Maxwell D.</forenames></author><author><keyname>Zhu</keyname><forenames>Yukun</forenames></author><author><keyname>Liu</keyname><forenames>Ting</forenames></author><author><keyname>Huang</keyname><forenames>Thomas S.</forenames></author><author><keyname>Adam</keyname><forenames>Hartwig</forenames></author><author><keyname>Chen</keyname><forenames>Liang-Chieh</forenames></author></authors><title>Panoptic-DeepLab</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>This work is presented at ICCV 2019 Joint COCO and Mapillary
  Recognition Challenge Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Panoptic-DeepLab, a bottom-up and single-shot approach for
panoptic segmentation. Our Panoptic-DeepLab is conceptually simple and delivers
state-of-the-art results. In particular, we adopt the dual-ASPP and
dual-decoder structures specific to semantic, and instance segmentation,
respectively. The semantic segmentation branch is the same as the typical
design of any semantic segmentation model (e.g., DeepLab), while the instance
segmentation branch is class-agnostic, involving a simple instance center
regression. Our single Panoptic-DeepLab sets the new state-of-art at all three
Cityscapes benchmarks, reaching 84.2% mIoU, 39.0% AP, and 65.5% PQ on test set,
and advances results on the other challenging Mapillary Vistas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04778</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04778</id><created>2019-10-10</created><updated>2019-11-13</updated><authors><author><keyname>Luo</keyname><forenames>Hengrui</forenames></author><author><keyname>Strait</keyname><forenames>Justin</forenames></author></authors><title>Combining Geometric and Topological Information in Image Segmentation</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>27 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in computer vision is image segmentation, where the
goal is to delineate the boundary of an object in the image. The focus of this
work is on the segmentation of grayscale images and its purpose is two-fold.
First, we conduct an in-depth study comparing active contour and topology-based
methods in a statistical framework, two popular approaches for boundary
detection of 2-dimensional images. Certain properties of the image dataset may
favor one method over the other, both from an interpretability perspective as
well as through evaluation of performance measures. Second, we propose the use
of topological knowledge to assist an active contour method, which can
potentially incorporate prior shape information. The latter is known to be
extremely sensitive to algorithm initialization, and thus, we use a topological
model to provide an automatic initialization. In addition, our proposed model
can handle objects in images with more complex topological structures,
including objects with holes and multiple objects within one image. We
demonstrate this on artificially-constructed image datasets from computer
vision, as well as real medical image data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04792</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04792</id><created>2019-10-10</created><authors><author><keyname>Jadon</keyname><forenames>Shruti</forenames></author><author><keyname>Jasim</keyname><forenames>Mahmood</forenames></author></authors><title>Video Summarization using Keyframe Extraction and Video Skimming</title><categories>cs.IR cs.CV cs.LG eess.IV</categories><comments>5 pages, 3 figures. Technical Report</comments><doi>10.1007/springerreference_64000</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Video is one of the robust sources of information and the consumption of
online and offline videos has reached an unprecedented level in the last few
years. A fundamental challenge of extracting information from videos is a
viewer has to go through the complete video to understand the context, as
opposed to an image where the viewer can extract information from a single
frame. In this work, we attempt to employ different Algorithmic methodologies
including local features and deep neural networks along with multiple
clustering methods to find an effective way of summarizing a video by
interesting keyframe extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04814</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04814</id><created>2019-10-10</created><updated>2020-02-01</updated><authors><author><keyname>Tajbakhsh</keyname><forenames>Nima</forenames></author><author><keyname>Lai</keyname><forenames>Brian</forenames></author><author><keyname>Ananth</keyname><forenames>Shilpa</forenames></author><author><keyname>Ding</keyname><forenames>Xiaowei</forenames></author></authors><title>ErrorNet: Learning error representations from limited data to improve
  vascular segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted in ISBI 2019. The supplementary material is only available
  in the arxiv version of our paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep convolutional neural networks have proved effective in segmenting
lesions and anatomies in various medical imaging modalities. However, in the
presence of small sample size and domain shift problems, these models often
produce masks with non-intuitive segmentation mistakes. In this paper, we
propose a segmentation framework called ErrorNet, which learns to correct these
segmentation mistakes through the repeated process of injecting systematic
segmentation errors to the segmentation result based on a learned shape prior,
followed by attempting to predict the injected error. During inference,
ErrorNet corrects the segmentation mistakes by adding the predicted error map
to the initial segmentation result. ErrorNet has advantages over alternatives
based on domain adaptation or CRF-based post processing, because it requires
neither domain-specific parameter tuning nor any data from the target domains.
We have evaluated ErrorNet using five public datasets for the task of retinal
vessel segmentation. The selected datasets differ in size and patient
population, allowing us to evaluate the effectiveness of ErrorNet in handling
small sample size and domain shift problems. Our experiments demonstrate that
ErrorNet outperforms a base segmentation model, a CRF-based post processing
scheme, and a domain adaptation method, with a greater performance gain in the
presence of the aforementioned dataset limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04841</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04841</id><created>2019-10-10</created><authors><author><keyname>Zeng</keyname><forenames>Ming</forenames></author><author><keyname>Fodor</keyname><forenames>Viktoria</forenames></author></authors><title>Dynamic Spectrum Sharing for Load Balancing in Multi-Cell Mobile Edge
  Computing</title><categories>cs.IT eess.SP math.IT</categories><comments>IEEE WCL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale mobile edge computing (MEC) systems require scalable solutions to
allocate communication and computing resources to the users. In this letter we
address this challenge by applying dynamic spectrum sharing among the base
stations (BSs), together with local resource allocation in the cells. We show
that the network-wide resource allocation can be transformed into a convex
optimization problem, and propose a distributed, hierarchical solution with
limited information exchange among the BSs. Numerical results demonstrate that
the proposed solution is superior to other baseline algorithms, when wireless
and computing resource allocation is not jointly optimized, or the wireless
resources allocated to the BSs are fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04852</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04852</id><created>2019-10-03</created><authors><author><keyname>Datta</keyname><forenames>Kushal</forenames></author><author><keyname>Hossain</keyname><forenames>Imtiaz</forenames></author><author><keyname>Choi</keyname><forenames>Sun</forenames></author><author><keyname>Saletore</keyname><forenames>Vikram</forenames></author><author><keyname>Ambert</keyname><forenames>Kyle</forenames></author><author><keyname>Godinez</keyname><forenames>William J.</forenames></author><author><keyname>Zhang</keyname><forenames>Xian</forenames></author></authors><title>Training Multiscale-CNN for Large Microscopy Image Classification in One
  Hour</title><categories>eess.IV cs.CV</categories><comments>15 pages, 10 figures</comments><journal-ref>Workshop on Scalable Data Analytics in Scientific Computing,
  International SuperComputing 2019, Frankfurt, Germany</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing approaches to train neural networks that use large images require to
either crop or down-sample data during pre-processing, use small batch sizes,
or split the model across devices mainly due to the prohibitively limited
memory capacity available on GPUs and emerging accelerators. These techniques
often lead to longer time to convergence or time to train (TTT), and in some
cases, lower model accuracy. CPUs, on the other hand, can leverage significant
amounts of memory. While much work has been done on parallelizing neural
network training on multiple CPUs, little attention has been given to tune
neural network training with large images on CPUs. In this work, we train a
multi-scale convolutional neural network (M-CNN) to classify large biomedical
images for high content screening in one hour. The ability to leverage large
memory capacity on CPUs enables us to scale to larger batch sizes without
having to crop or down-sample the input images. In conjunction with large batch
sizes, we find a generalized methodology of linearly scaling of learning rate
and train M-CNN to state-of-the-art (SOTA) accuracy of 99% within one hour. We
achieve fast time to convergence using 128 two socket Intel Xeon 6148 processor
nodes with 192GB DDR4 memory connected with 100Gbps Intel Omnipath
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04855</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04855</id><created>2019-09-25</created><authors><author><keyname>Kollias</keyname><forenames>Dimitrios</forenames></author><author><keyname>Zafeiriou</keyname><forenames>Stefanos</forenames></author></authors><title>Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task
  Learning and ArcFace</title><categories>cs.CV cs.HC cs.LG eess.IV</categories><comments>oral presentation in BMVC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Affective computing has been largely limited in terms of available data
resources. The need to collect and annotate diverse in-the-wild datasets has
become apparent with the rise of deep learning models, as the default approach
to address any computer vision task. Some in-the-wild databases have been
recently proposed. However: i) their size is small, ii) they are not
audiovisual, iii) only a small part is manually annotated, iv) they contain a
small number of subjects, or v) they are not annotated for all main behavior
tasks (valence-arousal estimation, action unit detection and basic expression
classification). To address these, we substantially extend the largest
available in-the-wild database (Aff-Wild) to study continuous emotions such as
valence and arousal. Furthermore, we annotate parts of the database with basic
expressions and action units. As a consequence, for the first time, this allows
the joint study of all three types of behavior states. We call this database
Aff-Wild2. We conduct extensive experiments with CNN and CNN-RNN architectures
that use visual and audio modalities; these networks are trained on Aff-Wild2
and their performance is then evaluated on 10 publicly available emotion
databases. We show that the networks achieve state-of-the-art performance for
the emotion recognition tasks. Additionally, we adapt the ArcFace loss function
in the emotion recognition context and use it for training two new networks on
Aff-Wild2 and then re-train them in a variety of diverse expression recognition
databases. The networks are shown to improve the existing state-of-the-art. The
database, emotion recognition models and source code are available at
http://ibug.doc.ic.ac.uk/resources/aff-wild2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04866</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04866</id><created>2019-10-01</created><authors><author><keyname>Amer</keyname><forenames>Rula</forenames></author><author><keyname>Nassar</keyname><forenames>Jannette</forenames></author><author><keyname>Bendahan</keyname><forenames>David</forenames></author><author><keyname>Greenspan</keyname><forenames>Hayit</forenames></author><author><keyname>Ben-Eliezer</keyname><forenames>Noam</forenames></author></authors><title>Automatic Segmentation of Muscle Tissue and Inter-muscular Fat in Thigh
  and Calf MRI Images</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures, 2 tables, MICCAI 2019, the 22nd International
  Conference on Medical Image Computing and Computer Assisted Intervention</comments><doi>10.1007/978-3-030-32245-8_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) of thigh and calf muscles is one of the most
effective techniques for estimating fat infiltration into muscular dystrophies.
The infiltration of adipose tissue into the diseased muscle region varies in
its severity across, and within, patients. In order to efficiently quantify the
infiltration of fat, accurate segmentation of muscle and fat is needed. An
estimation of the amount of infiltrated fat is typically done visually by
experts. Several algorithmic solutions have been proposed for automatic
segmentation. While these methods may work well in mild cases, they struggle in
moderate and severe cases due to the high variability in the intensity of
infiltration, and the tissue's heterogeneous nature. To address these
challenges, we propose a deep-learning approach, producing robust results with
high Dice Similarity Coefficient (DSC) of 0.964, 0.917 and 0.933 for
muscle-region, healthy muscle and inter-muscular adipose tissue (IMAT)
segmentation, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04868</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04868</id><created>2019-10-02</created><updated>2019-11-30</updated><authors><author><keyname>Hallgrimsson</keyname><forenames>Haraldur T.</forenames></author><author><keyname>Sharan</keyname><forenames>Richika</forenames></author><author><keyname>Grafton</keyname><forenames>Scott T.</forenames></author><author><keyname>Singh</keyname><forenames>Ambuj K.</forenames></author></authors><title>Estimating localized complexity of white-matter wiring with GANs</title><categories>eess.IV cs.CV cs.LG q-bio.QM stat.ML</categories><comments>Three page extended abstract, accepted to Medical Imaging meets
  NeurIPS 2019 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-vivo examination of the physical connectivity of axonal projections
through the white matter of the human brain is made possible by diffusion
weighted magnetic resonance imaging (dMRI) Analysis of dMRI commonly considers
derived scalar metrics such as fractional anisotrophy as proxies for &quot;white
matter integrity,&quot; and differences of such measures have been observed as
significantly correlating with various neurological diagnosis and clinical
measures such as executive function, presence of multiple sclerosis, and
genetic similarity. The analysis of such voxel measures is confounded in areas
of more complicated fiber wiring due to crossing, kissing, and dispersing
fibers. Recently, Volz et al. introduced a simple probabilistic measure of the
count of distinct fiber populations within a voxel, which was shown to reduce
variance in group comparisons. We propose a complementary measure that
considers the complexity of a voxel in context of its local region, with an aim
to quantify the localized wiring complexity of every part of white matter. This
allows, for example, identification of particularly ambiguous regions of the
brain for tractographic approaches of modeling global wiring connectivity. Our
method builds on recent advances in image inpainting, in which the task is to
plausibly fill in a missing region of an image. Our proposed method builds on a
Bayesian estimate of heteroscedastic aleatoric uncertainty of a region of white
matter by inpainting it from its context. We define the localized wiring
complexity of white matter as how accurately and confidently a well-trained
model can predict the missing patch. In our results, we observe low aleatoric
uncertainty along major neuronal pathways which increases at junctions and
towards cortex boundaries. This directly quantifies the difficulty of lesion
inpainting of dMRI images at all parts of white matter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04871</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04871</id><created>2019-10-02</created><authors><author><keyname>Cattaneo</keyname><forenames>Daniele</forenames></author><author><keyname>Vaghi</keyname><forenames>Matteo</forenames></author><author><keyname>Fontana</keyname><forenames>Simone</forenames></author><author><keyname>Ballardini</keyname><forenames>Augusto Luis</forenames></author><author><keyname>Sorrenti</keyname><forenames>Domenico Giorgio</forenames></author></authors><title>Global visual localization in LiDAR-maps through shared 2D-3D embedding
  space</title><categories>cs.CV cs.LG cs.RO eess.IV</categories><comments>Submitted to IEEE ICRA 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global localization is an important and widely studied problem for many
robotic applications. Place recognition approaches can be exploited to solve
this task, e.g., in the autonomous driving field. While most vision-based
approaches match an image w.r.t an image database, global visual localization
within LiDAR-maps remains fairly unexplored, even though the path toward high
definition 3D maps, produced mainly from LiDARs, is clear. In this work we
leverage DNN approaches to create a shared embedding space between images and
LiDAR-maps, allowing for image to 3D-LiDAR place recognition. We trained a 2D
and a 3D Deep Neural Networks (DNNs) that create embeddings, respectively from
images and from point clouds, that are close to each other whether they refer
to the same place. An extensive experimental activity is presented to assess
the effectiveness of the approach w.r.t. different learning methods, network
architectures, and loss functions. All the evaluations have been performed
using the Oxford Robotcar Dataset, which encompasses a wide range of weather
and light conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04910</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04910</id><created>2019-10-10</created><authors><author><keyname>Wagle</keyname><forenames>Ankit</forenames></author><author><keyname>Singh</keyname><forenames>Gian</forenames></author><author><keyname>Yang</keyname><forenames>Jinghua</forenames></author><author><keyname>Khatri</keyname><forenames>Sunil</forenames></author><author><keyname>Vrudhula</keyname><forenames>Sarma</forenames></author></authors><title>Threshold Logic in a Flash</title><categories>cs.ET cs.AR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel design of a threshold logic gate (a binary
perceptron) and its implementation as a standard cell. This new cell structure,
referred to as flash threshold logic (FTL), uses floating gate (flash)
transistors to realize the weights associated with a threshold function. The
threshold voltages of the flash transistors serve as a proxy for the weights.
An FTL cell can be equivalently viewed as a multi-input, edge-triggered
flipflop which computes a threshold function on a clock edge. Consequently, it
can be used in the automatic synthesis of ASICs. The use of flash transistors
in the FTL cell allows programming of the weights after fabrication, thereby
preventing discovery of its function by a foundry or by reverse engineering.
This paper focuses on the design and characteristics of the FTL cell. We
present a novel method for programming the weights of an FTL cell for a
specified threshold function using a modified perceptron learning algorithm.
The algorithm is further extended to select weights to maximize the robustness
of the design in the presence of process variations. The FTL circuit was
designed in 40nm technology and simulations with layout-extracted parasitics
included, demonstrate significant improvements in the area (79.7%), power
(61.1%), and performance (42.5%) when compared to the equivalent
implementations of the same function in conventional static CMOS design. Weight
selection targeting robustness is demonstrated using Monte Carlo simulations.
The paper also shows how FTL cells can be used for fixing timing errors after
fabrication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04918</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04918</id><created>2019-10-10</created><updated>2019-10-15</updated><authors><author><keyname>Eminaga</keyname><forenames>Okyaz</forenames></author><author><keyname>Tolkach</keyname><forenames>Yuri</forenames></author><author><keyname>Kunder</keyname><forenames>Christian</forenames></author><author><keyname>Abbas</keyname><forenames>Mahmood</forenames></author><author><keyname>Han</keyname><forenames>Ryan</forenames></author><author><keyname>Nolley</keyname><forenames>Rosalie</forenames></author><author><keyname>Semjonow</keyname><forenames>Axel</forenames></author><author><keyname>Boegemann</keyname><forenames>Martin</forenames></author><author><keyname>Huss</keyname><forenames>Sebastian</forenames></author><author><keyname>Loening</keyname><forenames>Andreas</forenames></author><author><keyname>West</keyname><forenames>Robert</forenames></author><author><keyname>Sonn</keyname><forenames>Geoffrey</forenames></author><author><keyname>Fan</keyname><forenames>Richard</forenames></author><author><keyname>Bettendorf</keyname><forenames>Olaf</forenames></author><author><keyname>Brook</keyname><forenames>James</forenames></author><author><keyname>Rubin</keyname><forenames>Daniel</forenames></author></authors><title>Deep Learning for Prostate Pathology</title><categories>q-bio.TO cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current study detects different morphologies related to prostate
pathology using deep learning models; these models were evaluated on 2,121
hematoxylin and eosin (H&amp;E) stain histology images captured using bright field
microscopy, which spanned a variety of image qualities, origins (whole slide,
tissue micro array, whole mount, Internet), scanning machines, timestamps, H&amp;E
staining protocols, and institutions. For case usage, these models were applied
for the annotation tasks in clinician-oriented pathology reports for
prostatectomy specimens. The true positive rate (TPR) for slides with prostate
cancer was 99.7% by a false positive rate of 0.785%. The F1-scores of Gleason
patterns reported in pathology reports ranged from 0.795 to 1.0 at the case
level. TPR was 93.6% for the cribriform morphology and 72.6% for the ductal
morphology. The correlation between the ground truth and the prediction for the
relative tumor volume was 0.987 n. Our models cover the major components of
prostate pathology and successfully accomplish the annotation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04919</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04919</id><created>2019-10-10</created><authors><author><keyname>Wang</keyname><forenames>Bin</forenames></author><author><keyname>Gao</keyname><forenames>Yongsheng</forenames></author><author><keyname>Yu</keyname><forenames>Xiaohan</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaohui</forenames></author><author><keyname>Xiong</keyname><forenames>Shengwu</forenames></author><author><keyname>Feng</keyname><forenames>Xianzhong</forenames></author></authors><title>From Species to Cultivar: Soybean Cultivar Recognition using Multiscale
  Sliding Chord Matching of Leaf Images</title><categories>cs.CV cs.LG eess.IV</categories><comments>33 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leaf image recognition techniques have been actively researched for plant
species identification. However it remains unclear whether leaf patterns can
provide sufficient information for cultivar recognition. This paper reports the
first attempt on soybean cultivar recognition from plant leaves which is not
only a challenging research problem but also important for soybean cultivar
evaluation, selection and production in agriculture. In this paper, we propose
a novel multiscale sliding chord matching (MSCM) approach to extract leaf
patterns that are distinctive for soybean cultivar identification. A chord is
defined to slide along the contour for measuring the synchronised patterns of
exterior shape and interior appearance of soybean leaf images. A multiscale
sliding chord strategy is developed to extract features in a coarse-to-fine
hierarchical order. A joint description that integrates the leaf descriptors
from different parts of a soybean plant is proposed for further enhancing the
discriminative power of cultivar description. We built a cultivar leaf image
database, SoyCultivar, consisting of 1200 sample leaf images from 200 soybean
cultivars for performance evaluation. Encouraging experimental results of the
proposed method in comparison to the state-of-the-art leaf species recognition
methods demonstrate the availability of cultivar information in soybean leaves
and effectiveness of the proposed MSCM for soybean cultivar identification,
which may advance the research in leaf recognition from species to cultivar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04935</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04935</id><created>2019-10-10</created><authors><author><keyname>Yang</keyname><forenames>Xin</forenames></author><author><keyname>Shi</keyname><forenames>Wenlong</forenames></author><author><keyname>Dou</keyname><forenames>Haoran</forenames></author><author><keyname>Qian</keyname><forenames>Jikuan</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Xue</keyname><forenames>Wufeng</forenames></author><author><keyname>Li</keyname><forenames>Shengli</forenames></author><author><keyname>Ni</keyname><forenames>Dong</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author></authors><title>FetusMap: Fetal Pose Estimation in 3D Ultrasound</title><categories>cs.CV cs.LG eess.IV</categories><comments>9 pages, 6 figures, 2 tables. Accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3D ultrasound (US) entrance inspires a multitude of automated prenatal
examinations. However, studies about the structuralized description of the
whole fetus in 3D US are still rare. In this paper, we propose to estimate the
3D pose of fetus in US volumes to facilitate its quantitative analyses in
global and local scales. Given the great challenges in 3D US, including the
high volume dimension, poor image quality, symmetric ambiguity in anatomical
structures and large variations of fetal pose, our contribution is three-fold.
(i) This is the first work about 3D pose estimation of fetus in the literature.
We aim to extract the skeleton of whole fetus and assign different
segments/joints with correct torso/limb labels. (ii) We propose a
self-supervised learning (SSL) framework to finetune the deep network to form
visually plausible pose predictions. Specifically, we leverage the
landmark-based registration to effectively encode case-adaptive anatomical
priors and generate evolving label proxy for supervision. (iii) To enable our
3D network perceive better contextual cues with higher resolution input under
limited computing resource, we further adopt the gradient check-pointing (GCP)
strategy to save GPU memory and improve the prediction. Extensively validated
on a large 3D US dataset, our method tackles varying fetal poses and achieves
promising results. 3D pose estimation of fetus has potentials in serving as a
map to provide navigation for many advanced studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04941</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04941</id><created>2019-10-10</created><authors><author><keyname>Choi</keyname><forenames>Hoesang</forenames></author><author><keyname>Moon</keyname><forenames>Hichan</forenames></author></authors><title>Throughput of CDM-based Random Access With SINR Capture</title><categories>eess.SP cs.IT math.IT</categories><comments>24pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code division multiplexing (CDM)-based random access is used in many
practical wireless systems. With CDM-based random access, a set of sequences is
reserved for random access. A remote station transmits a random access packet
using a randomly selected sequence among the set. If more than one remote
stations transmit random access packets using the same sequence simultaneously,
performance degrades due to sequence collision. In addition, if more than one
remote stations transmit random access packets using different sequences
simultaneously, performance also degrades due to interference. Therefore, the
performance of CDM-based random access is dependent on both sequence collision
and interference. There has been no previous research to analyze the
performance of CDM-based random access considering both sequence collision and
interference. In this paper, throughput of CDM-based random access is
investigated considering both sequence collision and interference based on a
signal to interference plus noise ratio (SINR) capture model. Analysis and
numerical simulation compare the throughputs of several random access schemes
including conventional and channel-adaptive random access. The results show
that channel-adaptive random access can achieve significantly higher throughput
than conventional random access. In addition, based on the results of this
paper, it is possible to analyze the trade-off between the throughput and
implementation complexity with increased number of sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04952</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04952</id><created>2019-10-10</created><authors><author><keyname>Chen</keyname><forenames>John</forenames></author><author><keyname>Kyrillidis</keyname><forenames>Anastasios</forenames></author></authors><title>Decaying momentum helps neural network training</title><categories>cs.LG eess.IV math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Momentum is a simple and popular technique in deep learning for
gradient-based optimizers. We propose a decaying momentum (Demon) rule,
motivated by decaying the total contribution of a gradient to all future
updates. Applying Demon to Adam leads to significantly improved training,
notably competitive to momentum SGD with learning rate decay, even in settings
in which adaptive methods are typically non-competitive. Similarly, applying
Demon to momentum SGD rivals momentum SGD with learning rate decay, and in many
cases leads to improved performance. Demon is trivial to implement and incurs
limited extra computational overhead, compared to the vanilla counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04954</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04954</id><created>2019-10-10</created><updated>2019-10-14</updated><authors><author><keyname>Jiang</keyname><forenames>Yan</forenames></author><author><keyname>Cohn</keyname><forenames>Eliza</forenames></author><author><keyname>Vorobev</keyname><forenames>Petr</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Dynamic Droop Approach for Storage-based Frequency Control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transient frequency dips that follow sudden power imbalances --frequency
Nadir-- represent a big challenge for frequency stability of low-inertia power
systems. Since low inertia is identified as one of the causes for deep
frequency Nadir, virtual inertia, which is provided by energy storage units, is
said to be one of the solutions to the problem. In the present paper, we
propose a new method for frequency control with energy storage systems (ESS),
called dynamic droop control (iDroop), that can completely eliminate frequency
Nadir during transients. Nadir elimination allows us to perform frequency
stability assessment without the need for direct numerical simulations of
system dynamics. We make a direct comparison of our developed strategy with the
usual control approaches --virtual inertia (VI) and droop control (DC)-- and
show that iDroop is more effective than both in eliminating the Nadir. More
precisely, iDroop achieves the Nadir elimination under significantly lower
gains than virtual inertia and requires almost $40\%$ less storage power
capacity to implement the control. Moreover, we show that rather unrealistic
control gains are required for virtual inertia in order to achieve Nadir
elimination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04961</identifier>
 <datestamp>2020-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04961</id><created>2019-10-10</created><updated>2020-01-21</updated><authors><author><keyname>Xing</keyname><forenames>Yunyan</forenames></author><author><keyname>Ge</keyname><forenames>Zongyuan</forenames></author><author><keyname>Zeng</keyname><forenames>Rui</forenames></author><author><keyname>Mahapatra</keyname><forenames>Dwarikanath</forenames></author><author><keyname>Seah</keyname><forenames>Jarrel</forenames></author><author><keyname>Law</keyname><forenames>Meng</forenames></author><author><keyname>Drummond</keyname><forenames>Tom</forenames></author></authors><title>Adversarial Pulmonary Pathology Translation for Pairwise Chest X-ray
  Data Augmentation</title><categories>eess.IV cs.CV</categories><comments>Code: https://github.com/yunyanxing/pairwise_xray_augmentation -
  Accepted to the International Conference on Medical Image Computing and
  Computer Assisted Intervention (MICCAI) 2019</comments><doi>10.1007/978-3-030-32226-7_84</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent works show that Generative Adversarial Networks (GANs) can be
successfully applied to chest X-ray data augmentation for lung disease
recognition. However, the implausible and distorted pathology features
generated from the less than perfect generator may lead to wrong clinical
decisions. Why not keep the original pathology region? We proposed a novel
approach that allows our generative model to generate high quality plausible
images that contain undistorted pathology areas. The main idea is to design a
training scheme based on an image-to-image translation network to introduce
variations of new lung features around the pathology ground-truth area.
Moreover, our model is able to leverage both annotated disease images and
unannotated healthy lung images for the purpose of generation. We demonstrate
the effectiveness of our model on two tasks: (i) we invite certified
radiologists to assess the quality of the generated synthetic images against
real and other state-of-the-art generative models, and (ii) data augmentation
to improve the performance of disease localisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04971</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04971</id><created>2019-10-11</created><authors><author><keyname>Neel</keyname><forenames>Garrison</forenames></author><author><keyname>Darwesh</keyname><forenames>Amir</forenames></author><author><keyname>Le</keyname><forenames>Quang</forenames></author><author><keyname>Saripalli</keyname><forenames>Srikanth</forenames></author></authors><title>Autonomous Shuttles for Last-Mile Connectivity</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an autonomous shuttle which targets providing last-mile
transportation. Often, this involves operation in crowded areas with high
levels of pedestrian traffic, and little to no lane markings or traffic
control. We aim to create a functional shuttle to be improved upon in the
future as new robust solutions are developed to replace the current components.
An initial implementation of such a shuttle presented, detailing the overall
architecture, controller structure, waypoint following, obstacle detection and
avoidance, LiDAR based sign detection, and pedestrian communication. The
performance of each component is evaluated, and future improvements are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04981</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04981</id><created>2019-10-11</created><authors><author><keyname>Dev</keyname><forenames>Soumyabrata</forenames></author><author><keyname>Savoy</keyname><forenames>Florian M.</forenames></author><author><keyname>Lee</keyname><forenames>Yee Hui</forenames></author><author><keyname>Winkler</keyname><forenames>Stefan</forenames></author></authors><title>Estimating Solar Irradiance Using Sky Imagers</title><categories>eess.IV cs.CV</categories><comments>Published in Atmospheric Measurement Techniques (AMT), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ground-based whole sky cameras are extensively used for localized monitoring
of clouds nowadays. They capture hemispherical images of the sky at regular
intervals using a fisheye lens. In this paper, we propose a framework for
estimating solar irradiance from pictures taken by those imagers. Unlike
pyranometers, such sky images contain information about cloud coverage and can
be used to derive cloud movement. An accurate estimation of solar irradiance
using solely those images is thus a first step towards short-term forecasting
of solar energy generation based on cloud movement. We derive and validate our
model using pyranometers co-located with our whole sky imagers. We achieve a
better performance in estimating solar irradiance and in particular its
short-term variations as compared to other related methods using ground-based
observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04988</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04988</id><created>2019-10-11</created><authors><author><keyname>Fan</keyname><forenames>Rui</forenames></author><author><keyname>Liu</keyname><forenames>Ming</forenames></author></authors><title>Road Damage Detection Based on Unsupervised Disparity Map Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>6 pages, 9 figures</comments><doi>10.1109/TITS.2019.2947206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel road damage detection algorithm based on
unsupervised disparity map segmentation. Firstly, a disparity map is
transformed by minimizing an energy function with respect to stereo rig roll
angle and road disparity projection model. Instead of solving this energy
minimization problem using non-linear optimization techniques, we directly find
its numerical solution. The transformed disparity map is then segmented using
Otus's thresholding method, and the damaged road areas can be extracted. The
proposed algorithm requires no parameters when detecting road damage. The
experimental results illustrate that our proposed algorithm performs both
accurately and efficiently. The pixel-level road damage detection accuracy is
approximately 97.56%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04995</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.04995</id><created>2019-10-11</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Rama Seshan</forenames></author><author><keyname>Colombo</keyname><forenames>Leonardo J.</forenames></author><author><keyname>Camarinha</keyname><forenames>Margarida</forenames></author><author><keyname>Banavar</keyname><forenames>Ravi</forenames></author><author><keyname>Bloch</keyname><forenames>Anthony</forenames></author></authors><title>Variational collision and obstacle avoidance of multi-agent systems on
  Riemannian manifolds</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to European Control Conference 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a path planning problem from a variational approach to
collision and obstacle avoidance for multi-agent systems evolving on a
Riemannian manifold. The problem consists of finding non-intersecting
trajectories between the agent and prescribed obstacles on the workspace, among
a set of admissible curves, to reach a specified configuration, based on
minimizing an energy functional that depends on the velocity, covariant
acceleration and an artificial potential function used to prevent collision
with the obstacles and among the agents. We apply the results to examples of a
planar rigid body, and collision and obstacle avoidance for agents evolving on
a sphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05054</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05054</id><created>2019-10-11</created><authors><author><keyname>Du</keyname><forenames>Zhiyong</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Guo</keyname><forenames>Weisi</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author><author><keyname>Wu</keyname><forenames>Qihui</forenames></author></authors><title>Green Deep Reinforcement Learning for Radio Resource Management:
  Architecture, Algorithm Compression and Challenge</title><categories>cs.LG cs.AI cs.NI eess.SP</categories><comments>under review in IEEE Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AI heralds a step-change in the performance and capability of wireless
networks and other critical infrastructures. However, it may also cause
irreversible environmental damage due to their high energy consumption. Here,
we address this challenge in the context of 5G and beyond, where there is a
complexity explosion in radio resource management (RRM). On the one hand, deep
reinforcement learning (DRL) provides a powerful tool for scalable optimization
for high dimensional RRM problems in a dynamic environment. On the other hand,
DRL algorithms consume a high amount of energy over time and risk compromising
progress made in green radio research. This paper reviews and analyzes how to
achieve green DRL for RRM via both architecture and algorithm innovations.
Architecturally, a cloud based training and distributed decision-making DRL
scheme is proposed, where RRM entities can make lightweight deep local
decisions whilst assisted by on-cloud training and updating. On the algorithm
level, compression approaches are introduced for both deep neural networks and
the underlying Markov Decision Processes, enabling accurate low-dimensional
representations of challenges. To scale learning across geographic areas, a
spatial transfer learning scheme is proposed to further promote the learning
efficiency of distributed DRL entities by exploiting the traffic demand
correlations. Together, our proposed architecture and algorithms provide a
vision for green and on-demand DRL capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05107</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05107</id><created>2019-10-11</created><authors><author><keyname>Nahata</keyname><forenames>Pulkit</forenames></author><author><keyname>La Bella</keyname><forenames>Alessio</forenames></author><author><keyname>Scattolini</keyname><forenames>Riccardo</forenames></author><author><keyname>Ferrari-Trecate</keyname><forenames>Giancarlo</forenames></author></authors><title>Hierarchical Control in Islanded DC Microgrids with Flexible Structures</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a comprehensive three-layered hierarchical control
architecture for islanded DC microgrids (DCmG) to achieve a well scheduled and
balanced utilization of various resources. Unlike previous contributions, we
discuss a top-to-bottom control scheme guaranteeing voltage stability and
allowing for generic topologies. Our supervisory control layer comprises a
secondary and a tertiary layer and it rests on top of a primary voltage layer.
The tertiary layer is governed by an Energy Management System (EMS), which
generates optimal power references and decision variables for generation units
by solving an MPC problem at every sampling instant. In particular, the
generated decision variables take decisions on turning ON/OFF of dispatchable
generators, and operation modes of PV generators and batteries. The secondary
layer receives power references from the EMS and translates them into
appropriate voltage references for the primary layer by solving an optimization
problem. We show that a simplified version of the secondary optimization
problem is guaranteed to be always feasible. Moreover, since the voltages can
only be enforced at the generator nodes, we provide a novel condition to
guarantee the uniqueness of the solution for load voltages and power injection
of the generation units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05110</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05110</id><created>2019-10-02</created><authors><author><keyname>Liberis</keyname><forenames>Edgar</forenames></author><author><keyname>Lane</keyname><forenames>Nicholas D.</forenames></author></authors><title>Neural networks on microcontrollers: saving memory at inference via
  operator reordering</title><categories>cs.LG eess.SP stat.ML</categories><comments>The tool is available at https://github.com/oxmlsys/tflite-tools</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing deep learning models for highly-constrained hardware would allow
imbuing many edge devices with intelligence. Microcontrollers (MCUs) are an
attractive platform for building smart devices due to their low cost, wide
availability, and modest power usage. However, they lack the computational
resources to run neural networks as straightforwardly as mobile or server
platforms, which necessitates changes to the network architecture and the
inference software. In this work, we discuss the deployment and memory concerns
of neural networks on MCUs and present a way of saving memory by changing the
execution order of the network's operators, which is orthogonal to other
compression methods. We publish a tool for reordering operators of TensorFlow
Lite models and demonstrate its utility by sufficiently reducing the memory
footprint of a CNN to deploy it on an MCU with 512KB SRAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05115</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05115</id><created>2019-09-28</created><authors><author><keyname>Aldeneh</keyname><forenames>Zakaria</forenames></author><author><keyname>Jaiswal</keyname><forenames>Mimansa</forenames></author><author><keyname>Picheny</keyname><forenames>Michael</forenames></author><author><keyname>McInnis</keyname><forenames>Melvin</forenames></author><author><keyname>Provost</keyname><forenames>Emily Mower</forenames></author></authors><title>Identifying Mood Episodes Using Dialogue Features from Clinical
  Interviews</title><categories>eess.AS cs.SD q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bipolar disorder, a severe chronic mental illness characterized by
pathological mood swings from depression to mania, requires ongoing symptom
severity tracking to both guide and measure treatments that are critical for
maintaining long-term health. Mental health professionals assess symptom
severity through semi-structured clinical interviews. During these interviews,
they observe their patients' spoken behaviors, including both what the patients
say and how they say it. In this work, we move beyond acoustic and lexical
information, investigating how higher-level interactive patterns also change
during mood episodes. We then perform a secondary analysis, asking if these
interactive patterns, measured through dialogue features, can be used in
conjunction with acoustic features to automatically recognize mood episodes.
Our results show that it is beneficial to consider dialogue features when
analyzing and building automated systems for predicting and monitoring mood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05118</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05118</id><created>2019-09-16</created><authors><author><keyname>Shamshirband</keyname><forenames>Shahaboddin</forenames></author><author><keyname>Hadipoor</keyname><forenames>Masoud</forenames></author><author><keyname>Baghban</keyname><forenames>Alireza</forenames></author><author><keyname>Mosavi</keyname><forenames>Amir</forenames></author><author><keyname>Bukor</keyname><forenames>Jozsef</forenames></author><author><keyname>Koczy</keyname><forenames>Annamaria Varkonyi</forenames></author></authors><title>Developing an ANFIS PSO Model to Estimate Mercury Emission in Combustion
  Flue Gases</title><categories>cs.LG eess.SP</categories><comments>31 pages, 7 figures</comments><msc-class>68Q05 68Q05</msc-class><doi>10.20944/preprints201905.0124.v3</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Accurate prediction of mercury content emitted from fossil fueled power
stations is of utmost important for environmental pollution assessment and
hazard mitigation. In this paper, mercury content in the output gas of power
stations boilers was predicted using adaptive neuro fuzzy inference system
method integrated with particle swarm optimization. The input parameters of the
model include coal characteristics and the operational parameters of the
boilers. The dataset has been collected from a number of power plants and
employed to educate and examine the proposed model. To evaluate the performance
of the proposed ANFIS PSO model the statistical meter of MARE was implemented.
Furthermore, relative errors between acquired data and predicted values
presented, which confirm the accuracy of the model to deal nonlinearity and
representing the dependency of flue gas mercury content into the specifications
of coal and the boiler type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05148</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05148</id><created>2019-10-11</created><authors><author><keyname>Boss</keyname><forenames>Mark</forenames></author><author><keyname>Lensch</keyname><forenames>Hendrik P. A.</forenames></author></authors><title>Single Image BRDF Parameter Estimation with a Conditional Adversarial
  Network</title><categories>cs.GR cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creating plausible surfaces is an essential component in achieving a high
degree of realism in rendering. To relieve artists, who create these surfaces
in a time-consuming, manual process, automated retrieval of the
spatially-varying Bidirectional Reflectance Distribution Function (SVBRDF) from
a single mobile phone image is desirable. By leveraging a deep neural network,
this casual capturing method can be achieved. The trained network can estimate
per pixel normal, base color, metallic and roughness parameters from the Disney
BRDF. The input image is taken with a mobile phone lit by the camera flash. The
network is trained to compensate for environment lighting and thus learned to
reduce artifacts introduced by other light sources. These losses contain a
multi-scale discriminator with an additional perceptual loss, a rendering loss
using a differentiable renderer, and a parameter loss. Besides the local
precision, this loss formulation generates material texture maps which are
globally more consistent. The network is set up as a generator network trained
in an adversarial fashion to ensure that only plausible maps are produced. The
estimated parameters not only reproduce the material faithfully in rendering
but capture the style of hand-authored materials due to the more global loss
terms compared to previous works without requiring additional post-processing.
Both the resolution and the quality is improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05149</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05149</id><created>2019-10-11</created><authors><author><keyname>Pilavci</keyname><forenames>Yusuf</forenames><affiliation>IMT Atlantique - ELEC, POLIMI</affiliation></author><author><keyname>Farrugia</keyname><forenames>Nicolas</forenames><affiliation>IMT Atlantique - ELEC</affiliation></author></authors><title>Spectral Graph Wavelet Transform as Feature Extractor for Machine
  Learning in Neuroimaging</title><categories>cs.LG cs.CV eess.IV</categories><proxy>ccsd</proxy><journal-ref>International Conference on Acoustics, Speech, and Signal
  Processing, May 2019, Brighton, United Kingdom</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph Signal Processing has become a very useful framework for signal
operations and representations defined on irregular domains. Exploiting
transformations that are defined on graph models can be highly beneficial when
the graph encodes relationships between signals. In this work, we present the
benefits of using Spectral Graph Wavelet Transform (SGWT) as a feature
extractor for machine learning on brain graphs. First, we consider a synthetic
regression problem in which the smooth graph signals are generated as input
with additive noise, and the target is derived from the input without noise.
This enables us to optimize the spectrum coverage using different wavelet
shapes. Finally, we present the benefits obtained by SGWT on a functional
Magnetic Resonance Imaging (fMRI) open dataset on human subjects, with several
graphs and wavelet shapes, by demonstrating significant performance
improvements compared to the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05171</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05171</id><created>2019-10-11</created><updated>2020-01-13</updated><authors><author><keyname>Kim</keyname><forenames>Byeonggeun</forenames></author><author><keyname>Lee</keyname><forenames>Mingu</forenames></author><author><keyname>Lee</keyname><forenames>Jinkyu</forenames></author><author><keyname>Kim</keyname><forenames>Yeonseok</forenames></author><author><keyname>Hwang</keyname><forenames>Kyuwoong</forenames></author></authors><title>Query-by-example on-device keyword spotting</title><categories>cs.LG cs.CL eess.AS stat.ML</categories><comments>IEEE ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A keyword spotting (KWS) system determines the existence of, usually
predefined, keyword in a continuous speech stream. This paper presents a
query-by-example on-device KWS system which is user-specific. The proposed
system consists of two main steps: query enrollment and testing. In query
enrollment step, phonetic posteriors are output by a small-footprint automatic
speech recognition model based on connectionist temporal classification. Using
the phonetic-level posteriorgram, hypothesis graph of finite-state transducer
(FST) is built, thus can enroll any keywords thus avoiding an out-of-vocabulary
problem. In testing, a log-likelihood is scored for input audio using the FST.
We propose a threshold prediction method while using the user-specific keyword
hypothesis only. The system generates query-specific negatives by rearranging
each query utterance in waveform. The threshold is decided based on the
enrollment queries and generated negatives. We tested two keywords in English,
and the proposed work shows promising performance while preserving simplicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05178</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05178</id><created>2019-10-11</created><authors><author><keyname>Tiwari</keyname><forenames>Anamika</forenames></author><author><keyname>Mohapatra</keyname><forenames>Abheejeet</forenames></author><author><keyname>Sahoo</keyname><forenames>Soumya Ranjan</forenames></author></authors><title>An Efficient Approach for obtaining Feasible solutions from SOCP
  formulation of ACOPF</title><categories>eess.SY cs.SY</categories><comments>3 pages, 2 figures, letter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exact Second Order Conic Programming (SOCP) formulation of AC Optimal Power
Flow (ACOPF) consists of non-convex arctangent constraints. Generally, these
constraints have been ignored or approximated (at the expense of increased
computational time) so as to solve the relaxed and convex SOCP formulation of
ACOPF. As a consequence, retrieving unique and feasible bus voltage phasors for
ACOPF of meshed networks is not always possible. In this letter, this issue has
been addressed. The arctangent constraints have been represented by alternate
linear constraints in the relaxed SOCP formulation of ACOPF, by exploiting the
properties of the meshed power network. Numerical tests show that the proposed
formulation gives an unique and feasible ACOPF solution, which is practically
realizable from system operation perspective and with global optimality
feature, as compared to other works reported in the literature. Moreover, the
proposed formulation is extremely efficient as only one execution of
formulation provides a feasible solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05243</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05243</id><created>2019-10-11</created><authors><author><keyname>Purabi</keyname><forenames>Sharmin Akther</forenames></author><author><keyname>Rashed</keyname><forenames>Rayhan</forenames></author><author><keyname>Islam</keyname><forenames>Md. Mirajul</forenames></author><author><keyname>Uddin</keyname><forenames>Md. Nahiyan</forenames></author><author><keyname>Naznin</keyname><forenames>Mahmuda</forenames></author><author><keyname>Islam</keyname><forenames>A. B. M. Alim Al</forenames></author></authors><title>As You Are, So Shall You Move Your Head: A System-Level Analysis between
  Head Movements and Corresponding Traits and Emotions</title><categories>cs.HC cs.IR cs.LG cs.SY eess.SY</categories><comments>9 pages, 7 figures, NSysS 2019</comments><doi>10.1145/3362966.3362985</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying physical traits and emotions based on system-sensed physical
activities is a challenging problem in the realm of human-computer interaction.
Our work contributes in this context by investigating an underlying connection
between head movements and corresponding traits and emotions. To do so, we
utilize a head movement measuring device called eSense, which gives
acceleration and rotation of a head. Here, first, we conduct a thorough study
over head movement data collected from 46 persons using eSense while inducing
five different emotional states over them in isolation. Our analysis reveals
several new head movement based findings, which in turn, leads us to a novel
unified solution for identifying different human traits and emotions through
exploiting machine learning techniques over head movement data. Our analysis
confirms that the proposed solution can result in high accuracy over the
collected data. Accordingly, we develop an integrated unified solution for
real-time emotion and trait identification using head movement data leveraging
outcomes of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05253</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05253</id><created>2019-10-03</created><authors><author><keyname>Sun</keyname><forenames>Tsai-Ho</forenames></author><author><keyname>Lai</keyname><forenames>Chien-Hsun</forenames></author><author><keyname>Wong</keyname><forenames>Sai-Keung</forenames></author><author><keyname>Wang</keyname><forenames>Yu-Shuen</forenames></author></authors><title>Adversarial Colorization Of Icons Based On Structure And Color
  Conditions</title><categories>cs.LG cs.GR eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a system to help designers create icons that are widely used in
banners, signboards, billboards, homepages, and mobile apps. Designers are
tasked with drawing contours, whereas our system colorizes contours in
different styles. This goal is achieved by training a dual conditional
generative adversarial network (GAN) on our collected icon dataset. One
condition requires the generated image and the drawn contour to possess a
similar contour, while the other anticipates the image and the referenced icon
to be similar in color style. Accordingly, the generator takes a contour image
and a man-made icon image to colorize the contour, and then the discriminators
determine whether the result fulfills the two conditions. The trained network
is able to colorize icons demanded by designers and greatly reduces their
workload. For the evaluation, we compared our dual conditional GAN to several
state-of-the-art techniques. Experiment results demonstrate that our network is
over the previous networks. Finally, we will provide the source code, icon
dataset, and trained network for public use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05259</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05259</id><created>2019-10-11</created><authors><author><keyname>Wu</keyname><forenames>Weiwen</forenames></author><author><keyname>Chen</keyname><forenames>Peijun</forenames></author><author><keyname>Vardhanabhuti</keyname><forenames>Vince</forenames></author><author><keyname>Wu</keyname><forenames>Weifei</forenames></author><author><keyname>Yu</keyname><forenames>Hengyong</forenames></author></authors><title>Improved Material Decomposition with a Two-step Regularization for
  spectral CT</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the advantages of spectral computed tomography (CT) is it can achieve
accurate material components using the material decomposition methods. The
image-based material decomposition is a common method to obtain specific
material components, and it can be divided into two steps: image reconstruction
and post material decomposition. To obtain accurate material maps, the image
reconstruction method mainly focuses on improving image quality by
incorporating regularization priors. Very recently, the regularization priors
are introduced into the post material decomposition procedure in the iterative
image-based methods. Since the regularization priors can be incorporated into
image reconstruction and post image-domain material decomposition, the
performance of regularization by combining these two cases is still an open
problem. To realize this goal, the material accuracy from those steps are first
analyzed and compared. Then, to further improve the accuracy of decomposition
materials, a two-step regularization based method is developed by incorporating
priors into image reconstruction and post material decomposition. Both
numerical simulation and preclinical mouse experiments are performed to
demonstrate the advantages of the two-step regularization based method in
improving material accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05262</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05262</id><created>2019-10-11</created><authors><author><keyname>Abdullah</keyname><forenames>Hadi</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Sajidur</forenames></author><author><keyname>Garcia</keyname><forenames>Washington</forenames></author><author><keyname>Blue</keyname><forenames>Logan</forenames></author><author><keyname>Warren</keyname><forenames>Kevin</forenames></author><author><keyname>Yadav</keyname><forenames>Anurag Swarnim</forenames></author><author><keyname>Shrimpton</keyname><forenames>Tom</forenames></author><author><keyname>Traynor</keyname><forenames>Patrick</forenames></author></authors><title>Hear &quot;No Evil&quot;, See &quot;Kenansville&quot;: Efficient and Transferable Black-Box
  Attacks on Speech Recognition and Voice Identification Systems</title><categories>cs.CR cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic speech recognition and voice identification systems are being
deployed in a wide array of applications, from providing control mechanisms to
devices lacking traditional interfaces, to the automatic transcription of
conversations and authentication of users. Many of these applications have
significant security and privacy considerations. We develop attacks that force
mistranscription and misidentification in state of the art systems, with
minimal impact on human comprehension. Processing pipelines for modern systems
are comprised of signal preprocessing and feature extraction steps, whose
output is fed to a machine-learned model. Prior work has focused on the models,
using white-box knowledge to tailor model-specific attacks. We focus on the
pipeline stages before the models, which (unlike the models) are quite similar
across systems. As such, our attacks are black-box and transferable, and
demonstrably achieve mistranscription and misidentification rates as high as
100% by modifying only a few frames of audio. We perform a study via Amazon
Mechanical Turk demonstrating that there is no statistically significant
difference between human perception of regular and perturbed audio. Our
findings suggest that models may learn aspects of speech that are generally not
perceived by human subjects, but that are crucial for model accuracy. We also
find that certain English language phonemes (in particular, vowels) are
significantly more susceptible to our attack. We show that the attacks are
effective when mounted over cellular networks, where signals are subject to
degradation due to transcoding, jitter, and packet loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05266</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05266</id><created>2019-10-09</created><updated>2020-02-17</updated><authors><author><keyname>Vlachas</keyname><forenames>Pantelis R.</forenames></author><author><keyname>Pathak</keyname><forenames>Jaideep</forenames></author><author><keyname>Hunt</keyname><forenames>Brian R.</forenames></author><author><keyname>Sapsis</keyname><forenames>Themistoklis P.</forenames></author><author><keyname>Girvan</keyname><forenames>Michelle</forenames></author><author><keyname>Ott</keyname><forenames>Edward</forenames></author><author><keyname>Koumoutsakos</keyname><forenames>Petros</forenames></author></authors><title>Backpropagation Algorithms and Reservoir Computing in Recurrent Neural
  Networks for the Forecasting of Complex Spatiotemporal Dynamics</title><categories>eess.SP cs.LG physics.flu-dyn</categories><comments>41 pages, submitted to Elsevier Journal of Neural Networks (accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the efficiency of Recurrent Neural Networks in forecasting the
spatiotemporal dynamics of high dimensional and reduced order complex systems
using Reservoir Computing (RC) and Backpropagation through time (BPTT) for
gated network architectures. We highlight advantages and limitations of each
method and discuss their implementation for parallel computing architectures.
We quantify the relative prediction accuracy of these algorithms for the
longterm forecasting of chaotic systems using as benchmarks the Lorenz-96 and
the Kuramoto-Sivashinsky (KS) equations. We find that, when the full state
dynamics are available for training, RC outperforms BPTT approaches in terms of
predictive performance and in capturing of the long-term statistics, while at
the same time requiring much less training time. However, in the case of
reduced order data, large scale RC models can be unstable and more likely than
the BPTT algorithms to diverge. In contrast, RNNs trained via BPTT show
superior forecasting abilities and capture well the dynamics of reduced order
systems. Furthermore, the present study quantifies for the first time the
Lyapunov Spectrum of the KS equation with BPTT, achieving similar accuracy as
RC. This study establishes that RNNs are a potent computational framework for
the learning and forecasting of complex spatiotemporal systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05303</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05303</id><created>2019-10-11</created><authors><author><keyname>Jiang</keyname><forenames>Yulun</forenames></author><author><keyname>Yu</keyname><forenames>Lei</forenames></author><author><keyname>Zhang</keyname><forenames>Haijian</forenames></author><author><keyname>Liu</keyname><forenames>Zhou</forenames></author></authors><title>Learning Cluster Structured Sparsity by Reweighting</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the paradigm of unfolding iterative algorithms into finite-length
feed-forward neural networks has achieved a great success in the area of sparse
recovery. Benefit from available training data, the learned networks have
achieved state-of-the-art performance in respect of both speed and accuracy.
However, the structure behind sparsity, imposing constraint on the support of
sparse signals, is often an essential prior knowledge but seldom considered in
the existing networks. In this paper, we aim at bridging this gap.
Specifically, exploiting the iterative reweighted $\ell_1$ minimization (IRL1)
algorithm, we propose to learn the cluster structured sparsity (CSS) by
rewegihting adaptively. In particular, we first unfold the Reweighted Iterative
Shrinkage Algorithm (RwISTA) into an end-to-end trainable deep architecture
termed as RW-LISTA. Then instead of the element-wise reweighting, the global
and local reweighting manner are proposed for the cluster structured sparse
learning. Numerical experiments further show the superiority of our algorithm
against both classical algorithms and learning-based networks on different
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05305</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05305</id><created>2019-10-02</created><authors><author><keyname>Mismar</keyname><forenames>Faris B.</forenames></author><author><keyname>AlAmmouri</keyname><forenames>Ahmad</forenames></author><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Evans</keyname><forenames>Brian L.</forenames></author></authors><title>Deep Learning Predictive Band Switching in Wireless Networks</title><categories>cs.NI cs.LG eess.SP stat.ML</categories><comments>28 pages, 13 figures, submitted to IEEE Transactions on Wireless
  Communications on October 2, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cellular systems, the user equipment (UE) can request a change in the
frequency band when its rate drops below a threshold on the current band. The
UE is then instructed by the base station (BS) to measure the quality of
candidate bands, which requires a measurement gap in the data transmission,
thus lowering the data rate. We propose a band switching approach based on
machine learning that does not require any measurement gap. Our proposed
classifier-based band switching policy instead exploits spatial and spectral
correlation between radio frequency signals in different bands based on
knowledge of the UE location. We focus on switching between a lower (e.g. 3.5
GHz) band and a millimeter wave band (e.g. 28 GHz), and design and evaluate two
classification models that are trained on a ray-tracing dataset. A key insight
is that measurement gaps are overkill, in that only the relative order of the
bands is necessary for band selection, rather than a full channel estimate. Our
proposed machine learning-based policies achieve roughly 30% improvement in
mean effective rates over those of the industry standard policy, while
achieving misclassification errors well below 0.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05306</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05306</id><created>2019-09-30</created><authors><author><keyname>Celik</keyname><forenames>Abdulkadir</forenames></author><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Shihada</keyname><forenames>Basem</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Software-Defined Opto-Acoustic Network Architecture for Internet of
  Underwater Things</title><categories>cs.NI cs.SY eess.SY</categories><comments>Submitted to IEEE Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we envision a hybrid opto-acoustic network design for the
internet of underwater things (IoUT). Software-defined underwater networking
(SDUN) is presented as an enabler of hybridizing benefits of optic and acoustic
systems and adapting IoUT nodes to the challenging and dynamically changing
underwater environment. We explain inextricably interwoven relations among
functionalities of different layers and analyze their impacts on key network
attributes. Network function virtualization (NFV) concept is then introduced to
realize application specific cross-layer protocol suites through an NFV
management and orchestration system. We finally discuss how SDUN and NFV can
slice available network resources as per the diverging service demands of
different underwater applications. Such a revolutionary architectural paradigm
shift is not only a cure for chronicle underwater networking problems but also
a way of smoothly integrating IoUT and IoT ecosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05312</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05312</id><created>2019-09-12</created><authors><author><keyname>Fiedler</keyname><forenames>David</forenames></author><author><keyname>&#x10c;&#xe1;p</keyname><forenames>Michal</forenames></author><author><keyname>Nykl</keyname><forenames>Jan</forenames></author><author><keyname>&#x17d;ileck&#xfd;</keyname><forenames>Pavol</forenames></author><author><keyname>Schaefer</keyname><forenames>Martin</forenames></author></authors><title>Map Matching Algorithm for Large-scale Datasets</title><categories>cs.NI cs.CV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GPS receivers embedded in cell phones and connected vehicles generate a
series of location measurements that can be used for various analytical
purposes. A common pre-processing step of this data is the so-called map
matching. The goal of map matching is to infer the trajectory that the device
followed in a road network from a potentially sparse series of noisy location
measurements. Although accurate and robust map matching algorithms based on
probabilistic models exist, they are computationally heavy and thus impractical
for processing of large datasets. In this paper, we present a scalable
map-matching algorithm based on Dijkstra shortest path method, that is both
accurate and applicable to large datasets. Our experiments on a
publicly-available dataset showed that the proposed method achieves accuracy
that is comparable to that of the existing map matching methods using only a
fraction of computational resources. In result, our algorithm can be used to
efficiently process large datasets of noisy and potentially sparse location
data that would be unexploitable using existing techniques due to their high
computational requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05313</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05313</id><created>2019-10-11</created><authors><author><keyname>Zhang</keyname><forenames>Chi</forenames></author><author><keyname>Kuppannagari</keyname><forenames>Sanmukh R.</forenames></author><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author><author><keyname>Prasanna</keyname><forenames>Viktor K.</forenames></author></authors><title>Building HVAC Scheduling Using Reinforcement Learning via Neural Network
  Based Model Approximation</title><categories>eess.SY cs.SY</categories><comments>10 pages, 13 figures, to be appear in ACM BuildSys '19, November
  13-14, 2019, New York, NY, USA</comments><doi>10.1145/3360322.3360861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Buildings sector is one of the major consumers of energy in the United
States. The buildings HVAC (Heating, Ventilation, and Air Conditioning)
systems, whose functionality is to maintain thermal comfort and indoor air
quality (IAQ), account for almost half of the energy consumed by the buildings.
Thus, intelligent scheduling of the building HVAC system has the potential for
tremendous energy and cost savings while ensuring that the control objectives
(thermal comfort, air quality) are satisfied. Recently, several works have
focused on model-free deep reinforcement learning based techniques such as Deep
Q-Network (DQN). Such methods require extensive interactions with the
environment. Thus, they are impractical to implement in real systems due to low
sample efficiency. Safety-aware exploration is another challenge in real
systems since certain actions at particular states may result in catastrophic
outcomes. To address these issues and challenges, we propose a model-based
reinforcement learning approach that learns the system dynamics using a neural
network. Then, we adopt Model Predictive Control (MPC) using the learned system
dynamics to perform control with random-sampling shooting method. To ensure
safe exploration, we limit the actions within safe range and the maximum
absolute change of actions according to prior knowledge. We evaluate our ideas
through simulation using widely adopted EnergyPlus tool on a case study
consisting of a two zone data-center. Experiments show that the average
deviation of the trajectories sampled from the learned dynamics and the ground
truth is below $20\%$. Compared with baseline approaches, we reduce the total
energy consumption by $17.1\% \sim 21.8\%$. Compared with model-free
reinforcement learning approach, we reduce the required number of training
steps to converge by 10x.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05329</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05329</id><created>2019-10-11</created><authors><author><keyname>Dash</keyname><forenames>Sambit</forenames></author><author><keyname>Subudhi</keyname><forenames>Umamani</forenames></author></authors><title>Multiple Power Quality Event Detection and Classification using Modified
  S Transform and WOA tuned SVM Classifier</title><categories>eess.SP</categories><comments>Submitted to Optik (Elsevier)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method for classification of power quality events is
illustrated. 15 types of power quality events consisting of single and
multi-stage disturbances are considered for study. A database of the synthetic
PQ events is generated in MATLAB using mathematical models. The generated
signals are passed through a novel Modified Stockwell transform consisting of
second order gaussian window which provides the ST matrix. From the ST matrix
various statistical features such as energy and standard deviation of the
magnitude and phase contour are extracted and given as input to Support Vector
Machine (SVM). Furthermore, to improve the performance of SVM, a novel
meta-heuristic technique called Whale Optimization Algorithm (WOA) is used to
tune the hyper parameters of the SVM classifier. The performance of the
proposed method is analyzed under noisy and noiseless conditions. It is
observed that WOA tuned SVM provides improved classification accuracy than
other widely used meta-heuristic optimization algorithms such as Particle Swarm
Optimization (PSO) tuned SVM and Genetic Algorithm (GA) tuned SVM. Further, two
novel circuits for generation of sag, swell and interrupt are developed and the
proposed technique is validated on real time signals obtained from the
circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05338</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05338</id><created>2019-10-11</created><updated>2019-11-25</updated><authors><author><keyname>Vu</keyname><forenames>Minh H.</forenames></author><author><keyname>Nyholm</keyname><forenames>Tufve</forenames></author><author><keyname>L&#xf6;fstedt</keyname><forenames>Tommy</forenames></author></authors><title>TuNet: End-to-end Hierarchical Brain Tumor Segmentation using Cascaded
  Networks</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted at MICCAI BrainLes 2019</comments><doi>10.13140/RG.2.2.20358.52803</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Glioma is one of the most common types of brain tumors; it arises in the
glial cells in the human brain and in the spinal cord. In addition to having a
high mortality rate, glioma treatment is also very expensive. Hence, automatic
and accurate segmentation and measurement from the early stages are critical in
order to prolong the survival rates of the patients and to reduce the costs of
the treatment. In the present work, we propose a novel end-to-end cascaded
network for semantic segmentation that utilizes the hierarchical structure of
the tumor sub-regions with ResNet-like blocks and Squeeze-and-Excitation
modules after each convolution and concatenation block. By utilizing
cross-validation, an average ensemble technique, and a simple post-processing
technique, we obtained dice scores of 88.06, 80.84, and 80.29, and Hausdorff
Distances (95th percentile) of 6.10, 5.17, and 2.21 for the whole tumor, tumor
core, and enhancing tumor, respectively, on the online test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05339</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05339</id><created>2019-10-11</created><updated>2020-02-02</updated><authors><author><keyname>Bansal</keyname><forenames>Chetan</forenames></author><author><keyname>Renganathan</keyname><forenames>Sundararajan</forenames></author><author><keyname>Asudani</keyname><forenames>Ashima</forenames></author><author><keyname>Midy</keyname><forenames>Olivier</forenames></author><author><keyname>Janakiraman</keyname><forenames>Mathru</forenames></author></authors><title>DeCaf: Diagnosing and Triaging Performance Issues in Large-Scale Cloud
  Services</title><categories>cs.DC cs.SE cs.SY eess.SY</categories><comments>To be published in the proceedings of ICSE-SEIP '20, Seoul, Republic
  of Korea</comments><doi>10.1145/3377813.3381353</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large scale cloud services use Key Performance Indicators (KPIs) for tracking
and monitoring performance. They usually have Service Level Objectives (SLOs)
baked into the customer agreements which are tied to these KPIs. Dependency
failures, code bugs, infrastructure failures, and other problems can cause
performance regressions. It is critical to minimize the time and manual effort
in diagnosing and triaging such issues to reduce customer impact. Large volume
of logs and mixed type of attributes (categorical, continuous) in the logs
makes diagnosis of regressions non-trivial.
  In this paper, we present the design, implementation and experience from
building and deploying DeCaf, a system for automated diagnosis and triaging of
KPI issues using service logs. It uses machine learning along with pattern
mining to help service owners automatically root cause and triage performance
issues. We present the learnings and results from case studies on two large
scale cloud services in Microsoft where DeCaf successfully diagnosed 10 known
and 31 unknown issues. DeCaf also automatically triages the identified issues
by leveraging historical data. Our key insights are that for any such diagnosis
tool to be effective in practice, it should a) scale to large volumes of
service logs and attributes, b) support different types of KPIs and ranking
functions, c) be integrated into the DevOps processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05369</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05369</id><created>2019-10-11</created><authors><author><keyname>Chaudhari</keyname><forenames>Shailesh</forenames></author><author><keyname>Kwon</keyname><forenames>HyukJoon</forenames></author><author><keyname>Song</keyname><forenames>Kee-Bong</forenames></author></authors><title>Reliable and Low-Complexity MIMO Detector Selection using Neural Network</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to dynamically select a MIMO detector using neural
network for each resource element (RE) in the transport block of 5G NR/LTE
communication system. The objective is to minimize the computational complexity
of MIMO detection while keeping the transport block error rate (BLER) close to
the BLER when dimension-reduced maximum-likelihood (DR-ML) detection is used. A
detector selection problem is formulated to achieve this objective. However,
since the problem is high dimensional and NP-hard, we first decompose the
problem into smaller problems and train a multi-layer perceptron (MLP) network
to obtain the solution. The MLP network is trained to select a low-complexity,
yet reliable, detector using instantaneous channel condition in the RE. We
first propose a method to generate a labeled dataset to select a low-complexity
detector. Then, the MLP is trained twice using quasi-Newton method to select a
reliable detector for each RE. The performance of online detector selection is
evaluated in 5G NR link level simulator in terms of BLER and the complexity is
quantified in terms of the number of Euclidean distance (ED) computations and
the number of real additions and multiplication. Results show that the
computational complexity in the MIMO detector can be reduced by ~10X using the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05370</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05370</id><created>2019-10-11</created><updated>2019-10-21</updated><authors><author><keyname>Oksuz</keyname><forenames>Ilkay</forenames></author><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Ruijsink</keyname><forenames>Bram</forenames></author><author><keyname>Anton</keyname><forenames>Esther Puyol</forenames></author><author><keyname>Bustin</keyname><forenames>Aurelien</forenames></author><author><keyname>Cruz</keyname><forenames>Gastao</forenames></author><author><keyname>Prieto</keyname><forenames>Claudia</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author><author><keyname>Schnabel</keyname><forenames>Julia A.</forenames></author></authors><title>Deep Learning Based Detection and Correction of Cardiac MR Motion
  Artefacts During Reconstruction for High-Quality Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Segmenting anatomical structures in medical images has been successfully
addressed with deep learning methods for a range of applications. However, this
success is heavily dependent on the quality of the image that is being
segmented. A commonly neglected point in the medical image analysis community
is the vast amount of clinical images that have severe image artefacts due to
organ motion, movement of the patient and/or image acquisition related issues.
In this paper, we discuss the implications of image motion artefacts on cardiac
MR segmentation and compare a variety of approaches for jointly correcting for
artefacts and segmenting the cardiac cavity. We propose to use a segmentation
network coupled with this in an end-to-end framework. Our training optimises
three different tasks: 1) image artefact detection, 2) artefact correction and
3) image segmentation. We train the reconstruction network to automatically
correct for motion-related artefacts using synthetically corrupted cardiac MR
k-space data and uncorrected reconstructed images. Using a test set of 500
2D+time cine MR acquisitions from the UK Biobank data set, we achieve
demonstrably good image quality and high segmentation accuracy in the presence
of synthetic motion artefacts. We quantitatively compare our method with a
variety of techniques for jointly recovering image quality and performing image
segmentation. We showcase better performance compared to state-of-the-art image
correction techniques. Moreover, our method preserves the quality of
uncorrupted images and therefore can be utilised as a global image
reconstruction algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05372</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05372</id><created>2019-10-11</created><updated>2019-12-02</updated><authors><author><keyname>Guo</keyname><forenames>Fenghua</forenames></author><author><keyname>Leemans</keyname><forenames>Alexander</forenames></author><author><keyname>Viergever</keyname><forenames>Max A.</forenames></author><author><keyname>Dell'Acqua</keyname><forenames>Flavio</forenames></author><author><keyname>De Luca</keyname><forenames>Alberto</forenames></author></authors><title>Generalized Richardson-Lucy (GRL) for analyzing multi-shell diffusion
  MRI data</title><categories>physics.med-ph cs.CE eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spherical deconvolution is a widely used approach to quantify fiber
orientation distribution from diffusion MRI data. The damped Richardson-Lucy
(dRL) is developed to perform robust spherical deconvolution on single shell
diffusion MRI data. While the dRL algorithm could in theory be directly applied
to multi-shell data, it is not optimised to model the signal from multiple
tissue types. In this work, we introduce a new framework based on dRL - dubbed
Generalized Richardson Lucy (GRL) - that uses multi-shell data in combination
with user-chosen tissue models to disentangle partial volume effects and
increase the accuracy in FOD estimation. The optimal weighting of multi-shell
data in the fit and the robustness to noise and partial volume effects of GRL
was studied with synthetic data. Subsequently, we investigated the performances
of GRL in comparison to dRL on a high-resolution diffusion MRI dataset from the
Human Connectome Project and on an MRI dataset acquired at 3T on a clinical
scanner. The feasibility of including intra-voxel incoherent motion (IVIM)
effects in the modelling was studied on a third dataset. Results of simulations
show that GRL can robustly disentangle different tissue types at SNR above 20
and improves the angular accuracy of the FOD estimation. On real data, GRL
provides signal fraction maps that are physiologically plausible and consistent
between datasets. When considering IVIM effects, high blood pseudo-diffusion
fraction is observed in the medial temporal lobe and in the sagittal sinus. In
comparison to dRL, GRL provides sharper FODs and less spurious peaks in
presence of partial volume effects and results in a better tract termination at
the grey/white matter interface or at the outer cortical surface. In
conclusion, GRL offers a new modular and flexible framework to perform
spherical deconvolution of multi-shell data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05375</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05375</id><created>2019-10-11</created><authors><author><keyname>Kim</keyname><forenames>Hyojin</forenames></author><author><keyname>Anirudh</keyname><forenames>Rushil</forenames></author><author><keyname>Mohan</keyname><forenames>K. Aditya</forenames></author><author><keyname>Champley</keyname><forenames>Kyle</forenames></author></authors><title>Extreme Few-view CT Reconstruction using Deep Inference</title><categories>eess.IV cs.CV cs.LG</categories><comments>Deep Inverse NeurIPS 2019 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstruction of few-view x-ray Computed Tomography (CT) data is a highly
ill-posed problem. It is often used in applications that require low radiation
dose in clinical CT, rapid industrial scanning, or fixed-gantry CT. Existing
analytic or iterative algorithms generally produce poorly reconstructed images,
severely deteriorated by artifacts and noise, especially when the number of
x-ray projections is considerably low. This paper presents a deep
network-driven approach to address extreme few-view CT by incorporating
convolutional neural network-based inference into state-of-the-art iterative
reconstruction. The proposed method interprets few-view sinogram data using
attention-based deep networks to infer the reconstructed image. The predicted
image is then used as prior knowledge in the iterative algorithm for final
reconstruction. We demonstrate effectiveness of the proposed approach by
performing reconstruction experiments on a chest CT dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05382</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05382</id><created>2019-10-11</created><authors><author><keyname>Watson</keyname><forenames>Ryan M.</forenames></author><author><keyname>Gross</keyname><forenames>Jason N.</forenames></author><author><keyname>Taylor</keyname><forenames>Clark N.</forenames></author><author><keyname>Leishman</keyname><forenames>Robert C.</forenames></author></authors><title>Robust Incremental State Estimation through Covariance Adaptation</title><categories>eess.SP cs.RO</categories><comments>8 pages, 4 figures, 2 tables, submitted to IEEE Robotics and
  Automation Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in the fields of robotics and automation have spurred
significant interest in robust state estimation. To enable robust state
estimation, several methodologies have been proposed. One such technique, which
has shown promising performance, is the concept of iteratively estimating a
Gaussian Mixture Model (GMM), based upon the state estimation residuals, to
characterize the measurement uncertainty model. Through this iterative process,
the measurement uncertainty model is more accurately characterized, which
enables robust state estimation through the appropriate de-weighting of
erroneous observations. This approach, however, has traditionally required a
batch estimation framework to enable the estimation of the measurement
uncertainty model, which is not advantageous to robotic applications. In this
paper, we propose an efficient, incremental extension to the measurement
uncertainty model estimation paradigm. The incremental covariance estimation
(ICE) approach, as detailed within this paper, is evaluated on several
collected data sets, where it is shown to provide a significant increase in
localization accuracy when compared to other state-of-the-art robust,
incremental estimation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05395</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05395</id><created>2019-10-11</created><updated>2019-11-20</updated><authors><author><keyname>Rashed</keyname><forenames>Hazem</forenames></author><author><keyname>Ramzy</keyname><forenames>Mohamed</forenames></author><author><keyname>Vaquero</keyname><forenames>Victor</forenames></author><author><keyname>Sallab</keyname><forenames>Ahmad El</forenames></author><author><keyname>Sistu</keyname><forenames>Ganesh</forenames></author><author><keyname>Yogamani</keyname><forenames>Senthil</forenames></author></authors><title>FuseMODNet: Real-Time Camera and LiDAR based Moving Object Detection for
  robust low-light Autonomous Driving</title><categories>cs.CV cs.RO eess.IV</categories><comments>Accepted for Oral presentation at ICCV 2019 Workshop on Autonomous
  Driving. https://sites.google.com/view/fusemodnet</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Moving object detection is a critical task for autonomous vehicles. As
dynamic objects represent higher collision risk than static ones, our own
ego-trajectories have to be planned attending to the future states of the
moving elements of the scene. Motion can be perceived using temporal
information such as optical flow. Conventional optical flow computation is
based on camera sensors only, which makes it prone to failure in conditions
with low illumination. On the other hand, LiDAR sensors are independent of
illumination, as they measure the time-of-flight of their own emitted lasers.
In this work, we propose a robust and real-time CNN architecture for Moving
Object Detection (MOD) under low-light conditions by capturing motion
information from both camera and LiDAR sensors. We demonstrate the impact of
our algorithm on KITTI dataset where we simulate a low-light environment
creating a novel dataset &quot;Dark KITTI&quot;. We obtain a 10.1% relative improvement
on Dark-KITTI, and a 4.25% improvement on standard KITTI relative to our
baselines. The proposed algorithm runs at 18 fps on a standard desktop GPU
using $256\times1224$ resolution images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05401</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05401</id><created>2019-10-11</created><authors><author><keyname>De Laurentiis</keyname><forenames>Leonardo</forenames></author><author><keyname>Pomente</keyname><forenames>Andrea</forenames></author><author><keyname>Del Frate</keyname><forenames>Fabio</forenames></author><author><keyname>Schiavon</keyname><forenames>Giovanni</forenames></author></authors><title>Capsule and convolutional neural network-based SAR ship classification
  in Sentinel-1 data</title><categories>eess.IV cs.CV cs.LG</categories><comments>Please check out the original SPIE paper for a complete list of
  figures, tables, references and general content</comments><journal-ref>SPIE Remote Sensing 2019: Proceedings Volume 11154, Active and
  Passive Microwave Remote Sensing for Environmental Monitoring III; 1115405
  (2019)</journal-ref><doi>10.1117/12.2532551</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthetic Aperture Radar (SAR) constitutes a fundamental asset for wide-areas
monitoring with high-resolution requirements. The first SAR sensors have given
rise to coarse coastal and maritime monitoring applications, including oil
spill, ship and ice floes detection. With the upgrade to very high-resolution
sensors in the recent years, with relatively new SAR missions such as
Sentinel-1, a great deal of data providing a stronger information content has
been released, enabling more refined studies on general targets features and
thus permitting complex classifications, as for ship classification, which has
become increasingly relevant given the growing need for coastal surveillance in
commercial and military segments. In the last decade, several works focused on
this topic have been presented, generally based on radiometric features
processing; furthermore, in the very recent years a significant amount of
research works have focused on emerging deep learning techniques, in particular
on Convolutional Neural Networks (CNN). Recently Capsule Neural Networks
(CapsNets) have been presented, demonstrating a notable improvement in
capturing the properties of given entities, improving the use of spatial
informations, in particular of spatial dependence between features, a severely
lacking feature in CNNs. In fact, CNNs pooling operations have been criticized
for losing spatial relations, thus special capsules, along with a new iterative
routing-by-agreement mechanism, have been proposed. In this work a comparison
between Capsule and CNNs potential in the ship classification application
domain is shown, by leveraging the OpenSARShip, a SAR Sentinel-1 ship chips
dataset; in particular, a performance comparison between capsule and various
convolutional architectures is built, demonstrating better performances of
CapsNet in classifying ships within a small dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05405</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05405</id><created>2019-10-11</created><authors><author><keyname>Chen</keyname><forenames>Shuhang</forenames></author><author><keyname>Devraj</keyname><forenames>Adithya M.</forenames></author><author><keyname>Bu&#x161;i&#x107;</keyname><forenames>Ana</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author></authors><title>Zap Q-Learning With Nonlinear Function Approximation</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Zap stochastic approximation (SA) algorithm was introduced recently as a
means to accelerate convergence in reinforcement learning algorithms. While
numerical results were impressive, stability (in the sense of boundedness of
parameter estimates) was established in only a few special cases. This class of
algorithms is generalized in this paper, and stability is established under
very general conditions. This general result can be applied to a wide range of
algorithms found in reinforcement learning. Two classes are considered in this
paper:
  (i)The natural generalization of Watkins' algorithm is not always stable in
function approximation settings. Parameter estimates may diverge to infinity
even in the \textit{linear} function approximation setting with a simple finite
state-action MDP. Under mild conditions, the Zap SA algorithm provides a stable
algorithm, even in the case of \textit{nonlinear} function approximation.
  (ii) The GQ algorithm of Maei et.~al.~2010 is designed to address the
stability challenge. Analysis is provided to explain why the algorithm may be
very slow to converge in practice. The new Zap GQ algorithm is stable even for
nonlinear function approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05409</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05409</id><created>2019-10-11</created><authors><author><keyname>Mieth</keyname><forenames>Robert</forenames></author><author><keyname>Kim</keyname><forenames>Jip</forenames></author><author><keyname>Dvorkin</keyname><forenames>Yury</forenames></author></authors><title>Risk- and Variance-Aware Electricity Pricing</title><categories>eess.SY cs.SY</categories><comments>7 pages, 1 figure, 1 table, 26 references, under review for PSCC 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The roll-out of stochastic renewable energy sources (RES) undermines the
efficiency of power system and market operations. This paper proposes an
approach to derive electricity prices that internalize RES stochasticity. We
leverage a chance-constrained AC Optimal Power Flow (CC AC-OPF) model, which is
robust against RES uncertainty and is also aware of the resulting variability
(variance) of the system state variables. Using conic duality theory, we derive
and analyze energy and balancing reserve prices that internalize the risk of
system limit violations and the variance of system state variables. We compare
the risk- and variance-aware prices on the IEEE 118-node testbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05410</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05410</id><created>2019-10-10</created><authors><author><keyname>de Pedro-Carracedo</keyname><forenames>J.</forenames></author><author><keyname>Ugena</keyname><forenames>A. M.</forenames></author><author><keyname>Gonzalez-Marcos</keyname><forenames>A. P.</forenames></author></authors><title>Phase space reconstruction from a biological time series. A
  PhotoPlethysmoGraphic signal a case study</title><categories>q-bio.OT eess.SP nlin.AO</categories><comments>12 pages, 12 figures with 37 subfigures</comments><msc-class>37-02, 37E99</msc-class><journal-ref>Appl. Sci. 2020, 10(4), 1430</journal-ref><doi>10.3390/app10041430</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the analysis of biological time series, the state space comprises a
framework for the study of systems with presumably deterministic properties.
However, a physiological experiment typically captures an observable, or, in
other words, a series of scalar measurements that characterize the temporal
response of the physiological system under study; the dynamic variables that
make up the state of the system at any time are not available. Therefore, only
from the acquired observations should state vectors reconstructed to emulate
the different states of the underlying system. It is what is known as the
reconstruction of the state space, called phase space in real-world signals,
for now only satisfactorily resolved using the method of delays. Each state
vector consists of m components, extracted from successive observations delayed
a time t. The morphology of the geometric structure described by the state
vectors, as well as their properties, depends on the chosen parameters t and m.
The real dynamics of the system under study is subject to the correct
determination of the parameters t and m. Only in this way can be deduced
characteristics with true physical meaning, revealing aspects that reliably
identify the dynamic complexity of the physiological system. The biological
signal presented in this work, as a case study, is the PhotoPlethysmoGraphic
(PPG) signal. We find that m is five for all the subjects analyzed and that t
depends on the time interval in which it evaluates. The H\'enon map and the
Lorenz flow are used to facilitate a more intuitive understanding of applied
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05411</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05411</id><created>2019-10-11</created><authors><author><keyname>Bianchi</keyname><forenames>Filippo Maria</forenames></author><author><keyname>Grahn</keyname><forenames>Jakob</forenames></author><author><keyname>Eckerstorfer</keyname><forenames>Markus</forenames></author><author><keyname>Malnes</keyname><forenames>Eirik</forenames></author><author><keyname>Vickers</keyname><forenames>Hannah</forenames></author></authors><title>Snow avalanche segmentation in SAR images with Fully Convolutional
  Neural Networks</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge about frequency and location of snow avalanche activity is
essential for forecasting and mapping of snow avalanche hazard. Traditional
field monitoring of avalanche activity has limitations, especially when
surveying large and remote areas. In recent years, avalanche detection in
Sentinel-1 radar satellite imagery has been developed to overcome this
monitoring problem. Current state-of-the-art detection algorithms, based on
radar signal processing techniques, have highly varying accuracy that is on
average much lower than the accuracy of visual detections from human experts.
To reduce this gap, we propose a deep learning architecture for detecting
avalanches in Sentinel-1 radar images. We trained a neural network on 6345
manually labelled avalanches from 117 Sentinel-1 images, each one consisting of
six channels with backscatter and topographical information. Then, we tested
the best network configuration on one additional SAR image. Comparing to the
manual labelling (the gold standard), we achieved an F1 score above 66%, while
the state-of-the-art detection algorithm produced an F1 score of 38%. A visual
interpretation of the network's results shows that it only fails to detect
small avalanches, while it manages to detect some that were not labelled by the
human expert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05425</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05425</id><created>2019-10-11</created><authors><author><keyname>Karimi</keyname><forenames>Mostafa</forenames></author><author><keyname>Veni</keyname><forenames>Gopalkrishna</forenames></author><author><keyname>Yu</keyname><forenames>Yen-Yun</forenames></author></authors><title>Illegible Text to Readable Text: An Image-to-Image Transformation using
  Conditional Sliced Wasserstein Adversarial Networks</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic text recognition from ancient handwritten record images is an
important problem in the genealogy domain. However, critical challenges such as
varying noise conditions, vanishing texts, and variations in handwriting make
the recognition task difficult. We tackle this problem by developing a
handwritten-to-machine-print conditional Generative Adversarial network
(HW2MP-GAN) model that formulates handwritten recognition as a
text-Image-to-text-Image translation problem where a given image, typically in
an illegible form, is converted into another image, close to its machine-print
form. The proposed model consists of three-components including a generator,
and word-level and character-level discriminators. The model incorporates
Sliced Wasserstein distance (SWD) and U-Net architectures in HW2MP-GAN for
better quality image-to-image transformation. Our experiments reveal that
HW2MP-GAN outperforms state-of-the-art baseline cGAN models by almost 30 in
Frechet Handwritten Distance (FHD), 0.6 on average Levenshtein distance and 39%
in word accuracy for image-to-image translation on IAM database. Further,
HW2MP-GAN improves handwritten recognition word accuracy by 1.3% compared to
baseline handwritten recognition models on the IAM database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05432</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05432</id><created>2019-10-11</created><authors><author><keyname>Han</keyname><forenames>Yu</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Ma</keyname><forenames>Xiaoli</forenames></author></authors><title>Channel Estimation for Extremely Large-Scale Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extremely large-scale massive multiple-input multiple-output (MIMO) has shown
considerable potential in future mobile communications. However, the use of
extremely large aperture arrays has led to near-field and spatial
non-stationary channel conditions, which result in changes to transceiver
design and channel state information that should be acquired. This letter
focuses on the channel estimation problem and describes the non-stationary
channel through mapping between subarrays and scatterers. We propose
subarray-wise and scatterer-wise channel estimation methods to estimate the
near-field non-stationary channel from the view of subarray and scatterer,
respectively. Numerical results demonstrate that subarray-wise method can
derive accurate channel estimation results with low complexity, whereas the
scatterer-wise method can accurately position the scatterers and identify
almost all the mappings between subarrays and scatterers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05443</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05443</id><created>2019-10-11</created><authors><author><keyname>Zhang</keyname><forenames>Weiqi</forenames></author><author><keyname>Roald</keyname><forenames>Line A.</forenames></author><author><keyname>Chien</keyname><forenames>Andrew A.</forenames></author><author><keyname>Birge</keyname><forenames>John R.</forenames></author><author><keyname>Zavala</keyname><forenames>Victor M.</forenames></author></authors><title>Flexibility from Networks of Data Centers: A Market Clearing Formulation
  with Virtual Links</title><categories>eess.SY cs.SY math.OC</categories><comments>7 pages, 4 figures, 2 tables. Submitted to the 21st Power Systems
  Computation Conference (PSCC 2020)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data centers owned and operated by large companies have a high power
consumption and this is expected to increase in the future. However, the
ability to shift computing loads geographically and in time can provide
flexibility to the power grid. We introduce the concept of virtual links to
capture space-time load flexibility provided by geographically-distributed data
centers in market clearing procedures. We show that the virtual link
abstraction fits well into existing market clearing frameworks and can help
analyze and establish market design properties. This is demonstrated using
illustrative case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05444</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05444</id><created>2019-10-11</created><authors><author><keyname>Amjad</keyname><forenames>Osama</forenames></author><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Ikki</keyname><forenames>Salama</forenames></author></authors><title>Energy Efficiency Maximization of Self-Sustained Wireless Body Area
  Sensor Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic health monitoring is one of the major applications of wireless
body area networks (WBANs) that helps with early detection of any abnormal
physiological symptoms. In this paper, we propose and solve an optimization
problem that maximizes the energy efficiency (EE) of WBAN consisting of sensor
nodes (SNs) equipped with energy harvesting capabilities communicating with an
aggregator. We exploit the structure of the optimization problem to provide a
sub-optimal solution at a lower computational complexity and derive the
mathematical expressions of upper and lower bounds of the source rates of the
SN. The simulation results reveal that the optimal allocation of the source
rate to energy critical SNs improves the system performance of WBAN in terms of
energy efficiency during different everyday activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05447</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05447</id><created>2019-10-11</created><authors><author><keyname>Zhang</keyname><forenames>Enda</forenames></author><author><keyname>Gupta</keyname><forenames>Gopal</forenames></author><author><keyname>Greif</keyname><forenames>Charles</forenames></author><author><keyname>Paplinski</keyname><forenames>Andrew</forenames></author></authors><title>An Efficient Modal-based Approach Towards Guzheng Sound Synthesis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Encouraged by recent interest in traditional Chinese instruments this work
proposes a computational sound synthesis model for a traditional Chinese
instrument, the guzheng. Digital waveguide model and modal synthesis are the
most popular physical modelling methods. However, the excitation signal is
usually over-simplified and the design of some digital filters is inadequate
for real-time synthesis. We propose an accurate and efficient approach to
synthesise the string signal of the guzheng. Our proposed model enables
accurate parametric control of the pluck because the parameters are based on
physical model of the instrument. The sound of the guzheng is then computed as
the convolution of the synthesised string signal and the impulse response of
the resonant body. As proof of concept, the 21st string of the guzheng is
synthesised using the proposed model. The sound computed using our model shows
improved accuracy with an acceptable computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05474</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05474</id><created>2019-10-11</created><authors><author><keyname>Boulogeorgos</keyname><forenames>Alexandros-Apostolos A.</forenames></author><author><keyname>Alexiou</keyname><forenames>Angeliki</forenames></author></authors><title>Analytical Performance Evaluation of Beamforming Under Transceivers
  Hardware Imperfections</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 5 figures, IEEE WCNC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide the mathematical framework to evaluate and quantify
the performance of wireless systems, which employ beamforming, in the presence
of hardware imperfections at both the basestation and the user equipment. In
more detail, by taking a macroscopic view of the joint impact of hardware
imperfections, we introduce a general model that accounts for transceiver
impairments in beamforming transmissions. In order to evaluate their impact, we
present novel closed form expressions for the outage probability and upper
bounds for the characterization of the system's capacity. Our analysis reveals
that the level of imperfection can significantly constraint the ergodic
capacity. Therefore, it is important to take them into account when evaluating
and designing beamforming systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05483</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05483</id><created>2019-10-12</created><updated>2020-02-06</updated><authors><author><keyname>Shen</keyname><forenames>Xiaoke</forenames></author><author><keyname>Stamos</keyname><forenames>Ioannis</forenames></author></authors><title>Frustum VoxNet for 3D object detection from RGB-D or Depth images</title><categories>cs.CV eess.IV</categories><comments>page 8, add Acknowledgement. page 10, add Supplementary Material. The
  paper got accepted by 2020 Winter Conference on Applications of Computer
  Vision (WACV '20). The first arxiv version can be found here:
  arXiv:1910.05483</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there have been a plethora of classification and detection systems
from RGB as well as 3D images. In this work, we describe a new 3D object
detection system from an RGB-D or depth-only point cloud. Our system first
detects objects in 2D (either RGB or pseudo-RGB constructed from depth). The
next step is to detect 3D objects within the 3D frustums these 2D detections
define. This is achieved by voxelizing parts of the frustums (since frustums
can be really large), instead of using the whole frustums as done in earlier
work. The main novelty of our system has to do with determining which parts (3D
proposals) of the frustums to voxelize, thus allowing us to provide high
resolution representations around the objects of interest. It also allows our
system to have reduced memory requirements. These 3D proposals are fed to an
efficient ResNet-based 3D Fully Convolutional Network (FCN). Our 3D detection
system is fast and can be integrated into a robotics platform. With respect to
systems that do not perform voxelization (such as PointNet), our methods can
operate without the requirement of subsampling of the datasets. We have also
introduced a pipelining approach that further improves the efficiency of our
system. Results on SUN RGB-D dataset show that our system, which is based on a
small network, can process 20 frames per second with comparable detection
results to the state-of-the-art, achieving a 2 times speedup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05491</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05491</id><created>2019-10-12</created><authors><author><keyname>Pirzadeh</keyname><forenames>Hessam</forenames></author><author><keyname>Seco-Granados</keyname><forenames>Gonzalo</forenames></author><author><keyname>Rao</keyname><forenames>Shilpa</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Spectral Efficiency of One-Bit Sigma-Delta Massive MIMO</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the uplink spectral efficiency of a massive MIMO base station
employing a one-bit Sigma-Delta sampling scheme implemented in the spatial
rather than the temporal domain. Using spatial rather than temporal
oversampling, and feedback of the quantization error between adjacent antennas,
the method shapes the spatial spectrum of the quantization noise away from an
angular sector where the signals of interest are assumed to lie. It is shown
that, while a direct Bussgang analysis of the Sigma-Delta approach is not
suitable, an alternative equivalent linear model can be formulated to
facilitate an analysis of the system performance. The theoretical properties of
the spatial quantization noise power spectrum are derived for the Sigma-Delta
array, as well as an expression for the spectral efficiency of maximum ratio
combining (MRC). Simulations verify the theoretical results and illustrate the
significant performance gains offered by the Sigma-Delta approach for both MRC
and zero-forcing receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05498</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05498</id><created>2019-10-12</created><updated>2020-02-11</updated><authors><author><keyname>Hao</keyname><forenames>Qiangjiang</forenames></author><author><keyname>Zhou</keyname><forenames>Kang</forenames></author><author><keyname>Yang</keyname><forenames>Jianlong</forenames></author><author><keyname>Fang</keyname><forenames>Liyang</forenames></author><author><keyname>Chai</keyname><forenames>Zhengjie</forenames></author><author><keyname>Ma</keyname><forenames>Yuhui</forenames></author><author><keyname>Hu</keyname><forenames>Yan</forenames></author><author><keyname>Gao</keyname><forenames>Shenghua</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author></authors><title>High signal-to-noise ratio reconstruction of low bit-depth optical
  coherence tomography using deep learning</title><categories>eess.IV physics.optics</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reducing the bit-depth is an effective approach to lower the cost of optical
coherence tomography (OCT) systems and increase the transmission efficiency in
data acquisition and telemedicine. However, a low bit-depth will lead to the
degeneration of the detection sensitivity thus reduce the signal-to-noise ratio
(SNR) of OCT images. In this paper, we propose to use deep learning for the
reconstruction of the high SNR OCT images from the low bit-depth acquisition.
Its feasibility was preliminarily evaluated by applying the proposed method to
the quantized $3\sim8$-bit data from native 12-bit interference fringes. We
employed a pixel-to-pixel generative adversarial network architecture in the
low to high bit-depth OCT image transition. Retinal OCT data of a healthy
subject from a homemade spectral-domain OCT system was used in the study.
Extensively qualitative and quantitative results show this deep-learning-based
approach could significantly improve the SNR of the low bit-depth OCT images
especially at the choroidal region. Superior similarity and SNR between the
reconstructed images and the original 12-bit OCT images could be derived when
the bit-depth $\geq 5$. This work demonstrates the proper integration of OCT
and deep learning could benefit the development of healthcare in low-resource
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05529</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05529</id><created>2019-10-12</created><authors><author><keyname>Chen</keyname><forenames>Jiaqi</forenames></author><author><keyname>Guo</keyname><forenames>Ye</forenames></author><author><keyname>Wu</keyname><forenames>Wenchuan</forenames></author></authors><title>An optimal dispatch scheme for DSO and prosumers by implementing
  three-phase distribution locational marginal prices</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since distribution system operator (DSO) cannot directly control prosumers
with controllable resources,this paper proposes an optimal dispatch method of
using three-phase distribution locational marginal prices (DLMPs) as effective
economic signals to incentivize prosumers' behaviors. In the proposed
three-phase DLMP model, DLMPs for both active power and reactive power are
calculated. To alleviate the imbalance, congestions and voltage violations in
active distribution networks (ADNs),the DSO and prosumers should be
coordinated. We develop such a coordinated control scheme for the DSO and
prosumers,in which the DSO generates and broadcasts three-phase DLMPs as price
signals to induce prosumers' behaviors. We prove that given the DLMPs for
active power and reactive power as settlement prices, the optimal dispatch of
the ADN will also maximize the surplus of prosumers. Therefore, the power
output of rational prosumers will match the optimal dispatch,resulting in
better operational conditions of ADNs. Then the three-phase
imbalance,congestions and voltage violations will be well reduced. Numerical
tests demonstrate the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05561</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05561</id><created>2019-10-12</created><updated>2019-10-16</updated><authors><author><keyname>Dees</keyname><forenames>Bruno Scalzo</forenames></author><author><keyname>Stankovic</keyname><forenames>Ljubisa</forenames></author><author><keyname>Constantinides</keyname><forenames>Anthony G.</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>Portfolio Cuts: A Graph-Theoretic Framework to Diversification</title><categories>eess.SP cs.IT math.IT q-fin.PM q-fin.ST</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Investment returns naturally reside on irregular domains, however, standard
multivariate portfolio optimization methods are agnostic to data structure. To
this end, we investigate ways for domain knowledge to be conveniently
incorporated into the analysis, by means of graphs. Next, to relax the
assumption of the completeness of graph topology and to equip the graph model
with practically relevant physical intuition, we introduce the portfolio cut
paradigm. Such a graph-theoretic portfolio partitioning technique is shown to
allow the investor to devise robust and tractable asset allocation schemes, by
virtue of a rigorous graph framework for considering smaller, computationally
feasible, and economically meaningful clusters of assets, based on graph cuts.
In turn, this makes it possible to fully utilize the asset returns covariance
matrix for constructing the portfolio, even without the requirement for its
inversion. The advantages of the proposed framework over traditional methods
are demonstrated through numerical simulations based on real-world price data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05580</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05580</id><created>2019-10-12</created><authors><author><keyname>Leng</keyname><forenames>Jian</forenames></author><author><keyname>Yu</keyname><forenames>Wen-Kai</forenames></author><author><keyname>Wang</keyname><forenames>Shuo-Fei</forenames></author></authors><title>Formation mechanism of correspondence imaging with thermal light</title><categories>physics.optics eess.IV</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correspondence imaging can achieve positive-negative ghost images by just
conditional averaging of partial patterns, without treating bucket intensities
as weights. To explain its imaging mechanism, we develop a probability theory
assuming the targets are of gray-scale and the thermal reference speckles obey
an arbitrary independent and identical distribution. By both simulation and
experiments, we find that the recovered values in each region of the same
original gray value conditionally obey a Gaussian distribution. A
crosspoint-to-standard-deviation ratio is used as the figure of merit to prove
that the patterns with respect to larger bucket values generate a positive
image with a higher quality, vice versa for negative one. This work complements
the theory of ghost imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05597</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05597</id><created>2019-10-12</created><authors><author><keyname>Armanious</keyname><forenames>Karim</forenames></author><author><keyname>Tanwar</keyname><forenames>Aastha</forenames></author><author><keyname>Abdulatif</keyname><forenames>Sherif</forenames></author><author><keyname>K&#xfc;stner</keyname><forenames>Thomas</forenames></author><author><keyname>Gatidis</keyname><forenames>Sergios</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author></authors><title>Unsupervised Adversarial Correction of Rigid MR Motion Artifacts</title><categories>eess.IV cs.CV</categories><comments>Submitted to IEEE ISBI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion is one of the main sources for artifacts in magnetic resonance (MR)
images. It can have significant consequences on the diagnostic quality of the
resultant scans. Previously, supervised adversarial approaches have been
suggested for the correction of MR motion artifacts. However, these approaches
suffer from the limitation of required paired co-registered datasets for
training which are often hard or impossible to acquire. Building upon our
previous work, we introduce a new adversarial framework with a new generator
architecture and loss function for the unsupervised correction of severe rigid
motion artifacts in the brain region. Quantitative and qualitative comparisons
with other supervised and unsupervised translation approaches showcase the
enhanced performance of the introduced framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05599</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05599</id><created>2019-10-12</created><authors><author><keyname>Du</keyname><forenames>Peter</forenames></author><author><keyname>Huang</keyname><forenames>Zhe</forenames></author><author><keyname>Liu</keyname><forenames>Tianqi</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Gao</keyname><forenames>Qichao</forenames></author><author><keyname>Sibai</keyname><forenames>Hussein</forenames></author><author><keyname>Driggs-Campbell</keyname><forenames>Katherine</forenames></author><author><keyname>Mitra</keyname><forenames>Sayan</forenames></author></authors><title>Online monitoring for safe pedestrian-vehicle interactions</title><categories>cs.RO cs.MA eess.SP</categories><comments>15 pages, 5 figures,</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As autonomous systems begin to operate amongst humans, methods for safe
interaction must be investigated. We consider an example of a small autonomous
vehicle in a pedestrian zone that must safely maneuver around people in a
free-form fashion. We investigate two key questions: How can we effectively
integrate pedestrian intent estimation into our autonomous stack. Can we
develop an online monitoring framework to give formal guarantees on the safety
of such human-robot interactions. We present a pedestrian intent estimation
framework that can accurately predict future pedestrian trajectories given
multiple possible goal locations. We integrate this into a reachability-based
online monitoring scheme that formally assesses the safety of these
interactions with nearly real-time performance (approximately 0.3 seconds).
These techniques are integrated on a test vehicle with a complete in-house
autonomous stack, demonstrating effective and safe interaction in real-world
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05603</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05603</id><created>2019-10-12</created><authors><author><keyname>Nguyen</keyname><forenames>Quang Minh</forenames></author><author><keyname>Nguyen</keyname><forenames>Thai Binh</forenames></author><author><keyname>Pham</keyname><forenames>Ngoc Phuong</forenames></author><author><keyname>Nguyen</keyname><forenames>The Loc</forenames></author></authors><title>VAIS ASR: Building a conversational speech recognition system using
  language model combination</title><categories>cs.CL cs.SD eess.AS</categories><comments>3 pages, 1 figures, Vietnamese Language and Speech Processing
  conference)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic Speech Recognition (ASR) systems have been evolving quickly and
reaching human parity in certain cases. The systems usually perform pretty well
on reading style and clean speech, however, most of the available systems
suffer from situation where the speaking style is conversation and in noisy
environments. It is not straight-forward to tackle such problems due to
difficulties in data collection for both speech and text. In this paper, we
attempt to mitigate the problems using language models combination techniques
that allows us to utilize both large amount of writing style text and small
number of conversation text data. Evaluation on the VLSP 2019 ASR challenges
showed that our system achieved 4.85% WER on the VLSP 2018 and 15.09% WER on
the VLSP 2019 data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05613</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05613</id><created>2019-10-12</created><authors><author><keyname>Maeda</keyname><forenames>Tomohiro</forenames></author><author><keyname>Satat</keyname><forenames>Guy</forenames></author><author><keyname>Swedish</keyname><forenames>Tristan</forenames></author><author><keyname>Sinha</keyname><forenames>Lagnojita</forenames></author><author><keyname>Raskar</keyname><forenames>Ramesh</forenames></author></authors><title>Recent Advances in Imaging Around Corners</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seeing around corners, also known as non-line-of-sight (NLOS) imaging is a
computational method to resolve or recover objects hidden around corners.
Recent advances in imaging around corners have gained significant interest.
This paper reviews different types of existing NLOS imaging techniques and
discusses the challenges that need to be addressed, especially for their
applications outside of a constrained laboratory environment. Our goal is to
introduce this topic to broader research communities as well as provide
insights that would lead to further developments in this research area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05626</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05626</id><created>2019-10-12</created><authors><author><keyname>Jung</keyname><forenames>Daniel</forenames></author></authors><title>Isolation and Localization of Unknown Faults Using Neural Network-Based
  Residuals</title><categories>eess.SP cs.LG stat.ML</categories><comments>8 pages, 7 figures, If citing this paper please use: In: Proceedings
  of the Annual Conference of the PHM Society, Scottsdale, Arizona, USA (2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization of unknown faults in industrial systems is a difficult task for
data-driven diagnosis methods. The classification performance of many machine
learning methods relies on the quality of training data. Unknown faults, for
example faults not represented in training data, can be detected using, for
example, anomaly classifiers. However, mapping these unknown faults to an
actual location in the real system is a non-trivial problem. In model-based
diagnosis, physical-based models are used to create residuals that isolate
faults by mapping model equations to faulty system components. Developing
sufficiently accurate physical-based models can be a time-consuming process.
Hybrid modeling methods combining physical-based methods and machine learning
is one solution to design data-driven residuals for fault isolation. In this
work, a set of neural network-based residuals are designed by incorporating
physical insights about the system behavior in the residual model structure.
The residuals are trained using only fault-free data and a simulation case
study shows that they can be used to perform fault isolation and localization
of unknown faults in the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05652</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05652</id><created>2019-10-12</created><authors><author><keyname>Kaba</keyname><forenames>Mustafa D.</forenames></author><author><keyname>Zhao</keyname><forenames>Mengnan</forenames></author><author><keyname>Vidal</keyname><forenames>Rene</forenames></author><author><keyname>Robinson</keyname><forenames>Daniel P.</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Generalized Nullspace Property for Structurally Sparse Signals</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new framework for studying the exact recovery of signals with
structured sparsity patterns, which generalizes the well-known nullspace
property for standard sparse recovery. We show that for each dictionary there
is a maximum sparsity pattern---described by a mathematical object called an
&quot;abstract simplicial complex&quot;---that can be recovered via
$\ell_1$-minimization. We provide two different characterizations of this
maximum sparsity pattern, one based on extreme points and the other based on
vectors of minimal support. In addition, we show how this new framework is
useful in the study of sparse recovery problems when the dictionary takes the
form of a graph incidence matrix or a partial discrete Fourier transform. In
both cases we successfully characterize the collection of all support sets for
which exact recovery via $\ell_1$-minimization is possible. As a by product, we
show that when the dictionary is an incidence matrix, exact recovery can be
certified in polynomial time, although this is known to be NP-hard for general
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05669</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05669</id><created>2019-10-12</created><authors><author><keyname>Chang</keyname><forenames>Dong Eui</forenames></author><author><keyname>Phogat</keyname><forenames>Karmvir Singh</forenames></author><author><keyname>Choi</keyname><forenames>Jongeun</forenames></author></authors><title>Model Predictive Tracking Control for Invariant Systems on Matrix Lie
  Groups via Stable Embedding into Euclidean Spaces</title><categories>math.OC cs.SY eess.SY</categories><doi>10.1109/TAC.2019.2946231</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For controller design for systems on manifolds embedded in Euclidean space,
it is convenient to utilize a theory that requires a single global coordinate
system on the ambient Euclidean space rather than multiple local charts on the
manifold or coordinate-free tools from differential geometry. In this article,
we apply such a theory to design model predictive tracking controllers for
systems whose dynamics evolve on manifolds and illustrate its efficacy with the
fully actuated rigid body attitude control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05672</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05672</id><created>2019-10-12</created><authors><author><keyname>Kamran</keyname><forenames>Sharif Amit</forenames></author><author><keyname>Saha</keyname><forenames>Sourajit</forenames></author><author><keyname>Sabbir</keyname><forenames>Ali Shihab</forenames></author><author><keyname>Tavakkoli</keyname><forenames>Alireza</forenames></author></authors><title>Optic-Net: A Novel Convolutional Neural Network for Diagnosis of Retinal
  Diseases from Optical Tomography Images</title><categories>eess.IV cs.CV</categories><comments>8 pages. Accepted to 18th IEEE International Conference on Machine
  Learning and Applications (ICMLA 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diagnosing different retinal diseases from Spectral Domain Optical Coherence
Tomography (SD-OCT) images is a challenging task. Different automated
approaches such as image processing, machine learning and deep learning
algorithms have been used for early detection and diagnosis of retinal
diseases. Unfortunately, these are prone to error and computational
inefficiency, which requires further intervention from human experts. In this
paper, we propose a novel convolution neural network architecture to
successfully distinguish between different degeneration of retinal layers and
their underlying causes. The proposed novel architecture outperforms other
classification models while addressing the issue of gradient explosion. Our
approach reaches near perfect accuracy of 99.8% and 100% for two separately
available Retinal SD-OCT data-set respectively. Additionally, our architecture
predicts retinal diseases in real time while outperforming human
diagnosticians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05674</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05674</id><created>2019-10-12</created><authors><author><keyname>Beattie</keyname><forenames>Chris A.</forenames></author><author><keyname>Gugercin</keyname><forenames>Serkan</forenames></author><author><keyname>Mehrmann</keyname><forenames>Volker</forenames></author></authors><title>Structure-preserving Interpolatory Model Reduction for Port-Hamiltonian
  Differential-Algebraic Systems</title><categories>math.NA cs.NA cs.SY eess.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine interpolatory model reduction methods that are well-suited for
treating large scale port-Hamiltonian differential-algebraic systems in a way
that is able to preserve and indeed, take advantage of the underlying
structural features of the system. We introduce approaches that incorporate
regularization together with prudent selection of interpolation data. We focus
on linear time-invariant systems and present a systematic treatment of a
variety of model classes that include combinations of index-$1$ and index-$2$
systems, describing in particular how constraints may be represented in the
transfer function and then preserved with interpolatory methods. We propose an
algorithm to generate effective interpolation data and illustrate its
effectiveness via two numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05678</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05678</id><created>2019-10-12</created><authors><author><keyname>Mejia</keyname><forenames>Carlos M. Paniagua</forenames></author></authors><title>An Image Segmentation Model Based on a Variational Formulation</title><categories>math.AP cs.CV eess.IV</categories><comments>16 pages, 11 figures</comments><msc-class>53C44 35K55 49M25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from a variational formulation, we present a model for image
segmentation that employs both region statistics and edge information. This
combination allows for improved flexibility, making the proposed model suitable
to process a wider class of images than purely region-based and edge-based
models. We perform several simulations with real images that attest to the
versatility of the model. We also show another set of experiments on images
with certain pathologies that suggest opportunities for improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05680</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05680</id><created>2019-10-12</created><authors><author><keyname>Huang</keyname><forenames>Chao-Tsung</forenames></author><author><keyname>Ding</keyname><forenames>Yu-Chun</forenames></author><author><keyname>Wang</keyname><forenames>Huan-Ching</forenames></author><author><keyname>Weng</keyname><forenames>Chi-Wen</forenames></author><author><keyname>Lin</keyname><forenames>Kai-Ping</forenames></author><author><keyname>Wang</keyname><forenames>Li-Wei</forenames></author><author><keyname>Chen</keyname><forenames>Li-De</forenames></author></authors><title>eCNN: A Block-Based and Highly-Parallel CNN Accelerator for Edge
  Inference</title><categories>cs.DC cs.CV cs.LG eess.IV</categories><comments>14 pages; appearing in IEEE/ACM International Symposium on
  Microarchitecture (MICRO), 2019</comments><doi>10.1145/3352460.3358263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNNs) have recently demonstrated superior
quality for computational imaging applications. Therefore, they have great
potential to revolutionize the image pipelines on cameras and displays.
However, it is difficult for conventional CNN accelerators to support
ultra-high-resolution videos at the edge due to their considerable DRAM
bandwidth and power consumption. Therefore, finding a further memory- and
computation-efficient microarchitecture is crucial to speed up this coming
revolution.
  In this paper, we approach this goal by considering the inference flow,
network model, instruction set, and processor design jointly to optimize
hardware performance and image quality. We apply a block-based inference flow
which can eliminate all the DRAM bandwidth for feature maps and accordingly
propose a hardware-oriented network model, ERNet, to optimize image quality
based on hardware constraints. Then we devise a coarse-grained instruction set
architecture, FBISA, to support power-hungry convolution by massive
parallelism. Finally,we implement an embedded processor---eCNN---which
accommodates to ERNet and FBISA with a flexible processing architecture. Layout
results show that it can support high-quality ERNets for super-resolution and
denoising at up to 4K Ultra-HD 30 fps while using only DDR-400 and consuming
6.94W on average. By comparison, the state-of-the-art Diffy uses dual-channel
DDR3-2133 and consumes 54.3W to support lower-quality VDSR at Full HD 30 fps.
Lastly, we will also present application examples of high-performance style
transfer and object recognition to demonstrate the flexibility of eCNN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05693</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05693</id><created>2019-10-13</created><updated>2020-01-21</updated><authors><author><keyname>Haarburger</keyname><forenames>Christoph</forenames></author><author><keyname>Schock</keyname><forenames>Justus</forenames></author><author><keyname>Truhn</keyname><forenames>Daniel</forenames></author><author><keyname>Weitz</keyname><forenames>Philippe</forenames></author><author><keyname>Mueller-Franzes</keyname><forenames>Gustav</forenames></author><author><keyname>Weninger</keyname><forenames>Leon</forenames></author><author><keyname>Merhof</keyname><forenames>Dorit</forenames></author></authors><title>Radiomic Feature Stability Analysis based on Probabilistic Segmentations</title><categories>eess.IV cs.CV</categories><comments>accepted at ISBI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying image features that are robust with respect to segmentation
variability and domain shift is a tough challenge in radiomics. So far, this
problem has mainly been tackled in test-retest analyses. In this work we
analyze radiomics feature stability based on probabilistic segmentations. Based
on a public lung cancer dataset, we generate an arbitrary number of plausible
segmentations using a Probabilistic U-Net. From these segmentations, we extract
a high number of plausible feature vectors for each lung tumor and analyze
feature variance with respect to the segmentations. Our results suggest that
there are groups of radiomic features that are more (e.g. statistics features)
and less (e.g. gray-level size zone matrix features) robust against
segmentation variability. Finally, we demonstrate that segmentation variance
impacts the performance of a prognostic lung cancer survival model and propose
a new and potentially more robust radiomics feature selection workflow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05704</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05704</id><created>2019-10-13</created><authors><author><keyname>Wang</keyname><forenames>Zhenzhou</forenames></author></authors><title>Slope Difference Distribution and Its Computer Vision Applications</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slope difference distribution (SDD) is computed from the one-dimensional
curve and makes it possible to find derivatives that do not exist in the
original curve. It is not only robust to calculate the threshold point to
separate the curve logically, but also robust to calculate the center of each
part of the separated curve. SDD has been used in image segmentation and it
outperforms all classical and state of the art image segmentation methods. SDD
is also very useful in calculating the features for pattern recognition and
object detection. For the gesture recognition, SDD achieved 100% accuracy for
two public datasets: the NUS dataset and the near-infrared dataset. For the
object recognition, SDD achieved 100% accuracy for the Kimia 99 dataset. In
this memorandum, I will demonstrate the effectiveness of SDD with some typical
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05751</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05751</id><created>2019-10-13</created><updated>2019-10-18</updated><authors><author><keyname>Zhang</keyname><forenames>Wenhua</forenames></author><author><keyname>Jiao</keyname><forenames>Licheng</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author></authors><title>Hierarchical Feature-Aware Tracking</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we propose a hierarchical feature-aware tracking framework for
efficient visual tracking. Recent years, ensembled trackers which combine
multiple component trackers have achieved impressive performance. In ensembled
trackers, the decision of results is usually a post-event process, i.e.,
tracking result for each tracker is first obtained and then the suitable one is
selected according to result ensemble. In this paper, we propose a pre-event
method. We construct an expert pool with each expert being one set of features.
For each frame, several experts are first selected in the pool according to
their past performance and then they are used to predict the object. The
selection rate of each expert in the pool is then updated and tracking result
is obtained according to result ensemble. We propose a novel pre-known
expert-adaptive selection strategy. Since the process is more efficient, more
experts can be constructed by fusing more types of features which leads to more
robustness. Moreover, with the novel expert selection strategy, overfitting
caused by fixed experts for each frame can be mitigated. Experiments on several
public available datasets demonstrate the superiority of the proposed method
and its state-of-the-art performance among ensembled trackers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05765</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05765</id><created>2019-10-13</created><authors><author><keyname>Soltani</keyname><forenames>Sohraab</forenames></author><author><keyname>Sagduyu</keyname><forenames>Yalin E.</forenames></author><author><keyname>Hasan</keyname><forenames>Raqibul</forenames></author><author><keyname>Davaslioglu</keyname><forenames>Kemal</forenames></author><author><keyname>Deng</keyname><forenames>Hongmei</forenames></author><author><keyname>Erpek</keyname><forenames>Tugba</forenames></author></authors><title>Real-Time and Embedded Deep Learning on FPGA for RF Signal
  Classification</title><categories>cs.NI cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We designed and implemented a deep learning based RF signal classifier on the
Field Programmable Gate Array (FPGA) of an embedded software-defined radio
platform, DeepRadio, that classifies the signals received through the RF front
end to different modulation types in real time and with low power. This
classifier implementation successfully captures complex characteristics of
wireless signals to serve critical applications in wireless security and
communications systems such as identifying spoofing signals in signal
authentication systems, detecting target emitters and jammers in electronic
warfare (EW) applications, discriminating primary and secondary users in
cognitive radio networks, interference hunting, and adaptive modulation.
Empowered by low-power and low-latency embedded computing, the deep neural
network runs directly on the FPGA fabric of DeepRadio, while maintaining
classifier accuracy close to the software performance. We evaluated the
performance when another SDR (USRP) transmits signals with different modulation
types at different power levels and DeepRadio receives the signals and
classifies them in real time on its FPGA. A smartphone with a mobile app is
connected to DeepRadio to initiate the experiment and visualize the
classification results. With real radio transmissions over the air, we show
that the classifier implemented on DeepRadio achieves high accuracy with low
latency (microsecond per sample) and low energy consumption (microJoule per
sample), and this performance is not matched by other embedded platforms such
as embedded graphics processing unit (GPU).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05774</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05774</id><created>2019-10-13</created><updated>2019-12-13</updated><authors><author><keyname>Carlsson</keyname><forenames>Hanne</forenames></author><author><keyname>Kollias</keyname><forenames>Dimitrios</forenames></author></authors><title>Image Generation and Recognition (Emotions)</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative Adversarial Networks (GANs) were proposed in 2014 by Goodfellow et
al., and have since been extended into multiple computer vision applications.
This report provides a thorough survey of recent GAN research, outlining the
various architectures and applications, as well as methods for training GANs
and dealing with latent space. This is followed by a discussion of potential
areas for future GAN research, including: evaluating GANs, better understanding
GANs, and techniques for training GANs. The second part of this report outlines
the compilation of a dataset of images `in the wild' representing each of the 7
basic human emotions, and analyses experiments done when training a StarGAN on
this dataset combined with the FER2013 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05787</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05787</id><created>2019-10-13</created><updated>2020-01-30</updated><authors><author><keyname>Huang</keyname><forenames>Chao-Tsung</forenames></author></authors><title>ERNet Family: Hardware-Oriented CNN Models for Computational Imaging
  Using Block-Based Inference</title><categories>cs.LG eess.IV stat.ML</categories><comments>5 pages; appearing in IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNNs) demand huge DRAM bandwidth for
computational imaging tasks, and block-based processing has recently been
applied to greatly reduce the bandwidth. However, the induced additional
computation for feature recomputing or the large SRAM for feature reusing will
degrade the performance or even forbid the usage of state-of-the-art models. In
this paper, we address these issues by considering the overheads and hardware
constraints in advance when constructing CNNs. We investigate a novel model
family---ERNet---which includes temporary layer expansion as another means for
increasing model capacity. We analyze three ERNet variants in terms of hardware
requirement and introduce a hardware-aware model optimization procedure.
Evaluations on Full HD and 4K UHD applications will be given to show the
effectiveness in terms of image quality, pixel throughput, and SRAM usage. The
results also show that, for block-based inference, ERNet can outperform the
state-of-the-art FFDNet and EDSR-baseline models for image denoising and
super-resolution respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05795</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05795</id><created>2019-10-13</created><authors><author><keyname>Bendjador</keyname><forenames>Hanna</forenames></author><author><keyname>Deffieux</keyname><forenames>Thomas</forenames></author><author><keyname>Tanter</keyname><forenames>Micka&#xeb;l</forenames></author></authors><title>The SVD Beamformer: Physical Principles and Application to Ultrafast
  Adaptive Ultrasound</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A shift of paradigm is currently underway in biomedical ultrasound thanks to
plane and diverging waves for ultrafast imaging. One remaining challenge
consists in the correction of phase and amplitude aberrations induced during
propagation through complex layers. Unlike conventional line-per-line imaging,
ultrafast ultrasound provides for each transmission, backscattering information
from the whole imaged area. Here, we take benefit from this feature and propose
an efficient approach to perform fast aberration correction based on the
Singular Value Decomposition of an ultrafast compound matrix built from
backscattered data for several plane wave transmissions. First, we explain the
physical signification of SVD and associated singular vectors within the
ultrafast matrix formalism. We theoretically demonstrate that the spatial and
angular variables separation, rendered by SVD on ultrafast data, provides an
elegant and straightforward way to optimize angular coherence of backscattered
data. In heterogeneous media with an aberrating phase screen approximation, we
demonstrate that the first spatial and angular singular vectors retrieve on one
side the non-aberrated image, and on the other, the phase and amplitude of the
aberration law. In vitro results prove the efficiency of the image correction,
but also the accuracy of the aberrator determination. Based on spatial and
angular coherence, we introduce a complete methodology for adaptive beamforming
of ultrafast data, performed on successive isoplanatism patches undergoing SVD
beamforming. The simplicity of this method paves the way to real-time adaptive
ultrafast ultrasound imaging and provides a theoretical framework for future
quantitative ultrasound applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05801</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05801</id><created>2019-10-13</created><updated>2019-10-15</updated><authors><author><keyname>Zuo</keyname><forenames>Yihui</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author><author><keyname>Sossan</keyname><forenames>Fabrizio.</forenames></author></authors><title>Effect of Voltage Source Converters with Electrochemical Storage Systems
  on Dynamics of Reduced-inertia Bulk Power Grids</title><categories>eess.SY cs.SY</categories><comments>9 pages, 11 figures, submitted to Power System Computation Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major concern associated to the massive connection of distributed energy
resources is the increasing share of power electronic interfaces resulting in
the global inertia reduction of power systems. The recent literature advocated
the use of voltage source converter (VSC) interfaced battery energy storage
system (BESS) as a potential way to counterbalance this lack of inertia.
However, the impact of VSCs on the dynamics of reduced-inertia grids is not
well understood especially with respect to large transmission grids interfacing
a mix of rotating machines and resources interfaced with power electronics. In
this regards, we propose an extension of the IEEE 39-bus test network used to
quantify the impact of VSCs on reduced-inertia grids. In this respect, a
reduced-inertia 39-bus system is obtained by replacing 4 synchronous generators
in the original 10-synchronous machine system, with 4 wind power plants modeled
as aggregated type-3 wind turbines. Then, a large-scale BESS is integrated into
the reduced-inertia network via a three-level neutral-point clamped (NPC)
converter, thereby to be used for studying the impact of VSC on the dynamics of
the inertia-reduced power system, as well as for comparing different VSC
controls. The proposed models are implemented on a real-time simulator to
conduct post-contingency analysis, respectively, for the original power system
and the reduced-inertia one, with and without the BESS-VSC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05815</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05815</id><created>2019-10-13</created><authors><author><keyname>Kalayci</keyname><forenames>Ali O.</forenames></author><author><keyname>Guvensen</keyname><forenames>Gokhan M.</forenames></author></authors><title>An Efficient Beam and Channel Acquisition via Sparsity Map and Joint
  Angle-Delay Power Profile Estimation for Wideband Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>32 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an efficient beam and channel acquisition scheme together with
joint angle-delay power profile (JADPP) construction are proposed for
single-carrier mm-wave wideband sparse massive multiple-input multiple-output
(MIMO) channels when hybrid beamforming architecture is utilized. We consider
two different modes of operation, namely slow-time beam acquisition and
fast-time instantaneous channel estimation, for training stage of time division
duplex based systems. In the first mode, where pre-structured hybrid beams are
formed to scan intended angular sectors, the joint angle-delay sparsity map
together with power intensities of each user channels are obtained by using a
novel constant false alarm rate thresholding algorithm inspired from adaptive
radar detection theory. The proposed thresholding algorithm employs a
spatio-temporal adaptive matched filter type estimator, taking the strong
interference due to simultaneously active multipath components of different
user channels into account, in order to estimate JADPP of each user. After
applying the proposed thresholding algorithm on the estimated power profile,
the angle-delay sparsity map of the massive MIMO channel is constructed, based
on which the channel covariance matrices (CCMs) are formed with significantly
reduced amount of training snapshots. Then, by using the estimated CCMs, the
analog beamformer is reconstructed by means of a virtual sectorization while
taking the inter-group and inter-symbol interference into account. Finally, for
the second mode of operation, two novel reduced-rank instantaneous channel
estimators, operating in a proper beamspace formed by the hybrid structure, are
proposed. The proposed beam and channel acquisition techniques attain the
channel estimation accuracy of minimum mean square error filter with true
knowledge of CCMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05827</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05827</id><created>2019-10-13</created><authors><author><keyname>Wei</keyname><forenames>Jerry</forenames></author><author><keyname>Suriawinata</keyname><forenames>Arief</forenames></author><author><keyname>Vaickus</keyname><forenames>Louis</forenames></author><author><keyname>Ren</keyname><forenames>Bing</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoying</forenames></author><author><keyname>Wei</keyname><forenames>Jason</forenames></author><author><keyname>Hassanpour</keyname><forenames>Saeed</forenames></author></authors><title>Generative Image Translation for Data Augmentation in Colorectal
  Histopathology Images</title><categories>eess.IV cs.CV</categories><comments>NeurIPS 2019 Machine Learning for Health Workshop Full Paper (19/111
  accepted papers = 17% acceptance rate)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an image translation approach to generate augmented data for
mitigating data imbalances in a dataset of histopathology images of colorectal
polyps, adenomatous tumors that can lead to colorectal cancer if left
untreated. By applying cycle-consistent generative adversarial networks
(CycleGANs) to a source domain of normal colonic mucosa images, we generate
synthetic colorectal polyp images that belong to diagnostically less common
polyp classes. Generated images maintain the general structure of their source
image but exhibit adenomatous features that can be enhanced with our proposed
filtration module, called Path-Rank-Filter. We evaluate the quality of
generated images through Turing tests with four gastrointestinal pathologists,
finding that at least two of the four pathologists could not identify generated
images at a statistically significant level. Finally, we demonstrate that using
CycleGAN-generated images to augment training data improves the AUC of a
convolutional neural network for detecting sessile serrated adenomas by over
10%, suggesting that our approach might warrant further research for other
histopathology image classification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05857</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05857</id><created>2019-10-13</created><authors><author><keyname>Sun</keyname><forenames>Haoran</forenames></author><author><keyname>Lu</keyname><forenames>Songtao</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author></authors><title>Improving the Sample and Communication Complexity for Decentralized
  Non-Convex Optimization: A Joint Gradient Estimation and Tracking Approach</title><categories>math.OC cs.DC cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many modern large-scale machine learning problems benefit from decentralized
and stochastic optimization. Recent works have shown that utilizing both
decentralized computing and local stochastic gradient estimates can outperform
state-of-the-art centralized algorithms, in applications involving highly
non-convex problems, such as training deep neural networks.
  In this work, we propose a decentralized stochastic algorithm to deal with
certain smooth non-convex problems where there are $m$ nodes in the system, and
each node has a large number of samples (denoted as $n$). Differently from the
majority of the existing decentralized learning algorithms for either
stochastic or finite-sum problems, our focus is given to both reducing the
total communication rounds among the nodes, while accessing the minimum number
of local data samples. In particular, we propose an algorithm named D-GET
(decentralized gradient estimation and tracking), which jointly performs
decentralized gradient estimation (which estimates the local gradient using a
subset of local samples) and gradient tracking (which tracks the global full
gradient using local estimates). We show that, to achieve certain $\epsilon$
stationary solution of the deterministic finite sum problem, the proposed
algorithm achieves an $\mathcal{O}(mn^{1/2}\epsilon^{-1})$ sample complexity
and an $\mathcal{O}(\epsilon^{-1})$ communication complexity. These bounds
significantly improve upon the best existing bounds of
$\mathcal{O}(mn\epsilon^{-1})$ and $\mathcal{O}(\epsilon^{-1})$, respectively.
Similarly, for online problems, the proposed method achieves an $\mathcal{O}(m
\epsilon^{-3/2})$ sample complexity and an $\mathcal{O}(\epsilon^{-1})$
communication complexity, while the best existing bounds are
$\mathcal{O}(m\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-2})$, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05859</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05859</id><created>2019-10-13</created><authors><author><keyname>Cai</keyname><forenames>HanQin</forenames></author><author><keyname>Cai</keyname><forenames>Jian-Feng</forenames></author><author><keyname>Wang</keyname><forenames>Tianming</forenames></author><author><keyname>Yin</keyname><forenames>Guojian</forenames></author></authors><title>Fast and Robust Spectrally Sparse Signal Recovery: A Provable Non-Convex
  Approach via Robust Low-Rank Hankel Matrix Reconstruction</title><categories>cs.IT cs.LG eess.SP math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a spectrally sparse signal $\boldsymbol{x}$ that consists of $r$
complex sinusoids with or without damping. We study the robust recovery problem
for the spectrally sparse signal under the fully observed setting, which is
about recovering $\boldsymbol{x}$ and a sparse corruption vector
$\boldsymbol{s}$ from their sum $\boldsymbol{z}=\boldsymbol{x}+\boldsymbol{s}$.
In this paper, we exploit the low-rank property of the Hankel matrix
constructed from $\boldsymbol{x}$, and develop an efficient non-convex
algorithm, coined Accelerated Alternating Projections for Robust Low-Rank
Hankel Matrix Reconstruction (AAP-Hankel). The high computational efficiency
and low space complexity of AAP-Hankel are achieved by fast computations
involving structured matrices, and a subspace projection method for accelerated
low-rank approximation. Theoretical recovery guarantee with a linear
convergence rate has been established for AAP-Hankel. Empirical performance
comparisons on synthetic and real-world datasets demonstrate the computational
advantages of AAP-Hankel, in both efficiency and robustness aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05907</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05907</id><created>2019-10-13</created><authors><author><keyname>Li</keyname><forenames>Changfu</forenames></author><author><keyname>Jin</keyname><forenames>Chenrui</forenames></author><author><keyname>Sharma</keyname><forenames>Ratnesh</forenames></author></authors><title>Coordination of PV Smart Inverters Using Deep Reinforcement Learning for
  Grid Voltage Regulation</title><categories>eess.SY cs.LG cs.SY</categories><comments>18th IEEE International Conference on Machine Learning and
  Applications - ICMLA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing adoption of solar photovoltaic (PV) presents new challenges to
modern power grid due to its variable and intermittent nature. Fluctuating
outputs from PV generation can cause the grid violating voltage operation
limits. PV smart inverters (SIs) provide a fast-response method to regulate
voltage by modulating real and/or reactive power at the connection point. Yet
existing local autonomous control scheme of SIs is based on local information
without coordination, which can lead to suboptimal performance. In this paper,
a deep reinforcement learning (DRL) based algorithm is developed and
implemented for coordinating multiple SIs. The reward scheme of the DRL is
carefully designed to ensure voltage operation limits of the grid are met with
more effective utilization of SI reactive power. The proposed DRL agent for
voltage control can learn its policy through interaction with massive offline
simulations, and adapts to load and solar variations. The performance of the
DRL agent is compared against the local autonomous control on the IEEE 37 node
system with thousands of scenarios. The results show a properly trained DRL
agent can intelligently coordinate different SIs for maintaining grid voltage
within allowable ranges, achieving reduction of PV production curtailment, and
decreasing system losses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05911</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05911</id><created>2019-10-14</created><authors><author><keyname>McCouat</keyname><forenames>James</forenames></author><author><keyname>Glocker</keyname><forenames>Ben</forenames></author></authors><title>Vertebrae Detection and Localization in CT with Two-Stage CNNs and Dense
  Annotations</title><categories>eess.IV cs.CV</categories><comments>Accept into the MICCAI workshop MSKI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new, two-stage approach to the vertebrae centroid detection and
localization problem. The first stage detects where the vertebrae appear in the
scan using 3D samples, the second identifies the specific vertebrae within that
region-of-interest using 2D slices. Our solution utilizes new techniques to
improve the accuracy of the algorithm such as a revised approach to dense
labelling from sparse centroid annotations and usage of large anisotropic
kernels in the base level of a U-net architecture to maximize the receptive
field. Our method improves the state-of-the-art's mean localization accuracy by
0.87mm on a publicly available spine CT benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05920</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05920</id><created>2019-10-14</created><authors><author><keyname>Lammie</keyname><forenames>Corey</forenames></author><author><keyname>Krestinskaya</keyname><forenames>Olga</forenames></author><author><keyname>James</keyname><forenames>Alex</forenames></author><author><keyname>Azghadi</keyname><forenames>Mostafa Rahimi</forenames></author></authors><title>Variation-aware Binarized Memristive Networks</title><categories>cs.ET cs.NE eess.SP</categories><comments>4 pages, 3 figures, 3 tables</comments><journal-ref>2019 IEEE 26th International Conference on Electronics Circuits
  and Systems (ICECS)</journal-ref><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The quantization of weights to binary states in Deep Neural Networks (DNNs)
can replace resource-hungry multiply accumulate operations with simple
accumulations. Such Binarized Neural Networks (BNNs) exhibit greatly reduced
resource and power requirements. In addition, memristors have been shown as
promising synaptic weight elements in DNNs. In this paper, we propose and
simulate novel Binarized Memristive Convolutional Neural Network (BMCNN)
architectures employing hybrid weight and parameter representations. We train
the proposed architectures offline and then map the trained parameters to our
binarized memristive devices for inference. To take into account the variations
in memristive devices, and to study their effect on the performance, we
introduce variations in $R_{ON}$ and $R_{OFF}$. Moreover, we introduce means to
mitigate the adverse effect of memristive variations in our proposed networks.
Finally, we benchmark our BMCNNs and variation-aware BMCNNs using the MNIST
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05935</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05935</id><created>2019-10-14</created><authors><author><keyname>Rau</keyname><forenames>Richard</forenames></author><author><keyname>Schweizer</keyname><forenames>Dieter</forenames></author><author><keyname>Vishnevskiy</keyname><forenames>Valery</forenames></author><author><keyname>Goksel</keyname><forenames>Orcun</forenames></author></authors><title>Speed-of-Sound Imaging using Diverging Waves</title><categories>physics.med-ph eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent ultrasound imaging modalities based on ultrasound computed tomography
indicate a huge potential to detect pathologies is tissue due to altered
biomechanical properties. Especially the imaging of speed-of-sound (SoS)
distribution in tissue has shown clinical promise and thus gained increasing
attention in the field -- with several methods proposed based on transmission
mode tomography. SoS imaging using conventional ultrasound (US) systems would
be convenient and easy for clinical translation, but this requires using
conventional US probes with single-sides tissue access and thus pulse-echo
imaging sequences. Recent pulse-echo SoS imaging methods rely on plane wave
(PW) insonifications, which is prone to strong aberration effects for
non-homogeneous tissue composition. In this paper we propose to use diverging
waves (DW) for SoS imaging and thus substantially improve the reconstruction of
SoS distributions. We study this proposition by first plane wavefront
aberrations compared to DW. We then present the sensitivity of both approaches
to major parameterization choices on a set of simulated phantoms. Using the
optimum parameter combination for each method for a given transducer model and
imaging sequence, we analyze the SoS imaging performance comparatively between
the two approaches. Results indicate that using DW instead of PW, the
reconstruction accuracy improves substantially, by over 22% in reconstruction
error (RMSE) and by 55% in contrast (CNR). We also demonstrate improvements in
SoS reconstructions from an actual US acquisition of a breast phantom with
tumor- and cyst-representative inclusions, with high and low SoS contrast,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05944</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05944</id><created>2019-10-14</created><authors><author><keyname>Bellinguer</keyname><forenames>Kevin</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Girard</keyname><forenames>Robin</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Bontron</keyname><forenames>Guillaume</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Kariniotakis</keyname><forenames>Georges</forenames><affiliation>PERSEE</affiliation></author></authors><title>Short-term photovoltaic generation forecasting using multiple
  heterogenous sources of data</title><categories>stat.AP eess.SP</categories><proxy>ccsd</proxy><journal-ref>36th European PV Solar Energy Conference and Exhibition (EU
  PVSEC), WIP Renewable Energies, Sep 2019, Marseille, France</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Renewable Energies (RES) penetration is progressing rapidly: in France, the
installed capacity of photovoltaic (PV) power rose from 26MW in 2007 to 8GW in
2017 [1]. Power generated by PV plants being highly dependent on variable
weather conditions, this ever-growing pace is raising issues regarding grid
stability and revenue optimization. To overcome these obstacles, PV forecasting
became an area of intense research. In this paper, we propose a low complexity
forecasting model able to operate with multiple heterogenous sources of data
(power measurements, satellite images and Numerical Weather Predictions (NWP)).
Being non-parametric, this model can be extended to include inputs. The main
strength of the proposed model lies in its ability to automatically select the
optimal sources of data according to the desired forecast horizon (from 15min
to 6h ahead) thanks to a feature selection procedure. To take advantage of the
growing number of PV plants, a Spatio-Temporal (ST) approach is implemented.
This approach considers the dependencies between spatially distributed plants.
Each source has been studied incrementally so as to quantify their impact on
forecast performances. This plurality of sources enhances the forecasting
performances up to 40% in terms of RMSE compared to a reference model. The
evaluation process is carried out on nine PV plants from the Compagnie
Nationale du Rh{\^o}ne (CNR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05967</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05967</id><created>2019-10-14</created><authors><author><keyname>Yuan</keyname><forenames>Hang</forenames></author><author><keyname>Yang</keyname><forenames>Nan</forenames></author><author><keyname>Yang</keyname><forenames>Kai</forenames></author><author><keyname>Han</keyname><forenames>Chong</forenames></author><author><keyname>An</keyname><forenames>Jianping</forenames></author></authors><title>Hybrid Beamforming for Terahertz MIMO-OFDM Systems Over Frequency
  Selective Fading</title><categories>eess.SP</categories><comments>30 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose novel hybrid beamforming schemes for the terahertz (THz) wireless
system where a multi-antenna base station (BS) communicates with a
multi-antenna user over frequency selective channels. Here, we assume that the
BS employs sub-connected hybrid beamforming, due to its low complexity, and
orthogonal frequency-division multiplexing (OFDM) to deliver ultra high data
rate. First, we build a three-dimensional wideband THz channel model by
incorporating the joint effect of molecular absorption, high reflection loss,
and multipath fading, and consider the carrier frequency offset in OFDM. With
this model, we propose a two-stage hybrid beamforming scheme which includes a
normalized beamsteering codebook searching algorithm for analog beamforming and
a regularized channel inversion method for digital beamforming. We then propose
a novel wideband hybrid beamforming scheme with two digital beamformers. In
this scheme, an additional digital beamformer is developed to compensate for
the performance loss caused by the difference among subcarriers and hardware
constraints. Furthermore, we consider imperfect channel state information (CSI)
and propose a probabilistic robust hybrid beamforming scheme to combat channel
estimation errors. Numerical results demonstrate the benefits of our proposed
schemes for the sake of practical implementation, especially considering its
high spectral efficiency, low complexity, and robustness against imperfect CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05972</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.05972</id><created>2019-10-14</created><authors><author><keyname>Kheradmand</keyname><forenames>Shakiba</forenames></author><author><keyname>Saeedi</keyname><forenames>Parvaneh</forenames></author><author><keyname>Au</keyname><forenames>Jason</forenames></author><author><keyname>Havelock</keyname><forenames>John</forenames></author></authors><title>Preimplantation Blastomere Boundary Identification in HMC Microscopic
  Images of Early Stage Human Embryos</title><categories>cs.CV eess.IV q-bio.QM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method for identification of the boundary of embryonic
cells (blastomeres) in Hoffman Modulation Contrast (HMC) microscopic images
that are taken between day one to day three. Identification of boundaries of
blastomeres is a challenging task, especially in the cases containing four or
more cells. This is because these cells are bundled up tightly inside an
embryo's membrane and any 2D image projection of such 3D embryo includes cell
overlaps, occlusions, and projection ambiguities. Moreover, human embryos
include fragmentation, which does not conform to any specific patterns or
shape. Here we developed a model-based iterative approach, in which blastomeres
are modeled as ellipses that conform to the local image features, such as edges
and normals. In an iterative process, each image feature contributes only to
one candidate and is removed upon being associated to a model candidate. We
have tested the proposed algorithm on an image dataset comprising of 468 human
embryos obtained from different sources. An overall Precision, Sensitivity and
Overall Quality (OQ) of 92%, 88% and 83% are achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06017</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06017</id><created>2019-10-14</created><authors><author><keyname>Fassold</keyname><forenames>Hannes</forenames></author><author><keyname>Ghermi</keyname><forenames>Ridouane</forenames></author></authors><title>OmniTrack: Real-time detection and tracking of objects, text and logos
  in video</title><categories>cs.CV eess.IV</categories><comments>accepted for IEEE ISM Conference, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automatic detection and tracking of general objects (like persons,
animals or cars), text and logos in a video is crucial for many video
understanding tasks, and usually real-time processing as required. We propose
OmniTrack, an efficient and robust algorithm which is able to automatically
detect and track objects, text as well as brand logos in real-time. It combines
a powerful deep learning based object detector (YoloV3) with high-quality
optical flow methods. Based on the reference YoloV3 C++ implementation, we did
some important performance optimizations which will be described. The major
steps in the training procedure for the combined detector for text and logo
will be presented. We will describe then the OmniTrack algorithm, consisting of
the phases preprocessing, feature calculation, prediction, matching and update.
Several performance optimizations have been implemented there as well, like
doing the object detection and optical flow calculation asynchronously.
Experiments show that the proposed algorithm runs in real-time for standard
definition ($720x576$) video on a PC with a Quadro RTX 5000 GPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06041</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06041</id><created>2019-10-14</created><authors><author><keyname>Gurumurthy</keyname><forenames>Vikas Agaradahalli</forenames></author></authors><title>Encoder-Decoder based CNN and Fully Connected CRFs for Remote Sensed
  Image Segmentation</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advancement of remote-sensed imaging large volumes of very high
resolution land cover images can now be obtained. Automation of object
recognition in these 2D images, however, is still a key issue. High intra-class
variance and low inter-class variance in Very High Resolution (VHR) images
hamper the accuracy of prediction in object recognition tasks. Most successful
techniques in various computer vision tasks recently are based on deep
supervised learning. In this work, a deep Convolutional Neural Network (CNN)
based on symmetric encoder-decoder architecture with skip connections is
employed for the 2D semantic segmentation of most common land cover object
classes - impervious surface, buildings, low vegetation, trees and cars. Atrous
convolutions are employed to have large receptive field in the proposed CNN
model. Further, the CNN outputs are post-processed using Fully Connected
Conditional Random Field (FCRF) model to refine the CNN pixel label
predictions. The proposed CNN-FCRF model achieves an overall accuracy of 90.5%
on the ISPRS Vaihingen Dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06047</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06047</id><created>2019-10-14</created><authors><author><keyname>Zhang</keyname><forenames>Xizhe</forenames></author><author><keyname>Zhu</keyname><forenames>Yuyan</forenames></author><author><keyname>Zhao</keyname><forenames>Yongkang</forenames></author></authors><title>Altering nodes types in controlling complex networks</title><categories>eess.SY cs.SI cs.SY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controlling a complex network towards a desired state is of great importance
in many applications. A network can be controlled by inputting suitable
external signals into some selected nodes, which are called driver nodes.
Previous works found there exist two control modes in dense networks:
distributed and centralized modes. For networks with the distributed mode, most
of the nodes can be act as driver nodes; and those with the centralized mode,
most of the nodes never be the driver nodes. Here we present an efficient
algorithm to change the control type of nodes, from input nodes to redundant
nodes, which is done by reversing edges of the network. We conclude four
possible cases when reversing an edge and show the control mode can be changed
by reversing very few in-edges of driver nodes. We evaluate the performance of
our algorithm on both synthetic and real networks. The experimental results
show that the control mode of a network can be easily changed by reversing a
few elaborately selected edges, and the number of possible driver nodes is
dramatically decreased. Our methods provide the ability to design the desired
control modes of the network for different control scenarios, which may be used
in many application regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06052</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06052</id><created>2019-10-14</created><authors><author><keyname>Zhang</keyname><forenames>Xizhe</forenames></author><author><keyname>Li</keyname><forenames>Qian</forenames></author></authors><title>Altering control modes of complex networks based on edge removal</title><categories>cs.SI cs.SY eess.SY physics.soc-ph</categories><journal-ref>Physica A: Statistical Mechanics and its Applications 516 (2019):
  185-193</journal-ref><doi>10.1016/j.physa.2018.09.146</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controlling a complex network is of great importance in many applications.
The network can be controlled by inputting external control signals through
some selected nodes, which are called input nodes. Previous works found that
the majority of the nodes in dense networks are either the input nodes or not,
which leads to the bimodality in controlling the complex networks. Due to the
physical or economic constraints of many real control scenarios, altering the
control mode of a network may be critical to many applications. Here we develop
a graph-based algorithm to alter the control mode of a network. The main idea
is to change the control connectivity of nodes by removing carefully selected
edges. We rigorously prove the correctness of our algorithm and evaluate its
performance on both synthetic and real networks. The experimental results show
that the control mode of a network can be easily changed by removing few
selected edges. Our methods provide the ability to design the desired control
mode for different control scenarios, which may be useful in many applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06066</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06066</id><created>2019-10-14</created><authors><author><keyname>Reina</keyname><forenames>Giulio</forenames></author><author><keyname>Leanza</keyname><forenames>Antonio</forenames></author><author><keyname>Milella</keyname><forenames>Annalisa</forenames></author><author><keyname>Messina</keyname><forenames>Arcangelo</forenames></author></authors><title>Mind the ground: A Power Spectral Density-based estimator for
  all-terrain rovers</title><categories>eess.SY cs.RO cs.SY</categories><comments>26 pages</comments><journal-ref>Measurement, 2019, 1-26</journal-ref><doi>10.1016/j.measurement.2019.107136</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing interest in new sensing technologies and processing
algorithms to increase the level of driving automation towards self-driving
vehicles. The challenge for autonomy is especially difficult for the
negotiation of uncharted scenarios, including natural terrain. This paper
proposes a method for terrain unevenness estimation that is based on the power
spectral density (PSD) of the surface profile as measured by exteroceptive
sensing, that is, by using a common onboard range sensor such as a stereoscopic
camera. Using these components, the proposed estimator can evaluate terrain
on-line during normal operations. PSD-based analysis provides insight not only
on the magnitude of irregularities, but also on how these irregularities are
distributed at various wavelengths. A feature vector can be defined to classify
roughness that is proved a powerful statistical tool for the characterization
of a given terrain fingerprint showing a limited sensitivity to vehicle tilt
rotations. First, the theoretical foundations behind the PSD-based estimator
are presented. Then, the system is validated in the field using an all-terrain
rover that operates on various natural surfaces. It is shown its potential for
automatic ground harshness estimation and, in general, for the development of
driving assistance systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06067</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06067</id><created>2019-10-14</created><authors><author><keyname>Deora</keyname><forenames>Puneesh</forenames></author><author><keyname>Vasudeva</keyname><forenames>Bhavya</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Saumik</forenames></author><author><keyname>Pradhan</keyname><forenames>Pyari Mohan</forenames></author></authors><title>Robust Compressive Sensing MRI Reconstruction using Generative
  Adversarial Networks</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing magnetic resonance imaging (CS-MRI) accelerates the
acquisition of MR images by breaking the Nyquist sampling limit. In this work,
a novel generative adversarial network (GAN) based framework for CS-MRI
reconstruction is proposed. Leveraging a combination of patchGAN discriminator
and structural similarity index based loss, our model focuses on preserving
high frequency content as well as fine textural details in the reconstructed
image. Dense and residual connections have been incorporated in a U-net based
generator architecture to allow easier transfer of information as well as
variable network length. We show that our algorithm outperforms
state-of-the-art methods in terms of quality of reconstruction and robustness
to noise. Also, the reconstruction time, which is of the order of milliseconds,
makes it highly suitable for real-time clinical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06070</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06070</id><created>2019-10-02</created><authors><author><keyname>Zhou</keyname><forenames>Hao</forenames></author><author><keyname>Laval</keyname><forenames>Jorge</forenames></author></authors><title>Longitudinal Motion Planning for Autonomous Vehicles and Its Impact on
  Congestion: A Survey</title><categories>eess.SP cs.CV cs.LG cs.RO</categories><comments>submitted to presentation at TRB 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews machine learning methods for the motion planning of
autonomous vehicles (AVs), with exclusive focus on the longitudinal behaviors
and their impact on traffic congestion. An extensive survey of training data,
model input/output, and learning methods for machine learning longitudinal
motion planning (mMP) is first presented. Each of those major components is
discussed and evaluated from the perspective of congestion impact. The emerging
technologies adopted by leading AV giants like Waymo and Tesla are highlighted
in our review. We find that: i) the AV industry has been focusing on the long
tail problem caused by &quot;corner errors&quot; threatening driving safety, ii) none of
the existing public datasets provides sufficient data under congestion
scenarios, and iii) although alternative and more advanced learning methods are
available in literature, the major mMP method adopted by industry is still
behavior cloning (BC).
  The study also surveys the connections between mMP and traditional
car-following (CF) models, and it reveals that: i) the model equivalence only
exists in simple settings, ii) studies have shown mMP can significantly
outperform CF models in long-term speed prediction, and iii) mMP's string
stability remains intractable yet, which can only be analyzed by model
approximation followed with numerical simulations. Future research needs are
also identified in the end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06072</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06072</id><created>2019-10-14</created><updated>2019-11-06</updated><authors><author><keyname>Liu</keyname><forenames>Chang-Le</forenames></author><author><keyname>Shih</keyname><forenames>Kuang-Tsu</forenames></author><author><keyname>Chen</keyname><forenames>Homer H.</forenames></author></authors><title>Light Field Synthesis by Training Deep Network in the Refocused Image
  Domain</title><categories>eess.IV cs.CV</categories><comments>submitted to IEEE Transactions on Image Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light field imaging, which captures spatio-angular information of incident
light on image sensor, enables many interesting applications like image
refocusing and augmented reality. However, due to the limited sensor
resolution, a trade-off exists between the spatial and angular resolution. To
increase the angular resolution, view synthesis techniques have been adopted to
generate new views from existing views. However, traditional learning-based
view synthesis mainly considers the image quality of each view of the light
field and neglects the quality of the refocused images. In this paper, we
propose a new loss function called refocused image error (RIE) to address the
issue. The main idea is that the image quality of the synthesized light field
should be optimized in the refocused image domain because it is where the light
field is perceived. We analyze the behavior of RIL in the spectral domain and
test the performance of our approach against previous approaches on both real
and software-rendered light field datasets using objective assessment metrics
such as MSE, MAE, PSNR, SSIM, and GMSD. Experimental results show that the
light field generated by our method results in better refocused images than
previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06075</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06075</id><created>2019-10-07</created><authors><author><keyname>Fadaie</keyname><forenames>Joshua</forenames></author></authors><title>The State of Modeling, Simulation, and Data Utilization within Industry:
  An Autonomous Vehicles Perspective</title><categories>cs.CY cs.SY eess.SY</categories><comments>arXiv admin note: text overlap with arXiv:1711.03938 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aviation industry has a market driven need to maintain and develop
enhanced simulation capabilities for a wide range of application domains. In
particular, the future growth and disruptive ability of smart cities,
autonomous vehicles and in general, urban mobility, hinges on the development
of state of the art simulation tools and the intelligent utilization of data.
While aviation based companies have several historical and/or proprietary
mission level simulation tools, there is much to learn from the current state
of the art within other industries (tangential and competing in scope), as well
as in academia. The purpose of this paper is to address and decompose the
simulation capabilities within the key players of the autonomous vehicle and
self-driving car industry (Toyota, Waymo, BMW, Microsoft, NVIDIA, Uber, etc.),
as well as several notable startups within the high fidelity 3D mapping and
simulation domain (Mapper, HERE, Cognata, etc.). While providing an overview of
how other companies are using simulation tools and reliable data-sets, this
paper will also seek to address several important and related questions,
namely: the interaction between simulation and supporting tools/software, the
intersection of simulation and the real world, the requirements and utilization
of compute infrastructure, the appropriate levels of fidelity within
simulation, and how simulation tools are critical to future safety and V&amp;V
concerns. In order for aviation based companies to adequately pursue disruptive
mobility within real-world environments, be it in air or on the ground,
modeling and simulation tools for autonomous vehicles provide key insights into
future development work and are essential technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06089</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06089</id><created>2019-10-10</created><authors><author><keyname>Won</keyname><forenames>Myounggyu</forenames></author></authors><title>UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery
  Swap Stations</title><categories>eess.SP cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) have been widely used in many applications.
The limited flight time of UAVs, however, still remains as a major challenge.
Although numerous approaches have been developed to recharge the battery of
UAVs effectively, little is known about optimal methodologies to deploy
charging stations. In this paper, we address the charging station deployment
problem with an aim to find the optimal number and locations of charging
stations such that the system performance is maximized. We show that the
problem is NP-Hard and propose UBAT, a heuristic framework based on the ant
colony optimization (ACO) to solve the problem. Additionally, a suite of
algorithms are designed to enhance the execution time and the quality of the
solutions for UBAT. Through extensive simulations, we demonstrate that UBAT
effectively performs multi-objective optimization of generation of UAV
trajectories and placement of charging stations that are within 8.3% and 7.3%
of the true optimal solutions, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06100</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06100</id><created>2019-10-14</created><authors><author><keyname>Al-Hussaini</keyname><forenames>Irfan</forenames></author><author><keyname>Xiao</keyname><forenames>Cao</forenames></author><author><keyname>Westover</keyname><forenames>M. Brandon</forenames></author><author><keyname>Sun</keyname><forenames>Jimeng</forenames></author></authors><title>SLEEPER: interpretable Sleep staging via Prototypes from Expert Rules</title><categories>cs.LG eess.SP stat.ML</categories><comments>Machine Learning for Healthcare Conference (MLHC) 2019. Proceedings
  of Machine Learning Research 106</comments><journal-ref>PMLR 106:721-739, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sleep staging is a crucial task for diagnosing sleep disorders. It is tedious
and complex as it can take a trained expert several hours to annotate just one
patient's polysomnogram (PSG) from a single night. Although deep learning
models have demonstrated state-of-the-art performance in automating sleep
staging, interpretability which defines other desiderata, has largely remained
unexplored. In this study, we propose Sleep staging via Prototypes from Expert
Rules (SLEEPER), which combines deep learning models with expert defined rules
using a prototype learning framework to generate simple interpretable models.
In particular, SLEEPER utilizes sleep scoring rules and expert defined features
to derive prototypes which are embeddings of PSG data fragments via
convolutional neural networks. The final models are simple interpretable models
like a shallow decision tree defined over those phenotypes. We evaluated
SLEEPER using two PSG datasets collected from sleep studies and demonstrated
that SLEEPER could provide accurate sleep stage classification comparable to
human experts and deep neural networks with about 85% ROC-AUC and .7 kappa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06110</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06110</id><created>2019-10-10</created><authors><author><keyname>Ye</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Qiu</keyname><forenames>Panghe</forenames></author><author><keyname>Wang</keyname><forenames>Haibo</forenames></author><author><keyname>Xiong</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Kaige</forenames></author></authors><title>Image watermarking and fusion based on Fourier single-pixel imaging with
  weighed light source</title><categories>eess.IV physics.optics</categories><comments>18 pages, 17 figures</comments><doi>10.1364/OE.27.036505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous single-pixel imaging systems, the light source was generally idle
with respect to time. Here, we propose a novel image fusion and visible
watermarking scheme based on Fourier single-pixel imaging (FSPI) with a
multiplexed time-varying (TV) signal, which is generated by the watermark
pattern hidden in the light source. We call this scheme as TV-FSPI. With
TV-FSPI, we can realize high-quality visible image watermarking, encrypted
image watermarking and full-color visible image watermarking. We also discuss
the extension to invisible watermarking based on TV-FSPI. Furthermore, we don't
have to recode illumination patterns, because TV-FSPI can be extended to
existing mainstream illumination patterns, such as random illumination mode and
Hadamard illumination mode. Thus TV-FSPI has the potential to be used in
single-pixel broadcasting system and multi-spectral single-pixel imaging
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06117</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06117</id><created>2019-10-14</created><authors><author><keyname>Guedes</keyname><forenames>P. F. S.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author></authors><title>Some remarks on the performance of Matlab, Python and Octave in
  simulating dynamical systems</title><categories>cs.MS cs.SY eess.SY</categories><comments>SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro
  Preto. 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matlab has been considered as a leader computational platform for many
engineering fields. Well documented and reliable, Matlab presents as a great
advantage its ability to increase the user productivity. However, Python and
Octave are among some of the languages that have challenged Matlab. Octave and
Python are well known examples of high-level scripting languages, with a great
advantage of being open source software. The novelty of this paper is devoted
to offer a comparison among these tree languages in the simulation of dynamical
systems. We have applied the lower bound error to estimate the error of
simulation. The comparison was performed with the chaotic systems Duffing-Ueda
oscillator and the Chua's circuit, both identified with polynomial NARMAX.
Octave presents the best reliable outcome. Nevertheless, Matlab needs the
lowest time to undertake the same activity. Python has presented the worse
result for the stop simulation criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06119</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06119</id><created>2019-10-11</created><authors><author><keyname>von Tycowicz</keyname><forenames>Christoph</forenames></author></authors><title>Towards Shape-based Knee Osteoarthritis Classification using Graph
  Convolutional Networks</title><categories>q-bio.QM eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a transductive learning approach for morphometric osteophyte
grading based on geometric deep learning. We formulate the grading task as
semi-supervised node classification problem on a graph embedded in shape space.
To account for the high-dimensionality and non-Euclidean structure of shape
space we employ a combination of an intrinsic dimension reduction together with
a graph convolutional neural network. We demonstrate the performance of our
derived classifier in comparisons to an alternative extrinsic approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06140</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06140</id><created>2019-10-14</created><authors><author><keyname>Kumar</keyname><forenames>Dileep</forenames></author><author><keyname>Kaleva</keyname><forenames>Jarkko</forenames></author><author><keyname>T&#xf6;lli</keyname><forenames>Antti</forenames></author></authors><title>Reliable mmWave Communication via Coordinated Multi-Point Connectivity</title><categories>eess.SP cs.IT math.IT</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental challenge of mmWave frequency band is the sensitivity of the
radio channel to blockage, which gives rise to unstable connectivity and also
impacts the reliability of a system. In this paper, we explore the viability of
using Coordinated Multi-Point (CoMP) connectivity for robust and resilient
downlink communication. We provide a novel iterative algorithm for Weighted
Sum-Rate Maximization (WSRM) leveraging Successive Convex Approximation (SCA)
with low computational complexity, which admits a closed-form solution via
iterative evaluation of the Karush-Kuhn-Tucker (KKT) optimality conditions.
Unlike in the conventional Joint Transmission (JT)-CoMP schemes, the proposed
precoder design has, per-iteration, computational complexity in the order of
base-station (BS) antennas instead of system-wide joint transmit antennas. This
is achieved by parallel beamformer processing across the coordinating BSs.
Furthermore, for the downlink precoder design, a conservative estimate of the
user-specific rates are obtained by considering possible combinations of
potentially blocked links, thus providing greatly improved communication
reliability. In the presence of random blockages, the proposed schemes are
shown to significantly outperform several baseline scenarios in terms of
effective throughput and outage performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06141</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06141</id><created>2019-10-14</created><authors><author><keyname>Sun</keyname><forenames>Miao</forenames></author><author><keyname>Isufi</keyname><forenames>Elvin</forenames></author><author><keyname>de Groot</keyname><forenames>Natasja M. S.</forenames></author><author><keyname>Hendriks</keyname><forenames>Richard C.</forenames></author></authors><title>Graph-Time Spectral Analysis for Atrial Fibrillation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Atrial fibrillation is a clinical arrhythmia with multifactorial mechanisms
still unresolved. Time-frequency analysis of epicardial electrograms has been
investigated to study atrial fibrillation. However, deeper understanding of
atrial fibrillation can be achieved if the spatial dimension can be
incorporated. Unfortunately, the physical models describing the spatial
relations of atrial fibrillation signals are complex and non-linear; hence, the
conventional signal processing techniques to study electrograms in the joint
space, time, and frequency domain are less suitable. In this study, we wish to
put forward a radically different approach to analyze atrial fibrillation with
a higher-level model. This approach relies on graph signal processing to
represent the spatial relations between epicardial electrograms and put forward
a graph-time spectral analysis for atrial fibrillation. To capture the
frequency content along both the time and graph domain, we proposed the joint
graph and short-time Fourier transform. The latter allows us to analyze the
spatial variability of the electrogram temporal frequencies. With this
technique, we have found that the spatial variation of the atrial electrograms
decreases during atrial fibrillation due to the reduction of the high temporal
frequencies of the atrial waves. The proposed analysis further confirms that
the ventricular activity is smoother over the atrial area compared with the
atrial activity. Besides using the proposed graph-time analysis to conduct a
first study on atrial fibrillation, we applied it to the cancellation of
ventricular activity from atrial electrograms. Experimental results on
simulated and real data further corroborate the findings in this atrial
fibrillation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06142</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06142</id><created>2019-10-14</created><authors><author><keyname>Teixeira</keyname><forenames>M.</forenames></author><author><keyname>Basilio</keyname><forenames>N. P.</forenames></author><author><keyname>Firmo</keyname><forenames>D. L.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author><author><keyname>Arias-Garcia</keyname><forenames>J.</forenames></author></authors><title>Simplification of the digital representation of the tent map through
  biased fixed point</title><categories>eess.SP cs.CR nlin.CD</categories><comments>SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro
  Preto. 6 pages. In Portuguese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chaotic systems have been investigated in several areas of engineering. In
control theory, such systems have instigated the emergence of new techniques as
well, have been used as a source of noise generation. The application of
chaotic systems as pseudo-random numbers has also been widely employed in
cryptography. One of the central aspects of these applications in high
performance situations, such as those involving a large amount of data (Big
Data), is the response of these systems in a short period of time. Despite the
great advances in the design of chaotic systems in analog circuits, it is
perceived less attention in the optimized design of these systems in the
digital domain. In this work, the polarized fixed point representation is
applied to reduce the number of digital elements. Using this approach, it was
possible to significantly reduce the number of logic gates in the subtraction
operation. When compared to other works in the literature, it has been viable
to reduce by 50 \% the number of elements per bit of the digital representation
of the tent map. The chaoticity was evidenced with the calculation of the
Lyapunov exponent. Histogram, entropy and autocorrelation tests were used
satisfactorily to evaluate the randomness of the represented system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06143</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06143</id><created>2019-10-14</created><authors><author><keyname>Medeiros</keyname><forenames>L. C.</forenames></author><author><keyname>Silva</keyname><forenames>P. H. O.</forenames></author><author><keyname>Lopes</keyname><forenames>V. H. S.</forenames></author><author><keyname>Oliveira</keyname><forenames>A. F.</forenames></author><author><keyname>Pereira</keyname><forenames>E. B.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author></authors><title>Detection of Muscle Fatigue Using Variable Bit Flow Modulation and Cross
  Correlation of Electromyographic Signals</title><categories>eess.SP</categories><comments>SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro
  Preto. 6 pages. In Portuguese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The surface electromyography (sEMG) analysis can provide information on
muscle fatigue status by estimation of muscle fibre conduction velocity (MFCV),
a measure of the travelling speed of motor unit action potentials in muscle
tissue. This paper proposes a technique for MFCV estimation using
cross-correlation methods and variable bitstream modulation. The technique
displays an estimate based on a set of data generated by the gain variation
modulation, providing an average estimate of the MFCV. The observed trend of
MFCV decrease correlates with the fatigue state of the observed muscle.
Finally, the values found were compared with information from the literature,
validating the method and showing the advantages of using variable modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06149</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06149</id><created>2019-10-11</created><authors><author><keyname>Ding</keyname><forenames>Yujia</forenames></author><author><keyname>Gu</keyname><forenames>Weiqing</forenames></author></authors><title>Accelerometer-Based Gait Segmentation: Simultaneously User and Adversary
  Identification</title><categories>eess.SP cs.LG stat.ML</categories><msc-class>62-07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new gait segmentation method based on
accelerometer data and develop a new distance function between two time series,
showing novel and effectiveness in simultaneously identifying user and
adversary. Comparing with the normally used Neural Network methods, our
approaches use geometric features to extract walking cycles more precisely and
employ a new similarity metric to conduct user-adversary identification. This
new technology for simultaneously identify user and adversary contributes to
cybersecurity beyond user-only identification. In particular, the new
technology is being applied to cell phone recorded walking data and performs an
accuracy of $98.79\%$ for 6 classes classification (user-adversary
identification) and $99.06\%$ for binary classification (user only
identification). In addition to walking signal, our approach works on walking
up, walking down and mixed walking signals. This technology is feasible for
both large and small data set, overcoming the current challenges facing to
Neural Networks such as tuning large number of hyper-parameters for large data
sets and lacking of training data for small data sets. In addition, the new
distance function developed here can be applied in any signal analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06150</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06150</id><created>2019-10-10</created><authors><author><keyname>Xiao</keyname><forenames>Fuyuan</forenames></author></authors><title>A generalized intelligent quality-based approach for fusing multi-source
  information</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a generalized intelligent quality-based approach
for fusing multi-source information. The goal of the proposed approach intends
to fuse the multi-complex-valued distribution information while maintaining a
high quality of the fused result by considering the usage of credible
information sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06153</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06153</id><created>2019-10-10</created><authors><author><keyname>Prado</keyname><forenames>Augustin</forenames></author><author><keyname>Kausik</keyname><forenames>Ravinath</forenames></author><author><keyname>Venkataramanan</keyname><forenames>Lalitha</forenames></author></authors><title>Dual Neural Network Architecture for Determining Epistemic and Aleatoric
  Uncertainties</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning techniques have been shown to be extremely effective for
various classification and regression problems, but quantifying the uncertainty
of their predictions and separating them into the epistemic and aleatoric
fractions is still considered challenging. In oil and gas exploration projects,
tools consisting of seismic, sonic, magnetic resonance, resistivity, dielectric
and/or nuclear sensors are sent downhole through boreholes to probe the earth's
rock and fluid properties. The measurements from these tools are used to build
reservoir models that are subsequently used for estimation and optimization of
hydrocarbon production. Machine learning algorithms are often used to estimate
the rock and fluid properties from the measured downhole data. Quantifying
uncertainties of these properties is crucial for rock and fluid evaluation and
subsequent reservoir optimization and production decisions. These machine
learning algorithms are often trained on a &quot;ground-truth&quot; or core database.
During the inference phase which involves application of these algorithms to
field data, it is critical that the machine learning algorithm flag data as out
of distribution from new geologies that the model was not trained upon. It is
also highly important to be sensitive to heteroscedastic aleatoric noise in the
feature space arising from the combination of tool and geological conditions.
Understanding the source of the uncertainty and reducing them is key to
designing intelligent tools and applications such as automated log
interpretation answer products for exploration and field development. In this
paper we describe a methodology consisting of a system of dual networks
comprising of the combination of a Bayesian Neural Network (BNN) and an
Artificial Neural Network (ANN) addressing this challenge for geophysical
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06154</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06154</id><created>2019-10-14</created><authors><author><keyname>Yao</keyname><forenames>Lisha</forenames></author><author><keyname>Li</keyname><forenames>Sui</forenames></author><author><keyname>Zhu</keyname><forenames>Manman</forenames></author><author><keyname>Zeng</keyname><forenames>Dong</forenames></author><author><keyname>Bian</keyname><forenames>Zhaoying</forenames></author><author><keyname>Ma</keyname><forenames>Jianhua</forenames></author></authors><title>Direct Energy-resolving CT Imaging via Energy-integrating CT images
  using a Unified Generative Adversarial Network</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>5 pages, 3 figures, Accepted by MIC/NSS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-resolving computed tomography (ErCT) has the ability to acquire
energy-dependent measurements simultaneously and quantitative material
information with improved contrast-to-noise ratio. Meanwhile, ErCT imaging
system is usually equipped with an advanced photon counting detector, which is
expensive and technically complex. Therefore, clinical ErCT scanners are not
yet commercially available, and they are in various stage of completion. This
makes the researchers less accessible to the ErCT images. In this work, we
investigate to produce ErCT images directly from existing energy-integrating CT
(EiCT) images via deep neural network. Specifically, different from other
networks that produce ErCT images at one specific energy, this model employs a
unified generative adversarial network (uGAN) to concurrently train EiCT
datasets and ErCT datasets with different energies and then performs
image-to-image translation from existing EiCT images to multiple ErCT image
outputs at various energy bins. In this study, the present uGAN generates ErCT
images at 70keV, 90keV, 110keV, and 130keV simultaneously from EiCT images
at140kVp. We evaluate the present uGAN model on a set of over 1380 CT image
slices and show that the present uGAN model can produce promising ErCT
estimation results compared with the ground truth qualitatively and
quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06220</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06220</id><created>2019-10-14</created><updated>2019-11-09</updated><authors><author><keyname>Wu</keyname><forenames>Qingqing</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Joint Active and Passive Beamforming Optimization for Intelligent
  Reflecting Surface Assisted SWIPT under QoS Constraints</title><categories>cs.IT eess.SP math.IT</categories><comments>We address the QoS-constrained beamforming optimization problem in
  IRS-aided SWIPT systems. More interesting works and an overview on IRS can be
  found at https://elewuqq.wixsite.com/mysite</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is a new and revolutionizing technology
for achieving spectrum and energy efficient wireless networks. By leveraging
massive low-cost passive elements that are able to reflect radio-frequency (RF)
signals with adjustable phase shifts, IRS can achieve high passive beamforming
gains, which are particularly appealing for improving the efficiency of
RF-based wireless power transfer. Motivated by the above, we study in the paper
an IRS-assisted simultaneous wireless information and power transfer (SWIPT)
system. Specifically, a set of IRSs are deployed to assist in the
information/power transfer from a multi-antenna access point (AP) to multiple
single-antenna information users (IUs) and energy users (EUs), respectively. We
aim to minimize the transmit power at the AP via jointly optimizing its
transmit precoders and the reflect phase shifts at all IRSs, subject to the
quality-of-service (QoS) constraints at all users, namely, the individual
signal-to-interference-plus-noise ratio (SINR) constraints at IUs and energy
harvesting constraints at EUs. However, this optimization problem is non-convex
with intricately coupled variables, for which the existing alternating
optimization approach is shown to be inefficient as the number of QoS
constraints increases. To tackle this challenge, we first apply proper
transformations on the QoS constraints and then propose an efficient iterative
algorithm by applying the penalty-based method. Moreover, by exploiting the
short-range coverage of IRSs, we further propose a low-complexity algorithm by
optimizing the phase shifts of all IRSs in parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06234</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06234</id><created>2019-10-14</created><authors><author><keyname>Tits</keyname><forenames>No&#xe9;</forenames></author><author><keyname>Haddad</keyname><forenames>Kevin El</forenames></author><author><keyname>Dutoit</keyname><forenames>Thierry</forenames></author></authors><title>The Theory behind Controllable Expressive Speech Synthesis: a
  Cross-disciplinary Approach</title><categories>eess.AS cs.HC cs.LG cs.SD</categories><comments>19 pages, 6 figures. To be published in the book &quot;Human Computer
  Interaction&quot; edited by Prof. Yves Rybarczyk, published by IntechOpen</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As part of the Human-Computer Interaction field, Expressive speech synthesis
is a very rich domain as it requires knowledge in areas such as machine
learning, signal processing, sociology, psychology. In this Chapter, we will
focus mostly on the technical side. From the recording of expressive speech to
its modeling, the reader will have an overview of the main paradigms used in
this field, through some of the most prominent systems and methods. We explain
how speech can be represented and encoded with audio features. We present a
history of the main methods of Text-to-Speech synthesis: concatenative,
parametric and statistical parametric speech synthesis. Finally, we focus on
the last one, with the last techniques modeling Text-to-Speech synthesis as a
sequence-to-sequence problem. This enables the use of Deep Learning blocks such
as Convolutional and Recurrent Neural Networks as well as Attention Mechanism.
The last part of the Chapter intends to assemble the different aspects of the
theory and summarize the concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06244</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06244</id><created>2019-10-11</created><authors><author><keyname>Chen</keyname><forenames>Tong</forenames></author><author><keyname>Liu</keyname><forenames>Haojie</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author><author><keyname>Shen</keyname><forenames>Qiu</forenames></author><author><keyname>Cao</keyname><forenames>Xun</forenames></author><author><keyname>Wang</keyname><forenames>Yao</forenames></author></authors><title>Neural Image Compression via Non-Local Attention Optimization and
  Improved Context Modeling</title><categories>eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1904.09757</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel Non-Local Attention optmization and Improved
Context modeling-based image compression (NLAIC) algorithm, which is built on
top of the deep nerual network (DNN)-based variational auto-encoder (VAE)
structure. Our NLAIC 1) embeds non-local network operations as non-linear
transforms in the encoders and decoders for both the image and the latent
representation probability information (known as hyperprior) to capture both
local and global correlations, 2) applies attention mechanism to generate masks
that are used to weigh the features, which implicitly adapt bit allocation for
feature elements based on their importance, and 3) implements the improved
conditional entropy modeling of latent features using joint 3D convolutional
neural network (CNN)-based autoregressive contexts and hyperpriors. Towards the
practical application, additional enhancements are also introduced to speed up
processing (e.g., parallel 3D CNN-based context prediction), reduce memory
consumption (e.g., sparse non-local processing) and alleviate the
implementation complexity (e.g., unified model for variable rates without
re-training). The proposed model outperforms existing methods on Kodak and CLIC
datasets with the state-of-the-art compression efficiency reported, including
learned and conventional (e.g., BPG, JPEG2000, JPEG) image compression methods,
for both PSNR and MS-SSIM distortion metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06250</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06250</id><created>2019-10-11</created><authors><author><keyname>Lins</keyname><forenames>Christian</forenames></author><author><keyname>Friedrich</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Hein</keyname><forenames>Andreas</forenames></author><author><keyname>Fudickar</keyname><forenames>Sebastian</forenames></author></authors><title>A modified Genetic Algorithm for continuous estimation of CPR quality
  parameters from wrist-worn inertial sensor data</title><categories>cs.NE eess.SP</categories><comments>21 pages. arXiv admin note: substantial text overlap with
  arXiv:1809.07692</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiopulmonary resuscitation (CPR) is the most important emergency
intervention for sudden cardiac arrest. In this paper, a robust sinusoidal
model fitting method based on a modified Genetic Algorithm for CPR quality
parameters - naming chest compression frequency and depth - as measured by an
inertial sensor placed at the wrist is presented. Once included into a
smartphone or smartwatch app, the proposed algorithm will enable bystanders to
improve CPR (as part of a continuous closed-loop support-system). By evaluating
the precision of the model with both, simulated data and data recorded by a
Laerdal Resusci Anne mannequin as reference standard, a variance for
compression frequency of +-3.7 cpm has been found for the sensor placed at the
wrist. Thereby, this previously unconsidered position and consequently the use
of smartwatches was shown to be a suitable alternative to the typical placement
of phones in the hand for CPR training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06271</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06271</id><created>2019-10-14</created><authors><author><keyname>Armanious</keyname><forenames>Karim</forenames></author><author><keyname>Abdulatif</keyname><forenames>Sherif</forenames></author><author><keyname>Bhaktharaguttu</keyname><forenames>Anish Rao</forenames></author><author><keyname>K&#xfc;stner</keyname><forenames>Thomas</forenames></author><author><keyname>Hepp</keyname><forenames>Tobias</forenames></author><author><keyname>Gatidis</keyname><forenames>Sergios</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author></authors><title>Organ-based Age Estimation based on 3D MRI Scans</title><categories>eess.IV cs.CV cs.LG</categories><comments>Submitted to IEEE ISBI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Individuals age differently depending on a multitude of different factors
such as lifestyle, medical history and genetics. Often, the global
chronological age is not indicative of the true ageing process. An organ-based
age estimation would yield a more accurate health state assessment. In this
work, we propose a new deep learning architecture for organ-based age
estimation based on magnetic resonance images (MRI). The proposed network is a
3D convolutional neural network (CNN) with increased depth and width made
possible by the hybrid utilization of inception and fire modules. We apply the
proposed framework for the tasks of brain and knee age estimation. Quantitative
comparisons against concurrent MR-based regression networks illustrated the
superior performance of the proposed work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06282</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06282</id><created>2019-10-08</created><authors><author><keyname>Tan</keyname><forenames>Mengxi</forenames></author><author><keyname>Xu</keyname><forenames>Xingyuan</forenames></author><author><keyname>Corcoran</keyname><forenames>Bill</forenames></author><author><keyname>Wu</keyname><forenames>Jiayang</forenames></author><author><keyname>Boes</keyname><forenames>Andreas</forenames></author><author><keyname>Nguyen</keyname><forenames>Thach G.</forenames></author><author><keyname>Chu</keyname><forenames>Sai T.</forenames></author><author><keyname>Little</keyname><forenames>Brent E.</forenames></author><author><keyname>Morandotti</keyname><forenames>Roberto</forenames></author><author><keyname>Mitchell</keyname><forenames>Arnan</forenames></author><author><keyname>Moss</keyname><forenames>David J.</forenames></author></authors><title>Microwave photonic fractional Hilbert transformer with an integrated
  optical soliton crystal micro-comb</title><categories>physics.app-ph eess.SP physics.optics</categories><comments>12 pages, 7 figures, 61 references</comments><journal-ref>IEEE Journal of Lightwave Technology, Volume 37, (2019)</journal-ref><doi>10.1109/JLT.2019.2946606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a photonic microwave and RF fractional Hilbert transformer based on
an integrated Kerr micro-comb source. The micro-comb source has a free spectral
range (FSR) of 50GHz, generating a large number of comb lines that serve as a
high-performance multi-wavelength source for the transformer. By programming
and shaping the comb lines according to calculated tap weights, we achieve both
arbitrary fractional orders and a broad operation bandwidth. We experimentally
characterize the RF amplitude and phase response for different fractional
orders and perform system demonstrations of real-time fractional Hilbert
transforms. We achieve a phase ripple of &lt; 0.15 rad within the 3-dB pass-band,
with bandwidths ranging from 5 to 9 octaves, depending on the order. The
experimental results show good agreement with theory, confirming the
effectiveness of our approach as a new way to implement high-performance
fractional Hilbert transformers with broad processing bandwidth, high
reconfigurability, and greatly reduced size and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06302</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06302</id><created>2019-10-14</created><authors><author><keyname>Noury</keyname><forenames>Erfan</forenames></author><author><keyname>Mannil</keyname><forenames>Suria S.</forenames></author><author><keyname>Chang</keyname><forenames>Robert T.</forenames></author><author><keyname>Ran</keyname><forenames>An Ran</forenames></author><author><keyname>Cheung</keyname><forenames>Carol Y.</forenames></author><author><keyname>Thapa</keyname><forenames>Suman S.</forenames></author><author><keyname>Rao</keyname><forenames>Harsha L.</forenames></author><author><keyname>Dasari</keyname><forenames>Srilakshmi</forenames></author><author><keyname>Riyazuddin</keyname><forenames>Mohammed</forenames></author><author><keyname>Nagaraj</keyname><forenames>Sriharsha</forenames></author><author><keyname>Zadeh</keyname><forenames>Reza</forenames></author></authors><title>Detecting Glaucoma Using 3D Convolutional Neural Network of Raw SD-OCT
  Optic Nerve Scans</title><categories>eess.IV cs.CV cs.LG</categories><comments>19 pages, 7 figures, 12 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose developing and validating a three-dimensional (3D) deep learning
system using the entire unprocessed OCT optic nerve volumes to distinguish true
glaucoma from normals in order to discover any additional imaging biomarkers
within the cube through saliency mapping. The algorithm has been validated
against 4 additional distinct datasets from different countries using
multimodal test results to define glaucoma rather than just the OCT alone.
  2076 OCT (Cirrus SD-OCT, Carl Zeiss Meditec, Dublin, CA) cube scans centered
over the optic nerve, of 879 eyes (390 healthy and 489 glaucoma) from 487
patients, age 18-84 years, were exported from the Glaucoma Clinic Imaging
Database at the Byers Eye Institute, Stanford University, from March 2010 to
December 2017. A 3D deep neural network was trained and tested on this unique
OCT optic nerve head dataset from Stanford. A total of 3620 scans (all obtained
using the Cirrus SD-OCT device) from 1458 eyes obtained from 4 different
institutions, from United States (943 scans), Hong Kong (1625 scans), India
(672 scans), and Nepal (380 scans) were used for external evaluation.
  The 3D deep learning system achieved an area under the receiver operation
characteristics curve (AUROC) of 0.8883 in the primary Stanford test set
identifying true normal from true glaucoma. The system obtained AUROCs of
0.8571, 0.7695, 0.8706, and 0.7965 on OCT cubes from United States, Hong Kong,
India, and Nepal, respectively.
  We also analyzed the performance of the model separately for each myopia
severity level as defined by spherical equivalent and the model was able to
achieve F1 scores of 0.9673, 0.9491, and 0.8528 on severe, moderate, and mild
myopia cases, respectively. Saliency map visualizations highlighted a
significant association between the optic nerve lamina cribrosa region in the
glaucoma group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06313</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06313</id><created>2019-10-03</created><updated>2019-11-19</updated><authors><author><keyname>Khamvilai</keyname><forenames>Thanakorn</forenames></author><author><keyname>Sutter</keyname><forenames>Louis</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Baufreton</keyname><forenames>Philippe</forenames></author><author><keyname>Neumann</keyname><forenames>Francois</forenames></author></authors><title>Decentralized On-line Task Reallocation on Parallel Computing
  Architectures with Safety-Critical Applications</title><categories>cs.DC cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a decentralized allocation algorithm of safety-critical
application on parallel computing architectures, where individual Computational
Units can be affected by faults.
  The described method consists in representing the architecture by an abstract
graph where each node represents a Computational Unit. Applications are also
represented by the graph of Computational Units they require for execution. The
problem is then to decide how to allocate Computational Units to applications
to guarantee execution of the safety-critical application. The problem is
formulated as an optimization problem, with the form of an Integer Linear
Program. A state-of-the-art solver is then used to solve the problem.
  Decentralizing the allocation process is achieved through redundancy of the
allocator executed on the architecture. No centralized element decides on the
allocation of the entire architecture, thus improving the reliability of the
system.
  Experimental reproduction of a multi-core architecture is also presented. It
is used to demonstrate the capabilities of the proposed allocation process to
maintain the operation of a physical system in a decentralized way while
individual component fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06323</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06323</id><created>2019-10-14</created><authors><author><keyname>Sasmal</keyname><forenames>Aritra</forenames></author><author><keyname>Geib</keyname><forenames>Nathan</forenames></author><author><keyname>Grosh</keyname><forenames>Karl</forenames></author></authors><title>Broadband nonreciprocal linear acoustics through nonlocal active media</title><categories>physics.app-ph cs.SY eess.SY</categories><comments>3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to create linear systems that manifest broadband nonreciprocal
wave propagation would provide for exquisite control over acoustic signals for
electronic filtering in communication and noise control. Until now, acoustic
nonreciprocity has been achieved through a variety of means including nonlinear
interaction, mean-flow biasing, smart skins, and spatio-temporal parametric
modulation. Each of these approaches suffers from at least one of the following
drawbacks: introduction of modulation tones, narrow band filtering, and the
introduction or interruption of mean flow in fluid acoustics. We now show that
an acoustic media that is nonlocal and active provides a new means to break
reciprocity in a linear fashion. We realize this media using a distributed
network of interlaced sensor-actuator pairs with a unidirectional signal
transport. We exploit this new design space to create media with non-even
dispersion relations and highly nonreciprocal behavior over a broad range of
frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06325</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06325</id><created>2019-10-14</created><authors><author><keyname>Khodaei</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Inaloo</keyname><forenames>Mohammad Hadi Balaghi</forenames></author><author><keyname>Mehrvarz</keyname><forenames>Amin</forenames></author><author><keyname>Jalili</keyname><forenames>Nader</forenames></author></authors><title>An Adaptive Neuro-fuzzy Strategy in Closed-loop Control of Anesthesia</title><categories>eess.SY cs.SY math.OC</categories><comments>10 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an adaptive neuro-fuzzy framework to improve drug
infusion rate in closed-loop control of anesthesia. The proposed controller
provides a sub-optimal propofol administration rate as input to reach the
desired bispectral index, which is the output of the system, in both induction
and maintenance phases. In this controller, a critic agent assesses the plant
output and produces a reinforcement signal to adapt the controller parameters
and minimize the propofol administration rate. The controller is applied to a
conventional pharmacokinetic-pharmacodynamics model of anesthesia to evaluate
its applicability in closed loop-control of anesthesia. To simulate the
designed controller, physiological parameters of 12 patients are used in the
mathematical model. The simulation results show that the proposed controller
can overcome current challenges in the closed-loop control of anesthesia like
inter patient variability, model uncertainties and surgical disturbances
without overdose or underdose in a time range of 2 to 4 minutes. Analytical
comparison of results shows the strength of the controller in closed-loop
control of anesthesia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06370</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06370</id><created>2019-10-14</created><updated>2020-02-02</updated><authors><author><keyname>Sorrentino</keyname><forenames>Ines</forenames></author><author><keyname>Chavez</keyname><forenames>Francisco Javier Andrade</forenames></author><author><keyname>Latella</keyname><forenames>Claudia</forenames></author><author><keyname>Fiorio</keyname><forenames>Luca</forenames></author><author><keyname>Traversaro</keyname><forenames>Silvio</forenames></author><author><keyname>Rapetti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Tirupachuri</keyname><forenames>Yeshasvi</forenames></author><author><keyname>Guedelha</keyname><forenames>Nuno</forenames></author><author><keyname>Maggiali</keyname><forenames>Marco</forenames></author><author><keyname>Dussoni</keyname><forenames>Simeone</forenames></author><author><keyname>Metta</keyname><forenames>Giorgio</forenames></author><author><keyname>Pucci</keyname><forenames>Daniele</forenames></author></authors><title>A Novel Sensorised Insole for Sensing Feet Pressure Distributions</title><categories>physics.app-ph cs.SY eess.SY</categories><comments>21 pages, 12 figures</comments><journal-ref>A Novel Sensorised Insole for Sensing Feet Pressure Distributions.
  Sensors 2020, 20, 747</journal-ref><doi>10.3390/s20030747</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wearable sensors are gaining in popularity because they enable outdoor
experimental monitoring. This paper presents a cost-effective sensorised insole
based on a mesh of tactile capacitive sensors. Each sensor's spatial resolution
is about 4 taxels/cm^2 in order to have an accurate reconstruction of the
contact pressure distribution. As a consequence, the insole provides
information such as contact forces, moments, and center of pressure. To
retrieve this information, a calibration technique that fuses measurements from
a vacuum chamber and shoes equipped with force/torque sensors is proposed. The
validation analysis shows that the best performance achieved a root mean square
error (RMSE) of about 7 N for the contact forces and 2 N m for the contact
moments when using the force/torque shoe data as ground truth. Thus, the insole
may be an alternative to force/torque sensors for certain applications, with a
considerably more cost-effective and less invasive hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06375</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06375</id><created>2019-10-14</created><authors><author><keyname>Konar</keyname><forenames>Sushan</forenames></author></authors><title>The Sounds of Music : Science of Musical Scales III -- Indian Classical</title><categories>cs.SD eess.AS</categories><comments>Final part of a 3-article series on Musical Scales, see
  arXiv:1908.07940, arXiv:1909.06259</comments><journal-ref>Resonance - Journal of Science Education, 24(10), 1125 (2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the previous articles of this series, we have discussed the development of
musical scales particularly that of the heptatonic scale which forms the basis
of Western classical music today. In this last article, we take a look at the
basic structure of scales used in Indian classical music and how different
`raga's are generated through the simple process of scale shifting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06379</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06379</id><created>2019-10-14</created><authors><author><keyname>Luo</keyname><forenames>Yi</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>Yoshioka</keyname><forenames>Takuya</forenames></author></authors><title>Dual-path RNN: efficient long sequence modeling for time-domain
  single-channel speech separation</title><categories>eess.AS cs.LG cs.SD</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Recent studies in deep learning-based speech separation have proven the
superiority of time-domain approaches to conventional time-frequency-based
methods. Unlike the time-frequency domain approaches, the time-domain
separation systems often receive input sequences consisting of a huge number of
time steps, which introduces challenges for modeling extremely long sequences.
Conventional recurrent neural networks (RNNs) are not effective for modeling
such long sequences due to optimization difficulties, while one-dimensional
convolutional neural networks (1-D CNNs) cannot perform utterance-level
sequence modeling when its receptive field is smaller than the sequence length.
In this paper, we propose dual-path recurrent neural network (DPRNN), a simple
yet effective method for organizing RNN layers in a deep structure to model
extremely long sequences. DPRNN splits the long sequential input into smaller
chunks and applies intra- and inter-chunk operations iteratively, where the
input length can be made proportional to the square root of the original
sequence length in each operation. Experiments show that by replacing 1-D CNN
with DPRNN and apply sample-level modeling in the time-domain audio separation
network (TasNet), a new state-of-the-art performance on WSJ0-2mix is achieved
with a 20 times smaller model than the previous best system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06401</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06401</id><created>2019-10-14</created><updated>2020-02-16</updated><authors><author><keyname>Ostrometzky</keyname><forenames>Jonatan</forenames></author><author><keyname>Berestizshevsky</keyname><forenames>Konstantin</forenames></author><author><keyname>Bernstein</keyname><forenames>Andrey</forenames></author><author><keyname>Zussman</keyname><forenames>Gil</forenames></author></authors><title>Physics-Informed Deep Neural Network Method for Limited Observability
  State Estimation</title><categories>eess.SY cs.LG cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The precise knowledge regarding the state of the power grid is important in
order to ensure optimal and reliable grid operation. Specifically, knowing the
state of the distribution grid becomes increasingly important as more renewable
energy sources are connected directly into the distribution network, increasing
the fluctuations of the injected power. In this paper, we consider the case
when the distribution grid becomes partially observable, and the state
estimation problem is under-determined. We present a new methodology that
leverages a deep neural network (DNN) to estimate the grid state. The standard
DNN training method is modified to explicitly incorporate the physical
information of the grid topology and line/shunt admittance. We show that our
method leads to a superior accuracy of the estimation when compared to the case
when no physical information is provided. Finally, we compare the performance
of our method to the standard state estimation approach, which is based on the
weighted least squares with pseudo-measurements, and show that our method
performs significantly better with respect to the estimation accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06407</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06407</id><created>2019-10-14</created><authors><author><keyname>Doshi</keyname><forenames>Jigar</forenames></author><author><keyname>Garcia</keyname><forenames>Dominic</forenames></author><author><keyname>Massey</keyname><forenames>Cliff</forenames></author><author><keyname>Llueca</keyname><forenames>Pablo</forenames></author><author><keyname>Borensztein</keyname><forenames>Nicolas</forenames></author><author><keyname>Baird</keyname><forenames>Michael</forenames></author><author><keyname>Cook</keyname><forenames>Matthew</forenames></author><author><keyname>Raj</keyname><forenames>Devaki</forenames></author></authors><title>FireNet: Real-time Segmentation of Fire Perimeter from Aerial Video</title><categories>cs.CV cs.LG eess.IV</categories><comments>Published at NeurIPS 2019; Workshop on Artificial Intelligence for
  Humanitarian Assistance and Disaster Response(AI+HADR 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we share our approach to real-time segmentation of fire
perimeter from aerial full-motion infrared video. We start by describing the
problem from a humanitarian aid and disaster response perspective.
Specifically, we explain the importance of the problem, how it is currently
resolved, and how our machine learning approach improves it. To test our models
we annotate a large-scale dataset of 400,000 frames with guidance from domain
experts. Finally, we share our approach currently deployed in production with
inference speed of 20 frames per second and an accuracy of 92 (F1 Score).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06412</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06412</id><created>2019-10-14</created><authors><author><keyname>Taylor</keyname><forenames>Chris</forenames></author><author><keyname>Luzzi</keyname><forenames>Colin</forenames></author><author><keyname>Nowzari</keyname><forenames>Cameron</forenames></author></authors><title>On the Effects of Collision Avoidance on Emergent Swarm Behavior</title><categories>cs.RO cs.MA cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Swarms of autonomous agents, through their decentralized and robust nature,
show great promise as a future solution to the myriad missions of business,
military, and humanitarian relief. The diverse nature of mission sets creates
the need for swarm algorithms to be deployed on a variety of hardware
platforms. Swarms are currently viable on platforms where collisions between
agents are harmless, but on many platforms collisions are prohibited since they
would damage the agents involved. The available literature typically assumes
that collisions can be avoided by adding a collision avoidance algorithm on top
of an existing swarm behavior. Through an illustrative example in our
experience replicating a particular behavior, we show that this can be
difficult to achieve since the swarm behavior can be disrupted by the collision
avoidance. We introduce metrics quantifying the level of disruption in our
swarm behavior and propose a technique that is able to assist in tuning the
collision avoidance algorithm such that the goal behavior is achieved as best
as possible while collisions are avoided. We validate our results through
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06424</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06424</id><created>2019-10-14</created><authors><author><keyname>Dikici</keyname><forenames>Engin</forenames></author><author><keyname>Bigelow</keyname><forenames>Matthew</forenames></author><author><keyname>Prevedello</keyname><forenames>Luciano M.</forenames></author><author><keyname>White</keyname><forenames>Richard D.</forenames></author><author><keyname>Erdal</keyname><forenames>Barbaros Selnur</forenames></author></authors><title>Integrating AI into Radiology workflow: Levels of research, production,
  and feedback maturity</title><categories>eess.IV</categories><comments>19 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report represents a roadmap for integrating Artificial Intelligence
(AI)-based image analysis algorithms into existing Radiology workflows such
that: (1) radiologists can significantly benefit from enhanced automation in
various imaging tasks due to AI; and (2) radiologists' feedback is utilized to
further improve the AI application. This is achieved by establishing three
maturity levels where: (1) research enables the visualization of AI-based
results/annotations by radiologists without generating new patient records; (2)
production allows the AI-based system to generate results stored in an
institution's Picture Archiving and Communication System; and (3) feedback
equips radiologists with tools for editing the AI inference results for
periodic retraining of the deployed AI systems, thereby allowing the continuous
organic improvement of AI-based radiology-workflow solutions. A case study
(i.e., detection of brain metastases with T1-weighted contrast-enhanced 3D MRI)
illustrates the deployment details of a particular AI-based application
according to the aforementioned maturity levels. It is shown that the given AI
application significantly improves with the feedback coming from radiologists;
the number of incorrectly detected brain metastases (false positives) reduces
from 14.2 to 9.12 per patient with the number of subsequently annotated
datasets increasing from 93 to 217 as a result of radiologist adjudication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06428</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06428</id><created>2019-10-14</created><authors><author><keyname>Venkatesh</keyname><forenames>Bairavi</forenames></author><author><keyname>Shah</keyname><forenames>Tosha</forenames></author><author><keyname>Chen</keyname><forenames>Antong</forenames></author><author><keyname>Ghafurian</keyname><forenames>Soheil</forenames></author></authors><title>Restoration of marker occluded hematoxylin and eosin stained whole slide
  histology images using generative adversarial networks</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is common for pathologists to annotate specific regions of the tissue,
such as tumor, directly on the glass slide with markers. Although this practice
was helpful prior to the advent of histology whole slide digitization, it often
occludes important details which are increasingly relevant to immuno-oncology
due to recent advancements in digital pathology imaging techniques. The current
work uses a generative adversarial network with cycle loss to remove these
annotations while still maintaining the underlying structure of the tissue by
solving an image-to-image translation problem. We train our network on up to
300 whole slide images with marker inks and show that 70% of the corrected
image patches are indistinguishable from originally uncontaminated image tissue
to a human expert. This portion increases 97% when we replace the human expert
with a deep residual network. We demonstrated the fidelity of the method to the
original image by calculating the correlation between image gradient
magnitudes. We observed a revival of up to 94,000 nuclei per slide in our
dataset, the majority of which were located on tissue border.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06444</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06444</id><created>2019-10-14</created><authors><author><keyname>Xu</keyname><forenames>Joseph Z.</forenames></author><author><keyname>Lu</keyname><forenames>Wenhan</forenames></author><author><keyname>Li</keyname><forenames>Zebo</forenames></author><author><keyname>Khaitan</keyname><forenames>Pranav</forenames></author><author><keyname>Zaytseva</keyname><forenames>Valeriya</forenames></author></authors><title>Building Damage Detection in Satellite Imagery Using Convolutional
  Neural Networks</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In all types of disasters, from earthquakes to armed conflicts, aid workers
need accurate and timely data such as damage to buildings and population
displacement to mount an effective response. Remote sensing provides this data
at an unprecedented scale, but extracting operationalizable information from
satellite images is slow and labor-intensive. In this work, we use machine
learning to automate the detection of building damage in satellite imagery. We
compare the performance of four different convolutional neural network models
in detecting damaged buildings in the 2010 Haiti earthquake. We also quantify
how well the models will generalize to future disasters by training and testing
models on different disaster events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06460</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06460</id><created>2019-10-14</created><authors><author><keyname>Miraglia</keyname><forenames>Giovanni</forenames></author><author><keyname>Hook</keyname><forenames>Loyd</forenames><suffix>IV</suffix></author></authors><title>A Feedback Motion Plan for Vehicles with Bounded Curvature Constraints</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of a feedback motion plan instead of the decoupled scheme consisting
of separate plan and control phases can facilitate the task of proving the
properties of an autonomous system. The advantage of using a feedback motion
plan is the possibility to validate the whole plan offline before its
execution, which means that trajectories having different initial states can be
tested simultaneously. In this paper, we formulate a feedback motion plan based
on the extension of the \emph{wavefront expansion} to the case of vehicles
having bounded curvature. Additionally, the use of a transition function and a
Gaussian filter limits undesired oscillations in the resultant trajectories.
The method is suitable for both single goal missions and path following. The
paper illustrates the algorithm for the generation of the plan and presents
simulation data containing example trajectories and analysis of tuning
parameters. Finally, future developments are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06462</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06462</id><created>2019-10-14</created><authors><author><keyname>Ugrinovskii</keyname><forenames>V.</forenames></author><author><keyname>James</keyname><forenames>M. R.</forenames></author></authors><title>Active versus Passive Coherent Equalization of Passive Linear Quantum
  Systems</title><categories>eess.SY cs.SY math.OC quant-ph</categories><comments>Accepted for presentation at the 58th IEEE Conference on Decision and
  Control, Nice, France, Dec 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers the problem of equalization of passive linear quantum
systems. While our previous work was concerned with the analysis and synthesis
of passive equalizers, in this paper we analyze coherent quantum equalizers
whose annihilation (respectively, creation) operator dynamics in the Heisenberg
picture are driven by both quadratures of the channel output field. We show
that the characteristics of the input field must be taken into consideration
when choosing the type of the equalizing filter. In particular, we show that
for thermal fields allowing the filter to process both quadratures of the
channel output may not improve mean square accuracy of the input field
estimate, in comparison with passive filters. This situation changes when the
input field is `squeezed'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06464</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06464</id><created>2019-10-14</created><authors><author><keyname>G&#xe2;rbacea</keyname><forenames>Cristina</forenames></author><author><keyname>Oord</keyname><forenames>A&#xe4;ron van den</forenames></author><author><keyname>Li</keyname><forenames>Yazhe</forenames></author><author><keyname>Lim</keyname><forenames>Felicia S C</forenames></author><author><keyname>Luebs</keyname><forenames>Alejandro</forenames></author><author><keyname>Vinyals</keyname><forenames>Oriol</forenames></author><author><keyname>Walters</keyname><forenames>Thomas C</forenames></author></authors><title>Low Bit-Rate Speech Coding with VQ-VAE and a WaveNet Decoder</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>ICASSP 2019</comments><journal-ref>ICASSP 2019-2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), pp. 735-739. IEEE, 2019</journal-ref><doi>10.1109/ICASSP.2019.8683277</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to efficiently transmit and store speech signals, speech codecs
create a minimally redundant representation of the input signal which is then
decoded at the receiver with the best possible perceptual quality. In this work
we demonstrate that a neural network architecture based on VQ-VAE with a
WaveNet decoder can be used to perform very low bit-rate speech coding with
high reconstruction quality. A prosody-transparent and speaker-independent
model trained on the LibriSpeech corpus coding audio at 1.6 kbps exhibits
perceptual quality which is around halfway between the MELP codec at 2.4 kbps
and AMR-WB codec at 23.05 kbps. In addition, when training on high-quality
recorded speech with the test speaker included in the training set, a model
coding speech at 1.6 kbps produces output of similar perceptual quality to that
generated by AMR-WB at 23.05 kbps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06465</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06465</id><created>2019-10-14</created><authors><author><keyname>de Alencar</keyname><forenames>Rodrigo R. M.</forenames></author><author><keyname>Landau</keyname><forenames>Lukas T. N.</forenames></author></authors><title>Continuous Phase Modulation With Faster-than-Nyquist Signaling for
  Channels With 1-bit Quantization and Oversampling at the Receiver</title><categories>cs.IT cs.ET cs.SY eess.SY math.IT</categories><comments>5 pages, submitted to IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous phase modulation (CPM) with 1-bit quantization at the receiver is
promising in terms of energy and spectral efficiency. In this study, CPM
waveforms with symbol durations significantly shorter than the inverse of the
signal bandwidth are proposed, termed faster-than-Nyquist CPM. This
configuration provides a better steering of zero-crossings as compared to
conventional CPM. Numerical results confirm a superior performance in terms of
BER in comparison with state-of-the-art methods, while having the same spectral
efficiency and a lower oversampling factor. Moreover, the new waveform can be
detected with low-complexity, which yields almost the same performance as using
the BCJR algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06468</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06468</id><created>2019-10-14</created><authors><author><keyname>Kolev</keyname><forenames>Vasil</forenames></author><author><keyname>Cooklev</keyname><forenames>Todor</forenames></author><author><keyname>Keinert</keyname><forenames>Fritz</forenames></author></authors><title>Matrix Spectral Factorization for SA4 Multiwavelet</title><categories>math.NA cs.CE cs.NA eess.SP</categories><comments>This is a preprint of a paper whose final and definite form is
  published in https://link.springer.com/article/10.1007/s11045-017-0520-x</comments><msc-class>47Axx, 42Cxx, 65Txx, 11Cxx, 12Yxx, 13P25, 15B05, 15B10, 97H60, 97R20</msc-class><journal-ref>Multidimensional Systems and Signal Processing,vol. 29, Issue 4,
  pp. 1613 - 1641, 2018</journal-ref><doi>10.1007/s11045-017-0520-x</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we investigate Bauer's method for the matrix spectral
factorization of an r-channel matrix product filter which is a halfband
autocorrelation matrix. We regularize the resulting matrix spectral factors by
an averaging approach and by multiplication by a unitary matrix. This leads to
the approximate and exact orthogonal SA4 multiscaling functions. We also find
the corresponding orthogonal multiwavelet functions, based on the QR
decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06522</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06522</id><created>2019-10-15</created><updated>2019-10-15</updated><authors><author><keyname>Chang</keyname><forenames>Xuankai</forenames></author><author><keyname>Zhang</keyname><forenames>Wangyou</forenames></author><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author><author><keyname>Roux</keyname><forenames>Jonathan Le</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>MIMO-SPEECH: End-to-End Multi-Channel Multi-Speaker Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted at ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the end-to-end approach has proven its efficacy in monaural
multi-speaker speech recognition. However, high word error rates (WERs) still
prevent these systems from being used in practical applications. On the other
hand, the spatial information in multi-channel signals has proven helpful in
far-field speech recognition tasks. In this work, we propose a novel neural
sequence-to-sequence (seq2seq) architecture, MIMO-Speech, which extends the
original seq2seq to deal with multi-channel input and multi-channel output so
that it can fully model multi-channel multi-speaker speech separation and
recognition. MIMO-Speech is a fully neural end-to-end framework, which is
optimized only via an ASR criterion. It is comprised of: 1) a monaural masking
network, 2) a multi-source neural beamformer, and 3) a multi-output speech
recognition model. With this processing, the input overlapped speech is
directly mapped to text sequences. We further adopted a curriculum learning
strategy, making the best use of the training set to improve the performance.
The experiments on the spatialized wsj1-2mix corpus show that our model can
achieve more than 60% WER reduction compared to the single-channel system with
high quality enhanced signals (SI-SDR = 23.1 dB) obtained by the above
separation function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06529</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06529</id><created>2019-10-15</created><authors><author><keyname>Shahab</keyname><forenames>Muhammad Basit</forenames></author><author><keyname>Abbas</keyname><forenames>Rana</forenames></author><author><keyname>Shirvanimoghaddam</keyname><forenames>Mahyar</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author></authors><title>Grant-free Non-orthogonal Multiple Access for IoT: A Survey</title><categories>eess.SP</categories><comments>Survey Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive machine-type communications (mMTC) is one of the main three focus
areas in the 5th generation (5G) of mobile standards to enable connectivity of
a massive number of internet of things (IoT) devices with little or no human
intervention. In conventional human-type communications (HTC), due to the
limited number of available radio resources and orthogonal/non-overlapping
nature of existing resource allocation techniques, users need to compete for
connectivity through a random access (RA) process, which may turn into a
performance bottleneck in mMTC. In this context, non-orthogonal multiple access
(NOMA) has emerged as a potential technology that allows overlapping of
multiple users over a radio resource, thereby creating an opportunity to enable
more autonomous and grant-free communication, where devices can transmit data
whenever they need. The existing literature on NOMA schemes majorly considers
centralized scheduling based HTC, where users are already connected, and
various system parameters like spreading sequences, interleaving patterns,
power control, etc., are predefined. Contrary to HTC, mMTC traffic is different
with mostly uplink communication, small data size per device, diverse quality
of service, autonomous nature, and massive number of devices. Hence, the
signaling overhead and latency of centralized scheduling becomes a potential
performance bottleneck. To tackle this, grant-free access is needed, where mMTC
devices can autonomously transmit their data over randomly chosen radio
resources. This article, in contrast to existing surveys, comprehensively
discusses the recent advances in NOMA from a grant-free connectivity
perspective. Moreover, related practical challenges and future directions are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06530</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06530</id><created>2019-10-15</created><authors><author><keyname>Song</keyname><forenames>Zhuoyuan</forenames></author><author><keyname>Mohseni</keyname><forenames>Kamran</forenames></author></authors><title>Concurrent Flow-Based Localization and Mapping in Time-Invariant Flow
  Fields</title><categories>cs.RO eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the concept of concurrent flow-based localization and mapping
(FLAM) for autonomous field robots navigating within background flows.
Different from the classical simultaneous localization and mapping (SLAM)
problem, where the robot interacts with discrete features, FLAM utilizes the
continuous flow fields as navigation references for mobile robots and provides
flow field mapping capability with in-situ flow velocity observations. This
approach is of importance to underwater vehicles in mid-depth oceans or aerial
vehicles in GPS-denied atmospheric circulations. This article introduces the
formulation of FLAM as a full SLAM solution motivated by the feature-based
GraphSLAM framework. The performance of FLAM was demonstrated through
simulation within artificial flow fields that represent typical geophysical
circulation phenomena: a steady single-gyre flow field and a double-gyre flow
field with unsteady turbulent perturbations. The results indicate that FLAM
provides significant improvements in the robots' localization accuracy and a
consistent approximation of the background flow field. It is also shown that
FLAM leads to smooth robot trajectory estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06536</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06536</id><created>2019-10-15</created><authors><author><keyname>Song</keyname><forenames>Yiwen</forenames></author><author><keyname>Sun</keyname><forenames>Ningning</forenames></author><author><keyname>Chen</keyname><forenames>Huimiao</forenames></author></authors><title>Demand Adaptive Multi-Objective Electric Taxi Fleet Dispatching with
  Carbon Emission Analysis</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a foreseeable future mode of transport with lower emissions and higher
efficiencies, electric vehicles have received worldwide attention. For
convenient centralized management, taxis are considered as the fleet with
electrification priority. In this work, we focus on the study on electric taxis
dispatching, with consideration of picking up customers and recharging, based
on real world traffic data of a large number of taxis in Beijing. First, the
assumed electric taxi charging stations are located using the K mean method.
Second, based on the station locations and the order demands, which are in form
of origin-destination pairs and extracted from the trajectory data, a
dispatching strategy as well as the simulation framework is developed with
consideration of reducing customer waiting time, mitigating electric taxi
charging congestion, and balancing order number distribution among electric
taxis. The proposed method models the electric taxi charging behaviors
temporally discretely from the aspects of charging demands and availability of
chargers, and further incorporates a centralized and intelligent fleet
dispatching platform, which is capable of handling taxi service requests and
arranging electric taxis' recharging in real time. The methodology in this
paper is readily applicable to dispatching of different types of electric
vehicle fleet with similar dataset available. Among the method, we use queueing
theory to model the electric vehicle charging station waiting phenomena and
include this factor into dispatching platform. Carbon emission is also surveyed
and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06561</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06561</id><created>2019-10-15</created><authors><author><keyname>Ferrari</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Richard</keyname><forenames>C&#xe9;dric</forenames></author><author><keyname>Verduci</keyname><forenames>Louis</forenames></author></authors><title>Distributed Change Detection in Streaming Graph Signals</title><categories>eess.SP cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting abrupt changes in streaming graph signals is relevant in a variety
of applications ranging from energy and water supplies, to environmental
monitoring. In this paper, we address this problem when anomalies activate
localized groups of nodes in a network. We introduce an online change-point
detection algorithm, which is fully distributed across nodes to monitor
large-scale dynamic networks. We analyze the detection statistics for
controlling the probability of a global type 1 error. Finally we illustrate the
detection and localization performance with simulated data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06565</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06565</id><created>2019-10-15</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Van Nieuwenhove</keyname><forenames>Vincent</forenames></author><author><keyname>Sijbers</keyname><forenames>Jan</forenames></author></authors><title>To Recurse or not to Recurse,a Low Dose CT Study</title><categories>eess.IV</categories><comments>Sections II.A to II.D is taken from sections II.A to II.D of
  arXiv:1904.03908 which is an unpublished article from the same authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restoring high-quality CT images from low dose CT counterparts is an
ill-posed, nonlinear problem to which Deep Learning approaches have been giving
superior solutions compared to classical model-based approaches. In this
article, a framework is presented wherein a Recurrent Neural Network (RNN) is
utilized to remove the streaking artefacts from low projection number CT
imaging. The results indicate similar image restoration performance for the RNN
compared to the feedforward network in low noise cases while in high noise
levels the RNN returns better results. The computational costs are also
compared between RNN and feedforward networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06569</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06569</id><created>2019-10-15</created><authors><author><keyname>Perez-Cruz</keyname><forenames>Fernando</forenames></author><author><keyname>Olmos</keyname><forenames>Pablo M.</forenames></author><author><keyname>Zhang</keyname><forenames>Michael Minyi</forenames></author><author><keyname>Huang</keyname><forenames>Howard</forenames></author></authors><title>Probabilistic Time of Arrival Localization</title><categories>cs.LG eess.SP stat.ML</categories><comments>IEEE Signal Processing Letters, 2019</comments><doi>10.1109/LSP.2019.2944005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we take a new approach for time of arrival geo-localization.
We show that the main sources of error in metropolitan areas are due to
environmental imperfections that bias our solutions, and that we can rely on a
probabilistic model to learn and compensate for them. The resulting
localization error is validated using measurements from a live LTE cellular
network to be less than 10 meters, representing an order-of-magnitude
improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06582</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06582</id><created>2019-10-15</created><authors><author><keyname>Barkhordari</keyname><forenames>Pegah</forenames></author><author><keyname>Galeazzi</keyname><forenames>Roberto</forenames></author><author><keyname>Tejada</keyname><forenames>Alejandro de Miguel</forenames></author><author><keyname>Santos</keyname><forenames>Ilmar F.</forenames></author></authors><title>Identification of Behavioural Models for Railway Turnouts Monitoring</title><categories>eess.SY cs.SY stat.AP</categories><comments>26 pages, 15 figures, submitted for evaluation to Elsevier journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study introduces a low-complexity behavioural model to describe the
dynamic response of railway turnouts due to the ballast and railpad components.
The behavioural model should serve as the basis for the future development of a
supervisory system for the continuous monitoring of turnouts. A fourth order
linear model is proposed based on spectral analysis of measured rail vertical
accelerations gathered during a receptance test and it is then identified at
several sections of the turnout applying the Eigensystem Realization Algorithm.
The predictviness and robustness of the behavioural models have been assessed
on a large data set of train passages differing for train type, speed and
loading condition. Last, the need for a novel modeling method is argued in
relation to high-fidelity mechanistic models widely used in the railway
engineering community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06585</identifier>
 <datestamp>2020-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06585</id><created>2019-10-15</created><updated>2020-01-03</updated><authors><author><keyname>Tao</keyname><forenames>Jiyun</forenames></author><author><keyname>Xing</keyname><forenames>Jing</forenames></author><author><keyname>Chen</keyname><forenames>Jienan</forenames></author><author><keyname>Zhang</keyname><forenames>Chuan</forenames></author><author><keyname>Fu</keyname><forenames>Shengli</forenames></author></authors><title>Hybrid Beamforming/Combining for Millimeter Wave MIMO: A Machine
  Learning Approach</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid beamforming (HB) has emerged as a promising technology to support
ultra high transmission capacity and with low complexity for Millimeter Wave
(mmWave) multiple-input and multiple-output (MIMO) system. However, the design
of digital and analog beamformer is a challenge task with non-convex
optimization, especially for the multi-user scenario. Recently, the blooming of
deep learning research provides a new vision for the signal processing of
communication system. In this work, we propose a deep neural network based HB
for the multi-User mmWave massive MIMO system, referred as DNHB. The HB system
is formulated as an autoencoder neural network, which is trained in a style of
end-to-end self-supervised learning. With the strong representation capability
of deep neural network, the proposed DNHB exhibits superior performance than
the traditional linear processing methods. According to the simulation results,
DNHB outperforms about 2 dB in terms of bit error rate (BER) performance
compared with existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06635</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06635</id><created>2019-10-15</created><authors><author><keyname>Jansen</keyname><forenames>Mari&#xeb;lle J. A.</forenames></author><author><keyname>Kuijf</keyname><forenames>Hugo J.</forenames></author><author><keyname>Niekel</keyname><forenames>Maarten</forenames></author><author><keyname>Veldhuis</keyname><forenames>Wouter B.</forenames></author><author><keyname>Wessels</keyname><forenames>Frank J.</forenames></author><author><keyname>Viergever</keyname><forenames>Max A.</forenames></author><author><keyname>Pluim</keyname><forenames>Josien P. W.</forenames></author></authors><title>Liver segmentation and metastases detection in MR images using
  convolutional neural networks</title><categories>eess.IV cs.CV q-bio.QM</categories><journal-ref>J. Med. Imag. 6(4), 044003 (2019)</journal-ref><doi>10.1117/1.JMI.6.4.044003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Primary tumors have a high likelihood of developing metastases in the liver
and early detection of these metastases is crucial for patient outcome. We
propose a method based on convolutional neural networks (CNN) to detect liver
metastases. First, the liver was automatically segmented using the six phases
of abdominal dynamic contrast enhanced (DCE) MR images. Next, DCE-MR and
diffusion weighted (DW) MR images are used for metastases detection within the
liver mask. The liver segmentations have a median Dice similarity coefficient
of 0.95 compared with manual annotations. The metastases detection method has a
sensitivity of 99.8% with a median of 2 false positives per image. The
combination of the two MR sequences in a dual pathway network is proven
valuable for the detection of liver metastases. In conclusion, a high quality
liver segmentation can be obtained in which we can successfully detect liver
metastases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06638</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06638</id><created>2019-10-15</created><authors><author><keyname>Gomez-Molina</keyname><forenames>Celia</forenames></author><author><keyname>Pons-Abenza</keyname><forenames>Alejandro</forenames></author><author><keyname>Do</keyname><forenames>James</forenames></author><author><keyname>Quesada-Pereira</keyname><forenames>Fernando</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoguang</forenames></author><author><keyname>Gomez-Diaz</keyname><forenames>Juan Sebastian</forenames></author><author><keyname>Alvarez-Melcon</keyname><forenames>Alejandro</forenames></author></authors><title>Wideband Bandpass Filters Using a Novel Thick Metallization Technology</title><categories>eess.SP</categories><comments>8 pages, 13 figuras, transaction</comments><journal-ref>IEEE Access, 2020</journal-ref><doi>10.1109/ACCESS.2020.2974552</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of wideband bandpass filters based on using thick metallic bars
as microwave resonators, instead of common microstrip lines, is presented.
These bars provide a series of advantages over fully planar printed
technologies, including higher coupling levels between resonators, better
unloaded quality factors QU, and larger bandwidths, implemented with more
compact structures. Moreover, thick bar resonators can easily be coupled to an
additional resonance excited in a box used for shielding, allowing to realize
transversal topologies able to implement transmission zeros at desired
frequencies. To illustrate the capabilities of this technology, two microwave
filters with different bandwidths and one transmission zero have been designed.
One of the filters has been manufactured and tested using copper bars inside an
aluminum housing partially filled with Teflon. Measured data demonstrates a
fractional bandwidth about FBW = 32%, spurious free range SFR &gt; 50%, unloaded
quality factor of QU = 1180 and return losses over 20 dB without requiring any
post-tuning on the prototype, confirming the exciting performance of the
proposed technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06640</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06640</id><created>2019-10-15</created><authors><author><keyname>Alonso</keyname><forenames>Andr&#xe9;s M.</forenames></author><author><keyname>Nogales</keyname><forenames>F. Javier</forenames></author><author><keyname>Ruiz</keyname><forenames>Carlos</forenames></author></authors><title>A Single Scalable LSTM Model for Short-Term Forecasting of Disaggregated
  Electricity Loads</title><categories>stat.ML cs.LG eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a powerful tool to improve their efficiency and sustainability, most
electricity systems worldwide are deploying advanced metering infrastructures
to collect relevant operational data. In particular, smart meters play a key
role in this transformation as they allow tracking electricity load consumption
at a very disaggregated level and at high frequency rates. This data opens the
possibility of developing new forecasting models with a potential positive
impact in both electricity distribution and retailing activities. In this work,
we present a general methodology that is able to process and forecast a large
number of smart meter time series. Instead of using traditional and univariate
approaches for each time series, we develop a single but complex recurrent
neural network model with long short-term memory that is able to capture
individual consumption patterns and also the cross-sectional relations among
different households. The resulting model can accurately predict future loads
(short-term) of individual consumers, even if these were not included in the
original training set (out-of-sample consumers). This entails a great potential
for large scale applications (Big Data) as once the single network is trained,
accurate individual forecast for new consumers can be obtained at almost no
computational cost. The performance of the proposed model is tested under a
large set of numerical experiments by using a real world dataset with thousands
of disaggregated electricity consumption time series. Furthermore, we exploit
the considered dataset to explore how geo-demographic segmentation of consumers
can improve the forecasting accuracy of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06652</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06652</id><created>2019-10-15</created><authors><author><keyname>Jang</keyname><forenames>Youngsu</forenames></author><author><keyname>Na</keyname><forenames>Jinyeop</forenames></author><author><keyname>Jeong</keyname><forenames>Seongah</forenames></author><author><keyname>Kang</keyname><forenames>Joonhyuk</forenames></author></authors><title>Energy-Efficient Task Offloading for Vehicular Edge Computing: Joint
  Optimization of Offloading and Bit Allocation</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of vehicular networks, various applications that
require high computation resources have emerged. To efficiently execute these
applications, vehicular edge computing (VEC) can be employed. VEC offloads the
computation tasks to the VEC node, i.e., the road side unit (RSU), which
improves vehicular service and reduces energy consumption of the vehicle.
However, communication environment is time-varying due to the movement of the
vehicle, so that finding the optimal offloading parameters is still an open
problem. Therefore, it is necessary to investigate an optimal offloading
strategy for effective energy savings in energy-limited vehicles. In this
paper, we consider the changes of communication environment due to various
speeds of vehicles, which are not considered in previous studies. Then, we
jointly optimize the offloading proportion and uplink/computation/downlink bit
allocation of multiple vehicles, for the purpose of minimizing the total energy
consumption of the vehicles under the delay constraint. Numerical results
demonstrate that the proposed energy-efficient offloading strategy
significantly reduces the total energy consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06674</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06674</id><created>2019-10-15</created><authors><author><keyname>Khokhriakov</keyname><forenames>Semyon</forenames></author><author><keyname>Manumachu</keyname><forenames>Ravi Reddy</forenames></author><author><keyname>Lastovetsky</keyname><forenames>Alexey</forenames></author></authors><title>Modern Multicore CPUs are not Energy Proportional: Opportunity for
  Bi-objective Optimization for Performance and Energy</title><categories>cs.DC cs.AR cs.PF cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy proportionality is the key design goal followed by architects of
modern multicore CPUs. One of its implications is that optimization of an
application for performance will also optimize it for energy. In this work, we
show that energy proportionality does not hold true for multicore CPUs. This
finding creates the opportunity for bi-objective optimization of applications
for performance and energy. We propose and study the first application-level
method for bi-objective optimization of multithreaded data-parallel
applications for performance and energy. The method uses two decision
variables, the number of identical multithreaded kernels (threadgroups)
executing the application and the number of threads in each threadgroup, with
the workload always partitioned equally between the threadgroups. We
experimentally demonstrate the efficiency of the method using four highly
optimized multithreaded data-parallel applications, 2D fast Fourier transform
based on FFTW and Intel MKL, and dense matrix-matrix multiplication using
OpenBLAS and Intel MKL. Four modern multicore CPUs are used in the experiments.
The experiments show that optimization for performance alone results in the
increase in dynamic energy consumption by up to 89% and optimization for
dynamic energy alone degrades the performance by up to 49%. By solving the
bi-objective optimization problem, the method determines up to 11 globally
Pareto-optimal solutions. Finally, we propose a qualitative dynamic energy
model employing performance monitoring counters as parameters, which we use to
explain the discovered energy nonproportionality and the Pareto-optimal
solutions determined by our method. The model shows that the energy
nonproportionality in our case is due to the activity of the data translation
lookaside buffer (dTLB), which is disproportionately energy expensive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06693</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06693</id><created>2019-10-15</created><authors><author><keyname>Cartas</keyname><forenames>Alejandro</forenames></author><author><keyname>Luque</keyname><forenames>Jordi</forenames></author><author><keyname>Radeva</keyname><forenames>Petia</forenames></author><author><keyname>Segura</keyname><forenames>Carlos</forenames></author><author><keyname>Dimiccoli</keyname><forenames>Mariella</forenames></author></authors><title>Seeing and Hearing Egocentric Actions: How Much Can We Learn?</title><categories>cs.CV cs.LG eess.AS</categories><comments>Accepted for the Fifth International Workshop on Egocentric
  Perception, Interaction and Computing (EPIC) at the International Conference
  on Computer Vision (ICCV) 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Our interaction with the world is an inherently multimodal experience.
However, the understanding of human-to-object interactions has historically
been addressed focusing on a single modality. In particular, a limited number
of works have considered to integrate the visual and audio modalities for this
purpose. In this work, we propose a multimodal approach for egocentric action
recognition in a kitchen environment that relies on audio and visual
information. Our model combines a sparse temporal sampling strategy with a late
fusion of audio, spatial, and temporal streams. Experimental results on the
EPIC-Kitchens dataset show that multimodal integration leads to better
performance than unimodal approaches. In particular, we achieved a 5.18%
improvement over the state of the art on verb classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06697</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06697</id><created>2019-10-15</created><authors><author><keyname>Ahmed</keyname><forenames>Asad</forenames></author><author><keyname>Tangri</keyname><forenames>Pratham</forenames></author><author><keyname>Panda</keyname><forenames>Anirban</forenames></author><author><keyname>Ramani</keyname><forenames>Dhruv</forenames></author><author><keyname>Karmakar</keyname><forenames>Samarjit</forenames></author></authors><title>VFNet: A Convolutional Architecture for Accent Classification</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted at IEEE INDICON 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding accent is an issue which can derail any human-machine
interaction. Accent classification makes this task easier by identifying the
accent being spoken by a person so that the correct words being spoken can be
identified by further processing, since same noises can mean entirely different
words in different accents of the same language. In this paper, we present
VFNet (Variable Filter Net), a convolutional neural network (CNN) based
architecture which captures a hierarchy of features to beat the previous
benchmarks of accent classification, through a novel and elegant technique of
applying variable filter sizes along the frequency band of the audio
utterances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06703</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06703</id><created>2019-10-02</created><authors><author><keyname>Brown</keyname><forenames>Trevor</forenames></author><author><keyname>Narendra</keyname><forenames>Chaitanya</forenames></author><author><keyname>Vahabzadeh</keyname><forenames>Yousef</forenames></author><author><keyname>Caloz</keyname><forenames>Christophe</forenames></author><author><keyname>Mojabi</keyname><forenames>Puyan</forenames></author></authors><title>On the Use of Electromagnetic Inversion for Metasurface Design</title><categories>physics.app-ph eess.SP physics.comp-ph physics.optics</categories><comments>13 pages</comments><doi>10.1109/TAP.2019.2944544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the use of the electromagnetic inverse source framework offers
great flexibility in the design of metasurfaces. In particular, this approach
is advantageous for antenna design applications where the goal is often to
satisfy a set of performance criteria such as half power beamwidths and null
directions, rather than satisfying a fully-known complex field. In addition,
the inverse source formulation allows the metasurface and the region over which
the desired field specifications are provided to be of arbitrary shape. Some of
the main challenges in solving this inverse source problem, such as formulating
and optimizing a nonlinear cost functional, are addressed. Lastly, some
two-dimensional (2D) and three-dimensional (3D) simulated examples are
presented to demonstrate the method, followed by a discussion of the method's
current limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06711</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06711</id><created>2019-10-08</created><updated>2019-12-08</updated><authors><author><keyname>Kumar</keyname><forenames>Kundan</forenames></author><author><keyname>Kumar</keyname><forenames>Rithesh</forenames></author><author><keyname>de Boissiere</keyname><forenames>Thibault</forenames></author><author><keyname>Gestin</keyname><forenames>Lucas</forenames></author><author><keyname>Teoh</keyname><forenames>Wei Zhen</forenames></author><author><keyname>Sotelo</keyname><forenames>Jose</forenames></author><author><keyname>de Brebisson</keyname><forenames>Alexandre</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author></authors><title>MelGAN: Generative Adversarial Networks for Conditional Waveform
  Synthesis</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous works (Donahue et al., 2018a; Engel et al., 2019a) have found that
generating coherent raw audio waveforms with GANs is challenging. In this
paper, we show that it is possible to train GANs reliably to generate high
quality coherent waveforms by introducing a set of architectural changes and
simple training techniques. Subjective evaluation metric (Mean Opinion Score,
or MOS) shows the effectiveness of the proposed approach for high quality
mel-spectrogram inversion. To establish the generality of the proposed
techniques, we show qualitative results of our model in speech synthesis, music
domain translation and unconditional music synthesis. We evaluate the various
components of the model through ablation studies and suggest a set of
guidelines to design general purpose discriminators and generators for
conditional sequence synthesis tasks. Our model is non-autoregressive, fully
convolutional, with significantly fewer parameters than competing models and
generalizes to unseen speakers for mel-spectrogram inversion. Our pytorch
implementation runs at more than 100x faster than realtime on GTX 1080Ti GPU
and more than 2x faster than real-time on CPU, without any hardware specific
optimization tricks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06715</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06715</id><created>2019-10-04</created><authors><author><keyname>Zhang</keyname><forenames>Jin</forenames></author><author><keyname>Li</keyname><forenames>Jingyue</forenames></author></authors><title>Testing and verification of neural-network-based safety-critical control
  software: A systematic literature review</title><categories>cs.LG cs.SE cs.SY eess.SY</categories><comments>This paper had been submitted to Journal of Information and Software
  Technology on April 20, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context: Neural Network (NN) algorithms have been successfully adopted in a
number of Safety-Critical Cyber-Physical Systems (SCCPSs). Testing and
Verification (T&amp;V) of NN-based control software in safety-critical domains are
gaining interest and attention from both software engineering and safety
engineering researchers and practitioners. Objective: With the increase in
studies on the T&amp;V of NN-based control software in safety-critical domains, it
is important to systematically review the state-of-the-art T&amp;V methodologies,
to classify approaches and tools that are invented, and to identify challenges
and gaps for future studies. Method: We retrieved 950 papers on the T&amp;V of
NN-based Safety-Critical Control Software (SCCS). To reach our result, we
filtered 83 primary papers published between 2001 and 2018, applied the
thematic analysis approach for analyzing the data extracted from the selected
papers, presented the classification of approaches, and identified challenges.
Conclusion: The approaches were categorized into five high-order themes:
assuring robustness of NNs, assuring safety properties of NN-based control
software, improving the failure resilience of NNs, measuring and ensuring test
completeness, and improving the interpretability of NNs. From the industry
perspective, improving the interpretability of NNs is a crucial need in
safety-critical applications. We also investigated nine safety integrity
properties within four major safety lifecycle phases to investigate the
achievement level of T&amp;V goals in IEC 61508-3. Results show that correctness,
completeness, freedom from intrinsic faults, and fault tolerance have drawn
most attention from the research community. However, little effort has been
invested in achieving repeatability; no reviewed study focused on precisely
defined testing configuration or on defense against common cause failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06731</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06731</id><created>2019-10-14</created><authors><author><keyname>Zhou</keyname><forenames>Cheng</forenames></author><author><keyname>Zhao</keyname><forenames>Xiwei</forenames></author><author><keyname>Huang</keyname><forenames>Heyan</forenames></author><author><keyname>Wang</keyname><forenames>Gangcheng</forenames></author><author><keyname>Wang</keyname><forenames>Xue</forenames></author><author><keyname>Song</keyname><forenames>Lijun</forenames></author><author><keyname>Xue</keyname><forenames>Kang</forenames></author></authors><title>Hadamard `Pipeline' Coding Computational Ghost Imaging</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hadamard matrix with orthogonality is a more important modulation matrix
for computational ghost imaging (CGI), especially its optimized Hadamard
matrix. However, as far as we know, little mention has been paid to efficient
and convenient Hadamard matrix generation for CGI. The existing methods are to
reconstruct any row of Hadamard matrix into two-dimensional matrix and then
optimize it. In this work, we propose a Hadamard `pipeline' coding
computational ghost imaging approach, which can directly generate
two-dimensional Hadamard derived pattern and Hadamard optimization sequence,
whereby both the memory consumption and the complexity of coding implementation
for CGI can be significantly reduced. The optimization method of commonly used
hadamard optimization sequence implementation is also discussed. This method
provides a new approach for Hadamard sequence optimization and ghost imaging
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06734</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06734</id><created>2019-10-10</created><authors><author><keyname>Haji</keyname><forenames>Aliasgar</forenames></author><author><keyname>Shah</keyname><forenames>Priyam</forenames></author><author><keyname>Bijoor</keyname><forenames>Srinivas</forenames></author></authors><title>Self Driving RC Car using Behavioral Cloning</title><categories>cs.RO cs.CV cs.SY eess.SY</categories><comments>4 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self Driving Car technology is a vehicle that guides itself without human
conduction. The first truly autonomous cars appeared in the 1980s with projects
funded by DARPA( Defense Advance Research Project Agency ). Since then a lot
has changed with the improvements in the fields of Computer Vision and Machine
Learning. We have used the concept of behavioral cloning to convert a normal RC
model car into an autonomous car using Deep Learning technology
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06741</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06741</id><created>2019-10-13</created><authors><author><keyname>Polanco</keyname><forenames>Luis</forenames></author><author><keyname>Perea</keyname><forenames>Jose A.</forenames></author></authors><title>Adaptive template systems: Data-driven feature selection for learning
  with persistence diagrams</title><categories>cs.LG cs.CG eess.IV math.AT stat.ML</categories><comments>To appear in proceedings of IEEE ICMLA 2019</comments><msc-class>55U99 (Primary) 68W05, 55N99 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature extraction from persistence diagrams, as a tool to enrich machine
learning techniques, has received increasing attention in recent years. In this
paper we explore an adaptive methodology to localize features in persistent
diagrams, which are then used in learning tasks. Specifically, we investigate
three algorithms, CDER, GMM and HDBSCAN, to obtain adaptive template
functions/features. Said features are evaluated in three classification
experiments with persistence diagrams. Namely, manifold, human shapes and
protein classification. The main conclusion of our analysis is that adaptive
template systems, as a feature extraction technique, yield competitive and
often superior results in the studied examples. Moreover, from the adaptive
algorithms here studied, CDER consistently provides the most reliable and
robust adaptive featurization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06742</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06742</id><created>2019-10-11</created><updated>2019-10-23</updated><authors><author><keyname>Fang</keyname><forenames>Song</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>Generic Bounds on the Maximum Deviations in Sequential Prediction: An
  Information-Theoretic Analysis</title><categories>cs.LG cs.IT eess.SP math.IT math.ST stat.ML stat.TH</categories><comments>arXiv admin note: text overlap with arXiv:1904.04765</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive generic bounds on the maximum deviations in
prediction errors for sequential prediction via an information-theoretic
approach. The fundamental bounds are shown to depend only on the conditional
entropy of the data point to be predicted given the previous data points. In
the asymptotic case, the bounds are achieved if and only if the prediction
error is white and uniformly distributed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06745</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06745</id><created>2019-10-12</created><updated>2019-11-13</updated><authors><author><keyname>Zhang</keyname><forenames>Yundong</forenames></author><author><keyname>Wu</keyname><forenames>Hang</forenames></author><author><keyname>Liu</keyname><forenames>Huiye</forenames></author><author><keyname>Tong</keyname><forenames>Li</forenames></author><author><keyname>Wang</keyname><forenames>May D</forenames></author></authors><title>Improve Model Generalization and Robustness to Dataset Bias with
  Bias-regularized Learning and Domain-guided Augmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Learning has thrived on the emergence of biomedical big data. However,
medical datasets acquired at different institutions have inherent bias caused
by various confounding factors such as operation policies, machine protocols,
treatment preference and etc. As the result, models trained on one dataset,
regardless of volume, cannot be confidently utilized for the others. In this
study, we investigated model robustness to dataset bias using three large-scale
Chest X-ray datasets: first, we assessed the dataset bias using vanilla
training baseline; second, we proposed a novel multi-source domain
generalization model by (a) designing a new bias-regularized loss function; and
(b) synthesizing new data for domain augmentation. We showed that our model
significantly outperformed the baseline and other approaches on data from
unseen domain in terms of accuracy and various bias measures, without
retraining or finetuning. Our method is generally applicable to other
biomedical data, providing new algorithms for training models robust to bias
for big data analysis and applications. Demo training code is publicly
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06749</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06749</id><created>2019-10-12</created><authors><author><keyname>Gong</keyname><forenames>Yu</forenames></author><author><keyname>Teng</keyname><forenames>Yueyang</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Xiao</keyname><forenames>Taohui</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Liang</keyname><forenames>Guodong</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author></authors><title>Parameter Constrained Transfer Learning for Low Dose PET Image Denoising</title><categories>eess.IV cs.LG stat.ML</categories><comments>10 pages and 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Positron emission tomography (PET) is widely used in clinical practice.
However, the potential risk of PET-associated radiation dose to patients needs
to be minimized. With reduction of the radiation dose, the resultant images may
suffer from noise and artifacts which compromises the diagnostic performance.
In this paper, we propose a parameter-constrained generative adversarial
network with Wasserstein distance and perceptual loss (PC-WGAN) for low-dose
PET image denoising. This method makes two main contributions: 1) a PC-WGAN
framework is designed to denoise low-dose PET images without compromising
structural details; and 2) a transfer learning strategy is developed to train
PC-WGAN with parameters being constrained, which has major merits; namely,
making the training process of PC-WGAN efficient and improving the quality of
denoised images. The experimental results on clinical data show that the
proposed network can suppress image noise more effectively while preserving
better image fidelity than three selected state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06750</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06750</id><created>2019-10-15</created><updated>2020-02-18</updated><authors><author><keyname>Jegorova</keyname><forenames>Marija</forenames></author><author><keyname>Karjalainen</keyname><forenames>Antti Ilari</forenames></author><author><keyname>Vazquez</keyname><forenames>Jose</forenames></author><author><keyname>Hospedales</keyname><forenames>Timothy</forenames></author></authors><title>Full-Scale Continuous Synthetic Sonar Data Generation with Markov
  Conditional Generative Adversarial Networks</title><categories>cs.LG eess.IV stat.ML</categories><comments>6 pages, 6 figures. Accepted to ICRA2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deployment and operation of autonomous underwater vehicles is expensive and
time-consuming. High-quality realistic sonar data simulation could be of
benefit to multiple applications, including training of human operators for
post-mission analysis, as well as tuning and validation of autonomous target
recognition (ATR) systems for underwater vehicles. Producing realistic
synthetic sonar imagery is a challenging problem as the model has to account
for specific artefacts of real acoustic sensors, vehicle altitude, and a
variety of environmental factors. We propose a novel method for generating
realistic-looking sonar side-scans of full-length missions, called Markov
Conditional pix2pix (MC-pix2pix). Quantitative assessment results confirm that
the quality of the produced data is almost indistinguishable from real.
Furthermore, we show that bootstrapping ATR systems with MC-pix2pix data can
improve the performance. Synthetic data is generated 18 times faster than real
acquisition speed, with full user control over the topography of the generated
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06761</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06761</id><created>2019-10-13</created><authors><author><keyname>Li</keyname><forenames>Zijian</forenames></author><author><keyname>Cai</keyname><forenames>Ruichu</forenames></author><author><keyname>Chai</keyname><forenames>Kok Soon</forenames></author><author><keyname>Ng</keyname><forenames>Hong Wei</forenames></author><author><keyname>Vu</keyname><forenames>Hoang Dung</forenames></author><author><keyname>Winslett</keyname><forenames>Marianne</forenames></author><author><keyname>Fu</keyname><forenames>Tom Z. J.</forenames></author><author><keyname>Xu</keyname><forenames>Boyan</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenjie</forenames></author></authors><title>Causal Mechanism Transfer Network for Time Series Domain Adaptation in
  Mechanical Systems</title><categories>cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven models are becoming essential parts in modern mechanical systems,
commonly used to capture the behavior of various equipment and varying
environmental characteristics. Despite the advantages of these data-driven
models on excellent adaptivity to high dynamics and aging equipment, they are
usually hungry to massive labels over historical data, mostly contributed by
human engineers at an extremely high cost. The label demand is now the major
limiting factor to modeling accuracy, hindering the fulfillment of visions for
applications. Fortunately, domain adaptation enhances the model generalization
by utilizing the labelled source data as well as the unlabelled target data and
then we can reuse the model on different domains. However, the mainstream
domain adaptation methods cannot achieve ideal performance on time series data,
because most of them focus on static samples and even the existing time series
domain adaptation methods ignore the properties of time series data, such as
temporal causal mechanism. In this paper, we assume that causal mechanism is
invariant and present our Causal Mechanism Transfer Network(CMTN) for time
series domain adaptation. By capturing and transferring the dynamic and
temporal causal mechanism of multivariate time series data and alleviating the
time lags and different value ranges among different machines, CMTN allows the
data-driven models to exploit existing data and labels from similar systems,
such that the resulting model on a new system is highly reliable even with very
limited data. We report our empirical results and lessons learned from two
real-world case studies, on chiller plant energy optimization and boiler fault
detection, which outperforms the existing state-of-the-art method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06762</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06762</id><created>2019-10-13</created><updated>2020-02-11</updated><authors><author><keyname>Kim</keyname><forenames>Jaeyoung</forenames></author><author><keyname>El-Khamy</keyname><forenames>Mostafa</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author></authors><title>T-GSA: Transformer with Gaussian-weighted self-attention for speech
  enhancement</title><categories>eess.AS cs.SD</categories><comments>5 pages, Submitted to ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformer neural networks (TNN) demonstrated state-of-art performance on
many natural language processing (NLP) tasks, replacing recurrent neural
networks (RNNs), such as LSTMs or GRUs. However, TNNs did not perform well in
speech enhancement, whose contextual nature is different than NLP tasks, like
machine translation. Self-attention is a core building block of the
Transformer, which not only enables parallelization of sequence computation,
but also provides the constant path length between symbols that is essential to
learning long-range dependencies. In this paper, we propose a Transformer with
Gaussian-weighted self-attention (T-GSA), whose attention weights are
attenuated according to the distance between target and context symbols. The
experimental results show that the proposed T-GSA has significantly improved
speech-enhancement performance, compared to the Transformer and RNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06777</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06777</id><created>2019-10-14</created><authors><author><keyname>Tang</keyname><forenames>Chao</forenames></author><author><keyname>Zhang</keyname><forenames>Wenkun</forenames></author><author><keyname>Li</keyname><forenames>Haiting</forenames></author><author><keyname>Li</keyname><forenames>Lei</forenames></author><author><keyname>Li</keyname><forenames>Ziheng</forenames></author><author><keyname>Cai</keyname><forenames>Ailong</forenames></author><author><keyname>Wang</keyname><forenames>Linyuan</forenames></author><author><keyname>Shi</keyname><forenames>Dapeng</forenames></author><author><keyname>Yan</keyname><forenames>Bin</forenames></author></authors><title>CNN-based Automatic Detection of Bone Conditions via Diagnostic CT
  Images for Osteoporosis Screening</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: The purpose is to design a novelty automatic diagnostic method for
osteoporosis screening by using the potential capability of convolutional
neural network (CNN) in feature representation and extraction, which can be
incorporated into the procedure of routine CT diagnostic in physical
examination thereby improving the osteoporosis diagnosis and reducing the
patient burden. Methods: The proposed convolutional neural network-based method
mainly comprises two functional modules to perform automatic detection of bone
condition by analyzing the diagnostic CT image. The first functional module
aims to locate and segment the ROI of diagnostic CT image, called
Mark-Segmentation-Network (MS-Net). The second functional module is used to
determine the category of bone condition by the features of ROI, called
Bone-Conditions-Classification-Network (BCC-Net). The trained MS-Net can get
the mark image of inputted original CT image, thereby obtain the segmentation
image. The trained BCC-Net can obtain the probability value of normal bone
mass, low bone mass, and osteoporosis by inputting the segmentation image. On
the basis of network results, the radiologists can provide preliminary
qualitative diagnosis results of bone condition. Results: The proposed MS-Net
has an excellent segmentation precision on the shape preservation of different
lumbar vertebra. The numerical indicators of segmentation results are greater
than 0.998. The proposed BCC-Net was evaluated with 3,024 clinical images and
achieved an accuracy of 76.65% and an area under the receiver operating
characteristic curve of 0.9167. Conclusions: This study proposed a novel
two-step method for automatic detection of bone conditions via diagnostic CT
images and it has great potential in clinical applications for osteoporosis
screening. The method can potentially reduce the manual burden to radiologists
and diagnostic cost to patients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06781</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06781</id><created>2019-10-14</created><authors><author><keyname>Potapov</keyname><forenames>Pavel</forenames></author><author><keyname>Lubk</keyname><forenames>Axel</forenames></author></authors><title>Optimal principal component Analysis of STEM XEDS spectrum images</title><categories>eess.IV physics.data-an</categories><comments>21 pages, 14 figures</comments><journal-ref>Advanced Structural and Chemical Imaging (2019) 5:4</journal-ref><doi>10.1186/s40679-019-0066-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  STEM XEDS spectrum images can be drastically denoised by application of the
principal component analysis (PCA). This paper looks inside the PCA workflow
step by step on an example of a complex semiconductor structure consisting of a
number of different phases. Typical problems distorting the principal
components decomposition are highlighted and solutions for the successful PCA
are described. Particular attention is paid to the optimal truncation of
principal components in the course of reconstructing denoised data. A novel
accurate and robust method, which overperforms the existing truncation methods
is suggested for the first time and described in details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06784</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06784</id><created>2019-10-14</created><authors><author><keyname>Cho</keyname><forenames>Janghoon</forenames></author><author><keyname>Yun</keyname><forenames>Sungrack</forenames></author><author><keyname>Park</keyname><forenames>Hyoungwoo</forenames></author><author><keyname>Eum</keyname><forenames>Jungyun</forenames></author><author><keyname>Hwang</keyname><forenames>Kyuwoong</forenames></author></authors><title>Acoustic Scene Classification Based on a Large-margin Factorized CNN</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, DCASE 2019 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an acoustic scene classification framework based on
a large-margin factorized convolutional neural network (CNN). We adopt the
factorized CNN to learn the patterns in the time-frequency domain by
factorizing the 2D kernel into two separate 1D kernels. The factorized kernel
leads to learn the main component of two patterns: the long-term ambient and
short-term event sounds which are the key patterns of the audio scene
classification. In training our model, we consider the loss function based on
the triplet sampling such that the same audio scene samples from different
environments are minimized, and simultaneously the different audio scene
samples are maximized. With this loss function, the samples from the same audio
scene are clustered independently of the environment, and thus we can get the
classifier with better generalization ability in an unseen environment. We
evaluated our audio scene classification framework using the dataset of the
DCASE challenge 2019 task1A. Experimental results show that the proposed
algorithm improves the performance of the baseline network and reduces the
number of parameters to one third. Furthermore, the performance gain is higher
on unseen data, and it shows that the proposed algorithm has better
generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06788</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06788</id><created>2019-10-14</created><authors><author><keyname>Gunarathna</keyname><forenames>Udesh</forenames></author><author><keyname>Xie</keyname><forenames>Hairuo</forenames></author><author><keyname>Tanin</keyname><forenames>Egemen</forenames></author><author><keyname>Karunasekara</keyname><forenames>Shanika</forenames></author><author><keyname>Borovica-Gajic</keyname><forenames>Renata</forenames></author></authors><title>Dynamic Graph Configuration with Reinforcement Learning for Connected
  Autonomous Vehicle Trajectories</title><categories>eess.SY cs.DB cs.LG cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional traffic optimization solutions assume that the graph structure of
road networks is static, missing opportunities for further traffic flow
optimization. We are interested in optimizing traffic flows as a new type of
graph-based problem, where the graph structure of a road network can adapt to
traffic conditions in real time. In particular, we focus on the dynamic
configuration of traffic-lane directions, which can help balance the usage of
traffic lanes in opposite directions. The rise of connected autonomous vehicles
offers an opportunity to apply this type of dynamic traffic optimization at a
large scale. The existing techniques for optimizing lane-directions are however
not suitable for dynamic traffic environments due to their high computational
complexity and the static nature.
  In this paper, we propose an efficient traffic optimization solution, called
Coordinated Learning-based Lane Allocation (CLLA), which is suitable for
dynamic configuration of lane-directions. CLLA consists of a two-layer
multi-agent architecture, where the bottom-layer agents use a machine learning
technique to find a suitable configuration of lane-directions around individual
road intersections. The lane-direction changes proposed by the learning agents
are then coordinated at a higher level to reduce the negative impact of the
changes on other parts of the road network. Our experimental results show that
CLLA can reduce the average travel time significantly in congested road
networks. We believe our method is general enough to be applied to other types
of networks as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06790</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06790</id><created>2019-10-14</created><authors><author><keyname>Park</keyname><forenames>Hyoungwoo</forenames></author><author><keyname>Yun</keyname><forenames>Sungrack</forenames></author><author><keyname>Eum</keyname><forenames>Jungyun</forenames></author><author><keyname>Cho</keyname><forenames>Janghoon</forenames></author><author><keyname>Hwang</keyname><forenames>Kyuwoong</forenames></author></authors><title>Weakly Labeled Sound Event Detection Using Tri-training and Adversarial
  Learning</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, DCASE 2019 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a semi-supervised learning framework for weakly labeled
polyphonic sound event detection problems for the DCASE 2019 challenge's task4
by combining both the tri-training and adversarial learning. The goal of the
task4 is to detect onsets and offsets of multiple sound events in a single
audio clip. The entire dataset consists of the synthetic data with a strong
label (sound event labels with boundaries) and real data with weakly labeled
(sound event labels) and unlabeled dataset. Given this dataset, we apply the
tri-training where two different classifiers are used to obtain pseudo labels
on the weakly labeled and unlabeled dataset, and the final classifier is
trained using the strongly labeled dataset and weakly/unlabeled dataset with
pseudo labels. Also, we apply the adversarial learning to reduce the domain gap
between the real and synthetic dataset. We evaluated our learning framework
using the validation set of the task4 dataset, and in the experiments, our
learning framework shows a considerable performance improvement over the
baseline model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06797</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06797</id><created>2019-10-15</created><authors><author><keyname>Miraglia</keyname><forenames>Giovanni</forenames></author><author><keyname>Hook</keyname><forenames>Loyd</forenames><suffix>IV</suffix></author></authors><title>Feedback Motion Plan Verification for Vehicles with Bounded Curvature
  Constraints</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The kinematic approximation of Dubin's Vehicle has been largely exploited in
the formulation of various motion planning methods. In the majority of these
methods, planning and control phases are decoupled, and the burden of rejecting
disturbances is left to the controller. An alternative to this approach is the
use of a feedback motion plan, where for each state there is a specific
pre-computed action that will be executed. This planning approach provides the
ability to verify all trajectories off-line. The verification can be performed
using backward reachability, which provides the set of configurations from
which a region is reachable. In this paper, we formulate a verification process
that relies on the computation of the backward reachable set using geometric
principles. In addition to the theoretical foundation of the method, we provide
a numerical implementation of the method and we illustrate a practical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06809</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06809</id><created>2019-10-15</created><updated>2020-01-10</updated><authors><author><keyname>Liu</keyname><forenames>Xihui</forenames></author><author><keyname>Yin</keyname><forenames>Guojun</forenames></author><author><keyname>Shao</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Xiaogang</forenames></author><author><keyname>Li</keyname><forenames>Hongsheng</forenames></author></authors><title>Learning to Predict Layout-to-image Conditional Convolutions for
  Semantic Image Synthesis</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by NeurIPS 2019. Code is available soon at
  https://github.com/xh-liu/CC-FPSE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic image synthesis aims at generating photorealistic images from
semantic layouts. Previous approaches with conditional generative adversarial
networks (GAN) show state-of-the-art performance on this task, which either
feed the semantic label maps as inputs to the generator, or use them to
modulate the activations in normalization layers via affine transformations. We
argue that convolutional kernels in the generator should be aware of the
distinct semantic labels at different locations when generating images. In
order to better exploit the semantic layout for the image generator, we propose
to predict convolutional kernels conditioned on the semantic label map to
generate the intermediate feature maps from the noise maps and eventually
generate the images. Moreover, we propose a feature pyramid semantics-embedding
discriminator, which is more effective in enhancing fine details and semantic
alignments between the generated images and the input semantic layouts than
previous multi-scale discriminators. We achieve state-of-the-art results on
both quantitative metrics and subjective evaluation on various semantic
segmentation datasets, demonstrating the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06824</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06824</id><created>2019-10-03</created><updated>2019-12-31</updated><authors><author><keyname>Nkurikiyeyezu</keyname><forenames>Kizito</forenames></author><author><keyname>Yokokubo</keyname><forenames>Anna</forenames></author><author><keyname>Lopez</keyname><forenames>Guillaume</forenames></author></authors><title>Affect-aware thermal comfort provision in intelligent buildings</title><categories>cs.HC eess.IV eess.SP</categories><doi>10.1109/ACIIW.2019.8925184</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predominant thermal comfort provision technologies are energy-hungry, and yet
they perform crudely because they overlook the requisite precursors to thermal
comfort. They also fail to exclusively cool or heat the parts of the body
(e.g., the wrist, the feet, and the head) that influence the most a person's
thermal comfort satisfaction. Instead, they waste energy by heating or cooling
the whole room. This research investigates the influence of neck-coolers on
people's thermal comfort perception and proposes an effective method that
delivers thermal comfort depending on people's heart rate variability (HRV).
Moreover, because thermal comfort is idiosyncratic and depends on unforeseeable
circumstances, only person-specific thermal comfort models are adequate for
this task. Unfortunately, using person-specific models would be costly and
inflexible for deployment in, e.g., a smart building because a system that uses
person-specific models would require collecting extensive training data from
each person in the building. As a compromise, we devise a hybrid,
cost-effective, yet satisfactory technique that derives a personalized
person-specific-like model from samples collected from a large population. For
example, it was possible to double the accuracy of a generic model (from 47.77%
to 96.11%) using only 400 person-specific calibration samples. Finally, we
propose a practical implementation of a real-time thermal comfort provision
system that uses this strategy and highlighted its advantages and limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06828</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06828</id><created>2019-10-15</created><authors><author><keyname>Carriere</keyname><forenames>Thomas</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Vernay</keyname><forenames>Christophe</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Pitaval</keyname><forenames>Sebastien</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Neirac</keyname><forenames>Franccois-Pascal</forenames><affiliation>PERSEE</affiliation></author><author><keyname>Kariniotakis</keyname><forenames>George</forenames><affiliation>PERSEE</affiliation></author></authors><title>Sizing of a PV/Battery System Through Stochastic Control and Plant
  Aggregation</title><categories>eess.SY cs.SY</categories><proxy>ccsd</proxy><journal-ref>36th European PV Solar Energy Conference and Exhibition (EU
  PVSEC), Sep 2019, Marseille, France</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this work is to reduce the storage dimensions required to
operate a coupled photovoltaic (PV) and Battery Energy Storage System (BESS) in
an electricity market, while keeping the same level of performance. Performance
is measured either with the amount of errors between the energy sold on the
market and the actual generation of the PV/BESS i.e. the imbalance, or directly
with the revenue generated on the electricity market from the PV/BESS
operation. Two solutions are proposed and tested to reduce the BESS size
requirement. The first solution is to participate in electricity markets with
an aggregation of several plants instead of a single plant, which effectively
reduces the uncertainty of the PV power generation. The second is to
participate in an intra-day market to reduce the BESS usage. To evaluate the
effects of these two solutions on the BESS size requirement, we simulate the
control of the PV/BESS system in an electricity market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06832</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06832</id><created>2019-10-15</created><updated>2019-12-15</updated><authors><author><keyname>Tanaka</keyname><forenames>Akinori</forenames></author></authors><title>Discriminator optimal transport</title><categories>stat.ML cs.LG eess.IV</categories><comments>github link added, NeurIPS2019</comments><report-no>RIKEN-iTHEMS-Report-19</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within a broad class of generative adversarial networks, we show that
discriminator optimization process increases a lower bound of the dual cost
function for the Wasserstein distance between the target distribution $p$ and
the generator distribution $p_G$. It implies that the trained discriminator can
approximate optimal transport (OT) from $p_G$ to $p$.Based on some experiments
and a bit of OT theory, we propose a discriminator optimal transport (DOT)
scheme to improve generated images. We show that it improves inception score
and FID calculated by un-conditional GAN trained by CIFAR-10, STL-10 and a
public pre-trained model of conditional GAN by ImageNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06849</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06849</id><created>2019-10-15</created><authors><author><keyname>Li</keyname><forenames>Guohao</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Matthias</forenames></author><author><keyname>Qian</keyname><forenames>Guocheng</forenames></author><author><keyname>Delgadillo</keyname><forenames>Itzel C.</forenames></author><author><keyname>Abualshour</keyname><forenames>Abdulellah</forenames></author><author><keyname>Thabet</keyname><forenames>Ali</forenames></author><author><keyname>Ghanem</keyname><forenames>Bernard</forenames></author></authors><title>DeepGCNs: Making GCNs Go as Deep as CNNs</title><categories>cs.CV cs.LG eess.IV</categories><comments>First two authors contributed equally. This work is a journal
  extension of our ICCV'19 paper arXiv:1904.03751</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNNs) have been very successful at solving a
variety of computer vision tasks such as object classification and detection,
semantic segmentation, activity understanding, to name just a few. One key
enabling factor for their great performance has been the ability to train very
deep CNNs. Despite their huge success in many tasks, CNNs do not work well with
non-Euclidean data which is prevalent in many real-world applications. Graph
Convolutional Networks (GCNs) offer an alternative that allows for
non-Eucledian data as input to a neural network similar to CNNs. While GCNs
already achieve encouraging results, they are currently limited to shallow
architectures with 2-4 layers due to vanishing gradients during training. This
work transfers concepts such as residual/dense connections and dilated
convolutions from CNNs to GCNs in order to successfully train very deep GCNs.
We show the benefit of deep GCNs with as many as 112 layers experimentally
across various datasets and tasks. Specifically, we achieve state-of-the-art
performance in part segmentation and semantic segmentation on point clouds and
in node classification of protein functions across biological protein-protein
interaction (PPI) graphs. We believe that the insights in this work will open a
lot of avenues for future research on GCNs and transfer to further tasks not
explored in this work. The source code for this work is available for Pytorch
and Tensorflow at https://github.com/lightaime/deep_gcns_torch and
https://github.com/lightaime/deep_gcns respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06851</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06851</id><created>2019-10-15</created><updated>2019-10-17</updated><authors><author><keyname>Lai-Tim</keyname><forenames>Yann</forenames></author><author><keyname>Mugnier</keyname><forenames>Laurent M.</forenames></author><author><keyname>Orieux</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Baena-Gall&#xe9;</keyname><forenames>Roberto</forenames></author><author><keyname>Paques</keyname><forenames>Michel</forenames></author><author><keyname>Meimon</keyname><forenames>Serge</forenames></author></authors><title>Jointly super-resolved and optically sectioned Bayesian reconstruction
  method for structured illumination microscopy</title><categories>physics.optics eess.IV</categories><comments>17 pages, 9 figures, accepted manuscript for Optics Express</comments><doi>10.1364/OE.27.033251</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured Illumination Microscopy (SIM) is an imaging technique for
achieving both super-resolution (SR) and optical sectioning (OS) in wide-field
microscopy. It consists in illuminating the sample with periodic patterns at
different orientations and positions. The resulting images are then processed
to reconstruct the observed object with SR and/or OS. In this work, we present
BOSSA-SIM, a general-purpose SIM reconstruction method, applicable to moving
objects such as encountered in in vivo retinal imaging, that enables SR and OS
jointly in a fully unsupervised Bayesian framework. By modeling a 2-layer
object composed of an in-focus layer and a defocused layer, we show that
BOSSA-SIM is able to jointly reconstruct them so as to get a super-resolved and
optically sectioned in-focus layer. The achieved performance, assessed
quantitatively by simulations for several noise levels, compares favorably with
a state-of-the-art method. Finally, we validate our method on open-access
experimental microscopy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06895</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06895</id><created>2019-10-15</created><authors><author><keyname>Gao</keyname><forenames>Zhihui</forenames></author><author><keyname>Gao</keyname><forenames>Yunfan</forenames></author><author><keyname>Wang</keyname><forenames>Sulei</forenames></author><author><keyname>Li</keyname><forenames>Dan</forenames></author><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author><author><keyname>Jiang</keyname><forenames>Hongbo</forenames></author></authors><title>CRISLoc: Reconstructable CSI Fingerprintingfor Indoor Smartphone
  Localization</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel state information (CSI) based fingerprinting for WIFI indoor
localization has attracted lots of attention very recently.The frequency
diverse and temporally stable CSI better represents the location dependent
channel characteristics than the coarsereceived signal strength (RSS). However,
the acquisition of CSI requires the cooperation of access points (APs) and
involves only dataframes, which imposes restrictions on real-world deployment.
In this paper, we present CRISLoc, the first CSI fingerprinting
basedlocalization prototype system using ubiquitous smartphones. CRISLoc
operates in a completely passive mode, overhearing thepackets on-the-fly for
his own CSI acquisition. The smartphone CSI is sanitized via calibrating the
distortion enforced by WiFi amplifiercircuits. CRISLoc tackles the challenge of
altered APs with a joint clustering and outlier detection method to find them.
A novel transferlearning approach is proposed to reconstruct the
high-dimensional CSI fingerprint database on the basis of the outdated
fingerprintsand a few fresh measurements, and an enhanced KNN approach is
proposed to pinpoint the location of a smartphone. Our studyreveals important
properties about the stability and sensitivity of smartphone CSI that has not
been reported previously. Experimentalresults show that CRISLoc can achieve a
mean error of around 0.29m in a6m times 8mresearch laboratory. The mean error
increases by 5.4 cm and 8.6 cm upon the movement of one and two APs, which
validates the robustness of CRISLoc against environment changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06940</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06940</id><created>2019-10-15</created><authors><author><keyname>Liang</keyname><forenames>Kaichao</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author><author><keyname>Yang</keyname><forenames>Yirong</forenames></author><author><keyname>Yang</keyname><forenames>HongKai</forenames></author><author><keyname>Xing</keyname><forenames>Yuxiang</forenames></author></authors><title>A Model-based Deep Learning Reconstruction for X-ray CT</title><categories>physics.med-ph eess.IV</categories><comments>9 pages, 3 figures, conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Low dose CT is of great interest in these days. Dose reduction raises noise
level in projections and decrease image quality in reconstructions. Model based
image reconstruction can combine statistical noise model together with prior
knowledge into an Bayesian optimization problem so that significantly reduce
noise and artefacts. In this work, we propose a model-base deep learning for CT
reconstruction so that a reconstruction network can be trained with no
ground-truth images needed. Instead of minimizing cost function for each image,
the network learns to minimize an ensemble cost function for the whole training
set. No iteration will be needed for real data reconstruction using such a
trained network. We experimented with a penalized weighted least-squares (PWLS)
cost function for low dose CT reconstruction and tested on data from a
practical dental CT. Very encouraging results with great noise reductions are
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06950</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06950</id><created>2019-10-15</created><authors><author><keyname>Dvornek</keyname><forenames>Nicha C.</forenames></author><author><keyname>Li</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Zhuang</keyname><forenames>Juntang</forenames></author><author><keyname>Duncan</keyname><forenames>James S.</forenames></author></authors><title>Jointly Discriminative and Generative Recurrent Neural Networks for
  Learning from fMRI</title><categories>eess.IV cs.LG q-bio.NC stat.AP stat.ML</categories><comments>10th International Workshop on Machine Learning in Medical Imaging
  (MLMI 2019)</comments><doi>10.1007/978-3-030-32692-0_44</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks (RNNs) were designed for dealing with time-series
data and have recently been used for creating predictive models from functional
magnetic resonance imaging (fMRI) data. However, gathering large fMRI datasets
for learning is a difficult task. Furthermore, network interpretability is
unclear. To address these issues, we utilize multitask learning and design a
novel RNN-based model that learns to discriminate between classes while
simultaneously learning to generate the fMRI time-series data. Employing the
long short-term memory (LSTM) structure, we develop a discriminative model
based on the hidden state and a generative model based on the cell state. The
addition of the generative model constrains the network to learn functional
communities represented by the LSTM nodes that are both consistent with the
data generation as well as useful for the classification task. We apply our
approach to the classification of subjects with autism vs. healthy controls
using several datasets from the Autism Brain Imaging Data Exchange. Experiments
show that our jointly discriminative and generative model improves
classification learning while also producing robust and meaningful functional
communities for better model understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06960</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06960</id><created>2019-10-15</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Alrabeiah</keyname><forenames>Muhammad</forenames></author><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author></authors><title>Deep Learning for Massive MIMO with 1-Bit ADCs: When More Antennas Need
  Fewer Pilots</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted; 5 pages; 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers uplink massive MIMO systems with 1-bit analog-to-digital
converters (ADCs) and develops a deep-learning based channel estimation
framework. In this framework, the prior channel estimation observations and
deep neural network models are leveraged to learn the non-trivial mapping from
quantized received measurements to channels. For that, we derive the sufficient
length and structure of the pilot sequence to guarantee the existence of this
mapping function. This leads to the interesting, and
\textit{counter-intuitive}, observation that when more antennas are employed by
the massive MIMO base station, our proposed deep learning approach achieves
better channel estimation performance, for the same pilot sequence length.
Equivalently, for the same channel estimation performance, this means that when
more antennas are employed, fewer pilots are required. This observation is also
analytically proved for some special channel models. Simulation results confirm
our observations and show that more antennas lead to better channel estimation
both in terms of the normalized mean squared error and the achievable
signal-to-noise ratio per antenna.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06962</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.06962</id><created>2019-10-15</created><updated>2019-10-30</updated><authors><author><keyname>Hwang</keyname><forenames>Jyh-Jing</forenames></author><author><keyname>Yu</keyname><forenames>Stella X.</forenames></author><author><keyname>Shi</keyname><forenames>Jianbo</forenames></author><author><keyname>Collins</keyname><forenames>Maxwell D.</forenames></author><author><keyname>Yang</keyname><forenames>Tien-Ju</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao</forenames></author><author><keyname>Chen</keyname><forenames>Liang-Chieh</forenames></author></authors><title>SegSort: Segmentation by Discriminative Sorting of Segments</title><categories>cs.CV cs.LG eess.IV</categories><comments>In ICCV 2019. Webpage &amp; Code:
  https://jyhjinghwang.github.io/projects/segsort.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Almost all existing deep learning approaches for semantic segmentation tackle
this task as a pixel-wise classification problem. Yet humans understand a scene
not in terms of pixels, but by decomposing it into perceptual groups and
structures that are the basic building blocks of recognition. This motivates us
to propose an end-to-end pixel-wise metric learning approach that mimics this
process. In our approach, the optimal visual representation determines the
right segmentation within individual images and associates segments with the
same semantic classes across images. The core visual learning problem is
therefore to maximize the similarity within segments and minimize the
similarity between segments. Given a model trained this way, inference is
performed consistently by extracting pixel-wise embeddings and clustering, with
the semantic label determined by the majority vote of its nearest neighbors
from an annotated set.
  As a result, we present the SegSort, as a first attempt using deep learning
for unsupervised semantic segmentation, achieving $76\%$ performance of its
supervised counterpart. When supervision is available, SegSort shows consistent
improvements over conventional approaches based on pixel-wise softmax training.
Additionally, our approach produces more precise boundaries and consistent
region predictions. The proposed SegSort further produces an interpretable
result, as each choice of label can be easily understood from the retrieved
nearest segments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07002</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07002</id><created>2019-10-15</created><authors><author><keyname>Toslak</keyname><forenames>Devrim</forenames></author><author><keyname>Chau</keyname><forenames>Felix</forenames></author><author><keyname>Erol</keyname><forenames>Muhammet Kazim</forenames></author><author><keyname>Liu</keyname><forenames>Changgeng</forenames></author><author><keyname>Chan</keyname><forenames>R. V. Paul</forenames></author><author><keyname>Son</keyname><forenames>Taeyoon</forenames></author><author><keyname>Yao</keyname><forenames>Xincheng</forenames></author></authors><title>Trans-pars-planar illumination enables 200{\deg} ultra-wide field
  pediatric fundus photography for easy examination of the retina</title><categories>physics.med-ph eess.IV</categories><comments>9 pages, and 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study is to test the feasibility of using trans-pars-planar illumination
for ultrawide field pediatric fundus photography. Fundus examination of the
peripheral retina is essential for clinical management of pediatric eye
diseases. However, current pediatric fundus cameras with traditional
trans-pupillary illumination provide a limited field of view (FOV), making it
difficult to access the peripheral retina adequately for a comprehensive
assessment of eye conditions. Here, we report the first demonstration of
trans-pars-planar illumination in ultra-wide field pediatric fundus
photography. For proof-of-concept validation, all off-the-shelf optical
components were selected to construct a lab prototype pediatric camera
(PedCam). By freeing the entire pupil for imaging purpose only, the
trans-pars-planar illumination enables a 200o FOV in a snapshot fundus image,
allowing easy visualization of both the central and peripheral retina up to the
ora serrata. A low-cost, easy-to-use ultra-wide field PedCam provides a unique
opportunity to foster affordable telemedicine in rural and underserved areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07016</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07016</id><created>2019-10-15</created><updated>2019-10-28</updated><authors><author><keyname>Elvander</keyname><forenames>Filip</forenames></author><author><keyname>Ding</keyname><forenames>Jie</forenames></author><author><keyname>Jakobsson</keyname><forenames>Andreas</forenames></author></authors><title>On Harmonic Approximations of Inharmonic Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present the misspecified Gaussian Cram\'er-Rao lower bound
for the parameters of a harmonic signal, or pitch, when signal measurements are
collected from an almost, but not quite, harmonic model. For the asymptotic
case of large sample sizes, we present a closed-form expression for the bound
corresponding to the pseduo-true fundamental frequency. Using simulation
studies, it is shown that the bound is sharp and is attained by maximum
likelihood estimators derived under the misspecified harmonic assumption. It is
shown that misspecified harmonic models achieve a lower mean squared error than
correctly specified unstructured models for moderately inharmonic signals.
Examining voices from a speech database, we conclude that human speech belongs
to this class of signals, verifying that the use of a harmonic model for voiced
speech is preferable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07047</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07047</id><created>2019-10-15</created><authors><author><keyname>Jafarlou</keyname><forenames>Salar</forenames></author><author><keyname>Khorram</keyname><forenames>Soheil</forenames></author><author><keyname>Kothapally</keyname><forenames>Vinay</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Analyzing Large Receptive Field Convolutional Networks for Distant
  Speech Recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite significant efforts over the last few years to build a robust
automatic speech recognition (ASR) system for different acoustic settings, the
performance of the current state-of-the-art technologies significantly degrades
in noisy reverberant environments.
  Convolutional Neural Networks (CNNs) have been successfully used to achieve
substantial improvements in many speech processing applications including
distant speech recognition (DSR). However, standard CNN architectures were not
efficient in capturing long-term speech dynamics, which are essential in the
design of a robust DSR system. In the present study, we address this issue by
investigating variants of large receptive field CNNs (LRF-CNNs) which include
deeply recursive networks, dilated convolutional neural networks, and stacked
hourglass networks. To compare the efficacy of the aforementioned architectures
with the standard CNN for Wall Street Journal (WSJ) corpus, we use a hybrid
DNN-HMM based speech recognition system. We extend the study to evaluate the
system performances for distant speech simulated using realistic room impulse
responses (RIRs). Our experiments show that with fixed number of parameters
across all architectures, the large receptive field networks show consistent
improvements over the standard CNNs for distant speech. Amongst the explored
LRF-CNNs, stacked hourglass network has shown improvements with a 8.9% relative
reduction in word error rate (WER) and 10.7% relative improvement in frame
accuracy compared to the standard CNNs for distant simulated speech signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07048</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07048</id><created>2019-10-15</created><authors><author><keyname>Lei</keyname><forenames>Ke</forenames></author><author><keyname>Mardani</keyname><forenames>Morteza</forenames></author><author><keyname>Pauly</keyname><forenames>John M.</forenames></author><author><keyname>Vasawanala</keyname><forenames>Shreyas S.</forenames></author></authors><title>Wasserstein GANs for MR Imaging: from Paired to Unpaired Training</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lack of ground-truth MR images (labels) impedes the common supervised
training of deep networks for image reconstruction. To cope with this
challenge, this paper leverages WGANs for unpaired training of reconstruction
networks, where the inputs are the undersampled naively reconstructed images
from one dataset, and the outputs are high-quality images from another dataset.
The generator network is an unrolled neural network with a cascade of residual
blocks and data consistency modules. The discriminator is also a multilayer CNN
that plays the role of a critic scoring the quality of reconstructed images.
Our extensive experiments with knee MRI datasets demonstrate unpaired WGAN
training with minimal supervision is a viable option when there exists
insufficient or no fully-sampled training label images that match the input
images. Also, supervised paired training with additional WGAN loss achieves
better and faster reconstruction compared to wavelet-based compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07068</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07068</id><created>2019-10-15</created><authors><author><keyname>Wilde</keyname><forenames>Florian</forenames></author><author><keyname>Hiller</keyname><forenames>Matthias</forenames></author><author><keyname>Pehl</keyname><forenames>Michael</forenames></author></authors><title>Statistic-Based Security Analysis of Ring Oscillator PUFs</title><categories>eess.SP</categories><comments>Original publication at 2014 International Symposium on Integrated
  Circuits (ISIC). Was 4 pages, now 5 pages due to different line breaking of
  arXiv TeX system; source code is identical</comments><journal-ref>2014 International Symposium on Integrated Circuits (ISIC),
  Singapore, 2014, pp. 148-151</journal-ref><doi>10.1109/ISICIR.2014.7029528</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ring oscillators (ROs) are a robust way to implement a physical unclonable
function (PUF) into ASICs or FPGAs, but claims of predictability arose
recently. We describe why this likely results from not using adjacent ROs for
pairwise comparison because of spatial patterns in mean frequency and
correlation coefficients found by principal component analysis. We show that
the covariance is too small for our approach to estimate bits if adjacent ROs
are compared. Our assumption of normality for the inter-device distribution
passes an Anderson-Darling test and we outline that devices with proximate
serial numbers are not more similar than other devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07109</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07109</id><created>2019-10-15</created><authors><author><keyname>Narimani</keyname><forenames>Mohammad Rasoul</forenames></author><author><keyname>Azizivahed</keyname><forenames>Ali</forenames></author><author><keyname>Naderi</keyname><forenames>Ehsan</forenames></author></authors><title>An Efficient Scenario-based Stochastic Energy Management of Distribution
  Networks with Distributed Generation, PV Module, and Energy Storage</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Incorporating Renewable Energy Sources (RES) incurs a high level of
uncertainties to electric power systems. This level of uncertainties makes the
conventional energy management methods inefficient and jeopardizes the security
of distribution systems. In this connection, a scenario-based stochastic
programming is introduced to harness uncertainties in the load, electricity
price, and photovoltaic generation. Further, a hybrid evolutionary algorithm
based on Grey Wolf Optimizer and Particle Swarm Optimisation algorithm is
proposed to find the best operation cost, and Energy Not Supplied (ENS) as two
important objective functions, which almost always are in stark contrast with
each other. The proposed algorithm is applied to the modified IEEE 69-bus test
system and the results are validated in terms of efficiency, which indicates a
cogent trade-off between the fitness functions addressed above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07119</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07119</id><created>2019-10-15</created><authors><author><keyname>Xue</keyname><forenames>Hui</forenames></author><author><keyname>Brown</keyname><forenames>Louise A. E.</forenames></author><author><keyname>Nielles-Vallespin</keyname><forenames>Sonia</forenames></author><author><keyname>Plein</keyname><forenames>Sven</forenames></author><author><keyname>Kellman</keyname><forenames>Peter</forenames></author></authors><title>Automatic In-line Quantitative Myocardial Perfusion Mapping: processing
  algorithm and implementation</title><categories>eess.IV physics.med-ph q-bio.QM</categories><journal-ref>Magnetic Resonance in Medicine. 2019</journal-ref><doi>10.1002/mrm.27954</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative myocardial perfusion mapping has advantages over qualitative
assessment, including the ability to detect global flow reduction. However, it
is not clinically available and remains as a research tool. Building upon the
previously described imaging sequence, this paper presents algorithm and
implementation of an automated solution for inline perfusion flow mapping with
step by step performance characterization.
  An inline perfusion flow mapping workflow is proposed and demonstrated on
normal volunteers. Initial evaluation demonstrates the fully automated proposed
solution for the respiratory motion correction, AIF LV mask detection and
pixel-wise mapping, from free-breathing myocardial perfusion imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07122</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07122</id><created>2019-10-15</created><authors><author><keyname>Xue</keyname><forenames>Hui</forenames></author><author><keyname>Tseng</keyname><forenames>Ethan</forenames></author><author><keyname>Knott</keyname><forenames>Kristopher D</forenames></author><author><keyname>Kotecha</keyname><forenames>Tushar</forenames></author><author><keyname>Brown</keyname><forenames>Louise</forenames></author><author><keyname>Plein</keyname><forenames>Sven</forenames></author><author><keyname>Fontana</keyname><forenames>Marianna</forenames></author><author><keyname>Moon</keyname><forenames>James C</forenames></author><author><keyname>Kellman</keyname><forenames>Peter</forenames></author></authors><title>Automated Detection of Left Ventricle in Arterial Input Function Images
  for Inline Perfusion Mapping using Deep Learning: A study of 15,000 Patients</title><categories>q-bio.QM cs.CV eess.IV</categories><comments>Submitted to Magnetic Resonance in Medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantification of myocardial perfusion has the potential to improve detection
of regional and global flow reduction. Significant effort has been made to
automate the workflow, where one essential step is the arterial input function
(AIF) extraction. Since failure here invalidates quantification, high accuracy
is required. For this purpose, this study presents a robust AIF detection
method using the convolutional neural net (CNN) model. CNN models were trained
by assembling 25,027 scans (N=12,984 patients) from three hospitals, seven
scanners. A test set of 5,721 scans (N=2,805 patients) evaluated model
performance. The 2D+T AIF time series was inputted into CNN. Two variations
were investigated: a) Two Classes (2CS) for background and foreground (LV
mask); b) Three Classes (3CS) for background, foreground LV and RV. Final model
was deployed on MR scanners via the Gadgetron InlineAI. Model loading time on
MR scanner was ~340ms and applying it took ~180ms. The 3CS model successfully
detect LV for 99.98% of all test cases (1 failed out of 5,721 cases). The mean
Dice ratio for 3CS was 0.87+/-0.08 with 92.0% of all test cases having Dice
ratio &gt;0.75, while the 2CS model gave lower Dice of 0.82+/-0.22 (P&lt;1e-5).
Extracted AIF signals using CNN were further compared to manual ground-truth
for foot-time, peak-time, first-pass duration, peak value and area-under-curve.
No significant differences were found for all features (P&gt;0.2). This study
proposed, validated, and deployed a robust CNN solution to detect the LV for
the extraction of the AIF signal used in fully automated perfusion flow
mapping. A very large data cohort was assembled and resulting models were
deployed to MR scanners for fully inline AI in clinical hospitals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07129</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07129</id><created>2019-10-15</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author></authors><title>Large-Scale Landslides Detection from Satellite Images with Incomplete
  Labels</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Earthquakes and tropical cyclones cause the suffering of millions of people
around the world every year. The resulting landslides exacerbate the effects of
these disasters. Landslide detection is, therefore, a critical task for the
protection of human life and livelihood in mountainous areas. To tackle this
problem, we propose a combination of satellite technology and Deep Neural
Networks (DNNs). We evaluate the performance of multiple DNN-based methods for
landslide detection on actual satellite images of landslide damage. Our
analysis demonstrates the potential for a meaningful social impact in terms of
disasters and rescue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07133</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07133</id><created>2019-10-15</created><authors><author><keyname>Kolev</keyname><forenames>Vasil</forenames></author><author><keyname>Cooklev</keyname><forenames>Todor</forenames></author><author><keyname>Keinert</keyname><forenames>Fritz</forenames></author></authors><title>Design of a Simple Orthogonal Multiwavelet Filter by Matrix Spectral
  Factorization</title><categories>cs.CV cs.CE cs.NA cs.SY eess.SY math.NA</categories><comments>This is a preprint of a paper whose final and definite form is
  published in Circuits, Systems, and Signal Processing,, Springer,
  https://link.springer.com/article/10.1007/s00034-019-01240-9, ISSN 0278-081X
  (print), ISSN 1531-5878 (Online)</comments><msc-class>47Axx, 42Cxx, 65Txx, 11Cxx, 12Yxx, 13P25, 15B05, 15B10, 97H60, 97R20</msc-class><doi>10.1007/s00034-019-01240-9</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We consider the design of an orthogonal symmetric/antisymmetric multiwavelet
from its matrix product filter by matrix spectral factorization (MSF). As a
test problem, we construct a simple matrix product filter with desirable
properties, and factor it using Bauer's method, which in this case can be done
in closed form. The corresponding orthogonal multiwavelet function is derived
using algebraic techniques which allow symmetry to be considered. This leads to
the known orthogonal multiwavelet SA1, which can also be derived directly. We
also give a lifting scheme for SA1, investigate the influence of the number of
significant digits in the calculations, and show some numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07141</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07141</id><created>2019-10-15</created><updated>2019-10-20</updated><authors><author><keyname>Tian</keyname><forenames>Ran</forenames></author><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author><author><keyname>Yildiz</keyname><forenames>Yildiray</forenames></author><author><keyname>Girard</keyname><forenames>Anouck</forenames></author></authors><title>Game-theoretic Modeling of Traffic in Unsignalized Intersection Network
  for Autonomous Vehicle Control Verification and Validation</title><categories>cs.RO cs.SY eess.SY</categories><comments>IEEE Intelligent Transportation Systems Transactions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a foreseeable future, autonomous vehicles (AVs) will operate in traffic
together with human-driven vehicles. The AV planning and control systems need
extensive testing, including early-stage testing in simulations where the
interactions among autonomous/human-driven vehicles are represented. Motivated
by the need for such simulation tools, we propose a game-theoretic approach to
modeling vehicle interactions, in particular, for urban traffic environments
with unsignalized intersections. We develop traffic models with heterogeneous
(in terms of their driving styles) and interactive vehicles based on our
proposed approach, and use them for virtual testing, evaluation, and
calibration of AV control systems. For illustration, we consider two AV control
approaches, analyze their characteristics and performance based on the
simulation results with our developed traffic models, and optimize the
parameters of one of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07156</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07156</id><created>2019-10-15</created><authors><author><keyname>Tang</keyname><forenames>Yizheng</forenames></author><author><keyname>Ma</keyname><forenames>Ganggang</forenames></author><author><keyname>Xie</keyname><forenames>Hailiang</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Han</keyname><forenames>Xiao</forenames></author></authors><title>Joint Transmit and Reflective Beamforming Design for IRS-Assisted
  Multiuser MISO SWIPT Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies an intelligent reflecting surface (IRS)-assisted multiuser
multiple-input single-output (MISO) simultaneous wireless information and power
transfer (SWIPT) system. In this system, a multi-antenna access point (AP) uses
transmit beamforming to send both information and energy signals to a set of
receivers each for information decoding (ID) or energy harvesting (EH), and a
dedicatedly deployed IRS properly controls its reflecting phase shifts to form
passive reflection beams for facilitating both ID and EH at receivers. Under
this setup, we jointly optimize the (active) information and energy transmit
beamforming at the AP together with the (passive) reflective beamforming at the
IRS, to maximize the minimum power received at all EH receivers, subject to
individual signal-to-interference-plus-noise ratio (SINR) constraints at ID
receivers, and the maximum transmit power constraint at the AP. Although the
formulated SINR-constrained min-energy maximization problem is highly
non-convex, we present an efficient algorithm to obtain a high-quality solution
by using the techniques of alternating optimization and semi-definite
relaxation (SDR). Numerical results show that the proposed IRS-assisted SWIPT
system with both information and energy signals achieves significant
performance gains over benchmark schemes without IRS deployed and/or without
dedicated energy signals used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07169</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07169</id><created>2019-10-16</created><authors><author><keyname>Liu</keyname><forenames>Lanlan</forenames></author><author><keyname>Muelly</keyname><forenames>Michael</forenames></author><author><keyname>Deng</keyname><forenames>Jia</forenames></author><author><keyname>Pfister</keyname><forenames>Tomas</forenames></author><author><keyname>Li</keyname><forenames>Li-Jia</forenames></author></authors><title>Generative Modeling for Small-Data Object Detection</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Published in ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores object detection in the small data regime, where only a
limited number of annotated bounding boxes are available due to data rarity and
annotation expense. This is a common challenge today with machine learning
being applied to many new tasks where obtaining training data is more
challenging, e.g. in medical images with rare diseases that doctors sometimes
only see once in their life-time. In this work we explore this problem from a
generative modeling perspective by learning to generate new images with
associated bounding boxes, and using these for training an object detector. We
show that simply training previously proposed generative models does not yield
satisfactory performance due to them optimizing for image realism rather than
object detection accuracy. To this end we develop a new model with a novel
unrolling mechanism that jointly optimizes the generative model and a detector
such that the generated images improve the performance of the detector. We show
this method outperforms the state of the art on two challenging datasets,
disease detection and small data pedestrian detection, improving the average
precision on NIH Chest X-ray by a relative 20% and localization accuracy by a
relative 50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07180</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07180</id><created>2019-10-16</created><authors><author><keyname>Gharamohammadi</keyname><forenames>Ali</forenames></author><author><keyname>Behnia</keyname><forenames>Fereidoon</forenames></author><author><keyname>Shokouhmand</keyname><forenames>Arash</forenames></author></authors><title>Machine learning based identification of buried objects using sparse
  whitened NMF</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a whitening-based algorithm has been applied to sparse
non-negative matrix factorization (NMF) as a preprocessing practice enhancing
the identification of buried object, significantly. In fact, without utilizing
a suitable whitening algorithm, the input signals are very similar to one
another. Therefore, conventional approaches are not able to identify and
properly discriminate desired buried objects. A suitable whitening algorithm
makes the covariance matrix diagonal, such that the processed signals highly
resembles the unprocessed versions. Such a similarity would be helpful to
identify new received signal. In this study, we have employed the zero-phase
component analysis (ZCA) as our whitening method. Hence, although signals of
different targets are very similar in many cases, the mentioned advantages,
achieved by whitening method, make identification of targets much easier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07201</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07201</id><created>2019-10-16</created><authors><author><keyname>Lemarchand</keyname><forenames>Florian</forenames></author><author><keyname>Marlin</keyname><forenames>Cyril</forenames></author><author><keyname>Montreuil</keyname><forenames>Florent</forenames></author><author><keyname>Nogues</keyname><forenames>Erwan</forenames></author><author><keyname>Pelcat</keyname><forenames>Maxime</forenames></author></authors><title>Electro-Magnetic Side-Channel Attack Through Learned Denoising and
  Classification</title><categories>cs.CR cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an upgraded electro-magnetic side-channel attack that
automatically reconstructs the intercepted data. A novel system is introduced,
running in parallel with leakage signal interception and catching compromising
data in real-time. Based on deep learning and character recognition the
proposed system retrieves more than 57% of characters present in intercepted
signals regardless of signal type: analog or digital. The approach is also
extended to a protection system that triggers an alarm if the system is
compromised, demonstrating a success rate over 95%. Based on software-defined
radio and graphics processing unit architectures, this solution can be easily
deployed onto existing information systems where information shall be kept
secret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07204</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07204</id><created>2019-10-16</created><authors><author><keyname>Tsunoo</keyname><forenames>Emiru</forenames></author><author><keyname>Kashiwagi</keyname><forenames>Yosuke</forenames></author><author><keyname>Kumakura</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Transformer ASR with Contextual Block Processing</title><categories>eess.AS cs.CL</categories><comments>Accepted for ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Transformer self-attention network has recently shown promising
performance as an alternative to recurrent neural networks (RNNs) in end-to-end
(E2E) automatic speech recognition (ASR) systems. However, the Transformer has
a drawback in that the entire input sequence is required to compute
self-attention. In this paper, we propose a new block processing method for the
Transformer encoder by introducing a context-aware inheritance mechanism. An
additional context embedding vector handed over from the previously processed
block helps to encode not only local acoustic information but also global
linguistic, channel, and speaker attributes. We introduce a novel mask
technique to implement the context inheritance to train the model efficiently.
Evaluations of the Wall Street Journal (WSJ), Librispeech, VoxForge Italian,
and AISHELL-1 Mandarin speech recognition datasets show that our proposed
contextual block processing method outperforms naive block processing
consistently. Furthermore, the attention weight tendency of each layer is
analyzed to clarify how the added contextual inheritance mechanism models the
global information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07234</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07234</id><created>2019-10-16</created><authors><author><keyname>Ammar</keyname><forenames>Adel</forenames></author><author><keyname>Koubaa</keyname><forenames>Anis</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohanned</forenames></author><author><keyname>Saad</keyname><forenames>Abdulrahman</forenames></author></authors><title>Aerial Images Processing for Car Detection using Convolutional Neural
  Networks: Comparison between Faster R-CNN and YoloV3</title><categories>cs.CV cs.LG cs.NE eess.IV</categories><comments>12 pages, 23 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we address the problem of car detection from aerial images
using Convolutional Neural Networks (CNN). This problem presents additional
challenges as compared to car (or any object) detection from ground images
because features of vehicles from aerial images are more difficult to discern.
To investigate this issue, we assess the performance of two state-of-the-art
CNN algorithms, namely Faster R-CNN, which is the most popular region-based
algorithm, and YOLOv3, which is known to be the fastest detection algorithm. We
analyze two datasets with different characteristics to check the impact of
various factors, such as UAV's altitude, camera resolution, and object size.
The objective of this work is to conduct a robust comparison between these two
cutting-edge algorithms. By using a variety of metrics, we show that none of
the two algorithms outperforms the other in all cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07236</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07236</id><created>2019-10-16</created><updated>2019-11-28</updated><authors><author><keyname>Jetchev</keyname><forenames>Nikolay</forenames></author><author><keyname>Bergmann</keyname><forenames>Urs</forenames></author><author><keyname>Yildirim</keyname><forenames>G&#xf6;khan</forenames></author></authors><title>Transform the Set: Memory Attentive Generation of Guided and Unguided
  Image Collages</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>To be presented at the NeurIPS 2019 workshop on Creativity and AI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cutting and pasting image segments feels intuitive: the choice of source
templates gives artists flexibility in recombining existing source material.
Formally, this process takes an image set as input and outputs a collage of the
set elements. Such selection from sets of source templates does not fit easily
in classical convolutional neural models requiring inputs of fixed size.
Inspired by advances in attention and set-input machine learning, we present a
novel architecture that can generate in one forward pass image collages of
source templates using set-structured representations. This paper has the
following contributions: (i) a novel framework for image generation called
Memory Attentive Generation of Image Collages (MAGIC) which gives artists new
ways to create digital collages; (ii) from the machine-learning perspective, we
show a novel Generative Adversarial Networks (GAN) architecture that uses
Set-Transformer layers and set-pooling to blend sets of random image samples -
a hybrid non-parametric approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.07240</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1910.07240</id><created>2019-10-16</created><authors><author><keyname>Yi</keyname><forenames>Chunzhi</forenames></author><author><keyname>Jiang</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Wei</keyname><forenames>Baichun</forenames></author><author><keyname>Guo</keyname><forenames>Hao</forenames></author><author><keyname>Yin</keyname><forenames>Xunfeng</forenames></author><author><keyname>Li</keyname><forenames>Fangzhuo</forenames></author><author><keyname>Yang</keyname><forenames>Chifu</forenames></author></authors><title>Sensor-Movement-Robust Angle Estimation for 3-DoF Lower Limb Joints
  Without Calibration</title><categories>eess.SP</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inertial measurement unit (IMU)-based 3-DoF angle estimation methods for
lower limb joints have been studied for decades, however the calibration
motions and/or careful sensor placement are still necessary due to challenges
of real-time application. This study proposes a novel sensormovement-robust
3-DoF method for lower-limb joint angle estimation without calibration. A
realtime optimization process, which is based on a feedback iteration progress
to identify three joint axes of a 3-DoF joint, has been presented with a
reference frame calibration algorithm, and a safe-guarded strategy is proposed
to detect and compensate for the errors caused by sensor movements. The
experimental results obtained from a 3-DoF gimbal and ten healthy subjects
demonstrate a promising performance on 3-DoF angle estimation. Specially, the
experiments on ten subjects are performed with three gait modes and a 2-min
level walking. The root mean square error is below 2 deg for level walking and
5 deg for other two gait modes. The result of 2-min level walking shows our
algorithms stability under long run. The robustness against sensor movement are
demonstrated through data from multiple sets of IMUs. In addition, results from
the 3-DoF gimbal indicate that the accuracy of 3-DoF angle estimation could be
improved by 84.9% with our reference frame calibration algorithm. In
conclusion, our study proposes and validates a sensor-movement-robust 3-DoF
angle estimation for lowerlimb joints based on IMU. To the best of our
knowledge, our approach is the first experimental implementation of IMUbased
3-DoF angle estimation for lower-limb joints without calibration.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="10000" completeListSize="16166">4250076|11001</resumptionToken>
</ListRecords>
</OAI-PMH>
