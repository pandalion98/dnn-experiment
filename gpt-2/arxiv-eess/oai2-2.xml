<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T06:56:53Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|1001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02034</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02034</id><created>2017-12-18</created><authors><author><keyname>Pozzi</keyname><forenames>Michele</forenames></author></authors><title>Synchronicity and pure bending of piezoelectric bimorphs: a new approach
  to kinetic energy harvesting</title><categories>physics.app-ph eess.SP</categories><comments>17 pages, 9 figures, 2 tables, 27 references, 1.5 MByte</comments><doi>10.1088/1361-665X/aad073</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kinetic energy harvesting with piezoelectric bimorphs has attracted
considerable research interest in recent years. Many works have been dedicated
to the modelling and optimisation of the cantilevered geometry to increase
power density, bandwidth, etc. The increased efficiency coming from the use of
trapezoidal beams has been recognised, but little has been done to produce the
same uniform strain within the most commonly available rectangular beams. This
work proposes a new approach via a smart compliant structure which permits to
deform a set of bimorphs in pure bending. Furthermore, since the deflections
are synchronous, the power signals produced are in phase and power conditioning
is simplified and made more efficient. The kinematic requirements for uniform
strain are discussed, the novel structure is proposed and modelled with finite
elements, a prototype is presented and characterised to support the modelling.
The proposed structure induces almost perfectly uniform strain in the
piezoelectric beams for all useful rotation angles, demonstrating that,
compared to a traditional cantilever, twice as many charges can be produced
when the same maximum strain is applied to the material. Synchronicity is also
experimentally verified for the prototype, as power signals resulting from
impact excitation are observed to be in phase. The principle of synchronous
pure bending via helper structures can be applied in general to increase the
performance of piezoelectric energy harvesters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02040</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02040</id><created>2018-02-06</created><authors><author><keyname>Degraux</keyname><forenames>K&#xe9;vin</forenames></author><author><keyname>Cambareri</keyname><forenames>Valerio</forenames></author><author><keyname>Geelen</keyname><forenames>Bert</forenames></author><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author><author><keyname>Lafruit</keyname><forenames>Gauthier</forenames></author></authors><title>Multispectral Compressive Imaging Strategies using Fabry-P\'erot
  Filtered Sensors</title><categories>cs.CV eess.IV</categories><comments>19 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces two acquisition device architectures for multispectral
compressive imaging. Unlike most existing methods, the proposed computational
imaging techniques do not include any dispersive element, as they use a
dedicated sensor which integrates narrowband Fabry-P\'erot spectral filters at
the pixel level. The first scheme leverages joint inpainting and
super-resolution to fill in those voxels that are missing due to the device's
limited pixel count. The second scheme, in link with compressed sensing,
introduces spatial random convolutions, but is more complex and may be affected
by diffraction. In both cases we solve the associated inverse problems by using
the same signal prior. Specifically, we propose a redundant analysis signal
prior in a convex formulation. Through numerical simulations, we explore
different realistic setups. Our objective is also to highlight some practical
guidelines and discuss their complexity trade-offs to integrate these schemes
into actual computational imaging systems. Our conclusion is that the second
technique performs best at high compression levels, in a properly sized and
calibrated setup. Otherwise, the first, simpler technique should be favored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02046</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02046</id><created>2018-01-30</created><updated>2018-08-27</updated><authors><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Neural Network Detection of Data Sequences in Communication Systems</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>Accepted for publication in IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2018.2868322</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider detection based on deep learning, and show it is possible to
train detectors that perform well without any knowledge of the underlying
channel models. Moreover, when the channel model is known, we demonstrate that
it is possible to train detectors that do not require channel state information
(CSI). In particular, a technique we call a sliding bidirectional recurrent
neural network (SBRNN) is proposed for detection where, after training, the
detector estimates the data in real-time as the signal stream arrives at the
receiver. We evaluate this algorithm, as well as other neural network (NN)
architectures, using the Poisson channel model, which is applicable to both
optical and molecular communication systems. In addition, we also evaluate the
performance of this detection method applied to data sent over a molecular
communication platform, where the channel model is difficult to model
analytically. We show that SBRNN is computationally efficient, and can perform
detection under various channel conditions without knowing the underlying
channel model. We also demonstrate that the bit error rate (BER) performance of
the proposed SBRNN detector is better than that of a Viterbi detector with
imperfect CSI as well as that of other NN detectors that have been previously
proposed. Finally, we show that the SBRNN can perform well in rapidly changing
channels, where the coherence time is on the order of a single symbol duration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02083</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02083</id><created>2018-01-09</created><authors><author><keyname>Sonagara</keyname><forenames>Japit S.</forenames></author><author><keyname>Shah</keyname><forenames>Karan H.</forenames></author><author><keyname>Suvariya</keyname><forenames>Jaydeep D.</forenames></author><author><keyname>Patel</keyname><forenames>Shobhit K.</forenames></author></authors><title>Reconfigurable high Gain split Ring Resonator Microstrip Patch Antenna</title><categories>eess.SP</categories><comments>6 pages,8 figures,5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, reconfigurable high gain split ring resonator microstrip patch
antenna is designed and analysed. The aim to design such type antenna is to
achieve multiband application which is the demand of current technology in
frequency reconfiguration within single antenna. Here microstrip patch antenna
with rectangle shape of patch with patch dimension 11.6*11.6 mm2 is analysed.
The proposed design is tuned with two bands in the frequency range of 5-9 GHz
depending on the geometric specification of antenna and the location of feed
which can be used for multiband applications. Design results of VSWR, return
loss (S11), bandwidth and gain are shown in this paper which is obtained by
high frequency structure simulator (HFSS) which is used for simulating
microwave passive components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02129</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02129</id><created>2018-02-06</created><updated>2018-02-22</updated><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Age-Minimal Online Policies for Energy Harvesting Sensors with
  Incremental Battery Recharges</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Appeared in ITA 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor node that is sending measurement updates regarding some physical
phenomenon to a destination is considered. The sensor relies on energy
harvested from nature to transmit its updates, and is equipped with a finite
$B$-sized battery to save its harvested energy. Energy recharges the battery
incrementally in units, according to a Poisson process, and one update consumes
one energy unit to reach the destination. The setting is online, where the
energy arrival times are revealed causally after the energy is harvested. The
goal is to update the destination in a timely manner, namely, such that the
long term average age of information is minimized, subject to energy causality
constraints. The age of information at a given time is defined as the time
spent since the latest update has reached the destination. It is shown that the
optimal update policy follows a renewal structure, where the inter-update times
are independent, and the time durations between any two consecutive events of
submitting an update and having $k$ units of energy remaining in the battery
are independent and identically distributed for a given $k\leq B-1$. The
optimal renewal policy for the case of $B=2$ energy units is explicitly
characterized, and it is shown that it has an energy-dependent threshold
structure, where the sensor updates only if the age grows above a certain
threshold that is a function of the amount of energy in its battery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02241</identifier>
 <datestamp>2018-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02241</id><created>2018-01-17</created><authors><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>Lin</keyname><forenames>Youzuo</forenames></author><author><keyname>Zhou</keyname><forenames>Zheng</forenames></author><author><keyname>Delorey</keyname><forenames>Andrew</forenames></author></authors><title>Seismic-Net: A Deep Densely Connected Neural Network to Detect Seismic
  Events</title><categories>eess.SP cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the risks of large-scale geologic carbon sequestration is the
potential migration of fluids out of the storage formations. Accurate and fast
detection of this fluids migration is not only important but also challenging,
due to the large subsurface uncertainty and complex governing physics.
Traditional leakage detection and monitoring techniques rely on geophysical
observations including seismic. However, the resulting accuracy of these
methods is limited because of indirect information they provide requiring
expert interpretation, therefore yielding in-accurate estimates of leakage
rates and locations. In this work, we develop a novel machine-learning
detection package, named &quot;Seismic-Net&quot;, which is based on the deep densely
connected neural network. To validate the performance of our proposed leakage
detection method, we employ our method to a natural analog site at Chimay\'o,
New Mexico. The seismic events in the data sets are generated because of the
eruptions of geysers, which is due to the leakage of $\mathrm{CO}_\mathrm{2}$.
In particular, we demonstrate the efficacy of our Seismic-Net by formulating
our detection problem as an event detection problem with time series data. A
fixed-length window is slid throughout the time series data and we build a deep
densely connected network to classify each window to determine if a geyser
event is included. Through our numerical tests, we show that our model achieves
precision/recall as high as 0.889/0.923. Therefore, our Seismic-Net has a great
potential for detection of $\mathrm{CO}_\mathrm{2}$ leakage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02358</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02358</id><created>2018-02-07</created><authors><author><keyname>Smith</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Basarab</keyname><forenames>Adrian</forenames></author><author><keyname>Georgeot</keyname><forenames>Bertrand</forenames></author><author><keyname>Kouam&#xe9;</keyname><forenames>Denis</forenames></author></authors><title>Adaptive transform via quantum signal processing: application to signal
  and image denoising</title><categories>eess.SP</categories><journal-ref>IEEE International Conference on Image Processing (ICIP 2018),
  Athens, 07/10/18-10/10/18, IEEE : Institute of Electrical and Electronics
  Engineers, p. 1523-1527, october 2018</journal-ref><doi>10.1109/ICIP.2018.8451044</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main scope of this paper is to show how tools from quantum mechanics, in
particular the Schroedinger equation, can be used to construct an adaptive
transform suitable for signal and image processing applications. The proposed
dictionary is obtained by considering the signal or image as a discrete
potential in Schroedinger equation, further used to construct the Hamiltonien
operator. In order to illustrate its practical interest in signal and image
processing, we provide denoising results in the case of signal-dependent noise,
which is the noise type the most adapted to the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02427</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02427</id><created>2018-01-18</created><updated>2018-02-09</updated><authors><author><keyname>Chen</keyname><forenames>Lele</forenames></author><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>DSouza</keyname><forenames>Adora M.</forenames></author><author><keyname>Abidin</keyname><forenames>Anas Z.</forenames></author><author><keyname>Wismuller</keyname><forenames>Axel</forenames></author><author><keyname>Xu</keyname><forenames>Chenliang</forenames></author></authors><title>MRI Tumor Segmentation with Densely Connected 3D CNN</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Glioma is one of the most common and aggressive types of primary brain
tumors. The accurate segmentation of subcortical brain structures is crucial to
the study of gliomas in that it helps the monitoring of the progression of
gliomas and aids the evaluation of treatment outcomes. However, the large
amount of required human labor makes it difficult to obtain the manually
segmented Magnetic Resonance Imaging (MRI) data, limiting the use of precise
quantitative measurements in the clinical practice. In this work, we try to
address this problem by developing a 3D Convolutional Neural Network~(3D CNN)
based model to automatically segment gliomas. The major difficulty of our
segmentation model comes with the fact that the location, structure, and shape
of gliomas vary significantly among different patients. In order to accurately
classify each voxel, our model captures multi-scale contextual information by
extracting features from two scales of receptive fields. To fully exploit the
tumor structure, we propose a novel architecture that hierarchically segments
different lesion regions of the necrotic and non-enhancing tumor~(NCR/NET),
peritumoral edema~(ED) and GD-enhancing tumor~(ET). Additionally, we utilize
densely connected convolutional blocks to further boost the performance. We
train our model with a patch-wise training schema to mitigate the class
imbalance problem. The proposed method is validated on the BraTS 2017 dataset
and it achieves Dice scores of 0.72, 0.83 and 0.81 for the complete tumor,
tumor core and enhancing tumor, respectively. These results are comparable to
the reported state-of-the-art results, and our method is better than existing
3D-based methods in terms of compactness, time and space efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02464</identifier>
 <datestamp>2018-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02464</id><created>2018-02-06</created><authors><author><keyname>Sidorenko</keyname><forenames>Juri</forenames></author><author><keyname>Doktorski</keyname><forenames>Leo</forenames></author><author><keyname>Schatz</keyname><forenames>Volker</forenames></author><author><keyname>Scherer-Negenborn</keyname><forenames>Norbert</forenames></author><author><keyname>Arens</keyname><forenames>Michael</forenames></author></authors><title>Improved Time of Arrival measurement model for non-convex optimization
  with noisy data</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1801.03266</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quadratic system provided by the Time of Arrival technique can be solved
analytical or by optimization algorithms. In real environments the measurements
are always corrupted by noise. This measurement noise effects the analytical
solution more than non-linear optimization algorithms. On the other hand it is
also true that local optimization tends to find the local minimum, instead of
the global minimum. This article presents an approach how this risk can be
significantly reduced in noisy environments. The main idea of our approach is
to transform the local minimum to a saddle point, by increasing the number of
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02469</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02469</id><created>2018-02-07</created><authors><author><keyname>Flamant</keyname><forenames>Julien</forenames></author><author><keyname>Chainais</keyname><forenames>Pierre</forenames></author><author><keyname>Bihan</keyname><forenames>Nicolas Le</forenames></author></authors><title>A complete framework for linear filtering of bivariate signals</title><categories>eess.SP</categories><comments>11 pages, 3 figures</comments><doi>10.1109/TSP.2018.2855659</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete framework for the linear time-invariant (LTI) filtering theory of
bivariate signals is proposed based on a tailored quaternion Fourier transform.
This framework features a direct description of LTI filters in terms of their
eigenproperties enabling compact calculus and physically interpretable
filtering relations in the frequency domain. The design of filters exhibiting
fondamental properties of polarization optics (birefringence, diattenuation) is
straightforward. It yields an efficient spectral synthesis method and new
insights on Wiener filtering for bivariate signals with prescribed
frequency-dependent polarization properties. This generic framework facilitates
original descriptions of bivariate signals in two components with specific
geometric or statistical properties. Numerical experiments support our
theoretical analysis and illustrate the relevance of the approach on synthetic
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02607</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02607</id><created>2018-02-07</created><updated>2019-03-28</updated><authors><author><keyname>Shivakumar</keyname><forenames>Prashanth Gurunath</forenames></author><author><keyname>Li</keyname><forenames>Haoqi</forenames></author><author><keyname>Knight</keyname><forenames>Kevin</forenames></author><author><keyname>Georgiou</keyname><forenames>Panayiotis</forenames></author></authors><title>Learning from Past Mistakes: Improving Automatic Speech Recognition
  Output via Noisy-Clean Phrase Context Modeling</title><categories>cs.CL cs.SD eess.AS</categories><journal-ref>APSIPA Transactions on Signal and Information Processing 8.
  Cambridge University Press: e8, 2019</journal-ref><doi>10.1017/ATSIP.2018.31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic speech recognition (ASR) systems often make unrecoverable errors
due to subsystem pruning (acoustic, language and pronunciation models); for
example pruning words due to acoustics using short-term context, prior to
rescoring with long-term context based on linguistics. In this work we model
ASR as a phrase-based noisy transformation channel and propose an error
correction system that can learn from the aggregate errors of all the
independent modules constituting the ASR and attempt to invert those. The
proposed system can exploit long-term context using a neural network language
model and can better choose between existing ASR output possibilities as well
as re-introduce previously pruned or unseen (out-of-vocabulary) phrases. It
provides corrections under poorly performing ASR conditions without degrading
any accurate transcriptions; such corrections are greater on top of
out-of-domain and mismatched data ASR. Our system consistently provides
improvements over the baseline ASR, even when baseline is further optimized
through recurrent neural network language model rescoring. This demonstrates
that any ASR improvements can be exploited independently and that our proposed
system can potentially still provide benefits on highly optimized ASR. Finally,
we present an extensive analysis of the type of errors corrected by our system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02617</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02617</id><created>2018-02-07</created><updated>2019-04-28</updated><authors><author><keyname>Medhat</keyname><forenames>Fady</forenames></author><author><keyname>Chesmore</keyname><forenames>David</forenames></author><author><keyname>Robinson</keyname><forenames>John</forenames></author></authors><title>Recognition of Acoustic Events Using Masked Conditional Neural Networks</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Restricted Boltzmann Machine, RBM, Conditional Restricted Boltzmann
  Machine, CRBM, Conditional Neural Networks, CLNN, Masked Conditional Neural
  Networks, MCLNN, Deep Neural Network, Environmental Sound Recognition, ESR</comments><journal-ref>IEEE International Conference on Machine Learning and Applications
  (ICMLA) Year: 2017 Pages: 199 - 206</journal-ref><doi>10.1109/ICMLA.2017.0-158</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic feature extraction using neural networks has accomplished
remarkable success for images, but for sound recognition, these models are
usually modified to fit the nature of the multi-dimensional temporal
representation of the audio signal in spectrograms. This may not efficiently
harness the time-frequency representation of the signal. The ConditionaL Neural
Network (CLNN) takes into consideration the interrelation between the temporal
frames, and the Masked ConditionaL Neural Network (MCLNN) extends upon the CLNN
by forcing a systematic sparseness over the network's weights using a binary
mask. The masking allows the network to learn about frequency bands rather than
bins, mimicking a filterbank used in signal transformations such as MFCC.
Additionally, the Mask is designed to consider various combinations of
features, which automates the feature hand-crafting process. We applied the
MCLNN for the Environmental Sound Recognition problem using the Urbansound8k,
YorNoise, ESC-10 and ESC-50 datasets. The MCLNN have achieved competitive
performance compared to state-of-the-art Convolutional Neural Networks and
hand-crafted attempts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02656</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02656</id><created>2018-02-07</created><authors><author><keyname>Yang</keyname><forenames>Xuesong</forenames></author><author><keyname>Audhkhasi</keyname><forenames>Kartik</forenames></author><author><keyname>Rosenberg</keyname><forenames>Andrew</forenames></author><author><keyname>Thomas</keyname><forenames>Samuel</forenames></author><author><keyname>Ramabhadran</keyname><forenames>Bhuvana</forenames></author><author><keyname>Hasegawa-Johnson</keyname><forenames>Mark</forenames></author></authors><title>Joint Modeling of Accents and Acoustics for Multi-Accent Speech
  Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted in The 43rd IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of automatic speech recognition systems degrades with
increasing mismatch between the training and testing scenarios. Differences in
speaker accents are a significant source of such mismatch. The traditional
approach to deal with multiple accents involves pooling data from several
accents during training and building a single model in multi-task fashion,
where tasks correspond to individual accents. In this paper, we explore an
alternate model where we jointly learn an accent classifier and a multi-task
acoustic model. Experiments on the American English Wall Street Journal and
British English Cambridge corpora demonstrate that our joint model outperforms
the strong multi-task acoustic model baseline. We obtain a 5.94% relative
improvement in word error rate on British English, and 9.47% relative
improvement on American English. This illustrates that jointly modeling with
accent information improves acoustic model performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02665</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02665</id><created>2018-02-07</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author><author><keyname>Ahmad</keyname><forenames>M. Omair</forenames></author></authors><title>A Divide and Conquer Strategy for Musical Noise-free Speech Enhancement
  in Adverse Environments</title><categories>eess.AS cs.SD</categories><comments>11 pages, 8 tables, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A divide and conquer strategy for enhancement of noisy speeches in adverse
environments involving lower levels of SNR is presented in this paper, where
the total system of speech enhancement is divided into two separate steps. The
first step is based on noise compensation on short time magnitude and the
second step is based on phase compensation. The magnitude spectrum is
compensated based on a modified spectral subtraction method where the
cross-terms containing spectra of noise and clean speech are taken into
consideration, which are neglected in the traditional spectral subtraction
methods. By employing the modified magnitude and unchanged phase, a procedure
is formulated to compensate the overestimation or underestimation of noise by
phase compensation method based on the probability of speech presence. A
modified complex spectrum based on these two steps are obtained to synthesize a
musical noise free enhanced speech. Extensive simulations are carried out using
the speech files available in the NOIZEUS database in order to evaluate the
performance of the proposed method. It is shown in terms of the objective
measures, spectrogram analysis and formal subjective listening tests that the
proposed method consistently outperforms some of the state-of-the-art methods
of speech enhancement for noisy speech corrupted by street or babble noise at
very low as well as medium levels of SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02680</identifier>
 <datestamp>2018-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02680</id><created>2018-02-07</created><updated>2018-05-04</updated><authors><author><keyname>Beckus</keyname><forenames>Andre</forenames></author><author><keyname>Tamasan</keyname><forenames>Alexandru</forenames></author><author><keyname>Dogariu</keyname><forenames>Aristide</forenames></author><author><keyname>Abouraddy</keyname><forenames>Ayman F.</forenames></author><author><keyname>Atia</keyname><forenames>George K.</forenames></author></authors><title>On the inverse problem of source reconstruction from coherence
  measurements</title><categories>physics.optics eess.SP</categories><journal-ref>J. Opt. Soc. Am. A 35, 959-968 (2018)</journal-ref><doi>10.1364/JOSAA.35.000959</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an inverse source problem for partially coherent light
propagating in the Fresnel regime. The data is the coherence of the field
measured away from the source. The reconstruction is based on a minimum residue
formulation, which uses the authors' recent closed-form approximation formula
for the coherence of the propagated field. The developed algorithms require a
small data sample for convergence and yield stable inversion by exploiting
information in the coherence as opposed to intensity-only measurements.
Examples with both simulated and experimental data demonstrate the ability of
the proposed approach to simultaneously recover complex sources in different
planes transverse to the direction of propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02702</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02702</id><created>2018-02-07</created><authors><author><keyname>Salehifar</keyname><forenames>Mehdi</forenames></author><author><keyname>Nanjundaswamy</keyname><forenames>Tejaswi</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author></authors><title>On Quantizer Design to Exploit Common Information in Layered Coding of
  Vector Sources</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a layered coding framework with a relaxed hierarchical
structure. Advances in wired/wireless communication and consumer electronic
devices have created a requirement for serving the same content at different
quality levels. The key challenge is to optimally encode all the required
quality levels with efficient usage of storage and networking resources. The
approach to store and transmit independent copies for every required quality
level is highly wasteful in resources. Alternatively, conventional scalable
coding has inherent loss due to its structure. This paper studies a layered
coding framework with a relaxed hierarchical structure to transmit information
common to different quality levels along with individual bit streams for each
quality level. The flexibility of sharing only a properly selected subset of
information from a lower quality level with the higher quality level, enables
achieving operating points between conventional scalable coding and independent
coding, to control the layered coding penalty. Jointly designing common and
individual layers' coders overcomes the limitations of conventional scalable
coding and non-scalable coding, by providing the flexibility of transmitting
common and individual bit-streams for different quality levels. It extracts the
common information between different quality levels with negligible performance
penalty. Simulation results for practically important sources, confirm the
superiority of the work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02709</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02709</id><created>2018-02-07</created><authors><author><keyname>Salehifar</keyname><forenames>Mehdi</forenames></author><author><keyname>Nanjundaswamy</keyname><forenames>Tejaswi</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author></authors><title>Layered Coding of Hidden Markov Sources</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies optimal coding of hidden Markov sources (HMS), which
represent a broad class of practical sources obtained through noisy acquisition
processes, beside their explicit modeling use in speech processing and
recognition, image understanding and sensor networks. A new fundamental source
coding approach for HMS is proposed, based on tracking an estimate of the state
probability distribution, and is shown to be optimal. Practical encoder and
decoder schemes that leverage the main concepts are introduced. An iterative
approach is developed for optimizing the system. It also focuses on a
significant extension of the optimal HMS quantization paradigm. It proposes a
new approach for scalable coding of HMS which accounts for all the available
information while coding a given layer. Simulation results confirm that these
approaches significantly reduce the reconstructed distortion and substantially
outperform existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02731</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02731</id><created>2018-02-08</created><authors><author><keyname>Soler</keyname><forenames>Maxime</forenames></author><author><keyname>Plainchault</keyname><forenames>Melanie</forenames></author><author><keyname>Conche</keyname><forenames>Bruno</forenames></author><author><keyname>Tierny</keyname><forenames>Julien</forenames></author></authors><title>Topologically Controlled Lossy Compression</title><categories>eess.IV cs.CG cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new algorithm for the lossy compression of scalar data
defined on 2D or 3D regular grids, with topological control. Certain techniques
allow users to control the pointwise error induced by the compression. However,
in many scenarios it is desirable to control in a similar way the preservation
of higher-level notions, such as topological features , in order to provide
guarantees on the outcome of post-hoc data analyses. This paper presents the
first compression technique for scalar data which supports a strictly
controlled loss of topological features. It provides users with specific
guarantees both on the preservation of the important features and on the size
of the smaller features destroyed during compression. In particular, we present
a simple compression strategy based on a topologically adaptive quantization of
the range. Our algorithm provides strong guarantees on the bottleneck distance
between persistence diagrams of the input and decompressed data, specifically
those associated with extrema. A simple extension of our strategy additionally
enables a control on the pointwise error. We also show how to combine our
approach with state-of-the-art compressors, to further improve the geometrical
reconstruction. Extensive experiments, for comparable compression rates,
demonstrate the superiority of our algorithm in terms of the preservation of
topological features. We show the utility of our approach by illustrating the
compatibility between the output of post-hoc topological data analysis
pipelines, executed on the input and decompressed data, for simulated or
acquired data sets. We also provide a lightweight VTK-based C++ implementation
of our approach for reproduction purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02736</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02736</id><created>2018-02-08</created><updated>2018-02-11</updated><authors><author><keyname>Kim</keyname><forenames>Jeehyeong</forenames></author><author><keyname>Park</keyname><forenames>Joohan</forenames></author><author><keyname>Noh</keyname><forenames>Jaewon</forenames></author><author><keyname>Cho</keyname><forenames>Sunghyun</forenames></author></authors><title>Completely Distributed Power Allocation using Deep Neural Network for
  Device to Device communication Underlaying LTE</title><categories>eess.SP cs.LG</categories><comments>12 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device to device (D2D) communication underlaying LTE can be used to
distribute traffic loads of eNBs. However, a conventional D2D link is
controlled by an eNB, and it still remains burdens to the eNB. We propose a
completely distributed power allocation method for D2D communication
underlaying LTE using deep learning. In the proposed scheme, a D2D transmitter
can decide the transmit power without any help from other nodes, such as an eNB
or another D2D device. Also, the power set, which is delivered from each D2D
node independently, can optimize the overall cell throughput. We suggest a
distirbuted deep learning architecture in which the devices are trained as a
group, but operate independently. The deep learning can optimize total cell
throughput while keeping constraints such as interference to eNB. The proposed
scheme, which is implemented model using Tensorflow, can provide same
throughput with the conventional method even it operates completely on
distributed manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02794</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02794</id><created>2018-02-08</created><authors><author><keyname>Mendrzik</keyname><forenames>Rico</forenames></author><author><keyname>Bauch</keyname><forenames>Gerhard</forenames></author></authors><title>Position-Constrained Stochastic Inference for Cooperative Indoor
  Localization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of distributed cooperative localization in wireless
networks, i.e. nodes without prior position knowledge (agents) wish to
determine their own positions. In non-cooperative approaches, positioning is
only based on information from reference nodes with known positions (anchors).
However, in cooperative positioning, information from other agents is
considered as well. Cooperative positioning requires encoding of the
uncertainty of agents' positions. To cope with that demand, we employ
stochastic inference for localization which inherently considers the position
uncertainty of agents. However, stochastic inference comes at the expense of
high costs in terms of computation and information exchange. To relax the
requirements of inference algorithms, we propose the framework of
position-constrained stochastic inference, in which we first confine the
positions of nodes to feasible sets. We use convex polygons to impose
constraints on the possible positions of agents. By doing so, we enable
inference algorithms to concentrate on important regions of the sample space
rather than the entire sample space. We show through simulations that increased
localization accuracy, reduced computational complexity, and quicker
convergence can be achieved when compared to a state-of-the-art non-constrained
inference algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02912</identifier>
 <datestamp>2018-02-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02912</id><created>2018-02-08</created><authors><author><keyname>Pesce</keyname><forenames>Marica</forenames></author><author><keyname>Repetti</keyname><forenames>Audrey</forenames></author><author><keyname>Aur&#xed;a</keyname><forenames>Anna</forenames></author><author><keyname>Daducci</keyname><forenames>Alessandro</forenames></author><author><keyname>Thiran</keyname><forenames>Jean-Philippe</forenames></author><author><keyname>Wiaux</keyname><forenames>Yves</forenames></author></authors><title>Fast Fiber Orientation Estimation in Diffusion MRI from kq-Space
  Sampling and Anatomical Priors</title><categories>eess.IV physics.med-ph</categories><comments>10 pages, 5 figures, Supplementary Materials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High spatio-angular resolution diffusion MRI (dMRI) has been shown to provide
accurate identification of complex fiber configurations, albeit at the cost of
long acquisition times. We propose a method to recover intra-voxel fiber
configurations at high spatio-angular resolution relying on a kq-space
under-sampling scheme to enable accelerated acquisitions. The inverse problem
for reconstruction of the fiber orientation distribution (FOD) is regularized
by a structured sparsity prior promoting simultaneously voxelwise sparsity and
spatial smoothness of fiber orientation. Prior knowledge of the spatial
distribution of white matter, gray matter and cerebrospinal fluid is also
assumed. A minimization problem is formulated and solved via a forward-backward
convex optimization algorithmic structure. Simulations and real data analysis
suggest that accurate FOD mapping can be achieved from severe kq-space
under-sampling regimes, potentially enabling high spatio-angular dMRI in the
clinical setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02983</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02983</id><created>2018-02-07</created><authors><author><keyname>Cox</keyname><forenames>Stephen M.</forenames></author><author><keyname>Mouton</keyname><forenames>H. du Toit</forenames></author></authors><title>A third-order class-D amplifier with and without ripple compensation</title><categories>eess.SP</categories><comments>30 pages, 6 figures</comments><doi>10.1016/j.physd.2018.01.012</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We analyse the nonlinear behaviour of a third-order class-D amplifier, and
demonstrate the remarkable effectiveness of the recently introduced ripple
compensation (RC) technique in reducing the audio distortion of the device. The
amplifier converts an input audio signal to a high-frequency train of
rectangular pulses, whose widths are modulated according to the input signal
(pulse-width modulation) and employs negative feedback. After determining the
steady-state operating point for constant input and calculating its stability,
we derive a small-signal model (SSM), which yields in closed form the transfer
function relating (infinitesimal) input and output disturbances. This SSM shows
how the RC technique is able to linearise the small-signal response of the
device. We extend this SSM through a fully nonlinear perturbation calculation
of the dynamics of the amplifier, based on the disparity in time scales between
the pulse train and the audio signal. We obtain the nonlinear response of the
amplifier to a general audio signal, avoiding the linearisation inherent in the
SSM; we thereby more precisely quantify the reduction in distortion achieved
through RC. Finally, simulations corroborate our theoretical predictions and
illustrate the dramatic deterioration in performance that occurs when the
amplifier is operated in an unstable regime. The perturbation calculation is
rather general, and may be adapted to quantify the way in which other nonlinear
negative-feedback pulse-modulated devices track a time-varying input signal
that slowly modulates the system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03058</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03058</id><created>2018-02-08</created><authors><author><keyname>Mohammadkarimi</keyname><forenames>Mostafa</forenames></author><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Doppler Spread Estimation in MIMO Frequency-selective Fading Channels</title><categories>eess.SP cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One of the main challenges in high-speed mobile communications is the
presence of large Doppler spreads. Thus, accurate estimation of maximum Doppler
spread (MDS) plays an important role in improving the performance of the
communication link. In this paper, we derive the data-aided (DA) and
non-data-aided (NDA) Cramer-Rao lower bounds (CRLBs) and maximum likelihood
estimators (MLEs) for the MDS in multiple-input multiple-output (MIMO)
frequency-selective fading channel. Moreover, a lowcomplexity NDA-moment-based
estimator (MBE) is proposed. The proposed NDA-MBE relies on the second- and
fourth-order moments of the received signal, which are employed to estimate the
normalized squared autocorrelation function of the fading channel. Then, the
problem of MDS estimation is formulated as a non-linear regression problem, and
the least-squares curvefitting optimization technique is applied to determine
the estimate of the MDS. This is the first time in the literature when DAand
NDA-MDS estimation is investigated for MIMO frequency-selective fading channel.
Simulation results show that there is no significant performance gap between
the derived NDA-MLE and NDA-CRLB even when the observation window is relatively
small. Furthermore, the significant reduced-complexity in the NDA-MBE leads to
low root-mean-square error (NRMSE) over a wide range of MDSs when the
observation window is selected large enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03070</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03070</id><created>2018-02-08</created><authors><author><keyname>Abeida</keyname><forenames>Habti</forenames></author><author><keyname>Zhang</keyname><forenames>Qilin</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Merabtine</keyname><forenames>Nadjim</forenames></author></authors><title>Iterative Sparse Asymptotic Minimum Variance Based Approaches for Array
  Processing</title><categories>eess.SP</categories><comments>Abeida Habti, Qilin Zhang, Jian Li, and Nadjim Merabtine. &quot;Iterative
  sparse asymptotic minimum variance based approaches for array processing.&quot;
  IEEE Transactions on Signal Processing 61, no. 4 (2013): 933-944</comments><journal-ref>IEEE Transactions on Signal Processing 61, no. 4 (2013): 933-944</journal-ref><doi>10.1109/TSP.2012.2231676</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a series of user parameter-free iterative Sparse
Asymptotic Minimum Variance (SAMV) approaches for array processing applications
based on the asymptotically minimum variance (AMV) criterion. With the
assumption of abundant snapshots in the direction-of-arrival (DOA) estimation
problem, the signal powers and noise variance are jointly estimated by the
proposed iterative AMV approach, which is later proved to coincide with the
Maximum Likelihood (ML) estimator. We then propose a series of power-based
iterative SAMV approaches, which are robust against insufficient snapshots,
coherent sources and arbitrary array geometries. Moreover, to overcome the
direction grid limitation on the estimation accuracy, the SAMV-Stochastic ML
(SAMV-SML) approaches are derived by explicitly minimizing a closed form
stochastic ML cost function with respect to one scalar parameter, eliminating
the need of any additional grid refinement techniques. To assist the
performance evaluation, approximate solutions to the SAMV approaches are also
provided at high signal-to-noise ratio (SNR) and low SNR, respectively.
Finally, numerical examples are generated to compare the performance of the
proposed approaches with existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03156</identifier>
 <datestamp>2018-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03156</id><created>2018-02-09</created><updated>2018-09-30</updated><authors><author><keyname>Magron</keyname><forenames>Paul</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Complex ISNMF: a Phase-Aware Model for Monaural Audio Source Separation</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a phase-aware probabilistic model for audio source
separation. Classical source models in the short-term Fourier transform domain
use circularly-symmetric Gaussian or Poisson random variables. This is
equivalent to assuming that the phase of each source is uniformly distributed,
which is not suitable for exploiting the underlying structure of the phase.
Drawing on preliminary works, we introduce here a Bayesian anisotropic Gaussian
source model in which the phase is no longer uniform. Such a model permits us
to favor a phase value that originates from a signal model through a Markov
chain prior structure. The variance of the latent variables are structured with
nonnegative matrix factorization (NMF). The resulting model is called complex
Itakura-Saito NMF (ISNMF) since it generalizes the ISNMF model to the case of
non-isotropic variables. It combines the advantages of ISNMF, which uses a
distortion measure adapted to audio and yields a set of estimates which
preserve the overall energy of the mixture, and of complex NMF, which enables
one to account for some phase constraints. We derive a generalized
expectation-maximization algorithm to estimate the model parameters.
Experiments conducted on a musical source separation task in a semi-informed
setting show that the proposed approach outperforms state-of-the-art
phase-aware separation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03180</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03180</id><created>2018-02-09</created><updated>2018-04-30</updated><authors><author><keyname>Stein</keyname><forenames>Manuel S.</forenames></author><author><keyname>Fau&#xdf;</keyname><forenames>Michael</forenames></author></authors><title>In a One-Bit Rush: Low-Latency Wireless Spectrum Monitoring with Binary
  Sensor Arrays</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting the presence of a random wireless source with minimum latency
utilizing an array of radio sensors is considered. The problem is studied under
the constraint that the analog-to-digital conversion at each sensor is
restricted to reading the sign of the analog received signal. We formulate the
resulting digital signal processing task as a sequential hypothesis test in
simple form. To circumvent the intractable probabilistic model of the
multivariate binary array data, a reduced model representation within the
exponential family in conjunction with a log-likelihood ratio approximation is
employed. This approach allows us to design a likelihood-based sequential test
and to analyze its analytic performance along Wald's classical arguments. In
the context of wireless spectrum monitoring for satellite-based navigation and
synchronization systems, we study the achievable processing latency,
characterized by the average sample number, as a function of the binary sensors
in use. The practical feasibility and potential of the discussed low-complexity
sensing and decision-making technology is demonstrated via simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03195</identifier>
 <datestamp>2018-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03195</id><created>2018-02-09</created><updated>2018-11-22</updated><authors><author><keyname>Elzanaty</keyname><forenames>Ahmed</forenames></author><author><keyname>Giorgetti</keyname><forenames>Andrea</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>Limits on Sparse Data Acquisition: RIC Analysis of Finite Gaussian
  Matrices</title><categories>cs.IT eess.SP math.IT math.ST stat.TH</categories><comments>11 pages, 6 figures, accepted for publication in IEEE transactions on
  information theory</comments><doi>10.1109/TIT.2018.2859327</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One of the key issues in the acquisition of sparse data by means of
compressed sensing (CS) is the design of the measurement matrix. Gaussian
matrices have been proven to be information-theoretically optimal in terms of
minimizing the required number of measurements for sparse recovery. In this
paper we provide a new approach for the analysis of the restricted isometry
constant (RIC) of finite dimensional Gaussian measurement matrices. The
proposed method relies on the exact distributions of the extreme eigenvalues
for Wishart matrices. First, we derive the probability that the restricted
isometry property is satisfied for a given sufficient recovery condition on the
RIC, and propose a probabilistic framework to study both the symmetric and
asymmetric RICs. Then, we analyze the recovery of compressible signals in noise
through the statistical characterization of stability and robustness. The
presented framework determines limits on various sparse recovery algorithms for
finite size problems. In particular, it provides a tight lower bound on the
maximum sparsity order of the acquired data allowing signal recovery with a
given target probability. Also, we derive simple approximations for the RICs
based on the Tracy-Widom distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03248</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03248</id><created>2018-02-09</created><updated>2018-05-20</updated><authors><author><keyname>Fang</keyname><forenames>Chaowei</forenames></author><author><keyname>Liao</keyname><forenames>Zicheng</forenames></author><author><keyname>Yu</keyname><forenames>Yizhou</forenames></author></authors><title>Piecewise Flat Embedding for Image Segmentation</title><categories>cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new multi-dimensional nonlinear embedding -- Piecewise Flat
Embedding (PFE) -- for image segmentation. Based on the theory of sparse signal
recovery, piecewise flat embedding with diverse channels attempts to recover a
piecewise constant image representation with sparse region boundaries and
sparse cluster value scattering. The resultant piecewise flat embedding
exhibits interesting properties such as suppressing slowly varying signals, and
offers an image representation with higher region identifiability which is
desirable for image segmentation or high-level semantic analysis tasks. We
formulate our embedding as a variant of the Laplacian Eigenmap embedding with
an $L_{1,p} (0&lt;p\leq1)$ regularization term to promote sparse solutions. First,
we devise a two-stage numerical algorithm based on Bregman iterations to
compute $L_{1,1}$-regularized piecewise flat embeddings. We further generalize
this algorithm through iterative reweighting to solve the general
$L_{1,p}$-regularized problem. To demonstrate its efficacy, we integrate PFE
into two existing image segmentation frameworks, segmentation based on
clustering and hierarchical segmentation based on contour detection.
Experiments on four major benchmark datasets, BSDS500, MSRC, Stanford
Background Dataset, and PASCAL Context, show that segmentation algorithms
incorporating our embedding achieve significantly improved results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03280</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03280</id><created>2018-02-09</created><authors><author><keyname>Aguerrebere</keyname><forenames>Cecilia</forenames></author><author><keyname>Delbracio</keyname><forenames>Mauricio</forenames></author><author><keyname>Bartesaghi</keyname><forenames>Alberto</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>A Practical Guide to Multi-image Alignment</title><categories>eess.IV</categories><comments>To appear in ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-image alignment, bringing a group of images into common register, is an
ubiquitous problem and the first step of many applications in a wide variety of
domains. As a result, a great amount of effort is being invested in developing
efficient multi-image alignment algorithms. Little has been done, however, to
answer fundamental practical questions such as: what is the comparative
performance of existing methods? is there still room for improvement? under
which conditions should one technique be preferred over another? does adding
more images or prior image information improve the registration results? In
this work, we present a thorough analysis and evaluation of the main
multi-image alignment methods which, combined with theoretical limits in
multi-image alignment performance, allows us to organize them under a common
framework and provide practical answers to these essential questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03310</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03310</id><created>2018-02-08</created><authors><author><keyname>Madiraju</keyname><forenames>Naveen Sai</forenames></author><author><keyname>Kurella</keyname><forenames>Naresh</forenames></author><author><keyname>Valapudasu</keyname><forenames>Rama</forenames></author></authors><title>FPGA Implementation of ECG feature extraction using Time domain analysis</title><categories>eess.SP cs.AR</categories><comments>4 Pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An electrocardiogram (ECG) feature extraction system has been developed and
evaluated using Virtex-6 FPGA kit which belongs to Xilinx Ltd. In time domain,
Pan-Tompkins algorithm is used for QRS detection and it is followed by a
feature extractor block to extract ECG features. This whole system can be used
to detect cardiac arrhythmia. The completed algorithm was implemented on
Virtex-6(XC6VLX240-T) device and tested using hardware co-simulation in
Modelsim and simulink environment. The software generated ECG signals are
obtained from MIT-BIH arrhythmia Database [1]. The memory and time complexities
of the implemented design were recorded and feature extraction has been done.
We have achieved satisfactory results which is mainly due to parallel
implementation. Therefore accurate arrhythmia detection using hardware
implementation a viable approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03319</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03319</id><created>2018-02-09</created><authors><author><keyname>Ebrahimi</keyname><forenames>Samaneh</forenames></author><author><keyname>Vahabi</keyname><forenames>Hossein</forenames></author><author><keyname>Prockup</keyname><forenames>Matthew</forenames></author><author><keyname>Nieto</keyname><forenames>Oriol</forenames></author></authors><title>Predicting Audio Advertisement Quality</title><categories>stat.ML cs.SD eess.AS</categories><comments>WSDM '18 Proceedings of the Eleventh ACM International Conference on
  Web Search and Data Mining, 9 pages</comments><journal-ref>2018. In Proceedings of the Eleventh ACM International Conference
  on Web Search and Data Mining (WSDM '18)</journal-ref><doi>10.1145/3159652.3159701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online audio advertising is a particular form of advertising used abundantly
in online music streaming services. In these platforms, which tend to host tens
of thousands of unique audio advertisements (ads), providing high quality ads
ensures a better user experience and results in longer user engagement.
Therefore, the automatic assessment of these ads is an important step toward
audio ads ranking and better audio ads creation. In this paper we propose one
way to measure the quality of the audio ads using a proxy metric called Long
Click Rate (LCR), which is defined by the amount of time a user engages with
the follow-up display ad (that is shown while the audio ad is playing) divided
by the impressions. We later focus on predicting the audio ad quality using
only acoustic features such as harmony, rhythm, and timbre of the audio,
extracted from the raw waveform. We discuss how the characteristics of the
sound can be connected to concepts such as the clarity of the audio ad message,
its trustworthiness, etc. Finally, we propose a new deep learning model for
audio ad quality prediction, which outperforms the other discussed models
trained on hand-crafted features. To the best of our knowledge, this is the
first large-scale audio ad quality prediction study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03453</identifier>
 <datestamp>2019-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03453</id><created>2018-02-09</created><authors><author><keyname>Lee</keyname><forenames>Brian C.</forenames></author><author><keyname>Tward</keyname><forenames>Daniel J.</forenames></author><author><keyname>Mitra</keyname><forenames>Partha P.</forenames></author><author><keyname>Miller</keyname><forenames>Michael I.</forenames></author></authors><title>On variational solutions for whole brain serial-section histology using
  the computational anatomy random orbit model</title><categories>eess.IV</categories><doi>10.1371/journal.pcbi.1006610</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a variational framework for dense diffeomorphic
atlas-mapping onto high-throughput histology stacks at the 20 um meso-scale.
The observed sections are modelled as Gaussian random fields conditioned on a
sequence of unknown section by section rigid motions and unknown diffeomorphic
transformation of a three-dimensional atlas. To regularize over the
high-dimensionality of our parameter space (which is a product space of the
rigid motion dimensions and the diffeomorphism dimensions), the histology
stacks are modelled as arising from a first order Sobolev space smoothness
prior. We show that the joint maximum a-posteriori, penalized-likelihood
estimator of our high dimensional parameter space emerges as a joint
optimization interleaving rigid motion estimation for histology restacking and
large deformation diffeomorphic metric mapping to atlas coordinates. We show
that joint optimization in this parameter space solves the classical curvature
non-identifiability of the histology stacking problem. The algorithms are
demonstrated on a collection of whole-brain histological image stacks from the
Mouse Brain Architecture Project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03457</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03457</id><created>2018-02-09</created><authors><author><keyname>Salahdine</keyname><forenames>Fatima</forenames></author><author><keyname>Kaabouch</keyname><forenames>Naima</forenames></author><author><keyname>Ghazi</keyname><forenames>Hassan El</forenames></author></authors><title>Bayesian Compressive Sensing with Circulant Matrix for Spectrum Sensing
  in Cognitive Radio Networks</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/UEMCON.2016.7777851</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For wideband spectrum sensing, compressive sensing has been proposed as a
solution to speed up the high dimensional signals sensing and reduce the
computational complexity. Compressive sensing consists of acquiring the
essential information from a sparse signal and recovering it at the receiver
based on an efficient sampling matrix and a reconstruction technique. In order
to deal with the uncertainty, improve the signal acquisition performance, and
reduce the randomness during the sensing and reconstruction processes,
compressive sensing requires a robust sampling matrix and an efficient
reconstruction technique. In this paper, we propose an approach that combines
the advantages of a Circulant matrix with Bayesian models. This approach is
implemented, extensively tested, and its results have been compared to those of
l1 norm minimization with a Circulant or random matrix based on several
metrics. These metrics are Mean Square Error, reconstruction error,
correlation, recovery time, sampling time, and processing time. The results
show that our technique is faster and more efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03472</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03472</id><created>2018-02-09</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author><author><keyname>Ahmad</keyname><forenames>M. Omair</forenames></author></authors><title>Modeling of Teager Energy Operated Perceptual Wavelet Packet
  Coefficients with an Erlang-2 PDF for Real Time Enhancement of Noisy Speech</title><categories>eess.AS cs.SD</categories><comments>To appear in Digital Signal Processing, 27 pages, 19 figures, 10
  tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for real time enhancement of noisy speech, a method of
threshold determination based on modeling of Teager energy (TE) operated
perceptual wavelet packet (PWP) coefficients of the noisy speech and noise by
an Erlang-2 PDF is presented. The proposed method is computationally much
faster than the existing wavelet packet based thresholding methods. A custom
thresholding function based on a combination of mu-law and semisoft
thresholding functions is designed and exploited to apply the statistically
derived threshold upon the PWP coefficients. The proposed custom thresholding
function works as a mu-law or a semisoft thresholding function or their
combination based on the probability of speech presence and absence in a
subband of the PWP transformed noisy speech. By using the speech files
available in NOIZEUS database, a number of simulations are performed to
evaluate the performance of the proposed method for speech signals in the
presence of Gaussian white and street noises. The proposed method outperforms
some of the state-of-the-art speech enhancement methods both at high and low
levels of SNRs in terms of standard objective measures and subjective
evaluations including formal listening tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03503</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03503</id><created>2018-02-09</created><authors><author><keyname>Ling</keyname><forenames>Zenan</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author><author><keyname>He</keyname><forenames>Xing</forenames></author><author><keyname>Chu</keyname><forenames>Lei</forenames></author></authors><title>A New Approach of Exploiting Self-Adjoint Matrix Polynomials of Large
  Random Matrices for Anomaly Detection and Fault Location</title><categories>stat.AP eess.SP</categories><comments>12 pages, 13 figures, submitted to IEEE Trans on Big Data</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synchronized measurements of a large power grid enable an unprecedented
opportunity to study the spatialtemporal correlations. Statistical analytics
for those massive datasets start with high-dimensional data matrices.
Uncertainty is ubiquitous in a future's power grid. These data matrices are
recognized as random matrices. This new point of view is fundamental in our
theoretical analysis since true covariance matrices cannot be estimated
accurately in a high-dimensional regime. As an alternative, we consider
large-dimensional sample covariance matrices in the asymptotic regime to
replace the true covariance matrices. The self-adjoint polynomials of
large-dimensional random matrices are studied as statistics for big data
analytics. The calculation of the asymptotic spectrum distribution (ASD) for
such a matrix polynomial is understandably challenging. This task is made
possible by a recent breakthrough in free probability, an active research
branch in random matrix theory. This is the very reason why the work of this
paper is inspired initially. The new approach is interesting in many aspects.
The mathematical reason may be most critical. The real-world problems can be
solved using this approach, however.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03542</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03542</id><created>2018-02-10</created><authors><author><keyname>Lee</keyname><forenames>Soonam</forenames></author><author><keyname>Fu</keyname><forenames>Chichen</forenames></author><author><keyname>Salama</keyname><forenames>Paul</forenames></author><author><keyname>Dunn</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Delp</keyname><forenames>Edward J.</forenames></author></authors><title>Tubule segmentation of fluorescence microscopy images based on
  convolutional neural networks with inhomogeneity correction</title><categories>cs.CV cs.LG eess.IV</categories><comments>IS&amp;T International Symposium on Electronic Imaging 2018</comments><doi>10.2352/ISSN.2470-1173.2018.15.COIMG-199</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence microscopy has become a widely used tool for studying various
biological structures of in vivo tissue or cells. However, quantitative
analysis of these biological structures remains a challenge due to their
complexity which is exacerbated by distortions caused by lens aberrations and
light scattering. Moreover, manual quantification of such image volumes is an
intractable and error-prone process, making the need for automated image
analysis methods crucial. This paper describes a segmentation method for
tubular structures in fluorescence microscopy images using convolutional neural
networks with data augmentation and inhomogeneity correction. The segmentation
results of the proposed method are visually and numerically compared with other
microscopy segmentation methods. Experimental results indicate that the
proposed method has better performance with correctly segmenting and
identifying multiple tubular structures compared to other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03581</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03581</id><created>2018-02-10</created><authors><author><keyname>Ko</keyname><forenames>Kyung Pyo</forenames></author><author><keyname>Lee</keyname><forenames>Kwang Hee</forenames></author><author><keyname>Jang</keyname><forenames>Mi So</forenames></author><author><keyname>Park</keyname><forenames>Gun Hong</forenames></author></authors><title>2-gram-based Phonetic Feature Generation for Convolutional Neural
  Network in Assessment of Trademark Similarity</title><categories>cs.SD cs.CV eess.AS</categories><comments>10 pages, 6 figures, 10 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A trademark is a mark used to identify various commodities. If same or
similar trademark is registered for the same or similar commodity, the
purchaser of the goods may be confused. Therefore, in the process of trademark
registration examination, the examiner judges whether the trademark is the same
or similar to the other applied or registered trademarks. The confusion in
trademarks is based on the visual, phonetic or conceptual similarity of the
marks. In this paper, we focus specifically on the phonetic similarity between
trademarks. We propose a method to generate 2D phonetic feature for
convolutional neural network in assessment of trademark similarity. This
proposed algorithm is tested with 12,553 trademark phonetic similar pairs and
34,020 trademark phonetic non-similar pairs from 2010 to 2016. As a result, we
have obtained approximately 92% judgment accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03720</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03720</id><created>2018-02-11</created><authors><author><keyname>Paridar</keyname><forenames>Roya</forenames></author><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Double Minimum Variance Beamforming Method to Enhance Photoacoustic
  Imaging</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the common algorithms used to reconstruct photoacoustic (PA) images is
the non-adaptive Delay-and-Sum (DAS) beamformer. However, the quality of the
reconstructed PA images obtained by DAS is not satisfying due to its high level
of sidelobes and wide mainlobe. In contrast, adaptive beamformers, such as
minimum variance (MV), result in an improved image compared to DAS. In this
paper, a novel beamforming method, called Double MV (D-MV) is proposed to
enhance the image quality compared to the MV. It is shown that there is a
summation procedure between the weighted subarrays in the output of the MV
beamformer. This summation can be interpreted as the non-adaptive DAS
beamformer. It is proposed to replace the existing DAS with the MV algorithm to
reduce the contribution of the off-axis signals caused by the DAS beamformer
between the weighted subarrays. The numerical results show that the proposed
technique improves the full-width-half-maximum (FWHM) and signal-to-noise ratio
(SNR) for about 28.83 \mu m and 4.8 dB in average, respectively, compared to MV
beamformer. Also, quantitative evaluation of the experimental results indicates
that the proposed D-MV leads to 0.15 mm and 1.96 dB improvement in FWHM and
SNR, in comparison with MV beamformer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03724</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03724</id><created>2018-02-11</created><authors><author><keyname>Paridar</keyname><forenames>Roya</forenames></author><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mehrmohammadi</keyname><forenames>Mohammad</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Photoacoustic Image Formation Based on Sparse Regularization of Minimum
  Variance Beamformer</title><categories>eess.SP</categories><journal-ref>Biomedical Optics Express Vol. 9, Issue 6, pp. 2544-2561 (2018)</journal-ref><doi>10.1364/BOE.9.002544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay-and-Sum (DAS) is the most common algorithm used in photoacoustic (PA)
image formation. However, this algorithm results in a reconstructed image with
a wide mainlobe and high level of sidelobes. Minimum variance (MV), as an
adaptive beamformer, overcomes these limitations and improves the image
resolution and contrast. In this paper, a novel algorithm, named
modified-sparse-MV (MS-MV) is proposed in which a L1-norm constraint is added
to the MV minimization problem after some modifications, in order to suppress
the sidelobes more efficiently, compared to MV. The added constraint can be
interpreted as the sparsity of the output of the MV beamformed signals. Since
the final minimization problem is convex, it can be solved efficiently using a
simple iterative algorithm. The numerical results show that the proposed
method, MS-MV beamformer, improves the signal-to-noise (SNR) about 19.48 dB, in
average, compared to MV. Also, the experimental results, using a wire-target
phantom, show that MS-MV leads to SNR improvement of about 2.64 dB in
comparison with the MV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03784</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03784</id><created>2018-02-11</created><authors><author><keyname>Huo</keyname><forenames>Haiye</forenames></author><author><keyname>Sun</keyname><forenames>Wenchang</forenames></author><author><keyname>Xiao</keyname><forenames>Li</forenames></author></authors><title>Uncertainty Principles Associated with the Offset Linear Canonical
  Transform</title><categories>eess.SP</categories><comments>13 pages</comments><doi>10.1002/mma.5353</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a time-shifted and frequency-modulated version of the linear canonical
transform (LCT), the offset linear canonical transform (OLCT) provides a more
general framework of most existing linear integral transforms in signal
processing and optics. To study simultaneous localization of a signal and its
OLCT, the classical Heisenberg's uncertainty principle has been recently
generalized for the OLCT. In this paper, we complement it by presenting another
two uncertainty principles, i.e., Donoho-Stark's uncertainty principle and
Amrein-Berthier-Benedicks's uncertainty principle, for the OLCT. Moreover, we
generalize the short-time LCT to the short-time OLCT. We likewise present
Lieb's uncertainty principle for the short-time OLCT and give a lower bound for
its essential support.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03785</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03785</id><created>2018-02-11</created><updated>2018-06-06</updated><authors><author><keyname>Huo</keyname><forenames>Haiye</forenames></author></authors><title>Uncertainty Principles for the Offset Linear Canonical Transform</title><categories>eess.SP</categories><comments>13 pages</comments><journal-ref>Circuits, Systems and Signal Processing,2018</journal-ref><doi>10.1007/s00034-018-0863-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The offset linear canonical transform (OLCT) provides a more general
framework for a number of well known linear integral transforms in signal
processing and optics, such as Fourier transform, fractional Fourier transform,
linear canonical transform. In this paper, to characterize simultaneous
localization of a signal and its OLCT, we extend some different uncertainty
principles (UPs), including Nazarov's UP, Hardy's UP, Beurling's UP,
logarithmic UP and entropic UP, which have already been well studied in the
Fourier transform domain over the last few decades, to the OLCT domain in a
broader sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03789</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03789</id><created>2018-02-11</created><updated>2018-07-17</updated><authors><author><keyname>Huo</keyname><forenames>Haiye</forenames></author></authors><title>A new convolution theorem associated with the linear canonical transform</title><categories>eess.SP</categories><comments>13 pages</comments><journal-ref>Signal Image and Video Processing, July 2018</journal-ref><doi>10.1007/s11760-018-1337-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first introduce a new notion of canonical convolution
operator, and show that it satisfies the commutative, associative, and
distributive properties, which may be quite useful in signal processing.
Moreover, it is proved that the generalized convolution theorem and generalized
Young's inequality are also hold for the new canonical convolution operator
associated with the LCT. Finally, we investigate the sufficient and necessary
conditions for solving a class of convolution equations associated with the
LCT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03837</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03837</id><created>2018-02-11</created><updated>2018-10-30</updated><authors><author><keyname>Semiari</keyname><forenames>Omid</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Integrated Millimeter Wave and Sub-6 GHz Wireless Networks: A Roadmap
  for Joint Mobile Broadband and Ultra-Reliable Low-Latency Communications</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>Accepted in IEEE Wireless Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next-generation wireless networks must enable emerging technologies such as
augmented reality and connected autonomous vehicles via wide range of wireless
services that span enhanced mobile broadband (eMBB), as well as ultra-reliable
low-latency communication (URLLC). Existing wireless systems that solely rely
on the scarce sub-6 GHz, microwave ($\mu$W) frequency bands will be unable to
meet such stringent and mixed service requirements for future wireless services
due to spectrum scarcity. Meanwhile, operating at high-frequency millimeter
wave (mmWave) bands is seen as an attractive solution, primarily due to the
bandwidth availability and possibility of large-scale multi-antenna
communication. However, mmWave communication is inherently unreliable due to
its susceptibility to blockage, high path loss, and channel uncertainty. Hence,
to provide URLLC and high-speed wireless access, it is desirable to seamlessly
integrate the reliability of $\mu$W networks with the high capacity of mmWave
networks. To this end, in this paper, the first comprehensive tutorial for
\emph{integrated mmWave-$\mu$W} communications is introduced. This envisioned
integrated design will enable wireless networks to achieve URLLC along with
eMBB by leveraging the best of two worlds: reliable, long-range communications
at the $\mu$W bands and directional high-speed communications at the mmWave
frequencies. To achieve this goal, key solution concepts are discussed that
include new architectures for the radio interface, URLLC-aware frame structure
and resource allocation methods along with mobility management, to realize the
potential of integrated mmWave-$\mu$W communications. The opportunities and
challenges of each proposed scheme are discussed and key results are presented
to show the merits of the developed integrated mmWave-$\mu$W framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03867</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03867</id><created>2018-02-11</created><authors><author><keyname>Zhu</keyname><forenames>Dalin</forenames></author><author><keyname>Choi</keyname><forenames>Junil</forenames></author><author><keyname>Cheng</keyname><forenames>Qian</forenames></author><author><keyname>Xiao</keyname><forenames>Weimin</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>High-Resolution Angle Tracking for Mobile Wideband Millimeter-Wave
  Systems with Antenna Array Calibration</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) systems use directional beams to support high-rate
data communications. Small misalignment between the transmit and receive beams
(e.g., due to the mobility) can result in significant drop of the received
signal quality especially in line-of-sight communication channels. In this
paper, we propose and evaluate high-resolution angle tracking strategies for
wideband mmWave systems with mobility. We custom design pairs of auxiliary
beams as the tracking beams, and use them to capture the angle variations,
towards which the steering directions of the data beams are adjusted. Different
from conventional beam tracking designs, the proposed framework neither depends
on the angle variation model nor requires an on-grid assumption. For practical
implementation of the proposed methods, we examine the impact of the array
calibration errors on the auxiliary beam pair design. Numerical results reveal
that by employing the proposed methods, good angle tracking performance can be
achieved under various antenna array configurations, channel models, and
mobility conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03883</identifier>
 <datestamp>2018-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03883</id><created>2018-02-11</created><updated>2018-09-21</updated><authors><author><keyname>Md</keyname><forenames>Sameeulla Khan</forenames></author><author><keyname>Channappayya</keyname><forenames>Sumohana</forenames></author></authors><title>Estimating Depth-Salient Edges And its Application To Stereoscopic Image
  Quality Assessment</title><categories>eess.IV</categories><comments>The work is incomplete and also lack of novelty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The human visual system pays attention to salient regions while perceiving an
image. When viewing a stereoscopic 3D (S3D) image, we hypothesize that while
most of the contribution to saliency is provided by the 2D image, a small but
significant contribution is provided by the depth component. Further, we claim
that only a subset of image edges contribute to depth perception while viewing
an S3D image. In this paper, we propose a systematic approach for depth
saliency estimation, called Salient Edges with respect to Depth perception
(SED) which localizes the depth-salient edges in an S3D image. We demonstrate
the utility of SED in full reference stereoscopic image quality assessment
(FRSIQA). We consider gradient magnitude and inter-gradient maps for predicting
structural similarity. A coarse quality estimate is derived first by comparing
the 2D saliency and gradient maps of reference and test stereo pairs. We refine
this quality using SED maps for evaluating depth quality. Finally, we combine
this luminance and depth quality to obtain an overall stereo image quality. We
perform a comprehensive evaluation of our metric on seven publicly available
S3D IQA databases. The proposed metric shows competitive performance on all
seven databases with state-of-the-art performance on three of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03897</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03897</id><created>2018-02-12</created><authors><author><keyname>Cao</keyname><forenames>Kai</forenames></author><author><keyname>Lu</keyname><forenames>Peizhong</forenames></author><author><keyname>Zou</keyname><forenames>Yan</forenames></author><author><keyname>Ling</keyname><forenames>Lin</forenames></author></authors><title>A Novel Sub-Nyquist Multiband Signal Detection Algorithm for Cognitive
  Radio</title><categories>eess.SP</categories><comments>This work is to be submitted to the journal IEEE Transactions on
  Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wideband spectrum sensing (WSS) is an essential technology for cognitive
radio. However, the sampling rate is still a bottleneck of WSS. Several
sub-Nyquist sensing methods have been proposed. These technologies deteriorate
in the low signal to noise ratio (SNR) regime or suffer high computational
complexity. In this paper, we propose a novel sub-Nyquist WSS method based on
Multi-coset (MC) sampling. We design a simple SNR-robust and low-complexity
multiband signal detection algorithm. In particular, the proposed method
differs the commonly used detection algorithms which are based on energy
detection (ED), matched filter (MF) or cyclostationary detection (CD). We
exploit the linear recurrent relation between the locations of nonzero
frequencies and the DFT of the arithmetic-shifted subsampled signals. These
relations can be uniquely expressed by a series of the so-called frequency
locator polynomials (FLPs). The scalar of the relations is related to the
bandwidths of the subsignals. Basing on this, we propose a detector for sparse
multiband signals along with the method estimating carrier frequency and
bandwidth. The detector does not require priori knowledge about the frequency
locations of the signals of interest. Moreover, it has lower complexity of both
samples and computation compared to CD in sparse case. Experimental results
show the detector outperforms ED in the sub-Nyquist regime especially in low
SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03904</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03904</id><created>2018-02-12</created><authors><author><keyname>Zhou</keyname><forenames>Fuhui</forenames></author><author><keyname>Beaulieu</keyname><forenames>Norman C.</forenames></author></authors><title>An Improved and More Accurate Expression for a PDF Related to
  Eigenvalue-Based Spectrum Sensing</title><categories>eess.SP</categories><comments>It has been accepted by IEEE Systems Journal</comments><doi>10.1109/JSYST.2018.2805891</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cooperative spectrum sensing based on the limiting eigenvalue ratio of the
covariance matrix offers superior detection performance and overcomes the noise
uncertainty problem. While an exact expression exists, it is complex and
multiple useful approximate expressions have been published in the literature.
An improved, more accurate, integral solution for the probability density
function of the ratio is derived using order statistical analysis to remove the
simplifying, but incorrect, independence assumption. Thereby, the letter makes
an advance in the rigorous theory of eigenvalue-based spectrum sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03906</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03906</id><created>2018-02-12</created><authors><author><keyname>Zhou</keyname><forenames>Fuhui</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Sun</keyname><forenames>Haijian</forenames></author><author><keyname>Chu</keyname><forenames>Zheng</forenames></author></authors><title>UAV-Enabled Mobile Edge Computing: Offloading Optimization and
  Trajectory Design</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper has been accepted by IEEE ICC 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the emergence of diverse mobile applications (such as augmented
reality), the quality of experience of mobile users is greatly limited by their
computation capacity and finite battery lifetime. Mobile edge computing (MEC)
and wireless power transfer are promising to address this issue. However, these
two techniques are susceptible to propagation delay and loss. Motivated by the
chance of short-distance line-of-sight achieved by leveraging unmanned aerial
vehicle (UAV) communications, an UAV-enabled wireless powered MEC system is
studied. A power minimization problem is formulated subject to the constraints
on the number of the computation bits and energy harvesting causality. The
problem is non-convex and challenging to tackle. An alternative optimization
algorithm is proposed based on sequential convex optimization. Simulation
results show that our proposed design is superior to other benchmark schemes
and the proposed algorithm is efficient in terms of the convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03908</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03908</id><created>2018-02-12</created><authors><author><keyname>Zhou</keyname><forenames>Fuhui</forenames></author><author><keyname>Chu</keyname><forenames>Zheng</forenames></author><author><keyname>Sun</keyname><forenames>Haijian</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Resource Allocation for Secure MISO-NOMA Cognitive Radios Relying on
  SWIPT</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted by IEEE ICC 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cognitive radio (CR) and non-orthogonal multiple access (NOMA) are two
promising technologies in the next generation wireless communication systems.
The security of a NOMA CR network (CRN) is important but lacks of study. In
this paper, a multiple-input single-output NOMA CRN relying on simultaneous
wireless information and power transfer is studied. In order to improve the
security of both the primary and secondary network, an artificial noise-aided
cooperative jamming scheme is proposed. Different from the most existing works,
a power minimization problem is formulated under a practical non-linear energy
harvesting model. A suboptimal scheme is proposed to solve this problem based
on semidefinite relaxation and successive convex approximation. Simulation
results show that the proposed cooperative jamming scheme is efficient to
achieve secure communication and NOMA outperforms the conventional orthogonal
multiple access in terms of the power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03944</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.03944</id><created>2018-02-12</created><authors><author><keyname>Wang</keyname><forenames>Guanchu</forenames></author><author><keyname>Wang</keyname><forenames>Kun</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Zou</keyname><forenames>Difan</forenames></author><author><keyname>Jiang</keyname><forenames>Zhimeng</forenames></author><author><keyname>Xu</keyname><forenames>Zhengyuan</forenames></author></authors><title>A 1Mbps Real-time NLOS UV Scattering Communication System with Receiver
  Diversity over 1km</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the non-line of sight (NLOS) ultraviolet (UV) scattering communication,
the received signals exhibit the characteristics of discrete photoelectrons due
to the extremely large path loss. We design and demonstrate an NLOS UV
scattering communication system in this work, where the receiver-side signal
detection is designed based on a discrete-time Poisson channel model. In our
system, a laser and multiple photomultiplier tubes are employed as the optical
transmitter and detector, respectively. Furthermore, we design algorithms for
pulse-counting, synchronization, channel estimation and $LLR$ computation for
hardware realization in FPGA board. Simulation results are provided to evaluate
the proposed system design and specify the system key parameters. We perform
field tests for real-time communication with the transmission range over $1$km,
where the system throughput reaches $1$Mbps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04041</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04041</id><created>2018-02-12</created><updated>2019-10-01</updated><authors><author><keyname>Thom&#xe4;</keyname><forenames>Reiner S.</forenames></author><author><keyname>Andrich</keyname><forenames>Carsten</forenames></author><author><keyname>Del Galdo</keyname><forenames>Giovanni</forenames></author><author><keyname>D&#xf6;bereiner</keyname><forenames>Michael</forenames></author><author><keyname>Hein</keyname><forenames>Matthias A.</forenames></author><author><keyname>K&#xe4;ske</keyname><forenames>Martin</forenames></author><author><keyname>Sch&#xe4;fer</keyname><forenames>G&#xfc;nter</forenames></author><author><keyname>Schieler</keyname><forenames>Steffen</forenames></author><author><keyname>Schneider</keyname><forenames>Christian</forenames></author><author><keyname>Schwind</keyname><forenames>Andreas</forenames></author><author><keyname>Wendland</keyname><forenames>Philip</forenames></author></authors><title>Cooperative Passive Coherent Location: A Promising 5G Service to Support
  Road Safety</title><categories>eess.SP</categories><journal-ref>IEEE Communications Magazine, vol. 57, no. 9, pp. 86-92, September
  2019</journal-ref><doi>10.1109/MCOM.001.1800242</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G promises many new vertical service areas beyond simple communication and
data transfer. We propose CPCL (cooperative passive coherent location), a
distributed MIMO radar service, which can be offered by mobile radio network
operators as a service for public user groups. CPCL comes as an inherent part
of the radio network and takes advantage of the most important key features
proposed for 5G. It extends the well-known idea of passive radar (also known as
passive coherent location, PCL) by introducing cooperative principles. These
range from cooperative, synchronous radio signaling, and MAC up to radar data
fusion on sensor and scenario levels. By using software-defined radio and
network paradigms, as well as real-time mobile edge computing facilities
intended for 5G, CPCL promises to become a ubiquitous radar service which may
be adaptive, reconfigurable, and perhaps cognitive. As CPCL makes double use of
radio resources (both in terms of frequency bands and hardware), it can be
considered a green technology. Although we introduce the CPCL idea from the
viewpoint of vehicle-to-vehicle/infrastructure (V2X) communication, it can
definitely also be applied to many other applications in industry, transport,
logistics, and for safety and security applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04051</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04051</id><created>2018-02-12</created><updated>2019-02-11</updated><authors><author><keyname>Kim</keyname><forenames>Jaehun</forenames><affiliation>Delft University of Technology</affiliation></author><author><keyname>Urbano</keyname><forenames>Juli&#xe1;n</forenames><affiliation>Delft University of Technology</affiliation></author><author><keyname>Liem</keyname><forenames>Cynthia C. S.</forenames><affiliation>Delft University of Technology</affiliation></author><author><keyname>Hanjalic</keyname><forenames>Alan</forenames><affiliation>Delft University of Technology</affiliation></author></authors><title>One Deep Music Representation to Rule Them All? : A comparative analysis
  of different representation learning strategies</title><categories>cs.NE cs.SD eess.AS</categories><comments>This work has been accepted to &quot;Neural Computing and Applications:
  Special Issue on Deep Learning for Music and Audio&quot;</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Inspired by the success of deploying deep learning in the fields of Computer
Vision and Natural Language Processing, this learning paradigm has also found
its way into the field of Music Information Retrieval. In order to benefit from
deep learning in an effective, but also efficient manner, deep transfer
learning has become a common approach. In this approach, it is possible to
reuse the output of a pre-trained neural network as the basis for a new
learning task. The underlying hypothesis is that if the initial and new
learning tasks show commonalities and are applied to the same type of input
data (e.g. music audio), the generated deep representation of the data is also
informative for the new task. Since, however, most of the networks used to
generate deep representations are trained using a single initial learning
source, their representation is unlikely to be informative for all possible
future tasks. In this paper, we present the results of our investigation of
what are the most important factors to generate deep representations for the
data and learning tasks in the music domain. We conducted this investigation
via an extensive empirical study that involves multiple learning sources, as
well as multiple deep learning architectures with varying levels of information
sharing between sources, in order to learn music representations. We then
validate these representations considering multiple target datasets for
evaluation. The results of our experiments yield several insights on how to
approach the design of methods for learning widely deployable deep data
representations in the music domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04076</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04076</id><created>2018-02-09</created><authors><author><keyname>Airod</keyname><forenames>Fatima Ezzahra</forenames></author><author><keyname>Chafnaji</keyname><forenames>Houda</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Performance Analysis of Low Latency Multiple Full-Duplex Selective
  Decode and Forward Relays</title><categories>cs.IT cs.PF eess.SP math.IT</categories><comments>Accepted to the Emerging Technologies, Architectures and Services of
  the IEEE WCNC 2018 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to follow up with mission-critical applications, new features need
to be carried to satisfy a reliable communication with reduced latency. With
this regard, this paper proposes a low latency cooperative transmission scheme,
where multiple full-duplex relays, simultaneously, assist the communication
between a source node and a destination node. First, we present the
communication model of the proposed transmission scheme. Then, we derive the
outage probability closed-form for two cases: asynchronous transmission (where
all relays have different processing delay) and synchronous transmissions
(where all relays have the same processing delay). Finally, using simulations,
we confirm the theoretical results and compare the proposed multi-relays
transmission scheme with relay selection schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04113</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04113</id><created>2018-02-12</created><authors><author><keyname>Zhang</keyname><forenames>Xiao-Lei</forenames></author></authors><title>Linear Regression for Speaker Verification</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a linear regression based back-end for speaker
verification. Linear regression is a simple linear model that minimizes the
mean squared estimation error between the target and its estimate with a closed
form solution, where the target is defined as the ground-truth indicator
vectors of utterances. We use the linear regression model to learn speaker
models from a front-end, and verify the similarity of two speaker models by a
cosine similarity scoring classifier. To evaluate the effectiveness of the
linear regression model, we construct three speaker verification systems that
use the Gaussian mixture model and identity-vector (GMM/i-vector) front-end,
deep neural network and i-vector (DNN/i-vector) front-end, and deep vector
(d-vector) front-end as their front-ends, respectively. Our empirical
comparison results on the NIST speaker recognition evaluation data sets show
that the proposed method outperforms within-class covariance normalization,
linear discriminant analysis, and probabilistic linear discriminant analysis,
given any of the three front-ends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04156</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04156</id><created>2018-02-12</created><authors><author><keyname>Ly</keyname><forenames>Tiffany</forenames></author><author><keyname>Thompson</keyname><forenames>Jeremy</forenames></author><author><keyname>Harris</keyname><forenames>Tajie</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>The Coupled TuFF-BFF Algorithm for Automatic 3D Segmentation of
  Microglia</title><categories>eess.IV</categories><comments>submitted as a conference contribution to International Conference on
  Image Processing 2018</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose an automatic 3D segmentation algorithm for multiphoton microscopy
images of microglia. Our method is capable of segmenting tubular and blob-like
structures from noisy images. Current segmentation techniques and software fail
to capture the fine processes and soma of the microglia cells, useful for the
study of the microglia role in the brain during healthy and diseased states.
Our coupled tubularity flow field (TuFF)-blob flow field (BFF) method evolves a
level set toward the object boundary using the directional tubularity and
blobness measure of 3D images. Our method found a 20% performance increase
against state of the art segmentation methods on a dataset of 3D images of
microglia even in images with intensity heterogeneity throughout the object.
The coupled TuFF-BFF segmentation results also yielded 40% improvement in
accuracy for the ramification index of the processes, which displays the
efficacy of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04258</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04258</id><created>2018-02-11</created><updated>2018-04-27</updated><authors><author><keyname>Ceddia</keyname><forenames>David</forenames></author><author><keyname>Paganin</keyname><forenames>David M.</forenames></author></authors><title>On Random-Matrix Bases, Ghost Imaging and X-ray Phase Contrast
  Computational Ghost Imaging</title><categories>eess.IV</categories><comments>15 pages, 3 figures. V2 contains several points of added
  clarification and figure updates in response to helpful feedback</comments><journal-ref>Phys. Rev. A 97, 062119 (2018)</journal-ref><doi>10.1103/PhysRevA.97.062119</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theory of random-matrix bases is presented, including expressions for
orthogonality, completeness and the random-matrix synthesis of arbitrary
matrices. This is applied to ghost imaging as the realization of a random-basis
reconstruction, including an expression for the resulting signal-to-noise
ratio. Analysis of conventional direct imaging and ghost imaging leads to a
criterion which, when satisfied, implies reduced dose for computational ghost
imaging. We also propose an experiment for x-ray phase contrast computational
ghost imaging, which enables differential phase contrast to be achieved in an
x-ray ghost imaging context. We give a numerically robust solution to the
associated inverse problem of decoding differential phase contrast x-ray ghost
images, to yield a quantitative map of the projected thickness of the sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04371</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04371</id><created>2018-02-12</created><authors><author><keyname>Owusu-Mireku</keyname><forenames>Robert</forenames></author><author><keyname>Chiang</keyname><forenames>Hsiao-Dong</forenames></author></authors><title>A Direct Method for the Transient Stability Analysis of Transmission
  Switching Events</title><categories>eess.SP math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an energy-based method for the transient stability
analysis of a power system transmission switching event. In this method the
exit point of pseudo-fault trajectory is used to determine a relevant
controlling unstable equilibrium point (CUEP) for a switching event, the
stability of the switching event is then assessed based on the energy margin
between the computed relevant CUEP and the post-switching initial point. The
effectiveness of the method is demonstrated on switching events in the
structure-preserving models of a heavily loaded version of the WSCC 9-bus
3-machine system, and the base case IEEE 145-bus 50-machine system. A scheme
for the detailed analysis of power system switching events is then proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04388</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04388</id><created>2018-02-12</created><authors><author><keyname>Chow</keyname><forenames>Jacky C. K.</forenames></author></authors><title>Statistical Sensor Fusion of a 9-DoF MEMS IMU for Indoor Navigation</title><categories>eess.SP</categories><journal-ref>Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W7,
  333-338, 2017</journal-ref><doi>10.5194/isprs-archives-XLII-2-W7-333-2017</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sensor fusion of a MEMS IMU with a magnetometer is a popular system design,
because such 9-DoF (degrees of freedom) systems are capable of achieving
drift-free 3D orientation tracking. However, these systems are often vulnerable
to ambient magnetic distortions and lack useful position information; in the
absence of external position aiding (e.g. satellite/ultra-wideband positioning
systems) the dead-reckoned position accuracy from a 9-DoF MEMS IMU deteriorates
rapidly due to unmodelled errors. Positioning information is valuable in many
satellite-denied geomatics applications (e.g. indoor navigation, location-based
services, etc.). This paper proposes an improved 9-DoF IMU indoor pose tracking
method using batch optimization. By adopting a robust in-situ user
self-calibration approach to model the systematic errors of the accelerometer,
gyroscope, and magnetometer simultaneously in a tightly-coupled post-processed
least-squares framework, the accuracy of the estimated trajectory from a 9-DoF
MEMS IMU can be improved. Through a combination of relative magnetic
measurement updates and a robust weight function, the method is able to
tolerate a high level of magnetic distortions. The proposed auto-calibration
method was tested in-use under various heterogeneous magnetic field conditions
to mimic a person walking with the sensor in their pocket, a person checking
their phone, and a person walking with a smartwatch. In these experiments, the
presented algorithm improved the in-situ dead-reckoning orientation accuracy by
79.8 - 89.5% and the dead-reckoned positioning accuracy by 72.9 - 92.8%, thus
reducing the relative positioning error from metre-level to decimetre-level
after ten seconds of integration, without making assumptions about the user's
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04435</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04435</id><created>2018-02-12</created><authors><author><keyname>Yi</keyname><forenames>Zhehan</forenames></author><author><keyname>Babqi</keyname><forenames>Abdulrahman J.</forenames></author><author><keyname>Wang</keyname><forenames>Yishen</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Etemadi</keyname><forenames>Amir H.</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author><author><keyname>Huang</keyname><forenames>Bibin</forenames></author></authors><title>Finite-Control-Set Model Predictive Control (FCS-MPC) for Islanded
  Hybrid Microgrids</title><categories>math.OC eess.SP</categories><comments>This paper has been accepted by the 2018 IEEE PES General Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microgrids consisting of multiple distributed energy resources (DERs) provide
a promising solution to integrate renewable energies, e.g., solar photovoltaic
(PV) systems. Hybrid AC/DC microgrids leverage the merits of both AC and DC
power systems. In this paper, a control strategy for islanded multi-bus hybrid
microgrids is proposed based on the Finite-Control-Set Model Predictive Control
(FCS-MPC) technologies. The control loops are expedited by predicting the
future states and determining the optimal control action before switching
signals are sent. The proposed algorithm eliminates the needs of PI, PWM, and
droop components, and offers 1) accurate PV maximum power point tracking (MPPT)
and battery charging/discharging control, 2) DC and multiple AC bus
voltage/frequency regulation, 3) a precise power sharing scheme among DERs
without voltage or frequency deviation, and 4) a unified MPC design flow for
hybrid microgrids. Multiple case studies are carried out, which verify the
satisfactory performance of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04479</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04479</id><created>2018-02-13</created><authors><author><keyname>Ma</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Xun</forenames></author></authors><title>Phased Microphone Array for Sound Source Localization with Deep Learning</title><categories>eess.AS cs.SD</categories><comments>7 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To phased microphone array for sound source localization, algorithm with both
high computational efficiency and high precision is a persistent pursuit. In
this paper convolutional neural network (CNN) a kind of deep learning is
preliminarily applied as a new algorithm. At high frequency CNN can reconstruct
the sound localizations with excellent spatial resolution as good as DAMAS,
within a very short time as short as conventional beamforming. This exciting
result means that CNN perfectly finds source distribution directly from
cross-spectral matrix without given propagation function in advance, and thus
CNN deserves to be further explored as a new algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04513</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04513</id><created>2018-02-13</created><updated>2018-04-18</updated><authors><author><keyname>Formaggio</keyname><forenames>Francesco</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author></authors><title>Authentication of Satellite Navigation Signals by Wiretap Coding and
  Artificial Noise</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to combat the spoofing of global navigation satellite system (GNSS)
signals we propose a novel approach for satellite signal authentication based
on information-theoretic security. In particular we superimpose to the
navigation signal an authentication signal containing a secret message
corrupted by artificial noise (AN), still transmitted by the satellite. We
impose the following properties: a) the authentication signal is synchronous
with the navigation signal, b) the authentication signal is orthogonal to the
navigation signal and c) the secret message is undecodable by the attacker due
to the presence of the AN. The legitimate receiver synchronizes with the
navigation signal and stores the samples of the authentication signal with the
same synchronization. After the transmission of the authentication signal,
through a separate public asynchronous authenticated channel (e.g., a secure
Internet connection) additional information is made public allowing the
receiver to a) decode the secret message, thus overcoming the effects of AN,
and b) verify the secret message. We assess the performance of the proposed
scheme by the analysis of both the secrecy capacity of the authentication
message and the attack success probability, under various attack scenarios. A
comparison with existing approaches shows the effectiveness of the proposed
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04634</identifier>
 <datestamp>2019-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04634</id><created>2018-02-13</created><updated>2019-03-28</updated><authors><author><keyname>Mart&#xed;nez-Nuevo</keyname><forenames>Pablo</forenames></author><author><keyname>Oppenheim</keyname><forenames>Alan. V.</forenames></author></authors><title>Lattice Functions for the Analysis of Analog-to-Digital Conversion</title><categories>eess.SP cs.IT math.CV math.IT</categories><comments>9 pages, 5 figures, journal paper</comments><msc-class>30D20 (Primary) 30D15 (Secondary)</msc-class><acm-class>H.1.0</acm-class><doi>10.1109/TIT.2019.2907996</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog-to-digital (A/D) converters are the common interface between analog
signals and the domain of digital discrete-time signal processing. In essence,
this domain simultaneously incorporates quantization both in amplitude and
time, i.e. amplitude quantization and uniform time sampling. Thus, we view A/D
conversion as a sampling process in both the time and amplitude domains based
on the observation that the underlying continuous-time signals representing
digital sequences can be sampled in a lattice---i.e. at points restricted to
lie on a uniform grid both in time and amplitude. We refer to them as lattice
functions. This is in contrast with the traditional approach based on the
classical sampling theorem and quantization error analysis. The latter has been
mainly addressed with the help of probabilistic models, or deterministic ones
either confined to very particular scenarios or considering worst-case
assumptions. In this paper, we provide a deterministic theoretical analysis and
framework for the functions involved in digital discrete-time processing. We
show that lattice functions possess a rich analytic structure in the context of
integral-valued entire functions of exponential type. We derive set and
spectral properties of this class of functions. This allows us to prove in a
deterministic way and for general bandlimited functions a fundamental lower
bound on the maximum frequency component introduced by quantization that is
independent of the resolution of the quantizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04672</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04672</id><created>2018-02-13</created><updated>2020-02-07</updated><authors><author><keyname>Mart&#xed;nez-Nuevo</keyname><forenames>Pablo</forenames></author><author><keyname>Lai</keyname><forenames>Hsin-Yu</forenames></author><author><keyname>Oppenheim</keyname><forenames>Alan V.</forenames></author></authors><title>Delta-Ramp Encoder for Amplitude Sampling and its Interpretation as Time
  Encoding</title><categories>eess.SP cs.IT math.CV math.IT</categories><comments>12 pages, 11 figures, journal paper</comments><msc-class>30D20 (Primary) 30D15 (Secondary)</msc-class><acm-class>H.1.0; H.1.1; E.4</acm-class><doi>10.1109/TSP.2019.2904027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theoretical basis for conventional acquisition of bandlimited signals
typically relies on uniform time sampling and assumes infinite-precision
amplitude values. In this paper, we explore signal representation and recovery
based on uniform amplitude sampling with assumed infinite precision timing
information. The approach is based on the delta-ramp encoder which consists of
applying a one-level level-crossing detector to the result of adding an
appropriate sawtooth-like waveform to the input signal. The output samples are
the time instants of these level crossings, thus representing a time-encoded
version of the input signal. For theoretical purposes, this system can be
equivalently analyzed by reversibly transforming through ramp addition a
nonmonotonic input signal into a monotonic one which is then uniformly sampled
in amplitude. The monotonic function is then represented by the times at which
the signal crosses a predefined and equally-spaced set of amplitude values. We
refer to this technique as amplitude sampling. The time sequence generated can
be interpreted alternatively as nonuniform time sampling of the original source
signal. We derive duality and frequency-domain properties for the functions
involved in the transformation. Iterative algorithms are proposed and
implemented for recovery of the original source signal. As indicated in the
simulations, the proposed iterative amplitude-sampling algorithm achieves a
faster convergence rate than frame-based reconstruction for nonuniform
sampling. The performance can also be improved by appropriate choice of the
parameters while maintaining the same sampling density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04716</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04716</id><created>2018-02-13</created><authors><author><keyname>Righini</keyname><forenames>Davide</forenames></author><author><keyname>Tonello</keyname><forenames>Andrea M.</forenames></author></authors><title>Broadband MIMO Couplers Characterization and Comparison</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on MIMO Power Line Communication (PLC) to provide
increased performance. In MIMO PLC, appropriate coupling methods are necessary
in order to enable the effective injection of the signal through the broad band
PLC channel so that high data rates can be achieved. In this paper, we want to
analytically characterize strengths and weaknesses of each coupler design
(topology) from an electrical circuit perspective. We dwell on the description
and analysis of the three main and common configurations used for the MIMO
couplers: star (S), triangle ($\Delta$) and T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04820</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04820</id><created>2018-02-13</created><authors><author><keyname>Palmer</keyname><forenames>David M.</forenames></author><author><keyname>Holmes</keyname><forenames>Rebecca M.</forenames></author></authors><title>ELROI: A License Plate For Your Satellite</title><categories>astro-ph.IM eess.SP</categories><comments>Submitted to Journal of Spacecraft and Rockets</comments><report-no>LA-UR-17-28439</report-no><journal-ref>Journal of Spacecraft and Rockets, Vol. 55, No. 4 (2018), pp.
  1014-1023</journal-ref><doi>10.2514/1.A34106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space object identification is vital for operating spacecraft, space traffic
control, and space situational awareness, but initial determination,
maintenance, and recovery of identity are all difficult, expensive, and
error-prone, especially for small objects like CubeSats. Attaching a beacon or
license plate with a unique identification number to a space object before
launch would greatly simplify the task, but radio beacons are power-hungry and
can cause interference. This paper describes a new concept for a satellite
license plate, the Extremely Low Resource Optical Identifier or ELROI. ELROI is
a milliwatt-scale self-powered autonomous optical beacon that can be attached
to any space object to transmit a persistent identification signal to ground
stations. A system appropriate for a LEO CubeSat or other small space object
can fit in a package with the area of a postage stamp and a few millimeters
thick, and requires no power, data, or control from the host object. The
concept has been validated with ground tests, and the first flight test unit is
scheduled for launch in 2018. The unique identification number of a LEO
satellite can be determined unambiguously in a single orbital pass over a
low-cost ground station.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04869</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04869</id><created>2018-02-08</created><authors><author><keyname>Cheng</keyname><forenames>Chongsheng</forenames></author><author><keyname>Shen</keyname><forenames>Zhigang</forenames></author></authors><title>Time-Series Based Thermography on Concrete Block Void Detection</title><categories>eess.IV</categories><comments>11 pages, 5 color figures, and 1 table accepted by Construction
  Research Congress 2018 conference, April 2-7, 2018, New Orleans, LA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using thermography as a nondestructive method for subsurface detection of the
concrete structure has been developed for decades. However, the performance of
current practice is limited due to the heavy reliance on the environmental
conditions as well as complex environmental noises. A non-time-series method
suffers from the issue of solar radiation reflected by the target during
heating stage, and issues of potential non-uniform heat distribution. These
limitations are the major constraints of the traditional single thermal image
method. Time series-based methods such as Fourier transform-based pulse phase
thermography, principle component thermography, and high order statistics have
been reported with robust results on surface reflective property difference and
non-uniform heat distribution under the experimental setting. This paper aims
to compare the performance of above methods to that of the conventional static
thermal imaging method. The case used for the comparison is to detect voids in
a hollow concrete block during the heating phase. The result was quantitatively
evaluated by using Signal-to-Noise Ratio. Favorable performance was observed
using time-series methods compared to the single image approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.04931</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.04931</id><created>2018-02-13</created><authors><author><keyname>Wang</keyname><forenames>Qinglong</forenames></author></authors><title>Energy Spatio-Temporal Pattern Prediction for Electric Vehicle Networks</title><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information about the spatio-temporal pattern of electricity energy carried
by EVs, instead of EVs themselves, is crucial for EVs to establish more
effective and intelligent interactions with the smart grid. In this paper, we
propose a framework for predicting the amount of the electricity energy stored
by a large number of EVs aggregated within different city-scale regions, based
on spatio-temporal pattern of the electricity energy. The spatial pattern is
modeled via using a neural network based spatial predictor, while the temporal
pattern is captured via using a linear-chain conditional random field (CRF)
based temporal predictor. Two predictors are fed with spatial and temporal
features respectively, which are extracted based on real trajectories data
recorded in Beijing. Furthermore, we combine both predictors to build the
spatio-temporal predictor, by using an optimal combination coefficient which
minimizes the normalized mean square error (NMSE) of the predictions. The
prediction performance is evaluated based on extensive experiments covering
both spatial and temporal predictions, and the improvement achieved by the
combined spatio-temporal predictor. The experiment results show that the NMSE
of the spatio-temporal predictor is maintained below 0.1 for all investigate
regions of Beijing. We further visualize the prediction and discuss the
potential benefits can be brought to smart grid scheduling and EV charging by
utilizing the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05090</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05090</id><created>2018-02-14</created><authors><author><keyname>Huang</keyname><forenames>Yuwei</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cognitive UAV Communication via Joint Trajectory and Power Control</title><categories>eess.SP</categories><comments>5 papes, 2 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a new spectrum sharing scenario between unmanned
aerial vehicle (UAV) and terrestrial wireless communication systems. We
consider that a cognitive/secondary UAV transmitter communicates with a ground
secondary receiver (SR), in the presence of a number of primary terrestrial
communication links that operate over the same frequency band. We exploit the
UAV's controllable mobility via trajectory design, to improve the cognitive UAV
communication performance while controlling the co-channel interference at each
of the primary receivers (PRs). In particular, we maximize the average
achievable rate from the UAV to the SR over a finite mission/communication
period by jointly optimizing the UAV trajectory and transmit power allocation,
subject to constraints on the UAV's maximum speed, initial/final locations, and
average transmit power, as well as a set of interference temperature (IT)
constraints imposed at each of the PRs for protecting their communications.
However, the joint trajectory and power optimization problem is non-convex and
thus difficult to be solved optimally. To tackle this problem, we propose an
efficient algorithm that ensures to obtain a locally optimal solution by
applying the techniques of alternating optimization and successive convex
approximation (SCA). Numerical results show that our proposed joint UAV
trajectory and power control scheme significantly enhances the achievable rate
of the cognitive UAV communication system, as compared to benchmark schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05114</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05114</id><created>2018-02-09</created><authors><author><keyname>Petric</keyname><forenames>Danko</forenames></author><author><keyname>Milinkovic</keyname><forenames>Marija</forenames></author></authors><title>Comparison between CS and JPEG in terms of image compression</title><categories>eess.IV cs.MM</categories><comments>Paper sent for 7th Mediterranean Conference on Embedded Computing
  MECO 2018, Budva, Montenegro</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The comparison between two approaches, JPEG and Compressive Sensing, is done
in the paper. The approaches are compared in terms of image compression.
Comparison is done by measuring the image quality versus number of samples used
for image recovering. Images are visually compared. Also, numerical quality
value, PSNR, is calculated and compared for the two approaches. It is shown
that images, recovered by using the Compressive Sensing approach, have higher
PSNR values compared to the images under JPEG compression. Difference is larger
in grayscale images with small number of details, like e.g. medical images
(x-ray). The theory is supported by the experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05115</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05115</id><created>2018-02-08</created><authors><author><keyname>Konatar</keyname><forenames>Valentina</forenames></author><author><keyname>Vesovic</keyname><forenames>Maja</forenames></author></authors><title>The Hermite and Fourier transforms in sparse reconstruction of
  sinusoidal signals</title><categories>eess.SP cs.MM</categories><comments>Student paper submitted to Mediterranean Conference on Embedded
  Computing 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper observes the Hermite and the Fourier Transform domains in terms of
Frequency Hopping Spread Spectrum signals sparsification. Sparse signals can be
recovered from a reduced set of samples by using the Compressive Sensing
approach. The under-sampling and the reconstruction of those signals are also
analyzed in this paper. The number of measurements (available signal samples)
is varied and reconstruction performance is tested in all considered cases and
for both observed domains. The signal recovery is done using an adaptive
gradient based algorithm. The theory is verified with the experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05119</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05119</id><created>2018-02-12</created><authors><author><keyname>Naude</keyname><forenames>Jacques</forenames></author><author><keyname>Hofsajer</keyname><forenames>Ivan</forenames></author></authors><title>Random Switching for High Performance DC-DC Power Converters</title><categories>eess.SP</categories><comments>22 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random Pulse Width Modulation (RPWM) has been successfully applied in power
electronics for nearly 30 years. The effects of the various possible RPWM
strategies on the Power Spectral Density have been thoroughly studied. Despite
the effectiveness of RPWM in spreading harmonic content, an appeal is
consistently made to maintain the textbook Pulse Width Modulation scheme 'on
average'. Random Switching (RS) does away with this notion and
probabilistically operates the switch. In addition to fulfilling several
optimality conditions, including being the only viable switching strategy at
the theoretical limit of performance and having lower switching losses than any
other RPWM; RS allows for design of the DC behaviour separately from that of
the PSD. The pulse amplitude probability affects the DC and total PSD. The
first and second moment of the pulse length probability distribution affects
the shape of the envelope of the noise of the PSD. The minimum pulse length
acts like a selective harmonic filter. The PSD can therefore be shaped without
external filtering by changing these probabilities. Gaussian and Huffman pulse
length probabilities are shown to be good choices depending on whether
real-time PSD control or spectrum usage are the design goal. In addition, it is
shown that C\'uk's state space averaging model applies to RS, with $D \to p$,
hence no new tools are needed to understand the low frequency behavior or
control performance. A benefit of closed loop random switching is that no
filtering of the controlled variable is required. Randomly responding in a
biased manner dependent on the error is hence shown to be useful. There are
several good reasons to consider RS for high performance applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05123</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05123</id><created>2018-02-12</created><updated>2018-02-19</updated><authors><author><keyname>Kansakar</keyname><forenames>Prasanna</forenames></author><author><keyname>Munir</keyname><forenames>Arslan</forenames></author></authors><title>Selecting Microarchitecture Configuration of Processors for Internet of
  Things</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Transactions on Emerging Topics in
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things (IoT) makes use of ubiquitous internet connectivity to
form a network of everyday physical objects for purposes of automation, remote
data sensing and centralized management/control. IoT objects need to be
embedded with processing capabilities to fulfill these services. The design of
processing units for IoT objects is constrained by various stringent
requirements, such as performance, power, thermal dissipation etc. In order to
meet these diverse requirements, a multitude of processor design parameters
need to be tuned accordingly. In this paper, we propose a temporally efficient
design space exploration methodology which determines power and performance
optimized microarchitecture configurations. We also discuss the possible
combinations of these microarchitecture configurations to form an effective
two-tiered heterogeneous processor for IoT applications. We evaluate our design
space exploration methodology using a cycle-accurate simulator (ESESC) and a
standard set of PARSEC and SPLASH2 benchmarks. The results show that our
methodology determines microarchitecture configurations which are within
2.23%-3.69% of the configurations obtained from fully exhaustive exploration
while only exploring 3%-5% of the design space. Our methodology achieves on
average 24.16x speedup in design space exploration as compared to fully
exhaustive exploration in finding power and performance optimized
microarchitecture configurations for processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05125</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05125</id><created>2018-02-12</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author><author><keyname>Ahmad</keyname><forenames>M. Omair</forenames></author></authors><title>Enhancement of Noisy Speech with Low Speech Distortion Based on
  Probabilistic Geometric Spectral Subtraction</title><categories>eess.AS cs.SD</categories><comments>To appear in Computer Speech and Language, 16 pages, 13 figures, 8
  tables. arXiv admin note: text overlap with arXiv:1802.02665</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A speech enhancement method based on probabilistic geometric approach to
spectral subtraction (PGA) performed on short time magnitude spectrum is
presented in this paper. A confidence parameter of noise estimation is
introduced in the gain function of the proposed method to prevent subtraction
of the overestimated and underestimated noise, which not only removes the noise
efficiently but also prevents the speech distortion. The noise compensated
magnitude spectrum is then recombined with the unchanged phase spectrum to
produce a modified complex spectrum prior to synthesize an enhanced frame.
Extensive simulations are carried out using the speech files available in the
NOIZEUS database in order to evaluate the performance of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05132</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05132</id><created>2018-02-13</created><authors><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Mimilakis</keyname><forenames>Stylianos Ioannis</forenames></author><author><keyname>Floros</keyname><forenames>Andreas</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author><author><keyname>Schuller</keyname><forenames>Gerald</forenames></author></authors><title>Close Miking Empirical Practice Verification: A Source Separation
  Approach</title><categories>eess.AS cs.SD</categories><journal-ref>In Proceedings of the 142nd Audio Engineering Society Convention,
  Berlin, Germany, 2017</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Close miking represents a widely employed practice of placing a microphone
very near to the sound source in order to capture more direct sound and
minimize any pickup of ambient sound, including other, concurrently active
sources. It is used by the audio engineering community for decades for audio
recording, based on a number of empirical rules that were evolved during the
recording practice itself. But can this empirical knowledge and close miking
practice be systematically verified? In this work we aim to address this
question based on an analytic methodology that employs techniques and metrics
originating from the sound source separation evaluation field. In particular,
we apply a quantitative analysis of the source separation capabilities of the
close miking technique. The analysis is applied on a recording dataset obtained
at multiple positions of a typical musical hall, multiple distances between the
microphone and the sound source multiple microphone types and multiple level
differences between the sound source and the ambient acoustic component. For
all the above cases we compute the Source to Interference Ratio (SIR) metric.
The results obtained clearly demonstrate an optimum close-miking performance
that matches the current empirical knowledge of professional audio recording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05144</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05144</id><created>2018-02-14</created><authors><author><keyname>He</keyname><forenames>Yicong</forenames></author><author><keyname>Wang</keyname><forenames>Fei</forenames></author><author><keyname>Wang</keyname><forenames>Shiyuan</forenames></author><author><keyname>Ren</keyname><forenames>Pengju</forenames></author><author><keyname>Chen</keyname><forenames>Badong</forenames></author></authors><title>Maximum Total Correntropy Diffusion Adaptation over Networks with Noisy
  Links</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed estimation over networks draws much attraction in recent years.
In many situations, due to imperfect information communication among nodes, the
performance of traditional diffusion adaptive algorithms such as the diffusion
LMS (DLMS) may degrade. To deal with this problem, several modified DLMS
algorithms have been proposed. However, these DLMS based algorithms still
suffer from biased estimation and are not robust to impulsive link noise. In
this paper, we focus on improving the performance of diffusion adaptation with
noisy links from two aspects: accuracy and robustness. A new algorithm called
diffusion maximum total correntropy (DMTC) is proposed. The new algorithm is
theoretically unbiased in Gaussian noise, and can efficiently handle the link
noises in the presence of large outliers. The adaptive combination rule is
applied to further improve the performance. The stability analysis of the
proposed algorithm is given. Simulation results show that the DMTC algorithm
can achieve good performance in both Gaussian and non-Gaussian noise
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05162</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05162</id><created>2018-02-14</created><updated>2018-02-20</updated><authors><author><keyname>Colombo</keyname><forenames>Florian</forenames></author><author><keyname>Gerstner</keyname><forenames>Wulfram</forenames></author></authors><title>BachProp: Learning to Compose Music in Multiple Styles</title><categories>cs.SD eess.AS</categories><comments>Preliminary work. Under review by the 2018 International Conference
  on Machine Learning (ICML)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hand in hand with deep learning advancements, algorithms of music composition
increase in performance. However, most of the successful models are designed
for specific musical structures. Here, we present BachProp, an algorithmic
composer that can generate music scores in any style given sufficient training
data. To adapt BachProp to a broad range of musical styles, we propose a novel
normalized representation of music and train a deep network to predict the note
transition probabilities of a given music corpus. In this paper, new music
scores sampled by BachProp are compared with the original corpora via
crowdsourcing. This evaluation indicates that the music scores generated by
BachProp are not less preferred than the original music corpus the algorithm
was provided with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05178</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05178</id><created>2018-02-14</created><authors><author><keyname>Mehrabi</keyname><forenames>Adib</forenames></author><author><keyname>Choi</keyname><forenames>Keunwoo</forenames></author><author><keyname>Dixon</keyname><forenames>Simon</forenames></author><author><keyname>Sandler</keyname><forenames>Mark</forenames></author></authors><title>Similarity measures for vocal-based drum sample retrieval using deep
  convolutional auto-encoders</title><categories>cs.MM cs.SD eess.AS</categories><comments>ICASSP 2018 camera-ready</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The expressive nature of the voice provides a powerful medium for
communicating sonic ideas, motivating recent research on methods for query by
vocalisation. Meanwhile, deep learning methods have demonstrated
state-of-the-art results for matching vocal imitations to imitated sounds, yet
little is known about how well learned features represent the perceptual
similarity between vocalisations and queried sounds. In this paper, we address
this question using similarity ratings between vocal imitations and imitated
drum sounds. We use a linear mixed effect regression model to show how features
learned by convolutional auto-encoders (CAEs) perform as predictors for
perceptual similarity between sounds. Our experiments show that CAEs outperform
three baseline feature sets (spectrogram-based representations, MFCCs, and
temporal features) at predicting the subjective similarity ratings. We also
investigate how the size and shape of the encoded layer effects the predictive
power of the learned features. The results show that preservation of temporal
information is more important than spectral resolution for this application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05234</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05234</id><created>2018-02-14</created><authors><author><keyname>Yi</keyname><forenames>Jirong</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author></authors><title>Necessary and Sufficient Null Space Condition for Nuclear Norm
  Minimization in Low-Rank Matrix Recovery</title><categories>math.OC cs.IT cs.LG eess.SP math.IT stat.ML</categories><comments>17 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-rank matrix recovery has found many applications in science and
engineering such as machine learning, signal processing, collaborative
filtering, system identification, and Euclidean embedding. But the low-rank
matrix recovery problem is an NP hard problem and thus challenging. A commonly
used heuristic approach is the nuclear norm minimization. In [12,14,15], the
authors established the necessary and sufficient null space conditions for
nuclear norm minimization to recover every possible low-rank matrix with rank
at most r (the strong null space condition). In addition, in [12], Oymak et al.
established a null space condition for successful recovery of a given low-rank
matrix (the weak null space condition) using nuclear norm minimization, and
derived the phase transition for the nuclear norm minimization. In this paper,
we show that the weak null space condition in [12] is only a sufficient
condition for successful matrix recovery using nuclear norm minimization, and
is not a necessary condition as claimed in [12]. In this paper, we further give
a weak null space condition for low-rank matrix recovery, which is both
necessary and sufficient for the success of nuclear norm minimization. At the
core of our derivation are an inequality for characterizing the nuclear norms
of block matrices, and the conditions for equality to hold in that inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05235</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05235</id><created>2018-02-14</created><authors><author><keyname>Zaeemzadeh</keyname><forenames>Alireza</forenames></author><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author><author><keyname>Shahrasbi</keyname><forenames>Behzad</forenames></author><author><keyname>Rahnavard</keyname><forenames>Nazanin</forenames></author></authors><title>Robust Target Localization Based on Squared Range Iterative Reweighted
  Least Squares</title><categories>math.OC eess.SP</categories><comments>2017 IEEE 14th International Conference on Mobile Ad Hoc and Sensor
  Systems (MASS): http://ieeexplore.ieee.org/document/8108770/</comments><doi>10.1109/MASS.2017.50</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of target localization in the presence of outlying
sensors is tackled. This problem is important in practice because in many
real-world applications the sensors might report irrelevant data
unintentionally or maliciously. The problem is formulated by applying robust
statistics techniques on squared range measurements and two different
approaches to solve the problem are proposed. The first approach is
computationally efficient; however, only the objective convergence is
guaranteed theoretically. On the other hand, the whole-sequence convergence of
the second approach is established. To enjoy the benefit of both approaches,
they are integrated to develop a hybrid algorithm that offers computational
efficiency and theoretical guarantees. The algorithms are evaluated for
different simulated and real-world scenarios. The numerical results show that
the proposed methods meet the Cr'amer-Rao lower bound (CRLB) for a sufficiently
large number of measurements. When the number of the measurements is small, the
proposed position estimator does not achieve CRLB though it still outperforms
several existing localization methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05318</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05318</id><created>2018-02-14</created><updated>2018-06-01</updated><authors><author><keyname>Wang</keyname><forenames>Jie</forenames></author><author><keyname>Fu</keyname><forenames>Zhongxiao</forenames></author><author><keyname>Sadeghzadehyazdi</keyname><forenames>Nasrin</forenames></author><author><keyname>Kipnis</keyname><forenames>Jonathan</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>Nonlinear Shape Regression For Filtering Segmentation Results From
  Calcium Imaging</title><categories>eess.IV</categories><comments>v1: Submitted as a conference contribution to ICIP 2018 (pre-print
  version Feb. 14, 2018); v2: Accepted to be published in 2018 IEEE
  International Conference on Image Processing, Oct 7-10, 2018, Athens, Greece.
  IEEE Copyright notice added. Minor changes for camera-ready version (updated
  Jun. 1, 2018)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A shape filter is presented to repair segmentation results obtained in
calcium imaging of neurons in vivo. This post-segmentation algorithm can
automatically smooth the shapes obtained from a preliminary segmentation, while
precluding the cases where two neurons are counted as one combined component.
The shape filter is realized using a square-root velocity to project the shapes
on a shape manifold in which distances between shapes are based on elastic
changes. Two data-driven weighting methods are proposed to achieve a trade-off
between shape smoothness and consistency with the data. Intuitive comparisons
of proposed methods via projection onto Cartesian maps demonstrate the
smoothing ability of the shape filter. Quantitative measures also prove the
superiority of our methods over models that do not employ any weighting
criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05321</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05321</id><created>2018-02-14</created><updated>2018-06-05</updated><authors><author><keyname>Ma</keyname><forenames>Haoyi</forenames></author><author><keyname>Beiter</keyname><forenames>Rebecca</forenames></author><author><keyname>Gaultier</keyname><forenames>Alban</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author><author><keyname>Lin</keyname><forenames>Zongli</forenames></author></authors><title>OSLO: Automatic Cell Counting and Segmentation for Oligodendrocyte
  Progenitor Cells</title><categories>eess.IV</categories><comments>v1: Submitted to ICIP 2018; v2: Accepted to be published in 2018 IEEE
  International Conference on Image Processing, Oct 7-10, 2018, Athens, Greece.
  IEEE Copyright notice added. Minor changes for camera-ready version</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Reliable cell counting and segmentation of oligodendrocyte progenitor cells
(OPCs) are critical image analysis steps that could potentially unlock
mysteries regarding OPC function during pathology. We propose a saliency-based
method to detect OPCs and use a marker-controlled watershed algorithm to
segment the OPCs. This method first implements frequency-tuned saliency
detection on separate channels to obtain regions of cell candidates. Final
detection results and internal markers can be computed by combining information
from separate saliency maps. An optimal saliency level for OPCs (OSLO) is
highlighted in this work. Here, watershed segmentation is performed efficiently
with effective internal markers. Experiments show that our method outperforms
existing methods in terms of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05383</identifier>
 <datestamp>2018-02-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05383</id><created>2018-02-14</created><authors><author><keyname>Qian</keyname><forenames>Kaizhi</forenames></author><author><keyname>Zhang</keyname><forenames>Yang</forenames></author><author><keyname>Chang</keyname><forenames>Shiyu</forenames></author><author><keyname>Yang</keyname><forenames>Xuesong</forenames></author><author><keyname>Florencio</keyname><forenames>Dinei</forenames></author><author><keyname>Hasegawa-Johnson</keyname><forenames>Mark</forenames></author></authors><title>Deep Learning Based Speech Beamforming</title><categories>cs.CL cs.AI cs.SD eess.AS eess.SP</categories><comments>Accepted in The 43rd IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-channel speech enhancement with ad-hoc sensors has been a challenging
task. Speech model guided beamforming algorithms are able to recover natural
sounding speech, but the speech models tend to be oversimplified or the
inference would otherwise be too complicated. On the other hand, deep learning
based enhancement approaches are able to learn complicated speech distributions
and perform efficient inference, but they are unable to deal with variable
number of input channels. Also, deep learning approaches introduce a lot of
errors, particularly in the presence of unseen noise types and settings. We
have therefore proposed an enhancement framework called DEEPBEAM, which
combines the two complementary classes of algorithms. DEEPBEAM introduces a
beamforming filter to produce natural sounding speech, but the filter
coefficients are determined with the help of a monaural speech enhancement
neural network. Experiments on synthetic and real-world data show that DEEPBEAM
is able to produce clean, dry and natural sounding speech, and is robust
against unseen noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05395</identifier>
 <datestamp>2018-12-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05395</id><created>2018-02-14</created><updated>2018-12-02</updated><authors><author><keyname>Suwanwimolkul</keyname><forenames>Suwichaya</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Gong</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Zhen</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Ranasinghe</keyname><forenames>Damith C.</forenames></author><author><keyname>Shi</keyname><forenames>Qinfeng</forenames></author></authors><title>An Adaptive Markov Random Field for Structured Compressive Sensing</title><categories>eess.SP eess.IV</categories><comments>13 pages, submitted to IEEE Transactions on Image Processing</comments><doi>10.1109/TIP.2018.2878294</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exploiting intrinsic structures in sparse signals underpins the recent
progress in compressive sensing (CS). The key for exploiting such structures is
to achieve two desirable properties: generality (\ie, the ability to fit a wide
range of signals with diverse structures) and adaptability (\ie, being adaptive
to a specific signal). Most existing approaches, however, often only achieve
one of these two properties. In this study, we propose a novel adaptive Markov
random field sparsity prior for CS, which not only is able to capture a broad
range of sparsity structures, but also can adapt to each sparse signal through
refining the parameters of the sparsity prior with respect to the compressed
measurements. To maximize the adaptability, we also propose a new sparse signal
estimation where the sparse signals, support, noise and signal parameter
estimation are unified into a variational optimization problem, which can be
effectively solved with an alternative minimization scheme. Extensive
experiments on three real-world datasets demonstrate the effectiveness of the
proposed method in recovery accuracy, noise tolerance, and runtime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05427</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05427</id><created>2018-02-15</created><authors><author><keyname>Gao</keyname><forenames>Xuanxuan</forenames></author><author><keyname>Huang</keyname><forenames>Zhichao</forenames></author><author><keyname>Lu</keyname><forenames>Xintong</forenames></author><author><keyname>Zhang</keyname><forenames>Senjie</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author></authors><title>Implementation of Massive MIMO Uplink Receiver on RaPro Prototyping
  Platform</title><categories>eess.SP cs.IT math.IT</categories><comments>14 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The updated physical layer standard of the fifth generation wireless
communication suggests the necessity of a rapid prototyping platform. To this
end, we develop RaPro, a multi-core general purpose processor-based massive
multiple-input-multiple-output (MIMO) prototyping platform. To enhance RaPro,
high performance detection and beamforming are needed, whereas both of them
request for accurate channel state information (CSI). In this paper, linear
minimum mean square error (LMMSE)-based channel estimator is adopted and
encapsulated inside RaPro to gain more accurate CSI. Considering the high
comlexity and unknown of channel statistics, we design low-complexity LMMSE
channel estimator to alleviate the rising complexity along with increasing
antenna number and set more computational resource aside for massive MIMO
uplink detection and downlink beamforming. Simulation results indicate the high
mean square error performance and robustness of designed low-complexity method.
Indoor and corridor scenario tests show prominent improvement in bit error rate
performance. Time cost analysis proves the practical use and real-time
transmission ability of the implemented uplink receiver on RaPro.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05429</identifier>
 <datestamp>2018-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05429</id><created>2018-02-15</created><authors><author><keyname>Rolet</keyname><forenames>Antoine</forenames></author><author><keyname>Seguy</keyname><forenames>Vivien</forenames></author><author><keyname>Blondel</keyname><forenames>Mathieu</forenames></author><author><keyname>Sawada</keyname><forenames>Hiroshi</forenames></author></authors><title>Blind Source Separation with Optimal Transport Non-negative Matrix
  Factorization</title><categories>cs.SD eess.AS stat.ML</categories><comments>22 pages, 7 figures, 2 additional files</comments><doi>10.1186/s13634-018-0576-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal transport as a loss for machine learning optimization problems has
recently gained a lot of attention. Building upon recent advances in
computational optimal transport, we develop an optimal transport non-negative
matrix factorization (NMF) algorithm for supervised speech blind source
separation (BSS). Optimal transport allows us to design and leverage a cost
between short-time Fourier transform (STFT) spectrogram frequencies, which
takes into account how humans perceive sound. We give empirical evidence that
using our proposed optimal transport NMF leads to perceptually better results
than Euclidean NMF, for both isolated voice reconstruction and BSS tasks.
Finally, we demonstrate how to use optimal transport for cross domain sound
processing tasks, where frequencies represented in the input spectrograms may
be different from one spectrogram to another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05457</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05457</id><created>2018-02-15</created><updated>2019-07-02</updated><authors><author><keyname>Wong</keyname><forenames>Tak Ming</forenames></author><author><keyname>Kahl</keyname><forenames>Matthias</forenames></author><author><keyname>Bol&#xed;var</keyname><forenames>Peter Haring</forenames></author><author><keyname>Kolb</keyname><forenames>Andreas</forenames></author></authors><title>Computational Image Enhancement for Frequency Modulated Continuous Wave
  (FMCW) THz Image</title><categories>eess.IV</categories><comments>This is a pre-print of an article published in Journal of Infrared,
  Millimeter, and Terahertz Waves. The final authenticated version is available
  online at: https://doi.org/10.1007/s10762-019-00609-w</comments><journal-ref>Journal of Infrared, Millimeter, and Terahertz Waves (2019)</journal-ref><doi>10.1007/s10762-019-00609-w</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method to enhance Frequency Modulated Continuous Wave
(FMCW) THz imaging resolution beyond its diffraction limit is proposed. Our
method comprises two stages. Firstly, we reconstruct the signal in
depth-direction using a sinc-envelope, yielding a significant improvement in
depth estimation and signal parameter extraction. The resulting high precision
depth estimate is used to deduce an accurate reflection intensity THz image.
This image is fed in the second stage of our method to a 2D blind deconvolution
procedure, adopted to enhance the lateral THz image resolution beyond the
diffraction limit. Experimental data acquired with a FMCW system operating at
577 GHz with a bandwidth of 126 GHz shows that the proposed method enhances the
lateral resolution by a factor of 2.29 to 346.2um with respect to the
diffraction limit. The depth accuracy is 91um. Interestingly, the lateral
resolution enhancement achieved with this blind deconvolution concept leads to
better results in comparison to conventional gaussian deconvolution.
Experimental data on a PCB resolution target is presented, in order to quantify
the resolution enhancement and to compare the performance with established
image enhancement approaches. The presented technique allows exposure of the
interwoven fibre reinforced embedded structures of the PCB test sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05521</identifier>
 <datestamp>2018-02-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05521</id><created>2018-02-15</created><authors><author><keyname>Faisal</keyname><forenames>M</forenames></author><author><keyname>Manzoor</keyname><forenames>Sanaullah</forenames></author></authors><title>Deep Learning for Lip Reading using Audio-Visual Information for Urdu
  Language</title><categories>cs.CV cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human lip-reading is a challenging task. It requires not only knowledge of
underlying language but also visual clues to predict spoken words. Experts need
certain level of experience and understanding of visual expressions learning to
decode spoken words. Now-a-days, with the help of deep learning it is possible
to translate lip sequences into meaningful words. The speech recognition in the
noisy environments can be increased with the visual information [1]. To
demonstrate this, in this project, we have tried to train two different
deep-learning models for lip-reading: first one for video sequences using
spatiotemporal convolution neural network, Bi-gated recurrent neural network
and Connectionist Temporal Classification Loss, and second for audio that
inputs the MFCC features to a layer of LSTM cells and output the sequence. We
have also collected a small audio-visual dataset to train and test our model.
Our target is to integrate our both models to improve the speech recognition in
the noisy environment
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05584</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05584</id><created>2018-02-15</created><updated>2019-09-11</updated><authors><author><keyname>Chun</keyname><forenames>Il Yong</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>Convolutional Analysis Operator Learning: Acceleration and Convergence</title><categories>eess.IV cs.CV cs.LG math.OC stat.ML</categories><comments>22 pages, 11 figures, fixed incorrect math theorem numbers in fig. 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional operator learning is gaining attention in many signal
processing and computer vision applications. Learning kernels has mostly relied
on so-called patch-domain approaches that extract and store many overlapping
patches across training signals. Due to memory demands, patch-domain methods
have limitations when learning kernels from large datasets -- particularly with
multi-layered structures, e.g., convolutional neural networks -- or when
applying the learned kernels to high-dimensional signal recovery problems. The
so-called convolution approach does not store many overlapping patches, and
thus overcomes the memory problems particularly with careful algorithmic
designs; it has been studied within the &quot;synthesis&quot; signal model, e.g.,
convolutional dictionary learning. This paper proposes a new convolutional
analysis operator learning (CAOL) framework that learns an analysis sparsifying
regularizer with the convolution perspective, and develops a new convergent
Block Proximal Extrapolated Gradient method using a Majorizer (BPEG-M) to solve
the corresponding block multi-nonconvex problems. To learn diverse filters
within the CAOL framework, this paper introduces an orthogonality constraint
that enforces a tight-frame filter condition, and a regularizer that promotes
diversity between filters. Numerical experiments show that, with sharp
majorizers, BPEG-M significantly accelerates the CAOL convergence rate compared
to the state-of-the-art block proximal gradient (BPG) method. Numerical
experiments for sparse-view computational tomography show that a convolutional
sparsifying regularizer learned via CAOL significantly improves reconstruction
quality compared to a conventional edge-preserving regularizer. Using more and
wider kernels in a learned regularizer better preserves edges in reconstructed
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05615</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05615</id><created>2018-02-13</created><updated>2018-07-26</updated><authors><author><keyname>Roudas</keyname><forenames>I.</forenames></author><author><keyname>Kwapisz</keyname><forenames>J.</forenames></author><author><keyname>Nolan</keyname><forenames>D. A.</forenames></author></authors><title>Optimal launch states for the measurement of principal modes in optical
  fibers</title><categories>eess.SP physics.optics</categories><doi>10.1109/JLT.2018.2860974</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modal dispersion characterization of multimode optical fibers can be
performed using the recently-proposed mode-dependent signal delay method. This
method consists of sending optical pulses using different combinations of modes
though the multimode optical fiber and measuring the mode group delay at the
fiber output. From these measurements, it is possible to estimate the modal
dispersion vector, the principal modes, and their corresponding differential
mode group delays. In this paper, we revise and extend the theoretical
framework of the mode-dependent signal delay method to include the impact of
receiver noise and mode-dependent loss. We compute optimal launch modes,
minimizing the noise error in the estimation of the fiber modal dispersion
vector. We show that, for a 40-mode fiber, the electronic signal-to-noise ratio
(SNR) is improved asymptotically by almost 6 dB compared to conventional mode
combinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05630</identifier>
 <datestamp>2018-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05630</id><created>2018-02-15</created><updated>2018-09-11</updated><authors><author><keyname>Etienne</keyname><forenames>Caroline</forenames></author><author><keyname>Fidanza</keyname><forenames>Guillaume</forenames></author><author><keyname>Petrovskii</keyname><forenames>Andrei</forenames></author><author><keyname>Devillers</keyname><forenames>Laurence</forenames></author><author><keyname>Schmauch</keyname><forenames>Benoit</forenames></author></authors><title>CNN+LSTM Architecture for Speech Emotion Recognition with Data
  Augmentation</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>5 pages, 3 figures</comments><journal-ref>Workshop on Speech, Music and Mind 2018</journal-ref><doi>10.21437/SMM.2018-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we design a neural network for recognizing emotions in speech,
using the IEMOCAP dataset. Following the latest advances in audio analysis, we
use an architecture involving both convolutional layers, for extracting
high-level features from raw spectrograms, and recurrent ones for aggregating
long-term dependencies. We examine the techniques of data augmentation with
vocal track length perturbation, layer-wise optimizer adjustment, batch
normalization of recurrent layers and obtain highly competitive results of
64.5% for weighted accuracy and 61.7% for unweighted accuracy on four emotions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05686</identifier>
 <datestamp>2018-02-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05686</id><created>2018-02-15</created><authors><author><keyname>Nguyen</keyname><forenames>Anh Tuan</forenames></author><author><keyname>Xu</keyname><forenames>Jian</forenames></author><author><keyname>Yang</keyname><forenames>Zhi</forenames></author></authors><title>A Bio-inspired Redundant Sensing Architecture</title><categories>cs.NE cs.IT eess.SP math.IT</categories><journal-ref>(2016) A Bio-inspired Redundant Sensing Architecture. Advances in
  Neural Information Processing Systems (NIPS), Dec. 2016</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensing is the process of deriving signals from the environment that allows
artificial systems to interact with the physical world. The Shannon theorem
specifies the maximum rate at which information can be acquired. However, this
upper bound is hard to achieve in many man-made systems. The biological visual
systems, on the other hand, have highly efficient signal representation and
processing mechanisms that allow precise sensing. In this work, we argue that
redundancy is one of the critical characteristics for such superior
performance. We show architectural advantages by utilizing redundant sensing,
including correction of mismatch error and significant precision enhancement.
For a proof-of-concept demonstration, we have designed a heuristic-based
analog-to-digital converter - a zero-dimensional quantizer. Through Monte Carlo
simulation with the error probabilistic distribution as a priori, the
performance approaching the Shannon limit is feasible. In actual measurements
without knowing the error distribution, we observe at least 2-bit extra
precision. The results may also help explain biological processes including the
dominance of binocular vision, the functional roles of the fixational eye
movements, and the structural mechanisms allowing hyperacuity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05755</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05755</id><created>2018-02-15</created><authors><author><keyname>Asghar</keyname><forenames>Usman</forenames></author><author><keyname>Touati</keyname><forenames>Farid</forenames></author><author><keyname>Crescini</keyname><forenames>Damiano</forenames></author><author><keyname>Galli</keyname><forenames>Alessio</forenames></author><author><keyname>Mnaouer</keyname><forenames>Adel Ben</forenames></author></authors><title>Development of Highly Efficient Multi-invariable Wireless Sensor System
  Design for Energy Harvesting</title><categories>eess.SP cs.CY cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capillary wireless sensor networks devoted to air quality monitoring have
provided vital information on dangerous air conditions. In adopting the
environmentally generated energy as the fundamental energy source the main
challenge is the implementation of capillary networks rather than replacing the
batteries on a set period of times that leads to functional dilemma of devices
management and high costs. In this paper we present a battery-less,
self-governing, multi-parametric sensing platform for air quality monitoring
that harvests environment energy for long run. Furthermore study on sensor
section with their results have also been described in the paper. A customized
process of calibration to check the sensors' sensitivity and a basic portfolio
of variant energy sources over the power recovery section could productively
improve air quality standards tracing in indoor and outdoor application, in a
kind of 'set and forget' scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05792</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05792</id><created>2018-02-15</created><updated>2019-04-28</updated><authors><author><keyname>Medhat</keyname><forenames>Fady</forenames></author><author><keyname>Chesmore</keyname><forenames>David</forenames></author><author><keyname>Robinson</keyname><forenames>John</forenames></author></authors><title>Masked Conditional Neural Networks for Automatic Sound Events
  Recognition</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Restricted Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Belief
  Net, DBN, Conditional Neural Network, CLNN, Masked Conditional Neural
  Network, MCLNN, Environmental Sound Recognition, ESR</comments><journal-ref>IEEE International Conference on Data Science and Advanced
  Analytics (DSAA) Year: 2017, Pages: 389 - 394</journal-ref><doi>10.1109/DSAA.2017.43</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural network architectures designed for application domains other than
sound, especially image recognition, may not optimally harness the
time-frequency representation when adapted to the sound recognition problem. In
this work, we explore the ConditionaL Neural Network (CLNN) and the Masked
ConditionaL Neural Network (MCLNN) for multi-dimensional temporal signal
recognition. The CLNN considers the inter-frame relationship, and the MCLNN
enforces a systematic sparseness over the network's links to enable learning in
frequency bands rather than bins allowing the network to be frequency shift
invariant mimicking a filterbank. The mask also allows considering several
combinations of features concurrently, which is usually handcrafted through
exhaustive manual search. We applied the MCLNN to the environmental sound
recognition problem using the ESC-10 and ESC-50 datasets. MCLNN achieved
competitive performance, using 12% of the parameters and without augmentation,
compared to state-of-the-art Convolutional Neural Networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05800</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05800</id><created>2018-02-15</created><updated>2019-09-08</updated><authors><author><keyname>Roy</keyname><forenames>Deboleena</forenames></author><author><keyname>Panda</keyname><forenames>Priyadarshini</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Tree-CNN: A Hierarchical Deep Convolutional Neural Network for
  Incremental Learning</title><categories>cs.CV cs.AI eess.IV stat.ML</categories><comments>8 pages, 6 figures, 7 tables Accepted in Neural Networks, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past decade, Deep Convolutional Neural Networks (DCNNs) have shown
remarkable performance in most computer vision tasks. These tasks traditionally
use a fixed dataset, and the model, once trained, is deployed as is. Adding new
information to such a model presents a challenge due to complex training
issues, such as &quot;catastrophic forgetting&quot;, and sensitivity to hyper-parameter
tuning. However, in this modern world, data is constantly evolving, and our
deep learning models are required to adapt to these changes. In this paper, we
propose an adaptive hierarchical network structure composed of DCNNs that can
grow and learn as new data becomes available. The network grows in a tree-like
fashion to accommodate new classes of data, while preserving the ability to
distinguish the previously trained classes. The network organizes the
incrementally available data into feature-driven super-classes and improves
upon existing hierarchical CNN models by adding the capability of self-growth.
The proposed hierarchical model, when compared against fine-tuning a deep
network, achieves significant reduction of training effort, while maintaining
competitive accuracy on CIFAR-10 and CIFAR-100.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05853</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05853</id><created>2018-02-16</created><authors><author><keyname>Mitra</keyname><forenames>Vikramjit</forenames></author><author><keyname>Wang</keyname><forenames>Wen</forenames></author><author><keyname>Bartels</keyname><forenames>Chris</forenames></author><author><keyname>Franco</keyname><forenames>Horacio</forenames></author><author><keyname>Vergyri</keyname><forenames>Dimitra</forenames></author></authors><title>Articulatory information and Multiview Features for Large Vocabulary
  Continuous Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the use of multi-view features and their discriminative
transforms in a convolutional deep neural network (CNN) architecture for a
continuous large vocabulary speech recognition task. Mel-filterbank energies
and perceptually motivated forced damped oscillator coefficient (DOC) features
are used after feature-space maximum-likelihood linear regression (fMLLR)
transforms, which are combined and fed as a multi-view feature to a single CNN
acoustic model. Use of multi-view feature representation demonstrated
significant reduction in word error rates (WERs) compared to the use of
individual features by themselves. In addition, when articulatory information
was used as an additional input to a fused deep neural network (DNN) and CNN
acoustic model, it was found to demonstrate further reduction in WER for the
Switchboard subset and the CallHome subset (containing partly non-native
accented speech) of the NIST 2000 conversational telephone speech test set,
reducing the error rate by 12% relative to the baseline in both cases. This
work shows that multi-view features in association with articulatory
information can improve speech recognition robustness to spontaneous and
non-native speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05879</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05879</id><created>2018-02-16</created><authors><author><keyname>Tukuljac</keyname><forenames>Helena Pei&#x107;</forenames></author><author><keyname>Vu</keyname><forenames>Thach Pham</forenames></author><author><keyname>Lissek</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author></authors><title>Joint Estimation of Room Geometry and Modes with Compressed Sensing</title><categories>eess.AS cs.CV eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Acoustical behavior of a room for a given position of microphone and sound
source is usually described using the room impulse response. If we rely on the
standard uniform sampling, the estimation of room impulse response for
arbitrary positions in the room requires a large number of measurements. In
order to lower the required sampling rate, some solutions have emerged that
exploit the sparse representation of the room wavefield in the terms of plane
waves in the low-frequency domain. The plane wave representation has a simple
form in rectangular rooms. In our solution, we observe the basic axial modes of
the wave vector grid for extraction of the room geometry and then we propagate
the knowledge to higher order modes out of the low-pass version of the
measurements. Estimation of the approximate structure of the $k$-space should
lead to the reduction in the terms of number of required measurements and in
the increase of the speed of the reconstruction without great losses of
quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05959</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05959</id><created>2018-02-14</created><authors><author><keyname>Zhang</keyname><forenames>Jinyu</forenames></author><author><keyname>Chang</keyname><forenames>Wenting</forenames></author><author><keyname>Niu</keyname><forenames>Huaning</forenames></author><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author><author><keyname>Yang</keyname><forenames>Hongwen</forenames></author></authors><title>Grant-less Uplink Transmission for LTE Operated in Unlicensed Spectrum</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 6 figures - in IEEE International Symposium on Personal,
  Indoor and Mobile Radio Communications (PIMRC) 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deployment of Long Term Evolution (LTE) in unlicensed spectrum has been a
candidate feature to meet the explosive growth of traffic demand since 3GPP
release 13. To further explore the advantage of unlicensed bands, in this
context the operation of both uplink and downlink has been supported and
studied in the subsequent releases. However, it has been identified that
scheduled uplink transmission performance in unlicensed spectrum is
significantly degraded due to the double listen-before-talk (LBT) requirements
at both eNB when sending the uplink grant, and at the scheduled UEs before
transmission. In this paper, in order to overcome this issue, a novel uplink
transmission scheme, which does not require any grant, is proposed, and the
details regarding the system design are provided. By modeling the dynamics in
time of the LBT for both a system that employs a conventional uplink scheme, as
well as the proposed scheme, it is verified through analytical evaluation that
the double LBT scheme for uplink transmission greatly reduces the channel
access probability for the UE, and leads consequently to performance loss,
while the proposed scheme is able to alleviate this issue. System level
simulation results, compliant with the LTE standard, show that the proposed
scheme can achieve a significant performance gain in terms of throughput with
negligible performance loss for the downlink, and other technologies operating
in the same spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05962</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05962</id><created>2018-02-14</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author><author><keyname>Ahmad</keyname><forenames>M. Omair</forenames></author></authors><title>Enhancement of Noisy Speech Exploiting an Exponential Model Based
  Threshold and a Custom Thresholding Function in Perceptual Wavelet Packet
  Domain</title><categories>eess.AS</categories><comments>Submitted to Circuits, Systems and Signal Processing, 17 pages, 20
  figures, 8 tables. arXiv admin note: text overlap with arXiv:1802.03472</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For enhancement of noisy speech, a method of threshold determination based on
modeling of Teager energy (TE) operated perceptual wavelet packet (PWP)
coefficients of the noisy speech by exponential distribution is presented. A
custom thresholding function based on the combination of mu-law and semisoft
thresholding functions is designed and exploited to apply the statistically
derived threshold upon the PWP coefficients. The effectiveness of the proposed
method is evaluated for car and multi-talker babble noise corrupted speech
signals through performing extensive simulations using the NOIZEUS database.
The proposed method outperforms some of the state-of-the-art speech enhancement
methods both at high and low levels of SNRs in terms of the standard objective
measures and the subjective evaluations including formal listening tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05982</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.05982</id><created>2018-02-15</created><authors><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Yang</keyname><forenames>Yufeng</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames><affiliation>Shanghai Institute for Advanced Communications and Data Science, Shanghai University, Shanghai, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author></authors><title>Residual-Based Detections and Unified Architecture for Massive MIMO
  Uplink</title><categories>eess.SP cs.AR cs.CE cs.NA</categories><comments>submitted to Journal of Signal Processing Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (M-MIMO) technique brings better
energy efficiency and coverage but higher computational complexity than
small-scale MIMO. For linear detections such as minimum mean square error
(MMSE), prohibitive complexity lies in solving large-scale linear equations.
For a better trade-off between bit-error-rate (BER) performance and
computational complexity, iterative linear algorithms like conjugate gradient
(CG) have been applied and have shown their feasibility in recent years. In
this paper, residual-based detection (RBD) algorithms are proposed for M-MIMO
detection, including minimal residual (MINRES) algorithm, generalized minimal
residual (GMRES) algorithm, and conjugate residual (CR) algorithm. RBD
algorithms focus on the minimization of residual norm per iteration, whereas
most existing algorithms focus on the approximation of exact signal. Numerical
results have shown that, for $64$-QAM $128\times 8$ MIMO, RBD algorithms are
only $0.13$ dB away from the exact matrix inversion method when BER$=10^{-4}$.
Stability of RBD algorithms has also been verified in various correlation
conditions. Complexity comparison has shown that, CR algorithm require $87\%$
less complexity than the traditional method for $128\times 60$ MIMO. The
unified hardware architecture is proposed with flexibility, which guarantees a
low-complexity implementation for a family of RBD M-MIMO detectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06003</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06003</id><created>2018-02-13</created><authors><author><keyname>Kano</keyname><forenames>Takatomo</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>Structured-based Curriculum Learning for End-to-end English-Japanese
  Speech Translation</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence attentional-based neural network architectures have been
shown to provide a powerful model for machine translation and speech
recognition. Recently, several works have attempted to extend the models for
end-to-end speech translation task. However, the usefulness of these models
were only investigated on language pairs with similar syntax and word order
(e.g., English-French or English-Spanish). In this work, we focus on end-to-end
speech translation tasks on syntactically distant language pairs (e.g.,
English-Japanese) that require distant word reordering.
  To guide the encoder-decoder attentional model to learn this difficult
problem, we propose a structured-based curriculum learning strategy.
  Unlike conventional curriculum learning that gradually emphasizes difficult
data examples, we formalize learning strategies from easier network structures
to more difficult network structures. Here, we start the training with
end-to-end encoder-decoder for speech recognition or text-based machine
translation task then gradually move to end-to-end speech translation task. The
experiment results show that the proposed approach could provide significant
improvements in comparison with the one without curriculum learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06006</identifier>
 <datestamp>2018-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06006</id><created>2018-02-14</created><updated>2018-10-12</updated><authors><author><keyname>Arik</keyname><forenames>Sercan O.</forenames></author><author><keyname>Chen</keyname><forenames>Jitong</forenames></author><author><keyname>Peng</keyname><forenames>Kainan</forenames></author><author><keyname>Ping</keyname><forenames>Wei</forenames></author><author><keyname>Zhou</keyname><forenames>Yanqi</forenames></author></authors><title>Neural Voice Cloning with a Few Samples</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice cloning is a highly desired feature for personalized speech interfaces.
Neural network based speech synthesis has been shown to generate high quality
speech for a large number of speakers. In this paper, we introduce a neural
voice cloning system that takes a few audio samples as input. We study two
approaches: speaker adaptation and speaker encoding. Speaker adaptation is
based on fine-tuning a multi-speaker generative model with a few cloning
samples. Speaker encoding is based on training a separate model to directly
infer a new speaker embedding from cloning audios and to be used with a
multi-speaker generative model. In terms of naturalness of the speech and its
similarity to original speaker, both approaches can achieve good performance,
even with very few cloning audios. While speaker adaptation can achieve better
naturalness and similarity, the cloning time or required memory for the speaker
encoding approach is significantly less, making it favorable for low-resource
deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06042</identifier>
 <datestamp>2018-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06042</id><created>2018-02-16</created><updated>2018-02-20</updated><authors><author><keyname>Sundaresan</keyname><forenames>Karthikeyan</forenames></author><author><keyname>Chai</keyname><forenames>Eugene</forenames></author><author><keyname>Chakraborty</keyname><forenames>Ayon</forenames></author><author><keyname>Rangarajan</keyname><forenames>Sampath</forenames></author></authors><title>SkyLiTE: End-to-End Design of Low-Altitude UAV Networks for Providing
  LTE Connectivity</title><categories>cs.NI eess.SP</categories><report-no>NEC Labs America Technical Report 2018-TR001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Un-manned aerial vehicle (UAVs) have the potential to change the landscape of
wide-area wireless connectivity by bringing them to areas where connectivity
was sparing or non-existent (e.g. rural areas) or has been compromised due to
disasters. While Google's Project Loon and Facebook's Project Aquila are
examples of high-altitude, long-endurance UAV-based connectivity efforts in
this direction, the telecom operators (e.g. AT&amp;T and Verizon) have been
exploring low-altitude UAV-based LTE solutions for on-demand deployments.
Understandably, these projects are in their early stages and face formidable
challenges in their realization and deployment. The goal of this document is to
expose the reader to both the challenges as well as the potential offered by
these unconventional connectivity solutions. We aim to explore the end-to-end
design of such UAV-based connectivity networks particularly in the context of
low-altitude UAV networks providing LTE connectivity. Specifically, we aim to
highlight the challenges that span across multiple layers (access, core
network, and backhaul) in an inter-twined manner as well as the richness and
complexity of the design space itself. To help interested readers navigate this
complex design space towards a solution, we also articulate the overview of one
such end-to-end design, namely SkyLiTE-- a self-organizing network of
low-altitude UAVs that provide optimized LTE connectivity in a desired region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06043</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06043</id><created>2018-02-16</created><updated>2018-02-26</updated><authors><author><keyname>Setlur</keyname><forenames>Pawan</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>Flawed Waveform Design of Augusto Aubry, Antonio DeMaio et al</title><categories>eess.SP</categories><comments>arXiv admin note: This submission has been withdrawn by arXiv
  administrators due to unprofessional personal attack</comments><report-no>AFRL-RY-WP-TP-2018-0018</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  arXiv admin note: This submission has been withdrawn by arXiv administrators
due to unprofessional personal attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06067</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06067</id><created>2018-02-16</created><authors><author><keyname>Schl&#xf6;mer</keyname><forenames>Nico</forenames></author></authors><title>Algorithmic improvements for the CIECAM02 and CAM16 color appearance
  models</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This note is concerned with the CIECAM02 color appearance model and its
successor, the CAM16 color appearance model. Several algorithmic flaws are
pointed out and remedies are suggested. The resulting color model is
algebraically equivalent to CIECAM02/CAM16, but shorter, more efficient, and
works correctly for all edge cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06148</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06148</id><created>2018-02-16</created><authors><author><keyname>Hassan</keyname><forenames>Rana A.</forenames></author><author><keyname>Michelusi</keyname><forenames>Nicolo</forenames></author></authors><title>Multi-user Beam-Alignment for Millimeter-Wave Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave communications is the most promising technology for
next-generation cellular wireless systems, thanks to the large bandwidth
available compared to sub-6 GHz networks. Nevertheless, communication at these
frequencies requires narrow beams via massive MIMO and beamforming to overcome
the strong signal attenuation, and thus precise beam-alignment between
transmitter and receiver is needed. The resulting signaling overhead may become
a severe impairment, especially in mobile networks with high users density.
Therefore, it is imperative to optimize the beam-alignment protocol to minimize
the signaling overhead. In this paper, the design of energy efficient joint
beam-alignment protocols for two users is addressed, with the goal to minimize
the power consumption during data transmission, subject to rate constraints for
both users, under analog beamforming constraints. It is proved that a bisection
search algorithm is optimal. Additionally, the optimal scheduling strategy of
the two users in the data communication phase is optimized based on the outcome
of beam-alignment, according to a time division multiplexing scheme. The
numerical results show significant decrease in the power consumption for the
proposed joint beam-alignment scheme compared to exhaustive search and a
single-user beam-alignment scheme taking place separately for each user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06182</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06182</id><created>2018-02-16</created><authors><author><keyname>Kim</keyname><forenames>Jong Wook</forenames></author><author><keyname>Salamon</keyname><forenames>Justin</forenames></author><author><keyname>Li</keyname><forenames>Peter</forenames></author><author><keyname>Bello</keyname><forenames>Juan Pablo</forenames></author></authors><title>CREPE: A Convolutional Representation for Pitch Estimation</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of estimating the fundamental frequency of a monophonic sound
recording, also known as pitch tracking, is fundamental to audio processing
with multiple applications in speech processing and music information
retrieval. To date, the best performing techniques, such as the pYIN algorithm,
are based on a combination of DSP pipelines and heuristics. While such
techniques perform very well on average, there remain many cases in which they
fail to correctly estimate the pitch. In this paper, we propose a data-driven
pitch tracking algorithm, CREPE, which is based on a deep convolutional neural
network that operates directly on the time-domain waveform. We show that the
proposed model produces state-of-the-art results, performing equally or better
than pYIN. Furthermore, we evaluate the model's generalizability in terms of
noise robustness. A pre-trained version of CREPE is made freely available as an
open-source Python module for easy application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06199</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06199</id><created>2018-02-17</created><authors><author><keyname>Chow</keyname><forenames>Jacky C. K.</forenames></author></authors><title>Drift-Free Indoor Navigation Using Simultaneous Localization and Mapping
  of the Ambient Heterogeneous Magnetic Field</title><categories>cs.RO eess.SP</categories><comments>ISPRS Workshop Indoor 3D 2017</comments><journal-ref>Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W7,
  339-344, 2017</journal-ref><doi>10.5194/isprs-archives-XLII-2-W7-339-2017</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the absence of external reference position information (e.g. GNSS) SLAM
has proven to be an effective method for indoor navigation. The positioning
drift can be reduced with regular loop-closures and global relaxation as the
backend, thus achieving a good balance between exploration and exploitation.
Although vision-based systems like laser scanners are typically deployed for
SLAM, these sensors are heavy, energy inefficient, and expensive, making them
unattractive for wearables or smartphone applications. However, the concept of
SLAM can be extended to non-optical systems such as magnetometers. Instead of
matching features such as walls and furniture using some variation of the ICP
algorithm, the local magnetic field can be matched to provide loop-closure and
global trajectory updates in a Gaussian Process (GP) SLAM framework. With a
MEMS-based inertial measurement unit providing a continuous trajectory, and the
matching of locally distinct magnetic field maps, experimental results in this
paper show that a drift-free navigation solution in an indoor environment with
millimetre-level accuracy can be achieved. The GP-SLAM approach presented can
be formulated as a maximum a posteriori estimation problem and it can naturally
perform loop-detection, feature-to-feature distance minimization, global
trajectory optimization, and magnetic field map estimation simultaneously.
Spatially continuous features (i.e. smooth magnetic field signatures) are used
instead of discrete feature correspondences (e.g. point-to-point) as in
conventional vision-based SLAM. These position updates from the ambient
magnetic field also provide enough information for calibrating the
accelerometer and gyroscope bias in-use. The only restriction for this method
is the need for magnetic disturbances (which is typically not an issue
indoors); however, no assumptions are required for the general motion of the
sensor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06209</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06209</id><created>2018-02-17</created><authors><author><keyname>S</keyname><forenames>Maghilnan</forenames></author><author><keyname>M</keyname><forenames>Rajesh Kumar</forenames></author></authors><title>Sentiment Analysis on Speaker Specific Speech Data</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted and Published in 2017 IEEE International Conference on
  Intelligent Computing and Control (I2C2), 23 Jun - 24 Jun 2017, India</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sentiment analysis has evolved over past few decades, most of the work in it
revolved around textual sentiment analysis with text mining techniques. But
audio sentiment analysis is still in a nascent stage in the research community.
In this proposed research, we perform sentiment analysis on speaker
discriminated speech transcripts to detect the emotions of the individual
speakers involved in the conversation. We analyzed different techniques to
perform speaker discrimination and sentiment analysis to find efficient
algorithms to perform this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06220</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06220</id><created>2018-02-17</created><updated>2018-12-03</updated><authors><author><keyname>&#xdc;ney</keyname><forenames>Murat</forenames></author><author><keyname>Houssineau</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author><author><keyname>Delande</keyname><forenames>Emmanuel</forenames></author><author><keyname>Julier</keyname><forenames>Simon J.</forenames></author><author><keyname>Clark</keyname><forenames>Daniel E.</forenames></author></authors><title>Fusion of finite set distributions: Pointwise consistency and global
  cardinality</title><categories>eess.SP cs.IT cs.MA cs.SY math.IT</categories><comments>accepted for publication in the IEEE Transactions on Aerospace and
  Electronics Systems</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  A recent trend in distributed multi-sensor fusion is to use random finite set
filters at the sensor nodes and fuse the filtered distributions algorithmically
using their exponential mixture densities (EMDs). Fusion algorithms which
extend the celebrated covariance intersection and consensus based approaches
are such examples. In this article, we analyse the variational principle
underlying EMDs and show that the EMDs of finite set distributions do not
necessarily lead to consistent fusion of cardinality distributions. Indeed, we
demonstrate that these inconsistencies may occur with overwhelming probability
in practice, through examples with Bernoulli, Poisson and independent
identically distributed (IID) cluster processes. We prove that pointwise
consistency of EMDs does not imply consistency in global cardinality and vice
versa. Then, we redefine the variational problems underlying fusion and provide
iterative solutions thereby establishing a framework that guarantees
cardinality consistent fusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06250</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06250</id><created>2018-02-17</created><authors><author><keyname>Liu</keyname><forenames>Sijia</forenames></author><author><keyname>Chen</keyname><forenames>Pin-Yu</forenames></author><author><keyname>Rajapakse</keyname><forenames>Indika</forenames></author><author><keyname>Hero</keyname><forenames>Alfred</forenames></author></authors><title>First-order bifurcation detection for dynamic complex networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore how network centrality and network entropy can be
used to identify a bifurcation network event. A bifurcation often occurs when a
network undergoes a qualitative change in its structure as a response to
internal changes or external signals. In this paper, we show that network
centrality allows us to capture important topological properties of dynamic
networks. By extracting multiple centrality features from a network for
dimensionality reduction, we are able to track the network dynamics underlying
an intrinsic low-dimensional manifold. Moreover, we employ von Neumann graph
entropy (VNGE) to measure the information divergence between networks over
time. In particular, we propose an asymptotically consistent estimator of VNGE
so that the cubic complexity of VNGE is reduced to quadratic complexity that
scales more gracefully with network size. Finally, the effectiveness of our
approaches is demonstrated through a real-life application of cyber intrusion
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06327</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06327</id><created>2018-02-17</created><authors><author><keyname>Mehta</keyname><forenames>Ketan</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author></authors><title>Directional and Causal Information Flow in EEG for Assessing Perceived
  Audio Quality</title><categories>eess.SP eess.AS q-bio.NC</categories><comments>IEEE Transactions on Molecular, Biological, and Multi-Scale
  Communication, September 2017, Vol. 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, electroencephalography (EEG) measurements are used to infer
change in cortical functional connectivity in response to change in audio
stimulus. Experiments are conducted wherein the EEG activity of human subjects
is recorded as they listen to audio sequences whose quality varies with time. A
causal information theoretic framework is then proposed to measure the
information flow between EEG sensors appropriately grouped into different
regions of interest (ROI) over the cortex. A new causal bidirectional
information (CBI) measure is defined as an improvement over standard directed
information measures for the purposes of identifying connectivity between ROIs
in a generalized cortical network setting. CBI can be intuitively interpreted
as a causal bidirectional modification of directed information, and inherently
calculates the divergence of the observed data from a multiple access channel
with feedback. Further, we determine the analytical relationship between the
different causal measures and compare how well they are able to distinguish
between the perceived audio quality. The connectivity results inferred indicate
a significant change in the rate of information flow between ROIs as the
subjects listen to different audio qualities, with CBI being the best in
discriminating between the perceived audio quality, compared to using standard
directed information measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06412</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06412</id><created>2018-02-18</created><updated>2018-02-20</updated><authors><author><keyname>Kreyssig</keyname><forenames>Florian</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Woodland</keyname><forenames>Philip</forenames></author></authors><title>Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs</title><categories>cs.CL cs.AI cs.SD eess.AS stat.ML</categories><comments>5 pages, 3 figures, 2 tables, to appear in 2018 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time delay neural networks (TDNNs) are an effective acoustic model for large
vocabulary speech recognition. The strength of the model can be attributed to
its ability to effectively model long temporal contexts. However, current TDNN
models are relatively shallow, which limits the modelling capability. This
paper proposes a method of increasing the network depth by deepening the kernel
used in the TDNN temporal convolutions. The best performing kernel consists of
three fully connected layers with a residual (ResNet) connection from the
output of the first to the output of the third. The addition of
spectro-temporal processing as the input to the TDNN in the form of a
convolutional neural network (CNN) and a newly designed Grid-RNN was
investigated. The Grid-RNN strongly outperforms a CNN if different sets of
parameters for different frequency bands are used and can be further enhanced
by using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast
(MGB3) English data (275h) show that deep kernel TDNNs reduces the word error
rate (WER) by 6% relative and when combined with the frequency dependent
Grid-RNN gives a relative WER reduction of 9%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06513</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06513</id><created>2018-02-18</created><authors><author><keyname>Setlur</keyname><forenames>Pawan</forenames></author><author><keyname>O'Rourke</keyname><forenames>Sean</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>Constrained Least Squares, SDP, and QCQP Perspectives on Joint Biconvex
  Radar Receiver and Waveform design</title><categories>eess.SP</categories><comments>7 Pages, 1 figure, IET, International Conference on Radar Systems,
  23-27 OCT 2017, Belfast UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint radar receive filter and waveform design is non-convex, but is
individually convex for a fixed receiver filter while optimizing the waveform,
and vice versa. Such classes of problems are fre- quently encountered in
optimization, and are referred to biconvex programs. Alternating minimization
(AM) is perhaps the most popu- lar, effective, and simplest algorithm that can
deal with bi-convexity. In this paper we consider new perspectives on this
problem via older, well established problems in the optimization literature. It
is shown here specifically that the radar waveform optimization may be cast as
constrained least squares, semi-definite programs (SDP), and quadratically
constrained quadratic programs (QCQP). The bi-convex constraint introduces sets
which vary for each iteration in the alternat- ing minimization. We prove
convergence of alternating minimization for biconvex problems with biconvex
constraints by showing the equivalence of this to a biconvex problem with
constrained Cartesian product convex sets but for convex hulls of small
diameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06609</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06609</id><created>2018-02-19</created><authors><author><keyname>Cochez</keyname><forenames>Michael</forenames></author></authors><title>On the computation of Shannon Entropy from Counting Bloom Filters</title><categories>cs.IT eess.SP math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this short note a method for computing the naive plugin estimator of
discrete entropy from a counting Bloom filter will be presented. The method
does work reasonably as long as the collision probability in the bloom filter
is kept low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06641</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06641</id><created>2018-02-19</created><updated>2018-04-25</updated><authors><author><keyname>Dorize</keyname><forenames>Christian</forenames></author><author><keyname>Awwad</keyname><forenames>Elie</forenames></author></authors><title>Enhancing performance of coherent OTDR systems with polarization
  diversity complementary codes</title><categories>eess.SP</categories><comments>Revised version accepted for publication in Optics Express</comments><doi>10.1364/OE.26.012878</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monitoring the optical phase change in a fiber enables a wide range of
applications where fast phase variations are induced by acoustic signals or
vibrations in general. However, the quality of the estimated fiber response
strongly depends on the method used to modulate the light sent to the fiber and
capture the variations of the optical field. In this paper, we show that
distributed optical fiber sensing systems can advantageously exploit techniques
from the telecommunication domain, as those used in coherent optical
transmission, to enhance their performance in detecting mechanical events,
while jointly offering a simpler setup than widespread pulse-cloning or
spectral-sweep based schemes with acousto-optic modulators. We periodically
capture an overall fiber Jones matrix estimate thanks to a novel probing
technique using two mutually orthogonal complementary (Golay) pairs of binary
sequences applied simultaneously in phase and quadrature on two orthogonal
polarization states. A perfect channel response estimation of the sensor array
is achieved, subject to conditions detailed in the paper, thus enhancing the
sensitivity and bandwidth of coherent phase-OTDR systems. High sensitivity,
linear response, and bandwidth coverage up to 18 kHz are demonstrated with a
sensor array composed of 10 fiber Bragg gratings (FBGs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06750</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06750</id><created>2018-02-19</created><authors><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Pesavento</keyname><forenames>Marius</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Energy efficiency optimization in MIMO interference channels: A
  successive pseudoconvex approximation approach</title><categories>math.OC eess.SP</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2019.2923141</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the (global and sum) energy efficiency
optimization problem in downlink multi-input multi-output multi-cell systems,
where all users suffer from multi-user interference. This is a challenging
problem due to several reasons: 1) it is a nonconvex fractional programming
problem, 2) the transmission rate functions are characterized by
(complex-valued) transmit covariance matrices, and 3) the processing-related
power consumption may depend on the transmission rate. We tackle this problem
by the successive pseudoconvex approximation approach, and we argue that
pseudoconvex optimization plays a fundamental role in designing novel iterative
algorithms, not only because every locally optimal point of a pseudoconvex
optimization problem is also globally optimal, but also because a descent
direction is easily obtained from every optimal point of a pseudoconvex
optimization problem. The proposed algorithms have the following advantages: 1)
fast convergence as the structure of the original optimization problem is
preserved as much as possible in the approximate problem solved in each
iteration, 2) easy implementation as each approximate problem is suitable for
parallel computation and its solution has a closed-form expression, and 3)
guaranteed convergence to a stationary point or a Karush-Kuhn-Tucker point. The
advantages of the proposed algorithm are also illustrated numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06840</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06840</id><created>2018-02-19</created><authors><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Singh</keyname><forenames>Rita</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>Voice Impersonation using Generative Adversarial Networks</title><categories>cs.SD eess.AS</categories><comments>Accepted by 2018 International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice impersonation is not the same as voice transformation, although the
latter is an essential element of it. In voice impersonation, the resultant
voice must convincingly convey the impression of having been naturally produced
by the target speaker, mimicking not only the pitch and other perceivable
signal qualities, but also the style of the target speaker. In this paper, we
propose a novel neural network based speech quality- and style- mimicry
framework for the synthesis of impersonated voices. The framework is built upon
a fast and accurate generative adversarial network model. Given spectrographic
representations of source and target speakers' voices, the model learns to
mimic the target speaker's voice quality and style, regardless of the
linguistic content of either's voice, generating a synthetic spectrogram from
which the time domain signal is reconstructed using the Griffin-Lim method. In
effect, this model reframes the well-known problem of style-transfer for images
as the problem of style-transfer for speech signals, while intrinsically
addressing the problem of durational variability of speech sounds. Experiments
demonstrate that the model can generate extremely convincing samples of
impersonated speech. It is even able to impersonate voices across different
genders effectively. Results are qualitatively evaluated using standard
procedures for evaluating synthesized voices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06861</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06861</id><created>2018-02-16</created><authors><author><keyname>Mitra</keyname><forenames>Vikramjit</forenames></author><author><keyname>Franco</keyname><forenames>Horacio</forenames></author></authors><title>Interpreting DNN output layer activations: A strategy to cope with
  unseen data in speech recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages. arXiv admin note: substantial text overlap with
  arXiv:1708.09516</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unseen data can degrade performance of deep neural net acoustic models. To
cope with unseen data, adaptation techniques are deployed. For unlabeled unseen
data, one must generate some hypothesis given an existing model, which is used
as the label for model adaptation. However, assessing the goodness of the
hypothesis can be difficult, and an erroneous hypothesis can lead to poorly
trained models. In such cases, a strategy to select data having reliable
hypothesis can ensure better model adaptation. This work proposes a
data-selection strategy for DNN model adaptation, where DNN output layer
activations are used to ascertain the goodness of a generated hypothesis. In a
DNN acoustic model, the output layer activations are used to generate target
class probabilities. Under unseen data conditions, the difference between the
most probable target and the next most probable target is decreased compared to
the same for seen data, indicating that the model may be uncertain while
generating its hypothesis. This work proposes a strategy to assess a model's
performance by analyzing the output layer activations by using a distance
measure between the most likely target and the next most likely target, which
is used for data selection for performing unsupervised adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06862</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06862</id><created>2018-02-07</created><authors><author><keyname>Xing</keyname><forenames>Hong</forenames></author><author><keyname>Liu</keyname><forenames>Liang</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Joint Task Assignment and Wireless Resource Allocation for Cooperative
  Mobile-Edge Computing</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 4 figures, accepted by IEEE International Conference on
  Communications (ICC), Kansas City, MO, USA, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a multi-user cooperative mobile-edge computing (MEC)
system, in which a local mobile user can offload intensive computation tasks to
multiple nearby edge devices serving as helpers for remote execution. We focus
on the scenario where the local user has a number of independent tasks that can
be executed in parallel but cannot be further partitioned. We consider a time
division multiple access (TDMA) communication protocol, in which the local user
can offload computation tasks to the helpers and download results from them
over pre-scheduled time slots. Under this setup, we minimize the local user's
computation latency by optimizing the task assignment jointly with the time and
power allocations, subject to individual energy constraints at the local user
and the helpers. However, the joint task assignment and wireless resource
allocation problem is a mixed-integer non-linear program (MINLP) that is hard
to solve optimally. To tackle this challenge, we first relax it into a convex
problem, and then propose an efficient suboptimal solution based on the optimal
solution to the relaxed convex problem. Finally, numerical results show that
our proposed joint design significantly reduces the local user's computation
latency, as compared against other benchmark schemes that design the task
assignment separately from the offloading/downloading resource allocations and
local execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06869</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06869</id><created>2018-02-09</created><authors><author><keyname>Teng</keyname><forenames>Yunfei</forenames></author><author><keyname>Choromanska</keyname><forenames>Anna</forenames></author><author><keyname>Bojarski</keyname><forenames>Mariusz</forenames></author></authors><title>Invertible Autoencoder for domain adaptation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The unsupervised image-to-image translation aims at finding a mapping between
the source ($A$) and target ($B$) image domains, where in many applications
aligned image pairs are not available at training. This is an ill-posed
learning problem since it requires inferring the joint probability distribution
from marginals. Joint learning of coupled mappings $F_{AB}: A \rightarrow B$
and $F_{BA}: B \rightarrow A$ is commonly used by the state-of-the-art methods,
like CycleGAN [Zhu et al., 2017], to learn this translation by introducing
cycle consistency requirement to the learning problem, i.e. $F_{AB}(F_{BA}(B))
\approx B$ and $F_{BA}(F_{AB}(A)) \approx A$. Cycle consistency enforces the
preservation of the mutual information between input and translated images.
However, it does not explicitly enforce $F_{BA}$ to be an inverse operation to
$F_{AB}$. We propose a new deep architecture that we call invertible
autoencoder (InvAuto) to explicitly enforce this relation. This is done by
forcing an encoder to be an inverted version of the decoder, where
corresponding layers perform opposite mappings and share parameters. The
mappings are constrained to be orthonormal. The resulting architecture leads to
the reduction of the number of trainable parameters (up to $2$ times). We
present image translation results on benchmark data sets and demonstrate
state-of-the art performance of our approach. Finally, we test the proposed
domain adaptation method on the task of road video conversion. We demonstrate
that the videos converted with InvAuto have high quality and show that the
NVIDIA neural-network-based end-to-end learning system for autonomous driving,
known as PilotNet, trained on real road videos performs well when tested on the
converted ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06882</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06882</id><created>2018-02-15</created><updated>2018-03-04</updated><authors><author><keyname>Saito</keyname><forenames>Hiroshi</forenames></author><author><keyname>Kimura</keyname><forenames>Tatsuaki</forenames></author></authors><title>Theoretical Framework for Estimating Target-Object Shape by Using
  Location-Unknown Mobile Distance Sensors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a theoretical framework for estimating a target-object
shape, the location of which is not given, by using mobile distance sensors the
locations of which are also unknown. Typically, mobile sensors are mounted on
vehicles. Each sensor continuously measures the distance from it to the target
object. The proposed framework does not require any positioning function,
anchor-location information, or additional mechanisms to obtain side
information such as angle of arrival of signal. Under the assumption of a
convex polygon target object, each edge length and vertex angle and their
combinations are estimated and finally the shape of the target object is
estimated. To the best of our knowledge, this is the first result in which a
target-object shape was estimated by using the data of distance sensors without
using their locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06890</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06890</id><created>2018-02-19</created><authors><author><keyname>Tecchio</keyname><forenames>P. P. V.</forenames></author><author><keyname>Atanasov</keyname><forenames>N.</forenames></author><author><keyname>Pappas</keyname><forenames>G. J.</forenames></author></authors><title>Range-Only Localization in n-Dimensional Networks With Arbitrary Anchor
  Placement</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers node localization in static sensor networks using
range-only measurements. Similar to state- of-the-art algorithms, such as ECHO
and DILOC, we rely on barycentric coordinates of the nodes to transform the
non-convex node localization problem into a linear system of equations. The
main contribution of this paper is a simple closed-form expression for
generalized barycentric coordinates, which extends existing algorithms from two
to n dimensions and allows arbitrary anchor-node configurations. The result
relies on a connection between the Cayley-Menger bi-determinants of subsets of
n+1 neighbor nodes and the signed volume of the simplices defined by these
neighbor nodes. Hence, for noise-free measurements, the proposed method
computes the optimal sensor network embedding as the solution of a linear
system with coefficients obtained from the generalized barycentric node
coordinates. Using simulations, we provide comparisons with DILOC and Matlab's
MDS implementation. We also show that it is possible to improve our algorithm
run time using fewer subsets of neighbor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06894</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06894</id><created>2018-02-19</created><updated>2018-06-18</updated><authors><author><keyname>Huang</keyname><forenames>Kejun</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author></authors><title>Learning Hidden Markov Models from Pairwise Co-occurrences with
  Application to Topic Modeling</title><categories>cs.CL cs.LG eess.SP stat.ML</categories><comments>ICML 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for identifying the transition and emission
probabilities of a hidden Markov model (HMM) from the emitted data.
Expectation-maximization becomes computationally prohibitive for long
observation records, which are often required for identification. The new
algorithm is particularly suitable for cases where the available sample size is
large enough to accurately estimate second-order output probabilities, but not
higher-order ones. We show that if one is only able to obtain a reliable
estimate of the pairwise co-occurrence probabilities of the emissions, it is
still possible to uniquely identify the HMM if the emission probability is
\emph{sufficiently scattered}. We apply our method to hidden topic Markov
modeling, and demonstrate that we can learn topics with higher quality if
documents are modeled as observations of HMMs sharing the same emission (topic)
probability, compared to the simple but widely used bag-of-words model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06913</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06913</id><created>2018-02-19</created><authors><author><keyname>Batabyal</keyname><forenames>Tamal</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>ElasticPath2Path: Automated morphological classification of neurons by
  elastic path matching</title><categories>eess.IV q-bio.NC</categories><comments>This paper is submitted to IEEE International Conference on Image
  Processing, 2018</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In the study of neurons, morphology influences function. The complexity in
the structure of neurons poses a challenge in the identification and analysis
of similar and dissimilar neuronal cells. Existing methodologies carry out
structural and geometrical simplifications, which substantially change the
morphological statistics. Using digitally-reconstructed neurons, we extend the
work of Path2Path as ElasticPath2Path, which seamlessly integrates the
graph-theoretic and differential-geometric frameworks. By decomposing a neuron
into a set of paths, we derive graph metrics, which are path concurrence and
path hierarchy. Next, we model each path as an elastic string to compute the
geodesic distance between the paths of a pair of neurons. Later, we formulate
the problem of finding the distance between two neurons as a path assignment
problem with a cost function combining the graph metrics and the geodesic
deformation of paths. ElasticPath2Path is shown to have superior performance
over the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06929</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06929</id><created>2018-02-19</created><updated>2018-04-25</updated><authors><author><keyname>G.</keyname><forenames>Subhash Joshi T.</forenames></author><author><keyname>John</keyname><forenames>Vinod</forenames></author></authors><title>Thyristor Voltage Equalizing Network for Crowbar Application</title><categories>eess.SP</categories><comments>This paper is a preprint of a paper accepted by IET Power Electronics
  and is subject to Institution of Engineering and Technology Copyright. When
  the final version is published, the copy of record will be available at IET
  Digital Library&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many high voltage applications are realized with series connected thyristors.
Voltage imbalance among series connected thyristors during steady state as well
as in transients is one of the major concerns. This voltage imbalance is
mitigated by using static and dynamic balancing network. Dynamic balancing
networks are typically designed based on reverse recovery charge of the
thyristor during turn-off, which suits many applications. But this is not the
case for a crowbar application, where turn-off of the thyristor is not a major
circuit constraint. This paper proposes the design method for dynamic balancing
network considering gate turn-on delay time and the balancing network component
tolerances. The paper derives two models for the dynamic balancing network
based on its charge-discharge cycle. The importance of charge-discharge cycle
in the design of dynamic balancing network during high di/dt operation is
emphasized. Influence of dynamic balancing resistance and crowbar current
limiting inductance on voltage imbalance, charging current and discharging
current is studied using the analytical model. The proposed design method also
offers flexibility to incorporate differences in propagation delays among the
thyristor drivers that are used to trigger individual thyristors. Such delays
cannot be directly incorporated in the conventional balancing network design
method based on reverse recovery. Further, it is also analytically shown that
designing the dynamic balancing network based on reverse recovery charge makes
the balancing network lossy and bulky for crowbar application. Simulation
studies and experimental results on a 12kV , 1kA crowbar consisting of six
series connected thyristors confirms the theoretical analysis and validates the
proposed approach for crowbar applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06930</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06930</id><created>2018-02-19</created><authors><author><keyname>G.</keyname><forenames>Subhash Joshi T.</forenames></author><author><keyname>John</keyname><forenames>Vinod</forenames></author></authors><title>Small Signal Audiosusceptibility Model for Series Resonant Converter</title><categories>eess.SP</categories><comments>Submitted to IEEE Trans. on Industry Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models that accurately predict the output voltage ripple magnitude are
essential for applications with stringent performance target for it. Impact of
dc input ripple on the output ripple for a Series Resonant Converter (SRC)
using discrete domain exact discretization modelling method is analysed in this
paper. A novel discrete state space model along with a small signal model for
SRC considering 3 state variables is presented. The audiosusceptibility (AS)
transfer function which relates the input to output ripple is derived from the
small signal model. Analysis of the AS transfer function indicates a resonance
peak and an expression is derived connecting the AS resonance frequency for
input ripple with different SRC component values. Further analysis is done to
show that a set of values for SRC parameter exists, which forms a design
region, for which the normalized gain offered by the SRC for input ripple is
less than unity at any input ripple frequency. A test setup to introduce the
variable frequency ripple at the input of SRC for the experimental evaluation
of AS transfer function is also proposed. Influence of stray parameters on AS
gain, AS resonance frequency and on SRC tank resonance frequency is addressed.
An SRC is designed at a power level of 10kW. The analysis using the derived
model, simulations, and experimental results are found to be closely matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06935</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06935</id><created>2018-02-19</created><authors><author><keyname>Chang</keyname><forenames>Qi</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Zhao</keyname><forenames>Yao</forenames></author><author><keyname>Li</keyname><forenames>Xiaolong</forenames></author><author><keyname>Ni</keyname><forenames>Rongrong</forenames></author></authors><title>Non-Local Graph-Based Prediction For Reversible Data Hiding In Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible data hiding (RDH) is desirable in applications where both the
hidden message and the cover medium need to be recovered without loss. Among
many RDH approaches is prediction-error expansion (PEE), containing two steps:
i) prediction of a target pixel value, and ii) embedding according to the value
of prediction-error. In general, higher prediction performance leads to larger
embedding capacity and/or lower signal distortion. Leveraging on recent
advances in graph signal processing (GSP), we pose pixel prediction as a
graph-signal restoration problem, where the appropriate edge weights of the
underlying graph are computed using a similar patch searched in a semi-local
neighborhood. Specifically, for each candidate patch, we first examine
eigenvalues of its structure tensor to estimate its local smoothness. If
sufficiently smooth, we pose a maximum a posteriori (MAP) problem using either
a quadratic Laplacian regularizer or a graph total variation (GTV) term as
signal prior. While the MAP problem using the first prior has a closed-form
solution, we design an efficient algorithm for the second prior using
alternating direction method of multipliers (ADMM) with nested proximal
gradient descent. Experimental results show that with better quality GSP-based
prediction, at low capacity the visual quality of the embedded image exceeds
state-of-the-art methods noticeably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06941</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06941</id><created>2018-02-19</created><authors><author><keyname>Yi</keyname><forenames>Jiangyan</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author><author><keyname>Wen</keyname><forenames>Zhengqi</forenames></author><author><keyname>Liu</keyname><forenames>Bin</forenames></author></authors><title>Distilling Knowledge Using Parallel Data for Far-field Speech
  Recognition</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to improve the performance for far-field speech recognition, this
paper proposes to distill knowledge from the close-talking model to the
far-field model using parallel data. The close-talking model is called the
teacher model. The far-field model is called the student model. The student
model is trained to imitate the output distributions of the teacher model. This
constraint can be realized by minimizing the Kullback-Leibler (KL) divergence
between the output distribution of the student model and the teacher model.
Experimental results on AMI corpus show that the best student model achieves up
to 4.7% absolute word error rate (WER) reduction when compared with the
conventionally-trained baseline models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06963</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06963</id><created>2018-02-19</created><authors><author><keyname>Barsim</keyname><forenames>Karim Said</forenames></author><author><keyname>Mauch</keyname><forenames>Lukas</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author></authors><title>Neural Network Ensembles to Real-time Identification of Plug-level
  Appliance Measurements</title><categories>cs.LG cs.AI eess.SP</categories><comments>NILM Workshop 2016</comments><report-no>ID09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of identifying end-use electrical appliances from their
individual consumption profiles, known as the appliance identification problem,
is a primary stage in both Non-Intrusive Load Monitoring (NILM) and automated
plug-wise metering. Therefore, appliance identification has received dedicated
studies with various electric appliance signatures, classification models, and
evaluation datasets. In this paper, we propose a neural network ensembles
approach to address this problem using high resolution measurements. The models
are trained on the raw current and voltage waveforms, and thus, eliminating the
need for well engineered appliance signatures. We evaluate the proposed model
on a publicly available appliance dataset from 55 residential buildings, 11
appliance categories, and over 1000 measurements. We further study the
stability of the trained models with respect to training dataset, sampling
frequency, and variations in the steady-state operation of appliances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.06984</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.06984</id><created>2018-02-20</created><authors><author><keyname>Nachmani</keyname><forenames>Eliya</forenames></author><author><keyname>Polyak</keyname><forenames>Adam</forenames></author><author><keyname>Taigman</keyname><forenames>Yaniv</forenames></author><author><keyname>Wolf</keyname><forenames>Lior</forenames></author></authors><title>Fitting New Speakers Based on a Short Untranscribed Sample</title><categories>cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning-based Text To Speech systems have the potential to generalize from
one speaker to the next and thus require a relatively short sample of any new
voice. However, this promise is currently largely unrealized. We present a
method that is designed to capture a new speaker from a short untranscribed
audio sample. This is done by employing an additional network that given an
audio sample, places the speaker in the embedding space. This network is
trained as part of the speech synthesis system using various consistency
losses. Our results demonstrate a greatly improved performance on both the
dataset speakers, and, more importantly, when fitting new voices, even from
very short samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07016</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07016</id><created>2018-02-20</created><authors><author><keyname>Calvo-Palomino</keyname><forenames>Roberto</forenames></author><author><keyname>Ricciato</keyname><forenames>Fabio</forenames></author><author><keyname>Repas</keyname><forenames>Blaz</forenames></author><author><keyname>Giustiniano</keyname><forenames>Domenico</forenames></author><author><keyname>Lenders</keyname><forenames>Vincent</forenames></author></authors><title>Nanosecond-precision Time-of-Arrival Estimation for Aircraft Signals
  with low-cost SDR Receivers</title><categories>eess.SP cs.NI</categories><comments>IPSN 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precise Time-of-Arrival (TOA) estimations of aircraft and drone signals are
important for a wide set of applications including aircraft/drone tracking, air
traffic data verification, or self-localization. Our focus in this work is on
TOA estimation methods that can run on low-cost software-defined radio (SDR)
receivers, as widely deployed in Mode S / ADS-B crowdsourced sensor networks
such as the OpenSky Network. We evaluate experimentally classical TOA
estimation methods which are based on a cross-correlation with a reconstructed
message template and find that these methods are not optimal for such signals.
We propose two alternative methods that provide superior results for real-world
Mode S / ADS-B signals captured with low-cost SDR receivers. The best method
achieves a standard deviation error of 1.5 ns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07093</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07093</id><created>2018-02-20</created><authors><author><keyname>Chevreuil</keyname><forenames>Antoine</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author></authors><title>On the non-detectability of spiked large random tensors</title><categories>eess.SP</categories><comments>submitted to SSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the detection of a low rank high-dimensional tensor
corrupted by an additive complex Gaussian noise. In the asymptotic regime where
all the dimensions of the tensor converge towards $+\infty$ at the same rate,
existing results devoted to rank 1 tensors are extended. It is proved that if a
certain parameter depending on the low rank tensor is below a threshold, then
the null hypothesis and the presence of the low rank tensor are
undistinguishable hypotheses in the sense that no test performs better than a
random choice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07101</identifier>
 <datestamp>2018-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07101</id><created>2018-02-20</created><updated>2018-10-18</updated><authors><author><keyname>Jing</keyname><forenames>Yongcheng</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Yang</keyname><forenames>Yezhou</forenames></author><author><keyname>Feng</keyname><forenames>Zunlei</forenames></author><author><keyname>Yu</keyname><forenames>Yizhou</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Song</keyname><forenames>Mingli</forenames></author></authors><title>Stroke Controllable Fast Style Transfer with Adaptive Receptive Fields</title><categories>cs.CV eess.IV</categories><comments>Accepted by ECCV2018. Supplementary material:
  https://yongchengjing.com/pdf/strokeControllable_supp.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fast Style Transfer methods have been recently proposed to transfer a
photograph to an artistic style in real-time. This task involves controlling
the stroke size in the stylized results, which remains an open challenge. In
this paper, we present a stroke controllable style transfer network that can
achieve continuous and spatial stroke size control. By analyzing the factors
that influence the stroke size, we propose to explicitly account for the
receptive field and the style image scales. We propose a StrokePyramid module
to endow the network with adaptive receptive fields, and two training
strategies to achieve faster convergence and augment new stroke sizes upon a
trained model respectively. By combining the proposed runtime control
strategies, our network can achieve continuous changes in stroke sizes and
produce distinct stroke sizes in different spatial regions within the same
output image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07159</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07159</id><created>2018-02-20</created><authors><author><keyname>Chehardeh</keyname><forenames>Maziar Isapour</forenames></author><author><keyname>Siavashi</keyname><forenames>Ehsan M</forenames></author></authors><title>A Closed-loop controller to improve the Stability of Cascaded DC/DC
  Converters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Study of the buck converter and cascaded system considering the voltage mode
controller has been done. First the small signal analysis of a buck dc/dc
converter is presented and its mathematical representation has been showed.
Then, the cascaded converter model regarding close loop impedances and voltage
gain has been studied. The controller for this converter is proposed to
stabilize the performance of the plant. The effectiveness of the proposed
controller has been tested on a typical buck converter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07160</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07160</id><created>2018-02-19</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Performance analysis of a novel hybrid FSO / RF communication system</title><categories>eess.SP</categories><comments>8 pages, 5figues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel dual-hop relay-assisted hybrid Free Space Optical /
Radio Frequency (FSO / RF) communication system is presented. In this structure
an access point connects users within the building to the Base Station via a
hybrid parallel FSO / RF link, this link is proposed firstly. Parallel
combination of FSO and RF links and use of an access point, will increase
capacity, reliability and data rate of the system. It is the first time that
the effect of number of users on the performance of a dual-hop relay-assisted
hybrid parallel FSO / RF system is investigated. FSO link is considered in
Gamma-Gamma atmospheric turbulence with the effect of pointing error and RF
link is considered in Rayleigh fading. For the first time, closed-form
expressions are derived for Bit Error Rate (BER) and Outage Probability (P_out)
of the proposed system. Derived expressions are verified through MATLAB
simulations. It is shown that the performance of the proposed system is almost
independent of atmospheric turbulence intensity, thereby when atmospheric
turbulence strengthens, low power consumption is required for maintenance of
the system performance. Hence the proposed structure is particularly suitable
for mobile communication systems in which a small mobile battery supplies
transmitter power. Also the proposed system performance of the system is
preferable even at low signal to noise ratio (SNR). Therefore, proposed
structure significantly reduces power consumption while maintaining performance
of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07180</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07180</id><created>2018-02-18</created><authors><author><keyname>Koljensic</keyname><forenames>Tamara</forenames></author><author><keyname>Labudovic</keyname><forenames>Caslav</forenames></author></authors><title>Comparison of threshold-based algorithms for sparse signal recovery</title><categories>eess.SP cs.MM</categories><comments>student paper submitted to the za 7th Mediterranean Conference on
  Embedded Computing - MECO'2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intensively growing approach in signal processing and acquisition, the
Compressive Sensing approach, allows sparse signals to be recovered from small
number of randomly acquired signal coefficients. This paper analyses some of
the commonly used threshold-based algorithms for sparse signal reconstruction.
Signals satisfy the conditions required by the Compressive Sensing theory. The
Orthogonal Matching Pursuit, Iterative Hard Thresholding and Single Iteration
Reconstruction algorithms are observed. Comparison in terms of reconstruction
error and execution time is performed within the experimental part of the
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07257</identifier>
 <datestamp>2018-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07257</id><created>2018-02-21</created><authors><author><keyname>Rauter</keyname><forenames>Matthias</forenames></author><author><keyname>Winkler</keyname><forenames>Daniel</forenames></author></authors><title>Predicting Natural Hazards with Neuronal Networks</title><categories>eess.IV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gravitational mass flows, such as avalanches, debris flows and rockfalls are
common events in alpine regions with high impact on transport routes. Within
the last few decades, hazard zone maps have been developed to systematically
approach this threat. These maps mark vulnerable zones in habitable areas to
allow effective planning of hazard mitigation measures and development of
settlements. Hazard zone maps have shown to be an effective tool to reduce
fatalities during extreme events. They are created in a complex process, based
on experience, empirical models, physical simulations and historical data. The
generation of such maps is therefore expensive and limited to crucially
important regions, e.g. permanently inhabited areas.
  In this work we interpret the task of hazard zone mapping as a classification
problem. Every point in a specific area has to be classified according to its
vulnerability. On a regional scale this leads to a segmentation problem, where
the total area has to be divided in the respective hazard zones. The recent
developments in artificial intelligence, namely convolutional neuronal
networks, have led to major improvement in a very similar task, image
classification and semantic segmentation, i.e. computer vision. We use a
convolutional neuronal network to identify terrain formations with the
potential for catastrophic snow avalanches and label points in their reach as
vulnerable. Repeating this procedure for all points allows us to generate an
artificial hazard zone map. We demonstrate that the approach is feasible and
promising based on the hazard zone map of the Tirolean Oberland. However, more
training data and further improvement of the method is required before such
techniques can be applied reliably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07286</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07286</id><created>2018-02-19</created><updated>2018-11-20</updated><authors><author><keyname>Sayehvand</keyname><forenames>Javad</forenames></author><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Performance analysis of hybrid FSO/RF communication systems with
  Alamouti Coding or Antenna Selection</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a novel dual-hop relay-assisted hybrid Free Space Optical /
Radio Frequency (FSO / RF) communication system is presented. In this system,
RF signal is transmitted from two antennas, and then forwarded by a single
antenna relay through FSO channel. This is the first time that performance of
using Alamouti Coding (AC) or Antenna Selection (AS) at the transmitter of a
hybrid FSO / RF system is investigated. FSO link has Gamma-Gamma atmospheric
turbulence, and in order to get closer to the actual results, the effect of
pointing error is also considered. For the first time closed-form expressions
are derived for Bit Error Rate (BER) and Outage Probability of the proposed
system and validated through MATLAB simulations. Results indicate that in this
structure, there is slight performance difference between AC and AS schemes.
Hence due to more complexity, power consumption and latency of AC, AS is
recommended. Dual-hop, hybrid FSO / RF system significantly improves
performance and reliability of the system, and is particularly suitable for
long-range applications that direct RF communication between source and
destination is not possible. Considering these advantages this structure is
particularly suitable for mobile communications which has power and processing
limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07313</identifier>
 <datestamp>2018-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07313</id><created>2018-02-20</created><authors><author><keyname>Chehardeh</keyname><forenames>Maziar Isapour</forenames></author><author><keyname>Siavashi</keyname><forenames>Ehsan M</forenames></author></authors><title>A Novel Hybrid Islanding Detection Method for Inverter-based DG</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel method for achieving a better performance using the combination of
the available passive and active methods has been proposed. The algorithm
detects the islanding in proper time by using harmonic detection, the average
rate of change of voltage and shifting power generation. Harmonic detection in
this method decreases process time and also differentiates between islanding
and other power systems events. For harmonic detection, extended Kalman filter
has been used. Besides, the reliability of the method increases using the
average rate of change of the voltage. The proposed method uses a strategy for
decreasing the non-detection zone. In this strategy, minimum and maximum
average rates of change of voltage limits are defined to improve the security
of the system. Therefore, three main specifications of a proper method,
reliability, security and time of process are achievable by the combination of
these passive and active methods. By applying different power system events
under different power conditions, the proposed method has been verified in
Simulink software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07335</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07335</id><created>2018-02-19</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Performance Comparison of two novel Relay-Assisted Hybrid FSO / RF
  Communication Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript, two novel multi-hop relay-assisted hybrid Free Space
Optical / Radio Frequency (FSO / RF) communication systems are presented and
compared. In these structures, RF and FSO links, at each hop, are parallel and
send data simultaneously. This is the first time that in a multihop hybrid FSO
/ RF structure, Detect and Forward protocol is used. In the first structure, at
each hop, received signals with higher Signal to Noise Ratio (SNR) is selected.
But in the second structure, at each hop, received FSO and RF signals are
separately detected and forwarded and selection is done only at the last hop.
Considering FSO link in Negative Exponential atmospheric turbulence and RF link
in Rayleigh fading, for the first time, closed-form expressions are derived for
Outage Probability (P_out) and Bit Error Rate (BER) of the proposed structures.
MATLAB simulations are provided to verify derived expressions. The main
motivation of this work is to answer this question that how much is the
difference of selection at each hop and selection at the last hop. Results
indicate that the structure with selection at each hop has better performance
than the structure with selection at the last hop. At different target Outage
Probability, selection at the last hop consumes about two times (~3dB) more
power than selection at each hop. Both structures are particularly suitable for
long-range communications. However, selection at each hop, in the cost of more
complexity, is recommended for applications which have problem with supplying
the required power for communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07346</identifier>
 <datestamp>2018-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07346</id><created>2018-02-20</created><authors><author><keyname>Ouimet</keyname><forenames>Michael</forenames></author><author><keyname>Iglesias</keyname><forenames>David</forenames></author><author><keyname>Ahmed</keyname><forenames>Nisar</forenames></author><author><keyname>Martinez</keyname><forenames>Sonia</forenames></author></authors><title>Cooperative Robot Localization Using Event-triggered Estimation</title><categories>cs.RO cs.SY eess.SP stat.AP</categories><comments>Revised submission in review with AIAA Journal of Aerospace
  Information Systems (JAIS), submitted February 17, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel communication-spare cooperative localization
algorithm for a team of mobile unmanned robotic vehicles. Exploiting an
event-based estimation paradigm, robots only send measurements to neighbors
when the expected innovation for state estimation is high. Since agents know
the event-triggering condition for measurements to be sent, the lack of a
measurement is thus also informative and fused into state estimates. The robots
use a Covariance Intersection (CI) mechanism to occasionally synchronize their
local estimates of the full network state. In addition, heuristic balancing
dynamics on the robots' CI-triggering thresholds ensure that, in large diameter
networks, the local error covariances remains below desired bounds across the
network. Simulations on both linear and nonlinear dynamics/measurement models
show that the event-triggering approach achieves nearly optimal state
estimation performance in a wide range of operating conditions, even when using
only a fraction of the communication cost required by conventional full data
sharing. The robustness of the proposed approach to lossy communications, as
well as the relationship between network topology and CI-based synchronization
requirements, are also examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07348</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07348</id><created>2018-02-19</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>A novel hybrid FSO / RF communication system with receive diversity</title><categories>eess.SP</categories><doi>10.1016/j.ijleo.2019.03.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mobile communication system, due to the limitations of mobile device such
as low power supply as well as small size, most of the processing should be
done at the Base Station. Using multi-receive structure at the Base Station
really helps better recovery of the original signal by combining different
received signals. In this paper, for the first time, receive diversity is used
in single-hop hybrid Free Space Optical / Radio Frequency (FSO / RF)
communication system. Also it is the first time that a single-hop hybrid FSO /
RF system is investigated at saturate atmospheric turbulence regime. For the
first time, closed-form expression is derived for Outage Probability of the
proposed system and verified through MATLAB simulation. Results indicate a
significant improvement in the performance of the proposed structure compared
with common FSO and RF systems with receive diversity. Therefore it can be
concluded that although the proposed structure requires a complex receiver, but
addition of this complexity could significantly reduce processing or power
consumption required for performance maintenance of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07368</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07368</id><created>2018-02-20</created><updated>2019-01-09</updated><authors><author><keyname>Hu</keyname><forenames>Yue</forenames></author><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Chen</keyname><forenames>Yi</forenames></author><author><keyname>Wan</keyname><forenames>G. C.</forenames></author><author><keyname>Mei</keyname><forenames>S. T.</forenames></author></authors><title>Gaussian Random Number Generator: Implemented in FPGA for Quantum Key
  Distribution</title><categories>eess.SP</categories><comments>18 pages, 6 figures, accepted for publication in the International
  Journal of Numerical Modeling: Electronic Networks, Devices and Fields</comments><doi>10.1002/jnm.2554</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum Key Distribution is the process of using quantum communication to
establish a shared key between two parties. It has been demonstrated the
unconditional security and effective communication of quantum communication
system can be guaranteed by an excellent Gaussian random number generator with
high speed and an extended random period. In this paper, we propose to
construct the Gaussian random number generator using Field-Programmable Gate
Array (FPGA) which is able to process large data in high speed. We also compare
three algorithms ofGRNgeneration: Box-Muller algorithm, polarization decision
algorithm, and central limit algorithm. We demonstrate that the polarization
decision algorithm implemented inFPGArequires less computing resources and also
produces a high-quality Gaussian random number, through the null hypothesis
test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07406</identifier>
 <datestamp>2018-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07406</id><created>2018-02-20</created><authors><author><keyname>Baum</keyname><forenames>Amir Ebrahimi. Thomas</forenames></author><author><keyname>Ghorbani</keyname><forenames>Kamran</forenames></author></authors><title>Differential Bandpass Filters Based on Dumbbell-Shaped Defected Ground
  Resonators</title><categories>eess.SP</categories><journal-ref>IEEE Microwave and Wireless Components Letters, vol. 28, no. 2,
  pp. 129-131, Feb. 2018</journal-ref><doi>10.1109/LMWC.2017.2780765</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents a dumbbell-shaped defected ground resonator and its
application in the design of differential filters. The operation principle of
the dumbbell-shaped resonator (DSR) coupled to differential microstrip lines is
studied through a circuit model analysis. The proposed circuit model is
validated through the comparison with the electromagnetic simulation results.
It is shown that the bandpass configuration of microstripline- coupled DSR can
be used to design higher order bandpass filters. The design procedure is
explained by developing a thirdorder filter prototype. The designed filter
shows more than 57 dB common mode rejection within the differential passband.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07420</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07420</id><created>2018-02-20</created><updated>2018-03-06</updated><authors><author><keyname>Dalmia</keyname><forenames>Siddharth</forenames></author><author><keyname>Sanabria</keyname><forenames>Ramon</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author><author><keyname>Black</keyname><forenames>Alan W.</forenames></author></authors><title>Sequence-based Multi-lingual Low Resource Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages, 5 figures, to appear in 2018 IEEE International Conference
  on Acoustics, Speech and Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Techniques for multi-lingual and cross-lingual speech recognition can help in
low resource scenarios, to bootstrap systems and enable analysis of new
languages and domains. End-to-end approaches, in particular sequence-based
techniques, are attractive because of their simplicity and elegance. While it
is possible to integrate traditional multi-lingual bottleneck feature
extractors as front-ends, we show that end-to-end multi-lingual training of
sequence models is effective on context independent models trained using
Connectionist Temporal Classification (CTC) loss. We show that our model
improves performance on Babel languages by over 6% absolute in terms of
word/phoneme error rate when compared to mono-lingual systems built in the same
setting for these languages. We also show that the trained model can be adapted
cross-lingually to an unseen language using just 25% of the target data. We
show that training on multiple languages is important for very low resource
cross-lingual target scenarios, but not for multi-lingual testing scenarios.
Here, it appears beneficial to include large well prepared datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07454</identifier>
 <datestamp>2018-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07454</id><created>2018-02-21</created><authors><author><keyname>Ebrahimi</keyname><forenames>Amir</forenames></author><author><keyname>Baum</keyname><forenames>Thomas</forenames></author><author><keyname>Scott</keyname><forenames>James</forenames></author><author><keyname>Ghorbani</keyname><forenames>Kamran</forenames></author></authors><title>Narrowband Bandpass Frequency Selective Surface with Miniaturized
  Elements</title><categories>eess.SP</categories><journal-ref>2017 IEEE Asia Pacific Microwave Conference (APMC), Kuala Lumpar,
  2017, pp. 196-199</journal-ref><doi>10.1109/APMC.2017.8251412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a bandpass frequency selective surface (FSS) with a
narrowband frequency response. The designed FSS is made of miniaturized
elements unit cell. The operation principle of the FSS is explained by using an
equivalent circuit model, where the passband bandwidth can be controlled by the
values of the circuit elements corresponding to the geometrical dimensions of
the unit cell. The compatibility of the presented structure in designing higher
order narrowband filtering responses is verified by designing a second-order
bandpass FSS with 8:5% fractional bandwidth with a center frequency of 2:7 GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07470</identifier>
 <datestamp>2018-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07470</id><created>2018-02-21</created><authors><author><keyname>Pannuto</keyname><forenames>Pat</forenames></author><author><keyname>Kempke</keyname><forenames>Benjamin</forenames></author><author><keyname>Dutta</keyname><forenames>Prabal</forenames></author></authors><title>Slocalization: Sub-{\mu}W Ultra Wideband Backscatter Localization</title><categories>cs.NI eess.SP</categories><comments>Published at the 17th ACM/IEEE Conference on Information Processing
  in Sensor Networks (IPSN'18)</comments><doi>10.1109/IPSN.2018.00052</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Ultra wideband technology has shown great promise for providing high-quality
location estimation, even in complex indoor multipath environments, but
existing ultra wideband systems require tens to hundreds of milliwatts during
operation. Backscatter communication has demonstrated the viability of
astonishingly low-power tags, but has thus far been restricted to narrowband
systems with low localization resolution. The challenge to combining these
complimentary technologies is that they share a compounding limitation,
constrained transmit power. Regulations limit ultra wideband transmissions to
just -41.3 dBm/MHz, and a backscatter device can only reflect the power it
receives. The solution is long-term integration of this limited power, lifting
the initially imperceptible signal out of the noise. This integration only
works while the target is stationary. However, stationary describes the vast
majority of objects, especially lost ones. With this insight, we design
Slocalization, a sub-microwatt, decimeter-accurate localization system that
opens a new tradeoff space in localization systems and realizes an energy,
size, and cost point that invites the localization of every thing. To evaluate
this concept, we implement an energy-harvesting Slocalization tag and find that
Slocalization can recover ultra wideband backscatter in under fifteen minutes
across thirty meters of space and localize tags with a mean 3D Euclidean error
of only 30 cm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07759</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07759</id><created>2018-02-21</created><updated>2019-03-01</updated><authors><author><keyname>Kumar</keyname><forenames>Bhumesh</forenames></author><author><keyname>Borkar</keyname><forenames>Vivek</forenames></author><author><keyname>Shetty</keyname><forenames>Akhil</forenames></author></authors><title>Non-asymptotic Error Bounds For Constant Stepsize Stochastic
  Approximation For Tracking Mobile Agents</title><categories>eess.SP</categories><comments>Expanded and revised</comments><journal-ref>Mathematics of Control, Signals, and Systems (2019)</journal-ref><doi>10.1007/s00498-019-00249-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work revisits the constant stepsize stochastic approximation algorithm
for tracking a slowly moving target and obtains a bound for the tracking error
that is valid for the entire time axis, using the Alekseev non-linear variation
of constants formula. It is the first non-asymptptic bound for the entire time
axis in the sense that it is not based on the vanishing stepsize limit and
associated limit theorems unlike prior works, and captures clearly the
dependence on problem parameters and the dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07860</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07860</id><created>2018-02-21</created><updated>2019-04-25</updated><authors><author><keyname>Jati</keyname><forenames>Arindam</forenames></author><author><keyname>Georgiou</keyname><forenames>Panayiotis</forenames></author></authors><title>Neural Predictive Coding using Convolutional Neural Networks towards
  Unsupervised Learning of Speaker Characteristics</title><categories>cs.SD cs.CL eess.AS</categories><journal-ref>IEEE/ACM Transactions on Audio, Speech, and Language Processing,
  vol. 27, no. 10, pp. 1577-1589, Oct. 2019</journal-ref><doi>10.1109/TASLP.2019.2921890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning speaker-specific features is vital in many applications like speaker
recognition, diarization and speech recognition. This paper provides a novel
approach, we term Neural Predictive Coding (NPC), to learn speaker-specific
characteristics in a completely unsupervised manner from large amounts of
unlabeled training data that even contain many non-speech events and
multi-speaker audio streams. The NPC framework exploits the proposed short-term
active-speaker stationarity hypothesis which assumes two temporally-close short
speech segments belong to the same speaker, and thus a common representation
that can encode the commonalities of both the segments, should capture the
vocal characteristics of that speaker. We train a convolutional deep siamese
network to produce &quot;speaker embeddings&quot; by learning to separate `same' vs
`different' speaker pairs which are generated from an unlabeled data of audio
streams. Two sets of experiments are done in different scenarios to evaluate
the strength of NPC embeddings and compare with state-of-the-art in-domain
supervised methods. First, two speaker identification experiments with
different context lengths are performed in a scenario with comparatively
limited within-speaker channel variability. NPC embeddings are found to perform
the best at short duration experiment, and they provide complementary
information to i-vectors for full utterance experiments. Second, a large scale
speaker verification task having a wide range of within-speaker channel
variability is adopted as an upper-bound experiment where comparisons are drawn
with in-domain supervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.07984</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.07984</id><created>2018-02-22</created><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Vakili</keyname><forenames>Vahid Tabataba</forenames></author></authors><title>A new optimization problem in FSO communication system</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the physical phenomena of atmospheric channels and wave
propagation, performance of wireless communication systems can be optimized by
simply adjusting its parameters. This way is more economically favorable than
consuming power or using processing techniques. In this paper for the first
time an optimization problem is developed on the performance of free-space
optical multi-input multi-output (FSO-MIMO) communication system. Also it is
the first time that the optimization of FSO is developed under saturated
atmospheric turbulences. In order to get closer to the actual results, the
effect of pointing error is taken into considerations. Assuming MPSK, DPSK
modulation schemes, new closed-form expressions are derived for Bit Error Rate
(BER) of the proposed structure. Furthermore, an optimization is developed
taking into account the beam width as the variable parameter, and BER as the
objective function, there is no constraint in this system. The obtained results
can be a useful outcome for FSO-MIMO system designers in order to limit effects
of pointing error as well as atmospheric turbulences and thus achieves optimum
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08008</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08008</id><created>2018-02-22</created><authors><author><keyname>Sinclair</keyname><forenames>Stephen</forenames></author></authors><title>Sounderfeit: Cloning a Physical Model with Conditional Adversarial
  Autoencoders</title><categories>cs.SD cs.LG eess.AS</categories><comments>Published in the Brazilian Symposium on Computer Music (SBCM 2017)</comments><journal-ref>Proc. Brazilian Symp. on Comp. Music., 2017. p. 67--74</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An adversarial autoencoder conditioned on known parameters of a physical
modeling bowed string synthesizer is evaluated for use in parameter estimation
and resynthesis tasks. Latent dimensions are provided to capture variance not
explained by the conditional parameters. Results are compared with and without
the adversarial training, and a system capable of &quot;copying&quot; a given
parameter-signal bidirectional relationship is examined. A real-time synthesis
system built on a generative, conditioned and regularized neural network is
presented, allowing to construct engaging sound synthesizers based purely on
recorded data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08027</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08027</id><created>2018-02-22</created><authors><author><keyname>Emara</keyname><forenames>Mustafa</forenames></author><author><keyname>Filippou</keyname><forenames>Miltiades C.</forenames></author><author><keyname>Sabella</keyname><forenames>Dario</forenames></author></authors><title>MEC-assisted End-to-End Latency Evaluations for C-V2X Communications</title><categories>eess.SP</categories><comments>Submitted to EuCNC'18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient design of fifth generation (5G) mobile networks is driven by
the need to support the dynamic proliferation of several vertical market
segments. Considering the automotive sector, different Cellular
Vehicle-to-Everything (C-V2X) use cases have been identified by the industrial
and research world, referring to infotainment, automated driving and road
safety. A common characteristic of these use cases is the need to exploit
collective awareness of the road environment towards satisfying performance
requirements. One of these requirements is the End-to-End (E2E) latency when,
for instance, Vulnerable Road Users (VRUs) inform vehicles about their status
(e.g., location) and activity, assisted by the cellular network. In this paper,
focusing on a freeway-based VRU scenario, we argue that, in contrast to
conventional, remote cloud-based cellular architecture, the deployment of
Multi-access Edge Computing (MEC) infrastructure can substantially prune the
E2E communication latency. Our argument is supported by an extensive
simulation-based performance comparison between the conventional and the
MEC-assisted network architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08053</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08053</id><created>2018-02-12</created><authors><author><keyname>Costa</keyname><forenames>Luciano da F.</forenames></author></authors><title>On the Effects of Resistive and Reactive Loads on Signal Amplification</title><categories>eess.SP</categories><comments>A working manuscript with 13 pages and 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of reactive loads into amplification is studied. A simplified
common emitter circuit configuration was adopted and respective
time-independent and time-dependent voltage and current equations were
obtained. As phasor analysis cannot be used because of the non-linearity, the
voltage at the capacitor was represented in terms of the respective integral,
implying a numerical approach. The effect of purely resistive loads was
investigated first, and it was shown that the fanned structure of the
transistor isolines can severely distort the amplification, especially for
$V_a$ small and $s$ large. The total harmonic distortion was found not to
depend on $V_a$, being determined by $s$ and the load resistance $R$. An
expression was obtained for the current gain in terms of the base current and
it was shown that it decreases in an almost perfectly linearly fashion with
$I_B$. Remarkably, no gain variation, and hence perfectly linear amplification,
is obtained when $R=0$, provided maximum power dissipation limits are not
exceeded. Capacitive loads imply the detachment of the circuit trajectory from
a straight line to an &quot;ellipsoidal&quot;-like loop. This implies a gain asymmetry
along upper or lower arcs of this loop. By using the time-dependent circuit
equations, it was possible to show numerically and by an analytical
approximation that, at least for the adopted circuit and parameter values, the
asymmetry induced by capacitive loads is not substantial. However, capacitive
loads will imply lag between the output voltage and current and, hence,
low-pass filtering. It was shown that smaller $V_a$ and larger $s$ can
substantially reduce the phase lag, but at the cost of severe distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08154</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08154</id><created>2018-02-19</created><authors><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Sliding Bidirectional Recurrent Neural Networks for Sequence Detection
  in Communication Systems</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>accepted for publication in the proceedings of IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP) 2018. arXiv
  admin note: text overlap with arXiv:1802.02046 and arXiv:1705.08044</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design and analysis of communication systems typically rely on the
development of mathematical models that describe the underlying communication
channel. However, in some systems, such as molecular communication systems
where chemical signals are used for transfer of information, the underlying
channel models are unknown. In these scenarios, a completely new approach to
design and analysis is required. In this work, we focus on one important aspect
of communication systems, the detection algorithms, and demonstrate that by
using tools from deep learning, it is possible to train detectors that perform
well without any knowledge of the underlying channel models. We propose a
technique we call sliding bidirectional recurrent neural network (SBRNN) for
real-time sequence detection. We evaluate this algorithm using experimental
data that is collected by a chemical communication platform, where the channel
model is unknown and difficult to model analytically. We show that deep
learning algorithms perform significantly better than a detector proposed in
previous works, and the SBRNN outperforms other techniques considered in this
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08156</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08156</id><created>2018-02-19</created><authors><author><keyname>Zhou</keyname><forenames>Ao</forenames></author><author><keyname>Chen</keyname><forenames>Ni</forenames></author><author><keyname>Wang</keyname><forenames>Haichao</forenames></author><author><keyname>Situ</keyname><forenames>Guohai</forenames></author></authors><title>Analysis of Fourier ptychographic microscopy with half of the captured
  images</title><categories>eess.IV physics.optics</categories><doi>10.1088/2040-8986/aad453</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fourier ptychography microscopy (FPM) is a new computational imaging
technique that can provide gigapixel images with both high resolution and a
wide field of view (FOV). However, time consuming of the data-acquisition
process is a critical issue. In this paper, we make an analysis on the FPM
imaging system with half number of the captured images. Based on the image
analysis of the conventional FPM system, we then compare the reconstructed
images with different number of captured data. Simulation and experiment
results show that the reconstructed image with half number captured data do not
show obvious resolution degradation compared to that with all the captured
data, except a contrast reduction. In particular in the case when the object is
close to phase-only/amplitude only, the quality of the reconstructed image with
half of the captured data is nearly as good as the one reconstructed with full
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08314</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08314</id><created>2018-02-22</created><authors><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Woodland</keyname><forenames>Philip</forenames></author></authors><title>High Order Recurrent Neural Networks for Acoustic Modelling</title><categories>cs.CL cs.AI eess.AS stat.ML</categories><comments>5 pages, 2 figures, 2 tables, to appear in 2018 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vanishing long-term gradients are a major issue in training standard
recurrent neural networks (RNNs), which can be alleviated by long short-term
memory (LSTM) models with memory cells. However, the extra parameters
associated with the memory cells mean an LSTM layer has four times as many
parameters as an RNN with the same hidden vector size. This paper addresses the
vanishing gradient problem using a high order RNN (HORNN) which has additional
connections from multiple previous time steps. Speech recognition experiments
using British English multi-genre broadcast (MGB3) data showed that the
proposed HORNN architectures for rectified linear unit and sigmoid activation
functions reduced word error rates (WER) by 4.2% and 6.3% over the
corresponding RNNs, and gave similar WERs to a (projected) LSTM while using
only 20%--50% of the recurrent layer parameters and computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08338</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08338</id><created>2018-02-22</created><updated>2018-02-26</updated><authors><author><keyname>Whitaker</keyname><forenames>Darren A</forenames></author><author><keyname>Egan</keyname><forenames>David</forenames></author><author><keyname>OBrien</keyname><forenames>Eoin</forenames></author><author><keyname>Kinnear</keyname><forenames>David</forenames></author></authors><title>Application of Multivariate Data Analysis to machine power measurements
  as a means of tool life Predictive Maintenance for reducing product waste</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern manufacturing industries are increasingly looking to predictive
analytics to gain decision making information from process data. This is driven
by high levels of competition and a need to reduce operating costs. The
presented work takes data in the form of a power measurement recorded during a
medical device manufacturing process and uses multivariate data analysis (MVDA)
to extract information leading to the proposal of a predictive maintenance
scheduling algorithm. The proposed MVDA model was able to predict with 100 %
accuracy the condition of a grinding tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08397</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08397</id><created>2018-02-23</created><updated>2018-05-02</updated><authors><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author></authors><title>Harnessing Structures in Big Data via Guaranteed Low-Rank Matrix
  Estimation</title><categories>stat.ML cs.IT cs.LG eess.SP math.IT</categories><comments>To appear in IEEE Signal Processing Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-rank modeling plays a pivotal role in signal processing and machine
learning, with applications ranging from collaborative filtering, video
surveillance, medical imaging, to dimensionality reduction and adaptive
filtering. Many modern high-dimensional data and interactions thereof can be
modeled as lying approximately in a low-dimensional subspace or manifold,
possibly with additional structures, and its proper exploitations lead to
significant reduction of costs in sensing, computation and storage. In recent
years, there is a plethora of progress in understanding how to exploit low-rank
structures using computationally efficient procedures in a provable manner,
including both convex and nonconvex approaches. On one side, convex relaxations
such as nuclear norm minimization often lead to statistically optimal
procedures for estimating low-rank matrices, where first-order methods are
developed to address the computational challenges; on the other side, there is
emerging evidence that properly designed nonconvex procedures, such as
projected gradient descent, often provide globally optimal solutions with a
much lower computational cost in many problems. This survey article will
provide a unified overview of these recent advances on low-rank matrix
estimation from incomplete measurements. Attention is paid to rigorous
characterization of the performance of these algorithms, and to problems where
the low-rank matrix have additional structural properties that require new
algorithmic designs and theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08435</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08435</id><created>2018-02-23</created><updated>2018-06-25</updated><authors><author><keyname>Kalchbrenner</keyname><forenames>Nal</forenames></author><author><keyname>Elsen</keyname><forenames>Erich</forenames></author><author><keyname>Simonyan</keyname><forenames>Karen</forenames></author><author><keyname>Noury</keyname><forenames>Seb</forenames></author><author><keyname>Casagrande</keyname><forenames>Norman</forenames></author><author><keyname>Lockhart</keyname><forenames>Edward</forenames></author><author><keyname>Stimberg</keyname><forenames>Florian</forenames></author><author><keyname>Oord</keyname><forenames>Aaron van den</forenames></author><author><keyname>Dieleman</keyname><forenames>Sander</forenames></author><author><keyname>Kavukcuoglu</keyname><forenames>Koray</forenames></author></authors><title>Efficient Neural Audio Synthesis</title><categories>cs.SD cs.LG eess.AS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential models achieve state-of-the-art results in audio, visual and
textual domains with respect to both estimating the data distribution and
generating high-quality samples. Efficient sampling for this class of models
has however remained an elusive problem. With a focus on text-to-speech
synthesis, we describe a set of general techniques for reducing sampling time
while maintaining high output quality. We first describe a single-layer
recurrent neural network, the WaveRNN, with a dual softmax layer that matches
the quality of the state-of-the-art WaveNet model. The compact form of the
network makes it possible to generate 24kHz 16-bit audio 4x faster than real
time on a GPU. Second, we apply a weight pruning technique to reduce the number
of weights in the WaveRNN. We find that, for a constant number of parameters,
large sparse networks perform better than small dense networks and this
relationship holds for sparsity levels beyond 96%. The small number of weights
in a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile
CPU in real time. Finally, we propose a new generation scheme based on
subscaling that folds a long sequence into a batch of shorter sequences and
allows one to generate multiple samples at once. The Subscale WaveRNN produces
16 samples per step without loss of quality and offers an orthogonal method for
increasing sampling efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08567</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08567</id><created>2018-02-21</created><updated>2018-02-26</updated><authors><author><keyname>Bagheri</keyname><forenames>Alireza</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Rajendran</keyname><forenames>Bipin</forenames></author></authors><title>Adversarial Training for Probabilistic Spiking Neural Networks</title><categories>stat.ML cs.LG cs.NE eess.SP</categories><comments>Submitted for possible publication. arXiv admin note: text overlap
  with arXiv:1710.10704</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifiers trained using conventional empirical risk minimization or maximum
likelihood methods are known to suffer dramatic performance degradations when
tested over examples adversarially selected based on knowledge of the
classifier's decision rule. Due to the prominence of Artificial Neural Networks
(ANNs) as classifiers, their sensitivity to adversarial examples, as well as
robust training schemes, have been recently the subject of intense
investigation. In this paper, for the first time, the sensitivity of spiking
neural networks (SNNs), or third-generation neural networks, to adversarial
examples is studied. The study considers rate and time encoding, as well as
rate and first-to-spike decoding. Furthermore, a robust training mechanism is
proposed that is demonstrated to enhance the performance of SNNs under
white-box attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08591</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08591</id><created>2018-02-23</created><authors><author><keyname>Haneda</keyname><forenames>Katsuyuki</forenames></author><author><keyname>Heino</keyname><forenames>Mikko</forenames></author><author><keyname>J&#xe4;rvel&#xe4;inen</keyname><forenames>Jan</forenames></author></authors><title>Total Array Gains of Millimeter-Wave Mobile Phone Antennas Under
  Practical Conditions</title><categories>eess.SP</categories><comments>Publication in 2018 IEEE 87th Vehicular Technology Conference (VTC
  Spring 2018), Porto, Portugal, June 2018</comments><journal-ref>Publication in 2018 IEEE 87th Vehicular Technology Conference (VTC
  Spring 2018), Porto, Portugal, June 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a gain of an antenna array embedded on a mobile device
operating at a millimeter-wave radio frequency. Assuming that mobile phones at
millimeter-wave range operate with a single baseband unit and analog
beamforming like phased arrays, we define a total array gain denoting a path
gain of the phased antenna array in excess to the omni-directional path gain.
The total array gain circumvents the ambiguity of conventional array gain which
cannot be uniquely defined as there are multiple choices of a reference
single-element antenna in an array. Two types of 8-element patch antenna arrays
implemented on a mobile phone chassis, i.e., uniform linear array (ULA) and
distributed array (DA) both operating at 60 GHz, are studied. The gain
evaluated in a small-cell scenario in an airport shows that DA achieves higher
median and outage gain by up to 8 and 6 dB than ULA when different orientations
of the mobile phone are considered along with body torso and finger shadowing.
There are always postures of the mobile phone where ULA cannot see the
line-of-sight due to directionality of the patch antenna and of body and finger
shadowing, leading to outage gain of -15 dB in the worst case. The DA has much
smaller variation of the gain across different orientations of the phone, even
when the human torso shadowing and user's finger effects are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08630</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08630</id><created>2018-02-23</created><authors><author><keyname>Jahid</keyname><forenames>Abu</forenames></author><author><keyname>Shams</keyname><forenames>Abdullah Bin</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Farhad</forenames></author></authors><title>PV-Powered CoMP-Based Green Cellular Networks with a Standby Grid Supply</title><categories>eess.SP</categories><comments>14 pages, International Journal of Photoenergy, 6189468, 2017</comments><doi>10.1155/2017/6189468</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper proposes a novel framework for PV-powered cellular networks with a
standby grid supply and an essential energy management technique for achieving
envisaged green networks. The proposal considers an emerging cellular network
architecture employing two types of coordinated multipoint (CoMP) transmission
techniques for serving the subscribers. Under the proposed framework, each base
station (BS) is powered by an individual PV solar energy module having an
independent storage device. BSs are also connected to the conventional grid
supply for meeting additional energy demand. We also propose a dynamic inter-BS
solar energy sharing policy through a transmission line for further greening
the proposed network by minimizing the consumption from the grid supply. An
extensive simulation-based study in the downlink of a Long-Term Evolution (LTE)
cellular system is carried out for evaluating the energy efficiency performance
of the proposed framework. System performance is also investigated for
identifying the impact of various system parameters including storage factor,
storage capacity, solar generation capacity, transmission line loss, and
different CoMP techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08701</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08701</id><created>2018-02-23</created><updated>2019-02-10</updated><authors><author><keyname>Gewali</keyname><forenames>Utsav B.</forenames></author><author><keyname>Monteiro</keyname><forenames>Sildomar T.</forenames></author><author><keyname>Saber</keyname><forenames>Eli</forenames></author></authors><title>Machine learning based hyperspectral image analysis: A survey</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral sensors enable the study of the chemical properties of scene
materials remotely for the purpose of identification, detection, and chemical
composition analysis of objects in the environment. Hence, hyperspectral images
captured from earth observing satellites and aircraft have been increasingly
important in agriculture, environmental monitoring, urban planning, mining, and
defense. Machine learning algorithms due to their outstanding predictive power
have become a key tool for modern hyperspectral image analysis. Therefore, a
solid understanding of machine learning techniques have become essential for
remote sensing researchers and practitioners. This paper reviews and compares
recent machine learning-based hyperspectral image analysis methods published in
literature. We organize the methods by the image analysis task and by the type
of machine learning algorithm, and present a two-way mapping between the image
analysis tasks and the types of machine learning algorithms that can be applied
to them. The paper is comprehensive in coverage of both hyperspectral image
analysis tasks and machine learning algorithms. The image analysis tasks
considered are land cover classification, target detection, unmixing, and
physical parameter estimation. The machine learning algorithms covered are
Gaussian models, linear regression, logistic regression, support vector
machines, Gaussian mixture model, latent linear models, sparse linear models,
Gaussian mixture models, ensemble learning, directed graphical models,
undirected graphical models, clustering, Gaussian processes, Dirichlet
processes, and deep learning. We also discuss the open challenges in the field
of hyperspectral image analysis and explore possible future directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08805</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08805</id><created>2018-02-24</created><authors><author><keyname>Huang</keyname><forenames>Qian</forenames></author><author><keyname>Li</keyname><forenames>Yunqian</forenames></author><author><keyname>Chen</keyname><forenames>Linsen</forenames></author><author><keyname>Zhong</keyname><forenames>Xiaoming</forenames></author><author><keyname>Suo</keyname><forenames>Jinli</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author><author><keyname>Yue</keyname><forenames>Tao</forenames></author><author><keyname>Cao</keyname><forenames>Xun</forenames></author></authors><title>Multispectral Focal Stack Acquisition Using A Chromatic Aberration
  Enlarged Camera</title><categories>eess.IV</categories><comments>Proceedings of IEEE international conference on image processing
  (ICIP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capturing more information, e.g. geometry and material, using optical cameras
can greatly help the perception and understanding of complex scenes. This paper
proposes a novel method to capture the spectral and light field information
simultaneously. By using a delicately designed chromatic aberration enlarged
camera, the spectral-varying slices at different depths of the scene can be
easily captured. Afterwards, the multispectral focal stack, which is composed
of a stack of multispectral slice images focusing on different depths, can be
recovered from the spectral-varying slices by using a Local Linear
Transformation (LLT) based algorithm. The experiments verify the effectiveness
of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08910</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08910</id><created>2018-02-24</created><authors><author><keyname>Subramanian</keyname><forenames>Vaishnavi</forenames></author><author><keyname>Chidester</keyname><forenames>Benjamin</forenames></author><author><keyname>Ma</keyname><forenames>Jian</forenames></author><author><keyname>Do</keyname><forenames>Minh N.</forenames></author></authors><title>Correlating Cellular Features with Gene Expression using CCA</title><categories>eess.SP eess.IV q-bio.CB q-bio.QM stat.AP</categories><comments>To appear at IEEE International Symposium on Biomedical Imaging
  (ISBI) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand the biology of cancer, joint analysis of multiple data
modalities, including imaging and genomics, is crucial. The involved nature of
gene-microenvironment interactions necessitates the use of algorithms which
treat both data types equally. We propose the use of canonical correlation
analysis (CCA) and a sparse variant as a preliminary discovery tool for
identifying connections across modalities, specifically between gene expression
and features describing cell and nucleus shape, texture, and stain intensity in
histopathological images. Applied to 615 breast cancer samples from The Cancer
Genome Atlas, CCA revealed significant correlation of several image features
with expression of PAM50 genes, known to be linked to outcome, while Sparse CCA
revealed associations with enrichment of pathways implicated in cancer without
leveraging prior biological understanding. These findings affirm the utility of
CCA for joint phenotype-genotype analysis of cancer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08950</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08950</id><created>2018-02-24</created><authors><author><keyname>Zehni</keyname><forenames>Mona</forenames></author><author><keyname>Do</keyname><forenames>Minh N.</forenames></author><author><keyname>Zhao</keyname><forenames>Zhizhen</forenames></author></authors><title>Multi-Segment Reconstruction Using Invariant Features</title><categories>eess.SP</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-segment reconstruction (MSR) problem consists of recovering a signal
from noisy segments with unknown positions of the observation windows. One
example arises in DNA sequence assembly, which is typically solved by matching
short reads to form longer sequences. Instead of trying to locate the segment
within the sequence through pair-wise matching, we propose a new approach that
uses shift-invariant features to estimate both the underlying signal and the
distribution of the positions of the segments. Using the invariant features, we
formulate the problem as a constrained nonlinear least-squares. The
non-convexity of the problem leads to its sensitivity to the initialization.
However, with clean data, we show empirically that for longer segment lengths,
random initialization achieves exact recovery. Furthermore, we compare the
performance of our approach to the results of expectation maximization and
demonstrate that the new approach is robust to noise and computationally more
efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.08997</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.08997</id><created>2018-02-25</created><updated>2018-08-23</updated><authors><author><keyname>Xiang</keyname><forenames>Teng</forenames></author><author><keyname>Lu</keyname><forenames>Jing</forenames></author><author><keyname>Chen</keyname><forenames>Kai</forenames></author></authors><title>RLS-Based Adaptive Dereverberation Tracing Abrupt Position Change of
  Target Speaker</title><categories>eess.AS cs.SD</categories><comments>Accepted by 2018 IEEE Sensor Array and Multichannel Signal Processing
  Workshop (SAM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive algorithm based on multi-channel linear prediction is an effective
dereverberation method balancing well between the attenuation of the long-term
reverberation and the dereverberated speech quality. However, the abrupt change
of the speech source position, usually caused by the shift of the speakers,
forms an obstacle to the adaptive algorithm and makes it difficult to guarantee
both the fast convergence speed and the optimal steady-state behavior. In this
paper, the RLS-based adaptive multi-channel linear prediction method is
investigated and a time-varying forgetting factor based on the relative
weighted change of the adaptive filter coefficients is proposed to effectively
tracing the abrupt change of the target speaker position. The advantages of the
proposed scheme are demonstrated in the simulations and experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09005</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09005</id><created>2018-02-25</created><authors><author><keyname>Wang</keyname><forenames>Zelin</forenames></author><author><keyname>Lu</keyname><forenames>Jing</forenames></author><author><keyname>chen</keyname><forenames>Kai</forenames></author></authors><title>Frequency domain TRINICON-based blind source separation method with
  multi-source activity detection for sparsely mixed signals</title><categories>eess.AS cs.SD</categories><comments>This article has been submitted to 2018 IEEE Sensor Array and
  Multichannel Signal Processing Workshop (SAM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The TRINICON ('Triple-N ICA for convolutive mixtures') framework is an
effective blind signal separation (BSS) method for separating sound sources
from convolutive mixtures. It makes full use of the non-whiteness,
non-stationarity and non-Gaussianity properties of the source signals and can
be implemented either in time domain or in frequency domain, avoiding the
notorious internal permutation problem. It usually has best performance when
the sources are continuously mixed. In this paper, the offline dual-channel
frequency domain TRINICON implementation for sparsely mixed signals is
investigated, and a multi-source activity detection is proposed to locate the
active period of each source, based on which the filter updating strategy is
regularized to improve the separation performance. The objective metric
provided by the BSSEVAL toolkit is utilized to evaluate the performance of the
proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09026</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09026</id><created>2018-02-25</created><authors><author><keyname>Kang</keyname><forenames>Jian</forenames></author><author><keyname>K&#xf6;rner</keyname><forenames>Marco</forenames></author><author><keyname>Wang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Taubenb&#xf6;ck</keyname><forenames>Hannes</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Building Instance Classification Using Street View Images</title><categories>cs.CV eess.IV</categories><doi>10.1016/j.isprsjprs.2018.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Land-use classification based on spaceborne or aerial remote sensing images
has been extensively studied over the past decades. Such classification is
usually a patch-wise or pixel-wise labeling over the whole image. But for many
applications, such as urban population density mapping or urban utility
planning, a classification map based on individual buildings is much more
informative. However, such semantic classification still poses some fundamental
challenges, for example, how to retrieve fine boundaries of individual
buildings. In this paper, we proposed a general framework for classifying the
functionality of individual buildings. The proposed method is based on
Convolutional Neural Networks (CNNs) which classify facade structures from
street view images, such as Google StreetView, in addition to remote sensing
images which usually only show roof structures. Geographic information was
utilized to mask out individual buildings, and to associate the corresponding
street view images. We created a benchmark dataset which was used for training
and evaluating CNNs. In addition, the method was applied to generate building
classification maps on both region and city scales of several cities in Canada
and the US. Keywords: CNN, Building instance classification, Street view
images, OpenStreetMap
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09036</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09036</id><created>2018-02-25</created><authors><author><keyname>Qiu</keyname><forenames>Chunping</forenames></author><author><keyname>Schmitt</keyname><forenames>Michael</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Towards Automatic SAR-Optical Stereogrammetry over Urban Areas using
  Very High Resolution Imagery</title><categories>eess.IV</categories><doi>10.1016/j.isprsjprs.2017.12.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the potential and challenges regarding SAR-optical
stereogrammetry for urban areas, using very-high-resolution (VHR) remote
sensing imagery. Since we do this mainly from a geometrical point of view, we
first analyze the height reconstruction accuracy to be expected for different
stereogrammetric configurations. Then, we propose a strategy for simultaneous
tie point matching and 3D reconstruction, which exploits an epipolar-like
search window constraint. To drive the matching and ensure some robustness, we
combine different established handcrafted similarity measures. For the
experiments, we use real test data acquired by the Worldview-2, TerraSAR-X and
MEMPHIS sensors. Our results show that SAR-optical stereogrammetry using VHR
imagery is generally feasible with 3D positioning accuracies in the
meter-domain, although the matching of these strongly hetereogeneous
multi-sensor data remains very challenging. Keywords: Synthetic Aperture Radar
(SAR), optical images, remote sensing, data fusion, stereogrammetry
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09120</identifier>
 <datestamp>2019-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09120</id><created>2018-02-25</created><updated>2019-04-17</updated><authors><author><keyname>Giacoumidis</keyname><forenames>Elias</forenames></author><author><keyname>Wei</keyname><forenames>Jinlong</forenames></author><author><keyname>Aldaya</keyname><forenames>Ivan</forenames></author><author><keyname>Barry</keyname><forenames>Liam P.</forenames></author></authors><title>Exceeding the Nonlinear Shannon-Limit in Coherent Optical Communications
  by MIMO Machine Learning</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nonlinear Shannon capacity limit has been identified as the fundamental
barrier to the maximum rate of transmitted information in optical
communications. In long-haul high-bandwidth optical networks, this limit is
mainly attributed to deterministic Kerr-induced fiber nonlinearities and from
the interaction of amplified spontaneous emission noise from cascaded optical
amplifiers with fiber nonlinearity: the stochastic parametric noise
amplification. Unlike earlier impractical approaches that compensate solely
deterministic nonlinearities, here we demonstrate a novel electronic-based deep
neural network with multiple-inputs and outputs (MIMO) that tackles the
interplay of deterministic and stochastic nonlinearity manifestation in
coherent optical signals. Our demonstration shows that MIMO deep learning can
compensate nonlinear inter-carrier crosstalk effects even in the presence of
frequency stochastic variations, which has hitherto been considered impossible.
Our solution significantly outperforms conventional machine learning and
gold-standard nonlinear equalizers without sacrificing computational
complexity, leading to record-breaking transmission performance for up to 40
Gbit/sec high-spectral-efficient optical signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09221</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09221</id><created>2018-02-26</created><authors><author><keyname>Laufer-Goldshtein</keyname><forenames>Bracha</forenames></author><author><keyname>Talmon</keyname><forenames>Ronen</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author></authors><title>Data-Driven Source Separation Based on Simplex Analysis</title><categories>eess.AS cs.SD eess.SP</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind source separation (BSS) is addressed, using a novel data-driven
approach, based on a well-established probabilistic model. The proposed method
is specifically designed for separation of multichannel audio mixtures. The
algorithm relies on spectral decomposition of the correlation matrix between
different time frames. The probabilistic model implies that the column space of
the correlation matrix is spanned by the probabilities of the various speakers
across time. The number of speakers is recovered by the eigenvalue decay, and
the eigenvectors form a simplex of the speakers' probabilities. Time frames
dominated by each of the speakers are identified exploiting convex geometry
tools on the recovered simplex. The mixing acoustic channels are estimated
utilizing the identified sets of frames, and a linear umixing is performed to
extract the individual speakers. The derived simplexes are visually
demonstrated for mixtures of 2, 3 and 4 speakers. We also conduct a
comprehensive experimental study, showing high separation capabilities in
various reverberation conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09310</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09310</id><created>2018-02-26</created><authors><author><keyname>Paridar</keyname><forenames>Roya</forenames></author><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Three-Dimensional Photoacoustic Tomography using Delay Multiply and Sum
  Beamforming Algorithm</title><categories>eess.SP</categories><comments>This paper is presented in Photons Plus Ultrasound: Imaging and
  Sensing 2018 conference and published by International Society for Optics and
  Photonics</comments><journal-ref>Proceedings Volume 10494, Photons Plus Ultrasound: Imaging and
  Sensing 2018; 1049440 (2018);</journal-ref><doi>10.1117/12.2291546</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic imaging (PAI), is a promising medical imaging technique that
provides the high contrast of the optical imaging and the resolution of
ultrasound (US) imaging. Among all the methods, Three-dimensional (3D) PAI
provides a high resolution and accuracy. One of the most common algorithms for
3D PA image reconstruction is delay-and-sum (DAS). However, the quality of the
reconstructed image obtained from this algorithm is not satisfying, having high
level of sidelobes and a wide mainlobe. In this paper, delay-multiply-and-sum
(DMAS) algorithm is suggested to overcome these limitations in 3D PAI. It is
shown that DMAS algorithm is an appropriate reconstruction technique for 3D PAI
and the reconstructed images using this algorithm are improved in the terms of
the width of mainlobe and sidelobes, compared to DAS. Also, the quantitative
results show that DMAS improves signal-to-noise ratio (SNR) and
full-width-half-maximum (FWHM) for about 25 dB and 0.2 mm, respectively,
compared to DAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09313</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09313</id><created>2018-02-26</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Model-Based Photoacoustic Image Reconstruction using Compressed Sensing
  and Smoothed L0 Norm</title><categories>eess.SP</categories><comments>This paper is presented in Photons Plus Ultrasound: Imaging and
  Sensing 2018 conference and published by International Society for Optics and
  Photonics</comments><journal-ref>Proceedings Volume 10494, Photons Plus Ultrasound: Imaging and
  Sensing 2018; 104943Z (2018);</journal-ref><doi>10.1117/12.2291535</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic imaging (PAI) is a novel medical imaging modality that uses the
advantages of the spatial resolution of ultrasound imaging and the high
contrast of pure optical imaging. Analytical algorithms are usually employed to
reconstruct the photoacoustic (PA) images as a result of their simple
implementation. However, they provide a low accurate image. Model-based (MB)
algorithms are used to improve the image quality and accuracy while a large
number of transducers and data acquisition are needed. In this paper, we have
combined the theory of compressed sensing (CS) with MB algorithms to reduce the
number of transducer. Smoothed version of L0-norm (SL0) was proposed as the
reconstruction method, and it was compared with simple iterative reconstruction
(IR) and basis pursuit. The results show that S$\ell_0$ provides a higher image
quality in comparison with other methods while a low number of transducers
were. Quantitative comparison demonstrates that, at the same condition, the SL0
leads to a peak-signal-to-noise ratio for about two times of the basis pursuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09316</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09316</id><created>2018-02-26</created><authors><author><keyname>Heidari</keyname><forenames>Mehdi Haji</forenames></author><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Manwar</keyname><forenames>Rayyan</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author></authors><title>Effects of Important Parameters Variations on Computing Eigenspace-Based
  Minimum Variance Weights for Ultrasound Tissue Harmonic Imaging</title><categories>eess.SP</categories><comments>This paper is presented in Photons Plus Ultrasound: Imaging and
  Sensing 2018 conference and published by International Society for Optics and
  Photonics</comments><journal-ref>Proceedings Volume 10494, Photons Plus Ultrasound: Imaging and
  Sensing 2018; 104946R (2018);</journal-ref><doi>10.1117/12.2291549</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the minimum variance (MV) beamforming has been widely
studied due to its high resolution and contrast in B-mode Ultrasound imaging
(USI). However, the performance of the MV beamformer is degraded at the
presence of noise, as a result of the inaccurate covariance matrix estimation
which leads to a low quality image. Second harmonic imaging (SHI) provides many
advantages over the conventional pulse-echo USI, such as enhanced axial and
lateral resolutions. However, the low signal-to-noise ratio (SNR) is a major
problem in SHI. In this paper, Eigenspace-based minimum variance (EIBMV)
beamformer has been employed for second harmonic USI. The Tissue Harmonic
Imaging (THI) is achieved by Pulse Inversion (PI) technique. Using the EIBMV
weights, instead of the MV ones, would lead to reduced sidelobes and improved
contrast, without compromising the high resolution of the MV beamformer (even
at the presence of a strong noise). In addition, we have investigated the
effects of variations of the important parameters in computing EIBMV weights,
i.e., K, L, and {\delta}, on the resolution and contrast obtained in SHI. The
results are evaluated using numerical data (using point target and cyst
phantoms), and the proper parameters of EIBMV are indicated for THI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09319</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09319</id><created>2018-02-26</created><authors><author><keyname>Valizadeh</keyname><forenames>Sina</forenames></author><author><keyname>Makkiabadi</keyname><forenames>Bahador</forenames></author><author><keyname>Mirbagheri</keyname><forenames>Alireza</forenames></author><author><keyname>Soozande</keyname><forenames>Mehdi</forenames></author><author><keyname>Manwar</keyname><forenames>Rayyan</forenames></author><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author></authors><title>An Image Registration Based Technique for Noninvasive Vascular
  Elastography</title><categories>eess.SP eess.IV</categories><comments>This paper is presented in Photons Plus Ultrasound: Imaging and
  Sensing 2018 conference and published by International Society for Optics and
  Photonics</comments><journal-ref>Proceedings Volume 10494, Photons Plus Ultrasound: Imaging and
  Sensing 2018; 104946S (2018);</journal-ref><doi>10.1117/12.2291550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-invasive vascular elastography is an emerging technique in vascular
tissue imaging. During the past decades, several techniques have been suggested
to estimate the tissue elasticity by measuring the displacement of the Carotid
vessel wall. Cross correlation-based methods are the most prevalent approaches
to measure the strain exerted in the wall vessel by the blood pressure. In the
case of a low pressure, the displacement is too small to be apparent in
ultrasound imaging, especially in the regions far from the center of the
vessel, causing a high error of displacement measurement. On the other hand,
increasing the compression leads to a relatively large displacement in the
regions near the center, which reduces the performance of the cross
correlation-based methods. In this study, a non-rigid image registration-based
technique is proposed to measure the tissue displacement for a relatively large
compression. The results show that the error of the displacement measurement
obtained by the proposed method is reduced by increasing the amount of
compression while the error of the cross correlationbased method rises for a
relatively large compression. We also used the synthetic aperture imaging
method, benefiting the directivity diagram, to improve the image quality,
especially in the superficial regions. The best relative root-mean-square error
(RMSE) of the proposed method and the adaptive cross correlation method were
4.5% and 6%, respectively. Consequently, the proposed algorithm outperforms the
conventional method and reduces the relative RMSE by 25%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09328</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09328</id><created>2018-02-20</created><authors><author><keyname>Luo</keyname><forenames>Yu</forenames></author><author><keyname>Pu</keyname><forenames>Lina</forenames></author><author><keyname>Zhao</keyname><forenames>Yanxiao</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Yang</keyname><forenames>Qing</forenames></author></authors><title>Revisiting Transmission Scheduling in RF Energy Harvesting Wireless
  Communications</title><categories>eess.SP</categories><journal-ref>A Nonlinear Recursive Model based Optimal Transmission Scheduling
  in RF Energy Harvesting Wireless Communications, IEEE Transactions on
  Wireless Communications, 2020</journal-ref><doi>10.1109/TWC.2020.2973967</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transmission scheduling is a critical problem in radio frequency (RF)
energy harvesting communications. Existing transmission strategies in an
RF-based energy harvesting system is mainly based on a classic model, in which
the data transmission is scheduled in a fixed feasible energy tunnel. In this
paper, we re-examine the classic energy harvesting model and show through the
theoretical analysis and experimental results that the bounds of feasible
energy tunnel are dynamic, which can be affected by the transmission scheduling
due to the impact of residual energy on the harvested one. To describe a
practical energy harvesting process more accurately, a new model is proposed by
adding a feedback loop that reflects the interplay between the energy harvest
and the data transmission. Furthermore, to improve network performance, we
revisit the design of an optimal transmission scheduling strategy based on the
new model. To handle the challenge of the endless feedback loop in the new
model, a recursive algorithm is developed. The simulation results reveal that
the new transmission scheduling strategy can balance the efficiency of energy
reception and energy utilization regardless of the length of energy packets,
achieving improved throughput performance for wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09332</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09332</id><created>2018-02-04</created><authors><author><keyname>Caesarendra</keyname><forenames>Wahyu</forenames></author><author><keyname>Pratama</keyname><forenames>Mahardhika</forenames></author><author><keyname>Tjahjowidodo</keyname><forenames>Tegoeh</forenames></author><author><keyname>Tieud</keyname><forenames>Kiet</forenames></author><author><keyname>Kosasih</keyname><forenames>Buyung</forenames></author></authors><title>Parsimonious Network based on Fuzzy Inference System (PANFIS) for Time
  Series Feature Prediction of Low Speed Slew Bearing Prognosis</title><categories>eess.SP cs.NE</categories><comments>this paper is currently under review in Journal of Intelligence
  Manufacturing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the utilization of rotating parts, e.g. bearings and gears,
has been continuously supporting the manufacturing line to produce consistent
output quality. Due to their critical role, the breakdown of these components
might significantly impact the production rate. A proper condition based
monitoring (CBM) is among a few ways to maintain and monitor the rotating
systems. Prognosis, as one of the major tasks in CBM that predicts and
estimates the remaining useful life of the machine, has attracted significant
interest in decades. This paper presents a literature review on prognosis
approaches from published papers in the last decade. The prognostic approaches
are described comprehensively to provide a better idea on how to select an
appropriate prognosis method for specific needs. An advanced predictive
analytics, namely Parsimonious Network Based on Fuzzy Inference System
(PANFIS), was proposed and tested into the low speed slew bearing data. PANFIS
differs itself from conventional prognostic approaches in which it supports for
online lifelong prognostics without the requirement of retraining or
reconfiguration phase. The method is applied to normal-to-failure bearing
vibration data collected for 139 days and to predict the time-domain features
of vibration slew bearing signals. The performance of the proposed method is
compared to some established methods such as ANFIS, eTS, and Simp_eTS. From the
results, it is suggested that PANFIS offers outstanding performance compared to
those of other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09342</identifier>
 <datestamp>2019-04-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09342</id><created>2018-02-13</created><updated>2019-04-26</updated><authors><author><keyname>Mishonov</keyname><forenames>Todor M.</forenames></author><author><keyname>Marinov</keyname><forenames>Vladimir G.</forenames></author><author><keyname>Danchev</keyname><forenames>Victor I.</forenames></author><author><keyname>Petkov</keyname><forenames>Emil G.</forenames></author><author><keyname>Petkov</keyname><forenames>Aleksander P.</forenames></author><author><keyname>Dimitrova</keyname><forenames>Iglika M.</forenames></author><author><keyname>Gourev</keyname><forenames>Vassil N.</forenames></author><author><keyname>Serafimov</keyname><forenames>Nikola S.</forenames></author><author><keyname>Stefanov</keyname><forenames>Aleksander A.</forenames></author><author><keyname>Varonov</keyname><forenames>Albert M.</forenames></author></authors><title>Probability distribution function of crossover frequency of operational
  amplifiers in the framework of Manhattan equation for the operational
  amplifier</title><categories>eess.SP</categories><comments>5 pages, 3 figures, probability distribution function of crossover
  frequency measurements of 200 ADA4898-2 low noise operational amplifiers,
  dialogue with AD engineer taken into account</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the first time in electronics we represent experimental data for
probability distribution function of the crossover frequency of operational
amplifiers. We use 400 (200 double) ADA4898-2 low noise amplifiers. We present
an innovative method for determination of crossover frequency which requires an
USB lock-in with automatic frequency sweep. Our method is based on a
differential equation relating the voltage at the output of an operational
amplifier $U_0$ and the difference between the input voltages ($U_+$ and $U_-$)
which has been derived. The crossover frequency $f_0$ is a parameter in this
operational amplifier master equation. The formulae derived as a consequence of
this equation find applications in thousands of specifications for electronic
devices but as far as we know, the time dependent equation has never been
published. Actually, the master equation of operational amplifiers can be found
in the seminal article by Ragazzini, Randall and Russell [J. R. Ragazzini, R.
H. Randall and F. A. Russell, Proc. of the I.R.E. \textbf{35}(5), 444-452
(1947); Eq. (6), Eq. (7), Eq. (32)], but for more than 70 years it was not
analyzed and cited in journals and specifications of operational amplifiers.
During World War II, John Ragazzini was involved in the Manhattan Project
[&quot;John Ragazzini, 76, Educator and Engineer&quot;, The New York Times, November 24,
1988] working on significant projects in the field of electronics and therefore
it would be deservedly to say that the master equation we propose is &quot;Manhattan
equation&quot; for operational amplifiers. The exact knowledge of the crossover
frequency $f_0$ is necessary when we need to precisely determine the non-ideal
effects of operational amplifiers. For instance, in cases when there is a need
of an exact calculation of the pass bandwidth of amplifiers with active
filters, the Manhattan equation is indispensable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09346</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09346</id><created>2018-02-19</created><authors><author><keyname>G.</keyname><forenames>Subhash Joshi T.</forenames></author><author><keyname>John</keyname><forenames>Vinod</forenames></author></authors><title>Microwave Tube Fault-Current Model for Design of Crowbar Protection</title><categories>eess.SP physics.ins-det</categories><comments>Submitted to IEEE Trans. on Industry Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications that use high energy plasma are realized using Microwave
tubes (MWT) that operate at peak power in the range of hundreds of MW and
frequency in GHz. One failure mode of the MWT is due to the excess energy in
the tube during internal arcing events. Crowbar is used to protect the MWT by
diverting the energy during fault. To compute the energy released into the MWT,
the dc fault current model and the MWT model are essential. An equivalent fuse
wire model is utilized for the MWT for the crowbar applications. The paper
proposes a model for the dc fault current, the analysis for which is based on
Joules Integral energy concept. The model provides flexibility to choose a
range of practically observed reactance to resistance ratio (X/R) of
transformer and also allows the use of a range of dc current limiting
resistances that are utilized in the High Voltage (HV) power supply circuits in
Microwave applications. The non-linearity of the system due to the multipulse
diode rectifier is also considered by introducing a correction factor in the
model. This paper shows that the same correction factor can be applied for both
dc side parallel and series connected rectifier circuits. Both dc fault current
and MWT models are verified experimentally. Using the model a 10kV , 1kA
crowbar is built to limit the energy in MWT below 10J.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09354</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09354</id><created>2018-02-22</created><authors><author><keyname>Sher</keyname><forenames>Yoni</forenames></author><author><keyname>Cohen</keyname><forenames>Lior</forenames></author><author><keyname>Istrati</keyname><forenames>Daniel</forenames></author><author><keyname>Eisenberg</keyname><forenames>Hagai S.</forenames></author></authors><title>Low Intensity LiDAR using Compressed Sensing and a Photon Number
  Resolving Detector</title><categories>eess.SP physics.ins-det</categories><comments>7 pages, 14 figures, SPIE Photonics west 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LiDAR (laser based radar) systems are a major part of many new real-world
interactive systems, one of the most notable being autonomous cars. The current
market LiDAR systems are limited by detector sensitivity: when output power is
at eye-safe levels, the range is limited. Long range operation also slows image
acquisition as flight-time increases. We present an approach that combines a
high sensitivity photon number resolving diode with machine learning and a
micro-mechanical digital mirror device to achieve safe and fast long range 3D
scanning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09359</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09359</id><created>2018-02-22</created><authors><author><keyname>Psychoula</keyname><forenames>Ismini</forenames></author><author><keyname>Merdivan</keyname><forenames>Erinc</forenames></author><author><keyname>Singh</keyname><forenames>Deepika</forenames></author><author><keyname>Chen</keyname><forenames>Liming</forenames></author><author><keyname>Chen</keyname><forenames>Feng</forenames></author><author><keyname>Hanke</keyname><forenames>Sten</forenames></author><author><keyname>Kropf</keyname><forenames>Johannes</forenames></author><author><keyname>Holzinger</keyname><forenames>Andreas</forenames></author><author><keyname>Geist</keyname><forenames>Matthieu</forenames></author></authors><title>A Deep Learning Approach for Privacy Preservation in Assisted Living</title><categories>eess.SP cs.LG</categories><comments>6 pages, 6 figures, To be published in the IEEE International
  Conference on Pervasive Computing and Communications (SmarterAAL) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the era of Internet of Things (IoT) technologies the potential for privacy
invasion is becoming a major concern especially in regards to healthcare data
and Ambient Assisted Living (AAL) environments. Systems that offer AAL
technologies make extensive use of personal data in order to provide services
that are context-aware and personalized. This makes privacy preservation a very
important issue especially since the users are not always aware of the privacy
risks they could face. A lot of progress has been made in the deep learning
field, however, there has been lack of research on privacy preservation of
sensitive personal data with the use of deep learning. In this paper we focus
on a Long Short Term Memory (LSTM) Encoder-Decoder, which is a principal
component of deep learning, and propose a new encoding technique that allows
the creation of different AAL data views, depending on the access level of the
end user and the information they require access to. The efficiency and
effectiveness of the proposed method are demonstrated with experiments on a
simulated AAL dataset. Qualitatively, we show that the proposed model learns
privacy operations such as disclosure, deletion and generalization and can
perform encoding and decoding of the data with almost perfect recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09371</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09371</id><created>2018-02-23</created><authors><author><keyname>Dumas</keyname><forenames>Thierry</forenames><affiliation>Sirocco</affiliation></author><author><keyname>Roumy</keyname><forenames>Aline</forenames><affiliation>Sirocco</affiliation></author><author><keyname>Guillemot</keyname><forenames>Christine</forenames><affiliation>Sirocco</affiliation></author></authors><title>Autoencoder based image compression: can the learning be quantization
  independent?</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><comments>International Conference on Acoustics, Speech and Signal Processing
  ICASSP, Apr 2018, Calgary, Canada. 2018</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the problem of learning transforms for image compression
via autoencoders. Usually, the rate-distortion performances of image
compression are tuned by varying the quantization step size. In the case of
autoen-coders, this in principle would require learning one transform per
rate-distortion point at a given quantization step size. Here, we show that
comparable performances can be obtained with a unique learned transform. The
different rate-distortion points are then reached by varying the quantization
step size at test time. This approach saves a lot of training time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09431</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09431</id><created>2018-02-26</created><authors><author><keyname>Zhao</keyname><forenames>Can</forenames></author><author><keyname>Carass</keyname><forenames>Aaron</forenames></author><author><keyname>Dewey</keyname><forenames>Blake E.</forenames></author><author><keyname>Prince</keyname><forenames>Jerry L.</forenames></author></authors><title>Self Super-Resolution for Magnetic Resonance Images using Deep Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted by IEEE International Symposium on Biomedical Imaging (ISBI)
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High resolution magnetic resonance~(MR) imaging~(MRI) is desirable in many
clinical applications, however, there is a trade-off between resolution, speed
of acquisition, and noise. It is common for MR images to have worse
through-plane resolution~(slice thickness) than in-plane resolution. In these
MRI images, high frequency information in the through-plane direction is not
acquired, and cannot be resolved through interpolation. To address this issue,
super-resolution methods have been developed to enhance spatial resolution. As
an ill-posed problem, state-of-the-art super-resolution methods rely on the
presence of external/training atlases to learn the transform from low
resolution~(LR) images to high resolution~(HR) images. For several reasons,
such HR atlas images are often not available for MRI sequences. This paper
presents a self super-resolution~(SSR) algorithm, which does not use any
external atlas images, yet can still resolve HR images only reliant on the
acquired LR image. We use a blurred version of the input image to create
training data for a state-of-the-art super-resolution deep network. The trained
network is applied to the original input image to estimate the HR image. Our
SSR result shows a significant improvement on through-plane resolution compared
to competing SSR methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09448</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09448</id><created>2018-02-20</created><authors><author><keyname>Luo</keyname><forenames>Yu</forenames></author><author><keyname>Pu</keyname><forenames>Lina</forenames></author><author><keyname>Zhao</keyname><forenames>Yanxiao</forenames></author><author><keyname>Wang</keyname><forenames>Guodong</forenames></author><author><keyname>Song</keyname><forenames>Min</forenames></author></authors><title>DTER: Schedule Optimal RF Energy Request and Harvest for Internet of
  Things</title><categories>eess.SP</categories><doi>10.1109/JIOT.2018.2813429</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new energy harvesting strategy that uses a dedicated energy
source (ES) to optimally replenish energy for radio frequency (RF) energy
harvesting powered Internet of Things. Specifically, we develop a two-step dual
tunnel energy requesting (DTER) strategy that minimizes the energy consumption
on both the energy harvesting device and the ES. Besides the causality and
capacity constraints that are investigated in the existing approaches, DTER
also takes into account the overhead issue and the nonlinear charge
characteristics of an energy storage component to make the proposed strategy
practical. Both offline and online scenarios are considered in the second step
of DTER. To solve the nonlinear optimization problem of the offline scenario,
we convert the design of offline optimal energy requesting problem into a
classic shortest path problem and thus a global optimal solution can be
obtained through dynamic programming (DP) algorithms. The online suboptimal
transmission strategy is developed as well. Simulation study verifies that the
online strategy can achieve almost the same energy efficiency as the global
optimal solution in the long term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09580</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09580</id><created>2018-02-26</created><authors><author><keyname>Murray</keyname><forenames>Georgia</forenames></author><author><keyname>Kipnis</keyname><forenames>Alon</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>Lossy Compression of Decimated Gaussian Random Walks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating a Gaussian random walk from a lossy
compression of its decimated version. Hence, the encoder operates on the
decimated random walk, and the decoder estimates the original random walk from
its encoded version under a mean squared error (MSE) criterion. It is
well-known that the minimal distortion in this problem is attained by an
estimate-and-compress (EC) source coding strategy, in which the encoder first
estimates the original random walk and then compresses this estimate subject to
the bit constraint. In this work, we derive a closed-form expression for this
minimal distortion as a function of the bitrate and the decimation factor.
Next, we consider a compress-and-estimate (CE) source coding scheme, in which
the encoder first compresses the decimated sequence subject to an MSE criterion
(with respect to the decimated sequence), and the original random walk is
estimated only at the decoder. We evaluate the distortion under CE in a closed
form and show that there exists a nonzero gap between the distortion under the
two schemes. This difference in performance illustrates the importance of
having the decimation factor at the encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09588</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09588</id><created>2018-02-26</created><updated>2018-08-03</updated><authors><author><keyname>Pfister</keyname><forenames>Luke</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>Bounding Multivariate Trigonometric Polynomials with Applications to
  Filter Bank Design</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extremal values of multivariate trigonometric polynomials are of interest
in fields ranging from control theory to filter design, but finding the
extremal values of such a polynomial is generally NP-Hard. In this paper, we
develop simple and efficiently computable estimates of the extremal values of a
multivariate trigonometric polynomial directly from its samples. We provide an
upper bound on the modulus of a complex trigonometric polynomial, and develop
upper and lower bounds for real trigonometric polynomials. For a univarite
polynomial, these bounds are tighter than existing bounds, and the extension to
multivariate polynomials is new. As an application, the lower bound provides a
sufficient condition to certify global positivity of a real trigonometric
polynomial. We use this condition to motivate a new algorithm for
multi-dimensional, multirate, perfect reconstruction filter bank design. We
demonstrate our algorithm by designing a 2D perfect reconstruction filter bank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09600</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09600</id><created>2018-02-26</created><authors><author><keyname>Meng</keyname><forenames>Xiangyu</forenames></author><author><keyname>Cassandras</keyname><forenames>Christos G.</forenames></author></authors><title>Optimal Control of Autonomous Vehicles Approaching A Traffic Light</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper devotes to the development of an optimal acceleration/speed
profile for autonomous vehicles approaching a traffic light. The design
objective is to achieve both short travel time and low energy consumption as
well as avoid idling at a red light. This is achieved by taking full advantage
of the traffic light information based on vehicle-to-infrastructure
communication. The problem is modeled as a mixed integer programming, which is
equivalently transformed into optimal control problems by relaxing the integer
constraint. Then the direct adjoining approach is used to solve both free and
fixed terminal time optimal control problems subject to state constraints. By
an elaborate analysis, we are able to produce a real-time online analytical
solution, distinguishing our method from most existing approaches based on
numerical calculations. Extensive simulations are executed to compare the
performance of autonomous vehicles under the proposed speed profile and human
driving vehicles. The results show quantitatively the advantages of the
proposed algorithm in terms of energy consumption and travel time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09609</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09609</id><created>2018-02-20</created><authors><author><keyname>Zhou</keyname><forenames>Fuhui</forenames></author><author><keyname>Chu</keyname><forenames>Zheng</forenames></author><author><keyname>Sun</keyname><forenames>Haijian</forenames></author><author><keyname>Hu</keyname><forenames>Rose Qingyang</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Artificial Noise Aided Secure Cognitive Beamforming for Cooperative
  MISO-NOMA Using SWIPT</title><categories>eess.SP cs.GT</categories><comments>This paper has been accepted by IEEE Journal on Selected Areas in
  Communications. arXiv admin note: text overlap with arXiv:1802.03908</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cognitive radio (CR) and non-orthogonal multiple access (NOMA) have been
deemed two promising technologies due to their potential to achieve high
spectral efficiency and massive connectivity. This paper studies a
multiple-input single-output NOMA CR network relying on simultaneous wireless
information and power transfer (SWIPT) conceived for supporting a massive
population of power limited battery-driven devices. In contrast to most of the
existing works, which use an ideally linear energy harvesting model, this study
applies a more practical non-linear energy harvesting model. In order to
improve the security of the primary network, an artificial-noise-aided
cooperative jamming scheme is proposed. The artificial-noise-aided beamforming
design problems are investigated subject to the practical secrecy rate and
energy harvesting constraints. Specifically, the transmission power
minimization problems are formulated under both perfect channel state
information (CSI) and the bounded CSI error model. The problems formulated are
non-convex, hence they are challenging to solve. A pair of algorithms either
using semidefinite relaxation (SDR) or a cost function are proposed for solving
these problems. Our simulation results show that the proposed cooperative
jamming scheme succeeds in establishing secure communications and NOMA is
capable of outperforming the conventional orthogonal multiple access in terms
of its power efficiency. Finally, we demonstrate that the cost function
algorithm outperforms the SDR-based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09695</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09695</id><created>2018-02-26</created><authors><author><keyname>Xie</keyname><forenames>Yuxuan</forenames></author><author><keyname>Zhang</keyname><forenames>Xuefei</forenames></author><author><keyname>Cui</keyname><forenames>Qimei</forenames></author><author><keyname>Lu</keyname><forenames>Yanyan</forenames></author></authors><title>User Association for Offloading in Heterogeneous Network Based on Matern
  Cluster Process</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future mobile networks are converging toward heterogeneous multi-tier
networks, where various classes of base stations (BS) are deployed based on
user demand. So it is quite necessary to utilize the BSs resources rationally
when BSs are sufficient. In this paper, we develop a more realistic model that
fully considering the inter-tier dependence and the dependence between users
and BSs, where the macro base stations (MBSs) are distributed according to a
homogeneous Poisson point process (PPP) and the small base stations (SBSs)
follows a Matern cluster process (MCP) whose parent points are located in the
positions of the MBSs in order to offload the users from the over-loaded MBSs.
We also assume the users are just randomly located in the circles centered at
the MBSs. Under this model, we derive the association probability and the
average ergodic rate by stochastic geometry. An interesting result that the
density of MBS and the radius of the clusters jointly affect the association
probabilities in a joint form is obtained. We also observe that using the
clustered SBSs results in aggressive offloading compared with previous cellular
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09697</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09697</id><created>2018-02-26</created><authors><author><keyname>Dong</keyname><forenames>Mingwen</forenames></author></authors><title>Convolutional Neural Network Achieves Human-level Accuracy in Music
  Genre Classification</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music genre classification is one example of content-based analysis of music
signals. Traditionally, human-engineered features were used to automatize this
task and 61% accuracy has been achieved in the 10-genre classification.
However, it's still below the 70% accuracy that humans could achieve in the
same task. Here, we propose a new method that combines knowledge of human
perception study in music genre classification and the neurophysiology of the
auditory system. The method works by training a simple convolutional neural
network (CNN) to classify a short segment of the music signal. Then, the genre
of a music is determined by splitting it into short segments and then combining
CNN's predictions from all short segments. After training, this method achieves
human-level (70%) accuracy and the filters learned in the CNN resemble the
spectrotemporal receptive field (STRF) in the auditory system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09705</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09705</id><created>2018-02-26</created><updated>2018-08-01</updated><authors><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Li</keyname><forenames>Shining</forenames></author><author><keyname>Yang</keyname><forenames>Zhe</forenames></author><author><keyname>Gu</keyname><forenames>Tao</forenames></author><author><keyname>Qian</keyname><forenames>Cheng</forenames></author></authors><title>Enabling Multiple Access for Non-Line-of-Sight Light-to-Camera
  Communications</title><categories>cs.ET cs.NI eess.SP</categories><comments>12 pages, 13 figures</comments><doi>10.1109/TMC.2018.2880442</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light-to-Camera Communications (LCC) have emerged as a new wireless
communication technology with great potential to benefit a broad range of
applications. However, the existing LCC systems either require cameras directly
facing to the lights or can only communicate over a single link, resulting in
low throughputs and being fragile to ambient illuminant interference. We
present HYCACO, a novel LCC system, which enables multiple light emitting
diodes (LEDs) with an unaltered camera to communicate via the non-line-of-sight
(NLoS) links. Different from other NLoS LCC systems, the proposed scheme is
resilient to the complex indoor luminous environment. HYCACO can decode the
messages by exploring the mixed reflected optical signals transmitted from
multiple LEDs. By further exploiting the rolling shutter mechanism, we present
the optimal optical frequencies and camera exposure duration selection strategy
to achieve the best performance. We built a hardware prototype to demonstrate
the efficiency of the proposed scheme under different application scenarios.
The experimental results show that the system throughput reaches 4.5 kbps on
iPhone 6s with three transmitters. With the robustness, improved system
throughput and ease of use, HYCACO has great potentials to be used in a wide
range of applications such as advertising, tagging objects, and device
certifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09736</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09736</id><created>2018-02-27</created><updated>2019-02-04</updated><authors><author><keyname>Elbir</keyname><forenames>Ahmet M.</forenames></author><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Cognitive Radar Antenna Selection via Deep Learning</title><categories>eess.SP stat.ML</categories><comments>10 pages, 11 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direction of arrival (DoA) estimation of targets improves with the number of
elements employed by a phased array radar antenna. Since larger arrays have
high associated cost, area and computational load, there is recent interest in
thinning the antenna arrays without loss of far-field DoA accuracy. In this
context, a cognitive radar may deploy a full array and then select an optimal
subarray to transmit and receive the signals in response to changes in the
target environment. Prior works have used optimization and greedy search
methods to pick the best subarrays cognitively. In this paper, we leverage deep
learning to address the antenna selection problem. Specifically, we construct a
convolutional neural network (CNN) as a multi-class classification framework
where each class designates a different subarray. The proposed network
determines a new array every time data is received by the radar, thereby making
antenna selection a cognitive operation. Our numerical experiments show that
{the proposed CNN structure provides 22% better classification performance than
a Support Vector Machine and the resulting subarrays yield 72% more accurate
DoA estimates than random array selections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09843</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09843</id><created>2018-02-27</created><updated>2020-02-10</updated><authors><author><keyname>Verdoja</keyname><forenames>Francesco</forenames></author><author><keyname>Grangetto</keyname><forenames>Marco</forenames></author></authors><title>Graph Laplacian for Image Anomaly Detection</title><categories>eess.IV cs.CV eess.SP</categories><comments>Published in Machine Vision and Applications (Springer)</comments><journal-ref>Machine Vision and Applications, vol. 31, no. 1, Feb. 2020</journal-ref><doi>10.1007/s00138-020-01059-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reed-Xiaoli detector (RXD) is recognized as the benchmark algorithm for image
anomaly detection; however, it presents known limitations, namely the
dependence over the image following a multivariate Gaussian model, the
estimation and inversion of a high-dimensional covariance matrix, and the
inability to effectively include spatial awareness in its evaluation. In this
work, a novel graph-based solution to the image anomaly detection problem is
proposed; leveraging the graph Fourier transform, we are able to overcome some
of RXD's limitations while reducing computational cost at the same time. Tests
over both hyperspectral and medical images, using both synthetic and real
anomalies, prove the proposed technique is able to obtain significant gains
over performance by other algorithms in the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09879</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09879</id><created>2018-02-27</created><updated>2018-12-28</updated><authors><author><keyname>Yuan</keyname><forenames>Ganzhao</forenames></author><author><keyname>Ghanem</keyname><forenames>Bernard</forenames></author></authors><title>L0TV: A Sparse Optimization Method for Impulse Noise Image Restoration</title><categories>cs.NA eess.IV math.OC</categories><comments>to appear in IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Total Variation (TV) is an effective and popular prior model in the field of
regularization-based image processing. This paper focuses on total variation
for removing impulse noise in image restoration. This type of noise frequently
arises in data acquisition and transmission due to many reasons, e.g. a faulty
sensor or analog-to-digital converter errors. Removing this noise is an
important task in image restoration. State-of-the-art methods such as Adaptive
Outlier Pursuit(AOP) \cite{yan2013restoration}, which is based on TV with
$\ell_{02}$-norm data fidelity, only give sub-optimal performance. In this
paper, we propose a new sparse optimization method, called $\ell_0TV$-PADMM,
which solves the TV-based restoration problem with $\ell_0$-norm data fidelity.
To effectively deal with the resulting non-convex non-smooth optimization
problem, we first reformulate it as an equivalent biconvex Mathematical Program
with Equilibrium Constraints (MPEC), and then solve it using a proximal
Alternating Direction Method of Multipliers (PADMM). Our $\ell_0TV$-PADMM
method finds a desirable solution to the original $\ell_0$-norm optimization
problem and is proven to be convergent under mild conditions. We apply
$\ell_0TV$-PADMM to the problems of image denoising and deblurring in the
presence of impulse noise. Our extensive experiments demonstrate that
$\ell_0TV$-PADMM outperforms state-of-the-art image restoration methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09958</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09958</id><created>2018-02-27</created><authors><author><keyname>Xu</keyname><forenames>Jinkun</forenames></author><author><keyname>Chen</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Cui</keyname><forenames>Qimei</forenames></author><author><keyname>Tao</keyname><forenames>Xiaofeng</forenames></author></authors><title>Use of Two-Mode Circuitry and Optimal Energy-Efficient Power Control
  Under Target Delay-Outage Constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An accurate energy efficiency analytical model based on a two-mode circuitry
was recently proposed; and the model showed that the use of this circuitry can
significantly improve a system's energy efficiency. In this paper, we use this
analytical model to develop a new power control scheme, a scheme that is
capable of allocating a minimum transmission power precisely within the
delay-outage probability constraint. Precision brings substantial benefits as
numerical results show that the energy efficiency using our scheme is much
higher than other schemes. Results further suggest that data rate values affect
energy efficiency non-uniformly, i.e., there exists a specific data rate value
that achieves maximum energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09975</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09975</id><created>2018-02-27</created><authors><author><keyname>Scheidegger</keyname><forenames>Samuel</forenames></author><author><keyname>Benjaminsson</keyname><forenames>Joachim</forenames></author><author><keyname>Rosenberg</keyname><forenames>Emil</forenames></author><author><keyname>Krishnan</keyname><forenames>Amrit</forenames></author><author><keyname>Granstrom</keyname><forenames>Karl</forenames></author></authors><title>Mono-Camera 3D Multi-Object Tracking Using Deep Learning Detections and
  PMBM Filtering</title><categories>cs.CV eess.SP</categories><comments>8 pages, 2 figures, for associated videos, see https://goo.gl/AoydgW</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monocular cameras are one of the most commonly used sensors in the automotive
industry for autonomous vehicles. One major drawback using a monocular camera
is that it only makes observations in the two dimensional image plane and can
not directly measure the distance to objects. In this paper, we aim at filling
this gap by developing a multi-object tracking algorithm that takes an image as
input and produces trajectories of detected objects in a world coordinate
system. We solve this by using a deep neural network trained to detect and
estimate the distance to objects from a single input image. The detections from
a sequence of images are fed in to a state-of-the art Poisson multi-Bernoulli
mixture tracking filter. The combination of the learned detector and the PMBM
filter results in an algorithm that achieves 3D tracking using only mono-camera
images as input. The performance of the algorithm is evaluated both in 3D world
coordinates, and 2D image coordinates, using the publicly available KITTI
object tracking dataset. The algorithm shows the ability to accurately track
objects, correctly handle data associations, even when there is a big overlap
of the objects in the image, and is one of the top performing algorithms on the
KITTI object tracking benchmark. Furthermore, the algorithm is efficient,
running on average close to 20 frames per second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.09994</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.09994</id><created>2018-02-24</created><authors><author><keyname>Alevizos</keyname><forenames>Panos N.</forenames></author><author><keyname>Vougioukas</keyname><forenames>Georgios</forenames></author><author><keyname>Bletsas</keyname><forenames>Aggelos</forenames></author></authors><title>Nonlinear Energy Harvesting Models in Wireless Information and Power
  Transfer</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work compares different linear and nonlinear RF energy harvesting
models, including limited or unlimited sensitivity, for simultaneous wireless
information and power transfer (SWIPT). The probability of successful SWIPT
reception under a family of RF harvesting models is rigorously quantified,
using state-of-the-art rectifiers in the context of commercial RFIDs. A
significant portion of SWIPT literature uses oversimplified models that do not
account for limited sensitivity or nonlinearity of the underlying harvesting
circuitry. This work demonstrates that communications signals are not always
appropriate for simultaneous energy transfer and concludes that for practical
SWIPT studies, the inherent non-ideal characteristics of the harvester should
be carefully taken into account; specific harvester's modeling methodology is
also offered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10058</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10058</id><created>2018-02-27</created><authors><author><keyname>Sajil</keyname><forenames>C. K.</forenames></author><author><keyname>Biji</keyname><forenames>C. L.</forenames></author><author><keyname>Achuthsankar</keyname><forenames>S. Nair</forenames></author></authors><title>Effect of Transducer Positioning in Active Noise Control</title><categories>cs.SD eess.AS</categories><comments>6 pages, 11 figures. To appear in the Proceedings of the 5th
  International Conference on Signal Processing and Integrated Networks(SPIN
  2018), 22-23 February 2018, Delhi, India</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Research in traditional Active Noise Control(ANC) often abstracts acoustic
channels with band-limited filter coefficients. This is a limitation in
exploring structural and positional aspects of ANC. As a solution to this, we
propose the use of room acoustic models in ANC research. As a use case, we
demonstrate anti-noise source position optimization using room acoustics models
in achieving better noise control. Using numerical simulations, we show that
level of cancellation can be improved up to 7.34 dB. All the codes and results
are available in the Github repository https://github.com/cksajil/ancram in the
spirit of reproducible research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10066</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10066</id><created>2018-02-27</created><authors><author><keyname>Monier</keyname><forenames>&#xc9;tienne</forenames></author><author><keyname>Oberlin</keyname><forenames>Thomas</forenames></author><author><keyname>Brun</keyname><forenames>Nathalie</forenames></author><author><keyname>Tenc&#xe9;</keyname><forenames>Marcel</forenames></author><author><keyname>de Frutos</keyname><forenames>Marta</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author></authors><title>Reconstruction of partially sampled multi-band images - Application to
  STEM-EELS imaging</title><categories>eess.IV cond-mat.mtrl-sci cs.CV physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electron microscopy has shown to be a very powerful tool to map the chemical
nature of samples at various scales down to atomic resolution. However, many
samples can not be analyzed with an acceptable signal-to-noise ratio because of
the radiation damage induced by the electron beam. This is particularly crucial
for electron energy loss spectroscopy (EELS) which acquires spectral-spatial
data and requires high beam intensity. Since scanning transmission electron
microscopes (STEM) are able to acquire data cubes by scanning the electron
probe over the sample and recording a spectrum for each spatial position, it is
possible to design the scan pattern and to sample only specific pixels. As a
consequence, partial acquisition schemes are now conceivable, provided a
reconstruction of the full data cube is conducted as a post-processing step.
This paper proposes two reconstruction algorithms for multi-band images
acquired by STEM-EELS which exploits the spectral structure and the spatial
smoothness of the image. The performance of the proposed schemes is illustrated
thanks to experiments conducted on a realistic phantom dataset as well as real
EELS spectrum-images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10145</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10145</id><created>2018-02-27</created><authors><author><keyname>Kruzick</keyname><forenames>Stephen</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Graph Signal Processing: Filter Design and Spectral Statistics</title><categories>eess.SP</categories><comments>2017 IEEE International Workshop on Computational Advances in
  Multi-Sensor Adaptive Processing (CAMSAP 2017)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph signal processing analyzes signals supported on the nodes of a graph by
defining the shift operator in terms of a matrix, such as the graph adjacency
matrix or Laplacian matrix, related to the structure of the graph. With respect
to the graph shift operator, polynomial functions of the shift matrix perform
filtering. An application considered in this paper, convergence acceleration
filters for distributed average consensus may be viewed as lowpass graph
filters periodically applied to the states. Design of graph filters depends on
the shift matrix eigendecomposition. Consequently, random graphs present a
challenge as this information is often difficult to obtain. Nevertheless, the
asymptotic behavior of the shift matrix empirical spectral distribution
provides a substitute for suitable random matrix models. This paper employs
deterministic approximations for empirical spectral statistics from other works
to propose optimization criteria for consensus acceleration filters, evaluating
the results through simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10152</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10152</id><created>2018-02-27</created><authors><author><keyname>Kruzick</keyname><forenames>Stephen</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Optimal Filter Design for Consensus on Random Directed Graphs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal design of consensus acceleration graph filters relates closely to the
eigenvalues of the consensus iteration matrix. This task is complicated by
random networks with uncertain iteration matrix eigenvalues. Filter design
methods based on the spectral asymptotics of consensus iteration matrices for
large-scale, random undirected networks have been previously developed both for
constant and for time-varying network topologies. This work builds upon these
results by extending analysis to large-scale, constant, random directed
networks. The proposed approach uses theorems by Girko that analytically
produce deterministic approximations of the empirical spectral distribution for
suitable non-Hermitian random matrices. The approximate empirical spectral
distribution defines filtering regions in the proposed filter optimization
problem, which must be modified to accommodate complex-valued eigenvalues.
Presented numerical simulations demonstrate good results. Additionally,
limitations of the proposed method are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10159</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10159</id><created>2018-02-27</created><authors><author><keyname>Kruzick</keyname><forenames>Stephen</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Spectral Statistics of Directed Networks with Random Link Model
  Transpose-Asymmetry</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic network influences complicate graph filter design by producing
uncertainty in network iteration matrix eigenvalues, the points at which the
graph filter response is defined. While joint statistics for the eigenvalues
typically elude analysis, predictable spectral asymptotics can emerge for large
scale networks. Previously published works successfully analyze large-scale
networks described by undirected graphs and directed graphs with
transpose-symmetric distributions, focusing on consensus acceleration filter
design for time-invariant networks as an application. This work expands upon
these results by enabling analysis of certain large-scale directed networks
described by transpose-asymmetric distributions. Specifically, efficiently
computable spectral density approximations are possible for
transpose-asymmetric percolation network models with node-transitive symmetry
group and normal mean matrix. Numerical simulations support the derived
approximations and application to consensus filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10162</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10162</id><created>2018-02-27</created><authors><author><keyname>Useche</keyname><forenames>Jorge</forenames></author><author><keyname>Hurtado</keyname><forenames>Rafael</forenames></author><author><keyname>Demmer</keyname><forenames>Federico</forenames></author></authors><title>Interplay between musical practices and tuning in the marimba de chonta
  music</title><categories>cs.SD eess.AS</categories><comments>Total number of pages: 52, main manuscript: 18 pages, supplemental
  material: 34 pages, the main manuscript contains 6 tables and 9 figures</comments><msc-class>91Cxx, 91Dxx, 91Exx, 91Fxx</msc-class><acm-class>H.5.5; J.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Pacific Coast of Colombia there is a type of marimba called marimba de
chonta, which provides the melodic and harmonic contour for traditional music
with characteristic chants and dances. The tunings of this marimba are based on
the voice of female singers and allows musical practices, as a transposition
that preserves relative distances between bars. Here we show that traditional
tunings are consistent with isotonic scales, and that they have changed in the
last three decades due to the influence of Western music. Specifically, low
octaves have changed into just octaves. Additionally, consonance properties of
this instrument include the occurrence of a broad minimum of dissonance that is
used in the musical practices, while the narrow local peaks of dissonance are
avoided. We found that the main reason for this is the occurrence of
uncertainties in the tunings with respect to the mathematical successions of
isotonic scales. We conclude that in this music the emergence of tunings and
musical practices cannot be considered as separate issues. Consonance, timbre,
and musical practices are entangled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10220</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10220</id><created>2018-02-27</created><updated>2018-12-18</updated><authors><author><keyname>Girault</keyname><forenames>Benjamin</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author><author><keyname>Narayanan</keyname><forenames>Shrikanth</forenames></author></authors><title>Irregularity-Aware Graph Fourier Transforms</title><categories>eess.SP</categories><comments>This article has been published in IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2018.2870386</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel generalization of the graph Fourier
transform (GFT). Our approach is based on separately considering the
definitions of signal energy and signal variation, leading to several possible
orthonormal GFTs. Our approach includes traditional definitions of the GFT as
special cases, while also leading to new GFT designs that are better at taking
into account the irregular nature of the graph. As an illustration, in the
context of sensor networks we use the Voronoi cell area of vertices in our GFT
definition, showing that it leads to a more sensible definition of graph signal
energy even when sampling is highly irregular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10237</identifier>
 <datestamp>2018-04-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10237</id><created>2018-02-27</created><updated>2018-04-05</updated><authors><author><keyname>Moin</keyname><forenames>Ali</forenames></author><author><keyname>Zhou</keyname><forenames>Andy</forenames></author><author><keyname>Rahimi</keyname><forenames>Abbas</forenames></author><author><keyname>Benatti</keyname><forenames>Simone</forenames></author><author><keyname>Menon</keyname><forenames>Alisha</forenames></author><author><keyname>Tamakloe</keyname><forenames>Senam</forenames></author><author><keyname>Ting</keyname><forenames>Jonathan</forenames></author><author><keyname>Yamamoto</keyname><forenames>Natasha</forenames></author><author><keyname>Khan</keyname><forenames>Yasser</forenames></author><author><keyname>Burghardt</keyname><forenames>Fred</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author><author><keyname>Arias</keyname><forenames>Ana C.</forenames></author><author><keyname>Rabaey</keyname><forenames>Jan M.</forenames></author></authors><title>An EMG Gesture Recognition System with Flexible High-Density Sensors and
  Brain-Inspired High-Dimensional Classifier</title><categories>cs.HC cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EMG-based gesture recognition shows promise for human-machine interaction.
Systems are often afflicted by signal and electrode variability which degrades
performance over time. We present an end-to-end system combating this
variability using a large-area, high-density sensor array and a robust
classification algorithm. EMG electrodes are fabricated on a flexible substrate
and interfaced to a custom wireless device for 64-channel signal acquisition
and streaming. We use brain-inspired high-dimensional (HD) computing for
processing EMG features in one-shot learning. The HD algorithm is tolerant to
noise and electrode misplacement and can quickly learn from few gestures
without gradient descent or back-propagation. We achieve an average
classification accuracy of 96.64% for five gestures, with only 7% degradation
when training and testing across different days. Our system maintains this
accuracy when trained with only three trials of gestures; it also demonstrates
comparable accuracy with the state-of-the-art when trained with one trial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10255</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10255</id><created>2018-02-27</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Shi</keyname><forenames>Jia</forenames></author><author><keyname>Yang</keyname><forenames>Weiwei</forenames></author><author><keyname>Zhong</keyname><forenames>Ping</forenames></author></authors><title>Massive MIMO relaying with linear precoding in correlated channels under
  limited feedback</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study on a massive MIMO relay system with linear precoding
under the conditions of imperfect channel state information at the transmitter
(CSIT) and per-user channel transmit correlation. In our system the
source-relay channels are massive multiple-input multiple-output (MIMO) ones
and the relay-destination channels are massive multiple-input single-output
(MISO) ones. Large random matrix theory (RMT) is used to derive a deterministic
equivalent of the signal-to-interference-plus-noise ratio (SINR) at each user
in massive MIMO amplify-forward and decode-forward (M-MIMO-ADF) relaying with
regularized zero-forcing (RZF) precoding, as the number of transmit antennas
and users M,K approaches to infinity and M&gt;&gt;K. In this paper we obtain a
closed-form expression for the deterministic equivalent of
h^H_kW(hat)_lh(hat)_k, and we give two theorems and a corollary to derive the
deterministic equivalent of the SINR at each user. Simulation results show that
the deterministic equivalent of the SINR at each user in M-MIMO-ADF relaying
and the results of Theorem 1, Theorem 2, Proposition 1 and Corollary 1 are
accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10325</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10325</id><created>2018-02-28</created><updated>2018-03-27</updated><authors><author><keyname>Zheng</keyname><forenames>Lin</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author><author><keyname>Feng</keyname><forenames>Qing</forenames></author><author><keyname>Li</keyname><forenames>Xuebin</forenames></author></authors><title>Shifting Maximum Eigenvalue Detection in Low SNR Environment</title><categories>eess.SP</categories><comments>9 pages, 12 figures. The paper is submitted to IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum eigenvalue detection (MED) is an important application of random
matrix theory in spectrum sensing and signal detection. However, in small
signal-to-noise ratio environment, the maximum eigenvalue of the representative
signal is at the edge of Marchenko-Pastur (M-P) law bulk and meets the
Tracy-Widom distribution. Since the distribution of Tracy-Widom has no
closed-form expression, it brings great difficulty in processing. In this
paper, we propose a shifting maximum eigenvalue (SMED) algorithm, which shifts
the maximum eigenvalue out of the M-P law bulk by combining an auxiliary signal
associated with the signal to be detected. According to the random matrix
theory, the shifted maximum eigenvalue is consistent with Gaussian
distribution. The proposed SMED not only simplifies the detection algorithm,
but also greatly improve the detection performance. In this paper, the
performance of SMED, MED and trace (FMD) algorithm is analyzed and the
theoretical performance comparisons are obtained. The algorithm and theoretical
results are verified by the simulations in different signal environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10326</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10326</id><created>2018-02-28</created><updated>2018-03-26</updated><authors><author><keyname>Biswas</keyname><forenames>Sudip</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author><author><keyname>Singh</keyname><forenames>Keshav</forenames></author><author><keyname>Vuppala</keyname><forenames>Satyanarayana</forenames></author><author><keyname>Ratnarajah</keyname><forenames>Tharmalingam</forenames></author></authors><title>An Analysis on Caching Placement for Millimeter/Micro Wave Hybrid
  Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a hybrid millimeter wave (mmWave) and micro wave
($\mu$Wave) network from the perspective of \emph{wireless caching} and study
the optimal probabilistic content/file caching placement at desirable base
stations (BSs) using a stochastic geometric framework. Considering the average
success probability (ASP) of file delivery as the performance metric, we derive
expressions for the association probability of the typical user to the mmWave
and $\mu$Wave networks. Accordingly, we provide an upper bound for the ASP of
file delivery and formulate the content caching placement scheme as an
optimization problem with respect to caching probabilities, that jointly
optimizes the ASP of file delivery considering both content placement and
delivery phases. In particular, we consider the caching placement strategy
under both noise-limited and interference-limited environments. We numerically
evaluate the performance of the proposed caching schemes under essential
factors, such as blockages in the mmWave network, cluster radius, BS density,
and path loss and compare it with uniform caching placement, caching $M$ most
popular contents, and random caching placement. Numerical results demonstrate
the superiority of the proposed caching scheme over others, albeit certain
trade-offs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10438</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10438</id><created>2018-02-28</created><authors><author><keyname>Kabakulak</keyname><forenames>Banu</forenames></author></authors><title>Sensor and Sink Placement, Scheduling and Routing Algorithms for
  Connected Coverage of Wireless Sensor Networks</title><categories>cs.NI eess.SP</categories><comments>30 pages, 1 figure, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor is a small electronic device which has the ability to sense, compute
and communicate either with other sensors or directly with a base station
(sink). In a wireless sensor network (WSN), the sensors monitor a region and
transmit the collected data packets through routes to the sinks. In this study,
we propose a mixed--integer linear programming (MILP) model to maximize the
number of time periods that a WSN carries out the desired tasks with limited
energy and budget. Our sink and sensor placement, scheduling, routing with
connected coverage ($SPSRC$) model is the first in the literature that combines
the decisions for the locations of sinks and sensors, activity schedules of the
deployed sensors, and data flow routes from each active sensor to its assigned
sink for connected coverage of the network over a finite planning horizon. The
problem is NP--hard and difficult to solve even for small instances. Assuming
that the sink locations are known, we develop heuristics which construct a
feasible solution of the problem by gradually satisfying the constraints. Then,
we introduce search heuristics to determine the locations of the sinks to
maximize the network lifetime. Computational experiments reveal that our
heuristic methods can find near optimal solutions in an acceptable amount of
time compared to the commercial solver CPLEX 12.7.0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10444</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10444</id><created>2018-02-21</created><authors><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Liang</keyname><forenames>Xiao</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Wu</keyname><forenames>Zhizhen</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Wang</keyname><forenames>Feng</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames><affiliation>Shanghai Institute for Advanced Communications and Data Science, Shanghai University, Shanghai, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author></authors><title>On the Low-Complexity, Hardware-Friendly Tridiagonal Matrix Inversion
  for Correlated Massive MIMO Systems</title><categories>eess.SP cs.AR cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In massive MIMO (M-MIMO) systems, one of the key challenges in the
implementation is the large-scale matrix inversion operation, as widely used in
channel estimation, equalization, detection, and decoding procedures.
Traditionally, to handle this complexity issue, several low-complexity matrix
inversion approximation methods have been proposed, including the classic
Cholesky decomposition and the Neumann series expansion (NSE). However, the
conventional approaches failed to exploit neither the special structure of
channel matrices nor the critical issues in the hardware implementation, which
results in poorer throughput performance and longer processing delay. In this
paper, by targeting at the correlated M-MIMO systems, we propose a modified NSE
based on tridiagonal matrix inversion approximation (TMA) to accommodate the
complexity as well as the performance issue in the conventional hardware
implementation, and analyze the corresponding approximation errors. Meanwhile,
we investigate the VLSI implementation for the proposed detection algorithm
based on a Xilinx Virtex-7 XC7VX690T FPGA platform. It is shown that for
correlated massive MIMO systems, it can achieve near-MMSE performance and $630$
Mb/s throughput. Compared with other benchmark systems, the proposed pipelined
TMA detector can get high throughput-to-hardware ratio. Finally, we also
propose a fast iteration structure for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10458</identifier>
 <datestamp>2018-11-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10458</id><created>2018-02-26</created><updated>2018-11-01</updated><authors><author><keyname>Soleimani</keyname><forenames>Hamid</forenames></author><author><keyname>Aliasghar</keyname></author><author><keyname>Makhlooghpour</keyname></author><author><keyname>Nicola</keyname><forenames>Wilten</forenames></author><author><keyname>Clopath</keyname><forenames>Claudia</forenames></author><author><keyname>Drakakis</keyname><forenames>Emmanuel. M.</forenames></author></authors><title>A High GOPs/Slice Time Series Classifier for Portable and Embedded
  Biomedical Applications</title><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays a diverse range of physiological data can be captured continuously
for various applications in particular wellbeing and healthcare. Such data
require efficient methods for classification and analysis. Deep learning
algorithms have shown remarkable potential regarding such analyses, however,
the use of these algorithms on low-power wearable devices is challenged by
resource constraints such as area and power consumption. Most of the available
on-chip deep learning processors contain complex and dense hardware
architectures in order to achieve the highest possible throughput. Such a trend
in hardware design may not be efficient in applications where on-node
computation is required and the focus is more on the area and power efficiency
as in the case of portable and embedded biomedical devices. This paper presents
an efficient time-series classifier capable of automatically detecting
effective features and classifying the input signals in real-time. In the
proposed classifier, throughput is traded off with hardware complexity and cost
using resource sharing techniques. A Convolutional Neural Network (CNN) is
employed to extract input features and then a Long-Short-Term-Memory (LSTM)
architecture with ternary weight precision classifies the input signals
according to the extracted features. Hardware implementation on a Xilinx FPGA
confirm that the proposed hardware can accurately classify multiple complex
biomedical time series data with low area and power consumption and outperform
all previously presented state-of-the-art records. Most notably, our classifier
reaches 1.3$\times$ higher GOPs/Slice than similar state of the art FPGA-based
accelerators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10461</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10461</id><created>2018-02-27</created><authors><author><keyname>Zhao</keyname><forenames>Jianwei</forenames></author><author><keyname>Xie</keyname><forenames>Hongxiang</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Jia</keyname><forenames>Weimin</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Time Varying Channel Tracking with Spatial and Temporal BEM for Massive
  MIMO Systems</title><categories>eess.SP cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a channel tracking method for massive multi-input
and multi-output systems under both time-varying and spatial-varying
circumstance. Exploiting the characteristics of massive antenna array, a
spatial-temporal basis expansion model is designed to reduce the effective
dimensions of up-link and down-link channel, which decomposes channel state
information into the time-varying spatial information and gain information. We
firstly model the users movements as a one-order unknown Markov process, which
is blindly learned by the expectation and maximization (EM) approach. Then, the
up-link time varying spatial information can be blindly tracked by Taylor
series expansion of the steering vector, while the rest up-link channel gain
information can be trained by only a few pilot symbols. Due to angle
reciprocity (spatial reciprocity), the spatial information of the down-link
channel can be immediately obtained from the up-link counterpart, which greatly
reduces the complexity of down-link channel tracking. Various numerical results
are provided to demonstrate the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10493</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10493</id><created>2018-02-28</created><authors><author><keyname>Chen</keyname><forenames>Hua</forenames></author><author><keyname>Zehni</keyname><forenames>Mona</forenames></author><author><keyname>Zhao</keyname><forenames>Zhizhen</forenames></author></authors><title>A Spectral Method for Stable Bispectrum Inversion with Application to
  Multireference Alignment</title><categories>eess.SP</categories><comments>5 pages, 5 figures</comments><doi>10.1109/LSP.2018.2831631</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on an alignment-free method to estimate the underlying signal from a
large number of noisy randomly shifted observations. Specifically, we estimate
the mean, power spectrum, and bispectrum of the signal from the observations.
Since bispectrum contains the phase information of the signal, reliable
algorithms for bispectrum inversion is useful in many applications. We propose
a new algorithm using spectral decomposition of the normalized bispectrum
matrix for this task. For clean signals, we show that the eigenvectors of the
normalized bispectrum matrix correspond to the true phases of the signal and
its shifted copies. In addition, the spectral method is robust to noise. It can
be used as a stable and efficient initialization technique for local non-convex
optimization for bispectrum inversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.10495</identifier>
 <datestamp>2018-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.10495</id><created>2018-02-28</created><updated>2018-09-25</updated><authors><author><keyname>Huang</keyname><forenames>Yu-Siang</forenames></author><author><keyname>Chou</keyname><forenames>Szu-Yu</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Pop Music Highlighter: Marking the Emotion Keypoints</title><categories>eess.AS cs.AI cs.MM cs.SD</categories><comments>Transactions of the ISMIR vol. 1, no. 1</comments><doi>10.5334/tismir.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of music highlight extraction is to get a short consecutive segment
of a piece of music that provides an effective representation of the whole
piece. In a previous work, we introduced an attention-based convolutional
recurrent neural network that uses music emotion classification as a surrogate
task for music highlight extraction, for Pop songs. The rationale behind that
approach is that the highlight of a song is usually the most emotional part.
This paper extends our previous work in the following two aspects. First,
methodology-wise we experiment with a new architecture that does not need any
recurrent layers, making the training process faster. Moreover, we compare a
late-fusion variant and an early-fusion variant to study which one better
exploits the attention mechanism. Second, we conduct and report an extensive
set of experiments comparing the proposed attention-based methods against a
heuristic energy-based method, a structural repetition-based method, and a few
other simple feature-based methods for this task. Due to the lack of
public-domain labeled data for highlight extraction, following our previous
work we use the RWC POP 100-song data set to evaluate how the detected
highlights overlap with any chorus sections of the songs. The experiments
demonstrate the effectiveness of our methods over competing methods. For
reproducibility, we open source the code and pre-trained model at
https://github.com/remyhuang/pop-music-highlighter/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00187</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00187</id><created>2018-02-28</created><authors><author><keyname>Maeno</keyname><forenames>Yu</forenames></author><author><keyname>Mitsufuji</keyname><forenames>Yuki</forenames></author><author><keyname>Abhayapala</keyname><forenames>Thushara D.</forenames></author></authors><title>Mode Domain Spatial Active Noise Control Using Sparse Signal
  Representation</title><categories>cs.SD eess.AS eess.SP</categories><comments>to appear at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active noise control (ANC) over a sizeable space requires a large number of
reference and error microphones to satisfy the spatial Nyquist sampling
criterion, which limits the feasibility of practical realization of such
systems. This paper proposes a mode-domain feedforward ANC method to attenuate
the noise field over a large space while reducing the number of microphones
required. We adopt a sparse reference signal representation to precisely
calculate the reference mode coefficients. The proposed system consists of
circular reference and error microphone arrays, which capture the reference
noise signal and residual error signal, respectively, and a circular
loudspeaker array to drive the anti-noise signal. Experimental results indicate
that above the spatial Nyquist frequency,our proposed method can perform well
compared to a conventional methods. Moreover, the proposed method can even
reduce the number of reference microphones while achieving better noise
attenuation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00230</identifier>
 <datestamp>2019-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00230</id><created>2018-03-01</created><updated>2019-04-20</updated><authors><author><keyname>Chu</keyname><forenames>Lei</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author><author><keyname>Wen</keyname><forenames>Fei</forenames></author></authors><title>Eigen-Inference Precoding for Coarsely Quantized Massive MU-MIMO System
  with Imperfect CSI</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the precoding problem in massive multiuser multiple-input
multiple-output (MU-MIMO) systems equipped with low-resolution
digital-to-analog converters (DACs). In previous literature on this topic, it
is commonly assumed that the channel state information (CSI) is perfectly
known. However, in practical applications the CSI is inevitably contaminated by
noise. In this paper, we propose, for the first time, an eigen-inference (EI)
precoding scheme to improve the error performance of the coarsely quantized
massive MU-MIMO systems under imperfect CSI, which is mathematically modeled by
a sum of two rectangular random matrices (RRMs). Instead of performing analysis
based on the RRM, using Girko's Hermitization trick, the proposed method
leverages the block random matrix theory by augmenting the RRM into a block
symmetric channel matrix (BSCA). Specially, we derive the empirical
distribution of the eigenvalues of the BSCA and establish the limiting spectra
distribution connection between the true BSCA and its noisy observation. Then,
based on these theoretical results, we propose an EI-based moments matching
method for CSI-related noise level estimation and a rotation invariant
estimation method for CSI reconstruction. Based on the cleaned CSI, the
quantized precoding problem is tackled via the Bussgang theorem and the
Lagrangian multiplier method. The prosed methods are lastly verified by
numerical simulations and the results demonstrate the effectiveness of the
proposed precoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00260</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00260</id><created>2018-03-01</created><authors><author><keyname>Barath</keyname><forenames>Daniel</forenames></author></authors><title>Five-point Fundamental Matrix Estimation for Uncalibrated Cameras</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We aim at estimating the fundamental matrix in two views from five
correspondences of rotation invariant features obtained by e.g.\ the SIFT
detector. The proposed minimal solver first estimates a homography from three
correspondences assuming that they are co-planar and exploiting their
rotational components. Then the fundamental matrix is obtained from the
homography and two additional point pairs in general position. The proposed
approach, combined with robust estimators like Graph-Cut RANSAC, is superior to
other state-of-the-art algorithms both in terms of accuracy and number of
iterations required. This is validated on synthesized data and $561$ real image
pairs. Moreover, the tests show that requiring three points on a plane is not
too restrictive in urban environment and locally optimized robust estimators
lead to accurate estimates even if the points are not entirely co-planar. As a
potential application, we show that using the proposed method makes two-view
multi-motion estimation more accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00267</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00267</id><created>2018-03-01</created><authors><author><keyname>Fortunati</keyname><forenames>Stefano</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Greco</keyname><forenames>Maria S.</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>A fresh look at the Semiparametric Cram\'{e}r-Rao Bound</title><categories>eess.SP</categories><comments>Submitted to EUSIPCO 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at providing a fresh look at semiparametric estimation theory
and, in particular, at the Semiparametric Cram\'{e}r-Rao Bound (SCRB).
Semiparametric models are characterized by a finite-dimensional parameter
vector of interest and by an infinite-dimensional nuisance function that is
often related to an unspecified functional form of the density of the noise
underlying the observations. We summarize the main motivations and the
intuitive concepts about semiparametric models. Then we provide a new look at
the classical estimation theory based on a geometrical Hilbert space-based
approach. Finally, the semiparametric version of the Cram\'{e}r-Rao Bound for
the estimation of the finite-dimensional vector of the parameters of interest
is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00368</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00368</id><created>2018-02-28</created><updated>2018-03-11</updated><authors><author><keyname>Wang</keyname><forenames>Yuan</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author><author><keyname>Hu</keyname><forenames>Wuhua</forenames></author></authors><title>An Event-based Diffusion LMS Strategy</title><categories>eess.SP cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless sensor network consists of cooperative nodes, each of
them keep adapting to streaming data to perform a least-mean-squares
estimation, and also maintain information exchange among neighboring nodes in
order to improve performance. For the sake of reducing communication overhead,
prolonging batter life while preserving the benefits of diffusion cooperation,
we propose an energy-efficient diffusion strategy that adopts an event-based
communication mechanism, which allow nodes to cooperate with neighbors only
when necessary. We also study the performance of the proposed algorithm, and
show that its network mean error and MSD are bounded in steady state. Numerical
results demonstrate that the proposed method can effectively reduce the network
energy consumption without sacrificing steady-state network MSD performance
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00387</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00387</id><created>2018-02-12</created><authors><author><keyname>Du</keyname><forenames>Xinxin</forenames></author><author><keyname>Ang</keyname><forenames>Marcelo H.</forenames><suffix>Jr.</suffix></author><author><keyname>Karaman</keyname><forenames>Sertac</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>A General Pipeline for 3D Detection of Vehicles</title><categories>cs.CV eess.IV stat.ML</categories><comments>Accepted at ICRA 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous driving requires 3D perception of vehicles and other objects in
the in environment. Much of the current methods support 2D vehicle detection.
This paper proposes a flexible pipeline to adopt any 2D detection network and
fuse it with a 3D point cloud to generate 3D information with minimum changes
of the 2D detection networks. To identify the 3D box, an effective model
fitting algorithm is developed based on generalised car models and score maps.
A two-stage convolutional neural network (CNN) is proposed to refine the
detected 3D box. This pipeline is tested on the KITTI dataset using two
different 2D detection networks. The 3D detection results based on these two
networks are similar, demonstrating the flexibility of the proposed pipeline.
The results rank second among the 3D detection algorithms, indicating its
competencies in 3D detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00396</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00396</id><created>2018-02-18</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Asaduzzaman</keyname></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author><author><keyname>Ahmad</keyname><forenames>M. Omair</forenames></author></authors><title>Speech Enhancement in Adverse Environments Based on Non-stationary
  Noise-driven Spectral Subtraction and SNR-dependent Phase Compensation</title><categories>eess.AS cs.SD</categories><comments>15 pages, 10 figures, 8 tables. arXiv admin note: substantial text
  overlap with arXiv:1802.02665; text overlap with arXiv:1802.05125</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-step enhancement method based on spectral subtraction and phase
spectrum compensation is presented in this paper for noisy speeches in adverse
environments involving non-stationary noise and medium to low levels of SNR.
The magnitude of the noisy speech spectrum is modified in the first step of the
proposed method by a spectral subtraction approach, where a new noise
estimation method based on the low frequency information of the noisy speech is
introduced. We argue that this method of noise estimation is capable of
estimating the non-stationary noise accurately. The phase spectrum of the noisy
speech is modified in the second step consisting of phase spectrum
compensation, where an SNR-dependent approach is incorporated to determine the
amount of compensation to be imposed on the phase spectrum. A modified complex
spectrum is obtained by aggregating the magnitude from the spectral subtraction
step and modified phase spectrum from the phase compensation step, which is
found to be a better representation of enhanced speech spectrum. Speech files
available in the NOIZEUS database are used to carry extensive simulations for
evaluation of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00418</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00418</id><created>2018-02-28</created><authors><author><keyname>Gyrya</keyname><forenames>Vitaliy</forenames></author><author><keyname>Zlotnik</keyname><forenames>Anatoly</forenames></author></authors><title>An explicit staggered-grid method for numerical simulation of
  large-scale natural gas pipeline networks</title><categories>eess.SP</categories><comments>28 pages, 11 figures, 5 tables</comments><report-no>LA-UR-17-29345</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an explicit second order staggered finite difference (FD)
discretization scheme for forward simulation of natural gas transport in
pipeline networks. By construction, this discretization approach guarantees
that the conservation of mass condition is satisfied exactly. The mathematical
model is formulated in terms of density, pressure, and mass flux variables, and
as a result permits the use of a general equation of state to define the
relation between the gas density and pressure for a given temperature. In a
single pipe, the model represents the dynamics of the density by propagation of
a non-linear wave according to a variable wave speed. We derive compatibility
conditions for linking domain boundary values to enable efficient, explicit
simulation of gas flows propagating through a network with pressure changes
created by gas compressors. We compare Kiuchi's implicit method and an explicit
operator splitting method with our staggered grid method, and perform numerical
experiments to validate the convergence order of the new method. In addition,
we perform several computations to investigate the influence of non-ideal
equation of state models and temperature effects into pipeline simulations with
boundary conditions over various time and space scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00468</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00468</id><created>2018-02-28</created><authors><author><keyname>Hattam</keyname><forenames>Laura</forenames></author><author><keyname>Greetham</keyname><forenames>Danica Vukadinovic</forenames></author></authors><title>Energy Disaggregation for SMEs using Recurrence Quantification Analysis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy disaggregation determines the energy consumption of individual
appliances from the total demand signal, which is recorded using a single
monitoring device. There are varied approaches to this problem, which are
applied to different settings. Here, we focus on small and medium enterprises
(SMEs) and explore useful applications for energy disaggregation from the
perspective of SMEs. More precisely, we use recurrence quantification analysis
(RQA) of the aggregate and the individual device signals to create a
two-dimensional map, which is an outlined region in a reduced information space
that corresponds to 'normal' energy demand. Then, this map is used to monitor
and control future energy consumption within the example business so to improve
their energy efficiency practices. In particular, our proposed method is shown
to detect when an appliance may be faulty and if an unexpected, additional
device is in use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00473</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00473</id><created>2018-03-01</created><authors><author><keyname>Yadav</keyname><forenames>Animesh</forenames></author><author><keyname>Tsiropoulos</keyname><forenames>Georgios I.</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>Full-Duplex Communications: Performance in Ultra-Dense Small-Cell
  Wireless Networks</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Vehicular Technology Magazine,
  Special Issue on 5G Technologies and Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theoretically, full-duplex (FD) communications can double the
spectral-efficiency (SE) of a wireless link if the problem of self-interference
(SI) is completely eliminated. Recent developments towards SI cancellation
techniques have allowed to realize the FD communications on low-power
transceivers, such as small-cell (SC) base stations. Consequently, the FD
technology is being considered as a key enabler of 5G and beyond networks. In
the context of 5G, FD communications have been initially investigated in a
single SC and then into multiple SC environments. Due to FD operations, a
single SC faces residual SI and intra-cell co-channel interference (CCI),
whereas multiple SCs face additional inter-cell CCI, which grows with the
number of neighboring cells. The surge of interference in the multi-cell
environment poses the question of the feasibility of FD communications. In this
article, we first review the FD communications in single and multiple SC
environments and then provide the state-of-the-art for the CCI mitigation
techniques, as well as FD feasibility studies in a multi-cell environment.
Further, through numerical simulations, the SE performance gain of the FD
communications in ultra-dense massive multiple input multiple-output enabled
millimeter wave SCs is presented. Finally, potential open research challenges
of multi-cell FD communications are highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00485</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00485</id><created>2018-03-01</created><authors><author><keyname>Barazideh</keyname><forenames>Reza</forenames></author><author><keyname>Nikitin</keyname><forenames>Alexei V.</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author></authors><title>Practical Implementation of Adaptive Analog Nonlinear Filtering For
  Impulsive Noise Mitigation</title><categories>eess.SP</categories><comments>This paper has been accepted in IEEE International Conference on
  Communications (ICC) 2018. arXiv admin note: text overlap with
  arXiv:1712.03267</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the performance of OFDM-based Powerline Communication
(PLC) systems is impacted by impulsive noise. In this work, we propose a
practical blind adaptive analog nonlinear filter to efficiently detect and
mitigate impulsive noise. Specially, we design an Adaptive Canonical
Differential Limiter (ACDL) which is constructed from a Clipped Mean Tracking
Filter (CMTF) and Quartile Tracking Filters (QTFs). The QTFs help to determine
a real-time range that excludes outliers. This range is fed into the CMTF which
is responsible for mitigating impulsive noise. The CMTF is a nonlinear analog
filter and its nonlinearity is controlled by the aforementioned range. Proper
selection of this range ensures the improvement of the desired signal quality
in impulsive environment. It is important to note that the proposed ACDL
behaves like a linear filter in case of no impulsive noise. In this context,
the traditional matched filter construction is modified to ensure
distortionless processing of the desired signal. The performance improvement of
the proposed ACDL is due to the fact that unlike other nonlinear methods, the
ACDL is implemented in the analog domain where the outliers are still broadband
and distinguishable. Simulation results in PRIME (OFDM-based narrowband PLC
system) demonstrate the superior BER performance of ACDL relative to other
nonlinear approaches such as blanking and clipping in impulsive noise
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00521</identifier>
 <datestamp>2018-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00521</id><created>2018-02-22</created><updated>2018-03-16</updated><authors><author><keyname>Zhou</keyname><forenames>Huayi</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Liang</keyname><forenames>Xiao</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Li</keyname><forenames>Liping</forenames><affiliation>Key Laboratory of Intelligent Computing and Signal Processing of the Ministry of Education, Anhui University, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author></authors><title>Segmented Successive Cancellation List Polar Decoding with Tailored CRC</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the first error correction codes provably achieving the symmetric capacity
of binary-input discrete memory-less channels (B-DMCs), polar codes have been
recently chosen by 3GPP for eMBB control channel. Among existing algorithms,
CRC-aided successive cancellation list (CA-SCL) decoding is favorable due to
its good performance, where CRC is placed at the end of the decoding and helps
to eliminate the invalid candidates before final selection. However, the good
performance is obtained with a complexity increase that is linear in list size
$L$. In this paper, the tailored CRC-aided SCL (TCA-SCL) decoding is proposed
to balance performance and complexity. Analysis on how to choose the proper CRC
for a given segment is proposed with the help of \emph{virtual transform} and
\emph{virtual length}. For further performance improvement, hybrid automatic
repeat request (HARQ) scheme is incorporated. Numerical results have shown
that, with the similar complexity as the state-of-the-art, the proposed TCA-SCL
and HARQ-TCA-SCL schemes achieve $0.1$ dB and $0.25$ dB performance gain at
frame error rate $\textrm{FER}=10^{-2}$, respectively. Finally, an efficient
TCA-SCL decoder is implemented with FPGA demonstrating its advantages over
CA-SCL decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00558</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00558</id><created>2018-03-01</created><authors><author><keyname>Casta&#xf1;eda</keyname><forenames>Oscar</forenames></author><author><keyname>Jacobsson</keyname><forenames>Sven</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Goldstein</keyname><forenames>Tom</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>VLSI Design of a 3-bit Constant-Modulus Precoder for Massive MU-MIMO</title><categories>eess.SP cs.IT math.IT</categories><comments>To appear at ISCAS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifth-generation (5G) cellular systems will build on massive multi-user (MU)
multiple-input multiple-output (MIMO) technology to attain high spectral
efficiency. However, having hundreds of antennas and radio-frequency (RF)
chains at the base station (BS) entails prohibitively high hardware costs and
power consumption. This paper proposes a novel nonlinear precoding algorithm
for the massive MU-MIMO downlink in which each RF chain contains an 8-phase
(3-bit) constant-modulus transmitter, enabling the use of low-cost and
power-efficient analog hardware. We present a high-throughput VLSI architecture
and show implementation results on a Xilinx Virtex-7 FPGA. Compared to a
recently-reported nonlinear precoder for BS designs that use two 1-bit
digital-to-analog converters per RF chain, our design enables up to 3.75 dB
transmit power reduction at no more than a 2.7x increase in FPGA resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00621</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00621</id><created>2018-03-01</created><authors><author><keyname>Kundu</keyname><forenames>Chinmoy</forenames></author><author><keyname>Ghose</keyname><forenames>Sarbani</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Duong</keyname><forenames>Trung Q.</forenames></author><author><keyname>Bose</keyname><forenames>Ranjan</forenames></author></authors><title>Effects of CSI Knowledge on Secrecy of Threshold-Selection
  Decode-and-Forward Relaying</title><categories>eess.SP cs.IT math.IT</categories><comments>16 pages, 7 figures</comments><doi>10.1109/ACCESS.2017.2751525</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers secrecy of a three node cooperative wireless system in
the presence of a passive eavesdropper. The threshold-selection
decode-and-forward (DF) relay is considered, which can decode the source
message correctly only if a predefined signal-to-noise ratio (SNR) is achieved.
The effects of channel state information (CSI) availability on secrecy outage
probability (SOP) and ergodic secrecy rate (ESR) are investigated, and
closed-form expressions are derived. Diversity is achieved from the direct and
relaying paths both at the destination and at the eavesdropper by combinations
of maximal-ratio combining (MRC) and selection combining (SC) schemes. An
asymptotic analysis is provided when each hop SNR is the same in the balanced
case and when it is different in the unbalanced case. The analysis shows that
both hops can be a bottleneck for secure communication; however, they do not
affect the secrecy identically. While it is observed that CSI knowledge can
improve secrecy, the amount of improvement for SOP is more when the required
rate is low and for ESR when the operating SNR is also low. It is also shown
that the source to eavesdropper link SNR is more crucial for secure
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00626</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00626</id><created>2018-03-01</created><authors><author><keyname>Dubey</keyname><forenames>A.</forenames></author><author><keyname>Kundu</keyname><forenames>C.</forenames></author><author><keyname>Ngatched</keyname><forenames>T. M. N.</forenames></author><author><keyname>Dobre</keyname><forenames>O. A.</forenames></author><author><keyname>Mallik</keyname><forenames>R. K.</forenames></author></authors><title>Incremental selective decode-and-forward relaying for power line
  communication</title><categories>eess.SP</categories><comments>6 pages, 4 figures, VTC Fall 2017</comments><doi>10.1109/VTCFall.2017.8287947</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an incremental selective decode-and-forward (ISDF) relay
strategy is proposed for power line communication (PLC) systems to improve the
spectral efficiency. Traditional decode-and-forward (DF) relaying employs two
time slots by using half-duplex relays which significantly reduces the spectral
efficiency. The ISDF strategy utilizes the relay only if the direct link
quality fails to attain a certain information rate, thereby improving the
spectral efficiency. The path gain is assumed to be log-normally distributed
with very high distance dependent signal attenuation. Furthermore, the additive
noise is modeled as a Bernoulli-Gaussian process to incorporate the effects of
impulsive noise contents. Closed-form expressions for the outage probability
and the fraction of times the relay is in use, and an approximate closed-form
expression for the average bit error rate (BER) are derived for the binary
phase-shift keying signaling scheme. We observe that the fraction of times the
relay is in use can be significantly reduced compared to the traditional DF
strategy. It is also observed that at high transmit power, the spectral
efficiency increases while the average BER decreases with increase in the
required rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00631</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00631</id><created>2018-03-01</created><authors><author><keyname>Kundu</keyname><forenames>C.</forenames></author><author><keyname>Ngatched</keyname><forenames>T. M. N.</forenames></author><author><keyname>Dobre</keyname><forenames>O. A.</forenames></author></authors><title>Relay Selection to Improve Secrecy in Cooperative Threshold
  Decode-and-Forward Relaying</title><categories>eess.SP</categories><comments>6 pages, 5 figures, GLOBECOM 16</comments><doi>10.1109/GLOCOM.2016.7842212</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, relay selection is considered to enhance security of a
cooperative system with multiple threshold-selection decode-and-forward (DF)
relays. Threshold-selection DF relays are the relays in which a predefined
signal-to-noise ratio is set for the condition of successful decoding of the
source message. We focus on the practical and general scenario where the
channels suffer from independent non-identical Rayleigh fading and where the
direct links between the source and destination and source and eavesdropper are
available. Based on channel state information knowledge, three relay selection
strategies, namely traditional, improved traditional, and optimal, are studied.
In particular, the secrecy outage probability of all three strategies are
obtained in closed-form. It is found that the diversity of secrecy outage
probability of all strategies can improve with increasing the number of relays.
It is also observed that the secrecy outage probability is limited by either
the source to relay or relay to destination channel quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00636</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00636</id><created>2018-03-01</created><authors><author><keyname>Kundu</keyname><forenames>C.</forenames></author><author><keyname>Ngatched</keyname><forenames>T. M. N.</forenames></author><author><keyname>Dobre</keyname><forenames>O. A.</forenames></author></authors><title>Secrecy performance of dual-hop threshold relaying system with diversity
  reception</title><categories>eess.SP</categories><comments>6 pages, 5 figures</comments><doi>10.1109/VTCFall.2016.7881217</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the secrecy of a cooperative system consisting of a single
source, relay, destination and eavesdropper is analyzed. The
threshold-selection decode-and-forward relay is considered, where the relay can
correctly decode and forward only if it satisfies a threshold signal-to-noise
ratio (SNR). Both destination and eavesdropper take advantage of the direct and
relayed transmissions through maximal ratio diversity combining. The secrecy
outage probability (SOP) and ergodic secrecy rate are derived in closed-form
for different channel state information (CSI) availability. It was observed
that when the required rate is low, having CSI knowledge is more advantageous
than in the case of higher rate. An increase in the required threshold SNR at
the relay can increase the SOP if the relayed link SNR is relatively higher
than the direct link SNR. It was also shown that SOP cannot be improved beyond
a certain value when keeping either dual-hop link average SNR fixed and
increasing the other link SNR, whereas the ergodic secrecy rate can be
increased by keeping the source to destination average SNR fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00694</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00694</id><created>2018-03-01</created><updated>2018-03-05</updated><authors><author><keyname>Lee</keyname><forenames>Hoyeon</forenames></author><author><keyname>Lee</keyname><forenames>Jongha</forenames></author><author><keyname>Kim</keyname><forenames>Hyeongseok</forenames></author><author><keyname>Cho</keyname><forenames>Byungchul</forenames></author><author><keyname>Cho</keyname><forenames>Seungryong</forenames></author></authors><title>Deep-neural-network based sinogram synthesis for sparse-view CT image
  reconstruction</title><categories>physics.med-ph cs.CV eess.IV</categories><doi>10.1109/TRPMS.2018.2867611</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a number of approaches to low-dose computed tomography (CT) have
been developed and deployed in commercialized CT scanners. Tube current
reduction is perhaps the most actively explored technology with advanced image
reconstruction algorithms. Sparse data sampling is another viable option to the
low-dose CT, and sparse-view CT has been particularly of interest among the
researchers in CT community. Since analytic image reconstruction algorithms
would lead to severe image artifacts, various iterative algorithms have been
developed for reconstructing images from sparsely view-sampled projection data.
However, iterative algorithms take much longer computation time than the
analytic algorithms, and images are usually prone to different types of image
artifacts that heavily depend on the reconstruction parameters. Interpolation
methods have also been utilized to fill the missing data in the sinogram of
sparse-view CT thus providing synthetically full data for analytic image
reconstruction. In this work, we introduce a deep-neural-network-enabled
sinogram synthesis method for sparse-view CT, and show its outperformance to
the existing interpolation methods and also to the iterative image
reconstruction approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00704</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00704</id><created>2018-03-01</created><updated>2018-06-25</updated><authors><author><keyname>Zare</keyname><forenames>Ali</forenames></author><author><keyname>Ozdemir</keyname><forenames>Alp</forenames></author><author><keyname>Iwen</keyname><forenames>Mark A.</forenames></author><author><keyname>Aviyente</keyname><forenames>Selin</forenames></author></authors><title>Extension of PCA to Higher Order Data Structures: An Introduction to
  Tensors, Tensor Decompositions, and Tensor PCA</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread use of multisensor technology and the emergence of big data
sets have brought the necessity to develop more versatile tools to represent
higher-order data with multiple aspects and high dimensionality. Data in the
form of multidimensional arrays, also referred to as tensors, arises in a
variety of applications including chemometrics, hyperspectral imaging, high
resolution videos, neuroimaging, biometrics, and social network analysis. Early
multiway data analysis approaches reformatted such tensor data as large vectors
or matrices and then resorted to dimensionality reduction methods developed for
classical two-way analysis such as PCA. However, one cannot discover hidden
components within multiway data using conventional PCA. To this end, tensor
decomposition methods which are flexible in the choice of the constraints and
that extract more general latent components have been proposed. In this paper,
we review the major tensor decomposition methods with a focus on problems
targeted by classical PCA. In particular, we present tensor methods that aim to
solve three important challenges typically addressed by PCA: dimensionality
reduction, i.e. low-rank tensor approximation, supervised learning, i.e.
learning linear subspaces for feature extraction, and robust low-rank tensor
recovery. We also provide experimental results to compare different tensor
models for both dimensionality reduction and supervised learning applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00711</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00711</id><created>2018-03-01</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Performance of a Relay-Assisted Hybrid FSO/RF Communication System</title><categories>eess.SP</categories><doi>10.1016/j.optcom.2019.03.070</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates performance of a relay assisted hybrid Free Space
Optical / Radio Frequency (FSO/RF) communication system. The proposed structure
is particularly recommended anywhere that direct RF communication between
mobile users and base station is not possible due to atmospheric conditions. In
this system, a multiuser RF link connects mobile users to relay and a FSO link
connects relay to the base station. It is the first time that effect of number
of users within the cell, on the performance of such structure, is
investigated. Also it is the first time that performance of a dual hop hybrid
FSO / RF system is investigated in Negative Exponential atmospheric turbulence.
Considering wide range of atmospheric turbulence regimes, from moderate to
saturated, for the first time, closed-form expressions are derived for Bit
Error Rate (BER) and outage probability (P_out) of the proposed structure.
MATLAB simulations verified accuracy of the derived expressions. Considering
fixed and adaptive gain amplify and forward protocols at relay, it is shown
that adaptive gain relay is less sensitive to the number of users within the
cell. It is also shown that fixed gain relay, despite its low complexity, has
better performance; because its gain is adjusted such that the performance be
favorable even at the worst case scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00721</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00721</id><created>2018-03-02</created><authors><author><keyname>Katerenchuk</keyname><forenames>Denys</forenames></author></authors><title>Age Group Classification with Speech and Metadata Multimodality Fusion</title><categories>cs.CL cs.SD eess.AS</categories><journal-ref>Proceedings of the 15th Conference of the European Chapter of the
  Association for Computational Linguistics: Volume 2, Short Papers, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Children comprise a significant proportion of TV viewers and it is worthwhile
to customize the experience for them. However, identifying who is a child in
the audience can be a challenging task. Identifying gender and age from audio
commands is a well-studied problem but is still very challenging to get good
accuracy when the utterances are typically only a couple of seconds long. We
present initial studies of a novel method which combines utterances with user
metadata. In particular, we develop an ensemble of different machine learning
techniques on different subsets of data to improve child detection. Our initial
results show a 9.2\% absolute improvement over the baseline, leading to a
state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00860</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00860</id><created>2018-03-02</created><authors><author><keyname>Lorenzo-Trueba</keyname><forenames>Jaime</forenames></author><author><keyname>Fang</keyname><forenames>Fuming</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Echizen</keyname><forenames>Isao</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author></authors><title>Can we steal your vocal identity from the Internet?: Initial
  investigation of cloning Obama's voice using GAN, WaveNet and low-quality
  found data</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>conference manuscript submitted to Speaker Odyssey 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Thanks to the growing availability of spoofing databases and rapid advances
in using them, systems for detecting voice spoofing attacks are becoming more
and more capable, and error rates close to zero are being reached for the
ASVspoof2015 database. However, speech synthesis and voice conversion paradigms
that are not considered in the ASVspoof2015 database are appearing. Such
examples include direct waveform modelling and generative adversarial networks.
We also need to investigate the feasibility of training spoofing systems using
only low-quality found data. For that purpose, we developed a generative
adversarial network-based speech enhancement system that improves the quality
of speech data found in publicly available sources. Using the enhanced data, we
trained state-of-the-art text-to-speech and voice conversion models and
evaluated them in terms of perceptual speech quality and speaker similarity.
The results show that the enhancement models significantly improved the SNR of
low-quality degraded data found in publicly available sources and that they
significantly improved the perceptual cleanliness of the source speech without
significantly degrading the naturalness of the voice. However, the results also
show limitations when generating speech with the low-quality found data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00862</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00862</id><created>2018-03-02</created><updated>2019-06-20</updated><authors><author><keyname>Hansen</keyname><forenames>Thomas Lundgaard</forenames></author><author><keyname>Jensen</keyname><forenames>Tobias Lindstr&#xf8;m</forenames></author></authors><title>A Fast Interior Point Method for Atomic Norm Soft Thresholding</title><categories>math.NA cs.NA eess.SP</categories><comments>31 pages, accepted for publication in Elsevier Signal Processing</comments><acm-class>G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The atomic norm provides a generalization of the $\ell_1$-norm to continuous
parameter spaces. When applied as a sparse regularizer for line spectral
estimation the solution can be obtained by solving a convex optimization
problem. This problem is known as atomic norm soft thresholding (AST). It can
be cast as a semidefinite program and solved by standard methods. In the
semidefinite formulation there are $O(N^2)$ dual variables which complicates
the implementation of a standard primal-dual interior-point method based on
symmetric cones. That has lead researcher to consider alternating direction
method of multipliers (ADMM) for the solution of AST, but this method is still
somewhat slow for large problem sizes. To obtain a faster algorithm we
reformulate AST as a non-symmetric conic program. That has two properties of
key importance to its numerical solution: the conic formulation has only $O(N)$
dual variables and the Toeplitz structure inherent to AST is preserved. Based
on it we derive FastAST which is a primal-dual interior point method for
solving AST. Two variants are considered with the fastest one requiring only
$O(N^2)$ flops per iteration. Extensive numerical experiments demonstrate that
FastAST solves AST significantly faster than a state-of-the-art solver based on
ADMM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00873</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00873</id><created>2018-03-02</created><authors><author><keyname>Amiri</keyname><forenames>Fahime</forenames></author><author><keyname>Kahaei</keyname><forenames>Mohammad Hossein.</forenames></author></authors><title>Using Spatial Correlation in Semi-Supervised Hyperspectral Unmixing
  under Polynomial Post-nonlinear Mixing Model</title><categories>eess.SP</categories><comments>29 pages, 11 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a semi-supervised hyperspectral unmixing solution that
integrate the spatial information in the abundance estimation procedure. The
proposed method is applied on a nonlinear model based on polynomial
postnonlinear mixing model where characterizes each pixel reflections composed
of nonlinear function of pure spectral signatures added by noise. We
partitioned the image to classes where contains similar materials so share the
same abundance vector. The spatial correlation between pixels belonging to each
class is modelled by Markov Random Field. A Bayesian framework is proposed to
estimate the classes and corresponding abundance vectors alternatively. We
proposed sparse Dirichlet prior for abundance vector that made it possible to
use this algorithm in semi-supervised scenario where the exact involved
materials are unknown. In this approach, we just need to have a large library
of pure spectral signatures including the desired materials. An MCMC algorithm
is used to estimate the abundance vector based on generated samples. The result
of implementation on simulated data shows the prominence of proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00886</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00886</id><created>2018-02-27</created><authors><author><keyname>Li</keyname><forenames>Lantian</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Chen</keyname><forenames>Yixiang</forenames></author><author><keyname>Shi</keyname><forenames>Ying</forenames></author><author><keyname>Tang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Zheng</keyname><forenames>Thomas Fang</forenames></author></authors><title>Deep factorization for speech signal</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted by ICASSP 2018. arXiv admin note: substantial text overlap
  with arXiv:1706.01777</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various informative factors mixed in speech signals, leading to great
difficulty when decoding any of the factors. An intuitive idea is to factorize
each speech frame into individual informative factors, though it turns out to
be highly difficult. Recently, we found that speaker traits, which were assumed
to be long-term distributional properties, are actually short-time patterns,
and can be learned by a carefully designed deep neural network (DNN). This
discovery motivated a cascade deep factorization (CDF) framework that will be
presented in this paper. The proposed framework infers speech factors in a
sequential way, where factors previously inferred are used as conditional
variables when inferring other factors. We will show that this approach can
effectively factorize speech signals, and using these factors, the original
speech spectrum can be recovered with a high accuracy. This factorization and
reconstruction approach provides potential values for many speech processing
tasks, e.g., speaker recognition and emotion recognition, as will be
demonstrated in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00969</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00969</id><created>2018-03-02</created><authors><author><keyname>Zafaruddin</keyname><forenames>S. M.</forenames></author><author><keyname>Plachy</keyname><forenames>Jan</forenames></author><author><keyname>Becvar</keyname><forenames>Zdenek</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author></authors><title>Energy Efficiency of Opportunistic Device-to-Device Relaying Under
  Lognormal Shadowing</title><categories>cs.IT eess.SP math.IT</categories><comments>30 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption is a major limitation of low power and mobile devices.
Efficient transmission protocols are required to minimize an energy consumption
of the mobile devices for ubiquitous connectivity in the next generation
wireless networks. Opportunistic schemes select a single relay using the
criteria of the best channel and achieve a near-optimal diversity performance
in a cooperative wireless system. In this paper, we study the energy efficiency
of the opportunistic schemes for device-to-device communication. In the
opportunistic approach, an energy consumed by devices is minimized by selecting
a single neighboring device as a relay using the criteria of minimum consumed
energy in each transmission in the uplink of a wireless network. We derive
analytical bounds and scaling laws on the expected energy consumption when the
devices experience log-normal shadowing with respect to a base station
considering both the transmission as well as circuit energy consumptions. We
show that the protocol improves the energy efficiency of the network comparing
to the direct transmission even if only a few devices are considered for
relaying. We also demonstrate the effectiveness of the protocol by means of
simulations in realistic scenarios of the wireless network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00978</identifier>
 <datestamp>2018-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00978</id><created>2018-03-02</created><updated>2018-10-12</updated><authors><author><keyname>Namor</keyname><forenames>Emil</forenames></author><author><keyname>Sossan</keyname><forenames>Fabrizio</forenames></author><author><keyname>Cherkaoui</keyname><forenames>Rachid</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Control of Battery Storage Systems for the Simultaneous Provision of
  Multiple Services</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a control framework for a battery energy storage
system to provide simultaneously multiple services to the electrical grid. The
objective is to maximise the battery exploitation from these services in the
presence of uncertainty (load, stochastic distributed generation, grid
frequency). The framework is structured in two phases. In a period-ahead phase,
we solve an optimization problem that allocates the battery power and energy
budgets to the different services. In the subsequent real-time phase the
control set-points for the deployment of such services are calculated
separately and superimposed. The control framework is first formulated in a
general way and then casted in the problem of providing dispatchability of a
medium voltage feeder in conjunction to primary frequency control. The
performance of the proposed framework are validated by simulations and
real-scale experi- ments, performed with a grid-connected 560 kWh/720 kVA
Li-ion battery energy storage system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.00980</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.00980</id><created>2018-03-02</created><updated>2018-12-20</updated><authors><author><keyname>Moore</keyname><forenames>Michael G.</forenames></author><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author></authors><title>Estimation of Poisson arrival processes under linear models</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of estimating the parameters of a
Poisson arrival process where the rate function is assumed to lie in the span
of a known basis. Our goal is to estimate the basis expansions coefficients
given a realization of this process. We establish novel guarantees concerning
the accuracy achieved by the maximum likelihood estimate. Our initial result is
near-optimal, with the exception of an undesirable dependence on the dynamic
range of the rate function. We then show how to remove this dependence through
a process of &quot;noise regularization&quot;, which results in an improved bound. We
conjecture that a similar guarantee should be possible when using a more direct
(deterministic) regularization scheme. We conclude with a discussion of
practical applications and an empirical examination of the proposed
regularization schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01000</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01000</id><created>2018-02-28</created><authors><author><keyname>Greco</keyname><forenames>Maria S.</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Stinco</keyname><forenames>Pietro</forenames></author><author><keyname>Bell</keyname><forenames>Kristine</forenames></author></authors><title>Cognitive Radars: A Reality?</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes some key ideas and applications of cognitive radars,
highlighting the limits and the path forward. Cognitive radars are systems
based on the perception-action cycle of cognition that sense the environment,
learn from it relevant information about the target and the background, then
adapt the radar sensor to optimally satisfy the needs of their mission
according to a desired goal. The concept of cognitive radar was introduced
originally for active radar only. In this paper we describe how this paradigm
can be applied also to passive radar. In particular, we describe (i) cognitive
active radars that work in a spectrally dense environment and change the
transmitted waveform on-the-fly to avoid interference with the primary user of
the channel, such as broadcast or communication systems, (ii) cognitive active
radars that adjust transmit waveform parameters to achieve a specified level of
target tracking performance, and (iii) cognitive passive radars, that contrary
to the active radars cannot directly change the transmitted waveforms, but can
instead select the best source of opportunity to improve detection and tracking
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01065</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01065</id><created>2018-03-02</created><authors><author><keyname>Ghose</keyname><forenames>Sarbani</forenames></author><author><keyname>Kundu</keyname><forenames>Chinmoy</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>Secrecy Outage of Proactive Relay Selection by Eavesdropper</title><categories>eess.SP</categories><comments>6 pages, 4 figures, conference- GLOBECOM 17</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider an active eavesdropping scenario in a cooperative
system consisting of a source, a destination, and an active eavesdropper with
multiple decode-and-forward relays. Considering an existing assumption in which
an eavesdropper is also a part of network, a proactive relay selection by the
eavesdropper is proposed. The best relay which maximizes the eavesdropping rate
is selected by the eavesdropper. A relay selection scheme is also proposed to
improve the secrecy of the system by minimizing the eavesdropping rate.
Performances of these schemes are compared with two passive eavesdropping
scenarios in which the eavesdropper performs selection and maximal ratio
combining on the relayed links. A realistic channel model with independent
non-identical links between nodes and direct links from the source to both the
destination and eavesdropper are assumed. Closed-form expressions for the
secrecy outage probability (SOP) of these schemes in Rayleigh fading channel
are obtained. It is shown that the relay selection by the proactive
eavesdropper is most detrimental to the system as not only the SOP increases
with the increase in the number of relays, but its diversity also remains
unchanged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01077</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01077</id><created>2018-03-02</created><authors><author><keyname>Abdel-Razeq</keyname><forenames>Sharief</forenames></author><author><keyname>Zhao</keyname><forenames>Ming</forenames></author><author><keyname>Zhou</keyname><forenames>Shengli</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>Optimization of a Two-Hop Network with Energy Conferencing Relays</title><categories>eess.SP</categories><comments>16 pages</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN), Vol.
  10, No. 1, pp. 35--50, February 2018</journal-ref><doi>10.5121/ijwmn.2018.10104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a two-hop network consisting of a source, two parallel
half-duplex relay nodes, and two destinations. While the destinations have an
adequate power supply, the source and relay nodes rely on harvested energy for
data transmission. Different from all existing works, the two relay nodes can
also transfer their harvested energy to each other. For such a system, an
optimization problem is formulated with the objective of maximizing the total
data rate and conserving the source and relays transmission energy, where any
extra energy saved in the current transmission cycle can be used in the next
cycle. It turns out that the optimal solutions for this problem can be either
found in a closed form or through one-dimensional searches, depending on the
scenario. Simulation results based on both the average data rate and the outage
probability show that energy cooperation between the two relays consistently
improves the system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01094</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01094</id><created>2018-03-02</created><updated>2018-05-25</updated><authors><author><keyname>Torfi</keyname><forenames>Amirsina</forenames></author></authors><title>SpeechPy - A Library for Speech Processing and Recognition</title><categories>cs.SD eess.AS</categories><journal-ref>Journal of Open Source Software, 3(27), 749, 2018</journal-ref><doi>10.21105/joss.00749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SpeechPy is an open source Python package that contains speech preprocessing
techniques, speech features, and important post-processing operations. It
provides most frequent used speech features including MFCCs and filterbank
energies alongside with the log-energy of filter-banks. The aim of the package
is to provide researchers with a simple tool for speech feature extraction and
processing purposes in applications such as Automatic Speech Recognition and
Speaker Verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01099</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01099</id><created>2018-03-02</created><authors><author><keyname>Zhu</keyname><forenames>Xia</forenames></author><author><keyname>Sengupta</keyname><forenames>Dipanjan</forenames></author><author><keyname>Beers</keyname><forenames>Andrew</forenames></author><author><keyname>Jayashree</keyname><forenames>Kalpathy-Cramer</forenames></author><author><keyname>Willke</keyname><forenames>Theodore L.</forenames></author></authors><title>Temporo-Spatial Collaborative Filtering for Parameter Estimation in
  Noisy DCE-MRI Sequences: Application to Breast Cancer Chemotherapy Response</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is a minimally
invasive imaging technique which can be used for characterizing tumor biology
and tumor response to radiotherapy. Pharmacokinetic (PK) estimation is widely
used for DCE-MRI data analysis to extract quantitative parameters relating to
microvascu- lature characteristics of the cancerous tissues. Unavoidable noise
corruption during DCE-MRI data acquisition has a large effect on the accuracy
of PK estimation. In this paper, we propose a general denoising paradigm called
gather- noise attenuation and reduce (GNR) and a novel temporal-spatial
collaborative filtering (TSCF) denoising technique for DCE-MRI data. TSCF takes
advantage of temporal correlation in DCE-MRI, as well as anatomical spatial
similar- ity to collaboratively filter noisy DCE-MRI data. The proposed TSCF
denoising algorithm decreases the PK parameter normalized estimation error by
57% and improves the structural similarity of PK parameter estimation by 86%
com- pared to baseline without denoising, while being an order of magnitude
faster than state-of-the-art denoising methods. TSCF improves the univariate
linear regression (ULR) c-statistic value for early prediction of pathologic
response up to 18%, and shows complete separation of pathologic complete
response (pCR) and non-pCR groups on a challenge dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01107</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01107</id><created>2018-03-03</created><authors><author><keyname>Xie</keyname><forenames>Jiang-jian</forenames></author><author><keyname>Ding</keyname><forenames>Chang-qing</forenames></author><author><keyname>Li</keyname><forenames>Wen-bin</forenames></author><author><keyname>Cai</keyname><forenames>Cheng-hao</forenames></author></authors><title>Audio-only Bird Species Automated Identification Method with Limited
  Training Data Based on Multi-Channel Deep Convolutional Neural Networks</title><categories>cs.SD eess.AS</categories><comments>11 pages,11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the transfer learning, we design a bird species identification model
that uses the VGG-16 model (pretrained on ImageNet) for feature extraction,
then a classifier consisting of two fully-connected hidden layers and a Softmax
layer is attached. We compare the performance of the proposed model with the
original VGG16 model. The results show that the former has higher train
efficiency, but lower mean average precisions(MAP). To improve the MAP of the
proposed model, we investigate the result fusion mode to form multi-channel
identification model, the best MAP reaches 0.9998. The number of model
parameters is 13110, which is only 0.0082% of the VGG16 model. Also, the size
demand of sample is decreased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01122</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01122</id><created>2018-03-03</created><authors><author><keyname>Tao</keyname><forenames>Fei</forenames></author><author><keyname>Liu</keyname><forenames>Gang</forenames></author><author><keyname>Zhao</keyname><forenames>Qingen</forenames></author></authors><title>An Ensemble Framework of Voice-Based Emotion Recognition System for
  Films and TV Programs</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Employing voice-based emotion recognition function in artificial intelligence
(AI) product will improve the user experience. Most of researches that have
been done only focus on the speech collected under controlled conditions. The
scenarios evaluated in these research were well controlled. The conventional
approach may fail when background noise or nonspeech filler exist. In this
paper, we propose an ensemble framework combining several aspects of features
from audio. The framework incorporates gender and speaker information relying
on multi-task learning. Therefore it is able to dig and capture emotional
information as much as possible. This framework is evaluated on multimodal
emotion challenge (MEC) 2017 corpus which is close to real world. The proposed
framework outperformed the best baseline system by 29.5% (relative
improvement).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01141</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01141</id><created>2018-03-03</created><authors><author><keyname>Almeida</keyname><forenames>Jefferson Jesus Hengles</forenames></author><author><keyname>Lopes</keyname><forenames>P. B.</forenames></author><author><keyname>Akamine</keyname><forenames>Cristiano</forenames></author><author><keyname>Omar</keyname><forenames>Nizam</forenames></author></authors><title>An Application of Neural Networks to Channel Estimation of the ISDB-TB
  FBMC System</title><categories>eess.SP</categories><report-no>AIRCC-42</report-no><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  10, No. 1, February 2018</journal-ref><doi>10.5121/ijwmn.2018.10107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the evolution of technology and the diffusion of digital television,
many researchers are studying more efficient transmission and reception
methods. This fact occurs because of the demand of transmitting videos with
better quality using new standards such 8K SUPER Hi-VISION. In this scenario,
modulation techniques such as Filter Bank Multi Carrier, associated with
advanced coding and synchronization methods, are being applied, aiming to
achieve the desired data rate to support ultra-high definition videos.
Simultaneously, it is also important to investigate ways of channel estimation
that enable a better reception of the transmitted signal. This task is not
always trivial, depending on the characteristics of the channel. Thus, the use
of artificial intelligence can contribute to estimate the channel frequency
response, from the transmitted pilots. A classical algorithm called
Back-propagation Training can be applied to find the channel equalizer
coefficients, making possible the correct reception of TV signals. Therefore,
this work presents a method of channel estimation that uses neural network
techniques to obtain the channel response in the Brazilian Digital System
Television, called ISDB-TB, using Filter Bank Multi Carrier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01170</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01170</id><created>2018-03-03</created><authors><author><keyname>Yang</keyname><forenames>Fuqian</forenames></author><author><keyname>Zhu</keyname><forenames>Hanyu</forenames></author><author><keyname>Shen</keyname><forenames>Cong</forenames></author><author><keyname>Dai</keyname><forenames>Linglong</forenames></author><author><keyname>Luo</keyname><forenames>Xiliang</forenames></author></authors><title>How to interconnect for Massive MIMO Self-Calibration?</title><categories>eess.SP</categories><comments>5 pages, 5 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In time-division duplexing (TDD) systems, massive multiple-input
multiple-output (MIMO) relies on the channel reciprocity to obtain the downlink
(DL) channel state information (CSI) with the acquired uplink (UL) CSI at the
base station (BS). However, the mismatches in the radio frequency (RF) analog
circuits at different antennas at the BS break the end-to-end UL and DL channel
reciprocity. To restore the channel reciprocity, it is necessary to calibrate
all the antennas at the BS. This paper addresses the interconnection strategy
for the internal self-calibration at the BS where different antennas are
interconnected via hardware transmission lines. Specifically, the paper reveals
the optimality of the star interconnection and the daisy chain interconnection
respectively. From the results, we see the star interconnection is the optimal
interconnection strategy when the BS are given the same number of measurements.
On the other hand, the daisy chain interconnection outperforms the star
interconnection when the same amount of time resources are consumed. Numerical
results corroborate our theoretical analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01183</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01183</id><created>2018-03-03</created><authors><author><keyname>Sai</keyname><forenames>Tutika Chetan</forenames></author><author><keyname>Kumar</keyname><forenames>G. Dinesh</forenames></author><author><keyname>Charan</keyname><forenames>V.</forenames></author><author><keyname>Ramya</keyname><forenames>S.</forenames></author></authors><title>Design of Automated Dual Band 4G Jammer using MATLAB Simulink</title><categories>eess.SP</categories><comments>6 pages, 2016 published</comments><journal-ref>Indian Journal of Science and Technology, Volume 9, Issue 37,
  October 2016</journal-ref><doi>10.17485/ijst/2016/v9i37/95125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a design of efficient smart jammer to jam the 4G signals,
specifically band 3 and band 40 which can be predominantly used in India. The
MATLAB Simulink tool was used for the analysis of the circuit design. Simulink,
an advanced tool gives accurate results comparable to real-time analysis. The
DSP toolbox of the Simulink library has been largely used to construct and view
the results of the model. The main objective of this paper is to receive the
LTE signals, filter band 3 and band 40, add noise and increase the amplitude of
the signal. The uniqueness of this design is the use of full wave rectifier in
the circuit and the trigger enabled blocks. Full wave rectifier with added
circuitry acts as a trigger to the jammer which contains the noise block and
the gain block. Sine wave generators were used to replicate real-time signals
and additional signals were added as noise. The advantage of the design is when
none of the bands are detected, the output will not be generated, thus saving
power. The incorporation of the detector circuit and trigger circuit ensures
that power is not wasted by the jamming circuit when the signal is not
detected. These jammers can be used in examination halls, conference halls and
in secure location where telecommunication signals are unwanted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01184</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01184</id><created>2018-03-03</created><authors><author><keyname>Kim</keyname><forenames>Jip</forenames></author><author><keyname>Dvorkin</keyname><forenames>Yury</forenames></author></authors><title>Enhancing Distribution Resilience with Mobile Energy Storage: A
  Progressive Hedging Approach</title><categories>eess.SP math.OC</categories><comments>Accepted for publication in the Proc. of the 2018 IEEE General
  Meeting in Portland, Oregon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrochemical energy storage (ES) units (e.g. batteries) have been
field-validated as an efficient back-up resource that enhance resilience of the
distribution system in case of natural disasters. However, using these units
for resilience is not sufficient to economically justify their installation
and, therefore, these units are often installed in locations where they incur
the greatest economic value during normal operations. Motivated by the recent
progress in transportable ES technologies, i.e. ES units can be moved using
public transportation routes, this paper proposes to use this spatial
flexibility to bridge the gap between the economically optimal locations during
normal operations and disaster-specific locations where extra back-up capacity
is necessary. We propose a two-stage optimization model that optimizes
investments in mobile ES units in the first stage and can re-route the
installed mobile ES units in the second stage to avoid the expected load
shedding caused by disaster forecasts. Since the proposed model cannot be
solved efficiently with off-the-shelf solvers, even for relatively small
instances, we apply a progressive hedging algorithm. The proposed model and
progressive hedging algorithm are tested through two illustrative examples on a
15-bus radial distribution test system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01211</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01211</id><created>2018-03-03</created><updated>2018-08-08</updated><authors><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Wagner</keyname><forenames>Martin R.</forenames></author><author><keyname>Bromberg</keyname><forenames>David M.</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Robust Power Flow and Three-Phase Power Flow Analyses</title><categories>eess.SP cs.CE</categories><comments>Accepted manuscript for IEEE Transactions on Power Systems (under
  review). arXiv admin note: text overlap with arXiv:1711.01471</comments><journal-ref>IEEE Transactions on Power Systems, 2018</journal-ref><doi>10.1109/TPWRS.2018.2863042</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust simulation is essential for reliable operation and planning of
transmission and distribution power grids. At present, disparate methods exist
for steady-state analysis of the transmission (power flow) and distribution
power grid (three-phase power flow). Due to the non-linear nature of the
problem, it is difficult for alternating current (AC) power flow and
three-phase power flow analyses to ensure convergence to the correct physical
solution, particularly from arbitrary initial conditions, or when evaluating a
change (e.g. contingency) in the grid. In this paper, we describe our
equivalent circuit formulation approach with current and voltage variables that
models both the positive sequence network of the transmission grid and
three-phase network of the distribution grid without loss of generality. The
proposed circuit models and formalism enable the extension and application of
circuit simulation techniques to solve for the steady-state solution with
excellent robustness of convergence. Examples for positive sequence
transmission and three-phase distribution systems, including actual 75k+ nodes
Eastern Interconnection transmission test cases and 8k+ nodes taxonomy
distribution test cases, are solved from arbitrary initial guesses to
demonstrate the efficacy of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01257</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01257</id><created>2018-03-03</created><updated>2018-11-16</updated><authors><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Huang</keyname><forenames>Kejun</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>Nonnegative Matrix Factorization for Signal and Data Analytics:
  Identifiability, Algorithms, and Applications</title><categories>eess.SP cs.LG stat.ML</categories><comments>accepted version, IEEE Signal Processing Magazine; supplementary
  materials added. Some minor revisions implemented</comments><doi>10.1109/MSP.2018.2877582</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonnegative matrix factorization (NMF) has become a workhorse for signal and
data analytics, triggered by its model parsimony and interpretability. Perhaps
a bit surprisingly, the understanding to its model identifiability---the major
reason behind the interpretability in many applications such as topic mining
and hyperspectral imaging---had been rather limited until recent years.
Beginning from the 2010s, the identifiability research of NMF has progressed
considerably: Many interesting and important results have been discovered by
the signal processing (SP) and machine learning (ML) communities. NMF
identifiability has a great impact on many aspects in practice, such as
ill-posed formulation avoidance and performance-guaranteed algorithm design. On
the other hand, there is no tutorial paper that introduces NMF from an
identifiability viewpoint. In this paper, we aim at filling this gap by
offering a comprehensive and deep tutorial on model identifiability of NMF as
well as the connections to algorithms and applications. This tutorial will help
researchers and graduate students grasp the essence and insights of NMF,
thereby avoiding typical `pitfalls' that are often times due to unidentifiable
NMF formulations. This paper will also help practitioners pick/design suitable
factorization tools for their own problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01319</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01319</id><created>2018-03-04</created><authors><author><keyname>Yashashwi</keyname><forenames>Kumar</forenames></author><author><keyname>Sethi</keyname><forenames>Amit</forenames></author><author><keyname>Chaporkar</keyname><forenames>Prasanna</forenames></author></authors><title>A Learnable Distortion Correction Module for Modulation Recognition</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modulation recognition is a challenging task while performing spectrum
sensing in a cognitive radio setup. Recently, the use of deep convolutional
neural networks (CNNs) has shown to achieve state-of-the-art accuracy for
modulation recognition \cite{survey}. However, a wireless channel distorts the
signal and CNNs are not explicitly designed to undo these artifacts. To improve
the performance of CNN-based recognition schemes we propose a signal distortion
correction module (CM) and show that this CM+CNN scheme achieves accuracy
better than the existing schemes. The proposed CM is also based on a neural
network that estimates the random carrier frequency and phase offset introduced
by the channel and feeds it to a part that undoes this distortion right before
CNN-based modulation recognition. Its output is differentiable with respect to
its weights, which allows it to be trained end-to-end with the modulation
recognition CNN based on the received signal. For supervision, only the
modulation scheme label is used and the knowledge of true frequency or phase
offset is not required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01339</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01339</id><created>2018-03-04</created><authors><author><keyname>Coteli</keyname><forenames>Mert Burkay</forenames></author><author><keyname>Olgun</keyname><forenames>Orhun</forenames></author><author><keyname>Hacihabiboglu</keyname><forenames>Huseyin</forenames></author></authors><title>Multiple Sound Source Localisation with Steered Response Power Density
  and Hierarchical Grid Refinement</title><categories>cs.SD cs.MM eess.AS</categories><comments>14 pages, 10 figures, 4 tables, submitted to IEEE/ACM Transactions on
  Audio, Speech and Language Processing (03 March 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of the direction-of-arrival (DOA) of sound sources is an important
step in sound field analysis. Rigid spherical microphone arrays allow the
calculation of a compact spherical harmonic representation of the sound field.
A basic method for analysing sound fields recorded using such arrays is steered
response power (SRP) maps wherein the source DOA can be estimated as the
steering direction that maximises the output power of a maximally-directive
beam. This approach is computationally costly since it requires steering the
beam in all possible directions. This paper presents an extension to SRP called
steered response power density (SRPD) and an associated, signal-adaptive search
method called hierarchical grid refinement (HiGRID) for reducing the number of
steering directions needed for DOA estimation. The proposed method can localise
coherent as well as incoherent sources while jointly providing the number of
prominent sources in the scene. It is shown to be robust to reverberation and
additive white noise. An evaluation of the proposed method using simulations
and real recordings under highly reverberant conditions as well as a comparison
with state- of-the-art methods are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01417</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01417</id><created>2018-03-04</created><updated>2018-06-09</updated><authors><author><keyname>Chen</keyname><forenames>Yuhua</forenames></author><author><keyname>Shi</keyname><forenames>Feng</forenames></author><author><keyname>Christodoulou</keyname><forenames>Anthony G.</forenames></author><author><keyname>Zhou</keyname><forenames>Zhengwei</forenames></author><author><keyname>Xie</keyname><forenames>Yibin</forenames></author><author><keyname>Li</keyname><forenames>Debiao</forenames></author></authors><title>Efficient and Accurate MRI Super-Resolution using a Generative
  Adversarial Network and 3D Multi-Level Densely Connected Network</title><categories>cs.CV eess.IV</categories><comments>10 pages, 2 figures, 2 tables. MICCAI 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-resolution (HR) magnetic resonance images (MRI) provide detailed
anatomical information important for clinical application and quantitative
image analysis. However, HR MRI conventionally comes at the cost of longer scan
time, smaller spatial coverage, and lower signal-to-noise ratio (SNR). Recent
studies have shown that single image super-resolution (SISR), a technique to
recover HR details from one single low-resolution (LR) input image, could
provide high-quality image details with the help of advanced deep convolutional
neural networks (CNN). However, deep neural networks consume memory heavily and
run slowly, especially in 3D settings. In this paper, we propose a novel 3D
neural network design, namely a multi-level densely connected super-resolution
network (mDCSRN) with generative adversarial network (GAN)-guided training. The
mDCSRN quickly trains and inferences and the GAN promotes realistic output
hardly distinguishable from original HR images. Our results from experiments on
a dataset with 1,113 subjects show that our new architecture beats other
popular deep learning methods in recovering 4x resolution-downgraded im-ages
and runs 6x faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01438</identifier>
 <datestamp>2018-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01438</id><created>2018-03-04</created><updated>2018-04-10</updated><authors><author><keyname>Andrich</keyname><forenames>Carsten</forenames></author><author><keyname>Ihlow</keyname><forenames>Alexander</forenames></author><author><keyname>Bauer</keyname><forenames>Julia</forenames></author><author><keyname>Beuster</keyname><forenames>Niklas</forenames></author><author><keyname>Del Galdo</keyname><forenames>Giovanni</forenames></author></authors><title>High-Precision Measurement of Sine and Pulse Reference Signals using
  Software-Defined Radio</title><categories>eess.SP</categories><comments>10 pages, 15 figures, and 4 tables</comments><journal-ref>IEEE Transactions on Instrumentation and Measurement, vol. 67, no.
  5, pp. 1132 - 1141, May 2018</journal-ref><doi>10.1109/TIM.2018.2794940</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses simultaneous, high-precision measurement and analysis of
generic reference signals by using inexpensive commercial off-the-shelf
Software Defined Radio hardware. Sine reference signals are digitally
down-converted to baseband for the analysis of phase deviations. Hereby, we
compare the precision of the fixed-point hardware Digital Signal Processing
chain with a custom Single Instruction Multiple Data (SIMD) x86 floating-point
implementation. Pulse reference signals are analyzed by a software trigger that
precisely locates the time where the slope passes a certain threshold. The
measurement system is implemented and verified using the Universal Software
Radio Peripheral (USRP) N210 by Ettus Research LLC. Applying standard 10 MHz
and 1 PPS reference signals for testing, a measurement precision (standard
deviation) of 0.36 ps and 16.6 ps is obtained, respectively. In connection with
standard PC hardware, the system allows long-term acquisition and storage of
measurement data over several weeks. A comparison is given to the Dual Mixer
Time Difference (DMTD) and Time Interval Counter (TIC), which are
state-of-the-art measurement methods for sine and pulse signal analysis,
respectively. Furthermore, we show that our proposed USRP-based approach
outperforms measurements with a high-grade Digital Sampling Oscilloscope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01488</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01488</id><created>2018-03-04</created><authors><author><keyname>Diao</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Bin</forenames></author></authors><title>Data fusion of multivariate time series: Application to noisy 12-lead
  ECG signals</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  12-lead ECG signals fusion is crucial for further ECG signal processing. In
this paper, a novel fusion data algorithm is proposed. In the method, 12-lead
ECG signals are appropriately converted to a single-lead physiological signal
via the idea of the local weighted linear prediction algorithm. For effectively
inheriting the quality characteristics of the 12-lead ECG signals, the fuzzy
inference system is rationally designed to estimate the weighted coefficient in
our algorithm. Experimental results indicate that the algorithm can obtain
desirable results on synthetic ECG signals, noisy ECG signals and realistic ECG
signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01526</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01526</id><created>2018-03-05</created><authors><author><keyname>Caciularu</keyname><forenames>Avi</forenames></author><author><keyname>Burshtein</keyname><forenames>David</forenames></author></authors><title>Blind Channel Equalization using Variational Autoencoders</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>Accepted to ICC workshop, Promises and Challenges of Machine Learning
  in Communication Networks (ML4COM), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new maximum likelihood estimation approach for blind channel equalization,
using variational autoencoders (VAEs), is introduced. Significant and
consistent improvements in the error rate of the reconstructed symbols,
compared to constant modulus equalizers, are demonstrated. In fact, for the
channels that were examined, the performance of the new VAE blind channel
equalizer was close to the performance of a nonblind adaptive linear minimum
mean square error equalizer. The new equalization method enables a
significantly lower latency channel acquisition compared to the constant
modulus algorithm (CMA). The VAE uses a convolutional neural network with two
layers and a very small number of free parameters. Although the computational
complexity of the new equalizer is higher compared to CMA, it is still
reasonable, and the number of free parameters to estimate is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01546</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01546</id><created>2018-03-05</created><authors><author><keyname>Bao</keyname><forenames>Peng</forenames></author><author><keyname>Zhou</keyname><forenames>Jiliu</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author></authors><title>Few-View CT Reconstruction with Group-Sparsity Regularization</title><categories>physics.med-ph eess.IV</categories><comments>submitted to IJNMBE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical total variation (TV) based iterative reconstruction algorithms
assume that the signal is piecewise smooth, which causes reconstruction results
to suffer from the over-smoothing effect. To address this problem, this work
presents a novel computed tomography (CT) reconstruction method for the
few-view problem called the group-sparsity regularization-based simultaneous
algebraic reconstruction technique (GSR-SART). Group-based sparse
representation, which utilizes the concept of a group as the basic unit of
sparse representation instead of a patch, is introduced as the image domain
prior regularization term to eliminate the over-smoothing effect. By grouping
the nonlocal patches into different clusters with similarity measured by
Euclidean distance, the sparsity and nonlocal similarity in a single image are
simultaneously explored. The split Bregman iteration algorithm is applied to
obtain the numerical scheme. Experimental results demonstrate that our method
both qualitatively and quantitatively outperforms several existing
reconstruction methods, including filtered back projection, expectation
maximization, SART, and TV-based projections onto convex sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01621</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01621</id><created>2018-03-05</created><updated>2020-01-27</updated><authors><author><keyname>Antonello</keyname><forenames>Niccol&#xf2;</forenames></author><author><keyname>Stella</keyname><forenames>Lorenzo</forenames></author><author><keyname>Patrinos</keyname><forenames>Panagiotis</forenames></author><author><keyname>van Waterschoot</keyname><forenames>Toon</forenames></author></authors><title>Proximal Gradient Algorithms: Applications in Signal Processing</title><categories>eess.SP math.OC</categories><comments>30 pages, 14 figures</comments><acm-class>G.1.6; I.2; D.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in numerical optimization have supported breakthroughs in several
areas of signal processing. This paper focuses on the recent enhanced variants
of the proximal gradient numerical optimization algorithm, which combine
quasi-Newton methods with forward-adjoint oracles to tackle large-scale
problems and reduce the computational burden of many applications. These
proximal gradient algorithms are here described in an easy-to-understand way,
illustrating how they are able to address a wide variety of problems arising in
signal processing. A new high-level modeling language is presented which is
used to demonstrate the versatility of the presented algorithms in a series of
signal processing application examples such as sparse deconvolution, total
variation denoising, audio de-clipping and others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01685</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01685</id><created>2018-02-25</created><updated>2018-03-08</updated><authors><author><keyname>Goldman</keyname><forenames>Gil</forenames></author><author><keyname>Salman</keyname><forenames>Yehonatan</forenames></author><author><keyname>Yomdin</keyname><forenames>Yosef</forenames></author></authors><title>Prony Scenarios and Error Amplification in a Noisy Spike-Train
  Reconstruction</title><categories>eess.SP</categories><comments>20 pages</comments><msc-class>44A60, 34A55, 34A37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to the characterization of the geometry of Prony curves
arising from spike-train signals. We give a sufficient condition which
guarantees the blowing up of the amplitudes of a Prony curve S in case where
some of its nodes tend to collide. We also give sufficient conditions on S
which guarantee a certain asymptotic behavior of its nodes near infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01710</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01710</id><created>2018-02-28</created><updated>2019-05-06</updated><authors><author><keyname>Liu</keyname><forenames>Gi-Ren</forenames></author><author><keyname>Lo</keyname><forenames>Yu-Lun</forenames></author><author><keyname>Malik</keyname><forenames>John</forenames></author><author><keyname>Sheu</keyname><forenames>Yuan-Chung</forenames></author><author><keyname>Wu</keyname><forenames>Hau-tieng</forenames></author></authors><title>Diffuse to fuse EEG spectra -- intrinsic geometry of sleep dynamics for
  classification</title><categories>eess.SP physics.data-an stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel algorithm for sleep dynamics visualization and automatic
annotation by applying diffusion geometry based sensor fusion algorithm to fuse
spectral information from two electroencephalograms (EEG). The diffusion
geometry approach helps organize the nonlinear dynamical structure hidden in
the EEG signal. The visualization is achieved by the nonlinear dimension
reduction capability of the chosen diffusion geometry algorithms. For the
automatic annotation purpose, the {support vector machine} is trained to
predict the sleep stage. The prediction performance is validated on a publicly
available benchmark database, Physionet Sleep-EDF [extended] SC$^*$ {(SC =
Sleep Cassette)} and ST$^*$ {(ST = Sleep Telemetry)}, with the
leave-one-subject-out cross validation. When we have a single EEG channel
(Fpz-Cz), the overall accuracy, macro F1 and Cohen's kappa achieve
$82.72\%$,$75.91\%$ and $76.1\%$ respectively in Sleep-EDF SC$^*$ and
$78.63\%$, $73.58\%$ and $69.48\%$ in Sleep-EDF ST$^*$. This performance is
compatible {with} the state-of-the-art results. When we have two EEG channels
(Fpz-Cz and Pz-Oz), the overall accuracy, macro F1 and Cohen's kappa achieve
$84.44\%$,$78.25\%$ and $78.36\%$ respectively in Sleep-EDF SC$^*$ and
$79.05\%$, $74.73\%$ and $70.31\%$ in Sleep-EDF ST$^*$. The results suggest the
potential of the proposed algorithm in practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01729</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01729</id><created>2018-03-02</created><updated>2018-05-16</updated><authors><author><keyname>Lum</keyname><forenames>Daniel J.</forenames></author><author><keyname>Knarr</keyname><forenames>Samuel H.</forenames></author><author><keyname>Howell</keyname><forenames>John C.</forenames></author></authors><title>Frequency-modulated continuous-wave LiDAR compressive depth-mapping</title><categories>eess.SP physics.app-ph physics.optics</categories><journal-ref>Opt. Express 26, 15420-15435 (2018)</journal-ref><doi>10.1364/OE.26.015420</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an inexpensive architecture for converting a frequency-modulated
continuous-wave LiDAR system into a compressive-sensing based depth-mapping
camera. Instead of raster scanning to obtain depth-maps, compressive sensing is
used to significantly reduce the number of measurements. Ideally, our approach
requires two difference detectors. % but can operate with only one at the cost
of doubling the number of measurments. Due to the large flux entering the
detectors, the signal amplification from heterodyne detection, and the effects
of background subtraction from compressive sensing, the system can obtain
higher signal-to-noise ratios over detector-array based schemes while scanning
a scene faster than is possible through raster-scanning. %Moreover, we show how
a single total-variation minimization and two fast least-squares minimizations,
instead of a single complex nonlinear minimization, can efficiently recover
high-resolution depth-maps with minimal computational overhead. Moreover, by
efficiently storing only $2m$ data points from $m&lt;n$ measurements of an $n$
pixel scene, we can easily extract depths by solving only two linear equations
with efficient convex-optimization methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01761</identifier>
 <datestamp>2018-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01761</id><created>2018-03-05</created><updated>2018-11-04</updated><authors><author><keyname>Sinno</keyname><forenames>Zeina</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>Large-Scale Study of Perceptual Video Quality</title><categories>eess.IV</categories><journal-ref>IEEE Transactions on Image Processing, vol. 28, no. 2, pp.
  612-627, Feb. 2019</journal-ref><doi>10.1109/TIP.2018.2869673</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The great variations of videographic skills, camera designs, compression and
processing protocols, and displays lead to an enormous variety of video
impairments. Current no-reference (NR) video quality models are unable to
handle this diversity of distortions. This is true in part because available
video quality assessment databases contain very limited content, fixed
resolutions, were captured using a small number of camera devices by a few
videographers and have been subjected to a modest number of distortions. As
such, these databases fail to adequately represent real world videos, which
contain very different kinds of content obtained under highly diverse imaging
conditions and are subject to authentic, often commingled distortions that are
impossible to simulate. As a result, NR video quality predictors tested on
real-world video data often perform poorly. Towards advancing NR video quality
prediction, we constructed a large-scale video quality assessment database
containing 585 videos of unique content, captured by a large number of users,
with wide ranges of levels of complex, authentic distortions. We collected a
large number of subjective video quality scores via crowdsourcing. A total of
4776 unique participants took part in the study, yielding more than 205000
opinion scores, resulting in an average of 240 recorded human opinions per
video. We demonstrate the value of the new resource, which we call the LIVE
Video Quality Challenge Database (LIVE-VQC), by conducting a comparison of
leading NR video quality predictors on it. This study is the largest video
quality assessment study ever conducted along several key dimensions: number of
unique contents, capture devices, distortion types and combinations of
distortions, study participants, and recorded subjective scores. The database
is available for download on this link:
http://live.ece.utexas.edu/research/LIVEVQC/index.html .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01841</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01841</id><created>2018-03-03</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author></authors><title>Enhancement of Noisy Speech exploiting a Gaussian Modeling based
  Threshold and a PDF Dependent Thresholding Function</title><categories>eess.AS cs.SD</categories><comments>22 pages, 18 figures, 8 tables; submitted to EURASIP Journal on
  Audio, Speech, and Music Processing. arXiv admin note: substantial text
  overlap with arXiv:1802.05962; text overlap with arXiv:1802.03472</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a speech enhancement method, where an adaptive threshold
is statistically determined based on Gaussian modeling of Teager energy (TE)
operated perceptual wavelet packet (PWP) coefficients of noisy speech. In order
to obtain an enhanced speech, the threshold thus derived is applied upon the
PWP coefficients by employing a Gaussian pdf dependent custom thresholding
function, which is designed based on a combination of modified hard and
semisoft thresholding functions. The effectiveness of the proposed method is
evaluated for car and multi-talker babble noise corrupted speech signals
through performing extensive simulations using the NOIZEUS database. The
proposed method is found to outperform some of the state-of-the-art speech
enhancement methods not only at at high but also at low levels of SNRs in the
sense of standard objective measures and subjective evaluations including
formal listening tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01885</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01885</id><created>2018-03-05</created><updated>2018-03-25</updated><authors><author><keyname>Zhang</keyname><forenames>Shan</forenames></author><author><keyname>Liu</keyname><forenames>Sijia</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Optimal Sensor Collaboration for Parameter Tracking Using Energy
  Harvesting Sensors</title><categories>eess.SP</categories><doi>10.1109/TSP.2018.2827319</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we design an optimal sensor collaboration strategy among
neighboring nodes while tracking a time-varying parameter using wireless sensor
networks in the presence of imperfect communication channels. The sensor
network is assumed to be self-powered, where sensors are equipped with energy
harvesters that replenish energy from the environment. In order to minimize the
mean square estimation error of parameter tracking, we propose an online sensor
collaboration policy subject to real-time energy harvesting constraints. The
proposed energy allocation strategy is computationally light and only relies on
the second-order statistics of the system parameters. For this, we first
consider an offline non-convex optimization problem, which is solved exactly
using semidefinite programming. Based on the offline solution, we design an
online power allocation policy that requires minimal online computation and
satisfies the dynamics of energy flow at each sensor. We prove that the
proposed online policy is asymptotically equivalent to the optimal offline
solution and show its convergence rate and robustness. We empirically show that
the estimation performance of the proposed online scheme is better than that of
the online scheme when channel state information about the dynamical system is
available in the low SNR regime. Numerical results are conducted to demonstrate
the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01895</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01895</id><created>2018-03-05</created><updated>2018-03-19</updated><authors><author><keyname>Duarte</keyname><forenames>Azucena</forenames></author><author><keyname>Sampaio-Neto</keyname><forenames>Raimundo</forenames></author></authors><title>Precoding and Spatial Modulation in the Downlink of MU-MIMO Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work focuses on the downlink communication of a multiuser MIMO system
where the base station antennas and the users' receiving antennas are all
active, but at each transmission, only a subset of the receive antennas is
selected by the base station to receive the information symbols, and the
particular chosen subset (pattern) represents part of the information conveyed
to the user. In this paper we present a mathematical model for the system and
develop expressions that are fairly general and adequate for its analysis.
Based on these expressions we propose a procedure to optimize the choice by the
ERB of the sets of antenna patterns to be used in the transmissions to the
different users, aiming at the maximization of the detection signal-to-noise
ratio. Performance results, with and without the optimization procedure, are
presented for different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01897</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01897</id><created>2018-03-05</created><updated>2018-07-22</updated><authors><author><keyname>Khodabandehlou</keyname><forenames>Hamid</forenames></author></authors><title>Adaptive Matching Pursuit based Online Identification and Control Scheme
  for Nonlinear Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of adaptive control of nonlinear time-varying systems requires
the use of novel methods that have lower computational complexity as well as
ensuring good performance under time-varying parameter changes. In this study,
we use adaptive matching pursuit algorithm with wavelet bases for an online
identification and control of the nonlinear system with time-varying
parameters. We apply the proposed online identification and control scheme to
two different benchmark examples of nonlinear system identification and
control. Simulation results show that the proposed algorithm, using adaptive
matching pursuit with wavelet bases, can effectively identify and control the
nonlinear system even in presence of time-varying parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.01980</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.01980</id><created>2018-03-05</created><authors><author><keyname>Pfister</keyname><forenames>Luke</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>Learning Filter Bank Sparsifying Transforms</title><categories>stat.ML cs.LG eess.SP</categories><doi>10.1109/TSP.2018.2883021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data is said to follow the transform (or analysis) sparsity model if it
becomes sparse when acted on by a linear operator called a sparsifying
transform. Several algorithms have been designed to learn such a transform
directly from data, and data-adaptive sparsifying transforms have demonstrated
excellent performance in signal restoration tasks. Sparsifying transforms are
typically learned using small sub-regions of data called patches, but these
algorithms often ignore redundant information shared between neighboring
patches.
  We show that many existing transform and analysis sparse representations can
be viewed as filter banks, thus linking the local properties of patch-based
model to the global properties of a convolutional model. We propose a new
transform learning framework where the sparsifying transform is an undecimated
perfect reconstruction filter bank. Unlike previous transform learning
algorithms, the filter length can be chosen independently of the number of
filter bank channels. Numerical results indicate filter bank sparsifying
transforms outperform existing patch-based transform learning for image
denoising while benefiting from additional flexibility in the design process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02026</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02026</id><created>2018-03-06</created><authors><author><keyname>Mohammadian</keyname><forenames>Amirhossein</forenames></author><author><keyname>Mohammadi</keyname><forenames>Abbas</forenames></author><author><keyname>Abdipour</keyname><forenames>Abdolali</forenames></author><author><keyname>Baghani</keyname><forenames>Mina</forenames></author></authors><title>Spectral Analysis of GFDM Modulated Signal under Nonlinear Behavior of
  Power Amplifier</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General frequency division multiplexing (GFDM) is a flexible non-orthogonal
waveform candidate for 5G which can offer some advantages such as low
out-of-band (OOB) emission and high spectral efficiency. In this paper, the
effects of nonlinear behavior of practical PAs on GFDM signal are studied. In
the first step, a closed form expression for power spectral density (PSD) of
GFDM signal is extracted. Then, the PSD at the output of PA as a function of
input power and the coefficients of nonlinear polynomial PA model is derived.
In addition, the adjacent channel power (ACP) and ACP ratio, as two important
performance metrics, are evaluated. The simulation results confirm the accuracy
of derived analytical expressions. Moreover, to validate the performance of
GFDM modulation after nonlinear PA, it is compared with OFDM modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02084</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02084</id><created>2018-03-06</created><authors><author><keyname>Tom&#xe9;</keyname><forenames>Mauricio C.</forenames></author><author><keyname>Nardelli</keyname><forenames>Pedro H. J.</forenames></author><author><keyname>Alves</keyname><forenames>Hirley</forenames></author></authors><title>Long-range Low-power Wireless Networks and Sampling Strategies in
  Electricity Metering</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a specific low-power wireless technology capable of
reaching a long range, namely LoRa. Such a technology can be used by different
applications in cities involving many transmitting devices while requiring
loose communication constrains. We focus on electricity grids, where LoRa
end-devices are smart-meters that send the average power demanded by their
respective households during a given period. The successfully decoded data by
the LoRa gateway are used by an aggregator to reconstruct the daily households'
profiles. We show how the interference from concurrent transmissions from both
LoRa and non-LoRa devices negatively affect the communication outage
probability and the link effective bit-rate. Besides, we use actual electricity
consumption data to compare time-based and event-based sampling strategies,
showing the advantages of the latter. We then employ this analysis to assess
the gateway range that achieves an average outage probability that leads to a
signal reconstruction with a given requirement. We also discuss that, although
the proposed analysis focuses on electricity metering, it can be easily
extended to any other smart city application with similar requirements, like
water metering or traffic monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02089</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02089</id><created>2018-03-06</created><authors><author><keyname>Xu</keyname><forenames>Dongyang</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Ritcey</keyname><forenames>James A.</forenames></author></authors><title>Optimal Independence-Checking Coding For Secure Uplink Training in
  Large-Scale MISO-OFDM Systems</title><categories>eess.SP</categories><comments>accepted in IEEE International Conference on Communications 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the publicly-known deterministic character- istic of pilot tones,
pilot-aware attack, by jamming, nulling and spoofing pilot tones, can
significantly paralyze the uplink channel training in large-scale MISO-OFDM
systems. To solve this, we in this paper develop an independence-checking
coding based (ICCB) uplink training architecture for one-ring scattering
scenarios allowing for uniform linear arrays (ULA) deployment. Here, we not
only insert randomized pilots on subcarriers for channel impulse response (CIR)
estimation, but also diversify and encode subcarrier activation patterns (SAPs)
to convey those pilots simultaneously. The coded SAPs, though interfered by
arbitrary unknown SAPs in wireless environment, are qualified to be reliably
identified and decoded into the original pilots by checking the hidden channel
independence existing in subcarri- ers. Specifically, an independence-checking
coding (ICC) theory is formulated to support the encoding/decoding process in
this architecture. The optimal ICC code is further developed for guaranteeing a
well-imposed estimation of CIR while maximizing the code rate. Based on this
code, the identification error probability (IEP) is characterized to evaluate
the reliability of this architecture. Interestingly, we discover the principle
of IEP reduction by exploiting the array spatial correlation, and prove that
zero-IEP, i.e., perfect reliability, can be guaranteed under
continuously-distributed mean angle of arrival (AoA). Besides this, a novel
closed form of IEP expression is derived in discretely- distributed case.
Simulation results finally verify the effectiveness of the proposed
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02112</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02112</id><created>2018-03-06</created><updated>2018-06-21</updated><authors><author><keyname>Cruz</keyname><forenames>Crist&#xf3;v&#xe3;o</forenames></author><author><keyname>Foi</keyname><forenames>Alessandro</forenames></author><author><keyname>Katkovnik</keyname><forenames>Vladimir</forenames></author><author><keyname>Egiazarian</keyname><forenames>Karen</forenames></author></authors><title>Nonlocality-Reinforced Convolutional Neural Networks for Image Denoising</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in IEEE SPL</comments><doi>10.1109/LSP.2018.2850222</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a paradigm for nonlocal sparsity reinforced deep convolutional
neural network denoising. It is a combination of a local multiscale denoising
by a convolutional neural network (CNN) based denoiser and a nonlocal denoising
based on a nonlocal filter (NLF) exploiting the mutual similarities between
groups of patches. CNN models are leveraged with noise levels that
progressively decrease at every iteration of our framework, while their output
is regularized by a nonlocal prior implicit within the NLF. Unlike complicated
neural networks that embed the nonlocality prior within the layers of the
network, our framework is modular, it uses standard pre-trained CNNs together
with standard nonlocal filters. An instance of the proposed framework, called
NN3D, is evaluated over large grayscale image datasets showing state-of-the-art
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02219</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02219</id><created>2018-03-06</created><updated>2018-09-06</updated><authors><author><keyname>Rajam&#xe4;ki</keyname><forenames>Robin</forenames></author><author><keyname>Koivunen</keyname><forenames>Visa</forenames></author></authors><title>Sparse Active Rectangular Array with Few Closely Spaced Elements</title><categories>eess.SP</categories><comments>4+1 pages, 5 figures, 1 table</comments><msc-class>11B13</msc-class><doi>10.1109/LSP.2018.2876066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse sensor arrays offer a cost effective alternative to uniform arrays. By
utilizing the co-array, a sparse array can match the performance of a filled
array, despite having significantly fewer sensors. However, even sparse arrays
can have many closely spaced elements, which may deteriorate the array
performance in the presence of mutual coupling. This paper proposes a novel
sparse planar array configuration with few unit inter-element spacings. This
Concentric Rectangular Array (CRA) is designed for active sensing tasks, such
as microwave or ultra-sound imaging, in which the same elements are used for
both transmission and reception. The properties of the CRA are compared to two
well-known sparse geometries: the Boundary Array and the Minimum-Redundancy
Array (MRA). Numerical searches reveal that the CRA is the MRA with the fewest
unit element displacements for certain array dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02247</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02247</id><created>2018-03-06</created><authors><author><keyname>Gama</keyname><forenames>Fernando</forenames></author><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>MIMO Graph Filters for Convolutional Neural Networks</title><categories>cs.LG eess.SP stat.ML</categories><comments>Submitted to 19th IEEE International Workshop on Signal Processing
  Advances in Wireless Communications (SPAWC 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superior performance and ease of implementation have fostered the adoption of
Convolutional Neural Networks (CNNs) for a wide array of inference and
reconstruction tasks. CNNs implement three basic blocks: convolution, pooling
and pointwise nonlinearity. Since the two first operations are well-defined
only on regular-structured data such as audio or images, application of CNNs to
contemporary datasets where the information is defined in irregular domains is
challenging. This paper investigates CNNs architectures to operate on signals
whose support can be modeled using a graph. Architectures that replace the
regular convolution with a so-called linear shift-invariant graph filter have
been recently proposed. This paper goes one step further and, under the
framework of multiple-input multiple-output (MIMO) graph filters, imposes
additional structure on the adopted graph filters, to obtain three new (more
parsimonious) architectures. The proposed architectures result in a lower
number of model parameters, reducing the computational complexity, facilitating
the training, and mitigating the risk of overfitting. Simulations show that the
proposed simpler architectures achieve similar performance as more complex
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02353</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02353</id><created>2018-03-06</created><authors><author><keyname>Yu</keyname><forenames>Changsong</forenames></author><author><keyname>Barsim</keyname><forenames>Karim Said</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author></authors><title>Multi-level Attention Model for Weakly Supervised Audio Classification</title><categories>eess.AS cs.SD</categories><comments>5 pages, 3 figures, Submitted to Eusipco 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a multi-level attention model to solve the weakly
labelled audio classification problem. The objective of audio classification is
to predict the presence or absence of audio events in an audio clip. Recently,
Google published a large scale weakly labelled dataset called Audio Set, where
each audio clip contains only the presence or absence of the audio events,
without the onset and offset time of the audio events. Our multi-level
attention model is an extension to the previously proposed single-level
attention model. It consists of several attention modules applied on
intermediate neural network layers. The output of these attention modules are
concatenated to a vector followed by a multi-label classifier to make the final
prediction of each class. Experiments shown that our model achieves a mean
average precision (mAP) of 0.360, outperforms the state-of-the-art single-level
attention model of 0.327 and Google baseline of 0.314.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02421</identifier>
 <datestamp>2019-03-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02421</id><created>2018-03-06</created><updated>2019-03-23</updated><authors><author><keyname>Medhat</keyname><forenames>Fady</forenames></author><author><keyname>Chesmore</keyname><forenames>David</forenames></author><author><keyname>Robinson</keyname><forenames>John</forenames></author></authors><title>Masked Conditional Neural Networks for Audio Classification</title><categories>stat.ML cs.LG cs.SD eess.AS</categories><comments>Restricted BoltzmannMachine, RBM, Conditional Restricted Boltzmann
  Machine, CRBM, Music Information Retrieval, MIR, Conditional Neural Network,
  CLNN, Masked Conditional Neural Network, MCLNN, Deep Neural Network</comments><journal-ref>International Conference on Artificial Neural Networks (ICANN)
  Year: 2017</journal-ref><doi>10.1007/978-3-319-68612-7_40</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL
Neural Network (MCLNN) designed for temporal signal recognition. The CLNN takes
into consideration the temporal nature of the sound signal and the MCLNN
extends upon the CLNN through a binary mask to preserve the spatial locality of
the features and allows an automated exploration of the features combination
analogous to hand-crafting the most relevant features for the recognition task.
MCLNN has achieved competitive recognition accuracies on the GTZAN and the
ISMIR2004 music datasets that surpass several state-of-the-art neural network
based architectures and hand-crafted methods applied on both datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02445</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02445</id><created>2018-03-05</created><authors><author><keyname>Huang</keyname><forenames>Zhiying</forenames></author><author><keyname>Lu</keyname><forenames>Heng</forenames></author><author><keyname>Lei</keyname><forenames>Ming</forenames></author><author><keyname>Yan</keyname><forenames>Zhijie</forenames></author></authors><title>Linear networks based speaker adaptation for speech synthesis</title><categories>eess.AS cs.SD</categories><comments>5 pages, 6 figures, accepted by ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker adaptation methods aim to create fair quality synthesis speech voice
font for target speakers while only limited resources available. Recently, as
deep neural networks based statistical parametric speech synthesis (SPSS)
methods become dominant in SPSS TTS back-end modeling, speaker adaptation under
the neural network based SPSS framework has also became an important task. In
this paper, linear networks (LN) is inserted in multiple neural network layers
and fine-tuned together with output layer for best speaker adaptation
performance. When adaptation data is extremely small, the low-rank plus
diagonal(LRPD) decomposition for LN is employed to make the adapted voice more
stable. Speaker adaptation experiments are conducted under a range of
adaptation utterances numbers. Moreover, speaker adaptation from 1) female to
female, 2) male to female and 3) female to male are investigated. Objective
measurement and subjective tests show that LN with LRPD decomposition performs
most stable when adaptation data is extremely limited, and our best speaker
adaptation (SA) model with only 200 adaptation utterances achieves comparable
quality with speaker dependent (SD) model trained with 1000 utterances, in both
naturalness and similarity to target speaker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02494</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02494</id><created>2018-03-06</created><authors><author><keyname>Gencel</keyname><forenames>Muhammed Faruk</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author><author><keyname>Hespanha</keyname><forenames>Joao Pedro</forenames></author></authors><title>RF Source Seeking using Frequency Measurements</title><categories>eess.SP</categories><comments>Submitted to IEEE SPAWC 2018, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a problem motivated by search-and-rescue
applications, where an unmanned aerial vehicle (UAV) seeks to approach the
vicinity of a distant quasi-stationary radio frequency (RF) emitter surrounded
by local scatterers. The UAV employs only measurements of the Doppler frequency
of the received RF signal, along with its own bearing, to continuously adapt
its trajectory. We propose and evaluate a trajectory planning approach that
addresses technical difficulties such as the unknown carrier frequency offset
between the emitter and the UAV's receiver, the frequency drifts of the local
oscillators over time, the direction ambiguity in Doppler, and the noise in the
observations. For the initial trajectory, the UAV estimates the direction of
the emitter using a circular motion, which resolves direction ambiguity. The
trajectory is then continuously adapted using feedback from frequency
measurements obtained by perturbing the bearing around the current trajectory.
We show that the proposed algorithm converges to the vicinity of the emitter,
and illustrate its efficacy using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02551</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02551</id><created>2018-03-07</created><authors><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Extracting Domain Invariant Features by Unsupervised Learning for Robust
  Automatic Speech Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS stat.ML</categories><comments>accepted by 2018 International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of automatic speech recognition (ASR) systems can be
significantly compromised by previously unseen conditions, which is typically
due to a mismatch between training and testing distributions. In this paper, we
address robustness by studying domain invariant features, such that domain
information becomes transparent to ASR systems, resolving the mismatch problem.
Specifically, we investigate a recent model, called the Factorized Hierarchical
Variational Autoencoder (FHVAE). FHVAEs learn to factorize sequence-level and
segment-level attributes into different latent variables without supervision.
We argue that the set of latent variables that contain segment-level
information is our desired domain invariant feature for ASR. Experiments are
conducted on Aurora-4 and CHiME-4, which demonstrate 41% and 27% absolute word
error rate reductions respectively on mismatched domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02652</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02652</id><created>2018-03-07</created><authors><author><keyname>Doelman</keyname><forenames>Reinier</forenames></author><author><keyname>Nguyen</keyname><forenames>H. Thao</forenames></author><author><keyname>Verhaegen</keyname><forenames>Michel</forenames></author></authors><title>Solving large-scale general phase retrieval problems via a sequence of
  convex relaxations</title><categories>math.OC eess.SP</categories><doi>10.1364/JOSAA.35.001410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a convex relaxation-based algorithm for large-scale general phase
retrieval problems. General phase retrieval problems include i.a. the
estimation of the phase of the optical field in the pupil plane based on
intensity measurements of a point source recorded in the image (focal) plane.
The non-convex problem of finding the complex field that generates the correct
intensity is reformulated into a rank constraint problem. The nuclear norm is
used to obtain the convex relaxation of the phase retrieval problem. A new
iterative method, indicated as Convex Optimization-based Phase Retrieval
(COPR), is presented, with each iteration consisting of solving a convex
problem. In the noise-free case and for a class of phase retrieval problems the
solutions of the minimization problems converge linearly or faster towards a
correct solution. Since the solutions to nuclear norm minimization problems can
be computed using semidefinite programming, and this tends to be an expensive
optimization in terms of scalability, we provide a fast ADMM algorithm that
exploits the problem structure. The performance of the COPR algorithm is
demonstrated in a realistic numerical simulation study, demonstrating its
improvements in reliability and speed with respect to state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02670</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02670</id><created>2018-03-02</created><authors><author><keyname>Amiri</keyname><forenames>Fahime</forenames></author><author><keyname>Kahaei</keyname><forenames>Mohammad Hossein</forenames></author></authors><title>Bayesian Unmixing using Sparse Dirichlet Prior with Polynomial
  Post-nonlinear Mixing Model</title><categories>eess.SP</categories><comments>2 pages, 3 figures&quot;. arXiv admin note: substantial text overlap with
  arXiv:1803.00873</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sparse Dirichlet prior is proposed for estimating the abundance vector of
hyperspectral images with a nonlinear mixing model. This sparse prior is led to
an unmixing procedure in a semi-supervised scenario in which exact materials
are unknown. The nonlinear model is a polynomial post-nonlinear mixing model
that represents each hyperspectral pixel as a nonlinear function of pure
spectral signatures corrupted by additive white noise. Simulation results show
more than 50% improvement in the estimation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02681</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02681</id><created>2018-03-03</created><authors><author><keyname>Bragin</keyname><forenames>Mikhail</forenames></author><author><keyname>Dvorkin</keyname><forenames>Yury</forenames></author></authors><title>Toward Coordinated Transmission and Distribution Operations</title><categories>eess.SP</categories><comments>Accepted for publication in the Proc. of the 2018 IEEE General
  Meeting in Portland, Oregon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proliferation of smart grid technologies has enhanced observability and
controllability of distribution systems. If coordinated with the transmission
system, resources of both systems can be used more efficiently. This paper
proposes a model to operate transmission and distribution systems in a
coordinated manner. The proposed model is solved using a Surrogate Lagrangian
Relaxation (SLR) approach. The computational performance of this approach is
compared against existing methods (e.g. subgradient method). Finally, the
usefulness of the proposed model and solution approach is demonstrated via
numerical experiments on the illustrative example and IEEE benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02684</identifier>
 <datestamp>2018-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02684</id><created>2018-03-07</created><authors><author><keyname>Czech</keyname><forenames>Daniel</forenames></author><author><keyname>Mishra</keyname><forenames>Amit</forenames></author><author><keyname>Inggs</keyname><forenames>Michael</forenames></author></authors><title>A CNN and LSTM-Based Approach to Classifying Transient Radio Frequency
  Interference</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transient radio frequency interference (RFI) is detrimental to radio
astronomy. It is particularly difficult to identify the sources of transient
RFI, which is broadband and intermittent. Such RFI is often generated by
devices like mechanical relays, fluorescent lighting or AC machines, which may
be present in the surrounding infrastructure of a radio telescope array. One
mitigating approach is to deploy independent RFI monitoring stations at radio
telescope arrays. Once the sources of RFI signals are identified, they may be
removed or replaced where possible. For the first time in the open literature,
we demonstrate an approach to classifying the sources of transient RFI (in time
domain data) that makes use of deep learning techniques including CNNs and
LSTMs. Applied to a previously obtained dataset of experimentally recorded
transient RFI signals, our proposed approach offers good results. It shows
potential for development into a tool for identifying the sources of transient
RFI signals recorded by independent RFI monitoring stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02695</identifier>
 <datestamp>2018-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02695</id><created>2018-03-06</created><updated>2018-11-12</updated><authors><author><keyname>Daly</keyname><forenames>Donnacha</forenames></author><author><keyname>Sornette</keyname><forenames>Didier</forenames></author></authors><title>The Altes Family of Log-Periodic Chirplets and the Hyperbolic Chirplet
  Transform</title><categories>eess.SP physics.data-an</categories><comments>14 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work revisits a class of biomimetically inspired log-periodic waveforms
first introduced by R.A. Altes in the 1970s for generalized target description.
It was later observed that there is a close connection between such sonar
techniques and wavelet decomposition for multiresolution analysis. Motivated by
this, we formalize the original Altes waveforms as a family of hyperbolic
chirplets suitable for the detection of accelerating time-series oscillations.
The formalism results in a remarkably flexible set of wavelets with desirable
properties of admissibility, regularity, vanishing moments, and time-frequency
localization. These &quot;Altes wavelets&quot; also facilitate efficient implementation
of the scale invariant hyperbolic chirplet transform (HCT).
  From a practical perspective, log-periodic oscillations with an acceleration
towards criticality can serve as indicators of an incipient bifurcation. Such
signals abound in nature, often as precursors to phase transitions in the
non-linear dynamics of complex systems. For example, the authors' interest lies
in automatic detection of the well documented phenomenon of log-periodic price
dynamics during financial bubbles and preceding market crashes. However, the
methodology presented here is more widely applicable in such diverse domains as
prediction of critical failures in mechanical systems, and fault detection in
electrical networks. Examples beyond failure diagnostics include animal species
identification via call recordings, commercial \&amp; military radar, and there are
many more. A synthetic application is presented in this report for illustrative
purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02870</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02870</id><created>2018-03-03</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Saha</keyname><forenames>Udoy</forenames></author><author><keyname>Shahid</keyname><forenames>K. T.</forenames></author><author><keyname>Hussain</keyname><forenames>Ahmed Bin</forenames></author><author><keyname>Shahnaz</keyname><forenames>Celia</forenames></author></authors><title>Speech Enhancement Based on Non-stationary Noise-driven Geometric
  Spectral Subtraction and Phase Spectrum Compensation</title><categories>eess.AS cs.SD</categories><comments>13 pages, 10 figures, 8 tables. arXiv admin note: substantial text
  overlap with arXiv:1803.00396; text overlap with arXiv:1802.02665,
  arXiv:1802.05125, arXiv:1803.01841</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a speech enhancement method based on noise compensation
performed on short time magnitude as well phase spectra is presented. Unlike
the conventional geometric approach (GA) to spectral subtraction (SS), here the
noise estimate to be subtracted from the noisy speech spectrum is proposed to
be determined by exploiting the low frequency regions of current frame of noisy
speech rather than depending only on the initial silence frames. This approach
gives the capability of tracking non-stationary noise thus resulting in a
non-stationary noise-driven geometric approach of spectral subtraction for
speech enhancement. The noise compensated magnitude spectrum from the GA step
is then recombined with unchanged phase of noisy speech spectrum and used in
phase compensation to obtain an enhanced complex spectrum, which is used to
produce an enhanced speech frame. Extensive simulations are carried out using
speech files available in the NOIZEUS database shows that the proposed method
consistently outperforms some of the recent methods of speech enhancement when
employed on the noisy speeches corrupted by street or babble noise at different
levels of SNR in terms of objective measures, spectrogram analysis and formal
subjective listening tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02908</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02908</id><created>2018-03-07</created><authors><author><keyname>Ibraheem</keyname><forenames>Ibraheem Kasim</forenames></author><author><keyname>Abdul-Adheem</keyname><forenames>Wameedh Riyadh</forenames></author></authors><title>On the Improved Nonlinear Tracking Differentiator based Nonlinear PID
  Controller Design</title><categories>math.OC eess.SP</categories><journal-ref>(IJACSA) International Journal of Advanced Computer Science and
  Applications, Vol. 7, No. 10, 2016</journal-ref><doi>10.14569/IJACSA.2016.071032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new improved nonlinear tracking differentiator (INTD)
with hyperbolic tangent function in the state space system. The stability and
convergence of the INTD are thoroughly investigated and proved. Through the
error analysis, the proposed INTD can extract differentiation of any piecewise
smooth nonlinear signal to reach a high accuracy. the INTD has the required
filtering features and can cope with th nonlinearities caused by the niose.
Through simulations, the INTD is implemented as signal derivative generator for
the closed loop feedback control system with a nolinear PID controller for the
nonlinear Mass Spring Damper system and showed that it could achieve the signal
tracking and differentiation faster with a minimum mean square error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02944</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02944</id><created>2018-03-07</created><authors><author><keyname>Chen</keyname><forenames>Siheng</forenames></author><author><keyname>Singh</keyname><forenames>Aarti</forenames></author><author><keyname>Kova&#x10d;evi&#x107;</keyname><forenames>Jelena</forenames></author></authors><title>Multiresolution Representations for Piecewise-Smooth Signals on Graphs</title><categories>eess.SP cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is a mathematically rigorous way to describe the taxi-pickup
distribution in Manhattan, or the profile information in online social
networks? A deep understanding of representing those data not only provides
insights to the data properties, but also benefits to many subsequent
processing procedures, such as denoising, sampling, recovery and localization.
In this paper, we model those complex and irregular data as piecewise-smooth
graph signals and propose a graph dictionary to effectively represent those
graph signals. We first propose the graph multiresolution analysis, which
provides a principle to design good representations. We then propose a
coarse-to-fine approach, which iteratively partitions a graph into two
subgraphs until we reach individual nodes. This approach efficiently implements
the graph multiresolution analysis and the induced graph dictionary promotes
sparse representations piecewise-smooth graph signals. Finally, we validate the
proposed graph dictionary on two tasks: approximation and localization. The
empirical results show that the proposed graph dictionary outperforms eight
other representation methods on six datasets, including traffic networks,
social networks and point cloud meshes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02950</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02950</id><created>2018-03-07</created><authors><author><keyname>Huang</keyname><forenames>Song-Wen</forenames></author><author><keyname>Pados</keyname><forenames>Dimitris A.</forenames></author></authors><title>M-ary Orthogonal Chirp Modulation for Coherent and Non-coherent
  Underwater Acoustic Communications</title><categories>eess.SP</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an orthogonal chirp waveform design for underwater acoustic (UW-A)
communications and analyze the cross-correlation characteristics of orthogonal
chirp waveforms in coherent and non-coherent detections. We consider
information symbols are carried over proposed M-ary orthogonal chirp waveforms
for UW-A transmissions. Moreover, we develop a coherent and an optimal
non-coherent receivers based on proposed chirp waveforms. Explicit derivations
include closed-form expressions for cross-correlation coefficients, and
theoretical bit-error-rate (BER) of coherent and non-coherent receivers.
Performance of M-ary orthogonal chirp waveforms is evaluated in water tank
experiments. Therefore, we have demonstrated the effectiveness of proposed
M-ary orthogonal chirp modulation in UW-A multipath fading channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.02972</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.02972</id><created>2018-03-08</created><authors><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Godaliyadda</keyname><forenames>G. M. Dilshan</forenames></author><author><keyname>Ferrier</keyname><forenames>Nicola</forenames></author><author><keyname>Gulsoy</keyname><forenames>Emine B.</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author><author><keyname>Phatak</keyname><forenames>Charudatta</forenames></author></authors><title>SLADS-Net: Supervised Learning Approach for Dynamic Sampling using Deep
  Neural Networks</title><categories>eess.SP</categories><comments>6 pages, 8 figures, Electronic Imaging 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In scanning microscopy based imaging techniques, there is a need to develop
novel data acquisition schemes that can reduce the time for data acquisition
and minimize sample exposure to the probing radiation. Sparse sampling schemes
are ideally suited for such applications where the images can be reconstructed
from a sparse set of measurements. In particular, dynamic sparse sampling based
on supervised learning has shown promising results for practical applications.
However, a particular drawback of such methods is that it requires training
image sets with similar information content which may not always be available.
In this paper, we introduce a Supervised Learning Approach for Dynamic Sampling
(SLADS) algorithm that uses a deep neural network based training approach. We
call this algorithm SLADS- Net. We have performed simulated experiments for
dynamic sampling using SLADS-Net in which the training images either have
similar information content or completely different information content, when
compared to the testing images. We compare the performance across various
methods for training such as least- squares, support vector regression and deep
neural networks. From these results we observe that deep neural network based
training results in superior performance when the training and testing images
are not similar. We also discuss the development of a pre-trained SLADS-Net
that uses generic images for training. Here, the neural network parameters are
pre-trained so that users can directly apply SLADS-Net for imaging experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03145</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03145</id><created>2018-03-08</created><authors><author><keyname>O'Shea</keyname><forenames>Timothy J.</forenames></author><author><keyname>Roy</keyname><forenames>Tamoghna</forenames></author><author><keyname>West</keyname><forenames>Nathan</forenames></author><author><keyname>Hilburn</keyname><forenames>Benjamin C.</forenames></author></authors><title>Physical Layer Communications System Design Over-the-Air Using
  Adversarial Networks</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel method for synthesizing new physical layer
modulation and coding schemes for communications systems using a learning-based
approach which does not require an analytic model of the impairments in the
channel. It extends prior work published on the channel autoencoder to consider
the case where the channel response is not known or can not be easily modeled
in a closed form analytic expression. By adopting an adversarial approach for
channel response approximation and information encoding, we can jointly learn a
good solution to both tasks over a wide range of channel environments. We
describe the operation of the proposed adversarial system, share results for
its training and validation over-the-air, and discuss implications and future
work in the area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03169</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03169</id><created>2018-03-08</created><authors><author><keyname>Qi</keyname><forenames>Yinan</forenames></author><author><keyname>Al-Imari</keyname><forenames>Mohammed</forenames></author></authors><title>An Enabling Waveform for 5G - QAM-FBMC: Initial Analysis</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 9 figures, CSCN 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we identified the challenges and requirements for the waveform
design of the fifth generation mobile communication networks (5G) and compared
Orthogonal frequency-division multiplexing (OFDM) based waveforms with Filter
Bank Multicarrier (FBMC) based ones. Recently it has been shown that
Quadrature-Amplitude Modulation (QAM) transmission and reception can be enabled
in FBMC by using multiple prototype filters, resulting in a new waveform:
QAM-FBMC. Here, the transceiver architecture and signal model of QAM-FBMC are
presented and channel estimation error and RF impairment, e.g., phase noise,
are modeled. In addition, initial evaluation is made in terms of out-of-band
(OOB) emission and complexity. The simulation results show that QAM-FBCM can
achieve the same BER performance as cyclic-prefix (CP) OFDM without spectrum
efficiency reduction due to the adding of CP. Different equalization schemes
are evaluated and the effect of channel estimation error is investigated.
Moreover, effects of the phase noise are evaluated and QAM-FBMC is shown to be
robust to the phase noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03298</identifier>
 <datestamp>2018-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03298</id><created>2018-03-08</created><authors><author><keyname>Mohammadian</keyname><forenames>A.</forenames></author><author><keyname>Baghani</keyname><forenames>M.</forenames></author><author><keyname>Tellambura</keyname><forenames>C.</forenames></author></authors><title>Analysis and Rate Optimization of GFDM-based Cognitive Radios</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized frequency division multiplexing (GFDM) is suitable for cognitive
radio (CR) networks due to its low out-of-band (OOB) emission and high spectral
efficiency. In this paper, we thus consider the use of GFDM to allow an
unlicensed secondary user (SU) to access a spectrum hole. However, in an
extremely congested spectrum scenario, both active incumbent primary users
(PUs) on the left and right channels of the spectrum hole will experience OOB
interference. While constraining this interference, we thus investigate the
problem of power allocation to the SU transmit subcarriers in order to maximize
the overall data rate where the SU receiver is employing Matched filter (MF)
and zero-forcing (ZF) structures. The power allocation problem is thus solved
as a classic convex optimization problem. Finally, total transmission rate of
GFDM is compared with that of orthogonal frequency division multiplexing
(OFDM). For instance, when right and left interference temperature should be
below 10 dBm, the capacity gain of GFDM over OFDM is 400 %.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03353</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03353</id><created>2018-03-08</created><updated>2018-12-04</updated><authors><author><keyname>Wang</keyname><forenames>Fen</forenames></author><author><keyname>Wang</keyname><forenames>Yongchao</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author></authors><title>A-Optimal Sampling and Robust Reconstruction for Graph Signals via
  Truncated Neumann Series</title><categories>eess.SP</categories><comments>accepted to IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2018.2818062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph signal processing (GSP) studies signals that live on irregular data
kernels described by graphs. One fundamental problem in GSP is sampling---from
which subset of graph nodes to collect samples in order to reconstruct a
bandlimited graph signal in high fidelity. In this paper, we seek a sampling
strategy that minimizes the mean square error (MSE) of the reconstructed
bandlimited graph signals assuming an independent and identically distributed
(iid) noise model---leading naturally to the A-optimal design criterion. To
avoid matrix inversion, we first prove that the inverse of the information
matrix in the A-optimal criterion is equivalent to a Neumann matrix series. We
then transform the truncated Neumann series based sampling problem into an
equivalent expression that replaces eigenvectors of the Laplacian operator with
a sub-matrix of an ideal low-pass graph filter. Finally, we approximate the
ideal filter using a Chebyshev matrix polynomial. We design a greedy algorithm
to iteratively minimize the simplified objective. For signal reconstruction, we
propose an accompanied signal reconstruction strategy that reuses the
approximated filter sub-matrix and is provably more robust than conventional
least square recovery. Simulation results show that our sampling strategy
outperforms two previous strategies in MSE performance at comparable
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03355</identifier>
 <datestamp>2018-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03355</id><created>2018-03-08</created><authors><author><keyname>Huo</keyname><forenames>Haiye</forenames></author><author><keyname>Sun</keyname><forenames>Wenchang</forenames></author></authors><title>Nonuniform Sampling for Random Signals Bandlimited in the Linear
  Canonical Transform Domain</title><categories>eess.SP</categories><comments>22 pages,8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we mainly investigate the nonuniform sampling for random
signals which are bandlimited in the linear canonical transform (LCT) domain.
We show that the nonuniform sampling for a random signal bandlimited in the LCT
domain is equal to the uniform sampling in the sense of second order statistic
characters after a pre-filter in the LCT domain. Moreover, we propose an
approximate recovery approach for nonuniform sampling of random signals
bandlimited in the LCT domain. Furthermore, we study the mean square error of
the nonuniform sampling. Finally, we do some simulations to verify the
correctness of our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03534</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03534</id><created>2018-03-08</created><authors><author><keyname>Zhang</keyname><forenames>Yibo</forenames></author><author><keyname>Alexander</keyname><forenames>Michael</forenames></author><author><keyname>Yang</keyname><forenames>Sam</forenames></author><author><keyname>Bian</keyname><forenames>Yinxu</forenames></author><author><keyname>Botvinick</keyname><forenames>Elliot</forenames></author><author><keyname>Lakey</keyname><forenames>Jonathan R. T.</forenames></author><author><keyname>Ozcan</keyname><forenames>Aydogan</forenames></author></authors><title>High-throughput screening of encapsulated islets using wide-field
  lens-free on-chip imaging</title><categories>physics.ins-det eess.IV physics.app-ph</categories><msc-class>78A10</msc-class><journal-ref>ACS Photonics, 2018, 5(6), pp 2081-2086</journal-ref><doi>10.1021/acsphotonics.8b00343</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Islet microencapsulation is a promising solution to diabetes treatment, but
its quality control based on manual microscopic inspection is extremely
low-throughput, highly variable and laborious. This study presents a
high-throughput islet-encapsulation quality screening system based on lens-free
on-chip imaging with a wide field-of-view of 18.15 cm^2, which is more than 100
times larger than that of a lens-based optical microscope, enabling it to image
and analyze ~8,000 microcapsules in a single frame. Custom-written image
reconstruction and processing software provides the user with clinically
important information, such as microcapsule count, size, intactness, and
information on whether each capsule contains an islet. This high-throughput and
cost-effective platform can be useful for researchers to develop better
encapsulation protocols as well as perform quality control prior to
transplantation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03559</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03559</id><created>2018-03-09</created><authors><author><keyname>Nautsch</keyname><forenames>Andreas</forenames></author><author><keyname>Isadskiy</keyname><forenames>Sergey</forenames></author><author><keyname>Kolberg</keyname><forenames>Jascha</forenames></author><author><keyname>Gomez-Barrero</keyname><forenames>Marta</forenames></author><author><keyname>Busch</keyname><forenames>Christoph</forenames></author></authors><title>Homomorphic Encryption for Speaker Recognition: Protection of Biometric
  Templates and Vendor Model Parameters</title><categories>cs.CR cs.SD eess.AS</categories><journal-ref>Proc. Odyssey 2018: The Speaker and Language Recognition Workshop</journal-ref><doi>10.21437/Odyssey.2018-3</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Data privacy is crucial when dealing with biometric data. Accounting for the
latest European data privacy regulation and payment service directive,
biometric template protection is essential for any commercial application.
Ensuring unlinkability across biometric service operators, irreversibility of
leaked encrypted templates, and renewability of e.g., voice models following
the i-vector paradigm, biometric voice-based systems are prepared for the
latest EU data privacy legislation. Employing Paillier cryptosystems, Euclidean
and cosine comparators are known to ensure data privacy demands, without loss
of discrimination nor calibration performance. Bridging gaps from template
protection to speaker recognition, two architectures are proposed for the
two-covariance comparator, serving as a generative model in this study. The
first architecture preserves privacy of biometric data capture subjects. In the
second architecture, model parameters of the comparator are encrypted as well,
such that biometric service providers can supply the same comparison modules
employing different key pairs to multiple biometric service operators. An
experimental proof-of-concept and complexity analysis is carried out on the
data from the 2013-2014 NIST i-vector machine learning challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03714</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03714</id><created>2018-03-09</created><authors><author><keyname>Bostan</keyname><forenames>Emrah</forenames></author><author><keyname>Soltanolkotabi</keyname><forenames>Mahdi</forenames></author><author><keyname>Ren</keyname><forenames>David</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>Accelerated Wirtinger Flow for Multiplexed Fourier Ptychographic
  Microscopy</title><categories>eess.SP math.OC</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier ptychographic microscopy enables gigapixel-scale imaging, with both
large field-of-view and high resolution. Using a set of low-resolution images
that are recorded under varying illumination angles, the goal is to
computationally reconstruct high-resolution phase and amplitude images. To
increase temporal resolution, one may use multiplexed measurements where the
sample is illuminated simultaneously from a subset of the angles. In this
paper, we develop an algorithm for Fourier ptychographic microscopy with such
multiplexed illumination. Specifically, we consider gradient descent type
updates and propose an analytical step size that ensures the convergence of the
iterates to a stationary point. Furthermore, we propose an accelerated version
of our algorithm (with the same step size) which significantly improves the
convergence speed. We demonstrate that the practical performance of our
algorithm is identical to the case where the step size is manually tuned.
Finally, we apply our parameter-free approach to real data and validate its
applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03736</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03736</id><created>2018-03-09</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Glisic</keyname><forenames>Savo</forenames></author></authors><title>Joint Optimization of Scheduling and Routing in Multicast Wireless
  Ad-Hoc Network Using Soft Graph Coloring and Non-linear Cubic Games</title><categories>eess.SP cs.NI</categories><comments>33 pages, 8 figures</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol 60, no. 7, Sept.
  2011</journal-ref><doi>10.1109/TVT.2011.2161355</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present matrix game-theoretic models for joint routing,
network coding, and scheduling problem. First routing and network coding are
modeled by using a new approach based on compressed topology matrix that takes
into account the inherent multicast gain of the network. The scheduling is
optimized by a new approach called network graph soft coloring. Soft graph
coloring is designed by switching between different components of a wireless
network graph, which we refer to as graph fractals, with appropriate usage
rates. The network components, represented by graph fractals, are a new
paradigm in network graph partitioning that enables modeling of the network
optimization problem by using the matrix game framework. In the proposed game
which is a nonlinear cubic game, the strategy sets of the players are links,
path, and network components. The outputs of this game model are mixed strategy
vectors of the second and the third players at equilibrium. Strategy vector of
the second player specifies optimum multi-path routing and network coding
solution while mixed strategy vector of the third players indicates optimum
switching rate among different network components or membership probabilities
for optimal soft scheduling approach. Optimum throughput is the value of the
proposed nonlinear cubic game at equilibrium. The proposed nonlinear cubic game
is solved by extending fictitious playing method. Numerical and simulation
results prove the superior performance of the proposed techniques compared to
the conventional schemes using hard graph coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03738</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03738</id><created>2018-03-09</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Glisic</keyname><forenames>Savo</forenames></author></authors><title>Stochastic Models of Coalition Games for Spectrum Sharing in Large Scale
  Interference Channels</title><categories>eess.SP</categories><comments>6 pages, 4 figures, IEEE International Conference on Communications
  (ICC), 2011. arXiv admin note: text overlap with arXiv:0905.4057 by other
  authors</comments><doi>10.1109/icc.2011.5963190</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a framework for the analysis of self-organized
distributed coalition formation process for spectrum sharing in interference
channel for large-scale ad hoc networks. In this approach, we use the concept
of coalition clusters within the network where mutual interdependency between
different clusters is characterized by the concept of spatial network
correlation. Then by using stochastic models of the process we give up some
details characteristic for coalition game theory in order to be able to include
some additional parameters for network scaling. Applications of this model are
a) Estimation of average time to reach grand coalition and its variance through
closed-form equations. These parameters are important in designing the process
in a dynamic environment. b) Dimensioning the coalition cluster within the
network c) Modelling the network spatial correlation characterizing mutual
visibility of the interfering links. d) Modeling of the effect of the new link
activation/inactivation on the coalition forming process. e) Modeling the
effect of link mobility on the coalition-forming process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03740</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03740</id><created>2018-03-09</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Cluster Size Optimization in Cooperative Spectrum Sensing</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 5 figures, CSNR2011</comments><doi>10.1109/CNSR.2011.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study and optimize the cooperation cluster size in
cooperative spectrum sensing to maximize the throughput of secondary users
(SUs). To calculate the effective throughput, we assume each SU spends just 1
symbol to negotiate with the other SUs in its transmission range. This is the
minimum overhead required for each SU to broadcast its sensing decision to the
other members of the cluster. When the number of SUs is large, the throughput
spent for the negotiation is noticeable and therefore increasing the
cooperation cluster size does not improve the effective throughput anymore. In
this paper, we calculate the effective throughput as a function of the
cooperation cluster size, and then we maximize the throughput by finding the
optimal cluster size. Various numerical results show that when decisions are
combined by the OR-rule, the optimum cooperation cluster size is less than when
the AND-rule is used. On the other hand, the optimum cluster size monotonically
decreases with the increase in the average SNR of the SUs. Another interesting
result is that when the cluster size is optimized the OR-rule always
outperforms the AND-rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03828</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03828</id><created>2018-03-10</created><authors><author><keyname>Giwa</keyname><forenames>Oluwarotimi</forenames></author><author><keyname>Benkrid</keyname><forenames>Abdsamad</forenames></author></authors><title>Fire detection in a still image using colour information</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Colour analysis is a crucial step in image-based fire detection algorithms.
Many of the proposed fire detection algorithms in a still image are prone to
false alarms caused by objects with a colour similar to fire. To design a
colour-based system with a better false alarm rate, a new
colour-differentiating conversion matrix, efficient on images of high colour
complexity, is proposed. The elements of this conversion matrix are obtained by
performing K-medoids clustering and Particle Swarm Optimisation procedures on a
fire sample image with a background of high fire-colour similarity. The
proposed conversion matrix is then used to construct two new fire colour
detection frameworks. The first detection method is a two-stage non-linear
image transformation framework, while the second is a direct transformation of
an image with the proposed conversion matrix. A performance comparison of the
proposed methods with alternate methods in the literature was carried out.
Experimental results indicate that the linear image transformation method
outperforms other methods regarding false alarm rate while the non-linear
two-stage image transformation method has the best performance on the F-score
metric and provides a better trade-off between missed detection and false alarm
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03874</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03874</id><created>2018-03-10</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Shehata</keyname><forenames>Mohamed</forenames></author><author><keyname>Smith</keyname><forenames>Andrew</forenames></author></authors><title>Tracking of the Internal Jugular Vein in Ultrasound Images Using Optical
  Flow</title><categories>eess.IV</categories><comments>4 pages, 7 figures, CCECE2017</comments><doi>10.1109/CCECE.2017.7946589</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of relative changes in circulating blood volume is important to
guide resuscitation and manage variety of medical conditions including sepsis,
trauma, dialysis and congestive heart failure. Recent studies have shown that
estimates of circulating blood volume can be obtained from ultrasound imagery
of the of the internal jugular vein (IJV). However, segmentation and tracking
of the IJV is significantly influenced by speckle noise and shadowing which
introduce uncertainty in the boundaries of the vessel. In this paper, we
investigate the use of optical flow algorithms for segmentation and tracking of
the IJV and show that the classical Lucas-Kanade (LK) algorithm provides the
best performance among well-known flow tracking algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03878</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03878</id><created>2018-03-10</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia</forenames></author></authors><title>Identification of SM-OFDM and AL-OFDM Signals Based on Their
  Second-Order Cyclostationarity</title><categories>eess.SP</categories><comments>36 pages, 14 figures, TVT2015</comments><doi>10.1109/TVT.2014.2326107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic signal identification (ASI) has important applications to both
commercial and military communications, such as software defined radio,
cognitive radio, spectrum surveillance and monitoring, and electronic warfare.
While ASI has been intensively studied for single-input single-output systems,
only a few investigations have been recently presented for multiple-input
multiple-output systems. This paper introduces a novel algorithm for the
identification of spatial multiplexing (SM) and Alamouti coded (AL) orthogonal
frequency division multiplexing (OFDM) signals, which relies on the
second-order signal cyclostationarity. Analytical expressions for the
second-order cyclic statistics of SM-OFDM and AL-OFDM signals are derived and
further exploited for the algorithm development. The proposed algorithm
provides a good identification performance with low sensitivity to impairments
in the received signal, such as phase noise, timing offset, and channel
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03896</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03896</id><created>2018-03-10</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Improved Asymptotics for Zeros of Kernel Estimates via a Reformulation
  of the Leadbetter-Cryer Integral</title><categories>stat.ME eess.SP math.PR math.ST physics.data-an stat.TH</categories><journal-ref>Statistics &amp; Probability Letters Volume 32, Issue 4, 1 April 1997,
  Pages 351-356</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The expected number of false inflection points of kernel smoothers is
evaluated. To obtain the small noise limit, we use a reformulation of the
Leadbetter-Cryer integral for the expected number of zero crossings of a
differentiable Gaussian process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03897</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03897</id><created>2018-03-10</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Optimal Data-based Kernel Estimation of Evolutionary Spectra</title><categories>stat.ME eess.AS eess.IV eess.SP physics.data-an</categories><journal-ref>IEEE Transactions on Signal Processing ( Volume: 41, Issue: 7, Jul
  1993 ) Page(s): 2439 - 2447</journal-ref><doi>10.1109/78.224252</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex demodulation of evolutionary spectra is formulated as a
two-dimensional kernel smoother in the time-frequency domain. In the first
stage, a tapered Fourier transform, $y_{nu}(f,t)$, is calculated. Second, the
log-spectral estimate, $\hat{\theta}_{\nu}(f,t) \equiv \ln(|y_{nu}(f,t)|^2$, is
smoothed. As the characteristic widths of the kernel smoother increase, the
bias from temporal and frequency averaging increases while the variance
decreases. The demodulation parameters, such as the order, length, and
bandwidth of spectral taper and the kernel smoother, are determined by
minimizing the expected error. For well-resolved evolutionary spectra, the
optimal taper length is a small fraction of the optimal kernel half-width. The
optimal frequency bandwidth, $w$, for the spectral window scales as $w^2
\approx \lambda_F/ \tau $, where $\tau$ is the characteristic time, and
$\lambda_F$ is the characteristic frequency scale-length. In contrast, the
optimal half-widths for the second stage kernel smoother scales as $h \approx
1/(\tau \lambda_F)^{1 \over ( p+2) }$, where $p$ is the order of the kernel
smoother. The ratio of the optimal frequency half-width to the optimal time
half-width satisfies $h_F / h_T ~ (|\partial_t ^p \theta | / |\partial_f^p
\theta|)$. Since the expected loss depends on the unknown evolutionary spectra,
we initially estimate $|\partial_t^p \theta|^2$ and $|\partial_f^p \theta|^2$
using a higher order kernel smoothers, and then substitute the estimated
derivatives into the expected loss criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03899</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03899</id><created>2018-03-10</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Piecewise Convex Function Estimation: Pilot Estimators</title><categories>stat.ME eess.SP math.ST stat.TH</categories><comments>PDF on https://projecteuclid.org/download/pdf_1/euclid.aos/1030741086</comments><journal-ref>Annals of Statistics Volume 25, Number 6 (1997), 2592-2606</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given noisy data, function estimation is considered when the unknown function
is known a priori to consist of a small number of regions where the function is
either convex or concave. When the number of regions is unknown, the model
selection problem is to determine the number of convexity change points. For
kernel estimates in Gaussian noise, the number of false change points is
evaluated as a function of the smoothing parameter. To ensure that the number
of false convexity change points tends to zero, the smoothing level must be
larger than is generically optimal for minimizing the mean integrated square
error (MISE). A two-stage estimator is proposed and shown to achieve the
optimal rate of convergence of the MISE. In the first-stage, the number and
location of the change points is estimated using strong smoothing. In the
second-stage, a constrained smoothing spline fit is performed with the
smoothing level chosen to minimize the MISE. The imposed constraint is that a
single change point occur in a region about each empirical change point from
the first-stage estimate. This constraint is equivalent to the requirement that
the third derivative of the second-stage estimate have a single sign in a small
neighborhood about each first-stage change point. The change points from the
second-stage are in a neighborhood of the first-stage change points, but need
not be at the identical locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03901</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03901</id><created>2018-03-10</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Piecewise Convex Function Estimation: Representations, Duality and Model
  Selection</title><categories>stat.ME cs.SY eess.SP eess.SY math.ST physics.data-an stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider spline estimates which preserve prescribed piecewise convex
properties of the unknown function. A robust version of the penalized
likelihood is given and shown to correspond to a variable halfwidth kernel
smoother where the halfwidth adaptively decreases in regions of rapid change of
the unknown function. When the convexity change points are prescribed, we
derive representation results and smoothness properties of the estimates. A
dual formulation is given which reduces the estimate is reduced to a finite
dimensional convex optimization in the dual space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03903</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03903</id><created>2018-03-10</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Piecewise Convex Function Estimation and Model Selection</title><categories>stat.ME cs.LG eess.SP math.ST physics.data-an stat.TH</categories><comments>arXiv admin note: text overlap with arXiv:1803.03901</comments><journal-ref>Approximation Theory Viii - Volume 1: Approximation And
  Interpolation edited by Chui Charles K, Schumaker Larry L 1995 by World
  Scientific Publishing</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given noisy data, function estimation is considered when the unknown function
is known apriori to consist of a small number of regions where the function is
either convex or concave. When the regions are known apriori, the estimate is
reduced to a finite dimensional convex optimization in the dual space. When the
number of regions is unknown, the model selection problem is to determine the
number of convexity change points. We use a pilot estimator based on the
expected number of false inflection points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03904</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03904</id><created>2018-03-10</created><authors><author><keyname>Mullhaupt</keyname><forenames>Andrew P.</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Banded Matrix Fraction Representation of Triangular Input Normal Pairs</title><categories>stat.ME cs.SY eess.SY math.OC math.RT</categories><journal-ref>IEEE Transactions on Automatic Control ( Volume: 46, Issue: 12,
  Dec 2001 ) Page(s): 2018 - 2022</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An input pair $(A,B)$ is triangular input normal if and only if $A$ is
triangular and $AA^* + BB^* = I_n$, where $I_n$ is theidentity matrix. Input
normal pairs generate an orthonormal basis for the impulse response. Every
input pair may be transformed to a triangular input normal pair. A new system
representation is given: $(A,B)$ is triangular normal and $A$ is a matrix
fraction, $A=M^{-1}N$, where $M$ and $N$ are triangular matrices of low
bandwidth. For single input pairs, $M$ and $N$ are bidiagonal and an explicit
parameterization is given in terms of the eigenvalues of $A$. This band
fraction structure allows for fast updates of state space systems and fast
system identification. When A has only real eigenvalues, one state advance
requires $3n$ multiplications for the single input case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03906</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03906</id><created>2018-03-11</created><authors><author><keyname>Sidorenko</keyname><forenames>Alexander</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Adaptive Kernel Estimation of the Spectral Density with Boundary Kernel
  Analysis</title><categories>stat.ME cs.CV eess.AS eess.SP math.ST stat.TH</categories><journal-ref>Approximation Theory VIII: Approximation And Interpolation, pg
  519-528, edited by Chui, Schumaker, 1995 World Scientific</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hybrid estimator of the log-spectral density of a stationary time series is
proposed. First, a multiple taper estimate is performed, followed by kernel
smoothing the log-multitaper estimate. This procedure reduces the expected mean
square error by $({\pi^2 \over 4})^{.8}$ over simply smoothing the log tapered
periodogram. The optimal number of tapers is $O(N^{8/15})$. A data adaptive
implementation of a variable bandwidth kernel smoother is given. When the
spectral density is discontinuous, one sided smoothing estimates are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03908</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03908</id><created>2018-03-11</created><authors><author><keyname>Mullhaupt</keyname><forenames>Andrew P.</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Fast Adaptive Identification of Stable Innovation Filters</title><categories>stat.ME cs.SY eess.SP eess.SY math.ST stat.TH</categories><journal-ref>IEEE Transactions on Signal Processing, Volume: 45, Issue: 10, Oct
  1997, pgs. 2616 - 2619</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The adaptive identification of the impulse response of an innovation filter
is considered. The impulse response is a finite sum of known basis functions
with unknown coefficients. These unknown coefficients are estimated using a
pseudolinear regression. This estimate is implemented using a square root
algorithm based on a displacement rank structure. When the initial conditions
have low displacement rank, the filter update is $O(n)$. If the filter
architecture is chosen to be triangular input balanced, the estimation problem
is well-conditioned and a simple, low rank initialization is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03911</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03911</id><created>2018-03-11</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Optimal Estimation of Dynamically Evolving Diffusivities</title><categories>stat.ME eess.SP math.OC physics.data-an</categories><journal-ref>J. Computational Physics Vol 115, pg 1-11, 1995</journal-ref><doi>10.1006/jcph.1994.1173</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The augmented, iterated Kalman smoother is applied to system identification
for inverse problems in evolutionary differential equations. In the augmented
smoother, the unknown, time-dependent coefficients are included in the state
vector, and have a stochastic component. At each step in the iteration, the
estimate of the time evolution of the coefficients is linear. We update the
slowly varying mean temperature and conductivity by averaging the estimates of
the Kalman smoother. Applications include the estimation of anomalous diffusion
coefficients in turbulent fluids and the plasma rotation velocity in plasma
tomography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03939</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03939</id><created>2018-03-11</created><authors><author><keyname>Ishikawa</keyname><forenames>Naoki</forenames></author><author><keyname>Sugiura</keyname><forenames>Shinya</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>50 Years of Permutation, Spatial and Index Modulation: From Classic RF
  to Visible Light Communications and Data Storage</title><categories>eess.SP</categories><comments>34 pages, 28 figures, 10 tables, accepted for publication in IEEE
  Communications Surveys &amp; Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this treatise, we provide an interdisciplinary survey on spatial
modulation (SM), where multiple-input multiple-output microwave and visible
light, as well as single and multicarrier communications are considered.
Specifically, we first review the permutation modulation (PM) concept, which
was originally proposed by Slepian in 1965. The PM concept has been applied to
a wide range of applications, including wired and wireless communications and
data storage. By introducing a three-dimensional signal representation, which
consists of spatial, temporal and frequency axes, the hybrid PM concept is
shown to be equivalent to the recently proposed SM family. In contrast to other
survey papers, this treatise aims for celebrating the hitherto overlooked
studies, including papers and patents that date back to the 1960s, before the
invention of SM. We also provide simulation results that demonstrate the pros
and cons of PM-aided low-complexity schemes over conventional multiplexing
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03995</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03995</id><created>2018-03-11</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author><author><keyname>Sidorenko</keyname><forenames>A.</forenames></author></authors><title>Adaptive Smoothing of the Log-Spectrum with Multiple Tapering</title><categories>stat.ME eess.AS eess.SP math.ST physics.data-an stat.TH</categories><journal-ref>IEEE Trans. Signal Process., vol. 44, no. 7, pp. 1794-1800, Jul.
  1996</journal-ref><doi>10.1109/78.510625</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hybrid estimator of the log-spectral density of a stationary time series is
proposed. First, a multiple taper estimate is performed, followed by kernel
smoothing the log-multiple taper estimate. This procedure reduces the expected
mean square error by $(\pi^2/ 4)^{4/5} $ over simply smoothing the log tapered
periodogram. A data adaptive implementation of a variable bandwidth kernel
smoother is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.03999</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.03999</id><created>2018-03-11</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author><author><keyname>Sidorenko</keyname><forenames>A.</forenames></author></authors><title>Function Estimation Using Data Adaptive Kernel Estimation - How Much
  Smoothing?</title><categories>stat.ME cs.AI eess.SP math.ST physics.data-an stat.TH</categories><comments>Available at https://aip.scitation.org/doi/pdf/10.1063/1.4823316</comments><journal-ref>Computers in Physics Volume 8 Issue 4, July/Aug. 1994 Pages
  402-409</journal-ref><doi>10.1063/1.4823316</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the expected error by smoothing the data locally. Then we
optimize the shape of the kernel smoother to minimize the error. Because the
optimal estimator depends on the unknown function, our scheme automatically
adjusts to the unknown function. By self-consistently adjusting the kernel
smoother, the total estimator adapts to the data.
  Goodness of fit estimators select a kernel halfwidth by minimizing a function
of the halfwidth which is based on the average square residual fit error:
$ASR(h)$. A penalty term is included to adjust for using the same data to
estimate the function and to evaluate the mean square error. Goodness of fit
estimators are relatively simple to implement, but the minimum (of the goodness
of fit functional) tends to be sensitive to small perturbations. To remedy this
sensitivity problem, we fit the mean square error %goodness of fit functional
to a two parameter model prior to determining the optimal halfwidth.
  Plug-in derivative estimators estimate the second derivative of the unknown
function in an initial step, and then substitute this estimate into the
asymptotic formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04030</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04030</id><created>2018-03-11</created><authors><author><keyname>Hua</keyname><forenames>Kanru</forenames></author></authors><title>Modeling Singing F0 With Neural Network Driven Transition-Sustain Models</title><categories>eess.AS cs.SD</categories><comments>5 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This study focuses on generating fundamental frequency (F0) curves of singing
voice from musical scores stored in a midi-like notation. Current statistical
parametric approaches to singing F0 modeling meet difficulties in reproducing
vibratos and the temporal details at note boundaries due to the oversmoothing
tendency of statistical models. This paper presents a neural network based
solution that models a pair of neighboring notes at a time (the transition
model) and uses a separate network for generating vibratos (the sustain model).
Predictions from the two models are combined by summation after proper
enveloping to enforce continuity. In the training phase, mild misalignment
between the scores and the target F0 is addressed by back-propagating the
gradients to the networks' inputs. Subjective listening tests on the NITech
singing database show that transition-sustain models are able to generate F0
trajectories close to the original performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04038</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04038</id><created>2018-03-11</created><authors><author><keyname>Medra</keyname><forenames>Mostafa</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author></authors><title>Updating Beamformers to Respond to Changes in Users</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to BSC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-user multiple-input single-output downlink system that
provides each user with a prespecified level of quality-of-service. The base
station (BS) designs the beamformers so that each user receives a certain
signal-to-interference-and-noise ratio (SINR). In contrast to most of the
available literature in the beamforming field, we focus on the required
modifications when the system changes. We specifically study three cases: (i)
user entering the system, (ii) user leaving the system, and (iii) a change in
the SINR target. We do so in order to avoid designing the entire system from
scratch for every change in the requirements. In each of the three cases, we
describe the modifications required to the beamforming directions and the power
loading. We consider maximum ratio transmission (MRT), zero-forcing (ZF) and
the optimal beamformers. The proposed modifications provide performance that is
either exact or very close to that obtained when we redesign the entire system,
while having much lower computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04046</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04046</id><created>2018-03-11</created><authors><author><keyname>Mullhaupt</keyname><forenames>Andrew</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt</forenames></author></authors><title>Exponential Condition Number of Solutions of the Discrete Lyapunov
  Equation</title><categories>stat.ME cs.NA cs.SY eess.SY math.NA math.ST physics.data-an stat.TH</categories><journal-ref>IEEE Transactions on Signal Processing, Volume: 52, Issue: 5, May
  2004, pgs. 1257 - 1265</journal-ref><doi>10.1109/TSP.2004.826177</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The condition number of the $n\ x\ n$ matrix $P$ is examined, where $P$
solves %the discete Lyapunov equation, $P - A P A^* = BB^*$, and $B$ is a $n\
x\ d$ matrix. Lower bounds on the condition number, $\kappa$, of $P$ are given
when $A$ is normal, a single Jordan block or in Frobenius form. The bounds show
that the ill-conditioning of $P$ grows as $\exp(n/d) &gt;&gt; 1$. These bounds are
related to the condition number of the transformation that takes $A$ to input
normal form. A simulation shows that $P$ is typically ill-conditioned in the
case of $n&gt;&gt;1$ and $d=1$. When $A_{ij}$ has an independent Gaussian
distribution (subject to restrictions), we observe that $\kappa(P)^{1/n} ~=
3.3$. The effect of auto-correlated forcing on the conditioning on state space
systems is examined
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04061</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04061</id><created>2018-03-11</created><authors><author><keyname>Chen</keyname><forenames>Di</forenames></author><author><keyname>Liu</keyname><forenames>Zoe</forenames></author><author><keyname>Xu</keyname><forenames>Yaowu</forenames></author><author><keyname>Zhu</keyname><forenames>Fengqing</forenames></author><author><keyname>Delp</keyname><forenames>Edward</forenames></author></authors><title>Multi-Reference Video Coding Using Stillness Detection</title><categories>eess.IV cs.MM</categories><comments>4 pages, 3 figures, IS&amp;T Electronic Imaging on Visual Information
  Processing and Communication Conference. (2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Encoders of AOM/AV1 codec consider an input video sequence as succession of
frames grouped in Golden-Frame (GF) groups. The coding structure of a GF group
is fixed with a given GF group size. In the current AOM/AV1 encoder, video
frames are coded using a hierarchical, multilayer coding structure within one
GF group. It has been observed that the use of multilayer coding structure may
result in worse coding performance if the GF group presents consistent
stillness across its frames. This paper proposes a new approach that adaptively
designs the Golden-Frame (GF) group coding structure through the use of
stillness detection. Our new approach hence develops an automatic stillness
detection scheme using three metrics extracted from each GF group. It then
differentiates those GF groups of stillness from other non- still GF groups and
uses different GF coding structures accordingly. Experimental result
demonstrates a consistent coding gain using the new approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04066</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04066</id><created>2018-03-11</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Bui</keyname><forenames>Francis M.</forenames></author><author><keyname>Nguyen</keyname><forenames>Ha H.</forenames></author></authors><title>Multisensor Data Fusion for Water Quality Monitoring using Wireless
  Sensor Networks</title><categories>eess.SP</categories><comments>7 pages, 8 figures, ICCE2012</comments><doi>10.1109/CCE.2012.6315875</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the application of hierarchical wireless sensor networks in
water quality monitoring is investigated. Adopting a hierarchical structure,
the set of sensors is divided into multiple clusters where the value of the
sensing parameter is almost constant in each cluster. The members of each
cluster transmit their sensing information to the local fusion center (LFC) of
their corresponding cluster, where using some fusion rule, the received
information is combined, and then possibly sent to a higher-level central
fusion center (CFC). A two-phase processing scheme is also envisioned, in which
the first phase is dedicated to detection in the LFC, and the second phase is
dedicated to estimation in both the LFC and the CFC. The focus of the present
paper is on the problem of decision fusion at the LFC: we propose hard- and
soft-decision maximum a posteriori (MAP) algorithms, which exhibit flexibility
in minimizing the total cost imposed by incorrect detections in the first
phase. The proposed algorithms are simulated and compared with conventional
fusion techniques. It is shown that the proposed techniques result in lower
cost. Furthermore, when the number of sensors or the amount of contamination
increases, the performance gap between the proposed algorithms and the existing
methods also widens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04068</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04068</id><created>2018-03-11</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author></authors><title>Performance Analysis of Decision Directed Maximum Likelihood MIMO
  Channel Tracking Algorithm</title><categories>eess.SP</categories><comments>29 pages, 10 figures, International Journal of Communication Systems,
  Feb. 2012</comments><doi>10.1002/dac.2329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the performance of decision directed (DD) maximum likelihood
(ML) channel tracking algorithm is analyzed. The ML channel tracking algorithm
presents efficient performance especially in the decision directed mode of the
operation. In this paper, after introducing the method for analysis of DD
algorithms, the performance of ML Multiple-Input Multiple-Output (MIMO) channel
tracking algorithm in the DD mode of operation is analyzed. In this method
channel tracking error is evaluated for given decision error rate. Then, the
decision error rate is approximated for given channel tracking error. By
solving these two derived equations jointly, both the decision error rate and
the channel tracking error are computed. The presented analysis is compared
with simulation results for different channel ranks, Doppler frequency shifts,
and SNRs, and it is shown that the analysis is a good match for simulation
results especially in high rank MIMO channels and high Doppler shifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04070</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04070</id><created>2018-03-11</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author></authors><title>A Novel Detection Algorithm Efficient for Turbo coded CDMA Signals in
  Detect and Forward Cooperative Channels</title><categories>eess.SP</categories><comments>20 pages, 8 figures, Wireless Perfornal Communications, July 2012</comments><doi>10.1007/s11277-011-0227-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new detection algorithm is proposed for turbo coded Code
Division Multiple Access (CDMA) signals in detect and forward cooperative
channels. Use of user cooperation makes much improvement in the performance of
CDMA systems. Due to the special structure of CDMA systems, cooperative schemes
increase the sum and cutoff capacities of CDMA based wireless systems and
improve the quality of user-partner link which enhances the overall performance
of the system. In this paper, a new combining scheme is proposed that makes the
receiver more robust against the decision errors in the partner link. This
structure is simulated for punctured 1/2 rate 4 states turbo code in a channel
with first-order Markov time variation and different Rice factor variances.
Through various simulations, it is shown when the channel estimates are
available in the partner and receiver, the cooperation between users provides
much diversity gain especially while using the new proposed combining
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04072</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04072</id><created>2018-03-11</created><authors><author><keyname>Ye</keyname><forenames>Chang</forenames></author><author><keyname>Shafipour</keyname><forenames>Rasoul</forenames></author><author><keyname>Mateos</keyname><forenames>Gonzalo</forenames></author></authors><title>Blind Identification of Invertible Graph Filters with Multiple Sparse
  Inputs</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with problem of blind identification of a graph filter and
its sparse input signal, thus broadening the scope of classical blind
deconvolution of temporal and spatial signals to irregular graph domains. While
the observations are bilinear functions of the unknowns, a mild requirement on
invertibility of the filter enables an efficient convex formulation, without
relying on matrix lifting that can hinder applicability to large graphs. On top
of scaling, it is argued that (non-cyclic) permutation ambiguities may arise
with some particular graphs. Deterministic sufficient conditions under which
the proposed convex relaxation can exactly recover the unknowns are stated,
along with those guaranteeing identifiability under the Bernoulli-Gaussian
model for the inputs. Numerical tests with synthetic and real-world networks
illustrate the merits of the proposed algorithm, as well as the benefits of
leveraging multiple signals to aid the (blind) localization of sources of
diffusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04075</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04075</id><created>2018-03-11</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Kernel estimation of the instantaneous frequency</title><categories>stat.ME eess.AS eess.SP math.ST stat.AP stat.TH</categories><journal-ref>I.E.E.E. Trans. Signal Processing 42, pp. 2644-2649 (1994)</journal-ref><doi>10.1109/78.324730</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider kernel estimators of the instantaneous frequency of a slowly
evolving sinusoid in white noise. The expected estimation error consists of two
terms. The systematic bias error grows as the kernel halfwidth increases while
the random error decreases. For a non-modulated signal, $g(t)$, the kernel
halfwidth which minimizes the expected error scales as$h \sim \left[{ \sigma^2
\over
  N| \partial_t^2 g^{}|^2 } \right]^{1/ 5}$, where %$A^{(\ell)}$ is the
coherent signal at frequency, $f_{\ell}$, $\sigma^2$ is the noise variance and
$N$ is the number of measurements per unit time. We show that estimating the
instantaneous frequency corresponds to estimating the first derivative of a
modulated signal, $A(t)\exp(i\phi(t))$. For instantaneous frequency estimation,
the halfwidth which minimizes the expected error is larger: $h_{1,3} \sim
\left[{ \sigma^2 \over A^2N| \partial_t^3 (e^{i \tilde{\phi}(t)} )|^2 }
\right]^{1/ 7}$. Since the optimal halfwidths depend on derivatives of the
unknown function, we initially estimate these derivatives prior to estimating
the actual signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04078</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04078</id><created>2018-03-11</created><updated>2018-03-29</updated><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author><author><keyname>Sidorenko</keyname><forenames>Alexander</forenames></author></authors><title>Minimum bias multiple taper spectral estimation</title><categories>stat.ME eess.AS eess.SP math.ST physics.data-an stat.TH</categories><journal-ref>I.E.E.E. Trans. Signal Processing 43, pp. 188-195 (1995)</journal-ref><doi>10.1109/78.365298</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two families of orthonormal tapers are proposed for multi-taper spectral
analysis: minimum bias tapers, and sinusoidal tapers $\{ \bf{v}^{(k)}\}$, where
$v_n^{(k)}=\sqrt{\frac{2}{N+1}}\sin\frac{\pi kn}{N+1}$, and $N$ is the number
of points. The resulting sinusoidal multitaper spectral estimate is
$\hat{S}(f)=\frac{1}{2K(N+1)} \sum_{j=1}^K |y(f+\frac{j}{2N+2})
-y(f-\frac{j}{2N+2})|^2$, where $y(f)$ is the Fourier transform of the
stationary time series, $S(f)$ is the spectral density, and $K$ is the number
of tapers. For fixed $j$, the sinusoidal tapers converge to the minimum bias
tapers like $1/N$. Since the sinusoidal tapers have analytic expressions, no
numerical eigenvalue decomposition is necessary. Both the minimum bias and
sinusoidal tapers have no additional parameter for the spectral bandwidth. The
bandwidth of the $j$th taper is simply $\frac{1}{N}$ centered about the
frequencies $\frac{\pm j}{2N+2}$. Thus the bandwidth of the multitaper spectral
estimate can be adjusted locally by simply adding or deleting tapers. The band
limited spectral concentration, $\int_{-w}^w |V(f)|^2 df$, of both the minimum
bias and sinusoidal tapers is very close to the optimal concentration achieved
by the Slepian tapers. In contrast, the Slepian tapers can have the local bias,
$\int_{-1/2}^{1/2} f^2 |V(f)|^2 df$, much larger than of the minimum bias
tapers and the sinusoidal tapers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04092</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04092</id><created>2018-03-11</created><updated>2018-03-19</updated><authors><author><keyname>Saito</keyname><forenames>Hiroshi</forenames></author><author><keyname>Ikeuchi</keyname><forenames>Hiroki</forenames></author></authors><title>Estimating Shape of Target Object Moving on Unknown Trajectory by Using
  Location-Unknown Distance Sensors: Theoretical Framework</title><categories>eess.SP</categories><comments>11 pages, 13 figures, and 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using directional distance sensors that have unknown locations, this paper
proposes a method of estimating the shape of a location-unknown target object
$T$ moving with unknown speed on an unknown straight line trajectory.
Regardless of many unknown factors, the proposed method can estimate the shape
by using each sensor's continuous report of the measured distance to $T$
without using side information or additional mechanisms such as locations of
anchor sensors and angle-of-arrival measurements. By using the sensor reports,
the proposed method estimates (i) the moving speed of $T$, (ii) the length and
direction of an edge of $T$, and (iii) the order of consecutive edges. As a
result, we can obtain the shape of $T$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04096</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04096</id><created>2018-03-11</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>Saliency Inspired Quality Assessment of Stereoscopic 3D Video</title><categories>eess.IV</categories><comments>Multimedia Tools and Applications, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To study the visual attentional behavior of Human Visual System (HVS) on 3D
content, eye tracking experiments are performed and Visual Attention Models
(VAMs) are designed. One of the main applications of these VAMs is in quality
assessment of 3D video. The usage of 2D VAMs in designing 2D quality metrics is
already well explored. This paper investigates the added value of incorporating
3D VAMs into Full-Reference (FR) and No-Reference (NR) quality assessment
metrics for stereoscopic 3D video. To this end, state-of-the-art 3D VAMs are
integrated to quality assessment pipeline of various existing FR and NR
stereoscopic video quality metrics. Performance evaluations using a large scale
database of stereoscopic videos with various types of distortions demonstrated
that using saliency maps generally improves the performance of the quality
assessment task for stereoscopic video. However, depending on the type of
distortion, utilized metric, and VAM, the amount of improvement will change.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04139</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04139</id><created>2018-03-12</created><authors><author><keyname>Shariatmadari</keyname><forenames>Hamidreza</forenames></author><author><keyname>Iraji</keyname><forenames>Sassan</forenames></author><author><keyname>Jantti</keyname><forenames>Riku</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Li</keyname><forenames>Zexian</forenames></author><author><keyname>Uusitalo</keyname><forenames>Mikko A.</forenames></author></authors><title>5G Control Channel Design for Ultra-Reliable Low-Latency Communications</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The fifth generation (5G) of wireless systems holds the promise of supporting
a wide range of services with different communication requirements.
Ultra-reliable low-latency communications (URLLC) is a generic service that
enables mission-critical applications, such as industrial automation, augmented
reality, and vehicular communications. URLLC has stringent requirements for
reliability and latency of delivering both data and control information. In
order to meet these requirements, the Third Generation Partnership Project
(3GPP) has been introducing new features to the upcoming releases of the
cellular system standards, namely releases 15 and beyond. This article reviews
some of these features and introduces new enhancements for designing the
control channels to efficiently support the URLLC. In particular, a flexible
slot structure is presented as a solution to detect a failure in delivering the
control information at an early stage, thereby allowing timely retransmission
of the control information. Finally, some remaining challenges and envisioned
research directions are discussed for shaping the 5G new radio (NR) as a
unified wireless access technology for supporting different services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04193</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04193</id><created>2018-03-12</created><authors><author><keyname>Venkitaraman</keyname><forenames>Arun</forenames></author><author><keyname>Chatterjee</keyname><forenames>Saikat</forenames></author><author><keyname>H&#xe4;ndel</keyname><forenames>Peter</forenames></author></authors><title>Extreme Learning Machine for Graph Signal Processing</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we improve extreme learning machines for regression tasks
using a graph signal processing based regularization. We assume that the target
signal for prediction or regression is a graph signal. With this assumption, we
use the regularization to enforce that the output of an extreme learning
machine is smooth over a given graph. Simulation results with real data confirm
that such regularization helps significantly when the available training data
is limited in size and corrupted by noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04200</identifier>
 <datestamp>2018-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04200</id><created>2018-03-12</created><updated>2018-09-26</updated><authors><author><keyname>Illan</keyname><forenames>Ignacio Alvarez</forenames></author><author><keyname>Ramirez</keyname><forenames>Javier</forenames></author><author><keyname>Gorriz</keyname><forenames>Juan M.</forenames></author><author><keyname>Marino</keyname><forenames>Maria Adele</forenames></author><author><keyname>Avenda&#xf1;o</keyname><forenames>Daly</forenames></author><author><keyname>Helbich</keyname><forenames>Thomas</forenames></author><author><keyname>Baltzer</keyname><forenames>Pascal</forenames></author><author><keyname>Pinker</keyname><forenames>Katja</forenames></author><author><keyname>Meyer-Baese</keyname><forenames>Anke</forenames></author></authors><title>Automated detection and segmentation of non-mass enhancing breast tumors
  with dynamic contrast-enhanced magnetic resonance imaging</title><categories>eess.IV cs.CV</categories><comments>20 pages, 9 figures, Contrast Media and Molecular Imaging, in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-mass enhancing lesions (NME) constitute a diagnostic challenge in dynamic
contrast enhanced magnetic resonance imaging (DCE-MRI) of the breast. Computer
Aided Diagnosis (CAD) systems provide physicians with advanced tools for
analysis, assessment and evaluation that have a significant impact on the
diagnostic performance. Here, we propose a new approach to address the
challenge of NME detection and segmentation, taking advantage of independent
component analysis (ICA) to extract data-driven dynamic lesion
characterizations. A set of independent sources was obtained from DCE-MRI
dataset of breast patients, and the dynamic behavior of the different tissues
was described by multiple dynamic curves, together with a set of eigenimages
describing the scores for each voxel. A new test image is projected onto the
independent source space using the unmixing matrix, and each voxel is
classified by a support vector machine (SVM) that has already been trained with
manually delineated data. A solution to the high false positive rate problem is
proposed by controlling the SVM hyperplane location, outperforming previously
published approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04228</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04228</id><created>2018-03-12</created><authors><author><keyname>Wang</keyname><forenames>Tsun-Hsuan</forenames></author><author><keyname>Huang</keyname><forenames>Hung-Jui</forenames></author><author><keyname>Lin</keyname><forenames>Juan-Ting</forenames></author><author><keyname>Hu</keyname><forenames>Chan-Wei</forenames></author><author><keyname>Zeng</keyname><forenames>Kuo-Hao</forenames></author><author><keyname>Sun</keyname><forenames>Min</forenames></author></authors><title>Omnidirectional CNN for Visual Place Recognition and Navigation</title><categories>cs.CV eess.IV</categories><comments>8 pages. 6 figures. Accepted to 2018 IEEE International Conference on
  Robotics and Automation (ICRA 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  $ $Visual place recognition is challenging, especially when only a few place
exemplars are given. To mitigate the challenge, we consider place recognition
method using omnidirectional cameras and propose a novel Omnidirectional
Convolutional Neural Network (O-CNN) to handle severe camera pose variation.
Given a visual input, the task of the O-CNN is not to retrieve the matched
place exemplar, but to retrieve the closest place exemplar and estimate the
relative distance between the input and the closest place. With the ability to
estimate relative distance, a heuristic policy is proposed to navigate a robot
to the retrieved closest place. Note that the network is designed to take
advantage of the omnidirectional view by incorporating circular padding and
rotation invariance. To train a powerful O-CNN, we build a virtual world for
training on a large scale. We also propose a continuous lifted structured
feature embedding loss to learn the concept of distance efficiently. Finally,
our experimental results confirm that our method achieves state-of-the-art
accuracy and speed with both the virtual world and real-world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04261</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04261</id><created>2018-03-03</created><authors><author><keyname>Qian</keyname><forenames>Cheng</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author><author><keyname>Yang</keyname><forenames>Ye</forenames></author></authors><title>Tensor-Based Parameter Estimation of Double Directional Massive MIMO
  Channel with Dual-Polarized Antennas</title><categories>eess.SP</categories><comments>5 pages, 2 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3GPP suggests to combine dual polarized (DP) antenna arrays with the
double directional (DD) channel model for downlink channel estimation. This
combination strikes a good balance between high-capacity communications and
parsimonious channel modeling, and also brings limited feedback schemes for
downlink channel estimation within reach. However, most existing channel
estimation work under the DD model has not considered DP arrays, perhaps
because of the complex array manifold and the resulting difficulty in algorithm
design. In this paper, we first reveal that the DD channel with DP arrays at
the transmitter and receiver can be naturally modeled as a low-rank four-way
tensor, and thus the parameters can be effectively estimated via tensor
decomposition algorithms. To reduce computational complexity, we show that the
problem can be recast as a four-snapshot three-dimensional harmonic retrieval
problem, which can be solved using computationally efficient subspace methods.
On the theory side, we show that the DD channel with DP arrays is identifiable
under very mild conditions, leveraging identifiability of low-rank tensors.
Numerical simulations are employed to showcase the effectiveness of our
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04315</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04315</id><created>2018-03-12</created><updated>2018-11-27</updated><authors><author><keyname>Koyuncu</keyname><forenames>Erdem</forenames></author></authors><title>Power-Efficient Deployment of UAVs as Relays</title><categories>cs.IT eess.SP math.IT</categories><comments>This work has been presented at the IEEE Signal Processing Advances
  in Wireless Communications (SPAWC), June 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal deployment of unmanned aerial vehicles (UAVs) as communication relays
is studied for fixed-rate variable-power systems. The considered setup is a set
of ground transmitters (GTs) wishing to communicate with a set of ground
receivers (GRs) through the UAVs. Each GT-GR pair communicates through only one
selected UAV and have no direct link. Two different UAV selection scenarios are
studied: In centralized selection, a decision center assigns an optimal UAV
depending on the locations of all terminals. In distributed selection, a GT
selects its relaying UAV using only the local knowledge of its distances to the
UAVs. For both selection scenarios, the optimal tradeoff between the UAV and GT
power consumptions are determined using tools from quantization theory.
Specifically, the two extremal regimes of one UAV and very large number of UAVs
are analyzed for a path loss exponent of $2$. Numerical optimization of UAV
locations are also discussed. Simulations are provided to confirm the
analytical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04347</identifier>
 <datestamp>2018-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04347</id><created>2018-03-12</created><authors><author><keyname>Jekel</keyname><forenames>Charles F</forenames></author><author><keyname>Haftka</keyname><forenames>Raphael T.</forenames></author></authors><title>Classifying Online Dating Profiles on Tinder using FaceNet Facial
  Embeddings</title><categories>cs.CV cs.SI eess.IV stat.ML</categories><comments>6 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  A method to produce personalized classification models to automatically
review online dating profiles on Tinder is proposed, based on the user's
historical preference. The method takes advantage of a FaceNet facial
classification model to extract features which may be related to facial
attractiveness. The embeddings from a FaceNet model were used as the features
to describe an individual's face. A user reviewed 8,545 online dating profiles.
For each reviewed online dating profile, a feature set was constructed from the
profile images which contained just one face. Two approaches are presented to
go from the set of features for each face, to a set of profile features. A
simple logistic regression trained on the embeddings from just 20 profiles
could obtain a 65% validation accuracy. A point of diminishing marginal returns
was identified to occur around 80 profiles, at which the model accuracy of 73%
would only improve marginally after reviewing a significant number of
additional profiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04550</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04550</id><created>2018-03-12</created><updated>2019-03-29</updated><authors><author><keyname>Gama</keyname><forenames>Fernando</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Ergodicity in Stationary Graph Processes: A Weak Law of Large Numbers</title><categories>eess.SP math.ST stat.TH</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2019.2908909</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For stationary signals in time the weak law of large numbers (WLLN) states
that ensemble and realization averages are within e of each other with a
probability of order O(1/Ne^2) when considering N signal components. The graph
WLLN introduced in this paper shows that the same is essentially true for
signals supported on graphs. However, the notions of stationarity, ensemble
mean, and realization mean are different. Recent papers have defined graph
stationary signals as those that satisfy a form of invariance with respect to
graph diffusion. The ensemble mean of a graph stationary signal is not a
constant but a node-varying signal whose structure depends on the spectral
properties of the graph. The realization average of a graph signal is defined
here as an average of successive weighted averages of local signal values with
signal values of neighboring nodes. The graph WLLN shows that this two
node-varying signals are within e of each other with probability of order
O(1/Ne^2) in at least some nodes. In stationary time signals, the realization
average is not only a consistent estimator of the ensemble mean but also
optimal in terms of mean squared error (MSE). This is not true of graph
signals. Optimal MSE graph filter designs are also presented. An example
problem concerning the estimation of the mean of a Gaussian random field is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04551</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04551</id><created>2018-03-12</created><authors><author><keyname>Wei</keyname><forenames>Pan</forenames></author><author><keyname>Ball</keyname><forenames>John E.</forenames></author><author><keyname>Anderson</keyname><forenames>Derek T.</forenames></author></authors><title>Multi-Sensor Conflict Measurement and Information Fusion</title><categories>eess.SP cs.AI</categories><comments>15 pages, 9 figures, conference paper</comments><journal-ref>SPIE Defense, Security, and Sensing, April, 2016</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In sensing applications where multiple sensors observe the same scene, fusing
sensor outputs can provide improved results. However, if some of the sensors
are providing lower quality outputs, the fused results can be degraded. In this
work, a multi-sensor conflict measure is proposed which estimates multi-sensor
conflict by representing each sensor output as interval-valued information and
examines the sensor output overlaps on all possible n-tuple sensor
combinations. The conflict is based on the sizes of the intervals and how many
sensors output values lie in these intervals. In this work, conflict is defined
in terms of how little the output from multiple sensors overlap. That is, high
degrees of overlap mean low sensor conflict, while low degrees of overlap mean
high conflict. This work is a preliminary step towards a robust conflict and
sensor fusion framework. In addition, a sensor fusion algorithm is proposed
based on a weighted sum of sensor outputs, where the weights for each sensor
diminish as the conflict measure increases. The proposed methods can be
utilized to (1) assess a measure of multi-sensor conflict, and (2) improve
sensor output fusion by lessening weighting for sensors with high conflict.
Using this measure, a simulated example is given to explain the mechanics of
calculating the conflict measure, and stereo camera 3D outputs are analyzed and
fused. In the stereo camera case, the sensor output is corrupted by additive
impulse noise, DC offset, and Gaussian noise. Impulse noise is common in
sensors due to intermittent interference, a DC offset a sensor bias or
registration error, and Gaussian noise represents a sensor output with low SNR.
The results show that sensor output fusion based on the conflict measure shows
improved accuracy over a simple averaging fusion strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04556</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04556</id><created>2018-03-12</created><authors><author><keyname>Wei</keyname><forenames>Pan</forenames></author><author><keyname>Ball</keyname><forenames>John E.</forenames></author><author><keyname>Anderson</keyname><forenames>Derek T.</forenames></author><author><keyname>Harsh</keyname><forenames>Archit</forenames></author><author><keyname>Archibald</keyname><forenames>Christopher</forenames></author></authors><title>Measuring Conflict in a Multi-Source Environment as a Normal Measure</title><categories>eess.SP cs.AI cs.CV eess.IV</categories><comments>4 pages, 8 figures, conference paper</comments><journal-ref>IEEE International Workshop on Computational Advances in
  Multi-Sensor Adaptive Processing (CAMSAP), December, 2015</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In a multi-source environment, each source has its own credibility. If there
is no external knowledge about credibility then we can use the information
provided by the sources to assess their credibility. In this paper, we propose
a way to measure conflict in a multi-source environment as a normal measure. We
examine our algorithm using three simulated examples of increasing conflict and
one experimental example. The results demonstrate that the proposed measure can
represent conflict in a meaningful way similar to what a human might expect and
from it we can identify conflict within our sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04567</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04567</id><created>2018-03-12</created><updated>2018-04-21</updated><authors><author><keyname>Shon</keyname><forenames>Suwon</forenames></author><author><keyname>Ali</keyname><forenames>Ahmed</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Convolutional Neural Networks and Language Embeddings for End-to-End
  Dialect Recognition</title><categories>cs.SD eess.AS</categories><comments>Speaker Odyssey 2018, The Speaker and Language Recognition Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dialect identification (DID) is a special case of general language
identification (LID), but a more challenging problem due to the linguistic
similarity between dialects. In this paper, we propose an end-to-end DID system
and a Siamese neural network to extract language embeddings. We use both
acoustic and linguistic features for the DID task on the Arabic dialectal
speech dataset: Multi-Genre Broadcast 3 (MGB-3). The end-to-end DID system was
trained using three kinds of acoustic features: Mel-Frequency Cepstral
Coefficients (MFCCs), log Mel-scale Filter Bank energies (FBANK) and
spectrogram energies. We also investigated a dataset augmentation approach to
achieve robust performance with limited data resources. Our linguistic feature
research focused on learning similarities and dissimilarities between dialects
using the Siamese network, so that we can reduce feature dimensionality as well
as improve DID performance. The best system using a single feature set achieves
73% accuracy, while a fusion system using multiple features yields 78% on the
MGB-3 dialect test set consisting of 5 dialects. The experimental results
indicate that FBANK features achieve slightly better results than MFCCs.
Dataset augmentation via speed perturbation appears to add significant
robustness to the system. Although the Siamese network with language embeddings
did not achieve as good a result as the end-to-end DID system, the two
approaches had good synergy when combined together in a fused system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04573</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04573</id><created>2018-03-12</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Adnani</keyname><forenames>Nikhil</forenames></author></authors><title>Identification of GSM and LTE Signals Using Their Second-order
  Cyclostationarity</title><categories>eess.SP</categories><comments>5 pages, 9 figures</comments><journal-ref>I2MTC2015</journal-ref><doi>10.1109/I2MTC.2015.7151426</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic signal identification (ASI) has various millitary and commercial
applications, such as spectrum surveillance and cognitive radio. In this paper,
a novel ASI algorithm is proposed for the identification of GSM and LTE
signals, which is based on the pilot-induced second-order cyclostationarity.
The proposed algorithm provides a very good performance at low signal-to-noise
ratios and short observation times, with no need for channel estimation, and
timing and frequency synchronization. Simulations and off-the-air signals
acquired with the ThinkRF WSA4000 receiver are used to confirm the findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04606</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04606</id><created>2018-03-12</created><authors><author><keyname>Dehkordi</keyname><forenames>Amin Banitalebi</forenames></author><author><keyname>Hossein-Zadeh</keyname><forenames>Gholam-Ali</forenames></author></authors><title>On the Variability of Chaos Indices in Sleep EEG Signals</title><categories>eess.SP</categories><comments>ICBME, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous researches revealed the chaotic and nonlinear nature of EEG signal.
In this paper we inspected the variability of chaotic indices of the sleep EEG
signal such as largest Lyapunov exponent, mutual information, correlation
dimension and minimum embedding dimension among different subjects, conditions
and sleep stages. Empirical histograms of these indices are obtained from sleep
EEG of 31 subjects, showing that, with a good accuracy, these indices in each
stage of sleep vary from healthy human subjects to subjects suspected to have
sleep-disordered breathing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04607</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04607</id><created>2018-03-12</created><authors><author><keyname>Banitalebi</keyname><forenames>Amin</forenames></author><author><keyname>Nader-Esfahani</keyname><forenames>Said</forenames></author><author><keyname>Avanaki</keyname><forenames>Alireza Nasiri</forenames></author></authors><title>A Perceptual Based Motion Compensation Technique for Video Coding</title><categories>eess.IV</categories><journal-ref>MVIP, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion estimation is one of the important procedures in the all video
encoders. Most of the complexity of the video coder depends on the complexity
of the motion estimation step. The original motion estimation algorithm has a
remarkable complexity and therefore many improvements were proposed to enhance
the crude version of the motion estimation. The basic idea of many of these
works were to optimize some distortion function for mean squared error (MSE) or
sum of absolute difference (SAD) in block matching But it is shown that these
metrics do not conclude the quality as it is, on the other hand, they are not
compatible with the human visual system (HVS). In this paper we explored the
usage of the image quality metrics in the video coding and more specific in the
motion estimation. We have utilized the perceptual image quality metrics
instead of MSE or SAD in the block based motion estimation. Three different
metrics have used: structural similarity or SSIM, complex wavelet structural
similarity or CW-SSIM, visual information fidelity or VIF. Experimental results
showed that usage of the quality criterions can improve the compression rate
while the quality remains fix and thus better quality in coded video at the
same bit budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04614</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04614</id><created>2018-03-13</created><authors><author><keyname>Banitalebi</keyname><forenames>A.</forenames></author><author><keyname>Tohidypour</keyname><forenames>H. R.</forenames></author></authors><title>Exploring the Distributed Video Coding in a Quality Assessment Context</title><categories>eess.IV</categories><journal-ref>American Journal of Signal Processing, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the popular video coding trend, the encoder has the task to exploit both
spatial and temporal redundancies present in the video sequence, which is a
complex procedure. As a result almost all video encoders have five to ten times
more complexity than their decoders. In a video compression process, one of the
main tasks at the encoder side is motion estimation which is to extract the
temporal correlation between frames. Distributed video coding (DVC) proposed
the idea that can lead to low complexity encoders and higher complexity
decoders. DVC is a new paradigm in video compression based on the information
theoretic ideas of Slepian-Wolf and Wyner-Ziv theorems. Wyner-Ziv coding is
naturally robust against transmission errors and can be used for joint source
and channel coding. Side Information is one of the key components of the
Wyner-Ziv decoder. Better side information generation will result in better
functionality of Wyner-Ziv coder. In this paper we proposed a new method that
can generate side information with a better quality and thus better
compression. We have used HVS (human visual system) based image quality metrics
as our quality criterion. The motion estimation we used in the decoder is
modified due to these metrics such that we could obtain finer side information.
The motion compensation is optimized for perceptual quality metrics and leads
to better side information generation compared to con- ventional MSE (mean
squared error) or SAD (sum of absolute difference) based motion compensation
currently used in the literature. Better motion compensation means better
compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04617</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04617</id><created>2018-03-13</created><authors><author><keyname>Banitalebi</keyname><forenames>Amin</forenames></author><author><keyname>Nader-Esfahani</keyname><forenames>Said</forenames></author><author><keyname>Avanaki</keyname><forenames>Alireza Nasiri</forenames></author></authors><title>Robust LSB Watermarking Optimized for Local Structural Similarity</title><categories>cs.MM eess.IV</categories><comments>ICEE, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Growth of the Internet and networked multimedia systems has emphasized the
need for copyright protection of the media. Media can be images, audio clips,
videos and etc. Digital watermarking is today extensively used for many
applications such as authentication of ownership or identification of illegal
copies. Digital watermark is an invisible or maybe visible structure added to
the original media (known as asset). Images are considered as communication
channel when they are subject to a watermark embedding procedure so in the case
of embedding a digital watermark in an image, the capacity of the channel
should be considered. There is a trade-off between imperceptibility, robustness
and capacity for embedding a watermark in an asset. In the case of image
watermarks, it is reasonable that the watermarking algorithm should depend on
the content and structure of the image. Conventionally, mean squared error
(MSE) has been used as a common distortion measure to assess the quality of the
images. Newly developed quality metrics proposed some distortion measures that
are based on human visual system (HVS). These metrics show that MSE is not
based on HVS and it has a lack of accuracy when dealing with perceptually
important signals such as images and videos. SSIM or structural similarity is a
state of the art HVS based image quality criterion that has recently been of
much interest. In this paper we propose a robust least significant bit (LSB)
watermarking scheme which is optimized for structural similarity. The watermark
is embedded into a host image through an adaptive algorithm. Various attacks
examined on the embedding approach and simulation results revealed the fact
that the watermarked sequence can be extracted with an acceptable accuracy
after all attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04620</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04620</id><created>2018-03-13</created><authors><author><keyname>Tutika</keyname><forenames>Chetan Sai</forenames></author><author><keyname>Vallapaneni</keyname><forenames>Charan</forenames></author><author><keyname>R</keyname><forenames>Karthik</forenames></author><author><keyname>KP</keyname><forenames>Bharath</forenames></author><author><keyname>Muthu</keyname><forenames>N Ruban Rajesh Kumar</forenames></author></authors><title>Image Segmentation and Processing for Efficient Parking Space Analysis</title><categories>eess.IV cs.CV</categories><comments>6 pages, 2018 International Conference on Informatics Computing in
  Engineering Systems (ICICES)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a method to detect vacant parking spaces in an
environment with unclear segments and contours with the help of MATLAB image
processing capabilities. Due to the anomalies present in the parking spaces,
such as uneven illumination, distorted slot lines and overlapping of cars. The
present-day conventional algorithms have difficulties processing the image for
accurate results. The algorithm proposed uses a combination of image
pre-processing and false contour detection techniques to improve the detection
efficiency. The proposed method also eliminates the need to employ individual
sensors to detect a car, instead uses real-time static images to consider a
group of slots together, instead of the usual single slot method. This greatly
decreases the expenses required to design an efficient parking system. We
compare the performance of our algorithm to that of other techniques. These
comparisons show that the proposed algorithm can detect the vacancies in the
parking spots while ignoring the false data and other distortions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04621</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04621</id><created>2018-03-13</created><authors><author><keyname>Tutika</keyname><forenames>Chetan Sai</forenames></author><author><keyname>Vallapaneni</keyname><forenames>Charan</forenames></author><author><keyname>R</keyname><forenames>Karthik</forenames></author><author><keyname>KP</keyname><forenames>Bharath</forenames></author><author><keyname>Ruban</keyname><forenames>N</forenames></author><author><keyname>Muthu</keyname><forenames>Rajesh Kumar</forenames></author></authors><title>Cubic Spline Interpolation Segmenting over Conventional Segmentation
  Procedures: Application and Advantages</title><categories>eess.IV</categories><comments>7 pages, 2018 International Conference on Informatics Computing in
  Engineering Systems (ICICES)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To design a novel method for segmenting the image using Cubic Spline
Interpolation and compare it with different techniques to determine which gives
an efficient data to segment an image. This paper compares polynomial least
square interpolation and the conventional Otsu thresholding with spline
interpolation technique for image segmentation. The threshold value is
determined using the above-mentioned techniques which are then used to segment
an image into the binary image. The results of the proposed technique are also
compared with the conventional algorithms after applying image equalizations.
The better technique is determined based on the deviation and mean square error
when compared with an accurately segmented image. The image with least amount
of deviation and mean square error is declared as the better technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04624</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04624</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>A Human Visual System-Based 3D Video Quality Metric</title><categories>eess.IV</categories><comments>IC3D, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although several 2D quality metrics have been proposed for images and videos,
in the case of 3D efforts are only at the initial stages. In this paper, we
propose a new full-reference quality metric for 3D content. Our method is
modeled around the HVS, fusing the information of both left and right channels,
considering color components, the cyclopean views of the two videos and
disparity. Performance evaluations showed that our 3D quality metric
successfully monitors the degradation of quality caused by several
representative types of distortion and it has 86% correlation with the results
of subjective evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04627</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04627</id><created>2018-03-13</created><authors><author><keyname>Imani</keyname><forenames>Sajjad</forenames></author><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Cheraghi</keyname><forenames>Mehdi</forenames></author></authors><title>A Random Matrix Approach to Wide Band Spectrum Sensing: Unknown Noise
  Variance Case</title><categories>eess.SP</categories><journal-ref>ICEE, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper three different scenarios in wide band spectrum sensing have
been studied. While the signal and noise statistics are supposed to be
unspecified, random matrixes have been utilized in order to estimate the noise
variance. These scenarios are: 1- Number of subbands is specified and there is
enough information regarding being used or being unused for each of them. 2-
Number of subbands is known but there is no information about usage
distribution among them. 3- Number of subbands is unknown. Simulation results
showed the superior performance of the proposed scheme. Regarding the number of
samples, the proposed method requires less number of samples compared to the
cyclo-stationary spectrum sensing algorithms and more samples compared to the
energy detection based methods. But, regarding the detection probability, the
proposed method is superior compared to both other spectrum sensing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04629</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04629</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>3D Video Quality Metric for 3D Video Compression</title><categories>eess.IV</categories><journal-ref>IVMSP, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the evolution of multiview display technology is bringing glasses-free
3DTV closer to reality, MPEG and VCEG are preparing an extension to HEVC to
encode multiview video content. View synthesis in the current version of the 3D
video codec is performed using PSNR as a quality metric measure. In this paper,
we propose a full- reference Human-Visual-System based 3D video quality metric
to be used in multiview encoding as an alternative to PSNR. Performance of our
metric is tested in a 2-view case scenario. The quality of the compressed
stereo pair, formed from a decoded view and a synthesized view, is evaluated at
the encoder side. The performance is verified through a series of subjective
tests and compared with that of PSNR, SSIM, MS-SSIM, VIFp, and VQM metrics.
Experimental results showed that our 3D quality metric has the highest
correlation with Mean Opinion Scores (MOS) compared to the other tested
metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04652</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04652</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Mehdi</forenames></author><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author></authors><title>Music Genre Classification Using Spectral Analysis and Sparse
  Representation of the Signals</title><categories>cs.SD eess.AS</categories><journal-ref>Journal of Signal Processing Systems, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed a robust music genre classification method based
on a sparse FFT based feature extraction method which extracted with
discriminating power of spectral analysis of non-stationary audio signals, and
the capability of sparse representation based classifiers. Feature extraction
method combines two sets of features namely short-term features (extracted from
windowed signals) and long-term features (extracted from combination of
extracted short-time features). Experimental results demonstrate that the
proposed feature extraction method leads to a sparse representation of audio
signals. As a result, a significant reduction in the dimensionality of the
signals is achieved. The extracted features are then fed into a sparse
representation based classifier (SRC). Our experimental results on the GTZAN
database demonstrate that the proposed method outperforms the other state of
the art SRC approaches. Moreover, the computational efficiency of the proposed
method is better than that of the other Compressive Sampling (CS)-based
classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04653</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04653</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>Effect of High Frame Rates on 3D Video Quality of Experience</title><categories>eess.IV</categories><journal-ref>ICCE, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the effect of 3D videos with increased frame rates on
the viewers quality of experience. We performed a series of subjective tests to
seek the subjects preferences among videos of the same scene at four different
frame rates: 24, 30, 48, and 60 frames per second (fps). Results revealed that
subjects clearly prefer higher frame rates. In particular, Mean Opinion Score
(MOS) values associated with the 60 fps 3D videos were 55% greater than MOS
values of the 24 fps 3D videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04815</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04815</id><created>2018-03-13</created><authors><author><keyname>Azimi</keyname><forenames>Maryam</forenames></author><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Dong</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>Evaluating the Performance of Existing Full-Reference Quality Metrics on
  High Dynamic Range (HDR) Video Content</title><categories>eess.IV</categories><journal-ref>ICMSP, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there exists a wide variety of Low Dynamic Range (LDR) quality metrics,
only a limited number of metrics are designed specifically for the High Dynamic
Range (HDR) content. With the introduction of HDR video compression
standardization effort by international standardization bodies, the need for an
efficient video quality metric for HDR applications has become more pronounced.
The objective of this study is to compare the performance of the existing
full-reference LDR and HDR video quality metrics on HDR content and identify
the most effective one for HDR applications. To this end, a new HDR video
dataset is created, which consists of representative indoor and outdoor video
sequences with different brightness, motion levels and different representing
types of distortions. The quality of each distorted video in this dataset is
evaluated both subjectively and objectively. The correlation between the
subjective and objective results confirm that VIF quality metric outperforms
all to ther tested metrics in the presence of the tested types of distortions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04823</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04823</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Azimi</keyname><forenames>Maryam</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>Compression of High Dynamic Range Video Using the HEVC and H.264/AVC
  Standards</title><categories>eess.IV</categories><journal-ref>QSHINE, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing video coding standards such as H.264/AVC and High Efficiency
Video Coding (HEVC) have been designed based on the statistical properties of
Low Dynamic Range (LDR) videos and are not accustomed to the characteristics of
High Dynamic Range (HDR) content. In this study, we investigate the performance
of the latest LDR video compression standard, HEVC, as well as the recent
widely commercially used video compression standard, H.264/AVC, on HDR content.
Subjective evaluations of results on an HDR display show that viewers clearly
prefer the videos coded via an HEVC-based encoder to the ones encoded using an
H.264/AVC encoder. In particular, HEVC outperforms H.264/AVC by an average of
10.18% in terms of mean opinion score and 25.08% in terms of bit rate savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04826</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04826</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>The Effect of Frame Rate on 3D Video Quality and Bitrate</title><categories>eess.IV</categories><journal-ref>Journal of 3D Research, 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing the frame rate of a 3D video generally results in improved Quality
of Experience (QoE). However, higher frame rates involve a higher degree of
complexity in capturing, transmission, storage, and display. The question that
arises here is what frame rate guarantees high viewing quality of experience
given the existing/required 3D devices and technologies (3D cameras, 3D TVs,
compression, transmission bandwidth, and storage capacity). This question has
already been addressed for the case of 2D video, but not for 3D. The objective
of this paper is to study the relationship between 3D quality and bitrate at
different frame rates. Our performance evaluations show that increasing the
frame rate of 3D videos beyond 60 fps may not be visually distinguishable. In
addition, our experiments show that when the available bandwidth is reduced,
the highest possible 3D quality of experience can be achieved by adjusting
(decreasing) the frame rate instead of increasing the compression ratio. The
results of our study are of particular interest to network providers for rate
adaptation in variable bitrate channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04832</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04832</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>An Efficient Human Visual System Based Quality Metric for 3D Video</title><categories>eess.IV</categories><journal-ref>Multimedia Tools and Applications, 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stereoscopic video technologies have been introduced to the consumer market
in the past few years. A key factor in designing a 3D system is to understand
how different visual cues and distortions affect the perceptual quality of
stereoscopic video. The ultimate way to assess 3D video quality is through
subjective tests. However, subjective evaluation is time consuming, expensive,
and in some cases not possible. The other solution is developing objective
quality metrics, which attempt to model the Human Visual System (HVS) in order
to assess perceptual quality. Although several 2D quality metrics have been
proposed for still images and videos, in the case of 3D efforts are only at the
initial stages. In this paper, we propose a new full-reference quality metric
for 3D content. Our method mimics HVS by fusing information of both the left
and right views to construct the cyclopean view, as well as taking to account
the sensitivity of HVS to contrast and the disparity of the views. In addition,
a temporal pooling strategy is utilized to address the effect of temporal
variations of the quality in the video. Performance evaluations showed that our
3D quality metric quantifies quality degradation caused by several
representative types of distortions very accurately, with Pearson correlation
coefficient of 90.8 %, a competitive performance compared to the
state-of-the-art 3D quality metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04845</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04845</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Eleni</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>Benchmark 3D eye-tracking dataset for visual saliency prediction on
  stereoscopic 3D video</title><categories>eess.IV</categories><journal-ref>SPIE, 2016</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual Attention Models (VAMs) predict the location of an image or video
regions that are most likely to attract human attention. Although saliency
detection is well explored for 2D image and video content, there are only few
attempts made to design 3D saliency prediction models. Newly proposed 3D visual
attention models have to be validated over large-scale video saliency
prediction datasets, which also contain results of eye-tracking information.
There are several publicly available eye-tracking datasets for 2D image and
video content. In the case of 3D, however, there is still a need for
large-scale video saliency datasets for the research community for validating
different 3D-VAMs. In this paper, we introduce a large-scale dataset containing
eye-tracking data collected from 61 stereoscopic 3D videos (and also 2D
versions of those) and 24 subjects participated in a free-viewing test. We
evaluate the performance of the existing saliency detection methods over the
proposed dataset. In addition, we created an online benchmark for validating
the performance of the existing 2D and 3D visual attention models and
facilitate addition of new VAMs to the benchmark. Our benchmark currently
contains 50 different VAMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04847</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04847</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author></authors><title>Introducing A Public Stereoscopic 3D High Dynamic Range (SHDR) Video
  Database</title><categories>eess.IV</categories><journal-ref>Journal of 3D Research, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High Dynamic Range (HDR) displays and cameras are paving their ways through
the consumer market at a rapid growth rate. Thanks to TV and camera
manufacturers, HDR systems are now becoming available commercially to end
users. This is taking place only a few years after the blooming of 3D video
technologies. MPEG/ITU are also actively working towards the standardization of
these technologies. However, preliminary research efforts in these video
technologies are hammered by the lack of sufficient experimental data. In this
paper, we introduce a Stereoscopic 3D HDR (SHDR) database of videos that is
made publicly available to the research community. We explain the procedure
taken to capture, calibrate, and post-process the videos. In addition, we
provide insights on potential use-cases, challenges, and research
opportunities, implied by the combination of higher dynamic range of the HDR
aspect, and depth impression of the 3D aspect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04856</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04856</id><created>2018-03-13</created><authors><author><keyname>Griffith</keyname><forenames>Elias J</forenames></author><author><keyname>Mishra</keyname><forenames>Chinmaya</forenames></author><author><keyname>Ralph</keyname><forenames>Jason F.</forenames></author><author><keyname>Maskell</keyname><forenames>Simon</forenames></author></authors><title>A System for the Generation of Synthetic Wide Area Aerial Surveillance
  Imagery</title><categories>cs.OH cs.SY eess.IV</categories><comments>v1 (Accepted for publication in Simulation Modelling Practice and
  Theory)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development, benchmarking and validation of aerial Persistent
Surveillance (PS) algorithms requires access to specialist Wide Area Aerial
Surveillance (WAAS) datasets. Such datasets are difficult to obtain and are
often extremely large both in spatial resolution and temporal duration. This
paper outlines an approach to the simulation of complex urban environments and
demonstrates the viability of using this approach for the generation of
simulated sensor data, corresponding to the use of wide area imaging systems
for surveillance and reconnaissance applications. This provides a
cost-effective method to generate datasets for vehicle tracking algorithms and
anomaly detection methods. The system fuses the Simulation of Urban Mobility
(SUMO) traffic simulator with a MATLAB controller and an image generator to
create scenes containing uninterrupted door-to-door journeys across large areas
of the urban environment. This `pattern-of-life' approach provides
three-dimensional visual information with natural movement and traffic flows.
This can then be used to provide simulated sensor measurements (e.g. visual
band and infrared video imagery) and automatic access to ground-truth data for
the evaluation of multi-target tracking systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04862</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04862</id><created>2018-03-01</created><authors><author><keyname>Lee</keyname><forenames>Vincent T.</forenames></author><author><keyname>Alaghi</keyname><forenames>Armin</forenames></author><author><keyname>Ceze</keyname><forenames>Luis</forenames></author></authors><title>Correlation Manipulating Circuits for Stochastic Computing</title><categories>eess.SP cs.AR</categories><comments>6 pages, 5 figures, 4 tables, Design, Automation and Test in Europe
  Conference and Exhibition (2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic computing (SC) is an emerging computing technique that promises
high density, low power, and error tolerant solutions. In SC, values are
encoded as unary bitstreams and SC arithmetic circuits operate on one or more
bitstreams. In many cases, the input bitstreams must be correlated or
uncorrelated for SC arithmetic to produce accurate results. As a result, a key
challenge for designing SC accelerators is manipulating the impact of
correlation across SC operations. This paper presents and evaluates a set of
novel correlation manipulating circuits to manage correlation in SC
computation: a synchronizer, desynchronizer, and decorrelator. We then use
these circuits to propose improved SC maximum, minimum, and saturating adder
designs. Compared to existing correlation manipulation techniques, our circuits
are more accurate and up to 3x more energy efficient. In the context of an
image processing pipeline, these circuits can reduce the total energy
consumption by up to 24%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04864</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04864</id><created>2018-03-10</created><authors><author><keyname>Diamantoulakis</keyname><forenames>Panagiotis D.</forenames></author></authors><title>Resource Allocation in Wireless Networks with Energy Constraints</title><categories>eess.SP</categories><comments>Author's PhD Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This dissertation focuses on the development of novel scheduling and resource
allocation schemes, which take into account and regulate the energy constraints
imposed by the levels of harvested energy. To this direction, first, the
optimal energy, time, and bandwidth allocation problem for the downlink of
energy harvesting base stations (EHBSs) is investigated, with the main focus
being on autonomous EHBSs. The presented analysis considers the impact of the
energy constraint on users' preferences and the BS's revenue. In order to model
the competitive nature of the problem, game theory is used. The next two
chapters focus on wireless powered networks (WPNs) and simultaneous wireless
information and power transfer (SWIPT) using radio frequency (RF) technology.
One of the main contributions of these chapters is the introduction of both
uplink and downlink non-orthogonal multiple access (NOMA) for WPNs. Moreover,
the individual data rates and fairness are improved, while the formulated
problems are optimally and efficiently solved. It is shown that, compared to
orthogonal multiple access, NOMA offers a considerable improvement in
throughput, fairness, and energy efficiency. Rather than this, proportional
fairness is maximized and uplink/downlink of WPNs are jointly optimized, in
which cases, except for NOMA, time division multiple access (TDMA) is also
investigated. Furthermore, the role of interference is considered, which has
been recognized as one of the main reasons of the asymmetric overall
degradation of the users' performance, due to different path-loss values,
called from now on as cascaded near-far problem. Moreover, SWIPT is
investigated and efficiently optimized in the context of multicarrier
cooperative communication networks. Finally, simultaneous lightwave information
and power transfer (SLIPT) is introduced, while novel and fundamental
techniques are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04866</identifier>
 <datestamp>2018-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04866</id><created>2018-03-10</created><updated>2018-09-13</updated><authors><author><keyname>Gupta</keyname><forenames>Gaurav</forenames></author><author><keyname>Pequito</keyname><forenames>Sergio</forenames></author><author><keyname>Bogdan</keyname><forenames>Paul</forenames></author></authors><title>Dealing with Unknown Unknowns: Identification and Selection of Minimal
  Sensing for Fractional Dynamics with Unknown Inputs</title><categories>eess.SP cs.LG</categories><comments>7 pages, 4 figures, ACC-18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on analysis and design of time-varying complex networks
having fractional order dynamics. These systems are key in modeling the complex
dynamical processes arising in several natural and man made systems. Notably,
examples include neurophysiological signals such as electroencephalogram (EEG)
that captures the variation in potential fields, and blood oxygenation level
dependent (BOLD) signal, which serves as a proxy for neuronal activity.
Notwithstanding, the complex networks originated by locally measuring EEG and
BOLD are often treated as isolated networks and do not capture the dependency
from external stimuli, e.g., originated in subcortical structures such as the
thalamus and the brain stem. Therefore, we propose a paradigm-shift towards the
analysis of such complex networks under unknown unknowns (i.e., excitations).
Consequently, the main contributions of the present paper are threefold: (i) we
present an alternating scheme that enables to determine the best estimate of
the model parameters and unknown stimuli; (ii) we provide necessary and
sufficient conditions to ensure that it is possible to retrieve the state and
unknown stimuli; and (iii) upon these conditions we determine a small subset of
variables that need to be measured to ensure that both state and input can be
recovered, while establishing sub-optimality guarantees with respect to the
smallest possible subset. Finally, we present several pedagogical examples of
the main results using real data collected from an EEG wearable device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04935</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04935</id><created>2018-03-13</created><authors><author><keyname>Liang</keyname><forenames>Zhonghua</forenames></author><author><keyname>Zhang</keyname><forenames>Guowei</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>Huo</keyname><forenames>Yiming</forenames></author></authors><title>Design and Analysis of Passband Transmitted Reference Pulse Cluster UWB
  Systems in the Presence of Phase Noise</title><categories>eess.SP</categories><comments>12 pages, 7 figures, accepted by IEEE ACCESS</comments><doi>10.1109/ACCESS.2018.2815708</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmitted reference pulse cluster (TRPC) signaling was recently proposed
and developed for noncoherent ultra-wideband (UWB) communications. In this
paper, a practical passband TRPC-UWB system is designed and analyzed to deal
with the carrier frequency offset, phase offset and phase noise inherent in
voltage-controlled oscillators (VCO) of the transmitter and the receiver. Based
on a general model of noisy VCO and employing some reasonable assumptions, an
equivalent linear time-invariant (LTI) analytical model is obtained to
facilitate the bit error rate (BER) analysis. Our analysis shows that the
constant carrier frequency offset and the phase offset can be removed by
employing the passband transmitter and the noncoherent receiver. Furthermore, a
semi-analytical BER expression is derived to show the impact of phase noise on
the system error performance. Simulation results validate the semi-analytical
expressions and both of them indicate that TRPC is more robust to the effect of
phase noise than conventional transmitted reference (TR) and coherent UWB Rake
receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04964</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04964</id><created>2018-03-12</created><authors><author><keyname>Harsh</keyname><forenames>Archit</forenames></author><author><keyname>Ball</keyname><forenames>John E.</forenames></author><author><keyname>Wei</keyname><forenames>Pan</forenames></author></authors><title>Onion-Peeling Outlier Detection in 2-D data Sets</title><categories>cs.LG cs.CV eess.SP</categories><comments>6 pages, 4 figures, journal paper</comments><journal-ref>International Journal of Computer Application, Vol.139 (3),
  pp.26-31, April, 2016</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Outlier Detection is a critical and cardinal research task due its array of
applications in variety of domains ranging from data mining, clustering,
statistical analysis, fraud detection, network intrusion detection and
diagnosis of diseases etc. Over the last few decades, distance-based outlier
detection algorithms have gained significant reputation as a viable alternative
to the more traditional statistical approaches due to their scalable,
non-parametric and simple implementation. In this paper, we present a modified
onion peeling (Convex hull) genetic algorithm to detect outliers in a Gaussian
2-D point data set. We present three different scenarios of outlier detection
using a) Euclidean Distance Metric b) Standardized Euclidean Distance Metric
and c) Mahalanobis Distance Metric. Finally, we analyze the performance and
evaluate the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.04966</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.04966</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Mehdi</forenames></author><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Nader-Esfahani</keyname><forenames>Said</forenames></author></authors><title>An Improvement Technique based on Structural Similarity Thresholding for
  Digital Watermarking</title><categories>cs.MM eess.IV</categories><journal-ref>ACENG, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital watermarking is extensively used in ownership authentication and
copyright protection. In this paper, we propose an efficient thresholding
scheme to improve the watermark embedding procedure in an image. For the
proposed algorithm, watermark casting is performed separately in each block of
an image, and embedding in each block continues until a certain structural
similarity threshold is reached. Numerical evaluations demonstrate that our
scheme improves the imperceptibility of the watermark when the capacity remains
fix, and at the same time, robustness against attacks is assured. The proposed
method is applicable to most image watermarking algorithms. We verify this
issue on watermarking schemes in Discrete Cosine Transform (DCT), wavelet, and
spatial domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05053</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05053</id><created>2018-03-13</created><updated>2019-08-14</updated><authors><author><keyname>Gao</keyname><forenames>Mingjun</forenames></author><author><keyname>Li</keyname><forenames>Yongzhao</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>Blind Identification of SFBC-OFDM Signals Using Subspace Decompositions
  and Random Matrix Theory</title><categories>eess.SP</categories><journal-ref>IEEE Trans. Veh. Technol. 67 (2018) 9619-9630</journal-ref><doi>10.1109/TVT.2018.2859761</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind signal identification has important applications in both civilian and
military communications. Previous investigations on blind identification of
space-frequency block codes (SFBCs) only considered identifying Alamouti and
spatial multiplexing transmission schemes. In this paper, we propose a novel
algorithm to identify SFBCs by analyzing discriminating features for different
SFBCs, calculated by separating the signal subspace and noise subspace of the
received signals at different adjacent OFDM subcarriers. Relying on random
matrix theory, this algorithm utilizes a serial hypothesis test to determine
the decision boundary according to the maximum eigenvalue in the noise
subspace. Then, a decision tree of a special distance metric is employed for
decision making. The proposed algorithm does not require prior knowledge of the
signal parameters such as the number of transmit antennas, channel
coefficients, modulation mode and noise power. Simulation results verify the
viability of the proposed algorithm for a reduced observation period with an
acceptable computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05058</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05058</id><created>2018-03-13</created><authors><author><keyname>Scharenborg</keyname><forenames>Odette</forenames></author><author><keyname>Larson</keyname><forenames>Martha</forenames></author></authors><title>Investigating the Effect of Music and Lyrics on Spoken-Word Recognition</title><categories>cs.SD cs.CL eess.AS</categories><comments>Preliminary study</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background music in social interaction settings can hinder conversation. Yet,
little is known of how specific properties of music impact speech processing.
This paper addresses this knowledge gap by investigating 1) whether the masking
effect of background music with lyrics is larger than that of music without
lyrics, and 2) whether the masking effect is larger for more complex music. To
answer these questions, a word identification experiment was run in which Dutch
participants listened to Dutch CVC words embedded in stretches of background
music in two conditions, with and without lyrics, and at three SNRs. Three
songs were used of different genres and complexities. Music stretches with and
without lyrics were sampled from the same song in order to control for factors
beyond the presence of lyrics. The results showed a clear negative impact of
the presence of lyrics in background music on spoken-word recognition. This
impact is independent of complexity. The results suggest that social spaces
(e.g., restaurants, caf\'es and bars) should make careful choices of music to
promote conversation, and open a path for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05083</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05083</id><created>2018-03-13</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Block Diagonally Dominant Positive Definite Sub-optimal Filters and
  Smoothers</title><categories>stat.ME cs.SY eess.SY math.RT</categories><journal-ref>Automatica 29, pp. 779-783 (1993</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine stochastic dynamical systems where the transition matrix, $\Phi$,
and the system noise, $\bf{\Gamma}\bf{Q}\bf{\Gamma}^T$, covariance are nearly
block diagonal. When $\bf{H}^T \bf{R}^{-1} \bf{H}$ is also nearly block
diagonal, where $\bf{R}$ is the observation noise covariance and $\bf{H}$ is
the observation matrix, our suboptimal filter/smoothers are always positive
semi-definite, and have improved numerical properties. Applications for
distributed dynamical systems with time dependent pixel imaging are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05110</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05110</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>A Study on the Relationship Between Depth Map Quality and the Overall 3D
  Video Quality OF Experience</title><categories>eess.IV</categories><journal-ref>3DTV, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of multiview displays has made the need for synthesizing
virtual views more pronounced, since it is not practical to capture all of the
possible views when filming multiview content. View synthesis is performed
using the available views and depth maps. There is a correlation between the
quality of the synthesized views and the quality of depth maps. In this paper
we study the effect of depth map quality on perceptual quality of synthesized
view through subjective and objective analysis. Our evaluation results show
that: 1) 3D video quality depends highly on the depth map quality and 2) the
Visual Information Fidelity index computed between the reference and distorted
depth maps has Pearson correlation ratio of 0.75 and Spearman rank order
correlation coefficient of 0.67 with the subjective 3D video quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05118</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05118</id><created>2018-03-13</created><authors><author><keyname>Arjoune</keyname><forenames>Youness</forenames></author></authors><title>Spectrum Sensing: Enhanced Energy Detection Technique Based on Noise
  Measurement</title><categories>eess.SP</categories><doi>10.1109/CCWC.2018.8301619</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing enables cognitive radio systems to detect unused portions of
the radio spectrum and then use them while avoiding interferences to the
primary users. Energy detection is one of the most used techniques for spectrum
sensing because it does not require any prior information about the
characteristics of the primary user signal. However, this technique does not
distinguish between the signal and the noise. It has a low performance at low
SNR, and the selection of the threshold becomes an issue because the noise is
uncertain. The detection performance of this technique can be further improved
using a dynamic selection of the sensing threshold. In this work, we
investigate a dynamic selection of this threshold by measuring the power of
noise present in the received signal using a blind technique. The proposed
model was implemented and tested using GNU Radio software and USRP units. Our
results show that the dynamic selection of the threshold based on measuring the
noise level present in the received signal during the detection process
increases the probability of detection and decreases the probability of false
alarm compared to the ones of energy detection with a static threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05130</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05130</id><created>2018-03-14</created><authors><author><keyname>Riedel</keyname><forenames>Kurt</forenames></author></authors><title>Signal Processing and Piecewise Convex Estimation</title><categories>stat.ME eess.SP math.ST physics.data-an stat.ML stat.TH</categories><journal-ref>ICIAM Proceedings 1993</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems on signal processing reduce to nonparametric function
estimation. We propose a new methodology, piecewise convex fitting (PCF), and
give a two-stage adaptive estimate. In the first stage, the number and location
of the change points is estimated using strong smoothing. In the second stage,
a constrained smoothing spline fit is performed with the smoothing level chosen
to minimize the MSE. The imposed constraint is that a single change point
occurs in a region about each empirical change point of the first-stage
estimate. This constraint is equivalent to requiring that the third derivative
of the second-stage estimate has a single sign in a small neighborhood about
each first-stage change point. We sketch how PCF may be applied to signal
recovery, instantaneous frequency estimation, surface reconstruction, image
segmentation, spectral estimation and multivariate adaptive regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05290</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05290</id><created>2018-03-09</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Glisic</keyname><forenames>Savo</forenames></author></authors><title>Optimization of Scheduling in Wireless Ad-Hoc Networks Using Matrix
  Games</title><categories>cs.NI cs.GT eess.SP</categories><comments>5 pages, 4 figures, PIMRC2010. arXiv admin note: substantial text
  overlap with arXiv:1803.03736</comments><doi>10.1109/PIMRC.2010.5671633</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel application of matrix game theory for
optimization of link scheduling in wireless ad-hoc networks. Optimum scheduling
is achieved by soft coloring of network graphs. Conventional coloring schemes
are based on assignment of one color to each region or equivalently each link
is member of just one partial topology. These algorithms based on coloring are
not optimal when links are not activated with the same rate. Soft coloring,
introduced in this paper, solves this problem and provide optimal solution for
any requested link usage rate. To define the game model for optimum scheduling,
first all possible components of the graph are identified. Components are
defined as sets of the wireless links can be activated simultaneously without
suffering from mutual interference. Then by switching between components with
appropriate frequencies (usage rate) optimum scheduling is achieved. We call
this kind of scheduling as soft coloring because any links can be member of
more than one partial topology, in different time segments. To simplify this
problem, we model relationship between link rates and components selection
frequencies by a matrix game which provides a simple and helpful tool to
simplify and solve the problem. This proposed game theoretic model is solved by
fictitious playing method. Simulation results prove the efficiency of the
proposed technique compared to conventional scheduling based on coloring
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05307</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05307</id><created>2018-03-13</created><authors><author><keyname>Novoselov</keyname><forenames>Sergey</forenames></author><author><keyname>Kudashev</keyname><forenames>Oleg</forenames></author><author><keyname>Schemelinin</keyname><forenames>Vadim</forenames></author><author><keyname>Kremnev</keyname><forenames>Ivan</forenames></author><author><keyname>Lavrentyeva</keyname><forenames>Galina</forenames></author></authors><title>Deep CNN based feature extractor for text-prompted speaker recognition</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Submitted to ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is still not a very common tool in speaker verification field.
We study deep convolutional neural network performance in the text-prompted
speaker verification task. The prompted passphrase is segmented into word
states - i.e. digits -to test each digit utterance separately. We train a
single high-level feature extractor for all states and use cosine similarity
metric for scoring. The key feature of our network is the Max-Feature-Map
activation function, which acts as an embedded feature selector. By using
multitask learning scheme to train the high-level feature extractor we were
able to surpass the classic baseline systems in terms of quality and achieved
impressive results for such a novice approach, getting 2.85% EER on the RSR2015
evaluation set. Fusion of the proposed and the baseline systems improves this
result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05337</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05337</id><created>2018-03-13</created><authors><author><keyname>Defferrard</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Mohanty</keyname><forenames>Sharada P.</forenames></author><author><keyname>Carroll</keyname><forenames>Sean F.</forenames></author><author><keyname>Salath&#xe9;</keyname><forenames>Marcel</forenames></author></authors><title>Learning to Recognize Musical Genre from Audio</title><categories>cs.SD cs.IR cs.LG eess.AS stat.ML</categories><comments>submitted to WWW'18 after challenge round-1</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We here summarize our experience running a challenge with open data for
musical genre recognition. Those notes motivate the task and the challenge
design, show some statistics about the submissions, and present the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05387</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05387</id><created>2018-03-14</created><authors><author><keyname>Costante</keyname><forenames>Gabriele</forenames></author><author><keyname>Ciarfuglia</keyname><forenames>Thomas A.</forenames></author><author><keyname>Biondi</keyname><forenames>Filippo</forenames></author></authors><title>Towards Monocular Digital Elevation Model (DEM) Estimation by
  Convolutional Neural Networks - Application on Synthetic Aperture Radar
  Images</title><categories>eess.SP cs.CV</categories><comments>Accepted for publication in Proceedings of the 12th European
  Conference on Synthetic Aperture Radar</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthetic aperture radar (SAR) interferometry (InSAR) is performed using
repeat-pass geometry. InSAR technique is used to estimate the topographic
reconstruction of the earth surface. The main problem of the range-Doppler
focusing technique is the nature of the two-dimensional SAR result, affected by
the layover indetermination. In order to resolve this problem, a minimum of two
sensor acquisitions, separated by a baseline and extended in the
cross-slant-range, are needed. However, given its multi-temporal nature, these
techniques are vulnerable to atmosphere and Earth environment parameters
variation in addition to physical platform instabilities. Furthermore, either
two radars are needed or an interferometric cycle is required (that spans from
days to weeks), which makes real time DEM estimation impossible. In this work,
the authors propose a novel experimental alternative to the InSAR method that
uses single-pass acquisitions, using a data driven approach implemented by Deep
Neural Networks. We propose a fully Convolutional Neural Network (CNN)
Encoder-Decoder architecture, training it on radar images in order to estimate
DEMs from single pass image acquisitions. Our results on a set of Sentinel
images show that this method is able to learn to some extent the statistical
properties of the DEM. The results of this exploratory analysis are encouraging
and open the way to the solution of single-pass DEM estimation problem with
data driven approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05417</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05417</id><created>2018-03-14</created><updated>2019-01-17</updated><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author></authors><title>Potential Quality Improvement of Stochastic Optical Localization
  Nanoscopy Images Obtained by Frame-by-Frame Localization Algorithms</title><categories>eess.IV</categories><comments>12 pages, 4 figures</comments><msc-class>62-07, 62F12, 62M40</msc-class><acm-class>G.3; H.1.1; I.4.0; I.4.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data movie of stochastic optical localization nanoscopy contains spatial
and temporal correlations, both providing information of emitter locations. The
majority of localization algorithms in the literature estimate emitter
locations by frame-by-frame localization (FFL), which exploit only the spatial
correlation and leave the temporal correlation into the FFL nanoscopy images.
The temporal correlation contained in the FFL images, if exploited, can improve
the localization precision and the image quality. In this paper, we analyze the
potential quality improvement of the FFL images in terms of root mean square
minimum distance (RMSMD) with the reference of root mean square error (RMSE).
It is shown that RMSMD and RMSE can be potentially reduced by a maximum factor
equal to the square root of the average number of activations per emitter.
Several other statistical properties of RMSMD with respect to a large number of
data frames, bias and variance of localization errors, small estimation errors,
sample drafting, and the worst FFL image are also analyzed. Numerical examples
are taken and the results confirm the prediction of analysis. The results
suggest development of two kinds of localization algorithms: the algorithms
that can exploit the temporal correlation of FFL images and the unbiased
localization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05427</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05427</id><created>2018-03-14</created><updated>2018-08-10</updated><authors><author><keyname>Salehghaffari</keyname><forenames>Hossein</forenames></author></authors><title>Speaker Verification using Convolutional Neural Networks</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel Convolutional Neural Network architecture has been
developed for speaker verification in order to simultaneously capture and
discard speaker and non-speaker information, respectively. In training phase,
the network is trained to distinguish between different speaker identities for
creating the background model. One of the crucial parts is to create the
speaker models. Most of the previous approaches create speaker models based on
averaging the speaker representations provided by the background model. We
overturn this problem by further fine-tuning the trained model using the
Siamese framework for generating a discriminative feature space to distinguish
between same and different speakers regardless of their identity. This provides
a mechanism which simultaneously captures the speaker-related information and
create robustness to within-speaker variations. It is demonstrated that the
proposed method outperforms the traditional verification methods which create
speaker models directly from the background model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05428</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05428</id><created>2018-03-13</created><updated>2019-11-11</updated><authors><author><keyname>Roberts</keyname><forenames>Adam</forenames></author><author><keyname>Engel</keyname><forenames>Jesse</forenames></author><author><keyname>Raffel</keyname><forenames>Colin</forenames></author><author><keyname>Hawthorne</keyname><forenames>Curtis</forenames></author><author><keyname>Eck</keyname><forenames>Douglas</forenames></author></authors><title>A Hierarchical Latent Vector Model for Learning Long-Term Structure in
  Music</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>ICML Camera Ready Version (w/ fixed typos)</comments><journal-ref>ICML 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Variational Autoencoder (VAE) has proven to be an effective model for
producing semantically meaningful latent representations for natural data.
However, it has thus far seen limited application to sequential data, and, as
we demonstrate, existing recurrent VAE models have difficulty modeling
sequences with long-term structure. To address this issue, we propose the use
of a hierarchical decoder, which first outputs embeddings for subsequences of
the input and then uses these embeddings to generate each subsequence
independently. This structure encourages the model to utilize its latent code,
thereby avoiding the &quot;posterior collapse&quot; problem, which remains an issue for
recurrent VAEs. We apply this architecture to modeling sequences of musical
notes and find that it exhibits dramatically better sampling, interpolation,
and reconstruction performance than a &quot;flat&quot; baseline model. An implementation
of our &quot;MusicVAE&quot; is available online at http://g.co/magenta/musicvae-code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05482</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05482</id><created>2018-03-14</created><authors><author><keyname>Ignatiev</keyname><forenames>Vladimir</forenames></author><author><keyname>Trekin</keyname><forenames>Alexey</forenames></author><author><keyname>Lobachev</keyname><forenames>Viktor</forenames></author><author><keyname>Potapov</keyname><forenames>Georgy</forenames></author><author><keyname>Burnaev</keyname><forenames>Evgeny</forenames></author></authors><title>Targeted change detection in remote sensing images</title><categories>cs.CV cs.CE eess.IV</categories><comments>10 pages, 1 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent developments in the remote sensing systems and image processing made
it possible to propose a new method of the object classification and detection
of the specific changes in the series of satellite Earth images (so called
targeted change detection). In this paper we propose a formal problem statement
that allows to use effectively the deep learning approach to analyze
time-dependent series of remote sensing images. We also introduce a new
framework for the development of deep learning models for targeted change
detection and demonstrate some cases of business applications it can be used
for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05500</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05500</id><created>2018-03-12</created><authors><author><keyname>Banitalebi</keyname><forenames>A.</forenames></author><author><keyname>Setarehdan</keyname><forenames>S. K.</forenames></author><author><keyname>Hossein-Zadeh</keyname><forenames>G. A.</forenames></author></authors><title>A Technique Based on Chaos for Brain Computer Interfacing</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1803.04606</comments><journal-ref>CSICC, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A user of Brain Computer Interface (BCI) system must be able to control
external computer devices with brain activity. Although the proof-of-concept
was given decades ago, the reliable translation of user intent into device
control commands is still a major challenge. There are problems associated with
classification of different BCI tasks. In this paper we propose the use of
chaotic indices of the BCI. We use largest Lyapunov exponent, mutual
information, correlation dimension and minimum embedding dimension as the
features for the classification of EEG signals which have been released by BCI
Competition IV. A multi-layer Perceptron classifier and a KM- SVM(support
vector machine classifier based on k-means clustering) is used for
classification process, which lead us to an accuracy of 95.5%, for
discrimination between two motor imagery tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05506</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05506</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 - JCT3V-C0032: A human
  visual system based 3D video quality metric</title><categories>eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1803.04624,
  arXiv:1803.04629</comments><journal-ref>MPEG, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution proposes a full-reference Human-Visual-System based 3D
video quality metric. In this report, the presented metric is used to evaluate
the quality of compressed stereo pair formed from a decoded view and a
synthesized view. The performance of the proposed metric is verified through a
series of subjective tests and compared with that of PSNR, SSIM, MS-SSIM, VIFp,
and VQM metrics. The experimental results show that HV3D has the highest
correlation with Mean Opinion Scores (MOS) compared to other tested metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05507</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05507</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Azimi</keyname><forenames>Maryam</forenames></author><author><keyname>Dong</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>ISO/IEC JTC1/SC29/WG11 MPEG2014/ m34661: Quality Assessment of High
  Dynamic Range (HDR) Video Content Using Existing Full-Reference Metrics</title><categories>eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1803.04815</comments><journal-ref>MPEG, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main focus of this document is to evaluate the performance of the
existing LDR and HDR metrics on HDR video content which in turn will allow for
a better understanding of how well each of these metrics work and if they can
be applied in capturing, compressing, transmitting process of HDR data. To this
end a series of subjective tests is performed to evaluate the quality of
DML-HDR video database [1], when several different representing types of
artifacts are present using a HDR display. Then, the correlation between the
results from the existing LDR and HDR quality metrics and those from subjective
tests is measured to determine the most effective exiting quality metric for
HDR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05582</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05582</id><created>2018-03-14</created><authors><author><keyname>Kozek</keyname><forenames>Werner</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt</forenames></author></authors><title>On the Underspread/Overspread Classification of Random Processes</title><categories>stat.ME eess.AS eess.SP math.PR</categories><journal-ref>Conference: Time-Frequency and Time-Scale Analysis, Oct. 1994.,
  Proceedings of the IEEE-SP International Symposium on</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the impact of the recently introduced underspread/overspread
classificationon the spectra of processes with square-integrable covariance
functions. We briefly review the most prominent definitions of a time-varying
power spectrum and point out their limited applicability for {\em general}
nonstationary processes. The time-frequency-parametrized approximation of the
nonstationary Wiener filter provides an excellent example for the main
conclusion: It is the class of underspread processeswhere a time--varying power
spectrum can be used in the same manner as the time--invariant power spectrum
of stationary processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05592</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05592</id><created>2018-03-15</created><authors><author><keyname>Shimly</keyname><forenames>Samiya M.</forenames></author><author><keyname>Smith</keyname><forenames>David B.</forenames></author><author><keyname>Movassaghi</keyname><forenames>Samaneh</forenames></author></authors><title>Wide-Sense-Stationarity of Everyday Wireless Channels for Body-to-Body
  Networks</title><categories>eess.SP</categories><comments>6 pages, 6 figures, International Conference on Communications (ICC)
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of wide-sense-stationarity (WSS) in narrowband wireless
body-to-body networks is investigated for &quot;everyday&quot; scenarios using many hours
of contiguous experimental data. We employ different parametric and
non-parametric hypothesis tests for evaluating mean and variance stationarity,
along with distribution consistency, of several body-to-body channels found
from different on-body sensor locations. We also estimate the variation of
power spectrum to evaluate the time independence of the auto-covariance
function. Our results show that, with 95% confidence, the assumption of WSS is
met for at most 90% of the cases with window lengths of 5 seconds for the
channels between the hubs of different BANs. Additionally, in the best-case
scenario, the hub-to-hub channel remains reasonably stationary (with more than
80% probability of satisfying the null hypothesis) for longer window lengths of
more than 10 seconds. The short time power spectral variation for body-to-body
channels is also shown to be negligible. Moreover, we show that body-to-body
channels can be considered wide-sense-stationary over significantly longer
periods than on-body channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05627</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05627</id><created>2018-03-15</created><updated>2018-06-15</updated><authors><author><keyname>Yoon</keyname><forenames>Jaeyeon</forenames></author><author><keyname>Gong</keyname><forenames>Enhao</forenames></author><author><keyname>Chatnuntawech</keyname><forenames>Itthi</forenames></author><author><keyname>Bilgic</keyname><forenames>Berkin</forenames></author><author><keyname>Lee</keyname><forenames>Jingu</forenames></author><author><keyname>Jung</keyname><forenames>Woojin</forenames></author><author><keyname>Ko</keyname><forenames>Jingyu</forenames></author><author><keyname>Jung</keyname><forenames>Hosan</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Zaharchuk</keyname><forenames>Greg</forenames></author><author><keyname>Kim</keyname><forenames>Eung Yeop</forenames></author><author><keyname>Pauly</keyname><forenames>John</forenames></author><author><keyname>Lee</keyname><forenames>Jongho</forenames></author></authors><title>Quantitative Susceptibility Mapping using Deep Neural Network: QSMnet</title><categories>eess.IV</categories><comments>This work is accepted in neuroimage on 8 June, 2018 and soon will be
  published. The pubmed link is https://www.ncbi.nlm.nih.gov/pubmed/29894829</comments><doi>10.1016/j.neuroimage.2018.06.030.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have demonstrated promising potential for the field of
medical image reconstruction. In this work, an MRI reconstruction algorithm,
which is referred to as quantitative susceptibility mapping (QSM), has been
developed using a deep neural network in order to perform dipole deconvolution,
which restores magnetic susceptibility source from an MRI field map. Previous
approaches of QSM require multiple orientation data (e.g. Calculation of
Susceptibility through Multiple Orientation Sampling or COSMOS) or
regularization terms (e.g. Truncated K-space Division or TKD; Morphology
Enabled Dipole Inversion or MEDI) to solve the ill-conditioned deconvolution
problem. Unfortunately, they either require long multiple orientation scans or
suffer from artifacts. To overcome these shortcomings, a deep neural network,
QSMnet, is constructed to generate a high quality susceptibility map from
single orientation data. The network has a modified U-net structure and is
trained using gold-standard COSMOS QSM maps. 25 datasets from 5 subjects (5
orientation each) were applied for patch-wise training after doubling the data
using augmentation. Two additional datasets of 5 orientation data were used for
validation and test (one dataset each). The QSMnet maps of the test dataset
were compared with those from TKD and MEDI for image quality and consistency in
multiple head orientations. Quantitative and qualitative image quality
comparisons demonstrate that the QSMnet results have superior image quality to
those of TKD or MEDI and have comparable image quality to those of COSMOS.
Additionally, QSMnet maps reveal substantially better consistency across the
multiple orientations than those from TKD or MEDI. As a preliminary
application, the network was tested for two patients. The QSMnet maps showed
similar lesion contrasts with those from MEDI, demonstrating potential for
future applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05661</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05661</id><created>2018-03-15</created><authors><author><keyname>Hunukumbure</keyname><forenames>Mythri</forenames></author><author><keyname>Luo</keyname><forenames>Jian</forenames></author><author><keyname>Castaneda</keyname><forenames>Mario</forenames></author><author><keyname>DErrico</keyname><forenames>Raffaele</forenames></author><author><keyname>Zetterberg</keyname><forenames>Per</forenames></author><author><keyname>Zaidi</keyname><forenames>Ali A.</forenames></author><author><keyname>Vihriala</keyname><forenames>Jaakko</forenames></author><author><keyname>Giustiniano</keyname><forenames>Domenico</forenames></author></authors><title>Mm-wave specific challenges in designing 5G transceiver architectures
  and air-interfaces</title><categories>cs.IT eess.SP math.IT</categories><comments>EuCNC 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mm-wave spectrum will be of significant importance to 5G mobile systems.
There are multiple challenges in designing transceiver architectures and air
interfaces in this spectrum. This paper is an attempt to explain some of these
challenges and their interactions as means of enabling robust system design in
near future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05665</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05665</id><created>2018-03-15</created><authors><author><keyname>Hunukumbure</keyname><forenames>Mythri</forenames></author><author><keyname>DErrico</keyname><forenames>Raffaele</forenames></author><author><keyname>Clemente</keyname><forenames>Antonio</forenames></author><author><keyname>Ratajczak</keyname><forenames>Philippe</forenames></author><author><keyname>Gustavsson</keyname><forenames>Ulf</forenames></author><author><keyname>Qi</keyname><forenames>Yinan</forenames></author><author><keyname>Chen</keyname><forenames>Xiaoming</forenames></author></authors><title>Performance and Impairment Modelling for Hardware Components in
  Millimetre-wave Transceivers</title><categories>cs.IT eess.SP math.IT</categories><comments>EuCNC 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This invited paper details some of the hardware modelling and impairment
analysis carried out in the EU mmMAGIC project. The modelling work includes
handset and Access Point antenna arrays, where specific millimeter-wave
challenges are addressed. In power amplifier related analysis, statistical and
behavioural modelling approaches are discussed. Phase Noise, regarded as a main
impairment in millimeter-wave, is captured under two models and some analysis
into to the impact of phase noise is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05671</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05671</id><created>2018-03-15</created><authors><author><keyname>Cavalcante</keyname><forenames>Renato L. G.</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author></authors><title>Spectral radii of asymptotic mappings and the convergence speed of the
  standard fixed point algorithm</title><categories>eess.SP cs.NA math.NA math.OC</categories><comments>Paper accepted for presentation at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Important problems in wireless networks can often be solved by computing
fixed points of standard or contractive interference mappings, and the
conventional fixed point algorithm is widely used for this purpose. Knowing
that the mapping used in the algorithm is not only standard but also
contractive (or only contractive) is valuable information because we obtain a
guarantee of geometric convergence rate, and the rate is related to a property
of the mapping called modulus of contraction. To date, contractive mappings and
their moduli of contraction have been identified with case-by-case approaches
that can be difficult to generalize. To address this limitation of existing
approaches, we show in this study that the spectral radii of asymptotic
mappings can be used to identify an important subclass of contractive mappings
and also to estimate their moduli of contraction. In addition, if the fixed
point algorithm is applied to compute fixed points of positive concave
mappings, we show that the spectral radii of asymptotic mappings provide us
with simple lower bounds for the estimation error of the iterates. An immediate
application of this result proves that a known algorithm for load estimation in
wireless networks becomes slower with increasing traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05727</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05727</id><created>2018-03-08</created><authors><author><keyname>Shamwell</keyname><forenames>E. Jared</forenames></author><author><keyname>Nothwang</keyname><forenames>William D.</forenames></author><author><keyname>Perlis</keyname><forenames>Donald</forenames></author></authors><title>Multi-Hypothesis Visual-Inertial Flow</title><categories>eess.IV cs.RO</categories><comments>Submitted to IEEE RA-L</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the correspondences between pixels in sequences of images is a
critical first step for a myriad of tasks including vision-aided navigation
(e.g., visual odometry (VO), visual-inertial odometry (VIO), and visual
simultaneous localization and mapping (VSLAM)) and anomaly detection. We
introduce a new unsupervised deep neural network architecture called the Visual
Inertial Flow (VIFlow) network and demonstrate image correspondence and optical
flow estimation by an unsupervised multi-hypothesis deep neural network
receiving grayscale imagery and extra-visual inertial measurements. VIFlow
learns to combine heterogeneous sensor streams and sample from an unknown,
un-parametrized noise distribution to generate several (4 or 8 in this work)
probable hypotheses on the pixel-level correspondence mappings between a source
image and a target image . We quantitatively benchmark VIFlow against several
leading vision-only dense correspondence and flow methods and show a
substantial decrease in runtime and increase in efficiency compared to all
methods with similar performance to state-of-the-art (SOA) dense correspondence
matching approaches. We also present qualitative results showing how VIFlow can
be used for detecting anomalous independent motion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05776</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05776</id><created>2018-03-15</created><updated>2018-03-20</updated><authors><author><keyname>Venkitaraman</keyname><forenames>Arun</forenames></author><author><keyname>Chatterjee</keyname><forenames>Saikat</forenames></author><author><keyname>H&#xe4;ndel</keyname><forenames>Peter</forenames></author></authors><title>Gaussian Processes Over Graphs</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Gaussian processes for signals over graphs (GPG) using the apriori
knowledge that the target vectors lie over a graph. We incorporate this
information using a graph- Laplacian based regularization which enforces the
target vectors to have a specific profile in terms of graph Fourier transform
coeffcients, for example lowpass or bandpass graph signals. We discuss how the
regularization affects the mean and the variance in the prediction output. In
particular, we prove that the predictive variance of the GPG is strictly
smaller than the conventional Gaussian process (GP) for any non-trivial graph.
We validate our concepts by application to various real-world graph signals.
Our experiments show that the performance of the GPG is superior to GP for
small training data sizes and under noisy training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05815</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05815</id><created>2018-03-15</created><authors><author><keyname>Felix</keyname><forenames>Alexander</forenames></author><author><keyname>Cammerer</keyname><forenames>Sebastian</forenames></author><author><keyname>D&#xf6;rner</keyname><forenames>Sebastian</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>OFDM-Autoencoder for End-to-End Learning of Communications Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted to SPAWC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the idea of end-to-end learning of communications systems through
deep neural network (NN)-based autoencoders to orthogonal frequency division
multiplexing (OFDM) with cyclic prefix (CP). Our implementation has the same
benefits as a conventional OFDM system, namely singletap equalization and
robustness against sampling synchronization errors, which turned out to be one
of the major challenges in previous single-carrier implementations. This
enables reliable communication over multipath channels and makes the
communication scheme suitable for commodity hardware with imprecise
oscillators. We show that the proposed scheme can be realized with
state-of-the-art deep learning software libraries as transmitter and receiver
solely consist of differentiable layers required for gradient-based training.
We compare the performance of the autoencoder-based system against that of a
state-of-the-art OFDM baseline over frequency-selective fading channels.
Finally, the impact of a non-linear amplifier is investigated and we show that
the autoencoder inherently learns how to deal with such hardware impairments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05817</identifier>
 <datestamp>2018-03-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05817</id><created>2018-03-15</created><authors><author><keyname>Attar</keyname><forenames>Rahman</forenames></author><author><keyname>Xie</keyname><forenames>Xiang</forenames></author><author><keyname>Wang</keyname><forenames>Zhihua</forenames></author><author><keyname>Yue</keyname><forenames>Shigang</forenames></author></authors><title>2D Reconstruction of Small Intestine's Interior Wall</title><categories>eess.SP cs.CV eess.IV</categories><comments>Journal draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Examining and interpreting of a large number of wireless endoscopic images
from the gastrointestinal tract is a tiresome task for physicians. A practical
solution is to automatically construct a two dimensional representation of the
gastrointestinal tract for easy inspection. However, little has been done on
wireless endoscopic image stitching, let alone systematic investigation. The
proposed new wireless endoscopic image stitching method consists of two main
steps to improve the accuracy and efficiency of image registration. First, the
keypoints are extracted by Principle Component Analysis and Scale Invariant
Feature Transform (PCA-SIFT) algorithm and refined with Maximum Likelihood
Estimation SAmple Consensus (MLESAC) outlier removal to find the most reliable
keypoints. Second, the optimal transformation parameters obtained from first
step are fed to the Normalised Mutual Information (NMI) algorithm as an initial
solution. With modified Marquardt-Levenberg search strategy in a multiscale
framework, the NMI can find the optimal transformation parameters in the
shortest time. The proposed methodology has been tested on two different
datasets - one with real wireless endoscopic images and another with images
obtained from Micro-Ball (a new wireless cubic endoscopy system with six image
sensors). The results have demonstrated the accuracy and robustness of the
proposed methodology both visually and quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05849</identifier>
 <datestamp>2018-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05849</id><created>2018-03-05</created><authors><author><keyname>Bahou</keyname><forenames>Andrawes Al</forenames></author><author><keyname>Karunaratne</keyname><forenames>Geethan</forenames></author><author><keyname>Andri</keyname><forenames>Renzo</forenames></author><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional
  Neural Networks</title><categories>cs.CV cs.AI cs.AR cs.NE eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deploying state-of-the-art CNNs requires power-hungry processors and off-chip
memory. This precludes the implementation of CNNs in low-power embedded
systems. Recent research shows CNNs sustain extreme quantization, binarizing
their weights and intermediate feature maps, thereby saving 8-32\x memory and
collapsing energy-intensive sum-of-products into XNOR-and-popcount operations.
  We present XNORBIN, an accelerator for binary CNNs with computation tightly
coupled to memory for aggressive data reuse. Implemented in UMC 65nm technology
XNORBIN achieves an energy efficiency of 95 TOp/s/W and an area efficiency of
2.0 TOp/s/MGE at 0.8 V.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.05957</identifier>
 <datestamp>2018-09-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.05957</id><created>2018-03-15</created><updated>2018-09-12</updated><authors><author><keyname>Mello</keyname><forenames>Darli A. A.</forenames></author><author><keyname>Barbosa</keyname><forenames>Fabio A.</forenames></author><author><keyname>Reis</keyname><forenames>Jacklyn D.</forenames></author></authors><title>Interplay of Probabilistic Shaping and the Blind Phase Search Algorithm</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in the next available issue of the IEEE/OSA
  Journal of Lightwave Technology
  (https://ieeexplore.ieee.org/document/8457202/)</comments><doi>10.1109/JLT.2018.2869245</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic shaping (PS) is a promising technique to approach the Shannon
limit using typical constellation geometries. However, the impact of PS on the
chain of signal processing algorithms of a coherent receiver still needs
further investigation. In this work we study the interplay of PS and phase
recovery using the blind phase search (BPS) algorithm, which is widely used in
optical communications systems. We first investigate a supervised phase search
(SPS) algorithm as a theoretical upper bound on the BPS performance, assuming
perfect decisions. It is shown that PS influences the SPS algorithm, but its
impact can be alleviated by moderate noise rejection window sizes. On the other
hand, BPS is affected by PS even for long windows because of correlated
erroneous decisions in the phase recovery scheme. The simulation results also
show that the capacity-maximizing shaping is near to the BPS worst-case
situation for square-QAM constellations, causing potential implementation
penalties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06019</identifier>
 <datestamp>2018-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06019</id><created>2018-03-15</created><authors><author><keyname>Bergel</keyname><forenames>Itsik</forenames></author><author><keyname>Zafaruddin</keyname><forenames>S. M.</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author></authors><title>Large Matrix Asymptotic Analysis of ZF and MMSE Crosstalk Cancelers for
  Wireline Channels</title><categories>eess.SP</categories><comments>13 pages, 8 figures. This work has been submitted to the IEEE for
  possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present asymptotic expressions for user throughput in a multi-user
wireline system with a linear decoder, in increasingly large system sizes. This
analysis can be seen as a generalization of results obtained for wireless
communication. The features of the diagonal elements of the wireline channel
matrices make wireless asymptotic analyses inapplicable for wireline systems.
Further, direct application of results from random matrix theory (RMT) yields a
trivial lower bound. This paper presents a novel approach to asymptotic
analysis, where an alternative sequence of systems is constructed that includes
the system of interest in order to approximate the spectral efficiency of the
linear zero-forcing (ZF) and minimum mean squared error (MMSE) crosstalk
cancelers. Using works in the field of large dimensional random matrices, we
show that the user rate in this sequence converges to a non-zero rate. The
approximation of the user rate for both the ZF and MMSE cancelers are very
simple to evaluate and does not need to take specific channel realizations into
account. The analysis reveals the intricate behavior of the throughput as a
function of the transmission power and the channel crosstalk. This unique
behavior has not been observed for linear decoders in other systems. The
approximation presented here is much more useful for the next generation G.fast
wireline system than earlier digital subscriber line (DSL) systems as
previously computed performance bounds, which are strictly larger than zero
only at low frequencies. We also provide a numerical performance analysis over
measured and simulated DSL channels which show that the approximation is
accurate even for relatively low dimensional systems and is useful for many
scenarios in practical DSL systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06044</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06044</id><created>2018-03-15</created><updated>2018-03-25</updated><authors><author><keyname>Sidorenko</keyname><forenames>Alexander</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Optimal Boundary Kernels and Weightings for Local Polynomial Regression</title><categories>stat.ME eess.SP math.ST physics.data-an stat.TH</categories><comments>Manuscript date: 1993</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel smoothers are considered near the boundary of the interval. Kernels
which minimize the expected mean square error are derived. These kernels are
equivalent to using a linear weighting function in the local polynomial
regression. It is shown that any kernel estimator that satisfies the moment
conditions up to order $m$ is equivalent to a local polynomial regression of
order $m$ with some non-negative weight function if and only if the kernel has
at most $m$ sign changes. A fast algorithm is proposed for computing the kernel
estimate in the boundary region for an arbitrary placement of data points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06054</identifier>
 <datestamp>2018-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06054</id><created>2018-03-15</created><authors><author><keyname>Tandiya</keyname><forenames>Nistha</forenames></author><author><keyname>Jauhar</keyname><forenames>Ahmad</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>Deep Predictive Coding Neural Network for RF Anomaly Detection in
  Wireless Networks</title><categories>eess.SP</categories><comments>7 pages, 7 figures, Communications Workshop ICC'18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intrusion detection has become one of the most critical tasks in a wireless
network to prevent service outages that can take long to fix. The sheer variety
of anomalous events necessitates adopting cognitive anomaly detection methods
instead of the traditional signature-based detection techniques. This paper
proposes an anomaly detection methodology for wireless systems that is based on
monitoring and analyzing radio frequency (RF) spectrum activities. Our
detection technique leverages an existing solution for the video prediction
problem, and uses it on image sequences generated from monitoring the wireless
spectrum. The deep predictive coding network is trained with images
corresponding to the normal behavior of the system, and whenever there is an
anomaly, its detection is triggered by the deviation between the actual and
predicted behavior. For our analysis, we use the images generated from the
time-frequency spectrograms and spectral correlation functions of the received
RF signal. We test our technique on a dataset which contains anomalies such as
jamming, chirping of transmitters, spectrum hijacking, and node failure, and
evaluate its performance using standard classifier metrics: detection ratio,
and false alarm rate. Simulation results demonstrate that the proposed
methodology effectively detects many unforeseen anomalous events in real time.
We discuss the applications, which encompass industrial IoT, autonomous vehicle
control and mission-critical communications services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06059</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06059</id><created>2018-03-15</created><updated>2018-07-16</updated><authors><author><keyname>Zhang</keyname><forenames>Di</forenames></author></authors><title>Distributed Cache Enabled V2X Networks: Proposals, Research Trends and
  Challenging Issues</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the internet of vehicles (IoV) has been evolved into the stage of
vehicle to everything (V2X). However, the majority of existing work focuses on
the motor-vehicles. In contrast, the sharing bicycle system is vastly and
rapidly deployed as a feasible internet of things (IoT) application scene for
the last mile problem (e.g., from station to home/office). Moreover, the
internet access of current V2X is relied on the back-haul to roadside unit
(RSU) connections. In this paper, other than prior work, we propose a versatile
V2X system with a distributed framework and heterogeneous caching method. All
the vehicles and devices on-the-road (motor-vehicle, non-motor-vehicle,
pedestrian, etc.) are comprehensively included in the proposed networks. We
further introduce a heterogeneous cache method for effective wireless
transmission while utilizing the massive connected devices. The potential
research trends on achieving high speed transmission, deep programming
dedicated network slicing are highlighted as well as the big data, machine
learning (ML), fog computing based image recognition and reconstruction, to
provide some insights for future studies. Finally, the challenging issues,
i.e., urban street canyon path loss and channel models, ultra reliable
communication and low latency requirements, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06230</identifier>
 <datestamp>2018-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06230</id><created>2018-03-13</created><authors><author><keyname>Huang</keyname><forenames>Can</forenames></author><author><keyname>Thimmisetty</keyname><forenames>Charanraj A.</forenames></author><author><keyname>Chen</keyname><forenames>Xiao</forenames></author><author><keyname>Korkali</keyname><forenames>Mert</forenames></author><author><keyname>Donde</keyname><forenames>Vaibhav</forenames></author><author><keyname>Stewart</keyname><forenames>Emma</forenames></author><author><keyname>Top</keyname><forenames>Philip</forenames></author><author><keyname>Tong</keyname><forenames>Charles</forenames></author><author><keyname>Min</keyname><forenames>Liang</forenames></author></authors><title>Power Distribution System Synchrophasors with Non-Gaussian Errors:
  Real-World Measurements and Analysis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter studies the synchrophasor measurement error of electric power
distribution systems with on-line and off-line measurements using graphical and
numerical tests. It demonstrates that the synchrophasor measurement error
follows a non-Gaussian distribution instead of the traditionally-assumed
Gaussian distribution. It suggests the need to use non-Gaussian or Gaussian
mixture models to represent the synchrophasor measurement error. These models
are more realistic to accurately represent the error than the traditional
Gaussian model. The measurements and underlying analysis will be helpful for
the understanding of distribution system measurement characteristics, and also
for the modeling and simulation of distribution system applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06231</identifier>
 <datestamp>2018-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06231</id><created>2018-03-13</created><authors><author><keyname>Tang</keyname><forenames>Xinyao</forenames></author><author><keyname>Zhao</keyname><forenames>Haixiang</forenames></author><author><keyname>Mandal</keyname><forenames>Soumyajit</forenames></author></authors><title>A Programmable CMOS Transceiver for Structural Health Monitoring</title><categories>eess.SP</categories><journal-ref>2018 IEEE Custom Integrated Circuits Conference</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a highly-integrated CMOS transceiver for active structural health
monitoring (SHM). The chip actuates piezoelectric transducers and also senses
ultrasound waves received by the same or another transducer. The transmitter
uses an integer-N frequency synthesizer and pulse-width modulation (PWM) to
generate low-distortion, band-limited waveforms up to 12.7 Vpp with center
frequency from 0.1-2.75 MHz. The integrated offset-canceling fully-differential
receiver has programmable gain and bandwidth, and uses quadrature demodulation
to extract both amplitude and phase of the received waveforms for further
signal processing. The transceiver was fabricated in a 0.5 um CMOS process and
has been validated using (2D) damage localization on an SHM test bed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06234</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06234</id><created>2018-03-14</created><authors><author><keyname>Kawasumi</keyname><forenames>Ryota</forenames></author><author><keyname>Takeda</keyname><forenames>Koujin</forenames></author></authors><title>Approximate Method of Variational Bayesian Matrix
  Factorization/Completion with Sparse Prior</title><categories>eess.SP cond-mat.dis-nn cs.IT cs.LG math.IT</categories><comments>22 pages, 4 figures, part of this work was presented in IEEE
  International Workshop on Machine Learning for Signal Processing (2017)</comments><journal-ref>J. Stat. Mech. (2018) 053404</journal-ref><doi>10.1088/1742-5468/aabc7d</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive analytical expression of matrix factorization/completion solution
by variational Bayes method, under the assumption that observed matrix is
originally the product of low-rank dense and sparse matrices with additive
noise. We assume the prior of sparse matrix is Laplace distribution by taking
matrix sparsity into consideration. Then we use several approximations for
derivation of matrix factorization/completion solution. By our solution, we
also numerically evaluate the performance of sparse matrix reconstruction in
matrix factorization, and completion of missing matrix element in matrix
completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06248</identifier>
 <datestamp>2018-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06248</id><created>2018-03-13</created><authors><author><keyname>Banitalebi-Dehkordi</keyname><forenames>Amin</forenames></author><author><keyname>Pourazad</keyname><forenames>Mahsa T.</forenames></author><author><keyname>Nasiopoulos</keyname><forenames>Panos</forenames></author></authors><title>3D Video Quality Metric for Mobile Applications</title><categories>eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1803.04624;
  text overlap with arXiv:1803.04832 and arXiv:1803.04836</comments><journal-ref>ICASSP, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new full-reference quality metric for mobile 3D
content. Our method is modeled around the Human Visual System, fusing the
information of both left and right channels, considering color components, the
cyclopean views of the two videos and disparity. Our method is assessing the
quality of 3D videos displayed on a mobile 3DTV, taking into account the effect
of resolution, distance from the viewers eyes, and dimensions of the mobile
display. Performance evaluations showed that our mobile 3D quality metric
monitors the degradation of quality caused by several representative types of
distortion with 82 percent correlation with results of subjective tests, an
accuracy much better than that of the state of the art mobile 3D quality
metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06312</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06312</id><created>2018-03-16</created><updated>2018-04-16</updated><authors><author><keyname>Buckler</keyname><forenames>Mark</forenames></author><author><keyname>Bedoukian</keyname><forenames>Philip</forenames></author><author><keyname>Jayasuriya</keyname><forenames>Suren</forenames></author><author><keyname>Sampson</keyname><forenames>Adrian</forenames></author></authors><title>EVA$^2$: Exploiting Temporal Redundancy in Live Computer Vision</title><categories>cs.CV eess.IV</categories><comments>Appears in ISCA 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hardware support for deep convolutional neural networks (CNNs) is critical to
advanced computer vision in mobile and embedded devices. Current designs,
however, accelerate generic CNNs; they do not exploit the unique
characteristics of real-time vision. We propose to use the temporal redundancy
in natural video to avoid unnecessary computation on most frames. A new
algorithm, activation motion compensation, detects changes in the visual input
and incrementally updates a previously-computed output. The technique takes
inspiration from video compression and applies well-known motion estimation
techniques to adapt to visual changes. We use an adaptive key frame rate to
control the trade-off between efficiency and vision quality as the input
changes. We implement the technique in hardware as an extension to existing
state-of-the-art CNN accelerator designs. The new unit reduces the average
energy per frame by 54.2%, 61.7%, and 87.6% for three CNNs with less than 1%
loss in vision accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06441</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06441</id><created>2018-03-16</created><authors><author><keyname>Tan</keyname><forenames>Chunyu</forenames></author><author><keyname>Zhang</keyname><forenames>Liming</forenames></author><author><keyname>Wu</keyname><forenames>Hau-tieng</forenames></author></authors><title>A Novel Blaschke Unwinding Adaptive Fourier Decomposition based Signal
  Compression Algorithm with Application on ECG Signals</title><categories>eess.SP physics.data-an stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel signal compression algorithm based on the
Blaschke unwinding adaptive Fourier decomposition (AFD). The Blaschke unwinding
AFD is a newly developed signal decomposition theory. It utilizes the
Nevanlinna factorization and the maximal selection principle in each
decomposition step, and achieves a faster convergence rate with higher
fidelity. The proposed compression algorithm is applied to the
electrocardiogram signal. To assess the performance of the proposed compression
algorithm, in addition to the generic assessment criteria, we consider the less
discussed criteria related to the clinical needs -- for the heart rate
variability analysis purpose, how accurate the R peak information is preserved
is evaluated. The experiments are conducted on the MIT-BIH arrhythmia benchmark
database. The results show that the proposed algorithm performs better than
other state-of-the-art approaches. Meanwhile, it also well preserves the R peak
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06452</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06452</id><created>2018-03-16</created><updated>2018-03-29</updated><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author><author><keyname>Sidorenko</keyname><forenames>Alexander</forenames></author><author><keyname>Bretz</keyname><forenames>Norton</forenames></author><author><keyname>Thomson</keyname><forenames>David J.</forenames></author></authors><title>Spectral Estimation of Plasma Fluctuations II: Nonstationary Analysis of
  ELM Spectra</title><categories>physics.plasm-ph eess.AS physics.data-an stat.AP</categories><comments>Figures missing</comments><journal-ref>Physics of Plasmas, Volume 1, Issue 3, March 1994, pp.501-514</journal-ref><doi>10.1063/1.870939</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several analysis methods for nonstationary fluctuations are described and
applied to the edge localized mode (ELM) instabilities of limiter H-mode
plasmas. The microwave scattering diagnostic observes poloidal $k_{\theta}$
values of 3.3 cm$^{-1}$, averaged over a 20 cm region at the plasma edge.A
short autoregressive filter enhances the nonstationary component of the plasma
fluctuations by removing much of the background level of stationary
fluctuations. Between ELMs, the spectrum predominantly consists of broad-banded
300-700 kHz fluctuations propagating in the electron diamagnetic drift
direction, indicating the presence of a negative electric field near the plasma
edge. The time-frequency spectrogram is computed with the multiple taper
technique. By using the singular value decomposition of the spectrogram, it is
shown that the spectrum during the ELM is broader and more symmetric than that
of the stationary spectrum. The ELM period and the evolution of the spectrum
between ELMs varies from discharge to discharge. For the discharge under
consideration which has distinct ELMs with a 1 msec period, the spectrum has a
maximum in the electron drift direction which relaxes to a near constant value
%its characteristic shape in the first half millisecond after the end of the
ELM and then grows slowly. In contrast, the level of the fluctuations in the
ion drift direction increases exponentially by a factor of eight in the five
milliseconds~after the ELM. High frequency precursors are found which occur one
millisecond before the ELMs and propagate in the ion drift direction. These
precursors are very short ($\sim 10 \mu$secs), coherent bursts, and they
predict the occurrence of an ELM with a high success rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06466</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06466</id><created>2018-03-17</created><authors><author><keyname>Garcia</keyname><forenames>Diogo C.</forenames></author><author><keyname>Fonseca</keyname><forenames>Tiago A.</forenames></author><author><keyname>de Queiroz</keyname><forenames>Ricardo L.</forenames></author></authors><title>Example-based super-resolution for point-cloud video</title><categories>eess.SP</categories><comments>This paper was submitted to ICIP-2018 and its copyright may be
  transferred to IEEE. Work partially supported by CNPq under grant
  308150/2014-7</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a mixed-resolution point-cloud representation and an example-based
super-resolution framework, from which several processing tools can be derived,
such as compression, denoising and error concealment. By inferring the
high-frequency content of low-resolution frames based on the similarities
between adjacent full-resolution frames, the proposed framework achieves an
average 1.18 dB gain over low-pass versions of the point-cloud, for a
projection-based distortion metric[1-2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06480</identifier>
 <datestamp>2018-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06480</id><created>2018-03-17</created><authors><author><keyname>Kumaran</keyname><forenames>Santhosh Kelathodi</forenames></author><author><keyname>Dogra</keyname><forenames>Debi Prosad</forenames></author><author><keyname>Roy</keyname><forenames>Partha Pratim</forenames></author></authors><title>Queuing Theory Guided Intelligent Traffic Scheduling through Video
  Analysis using Dirichlet Process Mixture Model</title><categories>cs.CV eess.IV</categories><journal-ref>Expert Systems with Applications Volume 118, 15 March 2019, Pages
  169-181</journal-ref><doi>10.1016/j.eswa.2018.09.057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate prediction of traffic signal duration for roadway junction is a
challenging problem due to the dynamic nature of traffic flows. Though
supervised learning can be used, parameters may vary across roadway junctions.
In this paper, we present a computer vision guided expert system that can learn
the departure rate of a given traffic junction modeled using traditional
queuing theory. First, we temporally group the optical flow of the moving
vehicles using Dirichlet Process Mixture Model (DPMM). These groups are
referred to as tracklets or temporal clusters. Tracklet features are then used
to learn the dynamic behavior of a traffic junction, especially during on/off
cycles of a signal. The proposed queuing theory based approach can predict the
signal open duration for the next cycle with higher accuracy when compared with
other popular features used for tracking. The hypothesis has been verified on
two publicly available video datasets. The results reveal that the DPMM based
features are better than existing tracking frameworks to estimate $\mu$. Thus,
signal duration prediction is more accurate when tested on these datasets.The
method can be used for designing intelligent operator-independent traffic
control systems for roadway junctions at cities and highways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06554</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06554</id><created>2018-03-17</created><authors><author><keyname>Wei</keyname><forenames>Pan</forenames></author><author><keyname>Ball</keyname><forenames>John E.</forenames></author><author><keyname>Anderson</keyname><forenames>Derek T.</forenames></author></authors><title>Fusion of an Ensemble of Augmented Image Detectors for Robust Object
  Detection</title><categories>cs.CV cs.AI eess.IV</categories><comments>21 pages, 12 figures, journal paper, MDPI Sensors, 2018</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  A significant challenge in object detection is accurate identification of an
object's position in image space, whereas one algorithm with one set of
parameters is usually not enough, and the fusion of multiple algorithms and/or
parameters can lead to more robust results. Herein, a new computational
intelligence fusion approach based on the dynamic analysis of agreement among
object detection outputs is proposed. Furthermore, we propose an online versus
just in training image augmentation strategy. Experiments comparing the results
both with and without fusion are presented. We demonstrate that the augmented
and fused combination results are the best, with respect to higher accuracy
rates and reduction of outlier influences. The approach is demonstrated in the
context of cone, pedestrian and box detection for Advanced Driver Assistance
Systems (ADAS) applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06571</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06571</id><created>2018-03-17</created><authors><author><keyname>Mullhaupt</keyname><forenames>Andrew</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt</forenames></author></authors><title>Orthogonal Representations for Output System Pairs</title><categories>stat.ME cs.SY eess.SY math.ST stat.TH</categories><comments>Work done in 200. Minor Revision 2001</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of canonical forms is given proposed in which $(A, C)$ is in
Hessenberg observer or Schur form and output normal: $\bf{I} - A^*A =C^*C$.
Here, $C$ is the $d \times n$ measurement matrix and $A$ is the advance matrix.
The $(C, A)$ stack is expressed as the product of $n$ orthogonal matrices, each
of which depends on $d$ parameters. State updates require only ${\cal O}(nd)$
operations and derivatives of the system with respect to the parameters are
fast and convenient to compute. Restrictions are given such that these models
are generically identifiable. Since the observability Grammian is the identity
matrix, system identification is better conditioned than other classes of
models with fast updates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06690</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06690</id><created>2018-03-18</created><authors><author><keyname>Nagulu</keyname><forenames>Aravind</forenames></author><author><keyname>Dinc</keyname><forenames>Tolga</forenames></author><author><keyname>Xiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Tymchenko</keyname><forenames>Mykhailo</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios</forenames></author><author><keyname>Al&#xf9;</keyname><forenames>Andrea</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Harish</forenames></author></authors><title>Non-reciprocal Components Based on Switched Transmission Lines</title><categories>eess.SP</categories><comments>17 pages, 24 figures, TMTT, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-reciprocal components, such as isolators and circulators, are critical to
wireless communication and radar applications. Traditionally, non-reciprocal
components have been implemented using ferrite materials, which exhibit
non-reciprocity under the influence of an external magnetic field. However,
ferrite materials cannot be integrated into IC fabrication processes, and
consequently are bulky and expensive. In the recent past, there has been strong
interest in achieving non-reciprocity in a non-magnetic IC-compatible fashion
using spatio-temporal modulation. In this paper, we present a general approach
to non-reciprocity based on switched transmission lines. Switched transmission
lines enable broadband, lossless and compact non-reciprocity, and a wide range
of non-reciprocal functionalities, including non-reciprocal phase shifters,
ultra-broadband gyrators and isolators, frequency-conversion isolators, and
high-linearity/high-frequency/ultra-broadband circulators. We present a
detailed theoretical analysis of the various non-idealities that impact
insertion loss and provide design guidelines. The theory is validated by
experimental results from discrete-component-based gyrators and isolators, and
a 25GHz circulator fabricated in 45nm SOI CMOS technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06718</identifier>
 <datestamp>2018-05-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06718</id><created>2018-03-18</created><updated>2018-05-24</updated><authors><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author></authors><title>Directional emphasis in ambisonics</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an ambisonics enhancement method that increases the signal
strength in specified directions at low computational cost. The method can be
used in a static setup to emphasize the signal arriving from a particular
direction or set of directions. It can also be used in an adaptive arrangement
where it sharpens directionality and reduces the distortion in timbre
associated with low-degree ambisonics representations. The emphasis operator
has very low computational complexity and can be applied to time-domain as well
as time-frequency ambisonics representations. The operator upscales a
low-degree ambisonics representation to a higher degree representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06734</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06734</id><created>2018-03-18</created><updated>2019-06-11</updated><authors><author><keyname>Ma</keyname><forenames>Ke</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>The Strategic LQG System: A Dynamic Stochastic VCG Framework for Optimal
  Coordination</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classic Vickrey-Clarke-Groves (VCG) mechanism ensures incentive
compatibility, i.e., that truth-telling of all agents is a dominant strategy,
for a static one-shot game. However, in a dynamic environment that unfolds over
time, the agents' intertemporal payoffs depend on the expected future controls
and payments, and a direct extension of the VCG mechanism is not sufficient to
guarantee incentive compatibility. In fact, it does not appear to be feasible
to construct mechanisms that ensure the dominance of dynamic truth-telling for
agents comprised of general stochastic dynamic systems. The contribution of
this paper is to show that such a dynamic stochastic extension does exist for
the special case of Linear-Quadratic-Gaussian (LQG) agents with a careful
construction of a sequence of layered payments over time. For a set of LQG
agents, we propose a modified layered version of the VCG mechanism for payments
that decouples the intertemporal effect of current bids on future payoffs, and
prove that truth-telling of dynamic states forms a dominant strategy if system
parameters are known and agents are rational.
  An important example of a problem needing such optimal dynamic coordination
of stochastic agents arises in power systems where an Independent System
Operator (ISO) has to ensure balance of generation and consumption at all time
instants, while ensuring social optimality. The challenge is to determine a
bidding scheme between all agents and the ISO that maximizes social welfare,
while taking into account the stochastic dynamic models of agents, since
renewable energy resources such as solar/wind are stochastic and dynamic in
nature, as are consumptions by loads which are influenced by factors such as
local temperatures and thermal inertias of facilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06810</identifier>
 <datestamp>2018-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06810</id><created>2018-03-19</created><updated>2018-11-16</updated><authors><author><keyname>Sawant</keyname><forenames>Suneet</forenames></author><author><keyname>Kumar</keyname><forenames>Rohit</forenames></author><author><keyname>Hanawal</keyname><forenames>Manjesh K.</forenames></author><author><keyname>Darak</keyname><forenames>Sumit J.</forenames></author></authors><title>Learning to Coordinate in a Decentralized Cognitive Radio Network in
  Presence of Jammers</title><categories>eess.SP</categories><comments>Conference version published in WiOpt 2018
  (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8362853)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient utilization of licensed spectrum in the cognitive radio network is
challenging due to lack of coordination among the Secondary Users (SUs).
Distributed algorithms proposed in the literature aim to maximize the network
throughput by ensuring orthogonal channel allocation for the SUs. However,
these algorithms work under the assumption that all the SUs faithfully follow
the algorithms which may not always hold due to the decentralized nature of the
network. In this paper, we study distributed algorithms that are robust against
malicious behavior (jamming attack). We consider both the cases of jammers
launching coordinated and uncoordinated attacks. In the coordinated attack, the
jammers select non-overlapping channels to attack in each time slot and can
significantly increase the number of collisions for SUs. We setup the problem
in each scenario as a multi-player bandit and develop algorithms. The analysis
shows that when the SUs faithfully implement proposed algorithms, the regret is
constant with high probability. We validate our claims through exhaustive
synthetic experiments and also through a realistic USRP based experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06838</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06838</id><created>2018-03-19</created><authors><author><keyname>Abolfathi</keyname><forenames>Abbas</forenames></author><author><keyname>Behnia</keyname><forenames>Fereidoon</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>NLOS Mitigation Using Sparsity Feature And Iterative Methods</title><categories>eess.SP</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Well-known methods are employed to localize mobile station (MS) using line of
sight (LOS) measurements. These methods may result in large error if they are
fed with non LOS (NLOS) measurements. Our proposed algorithm, referred to as
Sparse Recovery of NLOS using IMAT (SRNI), considers NLOS as unknown variables
and solves the resultant underdetermined system emphasizing on its sparsity
feature based on IMAT methods. Simulations are conducted to investigate the
performance of SRNI in comparison of other conventional algorithms. Results
demonstrate that SRNI is fast enough to deal with large combination of BSs and
also accurate in lower number of BSs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06841</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06841</id><created>2018-03-19</created><updated>2018-07-19</updated><authors><author><keyname>Dai</keyname><forenames>Shuqi</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author><author><keyname>Xia</keyname><forenames>Gus G.</forenames></author></authors><title>Music Style Transfer: A Position Paper</title><categories>cs.SD eess.AS</categories><comments>In Proceeding of International Workshop on Musical Metacreation
  (MUME), 2018, Salamanca, Spain</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Led by the success of neural style transfer on visual arts, there has been a
rising trend very recently in the effort of music style transfer. However,
&quot;music style&quot; is not yet a well-defined concept from a scientific point of
view. The difficulty lies in the intrinsic multi-level and multi-modal
character of music representation (which is very different from image
representation). As a result, depending on their interpretation of &quot;music
style&quot;, current studies under the category of &quot;music style transfer&quot;, are
actually solving completely different problems that belong to a variety of
sub-fields of Computer Music. Also, a vanilla end-to-end approach, which aims
at dealing with all levels of music representation at once by directly adopting
the method of image style transfer, leads to poor results. Thus, we vitally
propose a more scientifically-viable definition of music style transfer by
breaking it down into precise concepts of timbre style transfer, performance
style transfer and composition style transfer, as well as to connect different
aspects of music style transfer with existing well-established sub-fields of
computer music studies. In addition, we discuss the current limitations of
music style modeling and its future directions by drawing spirit from some deep
generative models, especially the ones using unsupervised learning and
disentanglement techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06871</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06871</id><created>2018-03-19</created><authors><author><keyname>Haqiqatnejad</keyname><forenames>A.</forenames></author><author><keyname>Kayhan</keyname><forenames>F.</forenames></author><author><keyname>Ottersten</keyname><forenames>B.</forenames></author></authors><title>Symbol-Level Precoding Design for Max-Min SINR in Multiuser MISO
  Broadcast Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to SPAWC 2018, 7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the symbol level precoding (SLP) design problem
under max-min SINR criterion in the downlink of multiuser multiple-input
single-output (MISO) channels. First, we show that the distance preserving
constructive interference regions (DPCIR) are always polyhedral angles (shifted
pointed cones) for any given constellation point with unbounded decision
region. Then we prove that any signal in a given unbounded DPCIR has a norm
larger than the norm of the corresponding vertex if and only if the convex hull
of the constellation contains the origin. Using these properties, we show that
the power of the noiseless received signal lying on an unbounded DPCIR is an
strictly increasing function of two parameters. This allows us to reformulate
the originally non-convex SLP max-min SINR as a convex optimization problem. We
discuss the loss due to our proposed convex reformulation and provide some
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06892</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06892</id><created>2018-03-19</created><updated>2018-10-30</updated><authors><author><keyname>Sanchez</keyname><forenames>Santiago</forenames></author><author><keyname>Garces</keyname><forenames>Alejandro</forenames></author><author><keyname>Berna</keyname><forenames>Gilbert</forenames></author><author><keyname>Tedeschi</keyname><forenames>Elisabetta</forenames></author></authors><title>Dynamics and Stability of Meshed Multiterminal HVDC Networks</title><categories>eess.SP</categories><comments>8</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the existence of an equilibrium point in
multiterminal HVDC (MT-HVDC) grids, assesses its uniqueness and defines
conditions to ensure its stability. An offshore MT-HVDC system including two
wind farms is selected as application test case. At first, a generalized
dynamic model of the network is proposed, using hypergraph theory. Such model
captures the frequency dependence of transmission lines and cables, it is
non-linear due to the constant power behavior of the converter terminals using
droop regulation, and presents a suitable degree of simplifications of the MMC
converters, under given conditions, to allow system level studies over
potentially large networks. Based on this model, the existence and uniqueness
of the equilibrium point is demonstrated by returning the analysis to a
load-flow problem and using the Banach fixed point theorem. Additionally, the
stability of the equilibrium is analyzed by obtaining a Lyapunov function by
the Krasovskii's theorem. Computational results obtained for the selected 4
terminals MT-HVDC grid corroborate the requirement for the existence and
stability of the equilibrium point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.06943</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.06943</id><created>2018-03-19</created><authors><author><keyname>Huo</keyname><forenames>Yiming</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Yuen</keyname><forenames>Marvin</forenames></author></authors><title>Cellular and WiFi Co-design for 5G User Equipment</title><categories>eess.SP</categories><comments>6 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by providing solutions to design challenges of coexisting cellular
and WiFi for future 5G application scenarios, this paper, first, conducts an
in-depth investigation of current technological trends of 5G from user
equipment (UE) design perspective, and then presents a cost-effective
cellular-WiFi design methodology based on the new distributed phased array MIMO
(DPA-MIMO) architecture for practical 5G UE devices as an example. Furthermore,
additional 5G cellular-WiFi application scenarios and co-operation details
within 5G heterogeneous networks are unveiled on top of the said cellular-WiFi
co-enabled 5G UE design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07065</identifier>
 <datestamp>2018-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07065</id><created>2018-03-19</created><authors><author><keyname>Cho</keyname><forenames>Youngjun</forenames></author></authors><title>Sensorless Resonance Tracking of Resonant Electromagnetic Actuator
  through Back-EMF Estimation for Mobile Devices</title><categories>physics.app-ph cs.SY eess.SP math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resonant electromagnetic actuators have been broadly used as vibration motors
for mobile devices given their ability of generating relatively fast, strong,
and controllable vibration force at a given resonant frequency. Mechanism of
the actuators that is based on mechanical resonance, however, limits their use
to a situation where their resonant frequencies are known and unshifted. In
reality, there are many factors that alter the resonant frequency: for example,
manufacturing tolerances, worn mechanical components such as a spring,
nonlinearity in association with different input voltage levels. Here, we
describe a sensorless resonance tracking method that actuates the motor and
automatically detects its unknown damped natural frequency through the
estimation of back electromotive force (EMF) and inner mass movements. We
demonstrate the tracking performance of the proposed method through a series of
experiments. This approach has the potential to control residual vibrations and
then improve vibrotactile feedback, which can potentially be used for
human-computer interaction, cognitive and affective neuroscience research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07123</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07123</id><created>2018-03-19</created><authors><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Kim</keyname><forenames>Dong In</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Fundamentals of Wireless Information and Power Transfer: From RF Energy
  Harvester Models to Signal and System Designs</title><categories>cs.IT eess.SP math.IT</categories><comments>guest editor-authored tutorial paper submitted to IEEE JSAC special
  issue on wireless transmission of information and power</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio waves carry both energy and information simultaneously. Nevertheless,
Radio-Frequency (RF) transmission of these quantities have traditionally been
treated separately. Currently, we are experiencing a paradigm shift in wireless
network design, namely unifying wireless transmission of information and power
so as to make the best use of the RF spectrum and radiations as well as the
network infrastructure for the dual purpose of communicating and energizing. In
this paper, we review and discuss recent progress on laying the foundations of
the envisioned dual purpose networks by establishing a signal theory and design
for Wireless Information and Power Transmission (WIPT) and identifying the
fundamental tradeoff between conveying information and power wirelessly. We
start with an overview of WIPT challenges and technologies, namely Simultaneous
Wireless Information and Power Transfer (SWIPT),Wirelessly Powered
Communication Network (WPCN), and Wirelessly Powered Backscatter Communication
(WPBC). We then characterize energy harvesters and show how WIPT signal and
system designs crucially revolve around the underlying energy harvester model.
To that end, we highlight three different energy harvester models, namely one
linear model and two nonlinear models, and show how WIPT designs differ for
each of them in single-user and multi-user deployments. Topics discussed
include rate-energy region characterization, transmitter and receiver
architecture, waveform design, modulation, beamforming and input distribution
optimizations, resource allocation, and RF spectrum use. We discuss and check
the validity of the different energy harvester models and the resulting signal
theory and design based on circuit simulations, prototyping and
experimentation. We also point out numerous directions that are promising for
future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07160</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07160</id><created>2018-02-18</created><updated>2018-08-15</updated><authors><author><keyname>Salem</keyname><forenames>N. Pelin M. H.</forenames></author><author><keyname>Niver</keyname><forenames>Edip</forenames></author><author><keyname>Salem</keyname><forenames>Mohamed A.</forenames></author></authors><title>Microwave Vortex Beam Launcher Design</title><categories>physics.app-ph eess.SP physics.class-ph</categories><comments>This paper is a postprint of a paper submitted to and accepted for
  publication in IET Microwaves, Antennas &amp; Propagation Journal and is subject
  to Institution of Engineering and Technology Copyright. The copy of record is
  available at IET Digital Library</comments><journal-ref>Salem, Nedime Pelin M.H.; Niver, Edip; Salem, Mohamed A.:
  'Microwave vortex beam launcher design', IET Microwaves, Antennas &amp;
  Propagation, 2018</journal-ref><doi>10.1049/iet-map.2018.5007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel design for a vectorial vortex beam launcher in the microwave regime
is devised. The beam is formed by launching a single guided transverse electric
(TE) mode of a metallic circular waveguide into free-space. Excitation is
achieved by the mean of an inserted coaxial loop antenna. Modal expansion
coefficients are computed, and the resulting electric and magnetic fields are
determined. The effect of the antenna location inside the waveguide on its
effective input impedance is modelled using transmission-line relations and
location for optimal matching is established. The analytical results are
confirmed using multi-level fast multipole method full-wave simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07187</identifier>
 <datestamp>2019-04-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07187</id><created>2018-03-19</created><authors><author><keyname>Calatroni</keyname><forenames>Luca</forenames></author><author><keyname>d'Autume</keyname><forenames>Marie</forenames></author><author><keyname>Hocking</keyname><forenames>Rob</forenames></author><author><keyname>Panayotova</keyname><forenames>Stella</forenames></author><author><keyname>Parisotto</keyname><forenames>Simone</forenames></author><author><keyname>Ricciardi</keyname><forenames>Paola</forenames></author><author><keyname>Sch&#xf6;nlieb</keyname><forenames>Carola-Bibiane</forenames></author></authors><title>Unveiling the invisible - mathematical methods for restoring and
  interpreting illuminated manuscripts</title><categories>cs.CV eess.IV math.NA</categories><doi>10.1186/s40494-018-0216-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last fifty years have seen an impressive development of mathematical
methods for the analysis and processing of digital images, mostly in the
context of photography, biomedical imaging and various forms of engineering.
The arts have been mostly overlooked in this process, apart from a few
exceptional works in the last ten years. With the rapid emergence of
digitisation in the arts, however, the arts domain is becoming increasingly
receptive to digital image processing methods and the importance of paying
attention to this therefore increases. In this paper we discuss a range of
mathematical methods for digital image restoration and digital visualisation
for illuminated manuscripts. The latter provide an interesting opportunity for
digital manipulation because they traditionally remain physically untouched. At
the same time they also serve as an example for the possibilities mathematics
and digital restoration offer as a generic and objective toolkit for the arts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07195</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07195</id><created>2018-03-19</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Shehata</keyname><forenames>Mohamed</forenames></author><author><keyname>Smith</keyname><forenames>Andrew</forenames></author></authors><title>Adaptive Polar Active Contour for Segmentation and Tracking in
  Ultrasound Videos</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in IEEE Transactions on Circuit and Systems
  for Video Technology</comments><doi>10.1109/TCSVT.2018.2818072</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of relative changes in circulating blood volume is important to
guide resuscitation and manage a variety of medical conditions including
sepsis, trauma, dialysis and congestive heart failure. Recent studies have
shown that estimates of circulating blood volume can be obtained from the
cross-sectional area (CSA) of the internal jugular vein (IJV) from ultrasound
images. However, accurate segmentation and tracking of the IJV in ultrasound
imaging is a challenging task and is significantly influenced by a number of
parameters such as the image quality, shape, and temporal variation. In this
paper, we propose a novel adaptive polar active contour (Ad-PAC) algorithm for
the segmentation and tracking of the IJV in ultrasound videos. In the proposed
algorithm, the parameters of the Ad-PAC algorithm are adapted based on the
results of segmentation in previous frames. The Ad-PAC algorithm is applied to
65 ultrasound videos captured from 13 healthy subjects, with each video
containing 450 frames. The results show that spatial and temporal adaptation of
the energy function significantly improves segmentation performance when
compared to current state-of-the-art active contour algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07200</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07200</id><created>2018-03-19</created><updated>2018-05-14</updated><authors><author><keyname>Khodabandehlou</keyname><forenames>Hamid</forenames></author><author><keyname>Fadali</keyname><forenames>M. Sami</forenames></author></authors><title>Training Recurrent Neural Networks as a Constraint Satisfaction Problem</title><categories>cs.LG eess.SP stat.ML</categories><comments>9 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a new approach for training artificial neural networks
using techniques for solving the constraint satisfaction problem (CSP). The
quotient gradient system (QGS) is a trajectory-based method for solving the
CSP. This study converts the training set of a neural network into a CSP and
uses the QGS to find its solutions. The QGS finds the global minimum of the
optimization problem by tracking trajectories of a nonlinear dynamical system
and does not stop at a local minimum of the optimization problem. Lyapunov
theory is used to prove the asymptotic stability of the solutions with and
without the presence of measurement errors. Numerical examples illustrate the
effectiveness of the proposed methodology and compare it to a genetic algorithm
and error backpropagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07220</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07220</id><created>2018-03-19</created><updated>2018-05-03</updated><authors><author><keyname>Li</keyname><forenames>Xuelu</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author></authors><title>Collaborative Sparse Priors for Infrared Image Multi-view ATR</title><categories>eess.IV</categories><comments>4 pages, 3 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature extraction from infrared (IR) images remains a challenging task.
Learning based methods that can work on raw imagery/patches have therefore
assumed significance. We propose a novel multi-task extension of the widely
used sparse-representation-classification (SRC) method in both single and
multi-view set-ups. That is, the test sample could be a single IR image or
images from different views. When expanded in terms of a training dictionary,
the coefficient matrix in a multi-view scenario admits a sparse structure that
is not easily captured by traditional sparsity-inducing measures such as the
$l_0$-row pseudo norm. To that end, we employ collaborative spike and slab
priors on the coefficient matrix, which can capture fairly general sparse
structures. Our work involves joint parameter and sparse coefficient estimation
(JPCEM) which alleviates the need to handpick prior parameters before
classification. The experimental merits of JPCEM are substantiated through
comparisons with other state-of-art methods on a challenging mid-wave IR image
(MWIR) ATR database made available by the US Army Night Vision and Electronic
Sensors Directorate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07264</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07264</id><created>2018-03-20</created><authors><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author><author><keyname>Zenelis</keyname><forenames>Ilias</forenames></author></authors><title>Estimating Participation Factors and Mode Shapes for Electromechanical
  Oscillations in Ambient Conditions</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new technique is applied to conduct mode identification
using ambient measurement data. The proposed hybrid measurement- and
model-based method can accurately estimate the system state matrix in ambient
conditions, the eigenvalues and eigenvectors of which readily provide all the
modal knowledge including frequencies, damping ratios, mode shapes, and more
importantly, participation factors. Numerical simulations show that the
proposed technique is able to provide accurate estimation of modal knowledge
for all modes. In addition, the discrepancy between the participation factor
and the mode shape is shown through a numerical example, demonstrating that
using the mode shape may not effectively pinpoint the best location for damping
control. Therefore, the proposed technique capable of estimating participation
factors may greatly facilitate designing damping controls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07297</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07297</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author></authors><title>Polarization and Index Modulations: a Theoretical and Practical
  Perspective</title><categories>eess.SP cs.IT math.IT</categories><comments>Thesis. Check full quality images at
  http://theses.eurasip.org/theses/711/polarization-and-index-modulations-a-theoretical/</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Radiocommunication systems have evolved significantly in recent years in
order to meet present and future demands. Historically, time, frequency and
more recently, spatial dimensions have been used to improve capacity and
robustness. Paradoxically, radiocommunications that leverage the polarization
dimension have not evolved at the same pace. In particular, these
communications are widely used by satellites, where several streams are
multiplexed in each orthogonal polarization. Current communication trends
advocate for simplifying and unifying different frameworks in order to increase
flexibility and address future needs. Due to this, systems that do not require
channel information are progressively gaining traction. This dissertation aims
at challenging this perspective and promoting the use of polarization in new
radiocommunication systems. Consequently, the goal of this thesis is twofold:
first, we aim at increasing the current capacity of point-to-point and
point-to-multipoint links. Secondly, we introduce new mechanisms to increase
the robustness of communications in particularly hostile environments. In this
context, this thesis advocates for the use of polarization as a dimension to be
exploited in radiocommunications. In addition to the use of polarization, index
modulations help increase transmission rates whilst improving robustness
against errors and imperfections with a low computational complexity. Thus, the
study of polarization in these systems is essential. This dissertation explores
primordial aspects in this area, such as channel capacity, transmitter and
receiver design and performance benchmarking with current systems. Finally, we
identify and discuss various characteristic aspects of polarization. In this
thesis, the reader will navigate the mathematical foundations of the proposed
concepts as well as their implementation in real-life scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07306</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07306</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana I.</forenames></author></authors><title>Capacity Analysis of Index Modulations over Spatial, Polarization and
  Frequency Dimensions</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/TCOMM.2017.2743166</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Determining the capacity of a modulation scheme is a fundamental topic of
interest. Index Modulations (IM), such as Spatial Modulation (SMod), Polarized
Modulation (PMod) or Frequency Index Modulation (FMod), are widely studied in
the literature. However, finding a closed-form analytical expression for their
capacity still remains an open topic. In this paper, we formulate closed-form
expressions for the instantaneous capacity of IM, together with its $2$nd and
$4$th order approximations. We show that, in average, the $2$nd approximation
error tends to zero for low Signal to Noise Ratio (SNR) and is
$o\left(\textrm{SNR}\right)$. Also, a detailed analysis of the ergodic capacity
over Rayleigh, Rice and Nakagami-$m$ channel distributions is provided. As
application of the capacity analysis, we leverage the proposed expressions to
compute the ergodic capacities of SMod for different antenna configuration and
correlations, PMod for different channel components and conditions, and FMod
for different frequency separations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07314</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07314</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana I.</forenames></author></authors><title>Dual Polarized Modulation and Reception for Next Generation Mobile
  Satellite Communications</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/TCOMM.2015.2461221</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper presents the novel application of Polarized Modulation (PMod) for
increasing the throughput in mobile satellite transmissions. One of the major
drawbacks in mobile satellite communications is the fact that the power budget
is often restrictive, making unaffordable to improve the spectral efficiency
without an increment of transmitted power. By using dual polarized antennas in
the transmitter and receiver, the PMod technique achieves an improvement in
throughput of up to $100$\% with respect to existing deployments, with an
increase of less than $1$ dB at low \ebn regime. Additionally, the proposed
scheme implies minimum hardware modifications with respect to the existing dual
polarized systems and does not require additional channel state information at
the transmitter; thus it can be used in current deployments. Demodulation (i.e.
detection and decoding) alternatives, with different processing complexity and
performance, are studied. The results are validated in a typical mobile
interactive scenario, the newest version of TS 102 744 standard (Broadband
Global Area Network (BGAN)), which aims to provide interactive mobile satellite
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07315</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07315</id><created>2018-03-20</created><authors><author><keyname>George-Gavrincea</keyname><forenames>Ciprian</forenames></author><author><keyname>Baranda</keyname><forenames>Jorge</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author></authors><title>Rapid Prototyping of Standard-Compliant Visible Light Communications
  System</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/MCOM.2014.6852087</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This article describes the implementation of a prototype visible light
communications system based on the IEEE 802.15.7 standard using low-cost
commercial off-the-shelf analog devices. The aim of this article is to show
that this standard provides a framework that could promote the introduction of
applications into the market. Thus, these specifications could be further
developed, reducing the gap between the industry and research communities. The
implemented prototype makes use of software defined radio platforms to
interface between the analog devices and the computer where the signal
processing is performed. The use of this concept provides the system with
enough flexibility and modularity to include new features in the prototype
without requiring long development time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07318</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07318</id><created>2018-03-20</created><authors><author><keyname>Tato</keyname><forenames>Anxo</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Mosquera</keyname><forenames>Carlos</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana I.</forenames></author></authors><title>Link Adaptation Algorithms for Dual Polarization Mobile Satellite
  Systems</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1007/978-3-319-76571-6_6</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The use of dual polarization in mobile satellite systems is very promising as
a means for increasing the transmission capacity. In this paper we study a
system which uses simultaneously two orthogonal polarizations in order to
communicate with the users. The application of MIMO signal processing
techniques along with Adaptive Coding and Modulation in the forward link can
provide remarkable throughput gains up to 100 % when compared with the single
polarization system. The gateway is allowed to vary the MIMO and Modulation and
Coding Schemes for each frame. The selection is done by means of a link
adaptation algorithm which uses a tunable margin to achieve a prede ned target
Frame Error Rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07321</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07321</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana</forenames></author><author><keyname>Mazzali</keyname><forenames>Nicol&#xf2;</forenames></author><author><keyname>Mosquera</keyname><forenames>Carlos</forenames></author></authors><title>Advanced Signal Processing Techniques for Fixed and Mobile Satellite
  Communications</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/ASMS-SPSC.2016.7601468</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Enabling ultra fast systems has been widely investigated during recent
decades. Although polarization has been deployed from the beginning in
satellite communications, nowadays it is being exploited to increase the
throughput of satellite links. More precisely, the application of diversity
techniques to the polarization domain may provide reliable, robust, and fast
satellite communications. Better and more flexible spectrum use is also
possible if transmission and reception can take place simultaneously in close
or even overlapping frequency bands. In this paper we investigate novel signal
processing techniques to increase the throughput of satellite communications in
fixed and mobile scenarios. First, we investigate four-dimensional (4D)
constellations for the forward link. Second, we focus on the mobile scenario
and introduce an adaptive algorithm which selects the optimal tuple of
modulation order, coding rate, and MIMO scheme that maximizes the throughput
constraint to a maximum packet error rate. Finally, we describe the operation
of radio transceivers which cancel actively the self-interference posed by the
transmit signal when operating in full-duplex mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07325</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07325</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Shaat</keyname><forenames>Musbah</forenames></author><author><keyname>Navarro</keyname><forenames>M&#xf2;nica</forenames></author></authors><title>NOMA Assisted Joint Broadcast and Multicast Transmission in 5G Networks</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/ISWCS.2017.8108151</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we employ the non-orthogonal multiple access (NOMA) technique
to convey joint broadcast and multicast streams to a set of users. Thanks to
the spatial beamforming, different groups of users is able to receive different
streams in addition to the common broadcast information. With the proposed
scheme, the same time-frequency resources can be shared between different
streams, without requiring additional bandwidth. The transmitter implementation
is presented and two receiver classes are considered based on Successive
Interference Cancellation (SIC) and Joint Decoding (JD) approaches. In addition
to the performance assessment via simulation, a real hardware proof of concept
implementation of the proposed technique is performed in order to show the
practical viability of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07326</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07326</id><created>2018-03-20</created><authors><author><keyname>V&#xe1;zquez</keyname><forenames>Miguel &#xc1;ngel</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana</forenames></author><author><keyname>Mosquera</keyname><forenames>Carlos</forenames></author><author><keyname>Shankar</keyname><forenames>Bhavanni</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Panagopoulos</keyname><forenames>Athanasios D.</forenames></author><author><keyname>Giambere</keyname><forenames>Giovanni</forenames></author><author><keyname>Siris</keyname><forenames>Vasilios</forenames></author><author><keyname>Polyzos</keyname><forenames>George</forenames></author><author><keyname>Alagha</keyname><forenames>Nader</forenames></author></authors><title>Pushing for higher rates and efficiency in Satcom: the different
  perspectives within SatNExIV</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/ISWCS.2015.7454329</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  SatNEx IV project aims at studying medium and long term directions of
satellite telecommunication systems for any of the commercial or institutional
applications that can be considered appealing by key players although still not
mature enough for attracting industry or initiating dedicated ESA R&amp;D
activities. This paper summarizes the first year activities identified as very
promising techniques for next generation satellite communication systems.
Concretely, very high throughput satellite trunking, physical layer advances
for full-duplex and multipolarization systems, network coding applications and
multiple access schemes for information centric networking are briefly
presented. For all the activities, we identify the scenarios under study so as
the preliminary technical solutions to be further investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07332</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07332</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana I.</forenames></author></authors><title>Dual Polarized Modulation and Receivers for Mobile Communications in
  Urban Areas</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/SPAWC.2015.7226998</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Achieving an increase in the spectral efficiency (SE) has always been a major
driver in the design of communication systems. The use of MIMO techniques in
mobile communications has achieved significant benefits in improving the system
throughput. The basic underlying concept of MIMO is to exploit the signal and
channel characteristics to eliminate interference between multiple
transmissions. Departing from the work carried out under the industrial
projects \cite{NGW,Henarejos}, we extend the results provided in their
respective reports. The goal is to increase the SE without an increment of
radiated energy without any Channel State Information at Transmitter (CSIT) and
feedback at the transmitter and maintaining a very low computational complexity
at the receiver. Although a priori additional power is required to increase the
SE, we demonstrate that the proposed Polarized Modulation (PMod) scheme
exploits the polarization diversity reducing the required EbN0 and adding an
extra bit. We also introduce two receivers to demodulate this scheme of
different computational complexities. We describe a Near Optimal Detector (NOD)
which achieves almost the same performance as the optimal detector based on the
Maximum Likelihood Detection (MLD), but with lower computational complexity.
Finally, the results demonstrate that the PMod requires less EbN0 compared with
the single polarization case, guarantees the robustness in the presence of the
cross-polarization and validates that PMod can multiplex two streams of
different Quality of Service (QoS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07335</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07335</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>V&#xe1;zquez</keyname><forenames>Miguel &#xc1;ngel</forenames></author><author><keyname>Cocco</keyname><forenames>Giuseppe</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana I.</forenames></author></authors><title>Forward Link Interference Mitigation in Mobile Interactive Satellite
  Systems</title><categories>eess.SP cs.IT math.IT</categories><doi>10.2514/6.2013-5730</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We present the results of the performance evaluation of polarization-time
coding and soft interference cancellation in multi-beam satellite systems
affected by co-channel interference in realistic setups. The standard of
Broadband Global Area Network service (BGAN) has been considered as reference
for the physical layer and realistic interference and channel models have been
adopted. The work has been carried out in the framework of the Next Generation
Waveform for Increased Spectral Efficiency (NGWISE) project founded by the
European Space Agency (ESA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07337</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07337</id><created>2018-03-20</created><authors><author><keyname>Baranda</keyname><forenames>Jorge</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>George-Gavrincea</keyname><forenames>Ciprian</forenames></author></authors><title>An SDR Implementation of a Visible Light Communication System Based on
  the IEEE 802.15.7 Standard</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/ICTEL.2013.6632076</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The aim of this paper is to present an implementation of a functional IEEE
802.15.7 real-time testbed based on the Software Defined Radio (SDR) concept.
This implementation is built with low cost commercial off-the-shelf (COTS)
analog devices and the use of Universal Software Radio Peripheral version 2
(USRP2) equipment combined with a generic object-oriented framework that takes
advantage of several open source software libraries. The prototype is validated
in a controlled laboratory environment with an over-the-air measurement
campaign.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07339</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07339</id><created>2018-03-20</created><authors><author><keyname>Baranda</keyname><forenames>Jorge</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Grunenberger</keyname><forenames>Yan</forenames></author><author><keyname>Najar</keyname><forenames>Montse</forenames></author></authors><title>Prototyping with SDR: a quick way to play with next-gen communications
  systems</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/ISWCS.2011.6125301</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper we present our approach regarding the implementation of new
wireless radio receiver exploiting filterbank techniques, using a
software-development driven approach. Since most of the common radio
communications systems share a similar structure, this can be exploited
creating a framework which provides a generic layout and tools to construct a
reconfigurable transmitter and/or receiver. By combining the use of the
Universal Software Radio Peripheral version 2 (USRP2) with a generic
object-oriented framework of our own built on top of the GNU Radio software
framework, we have been able to quickly implement a working proof of concept of
an Uplink (UL) Filterbank Multicarrier (FBMC) receiver, both for SingleInput
Single-Output (SISO) and Multiple-Input Multiple-Output (MIMO) scenario, within
the project of the 7th European framework called PHYDYAS. We described here the
methodology we have applied from software engineering in order to build this
demonstrator, which shows the suitability of using Software Defined Radio (SDR)
technologies for fast prototyping of new wireless communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07342</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07342</id><created>2018-03-20</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Perez-Neira</keyname><forenames>Ana</forenames></author><author><keyname>Tralli</keyname><forenames>Velio</forenames></author><author><keyname>Moretti</keyname><forenames>Marco</forenames></author><author><keyname>Dimitriou</keyname><forenames>Nikos</forenames></author><author><keyname>Dainelli</keyname><forenames>Giulio</forenames></author></authors><title>Evolution of Spatial and Multicarrier Scheduling: Towards Multi-cell
  Scenario</title><categories>eess.SP</categories><doi>10.1007/978-3-642-16644-0_46</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  OFDMA systems are considered as the promising multiple access scheme of next
generation multi-cellular wireless systems. In order to ensure the optimum
usage of radio resources, OFDMA radio resource management algorithms have to
maximize the allocated power and rate of the different subchannels to the users
taking also into account the generated co-channel interference between
neighboring cells, which affects the received Quality of Service. This paper
discusses various schemes for power distribution schemes in multiple co-channel
cells. These schemes include centralized and distributed solutions, which may
involve various degrees of complexity and related overhead and may employ
procedures such as linear programming. Finally, the paper introduces a new
solution that uses a network flow model to solve the maximization of the
multi-cell system sum rate. The application of spatial beamforming at each cell
is suggested in order to better cope with interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07344</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07344</id><created>2018-03-20</created><authors><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana I.</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Tralli</keyname><forenames>Velio</forenames></author><author><keyname>Lagunas</keyname><forenames>Miguel A.</forenames></author></authors><title>A Low Complexity Space-Frequency Multiuser Scheduling Algorithm</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This work presents a resource allocation algorithm in K-user, M-subcarrier
and NT-antenna systems for on-line scheduling. To exploit temporal diversity
and to reduce complexity, the ergodic sum rate is maximized instead of the
instantaneous one. Dual optimization is applied to further diminish complexity
together with a stochastic approximation, which is more suitable for online
algorithms. Weighted sum rate is considered so that users can be either
prioritized by higher layers or differentiated by proportional rate
constraints. The performance and complexity of this algorithm is compared with
well-known benchmarks and also evaluated under real system conditions for the
MIMO Broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07381</identifier>
 <datestamp>2018-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07381</id><created>2018-03-20</created><authors><author><keyname>Kumar</keyname><forenames>Sanjay</forenames></author></authors><title>Convolution, Product and Correlation Theorems for Simplified Fractional
  Fourier Transform: A Mathematical Investigation</title><categories>eess.SP</categories><comments>24 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The notion of fractional Fourier transform (FrFT) has been used and
investigated for many years by various research communities, which finds
widespread applications in many diverse fields of research study. The potential
applications includes ranging from quantum physics, harmonic analysis, optical
information processing, pattern recognition to varied allied areas of signal
processing. Many significant theorems and properties of the FrFT have been
investigated and applied to many signal processing applications, most important
among these are convolution, product and correlation theorems. Still many
magnificent research works related to the conventional FrFT lacks the elegance
and simplicity of the convolution, product and correlation theorems similar to
the Euclidean Fourier transform (FT), which for convolution theorem states that
the FT of the convolution of two functions is the product of their respective
FTs. The purpose of this paper is to devise the equivalent elegancy of
convolution, product and correlation theorems, as in the case of Euclidean FT.
Building on the seminal work of Pei et al. and the potential of the simplified
fractional Fourier transform (SmFrFT), a detailed mathematical investigation is
established to present an elegant definition of convolution, product and
correlation theorems in the SmFrFT domain, along with their associated
important properties. It has been shown that the established theorems along
with their associated properties very nicely generalizes to the classical
Euclidean FT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07574</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07574</id><created>2018-03-20</created><authors><author><keyname>Meresescu</keyname><forenames>Alina G.</forenames></author><author><keyname>Kowalski</keyname><forenames>Matthieu</forenames></author><author><keyname>Schmidt</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Landais</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Water Residence Time Estimation by 1D Deconvolution in the Form of a
  l2-Regularized Inverse Problem With Smoothness, Positivity and Causality
  Constraints</title><categories>eess.SP</categories><doi>10.1016/j.cageo.2018.03.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Water Residence Time distribution is the equivalent of the impulse
response of a linear system allowing the propagation of water through a medium,
e.g. the propagation of rain water from the top of the mountain towards the
aquifers. We consider the output aquifer levels as the convolution between the
input rain levels and the Water Residence Time, starting with an initial
aquifer base level. The estimation of Water Residence Time is important for a
better understanding of hydro-bio-geochemical processes and mixing properties
of wetlands used as filters in ecological applications, as well as protecting
fresh water sources for wells from pollutants. Common methods of estimating the
Water Residence Time focus on cross-correlation, parameter fitting and
non-parametric deconvolution methods. Here we propose a 1D full-deconvolution,
regularized, non-parametric inverse problem algorithm that enforces smoothness
and uses constraints of causality and positivity to estimate the Water
Residence Time curve. Compared to Bayesian non-parametric deconvolution
approaches, it has a fast runtime per test case; compared to the popular and
fast cross-correlation method, it produces a more precise Water Residence Time
curve even in the case of noisy measurements. The algorithm needs only one
regularization parameter to balance between smoothness of the Water Residence
Time and accuracy of the reconstruction. We propose an approach on how to
automatically find a suitable value of the regularization parameter from the
input data only. Tests on real data illustrate the potential of this method to
analyze hydrological datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07713</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07713</id><created>2018-03-20</created><authors><author><keyname>Teng</keyname><forenames>Yinglei</forenames></author><author><keyname>Zhao</keyname><forenames>Wanxin</forenames></author><author><keyname>Yan</keyname><forenames>Mei</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author><author><keyname>Song</keyname><forenames>Mei</forenames></author></authors><title>Robust Beamforming for SWIPT System with Chance Constraints</title><categories>eess.SP</categories><comments>6 pages, 5 figures, to appear in IEEE ICC 2018, May 20-24</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The robust beamforming problem in multiple-input single-output (MISO)
downlink networks of simultaneous wireless information and power transfer
(SWIPT) is studied in this paper. Adopting the time switching fashion to
perform energy harvesting and information decoding respectively, we aim at
maximizing the sum rate under imperfect channel state information (CSI) and the
chance constraints of users' harvested energy. In view of the fact that the
constraints for minimal harvested energy is not necessary to meet from time to
time, this paper adopts chance constraint to model it and uses the Bernstein
inequality to transform it into deterministic constraints equivalently.
Recognizing the maximum sum rate problem of imperfect CSI as nonconvex problem,
we transform it into finding the expectation of minimum mean square error
(MMSE) equivalently in this paper, and an alternative optimization (AO)
algorithm is proposed to decompose the optimization problem into two
sub-problems: the transmit beamformer design and the division of switching
time. The simulation results show the performance gains compared to non-robust
state of the art schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07731</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07731</id><created>2018-03-20</created><authors><author><keyname>Teng</keyname><forenames>Yinglei</forenames></author><author><keyname>Wei</keyname><forenames>Min</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>Mixed-timescale Per-group Hybrid Precoding for Multiuser Massive MIMO
  Systems</title><categories>eess.SP</categories><doi>10.1109/LSP.2018.2812751</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the expensive radio frequency (RF) chain, huge training overhead
and feedback burden issues in massive MIMO, in this letter, we propose a
mixed-timescale per-group hybrid precoding (MPHP) scheme under an adaptive
partially-connected RF precoding structure (PRPS), where the RF precoder is
implemented using an adaptive connection network (ACN) and M analog phase
shifters (APSs), where M is the number of antennas at the base station (BS).
Exploiting the mixed-time stage channel state information (CSI) structure, the
joint-design of ACN and APSs is formulated as a statistical
signal-to-leakage-and-noise ratio (SSLNR) maximization problem, and a heuristic
group RF precoding (GRFP) algorithm is proposed to provide a near-optimal
solution. Simulation results show that the proposed design advances at better
energy efficiency (EE) and lower hardware cost, CSI signaling overhead and
computational complexity than the conventional hybrid precoding (HP) schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07768</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07768</id><created>2018-03-21</created><authors><author><keyname>H&#xe4;lsig</keyname><forenames>Tim</forenames></author><author><keyname>Cvetkovski</keyname><forenames>Darko</forenames></author><author><keyname>Grass</keyname><forenames>Eckhard</forenames></author><author><keyname>Lankl</keyname><forenames>Berthold</forenames></author></authors><title>Statistical Properties and Variations of LOS MIMO Channels at Millimeter
  Wave Frequencies</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted at WSA 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measurement results for millimeter wave LOS MIMO systems are presented with a
focus on time variation and multipath propagation. Different system setups are
used, including 2x2 and 3x3 MIMO, and involving different synchronization
procedures and front-ends. Furthermore, different propagation scenarios are
evaluated, covering a wide area of applications. The results show that the LOS
component carries significantly more power than the NLOS components, and that
frequency selectivity from front-ends should be taken into account when
designing these high bandwidth systems. Frequency offsets and other phase
variations due to transmit and receive oscillator differences are treated as
part of the channel and thus, depending on the synchronization setup, the MIMO
system exhibits different time variations, particularly in the case of
independent local oscillators. It is also observed that these systems
experience significant non-trivial long-term variations in terms of amplitude
and phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07772</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07772</id><created>2018-03-21</created><authors><author><keyname>Mokdad</keyname><forenames>Ali</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Moltafet</keyname><forenames>Mohammad</forenames></author><author><keyname>Ghaffari-Miab</keyname><forenames>Mohsen</forenames></author></authors><title>Cross-Layer Energy Efficient Resource Allocation in PD-NOMA based
  H-CRANs: Implementation via GPU</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a cross layer energy efficient resource allocation
and remote radio head (RRH) selection algorithm for heterogeneous traffic in
power domain - non-orthogonal multiple access (PD-NOMA) based heterogeneous
cloud radio access networks (H-CRANs). The main aim is to maximize the EE of
the elastic users subject to the average delay constraint of the streaming
users and the constraints, RRH selection, subcarrier, transmit power and
successive interference cancellation. The considered optimization problem is
non-convex, NP-hard and intractable. To solve this problem, we transform the
fractional objective function into a subtractive form. Then, we utilize
successive convex approximation approach. Moreover, in order to increase the
processing speed, we introduce a framework for accelerating the successive
convex approximation for low complexity with the Lagrangian method on graphics
processing unit. Furthermore, in order to show the optimality gap of the
proposed successive convex approximation approach, we solve the proposed
optimization problem by applying an optimal method based on the monotonic
optimization. Studying different scenarios show that by using both PD-NOMA
technique and H-CRAN, the system energy efficiency is improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07788</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07788</id><created>2018-03-21</created><authors><author><keyname>Tiwari</keyname><forenames>Ranjeet Kumar</forenames></author><author><keyname>Bhaumik</keyname><forenames>Shovan</forenames></author><author><keyname>Date</keyname><forenames>Paresh</forenames></author></authors><title>Particle Filter for Randomly Delayed Measurements with Unknown Latency
  Probability</title><categories>eess.SP</categories><comments>10 Pages, 11 figures, Submitted to IEEE Transaction on Control of
  Network Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on designing a particle filter for randomly delayed
measurements with an unknown latency probability. A generalized measurement
model is adopted which includes measurements that are delayed randomly by an
arbitrary but fixed maximum number of the steps, along with random packet
drops. Recursion equation for importance weights is derived under the presence
of random delays. Offline and online algorithms for identification of the
unknown latency parameter using the maximum likelihood criterion are proposed.
Further, this work explores the conditions which ensure the convergence of the
proposed particle filter. Finally, two numerical examples concerning problems
of non-stationary growth model and the bearing-only tracking are simulated to
show the effectiveness and superiority of the proposed filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07818</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07818</id><created>2018-03-21</created><authors><author><keyname>Ni</keyname><forenames>Sherry Xue-Ying</forenames></author><author><keyname>Yue</keyname><forenames>Man-Chung</forenames></author><author><keyname>Cheung</keyname><forenames>Kam-Fung</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author></authors><title>Phase Retrieval via Sensor Network Localization</title><categories>math.OC eess.SP math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of phase retrieval is revisited and studied from a fresh
perspective. In particular, we establish a connection between the phase
retrieval problem and the sensor network localization problem, which allows us
to utilize the vast theoretical and algorithmic literature on the latter to
tackle the former. Leveraging this connection, we develop a two-stage algorithm
for phase retrieval that can provably recover the desired signal. In both
sparse and dense settings, our proposed algorithm improves upon prior
approaches simultaneously in the number of required measurements for recovery
and the reconstruction time. We present numerical results to corroborate our
theory and to demonstrate the efficiency of the proposed algorithm. As a side
result, we propose a new form of phase retrieval problem and connect it to the
complex rigidity theory proposed by Gortler and Thurston.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07838</identifier>
 <datestamp>2018-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07838</id><created>2018-03-21</created><authors><author><keyname>Das</keyname><forenames>Anweshan</forenames></author><author><keyname>Dubbelman</keyname><forenames>Gijs</forenames></author></authors><title>An Experimental Study on Relative and Absolute Pose Graph Fusion for
  Vehicle Localization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we research and evaluate multiple pose-graph fusion strategies
for vehicle localization. We focus on fusing a single absolute localization
system, i.e. automotive-grade Global Navigation Satellite System (GNSS) at 1
Hertz, with a single relative localization system, i.e. vehicle odometry at 25
Hertz. Our evaluation is based on 180 Km long vehicle trajectories that are
recorded in highway, urban and rural areas, and that are accompanied with
post-processed Real Time Kinematic GNSS as ground truth. The results exhibit a
significant reduction in the error's standard deviation by 18% but the bias in
the error is unchanged, when compared to non-fused GNSS. We show that the
underlying principle is the fact that errors in GNSS readings are highly
correlated in time. This causes a bias that cannot be compensated for by using
the relative localization information from the odometry, but it can reduce the
standard deviation of the error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07864</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07864</id><created>2018-03-21</created><updated>2018-07-11</updated><authors><author><keyname>Avula</keyname><forenames>Ramana R.</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias J.</forenames></author><author><keyname>M&#xe5;nsson</keyname><forenames>Daniel</forenames></author></authors><title>Privacy-preserving smart meter control strategy including energy storage
  losses</title><categories>eess.SP</categories><comments>6 pages</comments><doi>10.1109/ISGTEurope.2018.8571537</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Privacy-preserving smart meter control strategies proposed in the literature
so far make some ideal assumptions such as instantaneous control without delay,
lossless energy storage systems etc. In this paper, we present a one-step-ahead
predictive control strategy using Bayesian risk to measure and control privacy
leakage with an energy storage system. The controller estimates energy state
using a three-circuit energy storage model to account for steady-state energy
losses. With numerical experiments, the controller is evaluated with real
household consumption data using a state-of-the-art adversarial algorithm.
Results show that the state estimation of the energy storage system
significantly affects the controller's performance. The results also show that
the privacy leakage can be effectively reduced using an energy storage system
but at the expense of energy loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.07905</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.07905</id><created>2018-03-14</created><updated>2019-02-18</updated><authors><author><keyname>Perin</keyname><forenames>Jose Krause</forenames></author><author><keyname>Kahn</keyname><forenames>Joseph M.</forenames></author><author><keyname>Downie</keyname><forenames>John D.</forenames></author><author><keyname>Hurley</keyname><forenames>Jason</forenames></author><author><keyname>Bennett</keyname><forenames>Kevin</forenames></author></authors><title>Importance of Amplifier Physics in Maximizing the Capacity of Submarine
  Links</title><categories>physics.app-ph eess.SP physics.optics</categories><doi>10.1109/JLT.2019.2897831</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The throughput of submarine transport cables is approaching fundamental
limits imposed by amplifier noise and Kerr nonlinearity. Energy constraints in
ultra-long submarine links exacerbate this problem, as the throughput per fiber
is further limited by the electrical power available to the undersea optical
amplifiers. Recent works have studied how employing more spatial dimensions can
mitigate these limitations. In this paper, we address the fundamental question
of how to optimally use each spatial dimension. Specifically, we discuss how to
optimize the channel power allocation in order to maximize the
information-theoretic capacity under an electrical power constraint. Our
formulation accounts for amplifier physics, Kerr nonlinearity, and power feed
constraints. Whereas recent works assume the optical amplifiers operate in deep
saturation, where power-conversion efficiency (PCE) is high, we show that given
a power constraint, operating in a less saturated regime, where PCE is lower,
supports a wider bandwidth and a larger number of spatial dimensions, thereby
maximizing capacity. This design strategy increases the capacity of submarine
links by about 70% compared to the theoretical capacity of a recently proposed
high-capacity system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08184</identifier>
 <datestamp>2018-03-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08184</id><created>2018-03-21</created><authors><author><keyname>Obermeier</keyname><forenames>Richard</forenames></author><author><keyname>Martinez-Lorenzo</keyname><forenames>Jose Angel</forenames></author></authors><title>Generalized Optimization of High Capacity Compressive Imaging Systems</title><categories>eess.IV math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the greatest challenges in applying compressive sensing (CS) signal
processing techniques to electromagnetic imaging applications is designing a
sensing matrix that has good reconstruction capabilities. Compressive reflector
antennas (CRA) are a class of antennas that have been shown to provide enhanced
image reconstruction performance over traditional reflector antennas (TRA) when
CS techniques are employed. In this paper, we present a unified CRA design
method, which considers both the sensing capacity and efficiency of the
antenna, and can be used for both compressive imaging and multiple-input
multiple-output (MIMO) communication applications. The unified design method is
assessed for a CRA configuration in which dielectric scatterers are added to
the surface of a TRA. The design results demonstrate the ability of the unified
design method to enhance the CS reconstruction capabilities of the CRA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08186</identifier>
 <datestamp>2018-03-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08186</id><created>2018-03-21</created><authors><author><keyname>Obermeier</keyname><forenames>Richard</forenames></author><author><keyname>Martinez-Lorenzo</keyname><forenames>Jose Angel</forenames></author></authors><title>Sensing Matrix Design via Capacity Maximization for Block Compressive
  Sensing Applications</title><categories>math.OC cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well established in the compressive sensing (CS) literature that
sensing matrices whose elements are drawn from independent random distributions
exhibit enhanced reconstruction capabilities. In many CS applications, such as
electromagnetic imaging, practical limitations on the measurement system
prevent one from generating sensing matrices in this fashion. Although one can
usually randomized the measurements to some degree, these sensing matrices do
not achieve the same reconstruction performance as the truly randomized sensing
matrices. In this paper, we present a novel method, based upon capacity
maximization, for designing sensing matrices with enhanced block-sparse signal
reconstruction capabilities. Through several numerical examples, we demonstrate
how our method significantly enhances reconstruction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08243</identifier>
 <datestamp>2019-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08243</id><created>2018-03-22</created><updated>2019-04-03</updated><authors><author><keyname>Ernst</keyname><forenames>Ori</forenames></author><author><keyname>Chazan</keyname><forenames>Shlomo E.</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author><author><keyname>Goldberger</keyname><forenames>Jacob</forenames></author></authors><title>Speech Dereverberation Using Fully Convolutional Networks</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech derverberation using a single microphone is addressed in this paper.
Motivated by the recent success of the fully convolutional networks (FCN) in
many image processing applications, we investigate their applicability to
enhance the speech signal represented by short-time Fourier transform (STFT)
images. We present two variations: a &quot;U-Net&quot; which is an encoder-decoder
network with skip connections and a generative adversarial network (GAN) with
U-Net as generator, which yields a more intuitive cost function for training.
To evaluate our method we used the data from the REVERB challenge, and compared
our results to other methods under the same conditions. We have found that our
method outperforms the competing methods in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08250</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08250</id><created>2018-03-22</created><updated>2018-05-25</updated><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Kakishima</keyname><forenames>Yuichi</forenames></author></authors><title>Coverage Enhancement for mmWave Communications using Passive Reflectors</title><categories>eess.SP cs.NI physics.app-ph</categories><comments>Accepted for IEEE GSMM 2018 conference. Camera ready version updated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) technology is expected to dominate the future 5G
networks mainly due to large spectrum available at these frequencies. However,
coverage deteriorates significantly at mmWave frequencies due to higher path
loss, especially for the non-line-of-sight (NLOS) scenarios. In this work, we
explore the use of passive reflectors for improving mmWave signal coverage in
NLOS indoor areas. Measurements are carried out using the PXI-based mmWave
transceiver platforms from National Instruments operating at 28 GHz, and the
results are compared with the outcomes of ray tracing (RT) simulations in a
similar environment. For both the measurements and RT simulations, different
shapes of metallic passive reflectors are used to observe the coverage (signal
strength) statistics on a receiver grid in an NLOS area. For a square metallic
sheet reflector of size 24 by 24 in and 33 by 33 in , we observe a significant
increase in the received power in the NLOS region, with a median gain of 20 dB
when compared to no reflector case. The cylindrical reflector shows more
uniform coverage on the receiver grid as compared to flat reflectors that are
more directional.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08252</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08252</id><created>2018-03-22</created><updated>2018-05-25</updated><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Temporal and Spatial Characteristics of mmWave Propagation Channels for
  UAVs</title><categories>eess.SP</categories><comments>Paper accepted for IEEE GSMM 2018 conference. Included some changes
  for the camera ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles~(UAVs) are envisioned to be an integral part of
future 5G communication systems. The agile nature of UAVs for serving users at
different locations can help to dynamically optimize coverage and
quality-of-service (QoS) in future networks. %However, there is very limited
literature available for mmWave communications using UAVs. In this work, we
explore the small scale temporal and spatial characteristics of mmWave
air-to-ground~(AG) line-of-sight~(LOS) propagation channels at $28$~GHz in
different environmental scenarios: dense-urban, suburban, rural, and over sea
using omni-directional antennas employing Wireless InSite ray tracing software.
We classify the received multipath components~(MPCs) into persistent and
non-persistent components. The small scale temporal and spatial characteristics
of the AG propagation channel are found to be dependent on the scatterer
properties: number, distribution, and geometry. Additionally, clustering of
MPCs in the time and spatial domain for different environments is found to be
dependent on the scatterer properties and receiver sensitivity. When the height
of the UAV is comparable to the height of the scatterers, we observe large
temporal and angular spreads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08276</identifier>
 <datestamp>2018-03-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08276</id><created>2018-03-22</created><authors><author><keyname>Jumelle</keyname><forenames>Maxime</forenames></author><author><keyname>Sakmeche</keyname><forenames>Taqiyeddine</forenames></author></authors><title>Speaker Clustering With Neural Networks And Audio Processing</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Speaker clustering is the task of differentiating speakers in a recording. In
a way, the aim is to answer &quot;who spoke when&quot; in audio recordings. A common
method used in industry is feature extraction directly from the recording
thanks to MFCC features, and by using well-known techniques such as Gaussian
Mixture Models (GMM) and Hidden Markov Models (HMM). In this paper, we studied
neural networks (especially CNN) followed by clustering and audio processing in
the quest to reach similar accuracy to state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08396</identifier>
 <datestamp>2018-03-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08396</id><created>2018-03-22</created><authors><author><keyname>Zhang</keyname><forenames>He</forenames></author><author><keyname>Patel</keyname><forenames>Vishal M.</forenames></author></authors><title>Densely Connected Pyramid Dehazing Network</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new end-to-end single image dehazing method, called Densely
Connected Pyramid Dehazing Network (DCPDN), which can jointly learn the
transmission map, atmospheric light and dehazing all together. The end-to-end
learning is achieved by directly embedding the atmospheric scattering model
into the network, thereby ensuring that the proposed method strictly follows
the physics-driven scattering model for dehazing. Inspired by the dense network
that can maximize the information flow along features from different levels, we
propose a new edge-preserving densely connected encoder-decoder structure with
multi-level pyramid pooling module for estimating the transmission map. This
network is optimized using a newly introduced edge-preserving loss function. To
further incorporate the mutual structural information between the estimated
transmission map and the dehazed result, we propose a joint-discriminator based
on generative adversarial network framework to decide whether the corresponding
dehazed image and the estimated transmission map are real or fake. An ablation
study is conducted to demonstrate the effectiveness of each module evaluated at
both estimated transmission map and dehazed result. Extensive experiments
demonstrate that the proposed method achieves significant improvements over the
state-of-the-art methods. Code will be made available at:
https://github.com/hezhangsprinter
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08629</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08629</id><created>2018-03-22</created><updated>2018-05-27</updated><authors><author><keyname>Mobin</keyname><forenames>Shariq</forenames></author><author><keyname>Cheung</keyname><forenames>Brian</forenames></author><author><keyname>Olshausen</keyname><forenames>Bruno</forenames></author></authors><title>Generalization Challenges for Neural Architectures in Audio Source
  Separation</title><categories>cs.SD cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown that recurrent neural networks can be trained to
separate individual speakers in a sound mixture with high fidelity. Here we
explore convolutional neural network models as an alternative and show that
they achieve state-of-the-art results with an order of magnitude fewer
parameters. We also characterize and compare the robustness and ability of
these different approaches to generalize under three different test conditions:
longer time sequences, the addition of intermittent noise, and different
datasets not seen during training. For the last condition, we create a new
dataset, RealTalkLibri, to test source separation in real-world environments.
We show that the acoustics of the environment have significant impact on the
structure of the waveform and the overall performance of neural network models,
with the convolutional model showing superior ability to generalize to new
environments. The code for our study is available at
https://github.com/ShariqM/source_separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08791</identifier>
 <datestamp>2018-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08791</id><created>2018-03-23</created><updated>2018-07-27</updated><authors><author><keyname>Pries</keyname><forenames>Aaron</forenames></author><author><keyname>Ram&#xed;rez</keyname><forenames>David</forenames></author><author><keyname>Schreier</keyname><forenames>Peter J.</forenames></author></authors><title>LMPIT-inspired Tests for Detecting a Cyclostationary Signal in Noise
  with Spatio-Temporal Structure</title><categories>eess.SP</categories><journal-ref>IEEE Trans. Wirel. Commun., vol. 17, no. 9, pp. 6321-6334, Sept.
  2018</journal-ref><doi>10.1109/TWC.2018.2859314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spectrum sensing for cognitive radio, the presence of a primary user can
be detected by making use of the cyclostationarity property of digital
communication signals. For the general scenario of a cyclostationary signal in
temporally colored and spatially correlated noise, it has previously been shown
that an asymptotic generalized likelihood ratio test (GLRT) and locally most
powerful invariant test (LMPIT) exist. In this paper, we derive detectors for
the presence of a cyclostationary signal in various scenarios with structured
noise. In particular, we consider noise that is temporally white and/or
spatially uncorrelated. Detectors that make use of this additional information
about the noise process have enhanced performance. We have previously derived
GLRTs for these specific scenarios; here, we examine the existence of LMPITs.
We show that these exist only for detecting the presence of a cyclostationary
signal in spatially uncorrelated noise. For white noise, an LMPIT does not
exist. Instead, we propose tests that approximate the LMPIT, and they are shown
to perform well in simulations. Finally, if the noise structure is not known in
advance, we also present hypothesis tests using our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08828</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08828</id><created>2018-03-23</created><updated>2018-04-04</updated><authors><author><keyname>Interdonato</keyname><forenames>Giovanni</forenames></author><author><keyname>Frenger</keyname><forenames>P&#xe5;l</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Utility-based Downlink Pilot Assignment in Cell-Free Massive MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>8 pages, 9 figures. 22nd International ITG Workshop on Smart Antennas
  (WSA 2018), 5G Wireless special session</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a strategy for orthogonal downlink pilot assignment in cell-free
massive MIMO (multiple-input multiple-output) that exploits knowledge of the
channel state information, the channel hardening degree at each user, and the
mobility conditions for the users. These elements, properly combined together,
are used to define a user pilot utility metric, which measures the user's real
need of a downlink pilot for efficient data decoding. The proposed strategy
consists in assigning orthogonal downlink pilots only to the users having a
pilot utility metric exceeding a predetermined threshold. Instead, users that
are not assigned with an orthogonal downlink pilot decode the data by using the
statistical channel state information. The utility-based approach guarantees
higher downlink net sum throughput, better support both for high-speed users
and shorter coherent intervals than prior art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08863</identifier>
 <datestamp>2018-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08863</id><created>2018-03-23</created><updated>2018-06-18</updated><authors><author><keyname>Hermann</keyname><forenames>Enno</forenames></author><author><keyname>Goldwater</keyname><forenames>Sharon</forenames></author></authors><title>Multilingual bottleneck features for subword modeling in zero-resource
  languages</title><categories>cs.CL eess.AS</categories><comments>5 pages, 2 figures, 4 tables; accepted at Interspeech 2018</comments><journal-ref>Proc. Interspeech 2018, 2668-2672</journal-ref><doi>10.21437/Interspeech.2018-2334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can we effectively develop speech technology for languages where no
transcribed data is available? Many existing approaches use no annotated
resources at all, yet it makes sense to leverage information from large
annotated corpora in other languages, for example in the form of multilingual
bottleneck features (BNFs) obtained from a supervised speech recognition
system. In this work, we evaluate the benefits of BNFs for subword modeling
(feature extraction) in six unseen languages on a word discrimination task.
First we establish a strong unsupervised baseline by combining two existing
methods: vocal tract length normalisation (VTLN) and the correspondence
autoencoder (cAE). We then show that BNFs trained on a single language already
beat this baseline; including up to 10 languages results in additional
improvements which cannot be matched by just adding more data from a single
language. Finally, we show that the cAE can improve further on the BNFs if
high-quality same-word pairs are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.08869</identifier>
 <datestamp>2018-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.08869</id><created>2018-03-23</created><updated>2018-10-26</updated><authors><author><keyname>Chrupa&#x142;a</keyname><forenames>Grzegorz</forenames></author><author><keyname>Gelderloos</keyname><forenames>Lieke</forenames></author><author><keyname>K&#xe1;d&#xe1;r</keyname><forenames>&#xc1;kos</forenames></author><author><keyname>Alishahi</keyname><forenames>Afra</forenames></author></authors><title>On the difficulty of a distributional semantics of spoken language</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Proceedings of the Society for Computation in Linguistics 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the domain of unsupervised learning most work on speech has focused on
discovering low-level constructs such as phoneme inventories or word-like
units. In contrast, for written language, where there is a large body of work
on unsupervised induction of semantic representations of words, whole sentences
and longer texts. In this study we examine the challenges of adapting these
approaches from written to spoken language. We conjecture that unsupervised
learning of the semantics of spoken language becomes feasible if we abstract
from the surface variability. We simulate this setting with a dataset of
utterances spoken by a realistic but uniform synthetic voice. We evaluate two
simple unsupervised models which, to varying degrees of success, learn semantic
representations of speech fragments. Finally we present inconclusive results on
human speech, and discuss the challenges inherent in learning distributional
semantic representations on unrestricted natural spoken language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09013</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09013</id><created>2018-03-23</created><authors><author><keyname>Novoa</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Escudero</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Wuth</keyname><forenames>Jorge</forenames></author><author><keyname>Poblete</keyname><forenames>Victor</forenames></author><author><keyname>King</keyname><forenames>Simon</forenames></author><author><keyname>Stern</keyname><forenames>Richard</forenames></author><author><keyname>Yoma</keyname><forenames>N&#xe9;stor Becerra</forenames></author></authors><title>Exploring the robustness of features and enhancement on speech
  recognition systems in highly-reverberant real environments</title><categories>eess.AS cs.SD</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper evaluates the robustness of a DNN-HMM-based speech recognition
system in highly-reverberant real environments using the HRRE database. The
performance of locally-normalized filter bank (LNFB) and Mel filter bank
(MelFB) features in combination with Non-negative Matrix Factorization (NMF),
Suppression of Slowly-varying components and the Falling edge (SSF) and
Weighted Prediction Error (WPE) enhancement methods are discussed and
evaluated. Two training conditions were considered: clean and reverberated
(Reverb). With Reverb training the use of WPE and LNFB provides WERs that are
3% and 20% lower in average than SSF and NMF, respectively. WPE and MelFB
provides WERs that are 11% and 24% lower in average than SSF and NMF,
respectively. With clean training, which represents a significant mismatch
between testing and training conditions, LNFB features clearly outperform MelFB
features. The results show that different types of training, parametrization,
and enhancement techniques may work better for a specific combination of
speaker-microphone distance and reverberation time. This suggests that there
could be some degree of complementarity between systems trained with different
enhancement and parametrization methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09016</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09016</id><created>2018-03-23</created><updated>2018-04-03</updated><authors><author><keyname>Escudero</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Novoa</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Mahu</keyname><forenames>Rodrigo</forenames></author><author><keyname>Wuth</keyname><forenames>Jorge</forenames></author><author><keyname>Huenup&#xe1;n</keyname><forenames>Fernando</forenames></author><author><keyname>Stern</keyname><forenames>Richard</forenames></author><author><keyname>Yoma</keyname><forenames>N&#xe9;stor Becerra</forenames></author></authors><title>An improved DNN-based spectral feature mapping that removes noise and
  reverberation for robust automatic speech recognition</title><categories>eess.AS cs.SD</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Reverberation and additive noise have detrimental effects on the performance
of automatic speech recognition systems. In this paper we explore the ability
of a DNN-based spectral feature mapping to remove the effects of reverberation
and additive noise. Experiments with the CHiME-2 database show that this DNN
can achieve an average reduction in WER of 4.5%, when compared to the baseline
system, at SNRs equal to -6 dB, -3 dB, 0 dB and 3 dB, and just 0.8% at greater
SNRs of 6 dB and 9 dB. These results suggest that this DNN is more effective in
removing additive noise than reverberation. To improve the DNN performance, we
combine it with the weighted prediction error (WPE) method that shows a
complementary behavior. While this combination provided a reduction in WER of
approximately 11% when compared with the baseline, the observed improvement is
not as great as that obtained using WPE alone. However, modifications to the
DNN training process were applied and an average reduction in WER equal to
18.3% was achieved when compared with the baseline system. Furthermore, the
improved DNN combined with WPE achieves a reduction in WER of 7.9% when
compared with WPE alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09017</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09017</id><created>2018-03-23</created><authors><author><keyname>Wang</keyname><forenames>Yuxuan</forenames></author><author><keyname>Stanton</keyname><forenames>Daisy</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author><author><keyname>Battenberg</keyname><forenames>Eric</forenames></author><author><keyname>Shor</keyname><forenames>Joel</forenames></author><author><keyname>Xiao</keyname><forenames>Ying</forenames></author><author><keyname>Ren</keyname><forenames>Fei</forenames></author><author><keyname>Jia</keyname><forenames>Ye</forenames></author><author><keyname>Saurous</keyname><forenames>Rif A.</forenames></author></authors><title>Style Tokens: Unsupervised Style Modeling, Control and Transfer in
  End-to-End Speech Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose &quot;global style tokens&quot; (GSTs), a bank of embeddings
that are jointly trained within Tacotron, a state-of-the-art end-to-end speech
synthesis system. The embeddings are trained with no explicit labels, yet learn
to model a large range of acoustic expressiveness. GSTs lead to a rich set of
significant results. The soft interpretable &quot;labels&quot; they generate can be used
to control synthesis in novel ways, such as varying speed and speaking style -
independently of the text content. They can also be used for style transfer,
replicating the speaking style of a single audio clip across an entire
long-form text corpus. When trained on noisy, unlabeled found data, GSTs learn
to factorize noise and speaker identity, providing a path towards highly
scalable but robust speech synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09033</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09033</id><created>2018-03-23</created><authors><author><keyname>Rao</keyname><forenames>Anyi</forenames></author><author><keyname>Lau</keyname><forenames>Francis</forenames></author></authors><title>Automatic Music Accompanist</title><categories>cs.SD cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic musical accompaniment is where a human musician is accompanied by a
computer musician. The computer musician is able to produce musical
accompaniment that relates musically to the human performance. The
accompaniment should follow the performance using observations of the notes
they are playing. This paper describes a complete and detailed construction of
a score following and accompanying system using Hidden Markov Models (HMMs). It
details how to train a score HMM, how to deal with polyphonic input, how this
HMM work when following score, how to build up a musical accompanist. It
proposes a new parallel hidden Markov model for score following and a fast
decoding algorithm to deal with performance errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09047</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09047</id><created>2018-03-23</created><authors><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author><author><keyname>Battenberg</keyname><forenames>Eric</forenames></author><author><keyname>Xiao</keyname><forenames>Ying</forenames></author><author><keyname>Wang</keyname><forenames>Yuxuan</forenames></author><author><keyname>Stanton</keyname><forenames>Daisy</forenames></author><author><keyname>Shor</keyname><forenames>Joel</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Clark</keyname><forenames>Rob</forenames></author><author><keyname>Saurous</keyname><forenames>Rif A.</forenames></author></authors><title>Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with
  Tacotron</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension to the Tacotron speech synthesis architecture that
learns a latent embedding space of prosody, derived from a reference acoustic
representation containing the desired prosody. We show that conditioning
Tacotron on this learned embedding space results in synthesized audio that
matches the prosody of the reference signal with fine time detail even when the
reference and synthesis speakers are different. Additionally, we show that a
reference prosody embedding can be used to synthesize text that is different
from that of the reference utterance. We define several quantitative and
subjective metrics for evaluating prosody transfer, and report results with
accompanying audio samples from single-speaker and 44-speaker Tacotron models
on a prosody transfer task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09059</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09059</id><created>2018-03-24</created><authors><author><keyname>Ding</keyname><forenames>Wenhao</forenames></author><author><keyname>He</keyname><forenames>Liang</forenames></author></authors><title>MTGAN: Speaker Verification through Multitasking Triplet Generative
  Adversarial Networks</title><categories>cs.SD eess.AS</categories><comments>submitted to Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an enhanced triplet method that improves the
encoding process of embeddings by jointly utilizing generative adversarial
mechanism and multitasking optimization. We extend our triplet encoder with
Generative Adversarial Networks (GANs) and softmax loss function. GAN is
introduced for increasing the generality and diversity of samples, while
softmax is for reinforcing features about speakers. For simplification, we term
our method Multitasking Triplet Generative Adversarial Networks (MTGAN).
Experiment on short utterances demonstrates that MTGAN reduces the verification
equal error rate (EER) by 67% (relatively) and 32% (relatively) over
conventional i-vector method and state-of-the-art triplet loss method
respectively. This effectively indicates that MTGAN outperforms triplet methods
in the aspect of expressing the high-level feature of speaker information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09075</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09075</id><created>2018-03-24</created><updated>2018-04-01</updated><authors><author><keyname>Obungoloch</keyname><forenames>Johnes</forenames></author><author><keyname>Harper</keyname><forenames>Joshua</forenames></author><author><keyname>Consevage</keyname><forenames>Steven</forenames></author><author><keyname>Savukov</keyname><forenames>Igor</forenames></author><author><keyname>Neuberger</keyname><forenames>Thomas</forenames></author><author><keyname>Tadigadapa</keyname><forenames>Srinivas</forenames></author><author><keyname>Schiff</keyname><forenames>Steven J.</forenames></author></authors><title>Design of a sustainable pre-polarizing magnetic resonance imaging system
  for infant hydrocephalus</title><categories>physics.med-ph eess.IV</categories><comments>21 pages, 9 figures, 39 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for affordable and appropriate medical technologies for developing
countries continue to rise as challenges such as inadequate energy supply,
limited technical expertise and poor infrastructure persists. Low-field MRI is
a technology that can be tailored to meet specific imaging needs within such
countries. Its low power requirements and the possibility of operating in
minimally shielded or unshielded environments make it especially attractive.
Although the technology has been widely demonstrated over several decades, it
is yet to be shown that it can be diagnostic and improve patient outcomes in
clinical applications. We here demonstrate the robustness of pre-polarizing MRI
(PMRI) technology for assembly and deployment in developing countries for the
specific application to infant hydrocephalus. Hydrocephalus treatment planning
and management requires modest spatial resolution, and only that the brain can
be distinguished from fluid - tissue contrast detail within the brain
parenchyma is not essential. We constructed an internally shielded PMRI system
based on the Lee-Whiting coil system with a 22 cm diameter of spherical volume.
In an unshielded room, projection phantom images were acquired at 113 kHz with
in-plane resolution of 3 mm x 3 mm, by introducing gradient fields of
sufficient magnitude to dominate the 5000ppm inhomogeneity of the readout
field. The low cost, straightforward assembly, deployment potential, and
maintenance requirements demonstrate the suitability of our PMRI system for
developing countries. Further improvement in the image spatial resolution and
contrast of low-field MRI will broaden its potential clinical utility beyond
hydrocephalus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09175</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09175</id><created>2018-03-24</created><authors><author><keyname>Yadav</keyname><forenames>Animesh</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ansari</keyname><forenames>Nirwan</forenames></author></authors><title>Distributed Energy and Resource Management for Full-Duplex Dense Small
  Cells for 5G</title><categories>eess.SP</categories><comments>In Proc. of IEEE IWCMC-2017, Valencia, Spain, Jun. 2017</comments><doi>10.1109/IWCMC.2017.7986275</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-carrier and densely deployed small cell network, where
small cells are powered by renewable energy source and operate in a full-duplex
mode. We formulate an energy and traffic aware resource allocation optimization
problem, where a joint design of the beamformers, power and sub-carrier
allocation, and users scheduling is proposed. The problem minimizes the sum
data buffer lengths of each user in the network by using the harvested energy.
A practical uplink user rate-dependent decoding energy consumption is included
in the total energy consumption at the small cell base stations. Hence,
harvested energy is shared with both downlink and uplink users. Owing to the
non-convexity of the problem, a faster convergence sub-optimal algorithm based
on successive parametric convex approximation framework is proposed. The
algorithm is implemented in a distributed fashion, by using the alternating
direction method of multipliers, which offers not only the limited information
exchange between the base stations, but also fast convergence. Numerical
results advocate the redesigning of the resource allocation strategy when the
energy at the base station is shared among the downlink and uplink
transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09272</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09272</id><created>2018-03-25</created><authors><author><keyname>Singh</keyname><forenames>Abhinoy Kumar</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Rahul</forenames></author><author><keyname>Bhaumik</keyname><forenames>Shovan</forenames></author><author><keyname>Date</keyname><forenames>Paresh</forenames></author></authors><title>Adaptive Sparse-grid Gauss-Hermite Filter</title><categories>eess.SP</categories><comments>27 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new nonlinear filter based on sparse-grid quadrature method
has been proposed. The proposed filter is named as adaptive sparse-grid
Gauss-Hermite filter (ASGHF). Ordinary sparse-grid technique treats all the
dimensions equally, whereas the ASGHF assigns a fewer number of points along
the dimensions with lower nonlinearity. It uses adaptive tensor product to
construct multidimensional points until a predefined error tolerance level is
reached. The performance of the proposed filter is illustrated with two
nonlinear filtering problems. Simulation results demonstrate that the new
algorithm achieves a similar accuracy as compared to sparse-grid Gauss-Hermite
filter (SGHF) and Gauss-Hermite filter (GHF) with a considerable reduction in
computational load. Further, in the conventional GHF and SGHF, any increase in
the accuracy level may result in an unacceptably high increase in the
computational burden. However, in ASGHF, a little increase in estimation
accuracy is possible with a limited increase in computational burden by varying
the error tolerance level and the error weighting parameter. This enables the
online estimator to operate near full efficiency with a predefined
computational budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09323</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09323</id><created>2018-03-25</created><authors><author><keyname>Balevi</keyname><forenames>Eren</forenames></author><author><keyname>Rabee</keyname><forenames>Faeik T. Al</forenames></author><author><keyname>Gitlin</keyname><forenames>Richard D.</forenames></author></authors><title>ALOHA-NOMA for Massive Machine-to-Machine IoT Communication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new medium access control (MAC) protocol for Internet
of Things (IoT) applications incorporating pure ALOHA with power domain
non-orthogonal multiple access (NOMA) in which the number of transmitters are
not known as a priori information and estimated with multi-hypothesis testing.
The proposed protocol referred to as ALOHA-NOMA is not only scalable, energy
efficient and matched to the low complexity requirements of IoT devices, but it
also significantly increases the throughput. Specifically, throughput is
increased to 1.27 with ALOHA-NOMA when 5 users can be separated via a SIC
(Successive Interference Cancellation) receiver in comparison to the classical
result of 0.18 in pure ALOHA. The results further show that there is a greater
than linear increase in throughput as the number of active IoT devices
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09350</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09350</id><created>2018-03-25</created><updated>2018-11-18</updated><authors><author><keyname>Zhang</keyname><forenames>Shan</forenames></author><author><keyname>Theagarajan</keyname><forenames>Lakshmi Narasimhan</forenames></author><author><keyname>Choi</keyname><forenames>Sora</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Fusion of Correlated Decisions Using Regular Vine Copulas</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2901379</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a regular vine copula based methodology for the
fusion of correlated decisions. Regular vine copula is an extremely flexible
and powerful graphical model to characterize complex dependence among multiple
modalities. It can express a multivariate copula by using a cascade of
bivariate copulas, the so-called pair copulas. Assuming that local detectors
are single threshold binary quantizers and taking complex dependence among
sensor decisions into account, we design an optimal fusion rule using a regular
vine copula under the Neyman-Pearson framework. In order to reduce the
computational complexity resulting from the complex dependence, we propose an
efficient and computationally light regular vine copula based optimal fusion
algorithm. Numerical experiments are conducted to demonstrate the effectiveness
of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09404</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09404</id><created>2018-03-26</created><authors><author><keyname>Imre</keyname><forenames>Kaya</forenames></author><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author><author><keyname>Schunke</keyname><forenames>Beatrix</forenames></author></authors><title>A Hierarchy of Empirical Models of Plasma Profiles and Transport</title><categories>stat.ME eess.SP</categories><journal-ref>Physics of Plasmas 2, 1614 (1995)</journal-ref><doi>10.1063/1.871311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two families of statistical models are presented which generalize global
confinement expressions to plasma profiles and local transport coefficients.
The temperature or diffusivity is parameterized as a function of the normalized
flux radius, $\bar{\psi}$, and the engineering variables, ${\bf u} =
(I_p,B_t,\bar{n},q_{95})^\dagger$. The log-additive temperature model assumes
that $\ln [T(\bar{\psi}, {\bf u})] =$ $f_0 (\bar{\psi}) + f_I
(\bar{\psi})\ln[I_p]$ $+ f_B (\bar{\psi}) \ln [B_t]$ $+ f_n (\bar{\psi}) \ln [
\bar{n}] + f_{q}\ln[q_{95}]$. The unknown $f_i (\bar{\psi})$ are estimated
using smoothing splines. A 43 profile Ohmic data set from the Joint European
Torus is analyzed and its shape dependencies are described. The best fit has an
average error of 152 eV which is 10.5 \% percent of the typical line average
temperature. The average error is less than the estimated measurement error
bars. The second class of models is log-additive diffusivity models where $\ln
[ \chi (\bar{\psi}, {\bf u})] $ $=\ g_0 (\bar{\psi}) + g_I (\bar{\psi})
\ln[I_p]$ $+ g_B (\bar{\psi}) \ln [B_t ]$ $+ g_n (\bar{\psi}) \ln [ \bar{n} ]$.
These log-additive diffusivity models are useful when the diffusivity is varied
smoothly with the plasma parameters. A penalized nonlinear regression technique
is recommended to estimate the $g_i (\bar{\psi})$. The physics implications of
the two classes of models, additive log-temperature models and additive
log-diffusivity models, are different. The additive log-diffusivity models
adjust the temperature profile shape as the radial distribution of sinks and
sources. In contrast, the additive log-temperature model predicts that the
temperature profile depends only on the global parameters and not on the radial
heat deposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09478</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09478</id><created>2018-03-26</created><authors><author><keyname>Rastorgueva-Foi</keyname><forenames>Elizaveta</forenames></author><author><keyname>Costa</keyname><forenames>M&#xe1;rio</forenames></author><author><keyname>Koivisto</keyname><forenames>Mike</forenames></author><author><keyname>Lepp&#xe4;nen</keyname><forenames>Kari</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>User Positioning in mmW 5G Networks using Beam-RSRP Measurements and
  Kalman Filtering</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 6 figure, submitted to FUSION 2018: 21st International
  Conference on Information Fusion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we exploit the 3D-beamforming features of multiantenna
equipment employed in fifth generation (5G) networks, operating in the
millimeter wave (mmW) band, for accurate positioning and tracking of users. We
consider sequential estimation of users' positions, and propose a two-stage
extended Kalman filter (EKF) that is based on reference signal received power
(RSRP) measurements. In particular, beamformed downlink (DL) reference signals
(RS) are transmitted by multiple base stations (BSs) and measured by user
equipmentn(UE) employing receive beamforming. The so-obtained BRSRP
measurements are fed back to the BS where the corresponding
direction-of-departure are sequentially estimated by a novel EKF. Such angle
estimates from multiple BSs are subsequently fused on a central entity into 3D
position estimates of UE by means of an angle-based EKF. The proposed
positioning scheme is scalable since the computational burden is shared among
different network entities, namely transmission/reception points (TRPs) and
5G-NR Node B (gNB), and may be accomplished with the signalling currently
specified for 5G. We assess the performance of the proposed algorithm on a
realistic outdoor 5G deployment with a detailed ray tracing propagation model
based on the METIS Madrid map. Numerical results with a system operating at 39
GHz show that sub-meter 3D positioning accuracy is achievable in future mmW 5G
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09487</identifier>
 <datestamp>2019-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09487</id><created>2018-03-26</created><updated>2018-08-30</updated><authors><author><keyname>Ringh</keyname><forenames>Axel</forenames></author><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author><author><keyname>Lindquist</keyname><forenames>Anders</forenames></author></authors><title>Lower bounds on the maximum delay margin by analytic interpolation</title><categories>math.OC cs.SY eess.SY</categories><comments>7 pages, minor revision, accepted for 57th IEEE Conference on
  Decision and Control (CDC 2018)</comments><msc-class>47N70, 93B52, 30E05,</msc-class><doi>10.1109/CDC.2018.8618930</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the delay margin problem in the context of recent works by T. Qi, J.
Zhu, and J. Chen, where a sufficient condition for the maximal delay margin is
formulated in terms of an interpolation problem obtained after introducing a
rational approximation. Instead we omit the approximation step and solve the
same problem directly using techniques from function theory and analytic
interpolation. Furthermore, we introduce a constant shift in the domain of the
interpolation problem. In this way we are able to improve on their lower bound
for the maximum delay margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09513</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09513</id><created>2018-03-26</created><authors><author><keyname>Elkourdi</keyname><forenames>Mohamed</forenames></author><author><keyname>Mazin</keyname><forenames>Asim</forenames></author><author><keyname>Balevi</keyname><forenames>Eren</forenames></author><author><keyname>Gitlin</keyname><forenames>Richard D.</forenames></author></authors><title>Enabling Aloha-NOMA for Massive M2M Communication in IoT Networks</title><categories>eess.SP</categories><comments>WAMICON submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of things (IoT), which is the network of physical devices
embedded with sensors, actuators, and connec- tivity, is being accelerated into
the mainstream by the emergence of 5G wireless networking. This paper presents
an uncoordinated non-orthogonal random access protocol, an enhancement to the
recently introduced Aloha-NOMA protocol, which provides high throughput, while
being matched to the low complexity requirements and the sporadic traffic
pattern of IoT devices. Under ideal conditions it has been shown that
Aloha-NOMA, using power-domain orthogonality, can significantly increase the
throughput using SIC (Successive Interference Cancellation) to enable correct
reception of multiple simultaneous transmitted signals. For this ideal
performance, the enhanced Aloha-NOMA receiver adaptively learns the number of
active devices (which is not known a priori) using a form of multi-hypothesis
testing. For small numbers of simultaneous transmissions, it is shown that
there can be substantial throughput gain of 6.9 dB relative to pure Aloha for
0.25 probability of transmission and up to 3 active transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09592</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09592</id><created>2018-03-26</created><authors><author><keyname>Schrumpf</keyname><forenames>Fabian</forenames></author><author><keyname>Bausch</keyname><forenames>Gerold</forenames></author><author><keyname>Sturm</keyname><forenames>Matthias</forenames></author><author><keyname>Fuchs</keyname><forenames>Mirco</forenames></author></authors><title>Similarity based hierarchical clustering of physiological parameters for
  the identification of health states - a feasibility study</title><categories>eess.SP cs.CY cs.LG</categories><comments>39th Annual International Conference of the IEEE Engineering in
  Medicine and Biology Society (EMBC)</comments><journal-ref>2017 39th Annual International Conference of the IEEE Engineering
  in Medicine and Biology Society (EMBC) (pp. 458-462)</journal-ref><doi>10.1109/EMBC.2017.8036861</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces a new unsupervised method for the clustering of
physiological data into health states based on their similarity. We propose an
iterative hierarchical clustering approach that combines health states
according to a similarity constraint to new arbitrary health states. We applied
method to experimental data in which the physical strain of subjects was
systematically varied. We derived health states based on parameters extracted
from ECG data. The occurrence of health states shows a high temporal
correlation to the experimental phases of the physical exercise. We compared
our method to other clustering algorithms and found a significantly higher
accuracy with respect to the identification of health states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09602</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09602</id><created>2018-03-26</created><authors><author><keyname>Kelner</keyname><forenames>Jan M.</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Ziolkowski</keyname><forenames>Cezary</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Uljasz</keyname><forenames>Bogdan</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author></authors><title>Comparison of angular spread for 6 and 60 GHz based on 3GPP standard</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 8 figures</comments><msc-class>94A40, 94A05, 94A12, 94A17</msc-class><acm-class>E.4; H.4.3</acm-class><journal-ref>Proceedings of 2018 22nd International Microwave and Radar
  Conference (MIKON), Poznan, Poland, 15-17.05.2018., pp. 1-5</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an urban environment, a multipath propagation is one of the basic
phenomena affecting a quality of received signals. This causes dispersions in
time and angular domains. Basic parameters describing these dispersions are the
rms delay spread and rms angle spread, respectively. The delay spread is
related to a frequency of the transmitted signal and the nature of the
propagation environment. In this paper, we show a mutual relationship between
the time and angular dispersions in the received signal. The obtained
simulation results present a comparison of the described dispersions for two
different frequencies. In this case, the multi-elliptical propagation model and
standard model developed by 3GPP are the basis for the simulation analysis of
new communication system solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09603</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09603</id><created>2018-03-26</created><authors><author><keyname>Kelner</keyname><forenames>Jan M.</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Ziolkowski</keyname><forenames>Cezary</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Uljasz</keyname><forenames>Bogdan</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author></authors><title>Evaluation of angular dispersion for various propagation environments in
  emerging 5G systems</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 10 figures, 3 tables</comments><msc-class>94A40, 94A05, 94A12, 94A17</msc-class><acm-class>E.4; H.4.3</acm-class><journal-ref>Proceedings of 2018 22nd International Microwave and Radar
  Conference (MIKON), Poznan, Poland, 15-17.05.2018., pp. 1-5</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Angular dispersion is the effect of a multi-path propagation observed in
received signals. An assessment of this phenomenon is particularly important
from the viewpoint of emerging fifth generation (5G) communication systems. In
these systems, using the beam-forming and massive multiple-input
multiple-output antenna arrays are planned. This phenomenon also has a negative
impact on direction finding and older generation communication systems used in
an urban environment. In this paper, we present the angular dispersion
evaluation for various propagation environments based on simulation studies.
This analysis is carried out for different environment types defined in the
3GPP standard model for a selected frequency. In this case, the angular spread
is determinated based on the power angular spectrum. This parameter is the
basis for the influence evaluation of the propagation environment on the
received signal angular dispersion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09609</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09609</id><created>2018-03-26</created><authors><author><keyname>Kelner</keyname><forenames>Jan M.</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Ziolkowski</keyname><forenames>Cezary</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author></authors><title>Modeling power angle spectrum and antenna pattern directions in
  multipath propagation environment</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 7 figures</comments><msc-class>94A40, 94A05, 94A12, 94A17</msc-class><acm-class>E.4; H.4.3</acm-class><journal-ref>Proceedings of 2018 12th European Conference on Antennas and
  Propagation (EuCAP), London, UK, 9-13.04.2018., pp. 1-5</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most propagation models do not consider the influence of antenna patterns on
the parameters and characteristics of received signals. This assumption is
equivalent to the use of isotropic or omnidirectional antennas in these models.
Empirical measurement results indicate that the radiation pattern, gain and
direction of directional antennas significantly influence on properties of the
received signal. This fact shows that consideration the directional antennas in
propagation models is very important especially in the context of emerging
telecommunication technologies such as beamforming or massive MIMO. The purpose
of this paper is to present the modeling method of power angular spectrum and
direction of antenna patterns in a multipath propagation environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09617</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09617</id><created>2018-03-26</created><authors><author><keyname>Ziolkowski</keyname><forenames>Cezary</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Kelner</keyname><forenames>Jan M.</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author><author><keyname>Nowosielski</keyname><forenames>Leszek</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author></authors><title>Correlation properties of signal at mobile receiver for different
  propagation environments</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages, 5 figures</comments><msc-class>94A40, 94A05, 94A12, 94A17</msc-class><acm-class>E.4; H.4.3</acm-class><journal-ref>Proceedings of 2018 14th International Conference on Advanced
  Trends in Radioelectronics, Telecommunications and Computer Engineering
  (TCSET), Lviv-Slavske, Ukraine, 20-24.02.2018., pp. 1-4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An issue of the parameter selection in various branches of a multi-antenna
receiver system determines its effectiveness. A significant effect on these
parameters are correlation properties of received signals. In this paper, the
assessment of the signal correlation properties for different environmental
conditions is presented. The obtained results showed that depending on the
receiver speed, the adaptive selection of the delays in the different RAKE
receiver branches provide minimization of the correlation between the signals.
Particularly low levels of the signal correlation could be obtained in complex
propagation environments such as urban and bad urban.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09631</identifier>
 <datestamp>2019-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09631</id><created>2018-03-26</created><updated>2018-10-25</updated><authors><author><keyname>Zhao</keyname><forenames>Mengnan</forenames></author><author><keyname>Kaba</keyname><forenames>M. Devrim</forenames></author><author><keyname>Vidal</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Robinson</keyname><forenames>Daniel P.</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Sparse Recovery over Graph Incidence Matrices</title><categories>cs.IT cs.SI eess.SP math.IT</categories><comments>Accepted to 57th IEEE Conference on Decision and Control</comments><doi>10.1109/CDC.2018.8619666</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical results in sparse recovery guarantee the exact reconstruction of
$s$-sparse signals under assumptions on the dictionary that are either too
strong or NP-hard to check. Moreover, such results may be pessimistic in
practice since they are based on a worst-case analysis. In this paper, we
consider the sparse recovery of signals defined over a graph, for which the
dictionary takes the form of an incidence matrix. We derive necessary and
sufficient conditions for sparse recovery, which depend on properties of the
cycles of the graph that can be checked in polynomial time. We also derive
support-dependent conditions for sparse recovery that depend only on the
intersection of the cycles of the graph with the support of the signal.
Finally, we exploit sparsity properties on the measurements and the structure
of incidence matrices to propose a specialized sub-graph-based recovery
algorithm that outperforms the standard $\ell_1$-minimization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09816</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09816</id><created>2018-03-26</created><authors><author><keyname>Bagchi</keyname><forenames>Deblin</forenames></author><author><keyname>Plantinga</keyname><forenames>Peter</forenames></author><author><keyname>Stiff</keyname><forenames>Adam</forenames></author><author><keyname>Fosler-Lussier</keyname><forenames>Eric</forenames></author></authors><title>Spectral feature mapping with mimic loss for robust speech recognition</title><categories>cs.SD cs.CL eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the task of speech enhancement, local learning objectives are agnostic to
phonetic structures helpful for speech recognition. We propose to add a global
criterion to ensure de-noised speech is useful for downstream tasks like ASR.
We first train a spectral classifier on clean speech to predict senone labels.
Then, the spectral classifier is joined with our speech enhancer as a noisy
speech recognizer. This model is taught to imitate the output of the spectral
classifier alone on clean speech. This \textit{mimic loss} is combined with the
traditional local criterion to train the speech enhancer to produce de-noised
speech. Feeding the de-noised speech to an off-the-shelf Kaldi training recipe
for the CHiME-2 corpus shows significant improvements in WER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09848</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09848</id><created>2018-03-26</created><authors><author><keyname>Hussein</keyname><forenames>Ramy</forenames></author><author><keyname>Palangi</keyname><forenames>Hamid</forenames></author><author><keyname>Ward</keyname><forenames>Rabab</forenames></author><author><keyname>Wang</keyname><forenames>Z. Jane</forenames></author></authors><title>Epileptic Seizure Detection: A Deep Learning Approach</title><categories>eess.SP</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epilepsy is the second most common brain disorder after migraine. Automatic
detection of epileptic seizures can considerably improve the patients' quality
of life. Current Electroencephalogram (EEG)-based seizure detection systems
encounter many challenges in real-life situations. The EEGs are non-stationary
signals and seizure patterns vary across patients and recording sessions.
Moreover, EEG data are prone to numerous noise types that negatively affect the
detection accuracy of epileptic seizures. To address these challenges, we
introduce the use of a deep learning-based approach that automatically learns
the discriminative EEG features of epileptic seizures. Specifically, to reveal
the correlation between successive data samples, the time-series EEG data are
first segmented into a sequence of non-overlapping epochs. Second, Long
Short-Term Memory (LSTM) network is used to learn the high-level
representations of the normal and the seizure EEG patterns. Third, these
representations are fed into Softmax function for training and classification.
The results on a well-known benchmark clinical dataset demonstrate the
superiority of the proposed approach over the existing state-of-the-art
methods. Furthermore, our approach is shown to be robust in noisy and real-life
conditions. Compared to current methods that are quite sensitive to noise, the
proposed method maintains its high detection performance in the presence of
common EEG artifacts (muscle activities and eye-blinking) as well as white
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09946</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09946</id><created>2018-03-27</created><authors><author><keyname>Nakashika</keyname><forenames>Toru</forenames></author><author><keyname>Takaki</keyname><forenames>Shinji</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Complex-Valued Restricted Boltzmann Machine for Direct Speech
  Parameterization from Complex Spectra</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Under the IEEE T-ASLP Review</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper describes a novel energy-based probabilistic distribution that
represents complex-valued data and explains how to apply it to direct feature
extraction from complex-valued spectra. The proposed model, the complex-valued
restricted Boltzmann machine (CRBM), is designed to deal with complex-valued
visible units as an extension of the well-known restricted Boltzmann machine
(RBM). Like the RBM, the CRBM learns the relationships between visible and
hidden units without having connections between units in the same layer, which
dramatically improves training efficiency by using Gibbs sampling or
contrastive divergence (CD). Another important characteristic is that the CRBM
also has connections between real and imaginary parts of each of the
complex-valued visible units that help represent the data distribution in the
complex domain. In speech signal processing, classification and generation
features are often based on amplitude spectra (e.g., MFCC, cepstra, and
mel-cepstra) even if they are calculated from complex spectra, and they ignore
phase information. In contrast, the proposed feature extractor using the CRBM
directly encodes the complex spectra (or another complex-valued representation
of the complex spectra) into binary-valued latent features (hidden units).
Since the visible-hidden connections are undirected, we can also recover
(decode) the complex spectra from the latent features directly. Our speech
coding experiments demonstrated that the CRBM outperformed other speech coding
methods, such as methods using the conventional RBM, the mel-log spectrum
approximate (MLSA) decoder, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.09960</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.09960</id><created>2018-03-27</created><updated>2018-03-28</updated><authors><author><keyname>Ronan</keyname><forenames>David</forenames></author><author><keyname>Ma</keyname><forenames>Zheng</forenames></author><author><keyname>Namara</keyname><forenames>Paul Mc</forenames></author><author><keyname>Gunes</keyname><forenames>Hatice</forenames></author><author><keyname>Reiss</keyname><forenames>Joshua D.</forenames></author></authors><title>Automatic Minimisation of Masking in Multitrack Audio using Subgroups</title><categories>eess.AS cs.SD</categories><comments>14 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The iterative process of masking minimisation when mixing multitrack audio is
a challenging optimisation problem, in part due to the complexity and
non-linearity of auditory perception. In this article, we first propose a
multitrack masking metric inspired by the MPEG psychoacoustic model. We
investigate different audio processing techniques to manipulate the frequency
and dynamic characteristics of the signal in order to reduce masking based on
the proposed metric. We also investigate whether or not automatically mixing
using subgrouping is beneficial or not to perceived quality and clarity of a
mix. Evaluation results suggest that our proposed masking metric when used in
an automatic mixing framework can be used to reduce inter-channel auditory
masking as well as improve the perceived quality and perceived clarity of a
mix. Furthermore, our results suggest that using subgrouping in an automatic
mixing framework can be used to improve the perceived quality and perceived
clarity of a mix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10013</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10013</id><created>2018-03-27</created><authors><author><keyname>Subramanian</keyname><forenames>Aswin Shanmugam</forenames></author><author><keyname>Chen</keyname><forenames>Szu-Jui</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Student-Teacher Learning for BLSTM Mask-based Speech Enhancement</title><categories>eess.AS cs.SD</categories><comments>Submitted for Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral mask estimation using bidirectional long short-term memory (BLSTM)
neural networks has been widely used in various speech enhancement
applications, and it has achieved great success when it is applied to
multichannel enhancement techniques with a mask-based beamformer. However, when
these masks are used for single channel speech enhancement they severely
distort the speech signal and make them unsuitable for speech recognition. This
paper proposes a student-teacher learning paradigm for single channel speech
enhancement. The beamformed signal from multichannel enhancement is given as
input to the teacher network to obtain soft masks. An additional cross-entropy
loss term with the soft mask target is combined with the original loss, so that
the student network with single-channel input is trained to mimic the soft mask
obtained with multichannel input through beamforming. Experiments with the
CHiME-4 challenge single channel track data shows improvement in ASR
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10108</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10108</id><created>2018-03-27</created><updated>2018-06-26</updated><authors><author><keyname>Koldovsk&#xfd;</keyname><forenames>Zbyn&#x11b;k</forenames></author><author><keyname>Tichavsk&#xfd;</keyname><forenames>Petr</forenames></author></authors><title>Gradient Algorithms for Complex Non-Gaussian Independent
  Component/Vector Extraction, Question of Convergence</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/TSP.2018.2887185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revise the problem of extracting one independent component from an
instantaneous linear mixture of signals. The mixing matrix is parameterized by
two vectors, one column of the mixing matrix and one row of the de-mixing
matrix. The separation is based on the non-Gaussianity of the source of
interest, while the other background signals are assumed to be Gaussian. Three
gradient-based estimation algorithms are derived using the maximum likelihood
principle and are compared with the Natural Gradient algorithm for Independent
Component Analysis and with One-unit FastICA based on negentropy maximization.
The ideas and algorithms are also generalized for the extraction of a vector
component when the extraction proceeds jointly from a set of instantaneous
mixtures. Throughout the paper, we address the problem of the size of the
region of convergence for which the algorithms guarantee the extraction of the
desired source. We show how that size is influenced by the ratio of powers of
the sources within the mixture. Simulations confirm this observation where
several algorithms are compared. They show various convergence behavior in a
scenario where the source of interest is dominant or weak. Here, our proposed
modifications of the gradient methods taking into account the
dominance/weakness of the source show improved global convergence property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10109</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10109</id><created>2018-03-27</created><authors><author><keyname>Chen</keyname><forenames>Szu-Jui</forenames></author><author><keyname>Subramanian</keyname><forenames>Aswin Shanmugam</forenames></author><author><keyname>Xu</keyname><forenames>Hainan</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Building state-of-the-art distant speech recognition using the CHiME-4
  challenge with a setup of speech enhancement baseline</title><categories>cs.SD cs.LG eess.AS</categories><comments>Submitted for Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new baseline system for automatic speech recognition
(ASR) in the CHiME-4 challenge to promote the development of noisy ASR in
speech processing communities by providing 1) state-of-the-art system with a
simplified single system comparable to the complicated top systems in the
challenge, 2) publicly available and reproducible recipe through the main
repository in the Kaldi speech recognition toolkit. The proposed system adopts
generalized eigenvalue beamforming with bidirectional long short-term memory
(LSTM) mask estimation. We also propose to use a time delay neural network
(TDNN) based on the lattice-free version of the maximum mutual information
(LF-MMI) trained with augmented all six microphones plus the enhanced data
after beamforming. Finally, we use a LSTM language model for lattice and n-best
re-scoring. The final system achieved 2.74\% WER for the real test set in the
6-channel track, which corresponds to the 2nd place in the challenge. In
addition, the proposed baseline recipe includes four different speech
enhancement measures, short-time objective intelligibility measure (STOI),
extended STOI (eSTOI), perceptual evaluation of speech quality (PESQ) and
speech distortion ratio (SDR) for the simulation test set. Thus, the recipe
also provides an experimental platform for speech enhancement studies with
these performance measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10132</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10132</id><created>2018-03-27</created><updated>2018-10-25</updated><authors><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Junbo</forenames></author><author><keyname>Sun</keyname><forenames>Sining</forenames></author><author><keyname>Wang</keyname><forenames>Yujun</forenames></author><author><keyname>Xiang</keyname><forenames>Fei</forenames></author><author><keyname>Xie</keyname><forenames>Lei</forenames></author></authors><title>Investigating Generative Adversarial Networks based Speech
  Dereverberation for Robust Speech Recognition</title><categories>cs.SD cs.CL eess.AS</categories><comments>Interspeech 2018</comments><journal-ref>Proceedings of Interspeech, 2018, pp. 1581-1585</journal-ref><doi>10.21437/Interspeech.2018-1780</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the use of generative adversarial networks (GANs) in speech
dereverberation for robust speech recognition. GANs have been recently studied
for speech enhancement to remove additive noises, but there still lacks of a
work to examine their ability in speech dereverberation and the advantages of
using GANs have not been fully established. In this paper, we provide deep
investigations in the use of GAN-based dereverberation front-end in ASR. First,
we study the effectiveness of different dereverberation networks (the generator
in GAN) and find that LSTM leads a significant improvement as compared with
feed-forward DNN and CNN in our dataset. Second, further adding residual
connections in the deep LSTMs can boost the performance as well. Finally, we
find that, for the success of GAN, it is important to update the generator and
the discriminator using the same mini-batch data during training. Moreover,
using reverberant spectrogram as a condition to discriminator, as suggested in
previous studies, may degrade the performance. In summary, our GAN-based
dereverberation front-end achieves 14%-19% relative CER reduction as compared
to the baseline DNN dereverberation network when tested on a strong
multi-condition training acoustic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10136</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10136</id><created>2018-03-27</created><authors><author><keyname>Nahid</keyname><forenames>Md Mahadi Hasan</forenames></author><author><keyname>Islam</keyname><forenames>Md. Ashraful</forenames></author><author><keyname>Purkaystha</keyname><forenames>Bishwajit</forenames></author><author><keyname>Islam</keyname><forenames>Md Saiful</forenames></author></authors><title>Comprehending Real Numbers: Development of Bengali Real Number Speech
  Corpus</title><categories>eess.AS cs.AI cs.SD</categories><comments>9 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Speech recognition has received a less attention in Bengali literature due to
the lack of a comprehensive dataset. In this paper, we describe the development
process of the first comprehensive Bengali speech dataset on real numbers. It
comprehends all the possible words that may arise in uttering any Bengali real
number. The corpus has ten speakers from the different regions of Bengali
native people. It comprises of more than two thousands of speech samples in a
total duration of closed to four hours. We also provide a deep analysis of our
corpus, highlight some of the notable features of it, and finally evaluate the
performances of two of the notable Bengali speech recognizers on it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10146</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10146</id><created>2018-03-27</created><updated>2018-10-25</updated><authors><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Junbo</forenames></author><author><keyname>Wang</keyname><forenames>Yujun</forenames></author><author><keyname>Xie</keyname><forenames>Lei</forenames></author></authors><title>Empirical Evaluation of Speaker Adaptation on DNN based Acoustic Model</title><categories>cs.SD cs.CL eess.AS</categories><comments>Interspeech 2018</comments><journal-ref>Proceedings of Interspeech, 2018, pp. 2429-2433</journal-ref><doi>10.21437/Interspeech.2018-1897</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker adaptation aims to estimate a speaker specific acoustic model from a
speaker independent one to minimize the mismatch between the training and
testing conditions arisen from speaker variabilities. A variety of neural
network adaptation methods have been proposed since deep learning models have
become the main stream. But there still lacks an experimental comparison
between different methods, especially when DNN-based acoustic models have been
advanced greatly. In this paper, we aim to close this gap by providing an
empirical evaluation of three typical speaker adaptation methods: LIN, LHUC and
KLD. Adaptation experiments, with different size of adaptation data, are
conducted on a strong TDNN-LSTM acoustic model. More challengingly, here, the
source and target we are concerned with are standard Mandarin speaker model and
accented Mandarin speaker model. We compare the performances of different
methods and their combinations. Speaker adaptation performance is also examined
by speaker's accent degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10219</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10219</id><created>2018-03-25</created><authors><author><keyname>Zhu</keyname><forenames>Boqing</forenames></author><author><keyname>Wang</keyname><forenames>Changjian</forenames></author><author><keyname>Liu</keyname><forenames>Feng</forenames></author><author><keyname>Lei</keyname><forenames>Jin</forenames></author><author><keyname>Lu</keyname><forenames>Zengquan</forenames></author><author><keyname>Peng</keyname><forenames>Yuxing</forenames></author></authors><title>Learning Environmental Sounds with Multi-scale Convolutional Neural
  Network</title><categories>cs.SD eess.AS</categories><comments>accepted by IJCNN 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has dramatically improved the performance of sounds
recognition. However, learning acoustic models directly from the raw waveform
is still challenging. Current waveform-based models generally use time-domain
convolutional layers to extract features. The features extracted by single size
filters are insufficient for building discriminative representation of audios.
In this paper, we propose multi-scale convolution operation, which can get
better audio representation by improving the frequency resolution and learning
filters cross all frequency area. For leveraging the waveform-based features
and spectrogram-based features in a single model, we introduce two-phase method
to fuse the different features. Finally, we propose a novel end-to-end network
called WaveMsNet based on the multi-scale convolution operation and two-phase
method. On the environmental sounds classification datasets ESC-10 and ESC-50,
the classification accuracies of our WaveMsNet achieve 93.75% and 79.10%
respectively, which improve significantly from the previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10225</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10225</id><created>2018-03-26</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Brakel</keyname><forenames>Philemon</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Light Gated Recurrent Units for Speech Recognition</title><categories>eess.AS cs.NE cs.SD eess.SP</categories><comments>Copyright 2018 IEEE</comments><journal-ref>IEEE Transactions on Emerging Topics in Computational
  Intelligence, vol. 2, no. 2, pp. 92-102, April 2018</journal-ref><doi>10.1109/TETCI.2017.2762739</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A field that has directly benefited from the recent advances in deep learning
is Automatic Speech Recognition (ASR). Despite the great achievements of the
past decades, however, a natural and robust human-machine speech interaction
still appears to be out of reach, especially in challenging environments
characterized by significant noise and reverberation. To improve robustness,
modern speech recognizers often employ acoustic models based on Recurrent
Neural Networks (RNNs), that are naturally able to exploit large time contexts
and long-term speech modulations. It is thus of great interest to continue the
study of proper techniques for improving the effectiveness of RNNs in
processing speech signals.
  In this paper, we revise one of the most popular RNN models, namely Gated
Recurrent Units (GRUs), and propose a simplified architecture that turned out
to be very effective for ASR. The contribution of this work is two-fold: First,
we analyze the role played by the reset gate, showing that a significant
redundancy with the update gate occurs. As a result, we propose to remove the
former from the GRU design, leading to a more efficient and compact single-gate
model. Second, we propose to replace hyperbolic tangent with ReLU activations.
This variation couples well with batch normalization and could help the model
learn long-term dependencies without numerical issues.
  Results show that the proposed architecture, called Light GRU (Li-GRU), not
only reduces the per-epoch training time by more than 30% over a standard GRU,
but also consistently improves the recognition accuracy across different tasks,
input features, noisy conditions, as well as across different ASR paradigms,
ranging from standard DNN-HMM speech recognizers to end-to-end CTC models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10258</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10258</id><created>2018-03-14</created><authors><author><keyname>Tran</keyname><forenames>Duc-Dung</forenames></author><author><keyname>Tran</keyname><forenames>Ha-Vu</forenames></author><author><keyname>Ha</keyname><forenames>Dac-Binh</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author></authors><title>Cooperation in NOMA Networks Under Limited User-to-User Communications:
  Solution and Analysis</title><categories>eess.SP</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new communication protocol for a cooperative
non-orthogonal multiple access (NOMA) system. In this system, based on users'
channel conditions, each two NOMA users are paired to reduce system complexity.
In this concern, the user with a better channel condition decodes and then
forwards messages received from the source to the user with a worse channel
condition. In particular, the direct link between the paired users is assumed
to be unavailable due to the weak transmission conditions. To overcome this
issue, we propose a new cooperative NOMA protocol in which an
amplify-and-forward (AF) relay is employed to help the user-to-user
communications. To evaluate the proposed protocol, the exact closed-form
expressions of outage probability (OP) at the two paired users are derived.
Based on the analysis of the OP, we further examine the system throughput in a
delay-sensitive transmission mode. Finally, our analytical results verified by
Monte-Carlo simulation show that the proposed protocol is efficient in
enhancing the performance of NOMA system when the user-to-user communications
is limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10261</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10261</id><created>2018-03-19</created><authors><author><keyname>Trigui</keyname><forenames>Im&#xe8;ne</forenames></author><author><keyname>Cherif</keyname><forenames>Nesrine</forenames></author><author><keyname>Affes</keyname><forenames>Sofi&#xe8;ne</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Mixed M\'alaga-$\mathcal{M}$ and Generalized-$\cal K$ Dual-Hop FSO/RF
  Systems with Interference</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the impact of radio frequency (RF) cochannel
interference (CCI) on the performance of dual-hop free-space optics (FSO)/RF
relay networks. The considered FSO/RF system operates over mixed
M\'alaga-$\mathcal{M}$/composite fading/shadowing generalized-$\cal K$ ($\cal
GK$) channels with pointing errors. The {\rm H}-transform theory, wherein
integral transforms involve Fox's {\rm H}-functions as kernels, is embodied
into a unifying performance analysis framework that encompasses closed-form
expressions for the outage probability, the average bit error rate (BER), and
the ergodic capacity. By virtue of some {\rm H}-transform asymptotic
expansions, the high signal-to-interference-plus-noise ratio (SINR) analysis
culminates in easy-to-compute expressions for the outage probability and BER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10299</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10299</id><created>2018-03-27</created><updated>2018-06-18</updated><authors><author><keyname>Renduchintala</keyname><forenames>Adithya</forenames></author><author><keyname>Ding</keyname><forenames>Shuoyang</forenames></author><author><keyname>Wiesner</keyname><forenames>Matthew</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Multi-Modal Data Augmentation for End-to-End ASR</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 Pages, 1 Figure, accepted at INTERSPEECH 2018</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We present a new end-to-end architecture for automatic speech recognition
(ASR) that can be trained using \emph{symbolic} input in addition to the
traditional acoustic input. This architecture utilizes two separate encoders:
one for acoustic input and another for symbolic input, both sharing the
attention and decoder parameters. We call this architecture a multi-modal data
augmentation network (MMDA), as it can support multi-modal (acoustic and
symbolic) input and enables seamless mixing of large text datasets with
significantly smaller transcribed speech corpora during training. We study
different ways of transforming large text corpora into a symbolic form suitable
for training our MMDA network. Our best MMDA setup obtains small improvements
on character error rate (CER), and as much as 7-10\% relative word error rate
(WER) improvement over a baseline both with and without an external language
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10343</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10343</id><created>2018-03-27</created><updated>2018-05-07</updated><authors><author><keyname>Taebi</keyname><forenames>Amirtaha</forenames></author><author><keyname>Solar</keyname><forenames>Brian E</forenames></author><author><keyname>Mansy</keyname><forenames>Hansen A</forenames></author></authors><title>An Adaptive Feature Extraction Algorithm for Classification of
  Seismocardiographic Signals</title><categories>eess.SP</categories><journal-ref>SoutheastCon (2018) 1-5</journal-ref><doi>10.1109/SECON.2018.8478958</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel adaptive feature extraction algorithm for
seismocardiographic (SCG) signals. The proposed algorithm divides the SCG
signal into a number of bins, where the length of each bin is determined based
on the signal change within that bin. For example, when the signal variation is
steeper, the bins are shorter and vice versa. The proposed algorithm was used
to extract features of the SCG signals recorded from 7 healthy individuals
(Age: 29.4$\pm$4.5 years) during different lung volume phases. The output of
the feature extraction algorithm was fed into a support vector machines
classifier to classify SCG events into two classes of high and low lung volume
(HLV and LLV). The classification results were compared with currently
available non-adaptive feature extraction methods for different number of bins.
Results showed that the proposed algorithm led to a classification accuracy of
~90%. The proposed algorithm outperformed the non-adaptive algorithm,
especially as the number of bins was reduced. For example, for 16 bins, F1
score for the adaptive and non-adaptive methods were 0.91$\pm$0.05 and
0.63$\pm$0.08, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10346</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10346</id><created>2018-03-27</created><updated>2018-05-07</updated><authors><author><keyname>Taebi</keyname><forenames>Amirtaha</forenames></author><author><keyname>Bomar</keyname><forenames>Andrew J</forenames></author><author><keyname>Sandler</keyname><forenames>Richard H</forenames></author><author><keyname>Mansy</keyname><forenames>Hansen A</forenames></author></authors><title>Heart Rate Monitoring During Different Lung Volume Phases Using
  Seismocardiography</title><categories>eess.SP</categories><journal-ref>SoutheastCon (2018) 1-6</journal-ref><doi>10.1109/SECON.2018.8479288</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismocardiography (SCG) is a non-invasive method that can be used for
cardiac activity monitoring. This paper presents a new electrocardiogram (ECG)
independent approach for estimating heart rate (HR) during low and high lung
volume (LLV and HLV, respectively) phases using SCG signals. In this study,
SCG, ECG, and respiratory flow rate (RFR) signals were measured simultaneously
in 7 healthy subjects. The lung volume information was calculated from the RFR
and was used to group the SCG events into low and high lung-volume groups. LLV
and HLV SCG events were then used to estimate the subjects HR as well as the HR
during LLV and HLV in 3 different postural positions, namely supine, 45 degree
heads-up, and sitting. The performance of the proposed algorithm was tested
against the standard ECG measurements. Results showed that the HR estimations
from the SCG and ECG signals were in a good agreement (bias of 0.08 bpm). All
subjects were found to have a higher HR during HLV (HR$_\text{HLV}$) compared
to LLV (HR$_\text{LLV}$) at all postural positions. The
HR$_\text{HLV}$/HR$_\text{LLV}$ ratio was 1.11$\pm$0.07, 1.08$\pm$0.05,
1.09$\pm$0.04, and 1.09$\pm$0.04 (mean$\pm$SD) for supine, 45 degree-first
trial, 45 degree-second trial, and sitting positions, respectively. This heart
rate variability may be due, at least in part, to the well-known respiratory
sinus arrhythmia. HR monitoring from SCG signals might be used in different
clinical applications including wearable cardiac monitoring systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10384</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10384</id><created>2018-03-27</created><authors><author><keyname>Gong</keyname><forenames>Yuan</forenames></author><author><keyname>Poellabauer</keyname><forenames>Christian</forenames></author></authors><title>Topic Modeling Based Multi-modal Depression Detection</title><categories>cs.CL cs.IR cs.LG cs.SD eess.AS</categories><comments>Proceedings of the 7th Audio/Visual Emotion Challenge and Workshop
  (AVEC). (Official Depression Challenge Winner)</comments><doi>10.1145/3133944.3133945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Major depressive disorder is a common mental disorder that affects almost 7%
of the adult U.S. population. The 2017 Audio/Visual Emotion Challenge (AVEC)
asks participants to build a model to predict depression levels based on the
audio, video, and text of an interview ranging between 7-33 minutes. Since
averaging features over the entire interview will lose most temporal
information, how to discover, capture, and preserve useful temporal details for
such a long interview are significant challenges. Therefore, we propose a novel
topic modeling based approach to perform context-aware analysis of the
recording. Our experiments show that the proposed approach outperforms
context-unaware methods and the challenge baselines for all metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10405</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10405</id><created>2018-03-28</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>A Sherman-Morrison-Woodbury Identity for Rank Augmenting Matrices with
  Application to Centering</title><categories>stat.ME cs.NA cs.SY eess.SY math.FA math.NA math.SP</categories><comments>Better in Mathematics, Spectral Theory, General, or Numerical
  Analysis</comments><journal-ref>SIAM Journal on Numerical Analysis Vol. 31, No. 4 (Aug., 1994),
  pp. 1219-1225</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrices of the form $\bf{A} + (\bf{V}_1 + \bf{W}_1)\bf{G}(\bf{V}_2 +
\bf{W}_2)^*$ are considered where $\bf{A}$ is a $singular$ $\ell \times \ell$
matrix and $\bf{G}$ is a nonsingular $k \times k$ matrix, $k \le \ell$. Let the
columns of $\bf{V}_1$ be in the column space of $\bf{A}$ and the columns of
$\bf{W}_1$ be orthogonal to $\bf{A}$. Similarly, let the columns of $\bf{V}_2$
be in the column space of $\bf{A}^*$ and the columns of $\bf{W}_2$ be
orthogonal to $\bf{A}^*$. An explicit expression for the inverse is given,
provided that $\bf{W}_i^* \bf{W}_i$ has rank $k$. %and $\bf{W}_1$ and
$\bf{W}_2$ have the same column space. An application to centering covariance
matrices about the mean is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10525</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10525</id><created>2018-03-28</created><authors><author><keyname>Tjandra</keyname><forenames>Andros</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>Machine Speech Chain with One-shot Speaker Adaptation</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work, we developed a closed-loop speech chain model based on deep
learning, in which the architecture enabled the automatic speech recognition
(ASR) and text-to-speech synthesis (TTS) components to mutually improve their
performance. This was accomplished by the two parts teaching each other using
both labeled and unlabeled data. This approach could significantly improve
model performance within a single-speaker speech dataset, but only a slight
increase could be gained in multi-speaker tasks. Furthermore, the model is
still unable to handle unseen speakers. In this paper, we present a new speech
chain mechanism by integrating a speaker recognition model inside the loop. We
also propose extending the capability of TTS to handle unseen speakers by
implementing one-shot speaker adaptation. This enables TTS to mimic voice
characteristics from one speaker to another with only a one-shot speaker
sample, even from a text without any speaker information. In the speech chain
loop mechanism, ASR also benefits from the ability to further learn an
arbitrary speaker's characteristics from the generated speech waveform,
resulting in a significant improvement in the recognition rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10557</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10557</id><created>2018-03-28</created><authors><author><keyname>Bekhiti</keyname><forenames>Belkacem</forenames></author><author><keyname>Dahimene</keyname><forenames>Abdelhakim</forenames></author><author><keyname>Hariche</keyname><forenames>Kamel</forenames></author><author><keyname>Fragulis</keyname><forenames>George F.</forenames></author></authors><title>On The Block Decomposition and Spectral Factors of {\lambda}-Matrices</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we factorize matrix polynomials into a complete set of spectral
factors using a new design algorithm and we provide a complete set of block
roots (solvents). The procedure is an extension of the (scalar) Horner method
for the computation of the block roots of matrix polynomials. The Block-Horner
method brings an iterative nature, faster convergence, nested programmable
scheme, needless of any prior knowledge of the matrix polynomial. In order to
avoid the initial guess method we proposed a combination of two computational
procedures . First we start giving the right Block-Q. D. (Quotient Difference)
algorithm for spectral decomposition and matrix polynomial factorization. Then
the construction of new block Horner algorithm for extracting the complete set
of spectral factors is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10609</identifier>
 <datestamp>2018-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10609</id><created>2018-03-28</created><authors><author><keyname>Barker</keyname><forenames>Jon</forenames><affiliation>CLSP</affiliation></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames><affiliation>CLSP</affiliation></author><author><keyname>Vincent</keyname><forenames>Emmanuel</forenames><affiliation>MULTISPEECH</affiliation></author><author><keyname>Trmal</keyname><forenames>Jan</forenames><affiliation>CLSP</affiliation></author></authors><title>The fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset,
  task and baselines</title><categories>cs.SD cs.AI eess.AS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The CHiME challenge series aims to advance robust automatic speech
recognition (ASR) technology by promoting research at the interface of speech
and language processing, signal processing , and machine learning. This paper
introduces the 5th CHiME Challenge, which considers the task of distant
multi-microphone conversational ASR in real home environments. Speech material
was elicited using a dinner party scenario with efforts taken to capture data
that is representative of natural conversational speech and recorded by 6
Kinect microphone arrays and 4 binaural microphone pairs. The challenge
features a single-array track and a multiple-array track and, for each track,
distinct rankings will be produced for systems focusing on robustness with
respect to distant-microphone capture vs. systems attempting to address all
aspects of the task including conversational language modeling. We discuss the
rationale for the challenge and provide a detailed description of the data
collection procedure, the task, and the baseline systems for array
synchronization, speech enhancement, and conventional and end-to-end ASR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10665</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10665</id><created>2018-03-28</created><authors><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Manzaneque</keyname><forenames>Tomas</forenames></author><author><keyname>Yang</keyname><forenames>Yansong</forenames></author><author><keyname>Gao</keyname><forenames>Liuqing</forenames></author><author><keyname>Gao</keyname><forenames>Anming</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>A Radio Frequency Non-reciprocal Network Based on Switched Acoustic
  Delay Lines</title><categories>eess.SP</categories><comments>13 pages, 23 figures</comments><journal-ref>IEEE Transactions on Microwave Theory and Techniques, vol. 67, no.
  4, pp. 1516-1530, April 2019</journal-ref><doi>10.1109/TMTT.2019.2895577</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work demonstrates the first non-reciprocal network based on switched
low-loss acoustic delay lines. The 4-port circulator is built upon a recently
reported frequency-independent, programmable, non-reciprocal framework based on
switched delay lines. The design space for such a system, including the origins
of the insertion loss and harmonic responses, is theoretically investigated,
illustrating that the key to better performance and low-cost modulation signal
synthesis lies in a large delay. To implement a large delay, we resort to
in-house fabricated low-loss, wide-band lithium niobate (LiNbO3) SH0 mode
acoustic delay lines employing single-phase unidirectional transducers (SPUDT).
The 4-port circulator, consisting of two switch modules and one delay line
module, has been modularly designed, assembled, and tested. The design process
employs time-domain full circuit simulation and the results match well with
measurements. A 18.8 dB non-reciprocal contrast between insertion loss (IL =
6.6 dB) and isolation (25.4 dB) has been achieved over a fractional bandwidth
of 8.8% at a center frequency 155 MHz, using a record low switching frequency
of 877.19 kHz. The circulator also shows 25.9 dB suppression for the
intra-modulated tone and 30 dBm for IIP3. Upon further development, such a
system can potentially lead to future wide-band, low-loss chip-scale
nonreciprocal RF systems with unprecedented programmability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10686</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10686</id><created>2018-03-24</created><updated>2018-06-30</updated><authors><author><keyname>Liu</keyname><forenames>Xintao</forenames></author><author><keyname>Chow</keyname><forenames>Joseph Y. J.</forenames></author><author><keyname>Li</keyname><forenames>Songnian</forenames></author></authors><title>Online monitoring of local taxi travel momentum and congestion effects
  using projections of taxi GPS-based vector fields</title><categories>eess.SP</categories><journal-ref>Journal of Geographical Systems, 2018</journal-ref><doi>10.1007/s10109-018-0273-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ubiquitous taxi trajectory data has made it possible to apply it to different
types of travel analysis. Of interest is the need to allow someone to monitor
travel momentum and associated congestion in any location in space in real
time. However, despite an abundant literature in taxi data visualization and
its applicability to travel analysis, no easy method exists. To measure taxi
travel momentum at a location, current methods require filtering taxi
trajectories that stop at a location at a particular time range, which is
computationally expensive. We propose an alternative, computationally cheaper
way based on pre-processing vector fields from the trajectories. Algorithms are
formalized for generating vector kernel density to estimate a travel-model-free
vector field-based representation of travel momentum in an urban space. The
algorithms are shared online as an open source GIS 3D extension called
VectorKD. Using 17 million daily taxi GPS points within Beijing over a four-day
period, we demonstrate how to generate in real time a series of projections
from a continuously updated vector field of taxi travel momentum to query a
point of interest anywhere in a city, such as the CBD or the airport. This
method allows a policy-maker to automatically identify temporal net influxes of
travel demand to a location. The proposed methodology is shown to be over
twenty times faster than a conventional selection query of trajectories. We
also demonstrate, using taxi data entering the Beijing Capital International
Airport and the CBD, how we can quantify in nearly real time the occurrence and
magnitude of inbound or outbound queueing and congestion periods due to taxis
cruising or waiting for passengers, all without having to fit any mathematical
queueing model to the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10765</identifier>
 <datestamp>2019-11-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10765</id><created>2018-03-27</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author></authors><title>Generalized Epsilon-Pseudospectra</title><categories>math.NA cs.NA cs.SY eess.SY math.SP physics.plasm-ph</categories><journal-ref>SIAM Journal on Numerical Analysis Vol. 31, No. 4 (Aug., 1994),
  pp. 1219-1225</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize $\epsilon$-pseudospectra and the associated computational
algorithms to the generalized eigenvalue problem. Rank one perturbations are
used to determine the $\epsilon$-pseudospectra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10849</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10849</id><created>2018-03-28</created><updated>2019-08-14</updated><authors><author><keyname>Gao</keyname><forenames>Mingjun</forenames></author><author><keyname>Li</keyname><forenames>Yongzhao</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>Joint Blind Identification of the Number of Transmit Antennas and MIMO
  Schemes Using Gerschgorin Radii and FNN</title><categories>eess.SP</categories><journal-ref>IEEE Trans. Wireless Commun. 18 (2019) 373-387</journal-ref><doi>10.1109/TWC.2018.2879941</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind enumeration of the number of transmit antennas and blind identification
of multiple-input multiple-output (MIMO) schemes are two pivotal steps in MIMO
signal identification for both military and commercial applications.
Conventional approaches treat them as two independent problems, namely the
source number enumeration and the presence detection of space-time redundancy,
respectively. In this paper, we develop a joint blind identification algorithm
to determine the number of transmit antennas and MIMO scheme simultaneously. By
restructuring the received signals, we derive three subspace-rank features
based on the signal subspace-rank to determine the number of transmit antennas
and identify space-time redundancy. Then, a Gerschgorin radii-based method and
a feed-forward neural network are employed to calculate these three features,
and a minimal weighted norm-1 distance metric is utilized for decision making.
In particular, our approach can identify additional MIMO schemes, which most
previous works have not considered, and is compatible with both single-carrier
and orthogonal frequency division multiplexing (OFDM) systems. Simulation
results verify the viability of our proposed approach for single-carrier and
OFDM systems and demonstrate its favorable identification performance for a
short observation period with acceptable complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10916</identifier>
 <datestamp>2018-03-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10916</id><created>2018-03-28</created><authors><author><keyname>Shan</keyname><forenames>Changhao</forenames></author><author><keyname>Zhang</keyname><forenames>Junbo</forenames></author><author><keyname>Wang</keyname><forenames>Yujun</forenames></author><author><keyname>Xie</keyname><forenames>Lei</forenames></author></authors><title>Attention-based End-to-End Models for Small-Footprint Keyword Spotting</title><categories>cs.SD cs.CL eess.AS</categories><comments>attention-based model, end-to-end keyword spotting, convolutional
  neural networks, recurrent neural networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an attention-based end-to-end neural approach for
small-footprint keyword spotting (KWS), which aims to simplify the pipelines of
building a production-quality KWS system. Our model consists of an encoder and
an attention mechanism. The encoder transforms the input signal into a high
level representation using RNNs. Then the attention mechanism weights the
encoder features and generates a fixed-length vector. Finally, by linear
transformation and softmax function, the vector becomes a score used for
keyword detection. We also evaluate the performance of different encoder
architectures, including LSTM, GRU and CRNN. Experiments on real-world wake-up
data show that our approach outperforms the recent Deep KWS approach by a large
margin and the best performance is achieved by CRNN. To be more specific, with
~84K parameters, our attention-based model achieves 1.02% false rejection rate
(FRR) at 1.0 false alarm (FA) per hour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10924</identifier>
 <datestamp>2018-03-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10924</id><created>2018-03-29</created><authors><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>Li</keyname><forenames>Jinyu</forenames></author><author><keyname>Xiao</keyname><forenames>Xiong</forenames></author><author><keyname>Yoshioka</keyname><forenames>Takuya</forenames></author><author><keyname>Wang</keyname><forenames>Huaming</forenames></author><author><keyname>Wang</keyname><forenames>Zhenghao</forenames></author><author><keyname>Gong</keyname><forenames>Yifan</forenames></author></authors><title>Cracking the cocktail party problem by multi-beam deep attractor network</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While recent progresses in neural network approaches to single-channel speech
separation, or more generally the cocktail party problem, achieved significant
improvement, their performance for complex mixtures is still not satisfactory.
In this work, we propose a novel multi-channel framework for multi-talker
separation. In the proposed model, an input multi-channel mixture signal is
firstly converted to a set of beamformed signals using fixed beam patterns. For
this beamforming, we propose to use differential beamformers as they are more
suitable for speech separation. Then each beamformed signal is fed into a
single-channel anchored deep attractor network to generate separated signals.
And the final separation is acquired by post selecting the separating output
for each beams. To evaluate the proposed system, we create a challenging
dataset comprising mixtures of 2, 3 or 4 speakers. Our results show that the
proposed system largely improves the state of the art in speech separation,
achieving 11.5 dB, 11.76 dB and 11.02 dB average signal-to-distortion ratio
improvement for 4, 3 and 2 overlapped speaker mixtures, which is comparable to
the performance of a minimum variance distortionless response beamformer that
uses oracle location, source, and noise information. We also run speech
recognition with a clean trained acoustic model on the separated speech,
achieving relative word error rate (WER) reduction of 45.76\%, 59.40\% and
62.80\% on fully overlapped speech of 4, 3 and 2 speakers, respectively. With a
far talk acoustic model, the WER is further reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10963</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10963</id><created>2018-03-29</created><updated>2019-02-24</updated><authors><author><keyname>Okabe</keyname><forenames>Koji</forenames></author><author><keyname>Koshinaka</keyname><forenames>Takafumi</forenames></author><author><keyname>Shinoda</keyname><forenames>Koichi</forenames></author></authors><title>Attentive Statistics Pooling for Deep Speaker Embedding</title><categories>eess.AS cs.SD</categories><comments>Proc. Interspeech 2018, pp2252--2256. arXiv admin note: text overlap
  with arXiv:1809.09311</comments><doi>10.21437/Interspeech.2018-993</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes attentive statistics pooling for deep speaker embedding
in text-independent speaker verification. In conventional speaker embedding,
frame-level features are averaged over all the frames of a single utterance to
form an utterance-level feature. Our method utilizes an attention mechanism to
give different weights to different frames and generates not only weighted
means but also weighted standard deviations. In this way, it can capture
long-term variations in speaker characteristics more effectively. An evaluation
on the NIST SRE 2012 and the VoxCeleb data sets shows that it reduces equal
error rates (EERs) from the conventional method by 7.5% and 8.1%, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.10993</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.10993</id><created>2018-03-29</created><updated>2018-04-03</updated><authors><author><keyname>Frid&#xe9;n</keyname><forenames>Jonas</forenames></author><author><keyname>Razavi</keyname><forenames>Aidin</forenames></author><author><keyname>Stjernman</keyname><forenames>Anders</forenames></author></authors><title>Angular sampling, Test Signal, and Near Field Aspects for Over-the-Air
  Total Radiated Power Assessment in Anechoic Chambers</title><categories>eess.SP</categories><comments>14 pages, 21 figures, 3 tables, submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5th Generation Mobile Network Systems(5G systems) operating in milli-meter
Wave (mmW) bands will employ base stations with integrated Active Antenna
Systems (AASs) capable of beam-tracking using narrow beams obtained from array
antennas encapsulated in a chip-like device. Regulatory limits for unwanted
Radio Frequency (RF) emissions are currently set in terms of Total Radiated
Power (TRP). As measurements at the antenna connectors are not possible,
Over-The-Air (OTA) methods for TRP of unwanted emissions are needed. The method
investigated here uses power density measurements on a spherical surface in an
anechoic chamber. Two major challenges with such a method are: need for large
number of angular points, and search for worst case antenna configuration per
frequency for electrically large devices at high frequencies. These challenges
are addressed by investigating the impact of correlation, sparse sampling, and
use of beam sweeping on the TRP estimate. Finally, it is investigated how and
in which spatial regions near-field tangential electric field measurements can
be used to assess TRP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11096</identifier>
 <datestamp>2018-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11096</id><created>2018-03-29</created><updated>2018-03-30</updated><authors><author><keyname>Jin</keyname><forenames>Danqi</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Richard</keyname><forenames>Cedric</forenames></author><author><keyname>Chen</keyname><forenames>Jingdong</forenames></author></authors><title>Adaptive Parameters Adjustment for Group Reweighted Zero-Attracting LMS</title><categories>eess.SP</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group zero-attracting LMS and its reweighted form have been proposed for
addressing system identification problems with structural group sparsity in the
parameters to estimate. Both algorithms however suffer from a trade-off between
sparsity degree and estimation bias and, in addition, between convergence speed
and steady-state performance like most adaptive filtering algorithms. It is
therefore necessary to properly set their step size and regularization
parameter. Based on a model of their transient behavior, we introduce a
variable-parameter variant of both algorithms to address this issue. By
minimizing their mean-square deviation at each time instant, we obtain
closed-form expressions of the optimal step size and regularization parameter.
Simulation results illustrate the effectiveness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11113</identifier>
 <datestamp>2018-03-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11113</id><created>2018-03-29</created><authors><author><keyname>Zhang</keyname><forenames>Yuhao</forenames></author><author><keyname>Cui</keyname><forenames>Qimei</forenames></author><author><keyname>Ni</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Ping</forenames></author></authors><title>Energy-Efficient Transmission of Hybrid Array with Non-Ideal Power
  Amplifiers and Circuitry</title><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach to efficiently maximizing the energy
efficiency (EE) of hybrid arrays under a practical setting of non-ideal power
amplifiers (PAs) and non-negligible circuit power, where coherent and
non-coherent beamforming are considered. As a key contribution, we reveal that
a bursty transmission mode can be energy-efficient to achieve steady
transmissions of a data stream under the practical setting. This is
distinctively different from existing studies under ideal circuits and PAs,
where continuous transmissions are the most energy-efficient. Another important
contribution is that the optimal transmit duration and powers are identified to
balance energy consumptions in the non-ideal circuits and PAs, and maximize the
EE. This is achieved by establishing the most energy-efficient structure of
transmit powers, given a transmit duration, and correspondingly partitioning
the non-convex feasible region of the transmit duration into segments with
self-contained convexity or concavity. Evident from simulations, significant EE
gains of the proposed approach are demonstrated through comparisons with the
state of the art, and the superiority of the bursty transmission mode is
confirmed especially under low data rate demands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11131</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11131</id><created>2018-03-29</created><authors><author><keyname>Singh</keyname><forenames>Pushpendra</forenames></author></authors><title>Novel Fourier Quadrature Transforms and Analytic Signal Representations
  for Nonlinear and Non-stationary Time Series Analysis</title><categories>eess.SP cs.NA</categories><comments>22 pages, 13 figures</comments><journal-ref>Royal Society Open Science, November 28, 2018</journal-ref><doi>10.1098/rsos.181131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hilbert transform (HT) and associated Gabor analytic signal (GAS)
representation are well-known and widely used mathematical formulations for
modeling and analysis of signals in various applications. In this study, like
the HT, to obtain quadrature component of a signal, we propose the novel
discrete Fourier cosine quadrature transforms (FCQTs) and discrete Fourier sine
quadrature transforms (FSQTs), designated as Fourier quadrature transforms
(FQTs). Using these FQTs, we propose sixteen Fourier-Singh analytic signal
(FSAS) representations with following properties: (1) real part of eight FSAS
representations is the original signal and imaginary part is the FCQT of the
real part, (2) imaginary part of eight FSAS representations is the original
signal and real part is the FSQT of the real part, (3) like the GAS, Fourier
spectrum of the all FSAS representations has only positive frequencies, however
unlike the GAS, the real and imaginary parts of the proposed FSAS
representations are not orthogonal to each other. The Fourier decomposition
method (FDM) is an adaptive data analysis approach to decompose a signal into a
set of small number of Fourier intrinsic band functions which are AM-FM
components. This study also proposes a new formulation of the FDM using the
discrete cosine transform (DCT) with the GAS and FSAS representations, and
demonstrate its efficacy for improved time-frequency-energy representation and
analysis of nonlinear and non-stationary time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11154</identifier>
 <datestamp>2018-03-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11154</id><created>2018-03-29</created><authors><author><keyname>Ronan</keyname><forenames>David</forenames></author><author><keyname>Reiss</keyname><forenames>Joshua D.</forenames></author><author><keyname>Gunes</keyname><forenames>Hatice</forenames></author></authors><title>An empirical approach to the relationship between emotion and music
  production quality</title><categories>eess.IV cs.SD eess.AS</categories><comments>12 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In music production, the role of the mix engineer is to take recorded music
and convey the expressed emotions as professionally sounding as possible. We
investigated the relationship between music production quality and musically
induced and perceived emotions. A listening test was performed where 10
critical listeners and 10 non-critical listeners evaluated 10 songs. There were
two mixes of each song, the low quality mix and the high quality mix. Each
participant's subjective experience was measured directly through questionnaire
and indirectly by examining peripheral physiological changes, change in facial
expressions and the number of head nods and shakes they made as they listened
to each mix. We showed that music production quality had more of an emotional
impact on critical listeners. Also, critical listeners had significantly
different emotional responses to non-critical listeners for the high quality
mixes and to a lesser extent the low quality mixes. The findings suggest that
having a high level of skill in mix engineering only seems to matter in an
emotional context to a subset of music listeners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11344</identifier>
 <datestamp>2018-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11344</id><created>2018-03-30</created><authors><author><keyname>Warnita</keyname><forenames>Tifani</forenames></author><author><keyname>Inoue</keyname><forenames>Nakamasa</forenames></author><author><keyname>Shinoda</keyname><forenames>Koichi</forenames></author></authors><title>Detecting Alzheimer's Disease Using Gated Convolutional Neural Network
  from Audio Data</title><categories>eess.AS cs.SD</categories><comments>5 pages, 3 figures, submitted to INTERSPEECH 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an automatic detection method of Alzheimer's diseases using a
gated convolutional neural network (GCNN) from speech data. This GCNN can be
trained with a relatively small amount of data and can capture the temporal
information in audio paralinguistic features. Since it does not utilize any
linguistic features, it can be easily applied to any languages. We evaluated
our method using Pitt Corpus. The proposed method achieved the accuracy of
73.6%, which is better than the conventional sequential minimal optimization
(SMO) by 7.6 points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11454</identifier>
 <datestamp>2018-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11454</id><created>2018-03-29</created><authors><author><keyname>Dwivedi</keyname><forenames>P.</forenames></author><author><keyname>Konijnenberg</keyname><forenames>A. P.</forenames></author><author><keyname>Pereira</keyname><forenames>S. F.</forenames></author><author><keyname>Urbach</keyname><forenames>H. P.</forenames></author></authors><title>Lateral position correction in ptychography with sub-pixel accuracy</title><categories>eess.IV physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ptychography, a form of Coherent Diffractive Imaging, is used with short
wavelengths (e.g. X-rays, electron beams) to achieve high-resolution image
reconstructions. One of the limiting factors for the reconstruction quality is
the accurate knowledge of the illumination probe positions. Recently, many
advances have been made to relax the requirement for the probe positions
accuracy. Here, we analyze and demonstrate a straightforward approach that can
be used to correct the probe positions with sub-pixel accuracy. Simulations and
experimental results with visible light are presented in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1803.11466</identifier>
 <datestamp>2018-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1803.11466</id><created>2018-03-28</created><authors><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author></authors><title>Generating Functional Analysis of Iterative Sparse Signal Recovery
  Algorithms with Divergence-Free Estimators</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, no figure. arXiv admin note: text overlap with
  arXiv:1106.0086</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate message passing (AMP) is an effective iterative sparse recovery
algorithm for linear system models. Its performance is characterized by the
state evolution (SE) which is a simple scalar recursion. However, depending on
a measurement matrix ensemble, AMP may face a convergence problem. To avoid
this problem, orthogonal AMP (OAMP), which uses de-correlation linear
estimation and divergence-free non-linear estimation, was proposed by Ma and
Ping. They also provide the SE analysis for OAMP. In their SE analysis, the
following two assumptions were made: (i) The estimated vector of the
de-correlation linear estimator consists of i.i.d. zero-mean Gaussian entries
independent of the vector to be estimated and (ii) the estimated vector of the
divergence-free non-linear estimator consists of i.i.d. entries independent of
the measurement matrix and the noise vector. In this paper, we derive a simple
scalar recursion to characterize iterative sparse recovery algorithms with
divergence-free estimators without such assumptions of independence of messages
by using the generating functional analysis (GFA), which allows us to study the
dynamics by an exact way in the large system limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00003</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00003</id><created>2018-03-30</created><authors><author><keyname>Riedel</keyname><forenames>Kurt S.</forenames></author><author><keyname>Sidorenko</keyname><forenames>Alexander</forenames></author><author><keyname>Thomson</keyname><forenames>David J.</forenames></author></authors><title>Spectral Estimation of Plasma Fluctuations I: Comparison of Methods</title><categories>stat.AP eess.AS eess.SP math.ST stat.TH</categories><comments>Missing Figures</comments><journal-ref>Physics of Plasmas, Volume 1, Issue 3, March 1994, pp.485-500</journal-ref><doi>10.1063/1.870794</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relative root mean squared errors (RMSE) of nonparametric methods for
spectral estimation is compared for microwave scattering data of plasma
fluctuations. These methods reduce the variance of the periodogram estimate by
averaging the spectrum over a frequency bandwidth. As the bandwidth increases,
the variance decreases, but the bias error increases. The plasma spectra vary
by over four orders of magnitude, and therefore, using a spectral window is
necessary. We compare the smoothed tapered periodogram with the adaptive
multiple taper methods and hybrid methods. We find that a hybrid method, which
uses four orthogonal tapers and then applies a kernel smoother, performs best.
For 300 point data segments, even an optimized smoothed tapered periodogram has
a 24 \% larger relative RMSE than the hybrid method. We present two new
adaptive multi-taper weightings which outperform Thomson's original adaptive
weighting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00016</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00016</id><created>2018-03-30</created><updated>2019-08-19</updated><authors><author><keyname>Mandija</keyname><forenames>Stefano</forenames></author><author><keyname>Meliad&#xf2;</keyname><forenames>Ettore F.</forenames></author><author><keyname>Huttinga</keyname><forenames>Niek R. F.</forenames></author><author><keyname>Luijten</keyname><forenames>Peter R.</forenames></author><author><keyname>Berg</keyname><forenames>Cornelis A. T. van den</forenames></author></authors><title>Opening a new window on MR-based Electrical Properties Tomography with
  deep learning</title><categories>physics.med-ph eess.IV</categories><journal-ref>Published online in: Scientific Reports (Jun-2019) 9: 8895</journal-ref><doi>10.1038/s41598-019-45382-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrical properties (EPs) of tissues, conductivity and permittivity, are
modulated by the ionic and water content, which change in presence of
pathologies. Information on tissues EPs can be used e.g. as an endogenous
biomarker in oncology. MR-Electrical Properties Tomography (MR-EPT) aims to
reconstruct tissue EPs by solving an electromagnetic inverse problem relating
MR measurements of the transmit radiofrequency RF field to the EPs. However,
MR-EPT reconstructions highly suffer from noise in the RF field maps, which
limits the clinical applicability. Instead of employing electromagnetic models
posing strict requirements on the measured quantities, we propose a data driven
approach where the inverse transformation is learned by means of a neural
network. Supervised training of a conditional generative adversarial neural
network was performed using simulated realistic RF field maps and realistic
human head dielectric models. Deep learning EPT (DL-EPT) reconstructions are
presented for in-silica MR data and MR measurements at 3 Tesla on phantoms and
human brains. DL-EPT shows high quality EP maps, demonstrating good accuracy
and greatly improved precision compared to conventional MR-EPT. Moreover,
DL-EPT allows permittivity reconstructions at 3 Tesla, which is not possible
with state-of-art MR-EPT techniques. The supervised learning-based approach
leverages the strength of tailored electromagnetic simulations, allowing
inclusion of a priori information (e.g. coil setup) and circumvention of
inaccessible MR electromagnetic quantities. Since DL-EPT is highly
noise-robust, the requirements for MRI data acquisitions can be relaxed,
allowing faster acquisitions and higher resolutions. We believe that DL-EPT
greatly improves the quality and applicability of EPT opening a new window for
an endogenous biomarker in MRI diagnostics that reflects differences in ionic
tissue content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00037</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00037</id><created>2018-03-30</created><updated>2019-09-17</updated><authors><author><keyname>Partovi</keyname><forenames>Alireza</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Reactive Supervisory Control of Open Discrete-event Systems</title><categories>eess.SP cs.FL cs.LO</categories><comments>IEEE CDC technical report</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The conventional Wonham-Ramadge supervisory control framework of discrete
event systems enforces a closed discrete event system to generate correct
behaviors under certain environments, which can be captured by an appropriate
plant model. Nevertheless, such control methods cannot be directly applied for
many practical engineering systems nowadays since they are open systems and
their operation heavily depends on nontrivial interactions between the systems
and the external environments. These open systems should be controlled in such
a way that accomplishment of the control objective can be guaranteed for any
possible environment, which may be dynamic, uncertain and sometimes
unpredictable. In this paper, we aim at extending the conventional supervisory
control theory to open discrete event systems in a reactive manner. Starting
from a novel input-output automaton model of an open system, we consider
control objectives that characterize the desired input-output behaviors of the
system, based on which a game-theoretic approach is carried out to compute a
reactive supervisor that steers the system to fulfill the specifications
regardless of the environment behaviors. We present a necessary and sufficient
conditions for the existence of such a reactive supervisor. Furthermore,
illustrative examples are given throughout this paper to demonstrate the key
definitions and the effectiveness of the proposed reactive supervisor synthesis
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00047</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00047</id><created>2018-03-30</created><updated>2018-06-07</updated><authors><author><keyname>Haque</keyname><forenames>Albert</forenames></author><author><keyname>Guo</keyname><forenames>Michelle</forenames></author><author><keyname>Verma</keyname><forenames>Prateek</forenames></author></authors><title>Conditional End-to-End Audio Transforms</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an end-to-end method for transforming audio from one style to
another. For the case of speech, by conditioning on speaker identities, we can
train a single model to transform words spoken by multiple people into multiple
target voices. For the case of music, we can specify musical instruments and
achieve the same result. Architecturally, our method is a fully-differentiable
sequence-to-sequence model based on convolutional and hierarchical recurrent
neural networks. It is designed to capture long-term acoustic dependencies,
requires minimal post-processing, and produces realistic audio transforms.
Ablation studies confirm that our model can separate speaker and instrument
properties from acoustic content at different receptive fields. Empirically,
our method achieves competitive performance on community-standard datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00099</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00099</id><created>2018-03-30</created><updated>2018-11-18</updated><authors><author><keyname>Zou</keyname><forenames>Dongmian</forenames></author><author><keyname>Lerman</keyname><forenames>Gilad</forenames></author></authors><title>Graph Convolutional Neural Networks via Scattering</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>26 pages, 9 figures, 4 tables</comments><journal-ref>Applied and Computational Harmonic Analysis, 2019 (online)</journal-ref><doi>10.1016/j.acha.2019.06.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the scattering transform to graphs and consequently construct a
convolutional neural network on graphs. We show that under certain conditions,
any feature generated by such a network is approximately invariant to
permutations and stable to graph manipulations. Numerical results demonstrate
competitive performance on relevant datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00155</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00155</id><created>2018-03-31</created><authors><author><keyname>Shahin</keyname><forenames>Ismail</forenames></author></authors><title>Speaker Verification in Emotional Talking Environments based on
  Three-Stage Framework</title><categories>cs.SD eess.AS</categories><comments>5 pages, 1 figure, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is dedicated to introducing, executing, and assessing a three-stage
speaker verification framework to enhance the degraded speaker verification
performance in emotional talking environments. Our framework is comprised of
three cascaded stages: gender identification stage followed by an emotion
identification stage followed by a speaker verification stage. The proposed
framework has been assessed on two distinct and independent emotional speech
datasets: our collected dataset and Emotional Prosody Speech and Transcripts
dataset. Our results demonstrate that speaker verification based on both gender
cues and emotion cues is superior to each of speaker verification based on
gender cues only, emotion cues only, and neither gender cues nor emotion cues.
The achieved average speaker verification performance based on the suggested
methodology is very similar to that attained in subjective assessment by human
listeners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00180</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00180</id><created>2018-03-31</created><authors><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Yang</keyname><forenames>Chao</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Xu</keyname><forenames>Wei</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames><affiliation>Shanghai Institute for Advanced Communications and Data Science, Shanghai University, Shanghai, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author></authors><title>Efficient Sparse Code Multiple Access Decoder Based on Deterministic
  Message Passing Algorithm</title><categories>cs.IT cs.AR eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being an effective non-orthogonal multiple access (NOMA) technique, sparse
code multiple access (SCMA) is promising for future wireless communication.
Compared with orthogonal techniques, SCMA enjoys higher overloading tolerance
and lower complexity because of its sparsity. In this paper, based on
deterministic message passing algorithm (DMPA), algorithmic simplifications
such as domain changing and probability approximation are applied for SCMA
decoding. Early termination, adaptive decoding, and initial noise reduction are
also employed for faster convergence and better performance. Numerical results
show that the proposed optimizations benefit both decoding complexity and
speed. Furthermore, efficient hardware architectures based on folding and
retiming are proposed. VLSI implementation is also given in this paper.
Comparison with the state-of-the-art have shown the proposed decoder's
advantages in both latency and throughput (multi-Gbps).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00209</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00209</id><created>2018-03-31</created><updated>2019-07-10</updated><authors><author><keyname>Kasgari</keyname><forenames>Ali Taleb Zadeh</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Human-in-the-Loop Wireless Communications: Machine Learning and
  Brain-Aware Resource Management</title><categories>cs.IT eess.SP math.IT</categories><comments>33 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human-centric applications such as virtual reality and immersive gaming will
be central to the future wireless networks. Common features of such services
include: a) their dependence on the human user's behavior and state, and b)
their need for more network resources compared to conventional cellular
applications. To successfully deploy such applications over wireless and
cellular systems, the network must be made cognizant of not only the
quality-of-service (QoS) needs of the applications, but also of the perceptions
of the human users on this QoS. In this paper, by explicitly modeling the
limitations of the human brain, a concrete measure for the delay perception of
human users in a wireless network is introduced. Then, a novel learning method,
called probability distribution identification, is proposed to find a
probabilistic model for this delay perception based on the brain features of a
human user. The proposed learning method uses both supervised and unsupervised
learning techniques to build a Gaussian mixture model of the human brain
features. Given a model for the delay perception of the human brain, a novel
brain-aware resource management algorithm based on Lyapunov optimization is
proposed for allocating radio resources to human users while minimizing the
transmit power and taking into account the reliability of both machine type
devices and human users. The proposed algorithm is shown to have a low
complexity. Moreover, a closed-form relationship between the reliability
measure and wireless physical layer metrics of the network is derived.
Simulation results using real data from actual human users show that a
brain-aware approach can yield savings of up to 78% in power compared to the
system
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00290</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00290</id><created>2018-04-01</created><authors><author><keyname>Zhang</keyname><forenames>Jiacen</forenames></author><author><keyname>Inoue</keyname><forenames>Nakamasa</forenames></author><author><keyname>Shinoda</keyname><forenames>Koichi</forenames></author></authors><title>I-vector Transformation Using Conditional Generative Adversarial
  Networks for Short Utterance Speaker Verification</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I-vector based text-independent speaker verification (SV) systems often have
poor performance with short utterances, as the biased phonetic distribution in
a short utterance makes the extracted i-vector unreliable. This paper proposes
an i-vector compensation method using a generative adversarial network (GAN),
where its generator network is trained to generate a compensated i-vector from
a short-utterance i-vector and its discriminator network is trained to
determine whether an i-vector is generated by the generator or the one
extracted from a long utterance. Additionally, we assign two other learning
tasks to the GAN to stabilize its training and to make the generated ivector
more speaker-specific. Speaker verification experiments on the NIST SRE 2008
&quot;10sec-10sec&quot; condition show that our method reduced the equal error rate by
11.3% from the conventional i-vector and PLDA system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00311</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00311</id><created>2018-04-01</created><authors><author><keyname>Khalaf</keyname><forenames>Poya</forenames></author><author><keyname>Richter</keyname><forenames>Hanz</forenames></author></authors><title>Trajectory Optimization of Robots with Regenerative Drive Systems:
  Numerical and Experimental Results</title><categories>cs.SY cs.RO eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate energy-optimal control of robots with ultracapacitor based
regenerative drive systems. Based on a previously introduced framework, a
fairly generic model is considered for the robot and the drive system. An
optimal control problem is formulated to find point-to point trajectories
maximizing the amount of energy regenerated and stored in the capacitor. The
optimization problem, its numerical solution and an experimental evaluation are
demonstrated using a PUMA 560 manipulator. A comprehensive experimental setup
was prepared to evaluate power flows and energy regeneration. Tracking of
optimal trajectories was enforced on the robot using a standard robust
passivity based control approach. Experimental results show that when following
optimal trajectories, a reduction of about 13\% in energy consumption can be
achieved for the conditions of the study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00356</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00356</id><created>2018-04-01</created><authors><author><keyname>Rosas</keyname><forenames>Fernando</forenames></author><author><keyname>Chen</keyname><forenames>Kwang-Cheng</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author></authors><title>Social learning for resilient data fusion against data falsification
  attacks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things (IoT) suffers from vulnerable sensor nodes, which are
likely to endure data falsification attacks following physical or cyber
capture. Moreover, centralized decision-making and data fusion schemes commonly
used by these networks turn these decision points into single points of
failure, which are likely to be exploited by smart attackers. In order to face
this serious security thread, we propose a novel scheme that enables
distributed data aggregation and decision-making by following social learning
principles. Our proposed scheme makes sensor nodes to act resembling the
manners of agents within a social network. We analytically examine how local
actions of individual agents can propagate through the whole network, affecting
the collective behaviour. Finally, we show how social learning can enable
network resilience against data falsification attacks, even when a significant
portion of the nodes have been compromised by the adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00381</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00381</id><created>2018-04-01</created><authors><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Cai</keyname><forenames>Zexin</forenames></author><author><keyname>Liu</keyname><forenames>Wenbo</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoqi</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>Insights into End-to-End Learning Scheme for Language Identification</title><categories>eess.AS cs.LG cs.SD</categories><comments>ICASSP 2018 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel interpretable end-to-end learning scheme for language identification
is proposed. It is in line with the classical GMM i-vector methods both
theoretically and practically. In the end-to-end pipeline, a general encoding
layer is employed on top of the front-end CNN, so that it can encode the
variable-length input sequence into an utterance level vector automatically.
After comparing with the state-of-the-art GMM i-vector methods, we give
insights into CNN, and reveal its role and effect in the whole pipeline. We
further introduce a general encoding layer, illustrating the reason why they
might be appropriate for language identification. We elaborate on several
typical encoding layers, including a temporal average pooling layer, a
recurrent encoding layer and a novel learnable dictionary encoding layer. We
conducted experiment on NIST LRE07 closed-set task, and the results show that
our proposed end-to-end systems achieve state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00385</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00385</id><created>2018-04-01</created><authors><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Cai</keyname><forenames>Zexin</forenames></author><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoqi</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>A Novel Learnable Dictionary Encoding Layer for End-to-End Language
  Identification</title><categories>eess.AS cs.LG cs.SD</categories><comments>ICASSP 2018 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel learnable dictionary encoding layer is proposed in this paper for
end-to-end language identification. It is inline with the conventional GMM
i-vector approach both theoretically and practically. We imitate the mechanism
of traditional GMM training and Supervector encoding procedure on the top of
CNN. The proposed layer can accumulate high-order statistics from
variable-length input sequence and generate an utterance level
fixed-dimensional vector representation. Unlike the conventional methods, our
new approach provides an end-to-end learning framework, where the inherent
dictionary are learned directly from the loss function. The dictionaries and
the encoding representation for the classifier are learned jointly. The
representation is orderless and therefore appropriate for language
identification. We conducted a preliminary experiment on NIST LRE07 closed-set
task, and the results reveal that our proposed dictionary encoding layer
achieves significant error reduction comparing with the simple average pooling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00425</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00425</id><created>2018-04-02</created><authors><author><keyname>Fang</keyname><forenames>Fuming</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Echizen</keyname><forenames>Isao</forenames></author><author><keyname>Lorenzo-Trueba</keyname><forenames>Jaime</forenames></author></authors><title>High-quality nonparallel voice conversion based on cycle-consistent
  adversarial network</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>accepted at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although voice conversion (VC) algorithms have achieved remarkable success
along with the development of machine learning, superior performance is still
difficult to achieve when using nonparallel data. In this paper, we propose
using a cycle-consistent adversarial network (CycleGAN) for nonparallel
data-based VC training. A CycleGAN is a generative adversarial network (GAN)
originally developed for unpaired image-to-image translation. A subjective
evaluation of inter-gender conversion demonstrated that the proposed method
significantly outperformed a method based on the Merlin open source neural
network speech synthesis system (a parallel VC system adapted for our setup)
and a GAN-based parallel VC system. This is the first research to show that the
performance of a nonparallel VC method can exceed that of state-of-the-art
parallel VC methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00462</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00462</id><created>2018-04-02</created><authors><author><keyname>Kaloorazi</keyname><forenames>Maboud F.</forenames></author><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Subspace-Orbit Randomized Decomposition for Low-rank Matrix
  Approximation</title><categories>cs.NA eess.SP</categories><doi>10.1109/TSP.2018.2853137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient, accurate and reliable approximation of a matrix by one of lower
rank is a fundamental task in numerical linear algebra and signal processing
applications. In this paper, we introduce a new matrix decomposition approach
termed Subspace-Orbit Randomized singular value decomposition (SOR-SVD), which
makes use of random sampling techniques to give an approximation to a low-rank
matrix. Given a large and dense data matrix of size $m\times n$ with numerical
rank $k$, where $k \ll \text{min} \{m,n\}$, the algorithm requires a few passes
through data, and can be computed in $O(mnk)$ floating-point operations.
Moreover, the SOR-SVD algorithm can utilize advanced computer architectures,
and, as a result, it can be optimized for maximum efficiency. The SOR-SVD
algorithm is simple, accurate, and provably correct, and outperforms previously
reported techniques in terms of accuracy and efficiency. Our numerical
experiments support these claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00481</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00481</id><created>2018-04-02</created><updated>2018-08-31</updated><authors><author><keyname>Schoeffauer</keyname><forenames>Richard</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Predictive Network Control and Throughput Sub-Optimality of MaxWeight</title><categories>eess.SP math.OC</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel control policy, called Predictive Network Control (PNC) to
control wireless communication networks (on packet level), based on paradigms
of Model Predictive Control (MPC). In contrast to common myopic policies, who
use one step ahead prediction, PNC predicts the future behavior of the system
for an extended horizon, thus facilitating performance gains. We define an
advanced system model in which we use a Markov chain in combination with a
Bernoulli trial to model the stochastic components of the network. Furthermore
we introduce the algorithm and present two detailed simulation examples, which
show general improved performance and a gain in stability region compared to
the standard policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00558</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00558</id><created>2018-03-30</created><authors><author><keyname>Sarrafi</keyname><forenames>Aral</forenames></author><author><keyname>Mao</keyname><forenames>Zhu</forenames></author><author><keyname>Niezrecki</keyname><forenames>Christopher</forenames></author><author><keyname>Poozesh</keyname><forenames>Peyman</forenames></author></authors><title>Vibration-Based Damage Detection in Wind Turbine Blades using
  Phase-Based Motion Estimation and Motion Magnification</title><categories>eess.IV cs.CV</categories><report-no>10.1016/j.jsv.2018.01.050</report-no><journal-ref>Journal of Sound and Vibration, 421 (2018) 300-318</journal-ref><doi>10.1016/j.jsv.2018.01.050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vibration-based Structural Health Monitoring (SHM) techniques are among the
most common approaches for structural damage identification. The presence of
damage in structures may be identified by monitoring the changes in dynamic
behavior subject to external loading, and is typically performed by using
experimental modal analysis (EMA) or operational modal analysis (OMA). These
tools for SHM normally require a limited number of physically attached
transducers (e.g. accelerometers) in order to record the response of the
structure for further analysis. Signal conditioners, wires, wireless receivers
and a data acquisition system (DAQ) are also typical components of traditional
sensing systems used in vibration-based SHM. However, instrumentation of
lightweight structures with contact sensors such as accelerometers may induce
mass-loading effects, and for large-scale structures, the instrumentation is
labor intensive and time consuming. Achieving high spatial measurement
resolution for a large-scale structure is not always feasible while working
with traditional contact sensors, and there is also the potential for a lack of
reliability associated with fixed contact sensors in outliving the life-span of
the host structure. Among the state-of-the-art non-contact measurements,
digital video cameras are able to rapidly collect high-density spatial
information from structures remotely. In this paper, the subtle motions from
recorded video (i.e. a sequence of images) are extracted by means of
Phase-based Motion Estimation (PME) and the extracted information is used to
conduct damage identification on a 2.3-meter long Skystream wind turbine blade
(WTB). The PME and phased-based motion magnification approach estimates the
structural motion from the captured sequence of images for both a baseline and
damaged test cases on a wind turbine blade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00609</identifier>
 <datestamp>2019-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00609</id><created>2018-04-02</created><updated>2019-03-30</updated><authors><author><keyname>Bayisa</keyname><forenames>Fekadu L.</forenames></author><author><keyname>Zhou</keyname><forenames>Zhiyong</forenames></author><author><keyname>Cronie</keyname><forenames>Ottmar</forenames></author><author><keyname>Yu</keyname><forenames>Jun</forenames></author></authors><title>Adaptive Algorithm for Sparse Signal Recovery</title><categories>stat.ME eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spike and slab priors play a key role in inducing sparsity for sparse signal
recovery. The use of such priors results in hard non-convex and mixed integer
programming problems. Most of the existing algorithms to solve the optimization
problems involve either simplifying assumptions, relaxations or high
computational expenses. We propose a new adaptive alternating direction method
of multipliers (AADMM) algorithm to directly solve the presented optimization
problem. The algorithm is based on the one-to-one mapping property of the
support and non-zero element of the signal. At each step of the algorithm, we
update the support by either adding an index to it or removing an index from it
and use the alternating direction method of multipliers to recover the signal
corresponding to the updated support. Experiments on synthetic data and
real-world images show that the proposed AADMM algorithm provides superior
performance and is computationally cheaper, compared to the recently developed
iterative convex refinement (ICR) algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00623</identifier>
 <datestamp>2019-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00623</id><created>2018-03-05</created><updated>2019-03-14</updated><authors><author><keyname>Andri</keyname><forenames>Renzo</forenames></author><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Rossi</keyname><forenames>Davide</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>Hyperdrive: A Multi-Chip Systolically Scalable Binary-Weight CNN
  Inference Engine</title><categories>cs.DC cs.AR cs.CV eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have achieved impressive results in computer vision and
machine learning. Unfortunately, state-of-the-art networks are extremely
compute and memory intensive which makes them unsuitable for mW-devices such as
IoT end-nodes. Aggressive quantization of these networks dramatically reduces
the computation and memory footprint. Binary-weight neural networks (BWNs)
follow this trend, pushing weight quantization to the limit. Hardware
accelerators for BWNs presented up to now have focused on core efficiency,
disregarding I/O bandwidth and system-level efficiency that are crucial for
deployment of accelerators in ultra-low power devices. We present Hyperdrive: a
BWN accelerator dramatically reducing the I/O bandwidth exploiting a novel
binary-weight streaming approach, which can be used for arbitrarily sized
convolutional neural network architecture and input resolution by exploiting
the natural scalability of the compute units both at chip-level and
system-level by arranging Hyperdrive chips systolically in a 2D mesh while
processing the entire feature map together in parallel. Hyperdrive achieves 4.3
TOp/s/W system-level efficiency (i.e., including I/Os)---3.1x higher than
state-of-the-art BWN accelerators, even if its core uses resource-intensive
FP16 arithmetic for increased robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00644</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00644</id><created>2018-04-02</created><updated>2019-04-30</updated><authors><author><keyname>Meng</keyname><forenames>Zhong</forenames><affiliation>Fred</affiliation></author><author><keyname>Li</keyname><forenames>Jinyu</forenames><affiliation>Fred</affiliation></author><author><keyname>Gong</keyname><forenames>Yifan</forenames><affiliation>Fred</affiliation></author><author><keyname>Biing-Hwang</keyname><affiliation>Fred</affiliation></author><author><keyname>Juang</keyname></author></authors><title>Adversarial Teacher-Student Learning for Unsupervised Domain Adaptation</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>5 pages, 1 figure, ICASSP 2018</comments><journal-ref>2018 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), Calgary, Canada</journal-ref><doi>10.1109/ICASSP.2018.8461682</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The teacher-student (T/S) learning has been shown effective in unsupervised
domain adaptation [1]. It is a form of transfer learning, not in terms of the
transfer of recognition decisions, but the knowledge of posteriori
probabilities in the source domain as evaluated by the teacher model. It learns
to handle the speaker and environment variability inherent in and restricted to
the speech signal in the target domain without proactively addressing the
robustness to other likely conditions. Performance degradation may thus ensue.
In this work, we advance T/S learning by proposing adversarial T/S learning to
explicitly achieve condition-robust unsupervised domain adaptation. In this
method, a student acoustic model and a condition classifier are jointly
optimized to minimize the Kullback-Leibler divergence between the output
distributions of the teacher and student models, and simultaneously, to
min-maximize the condition classification loss. A condition-invariant deep
feature is learned in the adapted student model through this procedure. We
further propose multi-factorial adversarial T/S learning which suppresses
condition variabilities caused by multiple factors simultaneously. Evaluated
with the noisy CHiME-3 test set, the proposed methods achieve relative word
error rate improvements of 44.60% and 5.38%, respectively, over a clean source
model and a strong T/S learning baseline model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00732</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00732</id><created>2018-04-02</created><updated>2019-04-30</updated><authors><author><keyname>Meng</keyname><forenames>Zhong</forenames><affiliation>Fred</affiliation></author><author><keyname>Li</keyname><forenames>Jinyu</forenames><affiliation>Fred</affiliation></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames><affiliation>Fred</affiliation></author><author><keyname>Zhao</keyname><forenames>Yong</forenames><affiliation>Fred</affiliation></author><author><keyname>Mazalov</keyname><forenames>Vadim</forenames><affiliation>Fred</affiliation></author><author><keyname>Gong</keyname><forenames>Yifan</forenames><affiliation>Fred</affiliation></author><author><keyname>Biing-Hwang</keyname><affiliation>Fred</affiliation></author><author><keyname>Juang</keyname></author></authors><title>Speaker-Invariant Training via Adversarial Learning</title><categories>eess.AS cs.AI cs.CL cs.SD</categories><comments>5 pages, 3 figures, ICASSP 2018</comments><journal-ref>2018 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), Calgary, Canada</journal-ref><doi>10.1109/ICASSP.2018.8461932</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel adversarial multi-task learning scheme, aiming at actively
curtailing the inter-talker feature variability while maximizing its senone
discriminability so as to enhance the performance of a deep neural network
(DNN) based ASR system. We call the scheme speaker-invariant training (SIT). In
SIT, a DNN acoustic model and a speaker classifier network are jointly
optimized to minimize the senone (tied triphone state) classification loss, and
simultaneously mini-maximize the speaker classification loss. A
speaker-invariant and senone-discriminative deep feature is learned through
this adversarial multi-task learning. With SIT, a canonical DNN acoustic model
with significantly reduced variance in its output probabilities is learned with
no explicit speaker-independent (SI) transformations or speaker-specific
representations used in training or testing. Evaluated on the CHiME-3 dataset,
the SIT achieves 4.99% relative word error rate (WER) improvement over the
conventional SI acoustic model. With additional unsupervised speaker
adaptation, the speaker-adapted (SA) SIT model achieves 4.86% relative WER gain
over the SA SI acoustic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00736</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00736</id><created>2018-04-02</created><authors><author><keyname>Valada</keyname><forenames>Abhinav</forenames></author><author><keyname>Burgard</keyname><forenames>Wolfram</forenames></author></authors><title>Deep Spatiotemporal Models for Robust Proprioceptive Terrain
  Classification</title><categories>cs.RO cs.LG cs.SD eess.AS</categories><journal-ref>The International Journal of Robotics Research 36, no. 13-14
  (2017): 1521-1539</journal-ref><doi>10.1177/0278364917727062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Terrain classification is a critical component of any autonomous mobile robot
system operating in unknown real-world environments. Over the years, several
proprioceptive terrain classification techniques have been introduced to
increase robustness or act as a fallback for traditional vision based
approaches. However, they lack widespread adaptation due to various factors
that include inadequate accuracy, robustness and slow run-times. In this paper,
we use vehicle-terrain interaction sounds as a proprioceptive modality and
propose a deep Long-Short Term Memory (LSTM) based recurrent model that
captures both the spatial and temporal dynamics of such a problem, thereby
overcoming these past limitations. Our model consists of a new Convolution
Neural Network (CNN) architecture that learns deep spatial features,
complemented with LSTM units that learn complex temporal dynamics. Experiments
on two extensive datasets collected with different microphones on various
indoor and outdoor terrains demonstrate state-of-the-art performance compared
to existing techniques. We additionally evaluate the performance in adverse
acoustic conditions with high ambient noise and propose a noise-aware training
scheme that enables learning of more generalizable models that are essential
for robust real-world deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00847</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00847</id><created>2018-04-03</created><authors><author><keyname>Karttunen</keyname><forenames>Aki</forenames></author><author><keyname>J&#xe4;rvel&#xe4;inen</keyname><forenames>Jan</forenames></author><author><keyname>Nguyen</keyname><forenames>Sinh Le Hong</forenames></author><author><keyname>Haneda</keyname><forenames>Katsuyuki</forenames></author></authors><title>Modeling the Multipath Cross-Polarization Ratio for Above-6 GHz Radio
  Links</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we parameterize an excess loss-based multipath component (MPC)
cross-polarization ratio (XPR) model in indoor and outdoor environments for
above-6 GHz frequency bands. The results are based on 28 measurement campaigns
in several frequency bands ranging from 15 to 80 GHz. A conventional XPR model
of an MPC assuming a constant mean value fits our measurements very poorly and
moreover overestimates the depolarization effect. Our measurements revealed a
clear trend that the MPC XPR is inversely proportional to an excess loss in
reference to the free-space path loss. The model is physically sound as a
higher excess loss is attributed to more lossy interactions or to a greater
number of interactions with objects, leading to a greater chance of
depolarization. The measurements furthermore showed that the MPC XPR is not
strongly frequency or environment dependent. In our MPC XPR model, an MPC with
zero-dB excess loss has a mean XPR of 28 dB. The mean XPR decreases half-a-dB
as the excess loss increases by every dB and the standard deviation around the
mean is 6 dB. The model is applicable to existing channel models to reproduce
realistic MPC XPRs for the above 6-GHz radio links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00920</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00920</id><created>2018-04-03</created><authors><author><keyname>Juvela</keyname><forenames>Lauri</forenames></author><author><keyname>Bollepalli</keyname><forenames>Bajibabu</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author><author><keyname>Airaksinen</keyname><forenames>Manu</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Alku</keyname><forenames>Paavo</forenames></author></authors><title>Speech waveform synthesis from MFCC sequences with generative
  adversarial networks</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for generating speech from filterbank mel
frequency cepstral coefficients (MFCC), which are widely used in speech
applications, such as ASR, but are generally considered unusable for speech
synthesis. First, we predict fundamental frequency and voicing information from
MFCCs with an autoregressive recurrent neural net. Second, the spectral
envelope information contained in MFCCs is converted to all-pole filters, and a
pitch-synchronous excitation model matched to these filters is trained.
Finally, we introduce a generative adversarial network -based noise model to
add a realistic high-frequency stochastic component to the modeled excitation
signal. The results show that high quality speech reconstruction can be
obtained, given only MFCC information at test time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00930</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00930</id><created>2018-04-03</created><authors><author><keyname>Haqiqatnejad</keyname><forenames>Alireza</forenames></author><author><keyname>Kayhan</keyname><forenames>Farbod</forenames></author><author><keyname>Ottersten</keyname><forenames>Bjorn</forenames></author></authors><title>Symbol-Level Precoding Design Based on Distance Preserving Constructive
  Interference Regions</title><categories>eess.SP cs.IT math.IT</categories><comments>19 pages, 12 figures, Submitted to IEEE Transactions in Signal
  Processing</comments><doi>10.1109/TSP.2018.2872823</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the symbol-level precoding (SLP) design problem
in the downlink of a multiuser multiple-input single-output (MISO) channel. We
consider generic constellations with any arbitrary shape and size, and confine
ourselves to one of the main categories of constructive interference regions
(CIR), namely, distance preserving CIR (DPCIR). We provide a comprehensive
study of DPCIRs and derive some properties for these regions. Using these
properties, we first show that any signal in a given DPCIR has a norm greater
than or equal to the norm of the corresponding constellation point if and only
if the convex hull of the constellation contains the origin. It is followed by
proving that the power of the noiseless received signal lying on a DPCIR is a
monotonic strictly increasing function of two parameters relating to the
infinite Voronoi edges. Using the convex description of DPCIRs and their
properties, we formulate two design problems, namely, the SLP power
minimization with signal-to-interference-plus-noise ratio (SINR) constraints,
and the SLP SINR balancing problem under max-min fairness criterion. The SLP
power minimization based on DPCIRs can straightforwardly be written as a
quadratic program (QP). We provide a simplified reformulation of this problem
which is less computationally complex. The SLP max-min SINR, however, is
non-convex in its original form, and hence difficult to tackle. We propose
several alternative optimization approaches, including semidefinite program
(SDP) formulation and block coordinate descent (BCD) optimization. We discuss
and evaluate the loss due to the proposed alternative methods through extensive
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00959</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00959</id><created>2018-03-15</created><authors><author><keyname>Carvalho</keyname><forenames>Jo&#xe3;o M.</forenames></author><author><keyname>Br&#xe1;s</keyname><forenames>Susana</forenames></author><author><keyname>Pinho</keyname><forenames>Armando J.</forenames></author></authors><title>Compression-Based ECG Biometric Identification Using a Non-fiducial
  Approach</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1709.07346</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to its characteristics, there is a trend in biometrics to use the ECG
signal for personal identification. Recent works based on compression models
have shown that these approaches are suitable to ECG biometric identification.
However, the best results are usually achieved by the methods that, at least,
rely on one point of interest of the ECG.
  In this work, we propose a compression-based non-fiducial method, that uses a
measure of similarity, called the Normalized Relative Compression -- a measure
related to the Kolmogorov complexity of strings. Our method uses
extended-alphabet finite-context models (xaFCMs) on the quantized first-order
derivative of the signal, instead of using directly the original signal, as
other methods do.
  We were able to achieve state-of-the-art results on a database collected at
the University of Aveiro, which was used on previous works, making it a good
preliminary benchmark for the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00962</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00962</id><created>2018-03-19</created><authors><author><keyname>Tushar</keyname><forenames>Wayes</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Mohsenian-Rad</keyname><forenames>Hamed</forenames></author><author><keyname>Saha</keyname><forenames>Tapan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Wood</keyname><forenames>Kristin L</forenames></author></authors><title>Transforming Energy Networks via Peer to Peer Energy Trading: Potential
  of Game Theoretic Approaches</title><categories>eess.SP cs.GT cs.SY</categories><comments>38 pages, single column, double space</comments><journal-ref>IEEE Signal Processing Magazine, 2018</journal-ref><doi>10.1109/MSP.2018.2818327</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer (P2P) energy trading has emerged as a next-generation energy
management mechanism for the smart grid that enables each prosumer of the
network to participate in energy trading with one another and the grid. This
poses a significant challenge in terms of modeling the decision-making process
of each participant with conflicting interest and motivating prosumers to
participate in energy trading and to cooperate, if necessary, for achieving
different energy management goals. Therefore, such decision-making process
needs to be built on solid mathematical and signal processing tools that can
ensure an efficient operation of the smart grid. This paper provides an
overview of the use of game theoretic approaches for P2P energy trading as a
feasible and effective means of energy management. As such, we discuss various
games and auction theoretic approaches by following a systematic classification
to provide information on the importance of game theory for smart energy
research. Then, the paper focuses on the P2P energy trading describing its key
features and giving an introduction to an existing P2P testbed. Further, the
paper zooms into the detail of some specific game and auction theoretic models
that have recently been used in P2P energy trading and discusses some important
finding of these schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.00981</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.00981</id><created>2018-03-31</created><authors><author><keyname>Shahin</keyname><forenames>Ismail</forenames></author><author><keyname>Nassif</keyname><forenames>Ali Bou</forenames></author><author><keyname>Bahutair</keyname><forenames>Mohammed</forenames></author></authors><title>Emirati-Accented Speaker Identification in each of Neutral and Shouted
  Talking Environments</title><categories>cs.SD eess.AS</categories><comments>14 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1707.00686</comments><doi>10.1007/s10772-018-9502-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is devoted to capturing Emirati-accented speech database (Arabic
United Arab Emirates database) in each of neutral and shouted talking
environments in order to study and enhance text-independent Emirati-accented
speaker identification performance in shouted environment based on each of
First-Order Circular Suprasegmental Hidden Markov Models (CSPHMM1s),
Second-Order Circular Suprasegmental Hidden Markov Models (CSPHMM2s), and
Third-Order Circular Suprasegmental Hidden Markov Models (CSPHMM3s) as
classifiers. In this research, our database was collected from fifty Emirati
native speakers (twenty five per gender) uttering eight common Emirati
sentences in each of neutral and shouted talking environments. The extracted
features of our collected database are called Mel-Frequency Cepstral
Coefficients (MFCCs). Our results show that average Emirati-accented speaker
identification performance in neutral environment is 94.0%, 95.2%, and 95.9%
based on CSPHMM1s, CSPHMM2s, and CSPHMM3s, respectively. On the other hand, the
average performance in shouted environment is 51.3%, 55.5%, and 59.3% based,
respectively, on CSPHMM1s, CSPHMM2s, and CSPHMM3s. The achieved average speaker
identification performance in shouted environment based on CSPHMM3s is very
similar to that obtained in subjective assessment by human listeners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01002</identifier>
 <datestamp>2018-04-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01002</id><created>2018-04-02</created><updated>2018-04-05</updated><authors><author><keyname>Tan</keyname><forenames>Xiaosi</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Xu</keyname><forenames>Weihong</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Be'ery</keyname><forenames>Yair</forenames><affiliation>School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author></authors><title>Improving Massive MIMO Belief Propagation Detector with Deep Neural
  Network</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, deep neural network (DNN) is utilized to improve the belief
propagation (BP) detection for massive multiple-input multiple-output (MIMO)
systems. A neural network architecture suitable for detection task is firstly
introduced by unfolding BP algorithms. DNN MIMO detectors are then proposed
based on two modified BP detectors, damped BP and max-sum BP. The correction
factors in these algorithms are optimized through deep learning techniques,
aiming at improved detection performance. Numerical results are presented to
demonstrate the performance of the DNN detectors in comparison with various BP
modifications. The neural network is trained once and can be used for multiple
online detections. The results show that, compared to other state-of-the-art
detectors, the DNN detectors can achieve lower bit error rate (BER) with
improved robustness against various antenna configurations and channel
conditions at the same level of complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01028</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01028</id><created>2018-04-03</created><updated>2019-07-08</updated><authors><author><keyname>Tourigny-Plante</keyname><forenames>Alex</forenames></author><author><keyname>Michaud-Belleau</keyname><forenames>Vincent</forenames></author><author><keyname>Bourbeau-H&#xe9;bert</keyname><forenames>Nicolas</forenames></author><author><keyname>Bergeron</keyname><forenames>Hugo</forenames></author><author><keyname>Genest</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Desch&#xea;nes</keyname><forenames>Jean-Daniel</forenames></author></authors><title>An open and flexible digital phase-locked loop for optical metrology</title><categories>eess.SP</categories><comments>This article may be downloaded for personal use only. Any other use
  requires prior permission of the author and AIP Publishing. This article
  appeared in Review of Scientific Instruments 89, 093103 (2018) and may be
  found at https://doi.org/10.1063/1.5039344</comments><journal-ref>Review of Scientific Instruments 89, 093103 (2018)</journal-ref><doi>10.1063/1.5039344</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an open and flexible digital phase lock loop optimized
for laser stabilization systems. It is implemented on a cheap and easily
accessible FPGA-based digital electronics platform (Red Pitaya) running a
customizable open-source firmware. A PC-based software interface allows
controlling the platform and optimizing the loop parameters remotely. Several
tools are included to allow measurement of quantities of interest smoothly and
rapidly. To demonstrate the platform's capabilities, we built a fiber noise
canceler over a $400$~m fiber link. Noise cancellation was achieved over a
$30$~kHz bandwidth, a value limited mainly by the delays introduced by the
actuator and by the round-trip propagation over the fiber link. We measured a
total latency of $565$~ns for the platform itself, limiting the theoretically
achievable control bandwidth to approximately 225 kHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01059</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01059</id><created>2018-04-03</created><authors><author><keyname>Tang</keyname><forenames>Xuanxuan</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Cai</keyname><forenames>Yueming</forenames></author><author><keyname>Yang</keyname><forenames>Wendong</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Analyzing Power Beacon Assisted Multi-Source Transmission Using Markov
  Chain</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless power transmission (WPT) is envisioned to be a promising technology
for prolonging the lifetime of wireless devices in energy-constrained networks.
This paper presents a general power beacon (PB) assisted multi-source
transmission, where a practical source selection scheme with information
transmission (IT) mode or non-IT mode is developed to maximize the transmission
reliability. In the IT mode, a zero-forcing (ZF) beamformed signal with no
interference to the destination is transmitted at the multi-antenna PB to
supply wireless energy for the sources, and bring non-negative effect to the
destination. Among multiple sources, the energy-sufficient source with the best
channel quality is selected for wireless information transmission (WIT), while
the other sources remain for energy harvesting. In the non-IT mode, the equal
power transmission is adopted at PB to focus on energy delivery. Using Markov
chain theory, the energy arrival and departure of each finite-capacity storage
at the source is characterized mathematically, and the comprehensive analytical
expressions of the energy outage probability (EOP), the connection outage
probability (COP), and the average transmission delay (ATD) are formulated and
derived. Our results reveal that the EOP, COP, and ATD can be significantly
improved via increasing the number of sources deployed in the proposed network
with finite transmit power of PB. We also prove that the multi-source network
will never experience energy outage with infinite transmit power of PB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01146</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01146</id><created>2018-04-03</created><authors><author><keyname>Wang</keyname><forenames>Yun</forenames></author><author><keyname>Li</keyname><forenames>Juncheng</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance
  Learning for Weakly Supervised Sequence Learning Tasks</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many sequence learning tasks require the localization of certain events in
sequences. Because it can be expensive to obtain strong labeling that specifies
the starting and ending times of the events, modern systems are often trained
with weak labeling without explicit timing information. Multiple instance
learning (MIL) is a popular framework for learning from weak labeling. In a
common scenario of MIL, it is necessary to choose a pooling function to
aggregate the predictions for the individual steps of the sequences. In this
paper, we compare the &quot;max&quot; and &quot;noisy-or&quot; pooling functions on a speech
recognition task and a sound event detection task. We find that max pooling is
able to localize phonemes and sound events, while noisy-or pooling fails. We
provide a theoretical explanation of the different behavior of the two pooling
functions on sequence learning tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01149</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01149</id><created>2018-04-03</created><authors><author><keyname>Bahuleyan</keyname><forenames>Hareesh</forenames></author></authors><title>Music Genre Classification using Machine Learning Techniques</title><categories>cs.SD eess.AS</categories><comments>12 Pages, 6 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Categorizing music files according to their genre is a challenging task in
the area of music information retrieval (MIR). In this study, we compare the
performance of two classes of models. The first is a deep learning approach
wherein a CNN model is trained end-to-end, to predict the genre label of an
audio signal, solely using its spectrogram. The second approach utilizes
hand-crafted features, both from the time domain and the frequency domain. We
train four traditional machine learning classifiers with these features and
compare their performance. The features that contribute the most towards this
multi-class classification task are identified. The experiments are conducted
on the Audio set data set and we report an AUC value of 0.894 for an ensemble
classifier which combines the two proposed approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01176</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01176</id><created>2018-04-03</created><authors><author><keyname>Yuen</keyname><forenames>Kevan</forenames></author><author><keyname>Trivedi</keyname><forenames>Mohan M.</forenames></author></authors><title>Looking at Hands in Autonomous Vehicles: A ConvNet Approach using Part
  Affinity Fields</title><categories>eess.IV cs.CV</categories><comments>11 pages, 8 figures, 1 table. Submitted to &quot;IEEE Transactions on
  Intelligent Vehicles&quot; (under review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of autonomous driving, where humans may need to take over in
the event where the computer may issue a takeover request, a key step towards
driving safety is the monitoring of the hands to ensure the driver is ready for
such a request. This work, focuses on the first step of this process, which is
to locate the hands. Such a system must work in real-time and under varying
harsh lighting conditions. This paper introduces a fast ConvNet approach, based
on the work of original work of OpenPose for full body joint estimation. The
network is modified with fewer parameters and retrained using our own day-time
naturalistic autonomous driving dataset to estimate joint and affinity heatmaps
for driver &amp; passenger's wrist and elbows, for a total of 8 joint classes and
part affinity fields between each wrist-elbow pair. The approach runs real-time
on real-world data at 40 fps on multiple drivers and passengers. The system is
extensively evaluated both quantitatively and qualitatively, showing at least
95% detection performance on joint localization and arm-angle estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01212</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01212</id><created>2018-04-03</created><authors><author><keyname>Dalir</keyname><forenames>Ali</forenames></author><author><keyname>Beheshti</keyname><forenames>Ali Asghar</forenames></author><author><keyname>Masoom</keyname><forenames>Morteza Hoseini</forenames></author></authors><title>Classification of Vehicles Based on Audio Signals using Quadratic
  Discriminant Analysis and High Energy Feature Vectors</title><categories>cs.SD eess.AS</categories><journal-ref>International Journal on Soft Computing (IJSC) Vol.6, No. 1,
  February 2015</journal-ref><doi>10.5121/ijsc.2015.6105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this paper is on classification of different vehicles using
sound emanated from the vehicles. In this paper,quadratic discriminant analysis
classifies audio signals of passing vehicles to bus, car, motor, and truck
categories based on features such as short time energy, average zero cross
rate, and pitch frequency of periodic segments of signals. Simulation results
show that just by considering high energy feature vectors, better
classification accuracy can be achieved due to the correspondence of low energy
regions with noises of the background. To separate these elements, short time
energy and average zero cross rate are used simultaneously.In our method,we
have used a few features which are easy to be calculated in time domain and
enable practical implementation of efficient classifier. Although, the
computation complexity is low, the classification accuracy is comparable with
other classification methods based on long feature vectors reported in
literature for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01227</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01227</id><created>2018-04-03</created><authors><author><keyname>Liu</keyname><forenames>Yiguang</forenames></author></authors><title>A Unifying Decomposition and Reconstruction Model for Discrete Signals</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decomposing discrete signals such as images into components is vital in many
applications, and this paper propose a framework to produce filtering banks to
accomplish this task. The framework is an equation set which is ill-posed, and
thus have many solutions. Each solution can form a filtering bank consisting of
two decomposition filters, and two reconstruction filters. Especially, many
existing discrete wavelet filtering banks are special cases of the framework,
and thus the framework actually makes the different wavelet filtering banks
unifiedly presented. Moreover, additional constraints can impose on the
framework to make it well-posed, meaning that decomposition and reconstruction
(D&amp;R) can consider the practical requirements, not like existing discrete
wavelet filtering banks whose coefficients are fixed. All the filtering banks
produced by the framework can behave excellently, have many decomposition
effect and precise reconstruction accuracy, and this has been theoretically
proved and been confirmed by a large number experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01246</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01246</id><created>2018-04-04</created><updated>2018-08-09</updated><authors><author><keyname>Abdolhamidi</keyname><forenames>Mostafa</forenames></author><author><keyname>Mohammad-Taheri</keyname><forenames>Mahmoud</forenames></author></authors><title>Theory and design of a phase-inverted balanced coupled-line DC-blocker</title><categories>eess.SP</categories><comments>submitted for IET Microwaves, Antennas and Propagation, (under
  review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A planar DC-blocker suitable for differential mode signaling applications is
designed and fabricated. The theory of this component is explained in a new
form which utilizes the wave scattering transfer matrix. The proposed
interpretation of the transfer matrix is most suitable for series (cascade)
elements like DC-blockers. In addition to the theoretical enhancement, design
of a compressed balanced DC-blocker inserted through a shielded broadside
coupled stripline (SBCSL) transmission line is presented. The return loss of
better than 10 dB is obtained at 50-ohm differential-mode input ports of the
fabricated DC-blocker in the entire frequency range of 5.6-8.4 GHz. The lowest
air-gap width in the presented structure is about 10 times bigger than that of
a conventional coupled-line structure. So, the structure is much less sensitive
to fabrication tolerances. Moreover, the DC-blocker is likely to tolerate
higher DC-voltage differences. Also, a demonstration for a millimeter-wave
version of this DC-blocker suitable for integrated circuits (ICs) applications
is proposed for future development. The final achievement of this paper is
design and fabrication of a wideband substrate integrated waveguide
(SIW)-mediated balun structure for single-ended measurement of a balanced SBCSL
component. The fabricated balun exhibits a nearly perfect coaxial-mode to
coupled-stripline differential-mode conversion in the full range of 5-9 GHz.
The presented balun is successfully utilized to derive the scattering
parameters (S-parameters) of the fabricated balanced SBCSL DC-blocker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01408</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01408</id><created>2018-04-02</created><authors><author><keyname>Ardeshiri</keyname><forenames>Ghazaleh</forenames></author><author><keyname>Jamshidi</keyname><forenames>Ali</forenames></author><author><keyname>Keshavarz-Haddad</keyname><forenames>Alireza</forenames></author></authors><title>Optimal Relay Location in Diffusion Based Molecular Communications</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1401.3410, arXiv:1410.5585,
  arXiv:1504.03738, arXiv:1410.4258 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular Communications via Diffusion (MCvD) is a promising paradigm which
enables nano-machines to communicate with each other. However, the reliability
of existing systems degrade rapidly as the distance between the transmitters
and the receivers grows. To solve this issue, relaying schemes must be
implemented in practice. In this paper, we study two relaying schemes: In the
first case, the relay node decodes the incoming signal symbol and forwards it
to the receiver using a different type of molecule. Then, the receiver detects
the information bits by only considering the molecules from the relay node. In
the second case, the receiver considers both the types of molecules sent from
the transmitter and the relay node. For these two scenarios, the optimal
location of the relay node is obtained. We assume Quadruple Concentration Shift
Keying (QCSK) modulation in which the signal is encoded into the four level
concentrations of molecules emitted by the nano-machines. Our simulation
results indicate that adding a relay improves the performance by 10dB and 15dB
in the first and the second schemes, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01430</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01430</id><created>2018-04-04</created><authors><author><keyname>G&#xfc;nl&#xfc;</keyname><forenames>Onur</forenames></author><author><keyname>Kittichokechai</keyname><forenames>Kittipong</forenames></author><author><keyname>Schaefer</keyname><forenames>Rafael F.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Controllable Identifier Measurements for Private Authentication with
  Secret Keys</title><categories>cs.IT cs.CR cs.MM eess.SP math.IT math.PR</categories><comments>15 pages</comments><journal-ref>IEEE Transactions on Information Forensics and Security, vol. 13,
  no. 8, pp. 1945-1959 (Aug. 2018)</journal-ref><doi>10.1109/TIFS.2018.2806937</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of secret-key based authentication under a privacy constraint on
the source sequence is considered. The identifier measurements during
authentication are assumed to be controllable via a cost-constrained &quot;action&quot;
sequence. Single-letter characterizations of the optimal trade-off among the
secret-key rate, storage rate, privacy-leakage rate, and action cost are given
for the four problems where noisy or noiseless measurements of the source are
enrolled to generate or embed secret keys. The results are relevant for several
user-authentication scenarios including physical and biometric authentications
with multiple measurements. Our results include, as special cases, new results
for secret-key generation and embedding with action-dependent side information
without any privacy constraint on the enrolled source sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01455</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01455</id><created>2018-04-02</created><authors><author><keyname>Ebrahimi</keyname><forenames>Amir</forenames></author><author><keyname>Rahimian</keyname><forenames>Ardavan</forenames></author></authors><title>Estimation of Channel Parameters in a Multipath Environment via
  Optimizing Highly Oscillatory Error-Functions Using a Genetic Algorithm</title><categories>eess.SP cs.IT math.IT</categories><comments>In Proceedings of the 15th International Conference on Software,
  Telecommunications and Computer Networks (SoftCOM), September 2007, pp. 1-5</comments><doi>10.1109/SOFTCOM.2007.4446112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation is of crucial importance for tomorrow's wireless mobile
communication systems. This paper focuses on the solution of channel parameters
estimation problem in a scenario involving multiple paths in the presence of
additive white Gaussian noise. We assumed that number of paths in the multipath
environment is known and the transmitted signal consists of attenuated and
delayed replicas of a known transient signal. In order to determine the maximum
likelihood estimates one has to solve a complicated optimization problem.
Genetic Algorithms (GA) are well known for their robustness in solving complex
optimization problems. A GA is considered to extract channel parameters to
minimize the derived error-function. The solution is based on the
maximum-likelihood estimation of the channel parameters. Simulation results
also demonstrate GA's robustness to channel parameters estimation errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01484</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01484</id><created>2018-04-04</created><updated>2018-06-30</updated><authors><author><keyname>&#x15e;ahin</keyname><forenames>Serdar</forenames></author><author><keyname>Cipriano</keyname><forenames>Antonio M.</forenames></author><author><keyname>Poulliat</keyname><forenames>Charly</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>A Framework for Iterative Frequency Domain EP-based Receiver Design</title><categories>eess.SP</categories><comments>15 pages, 15 figures, under review for IEEE Journal on Transactions
  on Communications</comments><doi>10.1109/TCOMM.2018.2863724</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An original expectation propagation (EP) based message passing framework is
introduced, wherein transmitted symbols are considered to belong to the
multivariate white Gaussian distribution family. This approach allows deriving
a novel class of single-tap frequency domain (FD) receivers with a quasi-linear
computational complexity in block length, thanks to Fast-Fourier transform
(FFT) based implementation. This framework is exposed in detail, through the
design of a novel double-loop single-carrier frequency domain equalizer
(SC-FDE), where self-iterations of the equalizer with the demapper, and turbo
iterations with the decoder, provide numerous combinations for the performance
and complexity trade-off. Furthermore, the flexibility of this framework is
illustrated with the derivation of an overlap FDE, used for time-varying
channel equalization, among others, and with the design of a FD multiple-input
multiple-output (MIMO) detector, used for spatial multiplexing. Through these
different receiver design problems, this framework is shown to improve the
mitigation of inter-symbol, inter-block and multi-antenna interferences,
compared to alternative single-tap FD structures of previous works. Thanks to
finite-length and asymptotic analysis, supported by numerical results, the
improvement brought by the proposed structures is assessed, and then completed
by also accounting for computational costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01577</identifier>
 <datestamp>2018-04-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01577</id><created>2018-04-04</created><authors><author><keyname>Miah</keyname><forenames>Md. Suzan</forenames></author><author><keyname>khan</keyname><forenames>Ahsan Noor</forenames></author><author><keyname>Icheln</keyname><forenames>Clemens</forenames></author><author><keyname>Haneda</keyname><forenames>Katsuyuki</forenames></author><author><keyname>Takizawa</keyname><forenames>Ken-ichi</forenames></author></authors><title>Antenna Systems for Wireless Capsule Endoscope: Design, Analysis and
  Experimental Validation</title><categories>eess.SP</categories><comments>11 pages, 19 figures, Journal, IEEE Transactions on Antennas and
  Propagation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless capsule endoscopy (WCE) systems are used to capture images of the
human digestive tract for medical applications. The antenna is one of the most
important components in a WCE system. In this paper, we provide novel small
antenna solutions for a WCE system operating at the 433 MHz ISM band. The
in-body capsule transmitter uses an ultrawideband outer-wall conformal loop
antenna, whereas the on-body receiver uses a printed monopole antenna with a
partial ground plane. A colon-equivalent tissue phantom and CST Gustav voxel
human body model were used for the numerical studies of the capsule antenna.
The simulation results in the colon-tissue phantom were validated through
in-vitro measurements using a liquid phantom. According to the phantom
simulations, the capsule antenna has -10 dB impedance matching from 309 to 1104
MHz. The ultrawideband characteristic enables the capsule antenna to tolerate
the detuning effects due to electronic modules in the capsule and due to the
proximity of various different tissues in gastrointestinal tracts. The on-body
antenna was numerically evaluated on the colon-tissue phantom and the CST
Gustav voxel human body model, followed by in-vitro and ex-vivo measurements
for validation. The on-body antenna exceeds -10 dB impedance matching from 390
MHz to 500 MHz both in simulations and measurements. Finally, this paper
reports numerical and experimental studies of the path loss for the radio link
between an in-body capsule transmitter and an on-body receiver using our
antenna solutions. The path loss both in simulations and measurements is less
than 50 dB for any capsule orientation and location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01650</identifier>
 <datestamp>2018-04-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01650</id><created>2018-04-04</created><authors><author><keyname>Stoller</keyname><forenames>Daniel</forenames></author><author><keyname>Ewert</keyname><forenames>Sebastian</forenames></author><author><keyname>Dixon</keyname><forenames>Simon</forenames></author></authors><title>Jointly Detecting and Separating Singing Voice: A Multi-Task Approach</title><categories>cs.SD cs.LG eess.AS</categories><comments>10 pages, 2 figures, accepted for the 14th International Conference
  on Latent Variable Analysis and Signal Separation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A main challenge in applying deep learning to music processing is the
availability of training data. One potential solution is Multi-task Learning,
in which the model also learns to solve related auxiliary tasks on additional
datasets to exploit their correlation. While intuitive in principle, it can be
challenging to identify related tasks and construct the model to optimally
share information between tasks. In this paper, we explore vocal activity
detection as an additional task to stabilise and improve the performance of
vocal separation. Further, we identify problematic biases specific to each
dataset that could limit the generalisation capability of separation and
detection models, to which our proposed approach is robust. Experiments show
improved performance in separation as well as vocal detection compared to
single-task baselines. However, we find that the commonly used
Signal-to-Distortion Ratio (SDR) metrics did not capture the improvement on
non-vocal sections, indicating the need for improved evaluation methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01665</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01665</id><created>2018-04-05</created><updated>2018-07-26</updated><authors><author><keyname>Gao</keyname><forenames>Ruohan</forenames></author><author><keyname>Feris</keyname><forenames>Rogerio</forenames></author><author><keyname>Grauman</keyname><forenames>Kristen</forenames></author></authors><title>Learning to Separate Object Sounds by Watching Unlabeled Video</title><categories>cs.CV cs.MM cs.SD eess.AS</categories><comments>Published in ECCV 2018; Project Page:
  http://vision.cs.utexas.edu/projects/separating_object_sounds/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perceiving a scene most fully requires all the senses. Yet modeling how
objects look and sound is challenging: most natural scenes and events contain
multiple objects, and the audio track mixes all the sound sources together. We
propose to learn audio-visual object models from unlabeled video, then exploit
the visual context to perform audio source separation in novel videos. Our
approach relies on a deep multi-instance multi-label learning framework to
disentangle the audio frequency bases that map to individual visual objects,
even without observing/hearing those objects in isolation. We show how the
recovered disentangled bases can be used to guide audio source separation to
obtain better-separated, object-level sounds. Our work is the first to learn
audio source separation from large-scale &quot;in the wild&quot; videos containing
multiple audio sources per video. We obtain state-of-the-art results on
visually-aided audio source separation and audio denoising. Our video results:
http://vision.cs.utexas.edu/projects/separating_object_sounds/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01834</identifier>
 <datestamp>2018-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01834</id><created>2018-03-17</created><updated>2018-09-09</updated><authors><author><keyname>Abad</keyname><forenames>Mehdi Salehi Heydar</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>Finite Horizon Throughput Maximization and Sensing Optimization in
  Wireless Powered Devices over Fading Channels</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>Single column, 31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless power transfer (WPT) is a promising technology that provides the
network a way to replenish the batteries of the remote devices by utilizing RF
transmissions. We study a class of harvest-first-transmit-later type of WPT
policy, where an access point (AP) first employs RF power transfer to recharge
a wireless powered device (WPD) for a certain period subjected to optimization,
and then, the harvested energy is subsequently used by the WPD to transmit its
data bits back to the AP over a finite horizon. A significant challenge
regarding the studied WPT scenario is the time-varying nature of the wireless
channel linking the WPD to the AP. We first investigate as a benchmark the
offline case where the channel realizations are known non-causally prior to the
starting of the horizon. For the offline case, by finding the optimal WPT
duration and power allocations in the data transmission period, we derive an
upper bound on the throughput of the WPD. We then focus on the online
counterpart of the problem where the channel realizations are known causally.
We prove that the optimal WPT duration obeys a time-dependent threshold form
depending on the energy state of the WPD. In the subsequent data transmission
stage, the optimal transmit power allocation for the WPD is shown to be of a
fractional structure where at each time slot a fraction of energy depending on
the current channel and a measure of future channel state expectations is
allocated for data transmission. We numerically show that the online policy
performs almost identical to the upper bound. We then consider a data sensing
application, where the WPD adjusts the sensing resolution to balance between
the quality of the sensed data and the probability of successfully delivering
it. We use Bayesian inference as a reinforcement learning method to provide a
mean for the WPD in learning to balance the sensing resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01849</identifier>
 <datestamp>2018-04-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01849</id><created>2018-04-05</created><authors><author><keyname>Korzeniowski</keyname><forenames>Filip</forenames></author><author><keyname>Sears</keyname><forenames>David R. W.</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>A Large-Scale Study of Language Models for Chord Prediction</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Accepted at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We conduct a large-scale study of language models for chord prediction.
Specifically, we compare N-gram models to various flavours of recurrent neural
networks on a comprehensive dataset comprising all publicly available datasets
of annotated chords known to us. This large amount of data allows us to
systematically explore hyper-parameter settings for the recurrent neural
networks---a crucial step in achieving good results with this model class. Our
results show not only a quantitative difference between the models, but also a
qualitative one: in contrast to static N-gram models, certain RNN
configurations adapt to the songs at test time. This finding constitutes a
further step towards the development of chord recognition systems that are more
aware of local musical context than what was previously possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.01935</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.01935</id><created>2018-04-05</created><updated>2018-06-30</updated><authors><author><keyname>&#x15e;ahin</keyname><forenames>Serdar</forenames></author><author><keyname>Cipriano</keyname><forenames>Antonio M.</forenames></author><author><keyname>Poulliat</keyname><forenames>Charly</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>Iterative Equalization with Decision Feedback based on Expectation
  Propagation</title><categories>eess.SP</categories><comments>14 pages, 13 figures, to appear on IEEE Transactions on
  Communications, 2018</comments><doi>10.1109/TCOMM.2018.2843760</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the design and analysis of minimum mean square error
(MMSE) turbo decision feedback equalization (DFE), with expectation propagation
(EP), for single carrier modulations. Classical non iterative DFE structures
have substantial advantages at high data rates, even compared to turbo linear
equalizers - interference cancellers (LE-IC), hence making turbo DFE-IC schemes
an attractive solution. In this paper, we derive an iterative DFE-IC,
capitalizing on the use of soft feedback based on expectation propagation,
along with the use of prior information for improved filtering and interference
cancellation. This DFE-IC significantly outperforms exact turbo LE-IC,
especially at high spectral efficiency, and also exhibits various advantages
and performance improvements over existing variants of DFE-IC. The proposed
scheme can also be self-iterated, as done in the recent trend on EP-based
equalizers, and it is shown to be an attractive alternative to linear
self-iterated receivers. For time-varying (TV) filter equalizers, an efficient
matrix inversion scheme is also proposed, considerably reducing the
computational complexity relative to existing methods. Using finite-length and
asymptotic analysis on a severely selective channel, the proposed DFE-IC is
shown to achieve higher rates than known alternatives, with better waterfall
thresholds and faster convergence, while keeping a similar computational
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02027</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02027</id><created>2018-04-05</created><authors><author><keyname>Lin</keyname><forenames>Zhijian</forenames></author><author><keyname>Du</keyname><forenames>Xiaojiang</forenames></author><author><keyname>Chen</keyname><forenames>Hsiao-Hwa</forenames></author><author><keyname>Ai</keyname><forenames>Bo</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Wu</keyname><forenames>Dapeng</forenames></author></authors><title>Millimeter-Wave Propagation Modeling and Measurement</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) communication is one of the most promising
technologies in fifth generation (5G) mobile networks due to its access to a
large amount of available spectrum resources. Despite the theoretical potential
of a high data rate, there are still several key technical challenges with
using mmWave in mobile networks, such as severe pathloss, high penetration
loss, narrow beamwidth, etc. Hence, accurate and reliable knowledge of mmWave
channel propagation characteristics is essential for developing 5G wireless
communication systems. In this article, the fundamental characteristics of
mmWave are first presented. Then, two main channel modeling methods are
discussed. Finally, in order to investigate the channel characteristics at the
mmWave band, measurement campaigns using three different large-scale array
topologies are carried out and the typical channel parameters are extracted and
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02062</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02062</id><created>2018-04-05</created><updated>2018-04-28</updated><authors><author><keyname>Theiler</keyname><forenames>James</forenames></author><author><keyname>Zimmer</keyname><forenames>Beate</forenames></author><author><keyname>Ziemann</keyname><forenames>Amanda</forenames></author></authors><title>Closed-form detector for solid sub-pixel targets in multivariate
  t-distributed background clutter</title><categories>cs.CV eess.SP</categories><comments>4 pages, 2 figures</comments><report-no>LA-UR-18-20163</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized likelihood ratio test (GLRT) is used to derive a detector for
solid sub-pixel targets in hyperspectral imagery. A closed-form solution is
obtained that optimizes the replacement target model when the background is a
fat-tailed elliptically-contoured multivariate t-distribution. This generalizes
GLRT-based detectors that have previously been derived for the replacement
target model with Gaussian background, and for the additive target model with
an elliptically-contoured background. Experiments with simulated hyperspectral
data illustrate the performance of this detector in various parameter regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02072</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02072</id><created>2018-04-05</created><authors><author><keyname>Chen</keyname><forenames>Cheng-Ming</forenames></author><author><keyname>Volski</keyname><forenames>Vladimir</forenames></author><author><keyname>Van der Perre</keyname><forenames>Liesbet</forenames></author><author><keyname>Vandenbosch</keyname><forenames>Guy A. E.</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author></authors><title>Finite Large Antenna Arrays for Massive MIMO: Characterization and
  System Impact</title><categories>eess.SP</categories><comments>9 pages, IEEE Transactions on Antennas and Propagation</comments><journal-ref>IEEE Transactions on Antennas and Propagation Volume: 65 Issue: 12
  pgs 6712 - 6720 (2017)</journal-ref><doi>10.1109/TAP.2017.2754444</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Massive MIMO is considered a key technology for 5G. Various studies analyze
the impact of the number of antennas, relying on channel properties only and
assuming uniform antenna gains in very large arrays. In this paper, we
investigate the impact of mutual coupling and edge effects on the gain pattern
variation in the array. Our analysis focuses on the comparison of patch
antennas versus dipoles, representative for the antennas typically used in
massive MIMO experiments today. Through simulations and measurements, we show
that the finite patch array has a lower gain pattern variation compared with a
dipole array. The impact of a large gain pattern variation on the massive MIMO
system is that not all antennas contribute equally for all users, and the
effective number of antennas seen for a single user is reduced. We show that
the effect of this at system level is a decreased rate for all users for the
zero-forcing MIMO detector, up to 20% for the patch array and 35% for the
dipole array. The maximum ratio combining on the other hand, introduces user
unfairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02084</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02084</id><created>2018-04-05</created><authors><author><keyname>Lee</keyname><forenames>Donghoon</forenames></author><author><keyname>Berberidis</keyname><forenames>Dimitris</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Adaptive Bayesian Radio Tomography</title><categories>eess.SP stat.AP</categories><doi>10.1109/TSP.2019.2899806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio tomographic imaging (RTI) is an emerging technology to locate physical
objects in a geographical area covered by wireless networks. From the
attenuation measurements collected at spatially distributed sensors, radio
tomography capitalizes on spatial loss fields (SLFs) measuring the absorption
of radio frequency waves at each location along the propagation path. These
SLFs can be utilized for interference management in wireless communication
networks, environmental monitoring, and survivor localization after natural
disaster such as earthquakes. Key to success of RTI is to model accurately the
shadowing effects as the bi-dimensional integral of the SLF scaled by a weight
function, which is estimated using regularized regression. However, the
existing approaches are less effective when the propagation environment is
heterogeneous. To cope with this, the present work introduces a piecewise
homogeneous SLF governed by a hidden Markov random field (MRF) model. Efficient
and tractable SLF estimators are developed by leveraging Markov chain Monte
Carlo (MCMC) techniques. Furthermore, an uncertainty sampling method is
developed to adaptively collect informative measurements in estimating the SLF.
Numerical tests using synthetic and real datasets demonstrate capabilities of
the proposed algorithm for radio tomography and channel-gain estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02124</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02124</id><created>2018-04-05</created><authors><author><keyname>Yu</keyname><forenames>Tao</forenames></author><author><keyname>Haniz</keyname><forenames>Azril</forenames></author><author><keyname>Sano</keyname><forenames>Kentaro</forenames></author><author><keyname>Iwata</keyname><forenames>Ryosuke</forenames></author><author><keyname>Kosaka</keyname><forenames>Ryouta</forenames></author><author><keyname>Kuki</keyname><forenames>Yusuke</forenames></author><author><keyname>Tran</keyname><forenames>Gia Khanh</forenames></author><author><keyname>Takada</keyname><forenames>Jun-Ichi</forenames></author><author><keyname>Sakaguchi</keyname><forenames>Kei</forenames></author></authors><title>A Guide of Fingerprint Based Radio Emitter Localization using Multiple
  Sensors</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper is accepted by IEICE Transactions on Communications</comments><journal-ref>IEICE Trans. Commun., IEICE, Vol. E101-B, No.10, Oct. 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location information is essential to varieties of applications. It is one of
the most important context to be detected by wireless distributed sensors,
which is a key technology in Internet-of-Things. Fingerprint-based methods,
which compare location unique fingerprints collected beforehand with the
fingerprint measured from the target, have attracted much attention recently in
both of academia and industry. They have been successfully used for many
location-based applications.From the viewpoint of practical applications, in
this paper, four different typical approaches of fingerprint-based radio
emitter localization system are introduced with four different representative
applications: localization of LTE smart phone used for anti-cheating in exams,
indoor localization of Wi-Fi terminals, localized light control in BEMS using
location information of occupants, and illegal radio localization in outdoor
environments. Based on the different practical application scenarios, different
solutions, which are designed to enhance the localization performance, are
discussed in detail. To the best of the authors' knowledge, this is the first
paper to give a guideline for readers about fingerprint-based localization
system in terms of fingerprint selection, hardware architecture design and
algorithm enhancement
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02135</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02135</id><created>2018-04-06</created><updated>2019-02-11</updated><authors><author><keyname>Akuzawa</keyname><forenames>Kei</forenames></author><author><keyname>Iwasawa</keyname><forenames>Yusuke</forenames></author><author><keyname>Matsuo</keyname><forenames>Yutaka</forenames></author></authors><title>Expressive Speech Synthesis via Modeling Expressions with Variational
  Autoencoder</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted by Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in neural autoregressive models have improve the performance
of speech synthesis (SS). However, as they lack the ability to model global
characteristics of speech (such as speaker individualities or speaking styles),
particularly when these characteristics have not been labeled, making neural
autoregressive SS systems more expressive is still an open issue. In this
paper, we propose to combine VoiceLoop, an autoregressive SS model, with
Variational Autoencoder (VAE). This approach, unlike traditional autoregressive
SS systems, uses VAE to model the global characteristics explicitly, enabling
the expressiveness of the synthesized speech to be controlled in an
unsupervised manner. Experiments using the VCTK and Blizzard2012 datasets show
the VAE helps VoiceLoop to generate higher quality speech and to control the
expressions in its synthesized speech by incorporating global characteristics
into the speech generating process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02173</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02173</id><created>2018-04-06</created><authors><author><keyname>Lakomkin</keyname><forenames>Egor</forenames></author><author><keyname>Zamani</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Weber</keyname><forenames>Cornelius</forenames></author><author><keyname>Magg</keyname><forenames>Sven</forenames></author><author><keyname>Wermter</keyname><forenames>Stefan</forenames></author></authors><title>On the Robustness of Speech Emotion Recognition for Human-Robot
  Interaction with Deep Neural Networks</title><categories>cs.RO cs.CL cs.HC cs.SD eess.AS</categories><comments>Submitted to IROS'18, Madrid, Spain</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech emotion recognition (SER) is an important aspect of effective
human-robot collaboration and received a lot of attention from the research
community. For example, many neural network-based architectures were proposed
recently and pushed the performance to a new level. However, the applicability
of such neural SER models trained only on in-domain data to noisy conditions is
currently under-researched. In this work, we evaluate the robustness of
state-of-the-art neural acoustic emotion recognition models in human-robot
interaction scenarios. We hypothesize that a robot's ego noise, room
conditions, and various acoustic events that can occur in a home environment
can significantly affect the performance of a model. We conduct several
experiments on the iCub robot platform and propose several novel ways to reduce
the gap between the model's performance during training and testing in
real-world conditions. Furthermore, we observe large improvements in the model
performance on the robot and demonstrate the necessity of introducing several
data augmentation techniques like overlaying background noise and loudness
variations to improve the robustness of the neural approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02178</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02178</id><created>2018-04-06</created><authors><author><keyname>Abdelaziz</keyname><forenames>Mahmoud</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Brihuega</keyname><forenames>Alberto</forenames></author><author><keyname>Tufvesson</keyname><forenames>Fredrik</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Digital Predistortion for Hybrid MIMO Transmitters</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Journal of Selected Topics in Signal
  Processing</comments><doi>10.1109/JSTSP.2018.2824981</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article investigates digital predistortion (DPD) linearization of hybrid
beamforming large-scale antenna transmitters. We propose a novel DPD processing
and learning technique for an antenna sub-array, which utilizes a combined
signal of the individual power amplifier (PA) outputs in conjunction with a
decorrelation-based learning rule. In effect, the proposed approach results in
minimizing the nonlinear distortions in the direction of the intended receiver.
This feature is highly desirable, since emissions in other directions are
naturally weak due to beamforming. The proposed parameter learning technique
requires only a single observation receiver, and therefore supports simple
hardware implementation. It is also shown to clearly outperform the current
state-of-the-art technique which utilizes only a single PA for learning.
Analysis of the feedback network amplitude and phase imbalances reveals that
the technique is robust even to high levels of such imbalances. Finally, we
also show that the array system out-of-band emissions are well-behaving in all
spatial directions, and essentially below those of the corresponding
single-antenna transmitter, due to the combined effects of the DPD and
beamforming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02181</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02181</id><created>2018-04-06</created><authors><author><keyname>Oyamada</keyname><forenames>Keisuke</forenames></author><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author><author><keyname>Kaneko</keyname><forenames>Takuhiro</forenames></author><author><keyname>Tanaka</keyname><forenames>Kou</forenames></author><author><keyname>Hojo</keyname><forenames>Nobukatsu</forenames></author><author><keyname>Ando</keyname><forenames>Hiroyasu</forenames></author></authors><title>Generative adversarial network-based approach to signal reconstruction
  from magnitude spectrograms</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of reconstructing a time-domain signal
(or a phase spectrogram) solely from a magnitude spectrogram. Since magnitude
spectrograms do not contain phase information, we must restore or infer phase
information to reconstruct a time-domain signal. One widely used approach for
dealing with the signal reconstruction problem was proposed by Griffin and Lim.
This method usually requires many iterations for the signal reconstruction
process and depending on the inputs, it does not always produce high-quality
audio signals. To overcome these shortcomings, we apply a learning-based
approach to the signal reconstruction problem by modeling the signal
reconstruction process using a deep neural network and training it using the
idea of a generative adversarial network. Experimental evaluations revealed
that our method was able to reconstruct signals faster with higher quality than
the Griffin-Lim method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02195</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02195</id><created>2018-04-06</created><updated>2019-06-24</updated><authors><author><keyname>La Bella</keyname><forenames>Alessio</forenames></author><author><keyname>Farina</keyname><forenames>Marcello</forenames></author><author><keyname>Sandroni</keyname><forenames>Carlo</forenames></author><author><keyname>Scattolini</keyname><forenames>Riccardo</forenames></author></authors><title>Design of aggregators for the day-ahead management of microgrids
  providing active and reactive power services</title><categories>math.OC cs.SY eess.SY</categories><comments>(under revision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing diffusion of distributed energy generation systems requires
the development of new control paradigms for the coordination of
micro-generators, storage systems, and loads aimed at maintaining the
efficiency and the safe operability of the electricity network. MicroGrids
(MGs) are an interesting way to locally manage groups of generation devices,
but they cannot singularly provide a significant contribution to sustain the
main electricity grid in terms of ancillary services, such as the availability
of a minimum amount of power reserve for the frequency regulation. For these
reasons, in this paper we propose a framework for the aggregation and
coordination of interconnected MGs to provide ancillary services to the main
utility. The proposed framework is structured in three main phases. In the
first one, a distributed optimization algorithm computes the day-ahead profile
of the active power production of the MGs based on the available forecasts of
the renewable sources production and the loads absorption. In this phase,
scalability of the optimization problem and confidentiality requirements are
guaranteed. In the second phase, reactive power flows are scheduled and it is
ensured that the active power trends planned in the first phase do not
compromise the voltage/current limitations. A final third phase is used to
schedule the active and reactive power profiles of the generation units of each
MG to make them consistent with the requirements and results of the previous
two phases. The developed method is used for control of the IEEE 13-bus system
network and the results achieved are thoroughly discussed in terms of
performance and scalability properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02224</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02224</id><created>2018-04-06</created><authors><author><keyname>Brihuega</keyname><forenames>Alberto</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Performance Comparison of Constant Envelope and Zero-forcing Precoders
  in Multiuser Massive MIMO</title><categories>eess.SP</categories><comments>Accepted for publication at IEEE WCNC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, the adoption and performance of a constant envelope (CE)
type spatial precoder is addressed in large-scale multiuser MIMO based cellular
network. We first formulate an efficient computing solution to obtain the
antenna samples of such CE precoder. We then evaluate the achievable CE
precoder based multiuser downlink (DL) system performance and compare it with
the corresponding performance of more ordinary zero-forcing (ZF) spatial
precoder. We specifically also analyze how realistic highly nonlinear power
amplifiers (PAs) affect the achievable DL performance, as the individual PA
units in large-array or massive MIMO systems are expected to be small, cheap
and operating close to saturation for increased energy-efficiency purposes. It
is shown that the largely reduced peak-to-average power ratio (PAPR) of the PA
input signals in the CE precoder based system allows for pushing the PA units
harsher towards saturation, while allowing to reach higher
signal-to-interference-plus-noise ratio (SINRs) at the intended receivers
compared to the classical ZF precoder based system. The obtained results
indicate that the CE precoder can outperform the ZF precoder by up to 5-6 dBs,
in terms of the achievable SINRs, when the PA units are pushed towards their
saturating region. Such large gains are a substantial benefit when seeking to
improve the spectral and energy-efficiencies of the mobile cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02325</identifier>
 <datestamp>2018-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02325</id><created>2018-04-06</created><authors><author><keyname>Yela</keyname><forenames>Delia Fano</forenames></author><author><keyname>Stowell</keyname><forenames>Dan</forenames></author><author><keyname>Sandler</keyname><forenames>Mark</forenames></author></authors><title>Does k Matter? k-NN Hubness Analysis for Kernel Additive Modelling Vocal
  Separation</title><categories>cs.SD eess.AS</categories><comments>LVA-ICA 2018 - Feedback always welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel Additive Modelling (KAM) is a framework for source separation aiming
to explicitly model inherent properties of sound sources to help with their
identification and separation. KAM separates a given source by applying robust
statistics on the selection of time-frequency bins obtained through a
source-specific kernel, typically the k-NN function. Even though the parameter
k appears to be key for a successful separation, little discussion on its
influence or optimisation can be found in the literature. Here we propose a
novel method, based on graph theory statistics, to automatically optimise $k$
in a vocal separation task. We introduce the k-NN hubness as an indicator to
find a tailored k at a low computational cost. Subsequently, we evaluate our
method in comparison to the common approach to choose k. We further discuss the
influence and importance of this parameter with illuminating results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02425</identifier>
 <datestamp>2018-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02425</id><created>2018-04-06</created><updated>2018-05-09</updated><authors><author><keyname>Ma</keyname><forenames>Meng</forenames></author><author><keyname>Nikolakopoulos</keyname><forenames>Athanasios N.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Fast Decentralized Optimization over Networks</title><categories>math.OC cs.DC eess.SP</categories><comments>fix error in remark 4; clean up algorithms 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work introduces the hybrid consensus alternating direction method
of multipliers (H-CADMM), a novel framework for optimization over networks
which unifies existing distributed optimization approaches, including the
centralized and the decentralized consensus ADMM. H-CADMM provides a flexible
tool that leverages the underlying graph topology in order to achieve a
desirable sweet-spot between node-to-node communication overhead and rate of
convergence -- thereby alleviating known limitations of both C-CADMM and
D-CADMM. A rigorous analysis of the novel method establishes linear convergence
rate, and also guides the choice of parameters to optimize this rate. The novel
hybrid update rules of H-CADMM lend themselves to &quot;in-network acceleration&quot;
that is shown to effect considerable -- and essentially &quot;free-of-charge&quot; --
performance boost over the fully decentralized ADMM. Comprehensive numerical
tests validate the analysis and showcase the potential of the method in
tackling efficiently, widely useful learning tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02470</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02470</id><created>2018-04-06</created><authors><author><keyname>Yao</keyname><forenames>Gang</forenames></author><author><keyname>Dani</keyname><forenames>Ashwin</forenames></author></authors><title>Visual Tracking Using Sparse Coding and Earth Mover's Distance</title><categories>eess.IV cs.CV cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient iterative Earth Mover's Distance (iEMD) algorithm for visual
tracking is proposed in this paper. The Earth Mover's Distance (EMD) is used as
the similarity measure to search for the optimal template candidates in
feature-spatial space in a video sequence. The computation of the EMD is
formulated as the transportation problem from linear programming. The
efficiency of the EMD optimization problem limits its use for visual tracking.
To alleviate this problem, a transportation-simplex method is used for EMD
optimization and a monotonically convergent iterative optimization algorithm is
developed. The local sparse representation is used as the appearance models for
the iEMD tracker. The maximum-alignment-pooling method is used for constructing
a sparse coding histogram which reduces the computational complexity of the EMD
optimization. The template update algorithm based on the EMD is also presented.
The iEMD tracking algorithm assumes small inter-frame movement in order to
guarantee convergence. When the camera is mounted on a moving robot, e.g., a
flying quadcopter, the camera could experience a sudden and rapid motion
leading to large inter-frame movements. To ensure that the tracking algorithm
converges, a gyro-aided extension of the iEMD tracker is presented, where
synchronized gyroscope information is utilized to compensate for the rotation
of the camera. The iEMD algorithm's performance is evaluated using eight
publicly available datasets. The performance of the iEMD algorithm is compared
with seven state-of-the-art tracking algorithms based on relative percentage
overlap. The robustness of this algorithm for large inter-frame displacements
is also illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02496</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02496</id><created>2018-04-06</created><authors><author><keyname>Song</keyname><forenames>Jiayang</forenames></author><author><keyname>Dong</keyname><forenames>Ping</forenames></author><author><keyname>Zhou</keyname><forenames>Huachun</forenames></author><author><keyname>Zheng</keyname><forenames>Tao</forenames></author><author><keyname>Du</keyname><forenames>Xiaojiang</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author></authors><title>A Performance Analysis Model of TCP over Multiple Heterogeneous Paths
  for 5G Mobile Services</title><categories>cs.NI cs.CR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driven by the primary requirement of emerging 5G mobile services, the demand
for concurrent multipath transfer (CMT) is still prominent. Yet, multipath
transport protocols are not widely adopted and TCP-based CMT schemes will still
be in dominant position in 5G. However, the performance of TCP flow transferred
over multiple heterogeneous paths is prone to the link quality asymmetry, the
extent of which was revealed to be significant by our field investigation. In
this paper, we present a performance analysis model for TCP over multiple
heterogeneous paths in 5G scenarios, where both bandwidth and delay asymmetry
are taken into consideration. The evaluation adopting parameters from field
investigation shows that the proposed model can achieve high accuracy in
practical environments. Some interesting inferences can be drawn from the
proposed model, such as the dominant factor that affect the performance of TCP
over heterogeneous networks, and the criteria of determining the appropriate
number of links to be used under different circumstances of path heterogeneity.
Thus, the proposed model can provide a guidance to the design of TCP-based CMT
solutions for 5G mobile services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02498</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02498</id><created>2018-04-06</created><authors><author><keyname>Sun</keyname><forenames>Gang</forenames></author><author><keyname>Zhang</keyname><forenames>Yijing</forenames></author><author><keyname>Liao</keyname><forenames>Dan</forenames></author><author><keyname>Yu</keyname><forenames>Hongfang</forenames></author><author><keyname>Du</keyname><forenames>Xiaojiang</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author></authors><title>Bus Trajectory-Based Street-Centric Routing for Message Delivery in
  Urban Vehicular Ad hoc Networks</title><categories>cs.NI cs.CR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the routing algorithm for the communications between
vehicles and places in urban VANET. As one of the basic transportation
facilities in an urban setting, buses periodically run along their fixed routes
and widely cover city streets. The trajectory of bus lines can be seen as a sub
map of a city. Based on the characters of bus networks, we propose a bus
trajectory-based street-centric routing algorithm (BTSC), which uses bus as
main relay to deliver message. In BTSC, we build a routing graph based on the
trajectories of bus lines by analyzing the probability of bus appearing on
every street. We propose two novel concepts, i.e. the probability of street
consistency (PSC) and the probability of path consistency (PPC) which is used
as metrics to determine routing paths for message delivery. This aims to choose
the best path with higher density of busses and lower probability of
transmission direction deviating from the routing path. In order to improve the
bus forwarding opportunity, we design a bus-based forwarding strategy with ant
colony optimization (FACO) to find a reliable and steady multi-hop link between
two relay buses in order to decrease end-to-end delay. BTSC makes the
improvements in the selection of routing path and the strategy of message
forwarding. Simulation results show that our proposed routing algorithm has a
better performance in transmission ratio, transmission delay and adaptability
to different networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02549</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02549</id><created>2018-04-07</created><authors><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Lorenzo-Trueba</keyname><forenames>Jaime</forenames></author><author><keyname>Takaki</keyname><forenames>Shinji</forenames></author><author><keyname>Juvela</keyname><forenames>Lauri</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>A comparison of recent waveform generation and acoustic modeling methods
  for neural-network-based speech synthesis</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>To appear in ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in speech synthesis suggest that limitations such as the
lossy nature of the amplitude spectrum with minimum phase approximation and the
over-smoothing effect in acoustic modeling can be overcome by using advanced
machine learning approaches. In this paper, we build a framework in which we
can fairly compare new vocoding and acoustic modeling techniques with
conventional approaches by means of a large scale crowdsourced evaluation.
Results on acoustic models showed that generative adversarial networks and an
autoregressive (AR) model performed better than a normal recurrent network and
the AR model performed best. Evaluation on vocoders by using the same AR
acoustic model demonstrated that a Wavenet vocoder outperformed classical
source-filter-based vocoders. Particularly, generated speech waveforms from the
combination of AR acoustic model and Wavenet vocoder achieved a similar score
of speech quality to vocoded speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02665</identifier>
 <datestamp>2019-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02665</id><created>2018-04-08</created><updated>2019-04-11</updated><authors><author><keyname>Medhat</keyname><forenames>Fady</forenames></author><author><keyname>Chesmore</keyname><forenames>David</forenames></author><author><keyname>Robinson</keyname><forenames>John</forenames></author></authors><title>Environmental Sound Recognition using Masked Conditional Neural Networks</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Neural Network,
  DNN, Conditional Neural Network, CLNN, Masked Conditional Neural Net-work,
  MCLNN, Environmental Sound Recognition, ESR, Advanced Data Mining and
  Applications (ADMA) Year: 2017</comments><doi>10.1007/978-3-319-69179-4_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural network based architectures used for sound recognition are usually
adapted from other application domains, which may not harness sound related
properties. The ConditionaL Neural Network (CLNN) is designed to consider the
relational properties across frames in a temporal signal, and its extension the
Masked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within
the network, which enforces the network to learn in frequency bands rather than
bins. Additionally, it automates the exploration of different feature
combinations analogous to handcrafting the optimum combination of features for
a recognition task. We applied the MCLNN to the environmental sounds of the
ESC-10 dataset. The MCLNN achieved competitive accuracies compared to
state-of-the-art convolutional neural networks and hand-crafted attempts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02713</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02713</id><created>2018-04-08</created><updated>2019-05-08</updated><authors><author><keyname>Alsenwi</keyname><forenames>Madyan</forenames></author><author><keyname>Ismail</keyname><forenames>Tawfik</forenames></author><author><keyname>Darweesh</keyname><forenames>M. Saeed</forenames></author></authors><title>Hybrid Compression Techniques for EEG Data Based on Lossy/Lossless
  Compression Algorithms</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recorded Electroencephalography (EEG) data comes with a large size due to
the high sampling rate. Therefore, large space and more bandwidth are required
for storing and transmitting the EEG data. Thus, preprocessing and compressing
the EEG data is a very important part in order to transmit and store it
efficiently with less bandwidth and less space. The objective of this paper is
to develop an efficient system for EEG data compression. In this system, the
recorded EEG data are firstly preprocessed in the preprocessing unit.
Standardization and segmentation of EEG data are done in this unit. Then, the
resulting EEG data are passed to the compression unite. The compression unit
composes of a lossy compression algorithm followed by a lossless compression
algorithm. The lossy compression algorithm transforms the randomness EEG data
into data with high redundancy. Subsequently, A lossless compression algorithm
is added to investigate the high redundancy of the resulting data to get high
Compression Ratio (CR) without any additional loss. In this paper, the Discrete
Cosine Transform (DCT) and Discrete Wavelet Transform (DWT) are proposed as a
lossy compression algorithm. Furthermore, Arithmetic Encoding and Run Length
Encoding (RLE) are proposed as a lossless compression algorithm. We calculate
the total compression and reconstruction time (T), Root Mean Square Error
(RMSE), and CR in order to evaluate the proposed system. Simulation results
show that adding RLE after the DCT algorithm gives the best performance in
terms of compression ratio and complexity. Using the DCT as a lossy compression
algorithm followed by the RLE as a lossless compression algorithm gives CR=90%
at RMSE=0.14 and more than 95% of CR at RMSE=0.2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02793</identifier>
 <datestamp>2018-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02793</id><created>2018-04-08</created><authors><author><keyname>Davarikia</keyname><forenames>Hamzeh</forenames></author><author><keyname>Barati</keyname><forenames>Masoud</forenames></author><author><keyname>Znidi</keyname><forenames>Faycal</forenames></author><author><keyname>Iqbal</keyname><forenames>Kamran</forenames></author></authors><title>Real-Time Integrity Indices in Power Grid: A Synchronization Coefficient
  Based Clustering Approach</title><categories>eess.SP cs.SY</categories><report-no>Accepted in IEEE PES-GM 2018</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new methodology based on modularity clustering of
synchronization coefficient, to identify coherent groups of generators in the
power grid in real-time. The method uses real-time integrity indices, i.e., the
Generators Connectivity Index (GCI) that represents how generators are
coherently strong within the groups, the Generator Splitting Index (GSI) that
reveals to what extent the generators in different groups tend to swing against
the other groups, and the System Separation Index (SI) which discloses the
overall system separation status. We demonstrate how these integrity indices
can be used to study the dynamic behavior of the power system. Furthermore, a
comparison analysis is conducted between the synchronization coefficient (KS)
and the generator rotor angle correlation coefficient (CC). The proposed
indices demonstrate the dynamic behavior of power system following occurrence
the faults and thus represent a promising approach in power system islanding
studies. Our methodology is simple, fast, and computationally attractive.
Simulation case performed on IEEE 118-bus systems demonstrates the efficacy of
our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02812</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02812</id><created>2018-04-09</created><updated>2018-06-24</updated><authors><author><keyname>Chou</keyname><forenames>Ju-chieh</forenames></author><author><keyname>Yeh</keyname><forenames>Cheng-chieh</forenames></author><author><keyname>Lee</keyname><forenames>Hung-yi</forenames></author><author><keyname>Lee</keyname><forenames>Lin-shan</forenames></author></authors><title>Multi-target Voice Conversion without Parallel Data by Adversarially
  Learning Disentangled Audio Representations</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted to Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, cycle-consistent adversarial network (Cycle-GAN) has been
successfully applied to voice conversion to a different speaker without
parallel data, although in those approaches an individual model is needed for
each target speaker. In this paper, we propose an adversarial learning
framework for voice conversion, with which a single model can be trained to
convert the voice to many different speakers, all without parallel data, by
separating the speaker characteristics from the linguistic content in speech
signals. An autoencoder is first trained to extract speaker-independent latent
representations and speaker embedding separately using another auxiliary
speaker classifier to regularize the latent representation. The decoder then
takes the speaker-independent latent representation and the target speaker
embedding as the input to generate the voice of the target speaker with the
linguistic content of the source utterance. The quality of decoder output is
further improved by patching with the residual signal produced by another pair
of generator and discriminator. A target speaker set size of 20 was tested in
the preliminary experiments, and very good voice quality was obtained.
Conventional voice conversion metrics are reported. We also show that the
speaker information has been properly reduced from the latent representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02891</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02891</id><created>2018-04-09</created><authors><author><keyname>Dhabu</keyname><forenames>Sumedh</forenames></author><author><keyname>Ambede</keyname><forenames>Abhishek</forenames></author><author><keyname>G.</keyname><forenames>Smitha K.</forenames></author><author><keyname>and</keyname><forenames>Sumit Darak</forenames></author><author><keyname>Vinod</keyname><forenames>A. P.</forenames></author></authors><title>Variable Cutoff Frequency FIR Filters: A Survey</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many signal processing applications require digital filters with variable
frequency characteristics, especially the filters with variable bandwidth. Due
to their linear phase and inherent stability, variable bandwidth finite impulse
response (FIR) filters are the popular choice in majority of the applications.
Once a variable cutoff frequency (VCF) FIR lowpass filter is designed, variable
bandwidth bandpass / highpass / bandstop filters and reconfigurable filter
banks can be realized from the same. In this paper, we present a comprehensive
review of the existing variable cutoff frequency FIR filter design techniques,
including the developments in the recent two decades. We provide the basic
concepts, design and architectural details for each of these techniques and the
major developments / incremental works thereof. Qualitative as well as
quantitative comparisons are provided to assist the reader in choosing the most
suitable VCF filter design technique for a particular application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02918</identifier>
 <datestamp>2019-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02918</id><created>2018-04-09</created><updated>2019-03-18</updated><authors><author><keyname>Elowsson</keyname><forenames>Anders</forenames></author></authors><title>Polyphonic Pitch Tracking with Deep Layered Learning</title><categories>cs.SD eess.AS</categories><comments>This is a distilled version (14 pages) from my PhD thesis &quot;A.
  Elowsson; Modeling Music: Studies of Music Transcription, Music Perception
  and Music Production; 2018&quot;. This specific version added the learned active
  bin indices in the sparse kernel and the associated computed weights, which
  can be used to compute the Tentogram</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a polyphonic pitch tracking system able to extract both
framewise and note-based estimates from audio. The system uses several
artificial neural networks in a deep layered learning setup. First, cascading
networks are applied to a spectrogram for framewise fundamental frequency (f0)
estimation. A sparse receptive field is learned by the first network and then
used as a filter kernel for parameter sharing throughout the system. The f0
activations are connected across time to extract pitch contours. These contours
define a framework within which subsequent networks perform onset and offset
detection, operating across both time and smaller pitch fluctuations at the
same time. As input, the networks use, e.g., variations of latent
representations from the f0 estimation network. Finally, incorrect tentative
notes are removed one by one in an iterative procedure that allows a network to
classify notes within an accurate context. The system was evaluated on four
public test sets: MAPS, Bach10, TRIOS, and the MIREX Woodwind quintet, and
performed state-of-the-art results for all four datasets. It performs well
across all subtasks: f0, pitched onset, and pitched offset tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.02960</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.02960</id><created>2018-04-06</created><updated>2018-08-30</updated><authors><author><keyname>Gelmini</keyname><forenames>Simone</forenames></author><author><keyname>Strada</keyname><forenames>Silvia</forenames></author><author><keyname>Tanelli</keyname><forenames>Mara</forenames></author><author><keyname>Savaresi</keyname><forenames>Sergio</forenames></author><author><keyname>Biase</keyname><forenames>Vincenzo</forenames></author></authors><title>Analysis and development of a novel algorithm for the in-vehicle
  hand-usage of a smartphone</title><categories>cs.HC cs.LG eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Smartphone usage while driving is unanimously considered to be a really
dangerous habit due to strong correlation with road accidents. In this paper,
the problem of detecting whether the driver is using the phone during a trip is
addressed. To do this, high-frequency data from the triaxial inertial
measurement unit (IMU) integrated in almost all modern phone is processed
without relying on external inputs so as to provide a self-contained approach.
By resorting to a frequency-domain analysis, it is possible to extract from the
raw signals the useful information needed to detect when the driver is using
the phone, without being affected by the effects that vehicle motion has on the
same signals. The selected features are used to train a Support Vector Machine
(SVM) algorithm. The performance of the proposed approach are analyzed and
tested on experimental data collected during mixed naturalistic driving
scenarios, proving the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03000</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03000</id><created>2018-04-06</created><updated>2018-09-22</updated><authors><author><keyname>Shafipour</keyname><forenames>Rasoul</forenames></author><author><keyname>Khodabakhsh</keyname><forenames>Ali</forenames></author><author><keyname>Mateos</keyname><forenames>Gonzalo</forenames></author><author><keyname>Nikolova</keyname><forenames>Evdokia</forenames></author></authors><title>A Directed Graph Fourier Transform with Spread Frequency Components</title><categories>eess.SP</categories><comments>15 pages, 13 figures. arXiv admin note: text overlap with
  arXiv:1705.10821</comments><doi>10.1109/TSP.2018.2886151</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of constructing a graph Fourier transform (GFT) for
directed graphs (digraphs), which decomposes graph signals into different modes
of variation with respect to the underlying network. Accordingly, to capture
low, medium and high frequencies we seek a digraph (D)GFT such that the
orthonormal frequency components are as spread as possible in the graph
spectral domain. To that end, we advocate a two-step design whereby we: (i)
find the maximum directed variation (i.e., a novel notion of frequency on a
digraph) a candidate basis vector can attain; and (ii) minimize a smooth
spectral dispersion function over the achievable frequency range to obtain the
desired spread DGFT basis. Both steps involve non-convex,
orthonormality-constrained optimization problems, which are efficiently tackled
via a provably convergent, feasible optimization method on the Stiefel
manifold. We also propose a heuristic to construct the DGFT basis from
Laplacian eigen-vectors of an undirected version of the digraph. We show that
the spectral-dispersion minimization problem can be cast as supermodular
optimization over the set of candidate frequency components, whose
orthonormality can be enforced via a matroid basis constraint. This motivates
adopting a scalable greedy algorithm to obtain an approximate solution with
quantifiable worst-case spectral dispersion. We illustrate the effectiveness of
our DGFT algorithms through numerical tests on synthetic and real-world
networks. We also carry out a graph-signal denoising task, whereby the DGFT
basis is used to decompose and then low-pass filter temperatures recorded
across the United States.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03036</identifier>
 <datestamp>2018-04-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03036</id><created>2018-04-09</created><authors><author><keyname>Yao</keyname><forenames>Gang</forenames></author><author><keyname>Dani</keyname><forenames>Ashwin</forenames></author></authors><title>Image Moment Models for Extended Object Tracking</title><categories>eess.IV cs.RO cs.SY</categories><journal-ref>IEEE Transactions on Aerospace and Electronic Systems, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel image moments based model for shape estimation and
tracking of an object moving with a complex trajectory is presented. The camera
is assumed to be stationary looking at a moving object. Point features inside
the object are sampled as measurements. An ellipsoidal approximation of the
shape is assumed as a primitive shape. The shape of an ellipse is estimated
using a combination of image moments. Dynamic model of image moments when the
object moves under the constant velocity or coordinated turn motion model is
derived as a function for the shape estimation of the object. An Unscented
Kalman Filter-Interacting Multiple Model (UKF-IMM) filter algorithm is applied
to estimate the shape of the object (approximated as an ellipse) and track its
position and velocity. A likelihood function based on average log-likelihood is
derived for the IMM filter. Simulation results of the proposed UKF-IMM
algorithm with the image moments based models are presented that show the
estimations of the shape of the object moving in complex trajectories.
Comparison results, using intersection over union (IOU), and position and
velocity root mean square errors (RMSE) as metrics, with a benchmark algorithm
from literature are presented. Results on real image data captured from the
quadcopter are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03052</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03052</id><created>2018-04-09</created><authors><author><keyname>Harwath</keyname><forenames>David</forenames></author><author><keyname>Chuang</keyname><forenames>Galen</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Vision as an Interlingua: Learning Multilingual Semantic Embeddings of
  Untranscribed Speech</title><categories>cs.CL cs.SD eess.AS</categories><comments>to appear at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the learning of neural network embeddings for
natural images and speech waveforms describing the content of those images.
These embeddings are learned directly from the waveforms without the use of
linguistic transcriptions or conventional speech recognition technology. While
prior work has investigated this setting in the monolingual case using English
speech data, this work represents the first effort to apply these techniques to
languages beyond English. Using spoken captions collected in English and Hindi,
we show that the same model architecture can be successfully applied to both
languages. Further, we demonstrate that training a multilingual model
simultaneously on both languages offers improved performance over the
monolingual models. Finally, we show that these models are capable of
performing semantic cross-lingual speech-to-speech retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03068</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03068</id><created>2018-04-09</created><authors><author><keyname>Ferraris</keyname><forenames>Vinicius</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>Chabert</keyname><forenames>Marie</forenames></author></authors><title>Robust fusion algorithms for unsupervised change detection between
  multi-band optical images - A comprehensive case study</title><categories>eess.IV cs.CV physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised change detection techniques are generally constrained to two
multi-band optical images acquired at different times through sensors sharing
the same spatial and spectral resolution. This scenario is suitable for a
straight comparison of homologous pixels such as pixel-wise differencing.
However, in some specific cases such as emergency situations, the only
available images may be those acquired through different kinds of sensors with
different resolutions. Recently some change detection techniques dealing with
images with different spatial and spectral resolutions, have been proposed.
Nevertheless, they are focused on a specific scenario where one image has a
high spatial and low spectral resolution while the other has a low spatial and
high spectral resolution. This paper addresses the problem of detecting changes
between any two multi-band optical images disregarding their spatial and
spectral resolution disparities. We propose a method that effectively uses the
available information by modeling the two observed images as spatially and
spectrally degraded versions of two (unobserved) latent images characterized by
the same high spatial and high spectral resolutions. Covering the same scene,
the latent images are expected to be globally similar except for possible
changes in spatially sparse locations. Thus, the change detection task is
envisioned through a robust fusion task which enforces the differences between
the estimated latent images to be spatially sparse. We show that this robust
fusion can be formulated as an inverse problem which is iteratively solved
using an alternate minimization strategy. The proposed framework is implemented
for an exhaustive list of applicative scenarios and applied to real multi-band
optical images. A comparison with state-of-the-art change detection methods
evidences the accuracy of the proposed robust fusion-based strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03160</identifier>
 <datestamp>2018-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03160</id><created>2018-04-09</created><updated>2018-10-13</updated><authors><author><keyname>Zhao</keyname><forenames>Hang</forenames></author><author><keyname>Gan</keyname><forenames>Chuang</forenames></author><author><keyname>Rouditchenko</keyname><forenames>Andrew</forenames></author><author><keyname>Vondrick</keyname><forenames>Carl</forenames></author><author><keyname>McDermott</keyname><forenames>Josh</forenames></author><author><keyname>Torralba</keyname><forenames>Antonio</forenames></author></authors><title>The Sound of Pixels</title><categories>cs.CV cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce PixelPlayer, a system that, by leveraging large amounts of
unlabeled videos, learns to locate image regions which produce sounds and
separate the input sounds into a set of components that represents the sound
from each pixel. Our approach capitalizes on the natural synchronization of the
visual and audio modalities to learn models that jointly parse sounds and
images, without requiring additional manual supervision. Experimental results
on a newly collected MUSIC dataset show that our proposed Mix-and-Separate
framework outperforms several baselines on source separation. Qualitative
results suggest our model learns to ground sounds in vision, enabling
applications such as independently adjusting the volume of sound sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03179</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03179</id><created>2018-04-09</created><authors><author><keyname>Airod</keyname><forenames>Fatima Ezzahra</forenames></author><author><keyname>Chafnaji</keyname><forenames>Houda</forenames></author><author><keyname>Tamtaoui</keyname><forenames>Ahmed</forenames></author></authors><title>A Comparative Study of Full-Duplex Relaying Schemes for Low Latency
  Applications</title><categories>eess.SP cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various sectors are likely to carry a set of emerging applications while
targeting a reliable communication with low latency transmission. To address
this issue, upon a spectrally-efficient transmission, this paper investigates
the performance of a one full-dulpex (FD) relay system, and considers for that
purpose, two basic relaying schemes, namely the symbol-by-symbol transmission,
i.e., amplify-and-forward (AF) and the block-by-block transmission, i.e.,
selective decode-and-forward (SDF). The conducted analysis presents an
exhaustive comparison, covering both schemes, over two different transmission
modes, i.e., the non combining mode where the best link, direct or relay link
is decoded and the signals combining mode, where direct and relay links are
combined at the receiver side. While targeting latency purpose as a necessity,
simulations show a refined results of performed comparisons, and reveal that AF
relaying scheme is more adapted to combining mode, whereas the SDF relaying
scheme is more suitable for non combining mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03201</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03201</id><created>2018-04-09</created><updated>2018-06-15</updated><authors><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Scalable Factorized Hierarchical Variational Autoencoder Training</title><categories>stat.ML cs.CL cs.LG cs.SD eess.AS</categories><comments>Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep generative models have achieved great success in unsupervised learning
with the ability to capture complex nonlinear relationships between latent
generating factors and observations. Among them, a factorized hierarchical
variational autoencoder (FHVAE) is a variational inference-based model that
formulates a hierarchical generative process for sequential data. Specifically,
an FHVAE model can learn disentangled and interpretable representations, which
have been proven useful for numerous speech applications, such as speaker
verification, robust speech recognition, and voice conversion. However, as we
will elaborate in this paper, the training algorithm proposed in the original
paper is not scalable to datasets of thousands of hours, which makes this model
less applicable on a larger scale. After identifying limitations in terms of
runtime, memory, and hyperparameter optimization, we propose a hierarchical
sampling training algorithm to address all three issues. Our proposed method is
evaluated comprehensively on a wide variety of datasets, ranging from 3 to
1,000 hours and involving different types of generating factors, such as
recording conditions and noise types. In addition, we also present a new
visualization method for qualitatively evaluating the performance with respect
to the interpretability and disentanglement. Models trained with our proposed
algorithm demonstrate the desired characteristics on all the datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03225</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03225</id><created>2018-04-09</created><authors><author><keyname>Sheng</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author></authors><title>Applying Polynomial Chaos Expansion to Assess Probabilistic Available
  Delivery Capability for Distribution Networks with Renewables</title><categories>eess.SP</categories><comments>10 pages, 4 figures, journal paper accepted by IEEE Transactions on
  Power Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the increasing penetration of renewable energy sources and
electrical vehicles in utility distribution feeders, it is imperative to study
the impacts of the resulting increasing uncertainty on the delivery capability
of a distribution network. In this paper, probabilistic available delivery
capability (ADC) is formulated for a general distribution network integrating
various RES and load variations. To reduce the computational efforts by using
conventional Monte Carlo simulations, we develop and employ a computationally
efficient method to assess the probabilistic ADC, which combines the up-to-date
sparse polynomial chaos expansion (PCE) and the continuation method.
Particularly, the proposed method is able to handle a large number of
correlated random inputs with different marginal distributions. Numerical
examples in the IEEE 13 and IEEE 123 node test feeders are presented, showing
that the proposed method can achieve accuracy and efficiency simultaneously.
Numerical results also demonstrate that the randomness brought about by the RES
and loads indeed leads to a reduction in the delivery capability of a
distribution network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03282</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03282</id><created>2018-04-10</created><authors><author><keyname>Gheshlaghi</keyname><forenames>Saba Heidari</forenames></author><author><keyname>Madani</keyname><forenames>Abolfazl</forenames></author><author><keyname>Suratgar</keyname><forenames>AmirAbolfazl</forenames></author><author><keyname>Faraji</keyname><forenames>Fardin</forenames></author></authors><title>Segmentation of Multiple Sclerosis lesion in brain MR images using Fuzzy
  C-Means</title><categories>eess.IV cs.AI</categories><doi>10.5121/ijaia.2018.9203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance images (MRI) play an important role in supporting and
substituting clinical information in the diagnosis of multiple sclerosis (MS)
disease by presenting lesion in brain MR images. In this paper, an algorithm
for MS lesion segmentation from Brain MR Images has been presented. We revisit
the modification of properties of fuzzy -c means algorithms and the canny edge
detection. By changing and reformed fuzzy c-means clustering algorithms, and
applying canny contraction principle, a relationship between MS lesions and
edge detection is established. For the special case of FCM, we derive a
sufficient condition and clustering parameters, allowing identification of them
as (local) minima of the objective function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03295</identifier>
 <datestamp>2019-04-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03295</id><created>2018-04-09</created><updated>2019-03-29</updated><authors><author><keyname>Cuvelier</keyname><forenames>Travis</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>MmWave MU-MIMO for Aerial Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 4 figures, accepted at ISWCS Special Session 7:
  Vehicle-to-Everything (V2X) Communications. Small correction to equation (9)
  that I noticed after publication. Code available at:
  https://github.com/travisCuvelier/mmWaveAerialNetworks</comments><doi>10.1109/ISWCS.2018.8491045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave offers high bandwidth for air-to-air (A2A) communication. In
this paper, we evaluate the rate performance of a multiuser MIMO (MU-MIMO)
configuration where several aircraft communicate with a central hub. We
consider a hybrid subarray architecture, single path channels, and realistic
atmospheric attenuation effects. We propose a mathematical framework for the
analysis of millimeter wave (mmWave) MU-MIMO networks. Via Monte Carlo
simulation, we demonstrate that mmWave is a promising technology for delivering
gigabit connectivity in next-generation aerial networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03299</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03299</id><created>2018-04-09</created><authors><author><keyname>Eckert</keyname><forenames>Regina</forenames></author><author><keyname>Phillips</keyname><forenames>Zachary F.</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>Efficient illumination angle self-calibration in Fourier ptychography</title><categories>eess.SP</categories><comments>8 pages, 7 figures</comments><report-no>Vol. 57, Issue 19</report-no><journal-ref>Applied Optics, 2018</journal-ref><doi>10.1364/AO.57.005434</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier ptychography captures intensity images with varying source patterns
(illumination angles) in order to computationally reconstruct large
space-bandwidth-product images. Accurate knowledge of the illumination angles
is necessary for good image quality; hence, calibration methods are crucial,
despite often being impractical or slow. Here, we propose a fast, robust, and
accurate self-calibration algorithm that uses only experimentally-collected
data and general knowledge of the illumination setup. First, our algorithm
makes a direct estimate of the brightfield illumination angles based on image
processing. Then, a more computationally-intensive spectral correlation method
is used inside the iterative solver to further refine the angle estimates of
both brightfield and darkfield images. We demonstrate our method for correcting
large and small misalignment artifacts in both 2D and 3D Fourier ptychography
with different source types: an LED array, a galvo-steered laser, and a high-NA
quasi-dome LED illuminator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03370</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03370</id><created>2018-04-10</created><authors><author><keyname>Kingston</keyname><forenames>Andrew M.</forenames></author><author><keyname>Myers</keyname><forenames>Glenn R.</forenames></author><author><keyname>Pelliccia</keyname><forenames>Daniele</forenames></author><author><keyname>Svalbe</keyname><forenames>Imants D.</forenames></author><author><keyname>Paganin</keyname><forenames>David M.</forenames></author></authors><title>X-ray ghost tomography: denoising, dose fractionation and mask
  considerations</title><categories>eess.IV physics.med-ph</categories><journal-ref>IEEE Transactions on Computational Imaging 5, 136-149 (2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ghost imaging has recently been successfully achieved in the X-ray regime;
due to the penetrating power of X-rays this immediately opens up the
possibility of X-ray ghost tomography. No research into this topic currently
exists in the literature. Here we present adaptations of conventional
tomography techniques to this new ghost imaging scheme. Several numerical
implementations for tomography through X-ray ghost imaging are considered.
Specific attention is paid to schemes for denoising of the resulting
tomographic reconstruction, issues related to dose fractionation, and
considerations regarding the ensemble of illuminating masks used for ghost
imaging. Each theme is explored through a series of numerical simulations, and
several suggestions offered for practical realisations of X-ray ghost
tomography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03372</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03372</id><created>2018-04-10</created><authors><author><keyname>Gala</keyname><forenames>Deepak</forenames></author><author><keyname>Lindsay</keyname><forenames>Nathan</forenames></author><author><keyname>Sun</keyname><forenames>Liang</forenames></author></authors><title>Realtime Active Sound Source Localization for Unmanned Ground Robots
  Using a Self-Rotational Bi-Microphone Array</title><categories>cs.SD cs.RO eess.AS eess.SP</categories><comments>The paper is under revision for 'Journal of Intelligent &amp; Robotic
  Systems'</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a novel technique that performs both orientation and
distance localization of a sound source in a three-dimensional (3D) space using
only the interaural time difference (ITD) cue, generated by a newly-developed
self-rotational bi-microphone robotic platform. The system dynamics is
established in the spherical coordinate frame using a state-space model. The
observability analysis of the state-space model shows that the system is
unobservable when the sound source is placed with elevation angles of $90$ and
$0$ degree. The proposed method utilizes the difference between the azimuth
estimates resulting from respectively the 3D and the two-dimensional models to
check the zero-degree-elevation condition and further estimates the elevation
angle using a polynomial curve fitting approach. Also, the proposed method is
capable of detecting a $90$-degree elevation by extracting the zero-ITD signal
'buried' in noise. Additionally, a distance localization is performed by first
rotating the microphone array to face toward the sound source and then shifting
the microphone perpendicular to the source-robot vector by a predefined
distance of a fixed number of steps. The integrated rotational and
translational motions of the microphone array provide a complete orientation
and distance localization using only the ITD cue. A novel robotic platform
using a self-rotational bi-microphone array was also developed for unmanned
ground robots performing sound source localization. The proposed technique was
first tested in simulation and was then verified on the newly-developed robotic
platform. Experimental data collected by the microphones installed on a KEMAR
dummy head were also used to test the proposed technique. All results show the
effectiveness of the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03403</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03403</id><created>2018-04-10</created><authors><author><keyname>Dechouniotis</keyname><forenames>Dimitrios</forenames></author><author><keyname>Ifantis</keyname><forenames>Apostolos</forenames></author></authors><title>A Linear Modeling Approach on LTGP Signals and Seismic Activity</title><categories>eess.SP physics.geo-ph</categories><journal-ref>International Journal of Chaos, Control, Modelling and Simulation,
  March 2018, Volume 7, Number 1</journal-ref><doi>10.5121/ijccms.2018.7101</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This study illustrates presents a set of the Long-Term Geoelectric Potential
(LTGP) measurements that are collected for experimental investigation in
Western Greece during a five-year period (1993-1997). During this period, many
major destructive earthquake events occurred that caused human casualties and
extended material damages. The collection and processing of geoelectric
measurements was done by an automated data acquisition system at the
Seismological Laboratory of the University of Patras, Greece. This novel study
considers seismic activity of this area as a typical linear dynamic system and
the dynamic relationship between the magnitude of earthquakes and Long-Term
Geoelectric Potential signals is inferred by the Recursive Least Square
algorithm. The results are encouraging and show that linear dynamic systems,
which are widely used in modern control theory, can describe efficiently the
dynamic behavior of seismic activity and become a useful interpretative tool of
seismic phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03417</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03417</id><created>2018-04-10</created><authors><author><keyname>Z&#xf6;chmann</keyname><forenames>Erich</forenames></author><author><keyname>Caban</keyname><forenames>Sebastian</forenames></author><author><keyname>Mecklenbr&#xe4;uker</keyname><forenames>Christoph F.</forenames></author><author><keyname>Pratschner</keyname><forenames>Stefan</forenames></author><author><keyname>Lerch</keyname><forenames>Martin</forenames></author><author><keyname>Schwarz</keyname><forenames>Stefan</forenames></author><author><keyname>Rupp</keyname><forenames>Markus</forenames></author></authors><title>Better than Rician: Modelling millimetre wave channels as Two-Wave with
  Diffuse Power</title><categories>eess.SP physics.data-an</categories><comments>submitted to Eurasip Journal on Wireless Communications and
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution provides experimental evidence for the two-wave with
diffuse power (TWDP) fading model. We have conducted two indoor millimetre wave
measurement campaigns with directive horn antennas at both link ends. One horn
antenna is mounted in a corner of our laboratory, while the other is steerable
and scans azimuth and elevation. Our first measurement campaign is based on
scalar network analysis with 7 GHz of bandwidth. Our second measurement
campaign obtains magnitude and phase information, additionally sampled
directionally at several positions in space. %This second measurement campaign
is limited to 2 GHz bandwidth. We apply Akaike's information criterion to
decide whether Rician fading sufficiently explains the data or the generalized
TWDP fading model is necessary. Our results indicate that the TWDP fading
hypothesis is favoured over Rician fading in situations where the steerable
antenna is pointing towards reflecting objects or is slightly misaligned at
line-of-sight. We demonstrate TWDP fading in several different domains, namely,
frequency, space, and time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03421</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03421</id><created>2018-04-10</created><updated>2019-09-06</updated><authors><author><keyname>Interdonato</keyname><forenames>Giovanni</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Frenger</keyname><forenames>P&#xe5;l</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Ubiquitous Cell-Free Massive MIMO Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>Published in EURASIP Journal on Wireless Communications and
  Networking on August 5, 2019</comments><doi>10.1186/s13638-019-1507-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the first cellular networks were trialled in the 1970s, we have
witnessed an incredible wireless revolution. From 1G to 4G, the massive traffic
growth has been managed by a combination of wider bandwidths, refined radio
interfaces, and network densification, namely increasing the number of antennas
per site. Due its cost-efficiency, the latter has contributed the most. Massive
MIMO (multiple-input multiple-output) is a key 5G technology that uses massive
antenna arrays to provide a very high beamforming gain and spatially
multiplexing of users, and hence, increases the spectral and energy efficiency.
It constitutes a centralized solution to densify a network, and its performance
is limited by the inter-cell interference inherent in its cell-centric design.
Conversely, ubiquitous cell-free Massive MIMO refers to a distributed Massive
MIMO system implementing coherent user-centric transmission to overcome the
inter-cell interference limitation in cellular networks and provide additional
macro-diversity. These features, combined with the system scalability inherent
in the Massive MIMO design, distinguishes ubiquitous cell-free Massive MIMO
from prior coordinated distributed wireless systems. In this article, we
investigate the enormous potential of this promising technology while
addressing practical deployment issues to deal with the increased
back/front-hauling overhead deriving from the signal co-processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03505</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03505</id><created>2018-04-06</created><authors><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Angular and Temporal Correlation of V2X Channels Across Sub-6 GHz and
  mmWave Bands</title><categories>eess.SP cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G millimeter wave (mmWave) technology is envisioned to be an integral part
of next-generation vehicle-to-everything (V2X) networks and autonomous vehicles
due to its broad bandwidth, wide field of view sensing, and precise
localization capabilities. The reliability of mmWave links may be compromised
due to difficulties in beam alignment for mobile channels and due to blocking
effects between a mmWave transmitter and a receiver. To address such
challenges, out-of-band information from sub-6 GHz channels can be utilized for
predicting the temporal and angular channel characteristics in mmWave bands,
which necessitates a good understanding of how propagation characteristics are
coupled across different bands. In this paper, we use ray tracing simulations
to characterize the angular and temporal correlation across a wide range of
propagation frequencies for V2X channels ranging from 900 MHz up to 73 GHz, for
a vehicle maintaining line-of-sight (LOS) and non-LOS (NLOS) beams with a
transmitter in an urban environment. Our results shed light on increasing
sparsity behavior of propagation channels with increasing frequency and
highlight the strong temporal/angular correlation among 5.9 GHz and 28 GHz
bands especially for LOS channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03512</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03512</id><created>2018-04-03</created><authors><author><keyname>Tao</keyname><forenames>Qin</forenames></author><author><keyname>Zhong</keyname><forenames>Caijun</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author></authors><title>Symbol Detection of Ambient Backscatter Systems with Manchester Coding</title><categories>eess.SP cs.PF</categories><comments>accepted by IEEE transaction on wireless communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ambient backscatter communication is a newly emerged paradigm, which utilizes
the ambient radio frequency (RF) signal as the carrier to reduce the system
battery requirement, and is regarded as a promising solution for enabling large
scale deployment of future Internet of Things (IoT) networks. The key issue of
ambient backscatter communication systems is how to perform reliable detection.
In this paper, we propose novel encoding methods at the information tag, and
devise the corresponding symbol detection methods at the reader. In particular,
Manchester coding and differential Manchester coding are adopted at the
information tag, and the corresponding semi-coherent Manchester (SeCoMC) and
non-coherent Manchester (NoCoMC) detectors are developed. In addition,
analytical bit error rate (BER) expressions are characterized for both
detectors assuming either complex Gaussian or unknown deterministic ambient
signal. Simulation results show that the BER performance of unknown
deterministic ambient signal is better, and the SeCoMC detector outperforms the
NoCoMC detector. Finally, compared with the prior detectors for ambient
backscatter communications, the proposed detectors have the advantages of
achieving superior BER performance with lower communication delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03517</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03517</id><created>2018-04-03</created><authors><author><keyname>Chen</keyname><forenames>Tao</forenames></author><author><keyname>Yuan</keyname><forenames>Chen</forenames></author><author><keyname>Liu</keyname><forenames>Guangyi</forenames></author><author><keyname>Dai</keyname><forenames>Renchang</forenames></author></authors><title>Graph based Platform for Electricity Market Study, Education and
  Training</title><categories>eess.SP cs.HC math.OC</categories><comments>To be published (Accepted) in: Proceedings of the Power and Energy
  Society General Meeting (PESGM), Portland, OR, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the further development of deregulated electricity market in many other
countries around the world, a lot of challenges have been identified for market
data management, network topology processing and fast market-clearance
mechanism design. In this paper, a graph computing framework based on
TigerGraph database is proposed to solve a security constrained unit commitment
(SCUC) and security constrained economic dispatch (SCED) problem, with
parallelized graph power flow (PGPF) and innovative LU decomposition
techniques, for electricity market-clearance. It also provides a comprehensive
visualization platform to demonstrate the market clearing results vividly, such
as locational marginal price (LMP), and is able to be utilized for electricity
market operators' education and training purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03529</identifier>
 <datestamp>2019-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03529</id><created>2018-04-10</created><updated>2019-04-10</updated><authors><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Kong</keyname><forenames>Linglin</forenames></author></authors><title>Resource Allocation Algorithm for V2X communications based on SCMA</title><categories>eess.SP</categories><comments>This paper was accepted for CSPS 2017 in Harbin, China</comments><doi>10.1007/978-981-10-6571-2_243</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we propose a resource allocation algorithm for V2X
communications based on Sparse Code Multiple Access(SCMA). By analyzing the
interference model in the V2X scenario, we formulate the problem which deals
with resource allocation to maximize the system throughput. A graph color-based
user cluster algorithm combined with resource allocation algorithm based on
both result of clustering and SINR is presented to solve the problem. The
simulation results indicate that the throughput performance of system based on
SCMA is superior to which based on OFDMA, and the proposed algorithm can
improve the system throughput and the number of access users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03541</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03541</id><created>2018-04-10</created><authors><author><keyname>Han</keyname><forenames>Kaifeng</forenames></author><author><keyname>Ko</keyname><forenames>Seung-Woo</forenames></author><author><keyname>Chae</keyname><forenames>Hyukjin</forenames></author><author><keyname>Kim</keyname><forenames>Byoung-Hoon</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>Sensing Hidden Vehicles by Exploiting Multi-Path V2V Transmission</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a technology of sensing hidden vehicles by exploiting
multi-path vehicle-to-vehicle (V2V) communication. This overcomes the
limitation of existing RADAR technologies that requires line-of-sight (LoS),
thereby enabling more intelligent manoeuvre in autonomous driving and improving
its safety. The proposed technology relies on transmission of orthogonal
waveforms over different antennas at the target (hidden) vehicle. Even without
LoS, the resultant received signal enables the sensing vehicle to detect the
position, shape, and driving direction of the hidden vehicle by jointly
analyzing the geometry (AoA/AoD/propagation distance) of individual propagation
path. The accuracy of the proposed technique is validated by realistic
simulation including both highway and rural scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03618</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03618</id><created>2018-04-10</created><authors><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author></authors><title>On the Regimes in Millimeter wave Networks: Noise-limited or
  Interference-limited?</title><categories>eess.SP</categories><comments>This paper has been accepted for publication in ICC workshop 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the overcrowding in the 300 MHz-3 GHz spectrum, millimeter wave
(mmWave) spectrum is a promising candidate for the future generations of
wireless networks. With the unique propagation characteristics at mmWave
frequencies, one of the fundamental questions to address is whether mmWave
networks are noise or interference-limited. The regime in which the network
operates significantly impacts the MAC layer design, resource allocation
procedure and also interference management techniques. In this paper, we first
derive the statistical characteristic of the cumulative interference in
finite-sized mmWave networks considering configuration randomness across
spatial and spectral domains while including the effect of blockages.
Subsequently, using the derived interference model we set up a likelihood ratio
test (LRT) (that is dependent on various network parameters) in order to detect
the regime of the network from an arbitrarily located user standpoint. Unlike
traditional networks, in mmWave networks, different likelihood of experiencing
an interference-limited regime can be observed at different locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03619</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03619</id><created>2018-04-10</created><updated>2018-08-09</updated><authors><author><keyname>Ephrat</keyname><forenames>Ariel</forenames></author><author><keyname>Mosseri</keyname><forenames>Inbar</forenames></author><author><keyname>Lang</keyname><forenames>Oran</forenames></author><author><keyname>Dekel</keyname><forenames>Tali</forenames></author><author><keyname>Wilson</keyname><forenames>Kevin</forenames></author><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author><author><keyname>Freeman</keyname><forenames>William T.</forenames></author><author><keyname>Rubinstein</keyname><forenames>Michael</forenames></author></authors><title>Looking to Listen at the Cocktail Party: A Speaker-Independent
  Audio-Visual Model for Speech Separation</title><categories>cs.SD cs.CV eess.AS</categories><comments>Accepted to SIGGRAPH 2018. Project webpage:
  https://looking-to-listen.github.io</comments><journal-ref>ACM Trans. Graph. 37(4): 112:1-112:11 (2018)</journal-ref><doi>10.1145/3197517.3201357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a joint audio-visual model for isolating a single speech signal
from a mixture of sounds such as other speakers and background noise. Solving
this task using only audio as input is extremely challenging and does not
provide an association of the separated speech signals with speakers in the
video. In this paper, we present a deep network-based model that incorporates
both visual and auditory signals to solve this task. The visual features are
used to &quot;focus&quot; the audio on desired speakers in a scene and to improve the
speech separation quality. To train our joint audio-visual model, we introduce
AVSpeech, a new dataset comprised of thousands of hours of video segments from
the Web. We demonstrate the applicability of our method to classic speech
separation tasks, as well as real-world scenarios involving heated interviews,
noisy bars, and screaming children, only requiring the user to specify the face
of the person in the video whose speech they want to isolate. Our method shows
clear advantage over state-of-the-art audio-only speech separation in cases of
mixed speech. In addition, our model, which is speaker-independent (trained
once, applicable to any speaker), produces better results than recent
audio-visual speech separation methods that are speaker-dependent (require
training a separate model for each speaker of interest).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03641</identifier>
 <datestamp>2018-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03641</id><created>2018-04-10</created><updated>2018-10-09</updated><authors><author><keyname>Owens</keyname><forenames>Andrew</forenames></author><author><keyname>Efros</keyname><forenames>Alexei A.</forenames></author></authors><title>Audio-Visual Scene Analysis with Self-Supervised Multisensory Features</title><categories>cs.CV cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The thud of a bouncing ball, the onset of speech as lips open -- when visual
and audio events occur together, it suggests that there might be a common,
underlying event that produced both signals. In this paper, we argue that the
visual and audio components of a video signal should be modeled jointly using a
fused multisensory representation. We propose to learn such a representation in
a self-supervised way, by training a neural network to predict whether video
frames and audio are temporally aligned. We use this learned representation for
three applications: (a) sound source localization, i.e. visualizing the source
of sound in a video; (b) audio-visual action recognition; and (c) on/off-screen
audio source separation, e.g. removing the off-screen translator's voice from a
foreign official's speech. Code, models, and video results are available on our
webpage: http://andrewowens.com/multisensory
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03847</identifier>
 <datestamp>2018-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03847</id><created>2018-04-11</created><authors><author><keyname>Bariah</keyname><forenames>Lina</forenames></author><author><keyname>Al-Dweik</keyname><forenames>Arafat</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author></authors><title>On the Performance of Non-Orthogonal Multiple Access Systems with
  Imperfect Successive Interference Cancellation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) technique has sparked a growing
research interest due to its ability to enhance the overall spectral efficiency
of wireless systems. In this paper, we investigate the pairwise error
probability (PEP) performance of conventional NOMA systems, where an exact
closed form expression for the PEP is derived for different users, to give some
insight about the reliability of the far and near users. Through the derivation
of PEP expressions, we demonstrate that the maximum achievable diversity order
is proportional to the user's order. The obtained error probability expressions
are used to formulate an optimization problem that minimizes the overall bit
error rate (BER) under power and error rate threshold constrains. The derived
analytical results, corroborated by Monte Carlo simulations, are presented to
show the diversity order and error rate performance of each individual user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03932</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03932</id><created>2018-04-11</created><updated>2018-12-31</updated><authors><author><keyname>Vilni</keyname><forenames>Saeed Sadeghi</forenames></author></authors><title>Cooperative Energy Efficient Power Allocation Algorithm for downlink
  massive MIMO</title><categories>eess.SP cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper power allocation in a cellular network, which transmitter uses
massive multiple inputs multiple outputs (MIMO) system was studied. As circuit
power consumption is increased by the number of antenna in transmitter and
users, thus, to analyze the performance of the network, energy efficiency
objective function with considering circuit power consumption was selected. An
energy efficiency optimization problem under both maximum transmit power and
quality of service (QoS) constraints was considered. To solve this problem
under cooperation between users and their base station (BS), energy efficient
power allocation algorithm was proposed. In numerical result convergence of the
algorithm was shown, also the appropriate number of transmit antenna and users
were obtained. Finally, pilot contamination effect was evaluated, where it
showed energy efficiency fell down dramatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03961</identifier>
 <datestamp>2018-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03961</id><created>2018-04-11</created><authors><author><keyname>Carrera</keyname><forenames>Jose Luis V.</forenames></author><author><keyname>Zhao</keyname><forenames>Zhongliang</forenames></author><author><keyname>Braun</keyname><forenames>Torsten</forenames></author><author><keyname>Luo</keyname><forenames>Haiyong</forenames></author><author><keyname>Zhao</keyname><forenames>Fang</forenames></author></authors><title>Discriminative Learning-based Smartphone Indoor Localization</title><categories>cs.NI eess.SP</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the growing area of ubiquitous mobile applications, indoor
localization of smartphones has become an interesting research topic. Most of
the current indoor localization systems rely on intensive site survey to
achieve high accuracy. In this work, we propose an efficient smartphones indoor
localization system that is able to reduce the site survey effort while still
achieving high localization accuracy. Our system is built by fusing a variety
of signals, such as Wi-Fi received signal strength indicator, magnetic field
and floor plan information in an enhanced particle filter. To achieve high and
stable performance, we first apply discriminative learning models to integrate
Wi-Fi and magnetic field readings to achieve room level landmark detection.
Further, we integrate landmark detection, range-based localization models, with
a graph-based discretized system state representation. Because our approach
requires only discriminative learning-based room level landmark detections, the
time spent in the learning phase is significantly reduced compared to
traditional Wi-Fi fingerprinting or landmark-based approaches. We conduct
experimental studies to evaluate our system in an office-like indoor
environment. Experiment results show that our system can significantly reduce
the learning efforts, and the localization method can achieve performance with
an average localization error of 1.55 meters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.03990</identifier>
 <datestamp>2018-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.03990</id><created>2018-04-05</created><authors><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Ren</keyname><forenames>Hong</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Robust Beamforming Design for Ultra-dense User-Centric C-RAN in the Face
  of Realistic Pilot Contamination and Limited Feedback</title><categories>eess.SP</categories><comments>Under revision in IEEE TWC</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The ultra-dense cloud radio access network (UD-CRAN), in which remote radio
heads (RRHs) are densely deployed in the network, is considered. To reduce the
channel estimation overhead, we focus on the design of robust transmit
beamforming for user-centric frequency division duplex (FDD) UD-CRANs, where
only limited channel state information (CSI) is available. Specifically, we
conceive a complete procedure for acquiring the CSI that includes two key
steps: channel estimation and channel quantization. The phase ambiguity (PA) is
also quantized for coherent cooperative transmission. Based on the imperfect
CSI, we aim for optimizing the beamforming vectors in order to minimize the
total transmit power subject to users' rate requirements and fronthaul capacity
constraints. We derive the closed-form expression of the achievable data rate
by exploiting the statistical properties of multiple uncertain terms. Then, we
propose a low-complexity iterative algorithm for solving this problem based on
the successive convex approximation technique. In each iteration, the Lagrange
dual decomposition method is employed for obtaining the optimal beamforming
vector. Furthermore, a pair of low-complexity user selection algorithms are
provided to guarantee the feasibility of the problem. Simulation results
confirm the accuracy of our robust algorithm in terms of meeting the rate
requirements. Finally, our simulation results verify that using a single bit
for quantizing the PA is capable of achieving good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04000</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04000</id><created>2018-04-10</created><updated>2018-09-27</updated><authors><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Chan</keyname><forenames>Raymond</forenames></author><author><keyname>Nikolova</keyname><forenames>Mila</forenames></author><author><keyname>Plemmons</keyname><forenames>Robert</forenames></author><author><keyname>Prasad</keyname><forenames>Sudhakar</forenames></author></authors><title>Non-convex optimization for 3D point source localization using a
  rotating point spread function</title><categories>eess.SP</categories><comments>28 pages</comments><journal-ref>SIAM J. Imaging Sci. 2019</journal-ref><doi>10.1137/18M1178566</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the high-resolution imaging problem of 3D point source image
recovery from 2D data using a method based on point spread function (PSF)
engineering. The method involves a new technique, recently proposed by
S.~Prasad, based on the use of a rotating PSF with a single lobe to obtain
depth from defocus. The amount of rotation of the PSF encodes the depth
position of the point source. Applications include high-resolution single
molecule localization microscopy as well as the problem addressed in this paper
on localization of space debris using a space-based telescope. The localization
problem is discretized on a cubical lattice where the coordinates of nonzero
entries represent the 3D locations and the values of these entries the fluxes
of the point sources. Finding the locations and fluxes of the point sources is
a large-scale sparse 3D inverse problem. A new nonconvex regularization method
with a data-fitting term based on Kullback-Leibler (KL) divergence is proposed
for 3D localization for the Poisson noise model. In addition, we propose a new
scheme of estimation of the source fluxes from the KL data-fitting term.
Numerical experiments illustrate the efficiency and stability of the algorithms
that are trained on a random subset of image data before being applied to other
images. Our 3D localization algorithms can be readily applied to other kinds of
depth-encoding PSFs as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04112</identifier>
 <datestamp>2018-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04112</id><created>2018-04-11</created><authors><author><keyname>Gante</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Falc&#xe3;o</keyname><forenames>Gabriel</forenames></author><author><keyname>Sousa</keyname><forenames>Leonel</forenames></author></authors><title>Beamformed Fingerprint Learning for Accurate Millimeter Wave Positioning</title><categories>eess.SP cs.CV stat.ML</categories><comments>5 pages, 7 figures. Submitted to VTC2018-Fall (Chicago)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With millimeter wave wireless communications, the resulting radiation
reflects on most visible objects, creating rich multipath environments, namely
in urban scenarios. The radiation captured by a listening device is thus shaped
by the obstacles encountered, which carry latent information regarding their
relative positions. In this paper, a system to convert the received millimeter
wave radiation into the device's position is proposed, making use of the
aforementioned hidden information. Using deep learning techniques and a
pre-established codebook of beamforming patterns transmitted by a base station,
the simulations show that average estimation errors below 10 meters are
achievable in realistic outdoors scenarios that contain mostly
non-line-of-sight positions, paving the way for new positioning systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04203</identifier>
 <datestamp>2018-04-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04203</id><created>2018-04-11</created><authors><author><keyname>Cheng</keyname><forenames>Nan</forenames><affiliation>Sherman</affiliation></author><author><keyname>Lyu</keyname><forenames>Feng</forenames><affiliation>Sherman</affiliation></author><author><keyname>Chen</keyname><forenames>Jiayin</forenames><affiliation>Sherman</affiliation></author><author><keyname>Xu</keyname><forenames>Wenchao</forenames><affiliation>Sherman</affiliation></author><author><keyname>Zhou</keyname><forenames>Haibo</forenames><affiliation>Sherman</affiliation></author><author><keyname>Zhang</keyname><forenames>Shan</forenames><affiliation>Sherman</affiliation></author><author><keyname>Xuemin</keyname><affiliation>Sherman</affiliation></author><author><keyname>Shen</keyname></author></authors><title>Big Data Driven Vehicular Networks</title><categories>eess.SP</categories><comments>Accepted by IEEE Network Magazine. 5 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular communications networks (VANETs) enable information exchange among
vehicles, other end devices and public networks, which plays a key role in road
safety/infotainment, intelligent transportation system, and self-driving
system. As the vehicular connectivity soars, and new on-road mobile
applications and technologies emerge, VANETs are generating an ever-increasing
amount of data, requiring fast and reliable transmissions through VANETs. On
the other hand, a variety of VANETs related data can be analyzed and utilized
to improve the performance of VANETs. In this article, we first review the
VANETs technologies to efficiently and reliably transmit the big data. Then,
the methods employing big data for studying VANETs characteristics and
improving VANETs performance are discussed. Furthermore, we present a case
study where machine learning schemes are applied to analyze the VANETs
measurement data for efficiently detecting negative communication conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04262</identifier>
 <datestamp>2018-04-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04262</id><created>2018-04-11</created><authors><author><keyname>Lorenzo-Trueba</keyname><forenames>Jaime</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author><author><keyname>Saito</keyname><forenames>Daisuke</forenames></author><author><keyname>Villavicencio</keyname><forenames>Fernando</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author><author><keyname>Ling</keyname><forenames>Zhenhua</forenames></author></authors><title>The Voice Conversion Challenge 2018: Promoting Development of Parallel
  and Nonparallel Methods</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>Accepted for Speaker Odyssey 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the Voice Conversion Challenge 2018, designed as a follow up to
the 2016 edition with the aim of providing a common framework for evaluating
and comparing different state-of-the-art voice conversion (VC) systems. The
objective of the challenge was to perform speaker conversion (i.e. transform
the vocal identity) of a source speaker to a target speaker while maintaining
linguistic information. As an update to the previous challenge, we considered
both parallel and non-parallel data to form the Hub and Spoke tasks,
respectively. A total of 23 teams from around the world submitted their
systems, 11 of them additionally participated in the optional Spoke task. A
large-scale crowdsourced perceptual evaluation was then carried out to rate the
submitted converted speech in terms of naturalness and similarity to the target
speaker identity. In this paper, we present a brief summary of the
state-of-the-art techniques for VC, followed by a detailed explanation of the
challenge tasks and the results that were obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04267</identifier>
 <datestamp>2019-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04267</id><created>2018-04-11</created><updated>2019-01-02</updated><authors><author><keyname>Vilni</keyname><forenames>Saeed Sadeghi</forenames></author></authors><title>Energy Efficient Distributed Worst Case Robust Power Allocation in
  Massive MIMO</title><categories>eess.SP cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes an energy efficient distributed worst case robust power
allocation in massive multiple input multiple output (MIMO) system. We assume a
bounded channel state information (CSI) error and all channels lie in some
bounded uncertainty region. The problem is formulated as max-min one with
infinite constraint. At first, we solve the inner problem with triangle and
Cauchy-Schwarz inequality, then by fractional programming and successive convex
approximation (SCA) technique problem transfers to a convex optimization.
Finally closed form transmit power is obtained with distribution way.
Simulation results demonstrate proposed algorithm convergence and validate
robust power allocation. Also, the appropriate number of transmit antenna to
have maximum energy efficiency in simulation result is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04335</identifier>
 <datestamp>2018-04-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04335</id><created>2018-04-12</created><authors><author><keyname>Au-Yeung</keyname><forenames>Enrico</forenames></author></authors><title>Sparse Reconstruction with Multiple Walsh matrices</title><categories>math.FA eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of how to find a sparse representation of a signal is an
important one in applied and computational harmonic analysis. It is closely
related to the problem of how to reconstruct a sparse vector from its
projection in a much lower-dimensional vector space. This is the setting of
compressed sensing, where the projection is given by a matrix with many more
columns than rows. We introduce a class of random matrices that can be used to
reconstruct sparse vectors in this paradigm. These matrices satisfy the
restricted isometry property with overwhelming probability. We also discuss an
application in dimensionality reduction where we initially discovered this
class of matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04353</identifier>
 <datestamp>2018-04-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04353</id><created>2018-04-12</created><authors><author><keyname>Aralikatti</keyname><forenames>Rohith</forenames></author><author><keyname>Margam</keyname><forenames>Dilip</forenames></author><author><keyname>Sharma</keyname><forenames>Tanay</forenames></author><author><keyname>Abhinav</keyname><forenames>Thanda</forenames></author><author><keyname>Venkatesan</keyname><forenames>Shankar M</forenames></author></authors><title>Global SNR Estimation of Speech Signals using Entropy and Uncertainty
  Estimates from Dropout Networks</title><categories>eess.AS cs.AI eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates two novel methods to estimate the global SNR of
speech signals. In both methods, Deep Neural Network-Hidden Markov Model
(DNN-HMM) acoustic model used in speech recognition systems is leveraged for
the additional task of SNR estimation. In the first method, the entropy of the
DNN-HMM output is computed. Recent work on bayesian deep learning has shown
that a DNN-HMM trained with dropout can be used to estimate model uncertainty
by approximating it as a deep Gaussian process. In the second method, this
approximation is used to obtain model uncertainty estimates. Noise specific
regressors are used to predict the SNR from the entropy and model uncertainty.
The DNN-HMM is trained on GRID corpus and tested on different noise profiles
from the DEMAND noise database at SNR levels ranging from -10 dB to 30 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04431</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04431</id><created>2018-04-12</created><updated>2018-12-26</updated><authors><author><keyname>Guo</keyname><forenames>Shuaishuai</forenames></author><author><keyname>Park</keyname><forenames>Ki-Hong</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Ordered Sequence Detection and Barrier Signal Design for Digital Pulse
  Interval Modulation in Optical Wireless Communications</title><categories>eess.SP</categories><comments>Digital pulse interval modulation, ordered sequence detection, signal
  design, error propagation, bit error rate</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an ordered sequence detection (OSD) for digital pulse
interval modulation (DPIM) in optical wireless communications. Leveraging the
sparsity of DPIM sequences, OSD shows comparable performance to the optimal
maximum likelihood sequence detection (MLSD) with much lower complexity.
Compared with the widely adopted sample-by-sample optimal threshold detection
(OTD), it considerably improves the bit error rate (BER) performance by
mitigating error propagation. Moreover, this paper proposes a barrier
signal-aided digital pulse interval modulation (BDPIM), where the last of every
$K$ symbols is allocated with more power as an inserted barrier signal. BDPIM
with OSD (BDPIM-OSD) can limit the error propagation between two adjacent
barriers. To reduce the storing delay when using OSD to detect extremely large
packets, we propose BDPIM with a combination of OTD and OSD (BDPIM-OTD-OSD),
within which long sequences are cut into pieces and separately detected.
Approximate upper bounds of the average BER performance of DPIM-OTD, DPIM-OSD,
BDPIM-OSD and BDPIM-OTD-OSD are analyzed. Simulations are conducted to
corroborate our analysis. Optimal parameter settings are also investigated in
uncoded and coded systems by simulations. Simulation results show that the
proposed OSD and BDPIM bring significant improvement in uncoded and coded
systems over various channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04460</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04460</id><created>2018-04-12</created><updated>2018-12-07</updated><authors><author><keyname>Chen</keyname><forenames>Peng</forenames></author><author><keyname>Cao</keyname><forenames>Zhenxin</forenames></author><author><keyname>Chen</keyname><forenames>Zhimin</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author></authors><title>Off-Grid DOA Estimation Using Sparse Bayesian Learning in MIMO Radar
  With Unknown Mutual Coupling</title><categories>eess.SP</categories><journal-ref>P. Chen, Z. Cao, Z. Chen and X. Wang, &quot;Off-Grid DOA Estimation
  Using Sparse Bayesian Learning in MIMO Radar With Unknown Mutual Coupling,&quot;
  in IEEE Transactions on Signal Processing, vol. 67, no. 1, pp. 208-220, 1
  Jan.1, 2019</journal-ref><doi>10.1109/TSP.2018.2881663</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the practical radar with multiple antennas, the antenna imperfections
degrade the system performance. In this paper, the problem of estimating the
direction of arrival (DOA) in multiple-input and multiple-output (MIMO) radar
system with unknown mutual coupling effect between antennas is investigated. To
exploit the target sparsity in the spatial domain, the compressed sensing
(CS)-based methods have been proposed by discretizing the detection area and
formulating the dictionary matrix, so an \emph{off-grid} gap is caused by the
discretization processes. In this paper, different from the present DOA
estimation methods, both the off-grid gap due to the sparse sampling and the
unknown mutual coupling effect between antennas are considered at the same
time, and a novel sparse system model for DOA estimation is formulated. Then, a
novel sparse Bayesian learning (SBL)-based method named sparse Bayesian
learning with the mutual coupling (SBLMC) is proposed, where an
expectation-maximum (EM)-based method is established to estimate all the
unknown parameters including the noise variance, the mutual coupling vectors,
the off-grid vector and the variance vector of scattering coefficients.
Additionally, the prior distributions for all the unknown parameters are
theoretically derived. With regard to the DOA estimation performance, the
proposed SBLMC method can outperform state-of-the-art methods in the MIMO radar
with unknown mutual coupling effect, while keeping the acceptable computational
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04614</identifier>
 <datestamp>2018-04-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04614</id><created>2018-04-12</created><authors><author><keyname>Javaheri</keyname><forenames>Amirhossein</forenames></author><author><keyname>Zayyani</keyname><forenames>Hadi</forenames></author><author><keyname>Figueiredo</keyname><forenames>Mario A. T.</forenames></author><author><keyname>Marvasti</keyname><forenames>Farrokh</forenames></author></authors><title>Impulsive Noise Robust Sparse Recovery via Continuous Mixed Norm</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of sparse signal recovery in the presence
of additive impulsive noise. The heavytailed impulsive noise is well modelled
with stable distributions. Since there is no explicit formulation for the
probability density function of $S\alpha S$ distribution, alternative
approximations like Generalized Gaussian Distribution (GGD) are used which
impose $\ell_p$-norm fidelity on the residual error. In this paper, we exploit
a Continuous Mixed Norm (CMN) for robust sparse recovery instead of
$\ell_p$-norm. We show that in blind conditions, i.e., in case where the
parameters of noise distribution are unknown, incorporating CMN can lead to
near optimal recovery. We apply Alternating Direction Method of Multipliers
(ADMM) for solving the problem induced by utilizing CMN for robust sparse
recovery. In this approach, CMN is replaced with a surrogate function and
Majorization-Minimization technique is incorporated to solve the problem.
Simulation results confirm the efficiency of the proposed method compared to
some recent algorithms in the literature for impulsive noise robust sparse
recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04710</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04710</id><created>2018-04-12</created><authors><author><keyname>Banadaki</keyname><forenames>Ali Dehghan</forenames></author><author><keyname>Feliachi</keyname><forenames>Ali</forenames></author><author><keyname>Kulathumani</keyname><forenames>Vinod K.</forenames></author></authors><title>Fully Distributed Secondary Voltage Control in Inverter-Based Microgrids</title><categories>eess.SP cs.SY</categories><journal-ref>IEEE Transmission and Distribution Conference and Exposition (T&amp;D)
  2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Centralized secondary voltage control in a power system has been replaced by
the distributed controller in the recent literature due to its high dependency
on extensive communication messages. Although in the new method each
distributed generator only communicate with its neighbors to control the
voltage, yet the messages are circulating among the whole system. In this
paper, we have utilized distributed controller locally so that it will work as
a fully distributed control system. This controller has been justified by being
studied within a case study including 6 distributed generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04715</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04715</id><created>2018-04-12</created><updated>2019-03-02</updated><authors><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Sobieraj</keyname><forenames>Iwona</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Sound Event Detection and Time-Frequency Segmentation from Weakly
  Labelled Data</title><categories>cs.SD eess.AS</categories><comments>12 pages, 8 figures</comments><journal-ref>IEEE/ACM Transactions on Audio, Speech, and Language Processing
  (Volume: 27, Issue: 4, April 2019)</journal-ref><doi>10.1109/TASLP.2019.2895254</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound event detection (SED) aims to detect when and recognize what sound
events happen in an audio clip. Many supervised SED algorithms rely on strongly
labelled data which contains the onset and offset annotations of sound events.
However, many audio tagging datasets are weakly labelled, that is, only the
presence of the sound events is known, without knowing their onset and offset
annotations. In this paper, we propose a time-frequency (T-F) segmentation
framework trained on weakly labelled data to tackle the sound event detection
and separation problem. In training, a segmentation mapping is applied on a T-F
representation, such as log mel spectrogram of an audio clip to obtain T-F
segmentation masks of sound events. The T-F segmentation masks can be used for
separating the sound events from the background scenes in the time-frequency
domain. Then a classification mapping is applied on the T-F segmentation masks
to estimate the presence probabilities of the sound events. We model the
segmentation mapping using a convolutional neural network and the
classification mapping using a global weighted rank pooling (GWRP). In SED,
predicted onset and offset times can be obtained from the T-F segmentation
masks. As a byproduct, separated waveforms of sound events can be obtained from
the T-F segmentation masks. We remixed the DCASE 2018 Task 1 acoustic scene
data with the DCASE 2018 Task 2 sound events data. When mixing under 0 dB, the
proposed method achieved F1 scores of 0.534, 0.398 and 0.167 in audio tagging,
frame-wise SED and event-wise SED, outperforming the fully connected deep
neural network baseline of 0.331, 0.237 and 0.120, respectively. In T-F
segmentation, we achieved an F1 score of 0.218, where previous methods were not
able to do T-F segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04719</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04719</id><created>2018-04-12</created><authors><author><keyname>El-Darymli</keyname><forenames>Khalid</forenames></author><author><keyname>McGuire</keyname><forenames>Peter</forenames></author><author><keyname>Power</keyname><forenames>Desmond</forenames></author><author><keyname>Moloney</keyname><forenames>Cecilia</forenames></author></authors><title>Target detection in synthetic aperture radar imagery: a state-of-the-art
  survey</title><categories>eess.IV</categories><comments>35 pages, 13 figures</comments><journal-ref>El-Darymli, Khalid, Peter McGuire, Desmond Power, and Cecilia R.
  Moloney. &quot;Target detection in synthetic aperture radar imagery: a
  state-of-the-art survey.&quot; Journal of Applied Remote Sensing 7, no. 1 (2013):
  071598</journal-ref><doi>10.1117/1.JRS.7.071598</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Target detection is the front-end stage in any automatic target recognition
system for synthetic aperture radar (SAR) imagery (SAR-ATR). The efficacy of
the detector directly impacts the succeeding stages in the SAR-ATR processing
chain. There are numerous methods reported in the literature for implementing
the detector. We offer an umbrella under which the various research activities
in the field are broadly probed and taxonomized. First, a taxonomy for the
various detection methods is proposed. Second, the underlying assumptions for
different implementation strategies are overviewed. Third, a tabular comparison
between careful selections of representative examples is introduced. Finally, a
novel discussion is presented, wherein the issues covered include suitability
of SAR data models, understanding the multiplicative SAR data models, and two
unique perspectives on constant false alarm rate (CFAR) detection: signal
processing and pattern recognition. From a signal processing perspective, CFAR
is shown to be a finite impulse response band-pass filter. From a statistical
pattern recognition perspective, CFAR is shown to be a suboptimal one-class
classifier: a Euclidian distance classifier and a quadratic discriminant with a
missing term for one-parameter and two-parameter CFAR, respectively. We make a
contribution toward enabling an objective design and implementation for target
detection in SAR imagery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04744</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04744</id><created>2018-04-12</created><authors><author><keyname>Razavi</keyname><forenames>Aidin</forenames></author><author><keyname>Glazunov</keyname><forenames>Andr&#xe9;s Alay&#xf3;n</forenames></author><author><keyname>Maaskant</keyname><forenames>Rob</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author></authors><title>Back-of-the-envelope evaluation of the prevalence of RIMP or LOS
  propagation as a function of frequency</title><categories>eess.SP</categories><comments>8 pages, 4 figures, 24 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of 5G wireless communication systems, employing Massive-MIMO
at millimeter-wave frequencies, is most likely measured only in Over-The-Air
(OTA) setups. It is proposed to perform OTA measurements in two limiting
environments of Rich Isotropic MultiPath (RIMP) and Random Line-of-Sight
(Random-LOS) instead of a typical or representative channel. In the present
paper, we present a back-of-the envelope investigation of the impact of
scattering on the frequency dependence of the signal fading statistics in the
500 MHz-100 GHz band. We introduce a simple model for a generic scattering
environment by using randomly distributed resonant scatterers to investigate
the impact of the size of the scattering environment, the scatterer density,
and the number of scatterers on the signal variability in terms of the Rician
K-factor as a function of frequency. The simplified model is also verified
against full-wave simulation using the Method of Moments (MoM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04763</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04763</id><created>2018-04-12</created><authors><author><keyname>Cheng</keyname><forenames>Nan</forenames><affiliation>Shermen</affiliation></author><author><keyname>Xu</keyname><forenames>Wenchao</forenames><affiliation>Shermen</affiliation></author><author><keyname>Shi</keyname><forenames>Weisen</forenames><affiliation>Shermen</affiliation></author><author><keyname>Zhou</keyname><forenames>Yi</forenames><affiliation>Shermen</affiliation></author><author><keyname>Lu</keyname><forenames>Ning</forenames><affiliation>Shermen</affiliation></author><author><keyname>Zhou</keyname><forenames>Haibo</forenames><affiliation>Shermen</affiliation></author><author><keyname>Xuemin</keyname><affiliation>Shermen</affiliation></author><author><keyname>Shen</keyname></author></authors><title>Air-Ground Integrated Mobile Edge Networks: Architecture, Challenges and
  Opportunities</title><categories>eess.SP</categories><comments>Accepted by IEEE Communications Magazine. 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever-increasing mobile data demands have posed significant challenges in
the current radio access networks, while the emerging computation-heavy
Internet of things (IoT) applications with varied requirements demand more
flexibility and resilience from the cloud/edge computing architecture. In this
article, to address the issues, we propose a novel air-ground integrated mobile
edge network (AGMEN), where UAVs are flexibly deployed and scheduled, and
assist the communication, caching, and computing of the edge network. In
specific, we present the detailed architecture of AGMEN, and investigate the
benefits and application scenarios of drone-cells, and UAV-assisted edge
caching and computing. Furthermore, the challenging issues in AGMEN are
discussed, and potential research directions are highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04770</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04770</id><created>2018-04-12</created><updated>2018-04-17</updated><authors><author><keyname>Zafar</keyname><forenames>Adnan</forenames></author><author><keyname>Cao</keyname><forenames>Aijun</forenames></author><author><keyname>Abdullahi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author><author><keyname>Imran</keyname><forenames>Muhammad Ali</forenames></author></authors><title>Interference Analysis of QAM based Filter Bank Multicarrier System with
  Index Modulation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Index modulation (IM) has recently emerged as a promising concept for
spectrum and energy-efficient next generation wireless communications systems
since it strikes a good balance among error performance, complexity, and
spectral efficiency. IM technique, when applied to multicarrier waveforms,
yields the ability to convey the information not only by M-ary signal
constellations as in conventional multicarrier systems but also by the indexes
of the subcarriers, which are activated according to the incoming bit stream.
Although IM is well studied for OFDM based systems, FBMC with index modulation
has not been thoroughly investigated. In this paper, we shed light on the
potential and implementation of IM technique for QAM based FBMC system. We
start with a mathematical model of the IM based QAM-FBMC system (FBMC/QAM-IM)
along with the derivation of interference terms at the receiver due to channel
distortions and noise. The interference terms including the ones introduced by
the multipath channel are analyzed in terms of MSE and output SINR. It is shown
with analytical and simulation results that the interference power in
FBMC/QAM-IM is smaller compared to that of the conventional FBMC/QAM system as
some of the subcarriers are inactive. The performance of FBMC/QAM with IM is
investigated by comparing the SIR and output SINR with that of the conventional
FBMC/QAM system along with the BER performance which shows that the FBMC/QAM-IM
is a promising transmission technique for future wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04813</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04813</id><created>2018-04-13</created><authors><author><keyname>Bampis</keyname><forenames>Christos G.</forenames></author><author><keyname>Li</keyname><forenames>Zhi</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>SpatioTemporal Feature Integration and Model Fusion for Full Reference
  Video Quality Assessment</title><categories>eess.IV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perceptual video quality assessment models are either frame-based or
video-based, i.e., they apply spatiotemporal filtering or motion estimation to
capture temporal video distortions. Despite their good performance on video
quality databases, video-based approaches are time-consuming and harder to
efficiently deploy. To balance between high performance and computational
efficiency, Netflix developed the Video Multi-method Assessment Fusion (VMAF)
framework, which integrates multiple quality-aware features to predict video
quality. Nevertheless, this fusion framework does not fully exploit temporal
video quality measurements which are relevant to temporal video distortions. To
this end, we propose two improvements to the VMAF framework: SpatioTemporal
VMAF and Ensemble VMAF. Both algorithms exploit efficient temporal video
features which are fed into a single or multiple regression models. To train
our models, we designed a large subjective database and evaluated the proposed
models against state-of-the-art approaches. The compared algorithms will be
made available as part of the open source package in
https://github.com/Netflix/vmaf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04826</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04826</id><created>2018-04-13</created><authors><author><keyname>Arnold</keyname><forenames>Maximilian</forenames></author><author><keyname>D&#xf6;rner</keyname><forenames>Sebastian</forenames></author><author><keyname>Cammerer</keyname><forenames>Sebastian</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>On Deep Learning-based Massive MIMO Indoor User Localization</title><categories>eess.SP cs.IT math.IT</categories><comments>submitted to SPAWC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the usability of deep neural networks for multiple-input
multiple-output (MIMO) user positioning solely based on the orthogonal
frequency division multiplex (OFDM) complex channel coefficients. In contrast
to other indoor positioning systems (IPSs), the proposed method does not
require any additional piloting overhead or any other changes in the
communications system itself as it is deployed on top of an existing OFDM MIMO
system. Supported by actual measurements, we are mainly interested in the more
challenging non-line of sight (NLoS) scenario. However, gradient descent
optimization is known to require a large amount of data-points for training,
i.e., the required database would be too large when compared to conventional
methods. Thus, we propose a twostep training procedure, with training on
simulated line of sight (LoS) data in the first step, and finetuning on
measured NLoS positions in the second step. This turns out to reduce the
required measured training positions and thus, reduces the effort for data
acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04850</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04850</id><created>2018-04-13</created><authors><author><keyname>Miretti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato L. G.</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author></authors><title>FDD massive MIMO channel spatial covariance conversion using projection
  methods</title><categories>eess.SP</categories><comments>Paper accepted on 29/01/2018 for presentation at ICASSP 2018</comments><doi>10.1109/ICASSP.2018.8462048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge of second-order statistics of channels (e.g. in the form of
covariance matrices) is crucial for the acquisition of downlink channel state
information (CSI) in massive MIMO systems operating in the frequency division
duplexing (FDD) mode. Current MIMO systems usually obtain downlink covariance
information via feedback of the estimated covariance matrix from the user
equipment (UE), but in the massive MIMO regime this approach is infeasible
because of the unacceptably high training overhead. This paper considers
instead the problem of estimating the downlink channel covariance from uplink
measurements. We propose two variants of an algorithm based on projection
methods in an infinite-dimensional Hilbert space that exploit channel
reciprocity properties in the angular domain. The proposed schemes are
evaluated via Monte Carlo simulations, and they are shown to outperform current
state-of-the art solutions in terms of accuracy and complexity, for typical
array geometries and duplex gaps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04851</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04851</id><created>2018-04-13</created><updated>2018-08-29</updated><authors><author><keyname>Chevreuil</keyname><forenames>Antoine</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author></authors><title>On the detection of low rank matrices in the high-dimensional regime</title><categories>eess.SP math.ST stat.TH</categories><comments>7 pages, 2 figures, submitted to EUSIPCO2018</comments><journal-ref>EUSIPCO 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the detection of a low rank $n\times n$deterministic matrix
$\mathbf{X}_{0}$ from the noisy observation ${\bf X}_{0}+{\bf Z}$ when
$n\to\infty$, where ${\bf Z}$ is a complex Gaussian random matrix with
independent identically distributed $\mathcal{N}_{c}(0,\frac{1}{n})$ entries.
Thanks to large random matrix theory results, it is now well-known that if the
largest singular value $\lambda_{1}$ of ${\bf X}_{0}$ verifies $\lambda_{1}&gt;1$,
then it is possible to exhibit consistent tests. In this contribution, we prove
a contrario that under the condition $\lambda_{1}&lt;1$, there are no consistent
tests. Our proof is rather simple, inspired by previous works devoted to the
case of rank 1 matrices ${\bf X}_{0}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04862</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04862</id><created>2018-04-13</created><updated>2018-06-14</updated><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>He</keyname><forenames>Liang</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Johnson</keyname><forenames>Michael T.</forenames></author></authors><title>Speaker Embedding Extraction with Phonetic Information</title><categories>cs.SD eess.AS</categories><comments>submitted to Interspeech 2018 (accepted) and open-sourced. Please
  refer to Interspeech for the final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker embeddings achieve promising results on many speaker verification
tasks. Phonetic information, as an important component of speech, is rarely
considered in the extraction of speaker embeddings. In this paper, we introduce
phonetic information to the speaker embedding extraction based on the x-vector
architecture. Two methods using phonetic vectors and multi-task learning are
proposed. On the Fisher dataset, our best system outperforms the original
x-vector approach by 20% in EER, and by 15%, 15% in minDCF08 and minDCF10,
respectively. Experiments conducted on NIST SRE10 further demonstrate the
effectiveness of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04892</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04892</id><created>2018-04-13</created><updated>2018-10-25</updated><authors><author><keyname>Miretti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato L. G.</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author></authors><title>Downlink channel spatial covariance estimation in realistic FDD massive
  MIMO systems</title><categories>eess.SP</categories><comments>[v2] is the version accepted at GlobalSIP 2018. Only minor changes
  mainly in the introduction</comments><doi>10.1109/GlobalSIP.2018.8646487</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The knowledge of the downlink (DL) channel spatial covariance matrix at the
BS is of fundamental importance for large-scale array systems operating in
frequency division duplexing (FDD) mode. In particular, this knowledge plays a
key role in the DL channel state information (CSI) acquisition. In the massive
MIMO regime, traditional schemes based on DL pilots are severely limited by the
covariance feedback and the DL training overhead. To overcome this problem,
many authors have proposed to obtain an estimate of the DL spatial covariance
based on uplink (UL) measurements. However, many of these approaches rely on
simple channel models, and they are difficult to extend to more complex models
that take into account important effects of propagation in 3D environments and
of dual-polarized antenna arrays. In this study we propose a novel technique
that takes into account the aforementioned effects, in compliance with the
requirements of modern 4G and 5G system designs. Numerical simulations show the
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.04897</identifier>
 <datestamp>2019-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.04897</id><created>2018-04-13</created><updated>2019-03-06</updated><authors><author><keyname>Mulayoff</keyname><forenames>Rotem</forenames></author><author><keyname>Michaeli</keyname><forenames>Tomer</forenames></author></authors><title>On the Minimal Overcompleteness Allowing Universal Sparse Representation</title><categories>eess.SP cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representation over redundant dictionaries constitutes a good model
for many classes of signals (e.g., patches of natural images, segments of
speech signals, etc.). However, despite its popularity, very little is known
about the representation capacity of this model. In this paper, we study how
redundant a dictionary must be so as to allow any vector to admit a sparse
approximation with a prescribed sparsity and a prescribed level of accuracy. We
address this problem both in a worst-case setting and in an average-case one.
For each scenario we derive lower and upper bounds on the minimal required
overcompleteness. Our bounds have simple closed-form expressions that allow to
easily deduce the asymptotic behavior in large dimensions. In particular, we
find that the required overcompleteness grows exponentially with the sparsity
level and polynomially with the allowed representation error. This implies that
universal sparse representation is practical only at moderate sparsity levels,
but can be achieved at relatively high accuracy. As a side effect of our
analysis, we obtain a tight lower bound on the regularized incomplete beta
function, which may be interesting in its own right. We illustrate the validity
of our results through numerical simulations, which support our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05000</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05000</id><created>2018-04-13</created><authors><author><keyname>Sarma</keyname><forenames>Mousmita</forenames></author><author><keyname>Sarma</keyname><forenames>Kandarpa Kumar</forenames></author><author><keyname>Goel</keyname><forenames>Nagendra Kumar</forenames></author></authors><title>Language Recognition using Time Delay Deep Neural Network</title><categories>eess.AS cs.SD</categories><comments>5 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work explores the use of a monolingual Deep Neural Network (DNN) model
as an universal background model (UBM) to address the problem of Language
Recognition (LR) in I-vector framework. A Time Delay Deep Neural Network
(TDDNN) architecture is used in this work, which is trained as an acoustic
model in an English Automatic Speech Recognition (ASR) task. A logistic
regression model is trained to classify the I-vectors. The proposed system is
tested with fourteen languages with various confusion pairs and it can be
easily extended to include a new language by just retraining the last simple
logistic regression model. The architectural flexibility is the major advantage
of the proposed system compared to the single DNN classifier based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05053</identifier>
 <datestamp>2018-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05053</id><created>2018-04-13</created><updated>2018-05-15</updated><authors><author><keyname>Richey</keyname><forenames>Colleen</forenames></author><author><keyname>Barrios</keyname><forenames>Maria A.</forenames></author><author><keyname>Armstrong</keyname><forenames>Zeb</forenames></author><author><keyname>Bartels</keyname><forenames>Chris</forenames></author><author><keyname>Franco</keyname><forenames>Horacio</forenames></author><author><keyname>Graciarena</keyname><forenames>Martin</forenames></author><author><keyname>Lawson</keyname><forenames>Aaron</forenames></author><author><keyname>Nandwana</keyname><forenames>Mahesh Kumar</forenames></author><author><keyname>Stauffer</keyname><forenames>Allen</forenames></author><author><keyname>van Hout</keyname><forenames>Julien</forenames></author><author><keyname>Gamble</keyname><forenames>Paul</forenames></author><author><keyname>Hetherly</keyname><forenames>Jeff</forenames></author><author><keyname>Stephenson</keyname><forenames>Cory</forenames></author><author><keyname>Ni</keyname><forenames>Karl</forenames></author></authors><title>Voices Obscured in Complex Environmental Settings (VOICES) corpus</title><categories>cs.SD eess.AS</categories><comments>Submitted to Interspeech 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces the Voices Obscured In Complex Environmental Settings
(VOICES) corpus, a freely available dataset under Creative Commons BY 4.0. This
dataset will promote speech and signal processing research of speech recorded
by far-field microphones in noisy room conditions. Publicly available speech
corpora are mostly composed of isolated speech at close-range microphony. A
typical approach to better represent realistic scenarios, is to convolve clean
speech with noise and simulated room response for model training. Despite these
efforts, model performance degrades when tested against uncurated speech in
natural conditions. For this corpus, audio was recorded in furnished rooms with
background noise played in conjunction with foreground speech selected from the
LibriSpeech corpus. Multiple sessions were recorded in each room to accommodate
for all foreground speech-background noise combinations. Audio was recorded
using twelve microphones placed throughout the room, resulting in 120 hours of
audio per microphone. This work is a multi-organizational effort led by SRI
International and Lab41 with the intent to push forward state-of-the-art
distant microphone approaches in signal processing and speech recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05055</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05055</id><created>2018-04-13</created><updated>2018-04-21</updated><authors><author><keyname>Das</keyname><forenames>Snigdha</forenames></author><author><keyname>Chatterjee</keyname><forenames>Soumyajit</forenames></author><author><keyname>Chakraborty</keyname><forenames>Sandip</forenames></author><author><keyname>Mitra</keyname><forenames>Bivas</forenames></author></authors><title>MeetSense: A Lightweight Framework for Group Identification using
  Smartphones</title><categories>cs.SI cs.SD eess.AS</categories><doi>10.1109/TMC.2018.2886333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an organization, individuals prefer to form various formal and informal
groups for mutual interactions. Therefore, ubiquitous identification of such
groups and understanding their dynamics are important to monitor activities,
behaviours and well-being of the individuals. In this paper, we develop a
lightweight, yet near-accurate, methodology, called MeetSense, to identify
various interacting groups based on collective sensing through users'
smartphones. Group detection from sensor signals is not straightforward because
users in proximity may not always be under the same group. Therefore, we use
acoustic context extracted from audio signals to infer interaction pattern
among the subjects in proximity. We have developed an unsupervised and
lightweight mechanism for user group detection by taking cues from network
science and measuring the cohesivity of the detected groups in terms of
modularity. Taking modularity into consideration, MeetSense can efficiently
eliminate incorrect groups, as well as adapt the mechanism depending on the
role played by the proximity and the acoustic context in a specific scenario.
The proposed method has been implemented and tested under many real-life
scenarios in an academic institute environment, and we observe that MeetSense
can identify user groups with close to 90% accuracy even in a noisy
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05111</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05111</id><created>2018-04-13</created><authors><author><keyname>Gala</keyname><forenames>Deepak</forenames></author><author><keyname>Lindsay</keyname><forenames>Nathan</forenames></author><author><keyname>Sun</keyname><forenames>Liang</forenames></author></authors><title>Multi-Sound-Source Localization for Small Autonomous Unmanned Vehicles
  with a Self-Rotating Bi-Microphone Array</title><categories>cs.SD cs.RO eess.AS</categories><comments>This paper is submitted to International Conference on Intelligent
  Robots and Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While vision-based localization techniques have been widely studied for small
autonomous unmanned vehicles (SAUVs), sound-source localization capability has
not been fully enabled for SAUVs. This paper presents two novel approaches for
SAUVs to perform multi-sound-sources localization (MSSL) using only the
interaural time difference (ITD) signal generated by a self-rotating
bi-microphone array. The proposed two approaches are based on the DBSCAN and
RANSAC algorithms, respectively, whose performances are tested and compared in
both simulations and experiments. The results show that both approaches are
capable of correctly identifying the number of sound sources along with their
three-dimensional orientations in a reverberant environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05160</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05160</id><created>2018-04-13</created><authors><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Chen</keyname><forenames>Jinkun</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>Exploring the Encoding Layer and Loss Function in End-to-End Speaker and
  Language Recognition System</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted for Speaker Odyssey 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the encoding/pooling layer and loss function in the
end-to-end speaker and language recognition system. First, a unified and
interpretable end-to-end system for both speaker and language recognition is
developed. It accepts variable-length input and produces an utterance level
result. In the end-to-end system, the encoding layer plays a role in
aggregating the variable-length input sequence into an utterance level
representation. Besides the basic temporal average pooling, we introduce a
self-attentive pooling layer and a learnable dictionary encoding layer to get
the utterance level representation. In terms of loss function for open-set
speaker verification, to get more discriminative speaker embedding, center loss
and angular softmax loss is introduced in the end-to-end system. Experimental
results on Voxceleb and NIST LRE 07 datasets show that the performance of
end-to-end learning system could be significantly improved by the proposed
encoding layer and loss function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05164</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05164</id><created>2018-04-14</created><authors><author><keyname>Lyu</keyname><forenames>Yecheng</forenames></author><author><keyname>Huang</keyname><forenames>Xinming</forenames></author></authors><title>Road Segmentation Using CNN with GRU</title><categories>cs.CV eess.IV</categories><comments>submitted to IV2018</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper presents an accurate and fast algorithm for road segmentation
using convolutional neural network (CNN) and gated recurrent units (GRU). For
autonomous vehicles, road segmentation is a fundamental task that can provide
the drivable area for path planning. The existing deep neural network based
segmentation algorithms usually take a very deep encoder-decoder structure to
fuse pixels, which requires heavy computations, large memory and long
processing time. Hereby, a CNN-GRU network model is proposed and trained to
perform road segmentation using data captured by the front camera of a vehicle.
GRU network obtains a long spatial sequence with lower computational
complexity, comparing to traditional encoder-decoder architecture. The proposed
road detector is evaluated on the KITTI road benchmark and achieves high
accuracy for road segmentation at real-time processing speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05204</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05204</id><created>2018-04-14</created><updated>2018-06-18</updated><authors><author><keyname>Frasca</keyname><forenames>Marco</forenames></author><author><keyname>Farina</keyname><forenames>Alfonso</forenames></author></authors><title>Parcels of Universe or why Schr\&quot;odinger and Fourier are so relatives?</title><categories>eess.SP hep-th quant-ph</categories><comments>6 pages, 4 figures. Improved language in some points</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about the surprising connection between the Fourier heat
equation and the Schr\&quot;odinger wave equation. In fact, if the independent
&quot;time&quot; variable in the heat equation is replaced by the time variable
multiplied by $i=\sqrt{-1}$, the heat equation becomes the Schr\&quot;odinger
equation. Two quite different physical phenomena are put in close connection:
the heat diffusion in a material and the probability amplitude of particles in
an atom. It is a fact of life that the movements of a small particle floating
randomly in a fluid, the well-known Brownian motion, is regulated by the
Fourier equation while the probabilistic behavior of the matter around us, the
quantum world, is driven by the Schr\&quot;odinger equation but no known stochastic
process seems at work here. The apparent simplicity of the formal connection by
a &quot;time-rotation&quot;, a Wick rotation as it is commonly known, seems to point
otherwise. Why this connection? Is there any physical intuitive explanation? Is
there any practical value? In this paper, the authors attempt to shed some
light on the above questions. The recent concept of volume quantization in
noncommutative geometry, due to Connes, Chamseddine and Mukhanov, points again
to stochastic processes also underlying the quantum world making Fourier and
Schr\&quot;oodinger strict relatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05299</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05299</id><created>2018-04-14</created><authors><author><keyname>Bhattacharjee</keyname><forenames>Vikram</forenames></author><author><keyname>Khan</keyname><forenames>Irfan</forenames></author></authors><title>A non-linear convex cost model for economic dispatch in microgrids</title><categories>eess.SP</categories><comments>31 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a convex non-linear cost saving model for optimal
economic dispatch in a microgrid. The mod-el incorporates energy storage
degradation cost and intermittent renewable generation. Cell degradation cost
being a non-linear model, its incorporation in an objective function alters the
convexity of the optimization problem and stochastic algorithms are required
for its solution. This paper builds on the scope for usage of macroscopically
semi-empirical models for degradation cost in economic dispatch problems and
proves that these cost models derived from the existing semi-empirical capacity
fade equations for LiFePO4 cells are convex under some operating condi-tions.
The proposed non-linear model was tested on two data sets of varying size which
portray different trends of seasonality. The results show that the model
reflects the trends of seasonality existing in the data sets and it mini-mizes
the total fuel cost globally when compared to conventional systems of economic
dispatch. The results thus indicate that the model achieves a more accurate
estimate of fuel cost in the system and can be effectively utilized for cost
analysis in power system applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05305</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05305</id><created>2018-04-15</created><authors><author><keyname>Mirzaei</keyname><forenames>Morteza</forenames></author><author><keyname>Asif</keyname><forenames>Amir</forenames></author><author><keyname>Fortin</keyname><forenames>Maryse</forenames></author><author><keyname>Rivaza</keyname><forenames>Hassan</forenames></author></authors><title>Spatio-temporal normalized cross-correlation for estimation of the
  displacement field in ultrasound elastography</title><categories>physics.med-ph eess.IV</categories><comments>30 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel technique to estimate tissue displacement in
quasi-static elastography. A major challenge in elastography is estimation of
displacement (also referred to time-delay estimation) between pre-compressed
and post-compressed ultrasound data. Maximizing normalized cross correlation
(NCC) of ultrasound radio-frequency (RF) data of the pre- and post-compressed
images is a popular technique for strain estimation due to its simplicity and
computational efficiency. Several papers have been published to increase the
accuracy and quality of displacement estimation based on NCC. All of these
methods use spatial windows to estimate NCC, wherein displacement magnitude is
assumed to be constant within each window. In this work, we extend this
assumption along the temporal domain to exploit neighboring samples in both
spatial and temporal directions. This is important since traditional and
ultrafast ultrasound machines are, respectively, capable of imaging at more
than 30 frame per second (fps) and 1000 fps. We call our method spatial
temporal normalized cross correlation (STNCC) and show that it substantially
outperforms NCC using simulation, phantom and in-vivo experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05306</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05306</id><created>2018-04-15</created><authors><author><keyname>Tsai</keyname><forenames>Che-Ping</forenames></author><author><keyname>Tuan</keyname><forenames>Yi-Lin</forenames></author><author><keyname>Lee</keyname><forenames>Lin-shan</forenames></author></authors><title>Transcribing Lyrics From Commercial Song Audio: The First Step Towards
  Singing Content Processing</title><categories>cs.SD cs.CL eess.AS</categories><comments>Accepted as a conference paper at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spoken content processing (such as retrieval and browsing) is maturing, but
the singing content is still almost completely left out. Songs are human voice
carrying plenty of semantic information just as speech, and may be considered
as a special type of speech with highly flexible prosody. The various problems
in song audio, for example the significantly changing phone duration over
highly flexible pitch contours, make the recognition of lyrics from song audio
much more difficult. This paper reports an initial attempt towards this goal.
We collected music-removed version of English songs directly from commercial
singing content. The best results were obtained by TDNN-LSTM with data
augmentation with 3-fold speed perturbation plus some special approaches. The
WER achieved (73.90%) was significantly lower than the baseline (96.21%), but
still relatively high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05307</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05307</id><created>2018-04-15</created><updated>2018-04-22</updated><authors><author><keyname>Kanatsoulis</keyname><forenames>Charilaos I.</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>Hyperspectral Super-Resolution: A Coupled Tensor Factorization Approach</title><categories>eess.SP</categories><doi>10.1109/TSP.2018.2876362</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral super-resolution refers to the problem of fusing a
hyperspectral image (HSI) and a multispectral image (MSI) to produce a
super-resolution image (SRI) that has fine spatial and spectral resolution.
State-of-the-art methods approach the problem via low-rank matrix
approximations to the matricized HSI and MSI. These methods are effective to
some extent, but a number of challenges remain. First, HSIs and MSIs are
naturally third-order tensors (data &quot;cubes&quot;) and thus matricization is prone to
loss of structural information--which could degrade performance. Second, it is
unclear whether or not these low-rank matrix-based fusion strategies can
guarantee identifiability or exact recovery of the SRI. However,
identifiability plays a pivotal role in estimation problems and usually has a
significant impact on performance in practice. Third, the majority of the
existing methods assume that there are known (or easily estimated) degradation
operators applied to the SRI to form the corresponding HSI and MSI--which is
hardly the case in practice. In this work, we propose to tackle the
super-resolution problem from a tensor perspective. Specifically, we utilize
the multidimensional structure of the HSI and MSI to propose a coupled tensor
factorization framework that can effectively overcome the aforementioned
issues. The proposed approach guarantees the identifiability of the SRI under
mild and realistic conditions. Furthermore, it works with little knowledge of
the degradation operators, which is clearly an advantage over the existing
methods. Semi-real numerical experiments are included to show the effectiveness
of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05374</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05374</id><created>2018-04-15</created><updated>2018-06-11</updated><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Serdyuk</keyname><forenames>Dmitriy</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Twin Regularization for online speech recognition</title><categories>eess.AS cs.AI cs.CL cs.LG cs.NE</categories><comments>Accepted at INTESPEECH 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online speech recognition is crucial for developing natural human-machine
interfaces. This modality, however, is significantly more challenging than
off-line ASR, since real-time/low-latency constraints inevitably hinder the use
of future information, that is known to be very helpful to perform robust
predictions. A popular solution to mitigate this issue consists of feeding
neural acoustic models with context windows that gather some future frames.
This introduces a latency which depends on the number of employed look-ahead
features. This paper explores a different approach, based on estimating the
future rather than waiting for it. Our technique encourages the hidden
representations of a unidirectional recurrent network to embed some useful
information about the future. Inspired by a recently proposed technique called
Twin Networks, we add a regularization term that forces forward hidden states
to be as close as possible to cotemporal backward ones, computed by a &quot;twin&quot;
neural network running backwards in time. The experiments, conducted on a
number of datasets, recurrent architectures, input features, and acoustic
conditions, have shown the effectiveness of this approach. One important
advantage is that our method does not introduce any additional computation at
test time if compared to standard unidirectional recurrent networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05406</identifier>
 <datestamp>2019-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05406</id><created>2018-04-15</created><updated>2019-04-10</updated><authors><author><keyname>Cheng</keyname><forenames>Chongsheng</forenames></author><author><keyname>Shen</keyname><forenames>Zhigang</forenames></author></authors><title>Detecting Concrete Abnormality Using Time-series Thermal Imaging and
  Supervised Learning</title><categories>eess.IV cs.CV</categories><comments>Accepted as Poster for 98th Annual Meeting of Transportation Research
  Board (TRB)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nondestructive detecting defects (NDD) in concrete structures have been
explored for decades. Although limited successes were reported, major
limitations still exist. The major limitations are the high noises to signal
ratio created from the environmental factors, such as cloud, shadow, water,
surface texture etc. and the decision making still relies on the engineering
judgment of interpretation of image content. Time-series approach, such as
principle component thermography approach has been experimented with some
improved results. Recent progress in image processing using machine learning
approach made it possible for detecting defects thermal features in more
quantitative ways. In this paper, we provide a procedure to represent the
thermal feature in the time domain by principal component analysis and regress
the prediction of detection by two schemes of supervised learning models. Three
independent experiments were conducted in a similar laboratory setup but varied
in conditions to illustrate the performance and generalization of models.
Results showed the effectiveness for the detection purpose with appropriate
tuning for parameters. Future studies will focus on implementing more
sophisticated structured models to handle more realistic cases under natural
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05486</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05486</id><created>2018-04-15</created><authors><author><keyname>Takamoto</keyname><forenames>Ayaka</forenames></author><author><keyname>Yoshida</keyname><forenames>Mitsuo</forenames></author><author><keyname>Umemura</keyname><forenames>Kyoji</forenames></author><author><keyname>Ichikawa</keyname><forenames>Yuko</forenames></author></authors><title>Computing Information Quantity as Similarity Measure for Music
  Classification Task</title><categories>cs.SD eess.AS</categories><comments>The 2017 International Conference On Advanced Informatics: Concepts,
  Theory And Application (ICAICTA2017)</comments><doi>10.1109/ICAICTA.2017.8090990</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel method that can replace compression-based
dissimilarity measure (CDM) in composer estimation task. The main features of
the proposed method are clarity and scalability. First, since the proposed
method is formalized by the information quantity, reproduction of the result is
easier compared with the CDM method, where the result depends on a particular
compression program. Second, the proposed method has a lower computational
complexity in terms of the number of learning data compared with the CDM
method. The number of correct results was compared with that of the CDM for the
composer estimation task of five composers of 75 piano musical scores. The
proposed method performed better than the CDM method that uses the file size
compressed by a particular program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05512</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05512</id><created>2018-04-16</created><authors><author><keyname>Gupta</keyname><forenames>Supratim</forenames></author><author><keyname>Panigrahi</keyname><forenames>Susant Kumar</forenames></author></authors><title>Joint Bilateral Filter for Signal Recovery from Phase Preserved Curvelet
  Coefficients for Image Denoising</title><categories>eess.IV</categories><comments>10 pages, 8 figures. 3 tables, journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Thresholding of Curvelet Coefficients, for image denoising, drains out subtle
signal component in noise subspace. This produces ringing artifacts near edges
and granular effect in the denoised image. We found the noise sensitivity of
Curvelet phases (in contrast to their magnitude) reduces with higher noise
level. Thus, we preserved the phase of the coefficients below threshold at
coarser scale and estimated their magnitude by Joint Bilateral Filtering (JBF)
technique from the thresholded and noisy coefficients. In the finest scale, we
apply Bilateral Filter (BF) to keep edge information. Further, the Guided Image
Filter (GIF) is applied on the reconstructed image to localize the edges and to
preserve the small image details and textures. The lower noise sensitivity of
Curvelet phase at higher noise strength accelerate the performance of proposed
method over several state-of-theart techniques and provides comparable outcome
at lower noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05611</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05611</id><created>2018-04-16</created><authors><author><keyname>Kim</keyname><forenames>Jin Woo</forenames></author><author><keyname>Shin</keyname><forenames>Soo Young</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Performance Enhancement of Downlink NOMA by Combination with GSSK</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In non-orthogonal multiple access (NOMA), cell-edge users experience
significantly low spectral density because only some part of the total transmit
power is allocated. This leads to low spectral efficiency for the paired users
in NOMA. To overcome this problem, we propose an integration of NOMA and
generalized space shift keying (GSSK), called NOMA-GSSK, to improve the
spectral efficiency by exploiting the spatial domain. Spectral and energy
efficiency, bit error rate (BER), and computational complexity of the proposed
system were analyzed and compared to those of multiple-input multiple-output
NOMA (MIMO-NOMA). It is shown that NOMA-GSSK outperforms MIMO-NOMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05669</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05669</id><created>2018-04-08</created><authors><author><keyname>Ichimura</keyname><forenames>Takumi</forenames></author><author><keyname>Kamada</keyname><forenames>Shin</forenames></author></authors><title>A Clonal Selection Algorithm with Levenshtein Distance based Image
  Similarity in Multidimensional Subjective Tourist Information and Discovery
  of Cryptic Spots by Interactive GHSOM</title><categories>cs.IR cs.CV cs.SI eess.IV</categories><comments>6 pages, 9 figures, Proc. of 2013 IEEE International Conference on
  Systems, Man, and Cybernetics (IEEE SMC 2013). arXiv admin note: substantial
  text overlap with arXiv:1804.03993, arXiv:1804.02628, arXiv:1804.02816</comments><doi>10.1109/SMC.2013.357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Phone based Participatory Sensing (MPPS) system involves a community
of users sending personal information and participating in autonomous sensing
through their mobile phones. Sensed data can also be obtained from external
sensing devices that can communicate wirelessly to the phone. Our developed
tourist subjective data collection system with Android smartphone can determine
the filtering rules to provide the important information of sightseeing spot.
The rules are automatically generated by Interactive Growing Hierarchical SOM.
However, the filtering rules related to photograph were not generated, because
the extraction of the specified characteristics from images cannot be realized.
We propose the effective method of the Levenshtein distance to deduce the
spatial proximity of image viewpoints and thus determine the specified pattern
in which images should be processed. To verify the proposed method, some
experiments to classify the subjective data with images are executed by
Interactive GHSOM and Clonal Selection Algorithm with Immunological Memory
Cells in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05757</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05757</id><created>2018-04-16</created><authors><author><keyname>Amiri</keyname><forenames>Roohollah</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author></authors><title>Self-Organizing mmWave Networks : A Power Allocation Scheme Based on
  Machine Learning</title><categories>eess.SP</categories><comments>4 pages, 7 figures, GSMM18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) communication is anticipated to provide significant
throughout gains in urban scenarios. To this end, network densification is a
necessity to meet the high traffic volume generated by smart phones, tablets,
and sensory devices while overcoming large pathloss and high blockages at
mmWaves frequencies. These denser networks are created with users deploying
small mmWave base stations (BSs) in a plug-and-play fashion. Although, this
deployment method provides the required density, the amorphous deployment of
BSs needs distributed management. To address this difficulty, we propose a
self-organizing method to allocate power to mmWave BSs in an ultra dense
network. The proposed method consists of two parts: clustering using fast local
clustering and power allocation via Q-learning. The important features of the
proposed method are its scalability and self-organizing capabilities, which are
both important features of 5G. Our simulations demonstrate that the introduced
method, provides required quality of service (QoS) for all the users
independent of the size of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05809</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05809</id><created>2018-04-16</created><updated>2018-10-10</updated><authors><author><keyname>Vono</keyname><forenames>Maxime</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>Chainais</keyname><forenames>Pierre</forenames></author></authors><title>Split-and-augmented Gibbs sampler - Application to large-scale inference
  problems</title><categories>stat.ME eess.SP stat.CO</categories><doi>10.1109/TSP.2019.2894825</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives two new optimization-driven Monte Carlo algorithms
inspired from variable splitting and data augmentation. In particular, the
formulation of one of the proposed approaches is closely related to the
alternating direction method of multipliers (ADMM) main steps. The proposed
framework enables to derive faster and more efficient sampling schemes than the
current state-of-the-art methods and can embed the latter. By sampling
efficiently the parameter to infer as well as the hyperparameters of the
problem, the generated samples can be used to approximate Bayesian estimators
of the parameters to infer. Additionally, the proposed approach brings
confidence intervals at a low cost contrary to optimization methods.
Simulations on two often-studied signal processing problems illustrate the
performance of the two proposed samplers. All results are compared to those
obtained by recent state-of-the-art optimization and MCMC algorithms used to
solve these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05937</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05937</id><created>2018-04-13</created><authors><author><keyname>Turan</keyname><forenames>Mehmet Ali Tugtekin</forenames></author></authors><title>Enhancement of Throat Microphone Recordings Using Gaussian Mixture Model
  Probabilistic Estimator</title><categories>eess.AS eess.SP</categories><comments>M.Sc. Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The throat microphone is a body-attached transducer that is worn against the
neck. It captures the signals that are transmitted through the vocal folds,
along with the buzz tone of the larynx. Due to its skin contact, it is more
robust to the environmental noise compared to the acoustic microphone that
picks up the vibrations through air pressure, and hence the all interventions.
The throat speech is partly intelligible, but gives unnatural and croaky sound.
This thesis tries to recover missing frequency bands of the throat speech and
investigates envelope and excitation mapping problem with joint analysis of
throat- and acoustic-microphone recordings. A new phone-dependent GMM-based
spectral envelope mapping scheme, which performs the minimum mean square error
(MMSE) estimation of the acoustic-microphone spectral envelope, has been
proposed. In the source-filter decomposition framework, we observed that the
spectral envelope difference of the excitation signals of throat- and
acoustic-microphone recordings is an important source of the degradation in the
throat-microphone voice quality. Thus, we also model spectral envelope
difference of the excitation signals as a spectral tilt vector, and propose a
new phone-dependent GMM-based spectral tilt mapping scheme to enhance throat
excitation signal. Experimental evaluations are performed to compare the
proposed mapping scheme using both objective and subjective evaluations.
Objective evaluations are performed with the log-spectral distortion (LSD) and
the wide-band perceptual evaluation of speech quality (PESQ) metrics.
Subjective evaluations are performed with A/B pair comparison listening test.
Both objective and subjective evaluations yield that the proposed
phone-dependent mapping consistently improves performances over the
state-of-the-art GMM estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.05971</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.05971</id><created>2018-04-16</created><authors><author><keyname>Razavi</keyname><forenames>Aidin</forenames></author><author><keyname>Yu</keyname><forenames>Wenjie</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Glazunov</keyname><forenames>Andr&#xe9;s Alay&#xf3;n</forenames></author></authors><title>Design of a Planar Eleven Antenna for Optimal MIMO Performance as a
  Wideband Micro Base-station Antenna</title><categories>eess.SP</categories><comments>7 pages, 15 figures, 15 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new low-profile planar Eleven antenna is designed for optimal MIMO
performance as a wideband MIMO antenna for micro base-stations in future
wireless communication systems. The design objective has been to optimize both
the reflection coefficient at the input port of the antenna and the 1-bitstream
and 2-bitstream MIMO efficiency of the antenna at the same time, in both the
Rich Isotropic MultiPath (RIMP) and Random Line-of-Sight (Random-LOS)
environments. The planar Eleven antenna can be operated in 2-, 4-, and 8-port
modes with slight modifications. The optimization is performed using genetic
algorithms. The effects of polarization deficiencies and antenna total embedded
efficiency on the MIMO performance of the antenna are further studied. A
prototype of the antenna has been fabricated and the design has been verified
by measurements against the simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06131</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06131</id><created>2018-04-17</created><authors><author><keyname>Kumar</keyname><forenames>Sanjay</forenames></author></authors><title>Reduced Order Fractional Fourier Transform A New Variant to Fractional
  Signal Processing Definition and Properties</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new variant to fractional signal processing is proposed
known as the Reduced Order Fractional Fourier Transform. Various properties
satisfied by its transformation kernel is derived. The properties associated
with the proposed Reduced Order Fractional Fourier Transform like shift,
modulation, time-frequency shift property are also derived and it is shown
mathematically that when the rotation angle of Reduced Order Fractional Fourier
Transform approaches 90 degrees, the proposed Reduced Order Fractional Fourier
Transform reduces to the conventional Fourier transform. Also, the Reduced
Order Fractional Fourier Transform of various kinds of signals is also derived
and it is shown that the obtained analytical expressions of different Reduced
Order Fractional Fourier Transform are a reduced form of the conventional
fractional Fourier transform. It is also shown that proposed definition of
Fractional Fourier Transform is easier to be handled analytically. Finally, the
convolution theorem associated with the proposed Reduced Order Fractional
Fourier Transform is derived with its various properties like shift
convolution, modulation convolution, and time-frequency shift modulation
properties. It has been shown that with this proposed new definition of
fractional Fourier transform, the convolution theorem has been reduced to
multiplication in the fractional frequency domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06143</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06143</id><created>2018-04-17</created><authors><author><keyname>Huang</keyname><forenames>Yan</forenames></author><author><keyname>Jalaian</keyname><forenames>Brian</forenames></author><author><keyname>Russell</keyname><forenames>Stephen</forenames></author><author><keyname>Samani</keyname><forenames>Hooman</forenames></author></authors><title>Technical Report on Efficient Integration of Dynamic TDD with Massive
  MIMO</title><categories>eess.SP</categories><comments>24 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in massive multiple-input multiple-output (MIMO)
communication show that equipping base stations (BSs) with large arrays of
antenna can significantly improve the performance of cellular networks. Massive
MIMO has the potential to mitigate the interference in the network and enhance
the average throughput per user. On the other hand, dynamic time division
duplexing (TDD), which allows neighboring cells to operate with different
uplink (UL) and downlink (DL) sub-frame configurations, is a promising
enhancement for the conventional static TDD. Compared with static TDD, dynamic
TDD can offer more flexibility to accommodate various UL and DL traffic
patterns across different cells, but may result in additional interference
among cells transmitting in different directions. Based on the unique
characteristics and properties of massive MIMO and dynamic TDD, we propose a
marriage of these two techniques, i.e., to have massive MIMO address the
limitation of dynamic TDD in macro cell (MC) networks. Specifically, we
advocate that the benefits of dynamic TDD can be fully extracted in MC networks
equipped with massive MIMO, i.e., the BS-to-BS interference can be effectively
removed by increasing the number of BS antennas. We provide detailed analysis
using random matrix theory to show that the effect of the BS-to-BS interference
on uplink transmissions vanishes as the number of BS antennas per-user grows
infinitely large. Last but not least, we validate our analysis by numerical
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06159</identifier>
 <datestamp>2018-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06159</id><created>2018-04-17</created><authors><author><keyname>Roy</keyname><forenames>Tanmoy</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author><author><keyname>Chakraverty</keyname><forenames>Snehashish</forenames></author></authors><title>Precise Detection of Speech Endpoints Dynamically: A Wavelet Convolution
  based approach</title><categories>eess.AS</categories><comments>25 Pages</comments><doi>10.1016/j.cnsns.2018.07.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precise detection of speech endpoints is an important factor which affects
the performance of the systems where speech utterances need to be extracted
from the speech signal such as Automatic Speech Recognition (ASR) system.
Existing endpoint detection (EPD) methods mostly uses Short-Term Energy (STE),
Zero-Crossing Rate (ZCR) based approaches and their variants. But STE and ZCR
based EPD algorithms often fail in the presence of Non-speech Sound Artifacts
(NSAs) produced by the speakers. Algorithms based on pattern recognition and
classification techniques are also proposed but require labeled data for
training. A new algorithm termed as Wavelet Convolution based Speech Endpoint
Detection (WCSEPD) is proposed in this article to extract speech endpoints.
WCSEPD decomposes the speech signal into high-frequency and low-frequency
components using wavelet convolution and computes entropy based thresholds for
the two frequency components. The low-frequency thresholds are used to extract
voiced speech segments, whereas the high-frequency thresholds are used to
extract the unvoiced speech segments by filtering out the NSAs. WCSEPD does not
require any labeled data for training and can automatically extract speech
segments. Experiment results show that the proposed algorithm precisely
extracts speech endpoints in the presence of NSAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06244</identifier>
 <datestamp>2019-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06244</id><created>2018-04-16</created><updated>2018-08-22</updated><authors><author><keyname>Diederich</keyname><forenames>Benedict</forenames></author><author><keyname>Then</keyname><forenames>Patrick</forenames></author><author><keyname>J&#xfc;gler</keyname><forenames>Alexander</forenames></author><author><keyname>F&#xf6;rster</keyname><forenames>Ronny</forenames></author><author><keyname>Heintzmann</keyname><forenames>Rainer</forenames></author></authors><title>cellSTORM - Cost-effective Super-Resolution on a Cellphone using dSTORM</title><categories>eess.IV physics.optics</categories><doi>10.1371/journal.pone.0209827</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expensive scientific camera hardware is amongst the main cost factors in
modern, high-performance microscopes. Recent technological advantages have,
however, yielded consumer-grade camera devices that can provide surprisingly
good performance. The camera sensors of smartphones in particular have
benefited of this development. Combined with computing power and due to their
ubiquity, smartphones provide a fantastic opportunity for &quot;imaging on a
budget&quot;. Here we show that a consumer cellphone is capable even of optical
super-resolution imaging by (direct) Stochastic Optical Reconstruction
Microscopy (dSTORM), achieving optical resolution better than 80 nm. In
addition to the use of standard reconstruction algorithms, we investigated an
approach by a trained image-to-image generative adversarial network (GAN). This
not only serves as a versatile technique to reconstruct video sequences under
conditions where traditional algorithms provide sub-optimal localization
performance, but also allows processing directly on the smartphone. We believe
that &quot;cellSTORM&quot; paves the way for affordable super-resolution microscopy
suitable for research and education, expanding access to cutting edge research
to a large community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06258</identifier>
 <datestamp>2019-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06258</id><created>2018-04-16</created><updated>2018-12-27</updated><authors><author><keyname>Liu</keyname><forenames>Yu</forenames></author><author><keyname>Li</keyname><forenames>Jiahui</forenames></author><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author></authors><title>Joint Beam and Channel Tracking for Two-Dimensional Phased Antenna
  Arrays</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog beamforming is a low-cost architecture for millimeter-wave (mmWave)
mobile communications. However, it has two disadvantages for serving fast
mobility users: (i) the mmWave beam in the wireless channel and the beam
steered by analog beamforming have small angular spreads which are difficult to
align with each other and (ii) the receiver can only observe the mmWave channel
in one beam direction and rely on beam-probing algorithms to check other
directions. In this paper, we develop a beam probing and tracking algorithm
that can efficiently track fast-moving mmWave beams in three-dimensional (3D)
space. This algorithm has several salient features: (1) fading channel
supportive: it can simultaneously track the channel coefficient and
two-dimensional (2D) beam direction in fading channel environments; (2) low
probing overhead: it achieves the minimum probing requirement for joint beam
and channel tracking; (3) fast tracking speed and high tracking accuracy: its
tracking error converges to the minimum Cramer-Rao lower bound (CRLB) in static
scenarios in theory and it outperforms several existing tracking algorithms
with lower tracking error and faster tracking speed in simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06267</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06267</id><created>2018-04-17</created><updated>2018-07-06</updated><authors><author><keyname>St&#xf6;ter</keyname><forenames>Fabian-Robert</forenames></author><author><keyname>Liutkus</keyname><forenames>Antoine</forenames></author><author><keyname>Ito</keyname><forenames>Nobutaka</forenames></author></authors><title>The 2018 Signal Separation Evaluation Campaign</title><categories>eess.AS cs.SD</categories><comments>To appear in International Conference on Latent Variable Analysis and
  Signal Separation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the organization and results for the 2018 community-based
Signal Separation Evaluation Campaign (SiSEC 2018). This year's edition was
focused on audio and pursued the effort towards scaling up and making it easier
to prototype audio separation software in an era of machine-learning based
systems. For this purpose, we prepared a new music separation database:
MUSDB18, featuring close to 10h of audio. Additionally, open-source software
was released to automatically load, process and report performance on MUSDB18.
Furthermore, a new official Python version for the BSSEval toolbox was
released, along with reference implementations for three oracle separation
methods: ideal binary mask, ideal ratio mask, and multichannel Wiener filter.
We finally report the results obtained by the participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06304</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06304</id><created>2018-04-17</created><authors><author><keyname>Lotfollahi</keyname><forenames>Mahsa</forenames></author><author><keyname>Berisha</keyname><forenames>Sebastian</forenames></author><author><keyname>Saadatifard</keyname><forenames>Leila</forenames></author><author><keyname>Montier</keyname><forenames>Laura</forenames></author><author><keyname>Ziburkus</keyname><forenames>Jokubas</forenames></author><author><keyname>Mayerich</keyname><forenames>David</forenames></author></authors><title>Three-Dimensional GPU-Accelerated Active Contours for Automated
  Localization of Cells in Large Images</title><categories>eess.IV cs.CV</categories><doi>10.1371/journal.pone.0215843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cell segmentation in microscopy is a challenging problem, since cells are
often asymmetric and densely packed. This becomes particularly challenging for
extremely large images, since manual intervention and processing time can make
segmentation intractable. In this paper, we present an efficient and highly
parallel formulation for symmetric three-dimensional (3D) contour evolution
that extends previous work on fast two-dimensional active contours. We provide
a formulation for optimization on 3D images, as well as a strategy for
accelerating computation on consumer graphics hardware. The proposed software
takes advantage of Monte-Carlo sampling schemes in order to speed up
convergence and reduce thread divergence. Experimental results show that this
method provides superior performance for large 2D and 3D cell segmentation
tasks when compared to existing methods on large 3D brain images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06621</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06621</id><created>2018-04-18</created><authors><author><keyname>Jing</keyname><forenames>Haiyue</forenames></author><author><keyname>Cheng</keyname><forenames>Wenchi</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>A Simple Channel Independent Beamforming Scheme with Circular Array</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider a uniform circular array (UCA) based
line-of-sight (LOS) multiple-input-multiple-output (MIMO) system, where the
transmit and receive UCAs are aligned with each other. We propose a simple
channel independent beamforming scheme with fast symbol-wise maximum likelihood
(ML) detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06666</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06666</id><created>2018-04-18</created><authors><author><keyname>Fauziya</keyname><forenames>Farheen</forenames></author><author><keyname>Lall</keyname><forenames>Brejesh</forenames></author><author><keyname>Agrawal</keyname><forenames>Monika</forenames></author></authors><title>Application of Vector Sensor for Underwater Acoustic Communications</title><categories>eess.SP</categories><comments>29 pages, 15 figures and 2 tables</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The use of vector sensors as receivers for Underwater Acoustic Communications
systems is gaining popularity. It has become important to obtain performance
measures for such communication systems to quantify their efficacy. The
fundamental advantage of using a vector sensor as a receiver is that a single
sensor is able to provide diversity gains offered by MIMO systems. In a recent
work novel framework for evaluating capacity of underwater channel was
proposed. The approach is based on modeling the channel as a set of paths along
which the signal arrives at the receiver with different Angles of Arrival. In
this work, we build on that framework to provide a bound on the achievable
capacity of such a system. The analytical bounds have been compared against
simulation results for a vector sensor based SIMO underwater communications
system. The channel parameters are modeled by analysing the statistics
generated with Bellhop simulation tool. This representation of the channel is
flexible and allows for characterizing channels at differenet geographical
locations and at different time instances. This characterization in terms of
channel parameters enables the computing of the performance measure (channel
capacity bound) for different geographical locations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06724</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06724</id><created>2018-04-16</created><authors><author><keyname>Pietrini</keyname><forenames>Alberto</forenames></author><author><keyname>Nettelblad</keyname><forenames>Carl</forenames></author></authors><title>Using Convex Optimization of Autocorrelation with Constrained Support
  and Windowing for Improved Phase Retrieval Accuracy</title><categories>eess.SP cs.NA physics.bio-ph physics.data-an</categories><comments>19 pages, 4 figures, 1 table</comments><doi>10.1364/OE.26.024422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In imaging modalities recording diffraction data, the original image can be
reconstructed assuming known phases. When phases are unknown, oversampling and
a constraint on the support region in the original object can be used to solve
a non-convex optimization problem.
  Such schemes are ill-suited to find the optimum solution for sparse data,
since the recorded image does not correspond exactly to the original wave
function. We construct a convex optimization problem using a relaxed support
constraint and a maximum-likelihood treatment of the recorded data as a sample
from the underlying wave function. We also stress the need to use relevant
windowing techniques to account for the sampled pattern being finite.
  On simulated data, we demonstrate the benefits of our approach in terms of
visual quality and an improvement in the crystallographic R-factor from .4 to
.1 for highly noisy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06737</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06737</id><created>2018-04-17</created><authors><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Wu</keyname><forenames>Zhizhen</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Studer</keyname><forenames>Christoph</forenames><affiliation>School of Electrical and Computer Engineering, Cornell University, USA</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author></authors><title>Efficient Soft-Output Gauss-Seidel Data Detector for Massive MIMO
  Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For massive multiple-input multiple-output (MIMO) systems, linear minimum
mean-square error (MMSE) detection has been shown to achieve near-optimal
performance but suffers from excessively high complexity due to the large-scale
matrix inversion. Being matrix inversion free, detection algorithms based on
the Gauss-Seidel (GS) method have been proved more efficient than conventional
Neumann series expansion (NSE) based ones. In this paper, an efficient GS-based
soft-output data detector for massive MIMO and a corresponding VLSI
architecture are proposed. To accelerate the convergence of the GS method, a
new initial solution is proposed. Several optimizations on the VLSI
architecture level are proposed to further reduce the processing latency and
area. Our reference implementation results on a Xilinx Virtex-7 XC7VX690T FPGA
for a 128 base-station antenna and 8 user massive MIMO system show that our
GS-based data detector achieves a throughput of 732 Mb/s with close-to-MMSE
error-rate performance. Our implementation results demonstrate that the
proposed solution has advantages over existing designs in terms of complexity
and efficiency, especially under challenging propagation conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06743</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06743</id><created>2018-04-17</created><authors><author><keyname>Maity</keyname><forenames>Shovan</forenames></author><author><keyname>Chatterjee</keyname><forenames>Baibhab</forenames></author><author><keyname>Chang</keyname><forenames>Gregory</forenames></author><author><keyname>Sen</keyname><forenames>Shreyas</forenames></author></authors><title>A 6.3pJ/b 30Mbps -30dB SIR-tolerant Broadband Interference-Robust Human
  Body Communication Transceiver using Time Domain Signal-Interference
  Separation</title><categories>eess.SP</categories><journal-ref>Custom Integrated Circuits Conference (CICC) 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human Body Communication (HBC) provides a low power communication medium for
energy constrained wearable/ implantable devices in and around the human body.
This paper presents a broadband HBC transceiver implemented in 65nm CMOS that
achieves 6.3pJ/b energy efficiency at 30Mbps with -30dB interference-tolerance.
Capacitive termination at the receiver end is used to achieve a wideband HBC
channel, and Time Domain Signal-Interference Separation (TD-SIS) using
Integrating DDR (I-DDR) receiver allows a tolerance of -30 dB Signal to
Interference Ratio (SIR) with a BER &lt;10-3. The transceiver achieves 18X
improvement in energy-efficiency compared to the State-of-the-Art HBC
transceivers while being simultaneously broadband (carrier-less, low-energy)
and interference-robust. Such order-of-magnitude improvement in
energy-efficiency and private communication through the human body may enable
applications like closed-loop neuromodulation, health-monitoring, secure
authentication among many others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06745</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06745</id><created>2018-04-17</created><authors><author><keyname>Liu</keyname><forenames>Xiaozhen</forenames><affiliation>School of Electronic Science and Engineering, Nanjing University, China</affiliation></author><author><keyname>Sha</keyname><forenames>Jin</forenames><affiliation>School of Electronic Science and Engineering, Nanjing University, China</affiliation></author><author><keyname>Xie</keyname><forenames>Hongxiang</forenames><affiliation>Department of Automation, Tsinghua University, Beijing, China</affiliation></author><author><keyname>Gao</keyname><forenames>Feifei</forenames><affiliation>Department of Automation, Tsinghua University, Beijing, China</affiliation></author><author><keyname>Jin</keyname><forenames>Shi</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation></author></authors><title>Efficient Channel Estimator with Angle-Division Multiple Access</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (M-MIMO) is an enabling technology of
5G wireless communication. The performance of an M-MIMO system is highly
dependent on the speed and accuracy of obtaining the channel state information
(CSI). The computational complexity of channel estimation for an M-MIMO system
can be reduced by making use of the sparsity of the M-MIMO channel. In this
paper, we propose the hardware-efficient channel estimator based on
angle-division multiple access (ADMA) for the first time. Preamble, uplink (UL)
and downlink (DL) training are also implemented. For further
hardware-efficiency consideration, optimization regarding quantization and
approximation strategies have been discussed. Implementation techniques such as
pipelining and systolic processing are also employed for hardware regularity.
Numerical results and FPGA implementation have demonstrated the advantages of
the proposed channel estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06775</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06775</id><created>2018-04-18</created><updated>2018-08-23</updated><authors><author><keyname>Milde</keyname><forenames>Benjamin</forenames></author><author><keyname>Biemann</keyname><forenames>Chris</forenames></author></authors><title>Unspeech: Unsupervised Speech Context Embeddings</title><categories>cs.SD cs.CL eess.AS</categories><comments>Accepted at Interspeech 2018, Hyderabad, India. This version matches
  the final version submitted to the conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce &quot;Unspeech&quot; embeddings, which are based on unsupervised learning
of context feature representations for spoken language. The embeddings were
trained on up to 9500 hours of crawled English speech data without
transcriptions or speaker information, by using a straightforward learning
objective based on context and non-context discrimination with negative
sampling. We use a Siamese convolutional neural network architecture to train
Unspeech embeddings and evaluate them on speaker comparison, utterance
clustering and as a context feature in TDNN-HMM acoustic models trained on
TED-LIUM, comparing it to i-vector baselines. Particularly decoding
out-of-domain speech data from the recently released Common Voice corpus shows
consistent WER reductions. We release our source code and pre-trained Unspeech
models under a permissive open source license.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06779</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06779</id><created>2018-04-18</created><authors><author><keyname>Huang</keyname><forenames>Che-Wei</forenames></author><author><keyname>Narayanan</keyname><forenames>Shrikanth</forenames></author></authors><title>Shaking Acoustic Spectral Sub-bands Can Better Regularize Learning in
  Affective Computing</title><categories>cs.SD eess.AS</categories><comments>ICASSP paper with follow-up exps</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate a recently proposed regularization technique
based on multi-branch architectures, called Shake-Shake regularization, for the
task of speech emotion recognition. In addition, we also propose variants to
incorporate domain knowledge into model configurations. The experimental
results demonstrate: $1)$ independently shaking sub-bands delivers favorable
models compared to shaking the entire spectral-temporal feature maps. $2)$ with
proper patience in early stopping, the proposed models can simultaneously
outperform the baseline and maintain a smaller performance gap between training
and validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06861</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06861</id><created>2018-04-18</created><updated>2018-11-19</updated><authors><author><keyname>Li</keyname><forenames>Longguang</forenames></author><author><keyname>Sboui</keyname><forenames>Lokman</forenames></author><author><keyname>Rezki</keyname><forenames>Zouheir</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>On the Capacity of Fading Channels with Peak and Average Power
  Constraints at Low SNR</title><categories>eess.SP</categories><comments>8 pages, 3 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of fading channels under peak and average power constraints in
the low-SNR regime is investigated. We show that the capacity scales
essentially as ${C \approx A \ \text{SNR} \int_{1- \frac{1}{A}}^1
F^{-1}\left(t\right)dt}$, where $A$ is the peak to average power ratio (PAPR),
and $F(\cdot)$ is the cumulative distribution function of the fading channel.
  We also prove that an On-Off power scheme is sufficient to asymptotically
achieve the capacity. Furthermore, by considering the variable PAPR scenario,
we generalize the scalability of the capacity and derive the asymptotic
expression for the capacity in the low-SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.06899</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.06899</id><created>2018-04-18</created><updated>2018-08-02</updated><authors><author><keyname>Ghavamirad</keyname><forenames>Roohollah</forenames></author><author><keyname>Sebt</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Babashah</keyname><forenames>Hossein</forenames></author></authors><title>Phase Improvement Algorithm for NLFM Waveform Design to Reduction of
  Sidelobe Level in Autocorrelation Function</title><categories>eess.SP</categories><journal-ref>IET Electronics Letters 54(2018 ) 1091-1093</journal-ref><doi>10.1049/el.2018.5518</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a phase improvement algorithm has been developed to design the
nonlinear frequency modulated (NLFM) signal for the four windows of
Raised-Cosine, Taylor, Chebyshev, and Kaiser. We have already designed NLFM
signal by stationary phase method. The simulation results for the peak sidelobe
level of the autocorrelation function in the phase improvement algorithm reveal
a significant average decrement of about 5 dB with respect to stationary phase
method. Moreover, to evaluate the efficiency of the phase improvement
algorithm, minimum error value for each iteration is calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07141</identifier>
 <datestamp>2018-04-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07141</id><created>2018-03-19</created><authors><author><keyname>Javed</keyname><forenames>Barkha</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Khan</keyname><forenames>Zaheer</forenames></author><author><keyname>Shamdasani</keyname><forenames>Jetendr</forenames></author></authors><title>A Provenance Framework for Policy Analytics in Smart Cities</title><categories>cs.CY eess.SP</categories><comments>7 pages, 1 figure, 1 table</comments><journal-ref>Proc of the International Conference on Internet of Things and Big
  Data (IoTBD 2016), pp 429-434</journal-ref><doi>10.5220/0005931504290434</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sustainable urban environments based on Internet of Things (IoT) technologies
require appropriate policy management. However, such policies are established
as a result of underlying, potentially complex and long-term policy making
processes. Consequently, better policies require improved and verifiable
planning processes. In order to assess and evaluate the planning process,
transparency of the system is pivotal which can be achieved by tracking the
provenance of policy making process. However, at present no system is available
that can track the complete cycle of urban planning and decision making. We
propose to capture the complete process of policy making and to investigate the
role of IoT provenance to support design-making for policy analytics and
implementation. The environment in which this research will be demonstrated is
that of Smart Cities whose requirements will drive the research process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07145</identifier>
 <datestamp>2018-04-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07145</id><created>2018-04-19</created><authors><author><keyname>Schmitz</keyname><forenames>Thomas</forenames></author><author><keyname>Embrechts</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Real Time Emulation of Parametric Guitar Tube Amplifier With Long Short
  Term Memory Neural Network</title><categories>eess.SP cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous audio systems for musicians are expensive and bulky. Therefore, it
could be advantageous to model them and to replace them by computer emulation.
In guitar players' world, audio systems could have a desirable nonlinear
behavior (distortion effects). It is thus difficult to find a simple model to
emulate them in real time. Volterra series model and its subclass are usual
ways to model nonlinear systems. Unfortunately, these systems are difficult to
identify in an analytic way. In this paper we propose to take advantage of the
new progress made in neural networks to emulate them in real time. We show that
an accurate emulation can be reached with less than 1% of root mean square
error between the signal coming from a tube amplifier and the output of the
neural network. Moreover, the research has been extended to model the Gain
parameter of the amplifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07220</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07220</id><created>2018-04-19</created><authors><author><keyname>Ravazzi</keyname><forenames>Chiara</forenames></author><author><keyname>Hojjatinia</keyname><forenames>Sarah</forenames></author><author><keyname>Lagoa</keyname><forenames>Constantino M.</forenames></author><author><keyname>Dabbene</keyname><forenames>Fabrizio</forenames></author></authors><title>Randomized opinion dynamics over networks: influence estimation from
  partial observations</title><categories>cs.SY cs.SI eess.SP</categories><journal-ref>2018 IEEE Conference on Decision and Control (CDC)</journal-ref><doi>10.1109/CDC.2018.8619770</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a technique for the estimation of the influence
matrix in a sparse social network, in which $n$ individual communicate in a
gossip way. At each step, a random subset of the social actors is active and
interacts with randomly chosen neighbors. The opinions evolve according to a
Friedkin and Johnsen mechanism, in which the individuals updates their belief
to a convex combination of their current belief, the belief of the agents they
interact with, and their initial belief, or prejudice. Leveraging recent
results of estimation of vector autoregressive processes, we reconstruct the
social network topology and the strength of the interconnections starting from
\textit{partial observations} of the interactions, thus removing one of the
main drawbacks of finite horizon techniques. The effectiveness of the proposed
method is shown on randomly generation networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07239</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07239</id><created>2018-04-19</created><authors><author><keyname>Hojjatinia</keyname><forenames>Sarah</forenames></author><author><keyname>Bekiroglu</keyname><forenames>Korkut</forenames></author><author><keyname>Lagoa</keyname><forenames>Constantino M.</forenames></author></authors><title>Parsimonious Volterra System Identification</title><categories>cs.SY eess.SP</categories><journal-ref>2018 Annual American Control Conference (ACC)</journal-ref><doi>10.23919/ACC.2018.8431084</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short paper, we aim at developing algorithms for sparse Volterra
system identification when the system to be identified has infinite impulse
response. Assuming that the impulse response is represented as a sum of
exponentials and given input-output data, the problem of interest is to find
the &quot;simplest&quot; nonlinear Volterra model which is compatible with the a priori
information and the collected data. By simplest, we mean the model whose
impulse response has the least number of exponentials. The algorithms provided
are able to handle both fragmented data and measurement noise. Academic
examples at the end of paper show the efficacy of proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07254</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07254</id><created>2018-04-19</created><updated>2019-09-19</updated><authors><author><keyname>Rahimian</keyname><forenames>Samira</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>Performance Analysis of Massive MIMO Multi-Way Relay Networks with
  Low-Resolution ADCs</title><categories>eess.SP</categories><comments>Part of this work on the performance analysis of mMIMO multi-way
  relay networks with low-resolution uniform-ADC structures has been presented
  at the IEEE International Conference on Communications (ICC) 2019 [1]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High power consumption and hardware cost are two barriers for practical
massive multiple-input multiple-output (mMIMO) systems. A promising solution is
to employ low-resolution analog-to-digital converters (ADCs). In this paper, we
consider a general mMIMO multi-way relaying system with a multi-level mixed-ADC
architecture, in which each antenna is connected to an ADC pair of an arbitrary
resolution. By leveraging on Bussgang's decomposition theorem and Lloyd-Max
algorithm for quantization, tight closed-form approximations are derived for
the average achievable rates of zero-forcing (ZF) relaying considering both
perfect and imperfect channel state information (CSI). To conquer the
challenges caused by multi-way relaying, the complicated ZF beam-forming
matrix, and the general mixed-ADC structure, we develop a novel method for the
achievable rate analysis using the singular-value decomposition (SVD) for
Gaussian matrices, distributions of the singular values of Gaussian matrices,
and properties of Haar matrices. The results explicitly show the achievable
rate behavior in terms of the user and relay transmit powers and the numbers of
relay antennas and users. Most importantly, it quantifies the performance
degradation caused by low-resolution ADCs and channel estimation error. We
demonstrate that the average achievable rate has an almost linear relation with
the square of the average of quantization coefficients pertaining to the ADC
resolution profile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07297</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07297</id><created>2018-04-17</created><updated>2018-12-09</updated><authors><author><keyname>Elowsson</keyname><forenames>Anders</forenames></author></authors><title>Deep Layered Learning in MIR</title><categories>cs.SD eess.AS</categories><comments>Submitted for publication. Feedback always welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has boosted the performance of many music information retrieval
(MIR) systems in recent years. Yet, the complex hierarchical arrangement of
music makes end-to-end learning hard for some MIR tasks - a very deep and
flexible processing chain is necessary to model some aspect of music audio.
Representations involving tones, chords, and rhythm are fundamental building
blocks of music. This paper discusses how these can be used as intermediate
targets and priors in MIR to deal with structurally complex learning problems,
with learning modules connected in a directed acyclic graph. It is suggested
that this strategy for inference, referred to as deep layered learning (DLL),
can help generalization by (1) - enforcing the validity and invariance of
intermediate representations during processing, and by (2) - letting the
inferred representations establish the musical organization to support
higher-level invariant processing. A background to modular music processing is
provided together with an overview of previous publications. Relevant concepts
from information processing, such as pruning, skip connections, and performance
supervision are reviewed within the context of DLL. A test is finally
performed, showing how layered learning affects pitch tracking. It is indicated
that especially offsets are easier to detect if guided by extracted framewise
fundamental frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07300</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07300</id><created>2018-04-18</created><authors><author><keyname>Kotecha</keyname><forenames>Nikhil</forenames></author><author><keyname>Young</keyname><forenames>Paul</forenames></author></authors><title>Generating Music using an LSTM Network</title><categories>cs.SD cs.LG eess.AS</categories><comments>8 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of music needs to have the ability to recall past details and have a
clear, coherent understanding of musical structure. Detailed in the paper is a
neural network architecture that predicts and generates polyphonic music
aligned with musical rules. The probabilistic model presented is a Bi-axial
LSTM trained with a kernel reminiscent of a convolutional kernel. When analyzed
quantitatively and qualitatively, this approach performs well in composing
polyphonic music. Link to the code is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07345</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07345</id><created>2018-04-19</created><updated>2018-07-09</updated><authors><author><keyname>Parekh</keyname><forenames>Sanjeel</forenames></author><author><keyname>Essid</keyname><forenames>Slim</forenames></author><author><keyname>Ozerov</keyname><forenames>Alexey</forenames></author><author><keyname>Duong</keyname><forenames>Ngoc Q. K.</forenames></author><author><keyname>P&#xe9;rez</keyname><forenames>Patrick</forenames></author><author><keyname>Richard</keyname><forenames>Ga&#xeb;l</forenames></author></authors><title>Weakly Supervised Representation Learning for Unsynchronized
  Audio-Visual Events</title><categories>cs.CV cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio-visual representation learning is an important task from the
perspective of designing machines with the ability to understand complex
events. To this end, we propose a novel multimodal framework that instantiates
multiple instance learning. We show that the learnt representations are useful
for classifying events and localizing their characteristic audio-visual
elements. The system is trained using only video-level event labels without any
timing information. An important feature of our method is its capacity to learn
from unsynchronized audio-visual events. We achieve state-of-the-art results on
a large-scale dataset of weakly-labeled audio event videos. Visualizations of
localized visual regions and audio segments substantiate our system's efficacy,
especially when dealing with noisy situations where modality-specific cues
appear asynchronously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07411</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07411</id><created>2018-04-19</created><updated>2019-03-25</updated><authors><author><keyname>Hojjatinia</keyname><forenames>Sarah</forenames></author><author><keyname>Lagoa</keyname><forenames>Constantino M.</forenames></author><author><keyname>Dabbene</keyname><forenames>Fabrizio</forenames></author></authors><title>Identification of Switched Autoregressive Systems from Large Noisy Data
  Sets</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces a novel methodology for the identification of
coefficients of switched autoregressive linear models. We consider the case
when the system's outputs are contaminated by possibly large values of
measurement noise. It is assumed that only partial information on the
probability distribution of the noise is available. Given input-output data, we
aim at identifying switched system coefficients and parameters of the
distribution of the noise which are compatible with the collected data. System
dynamics are estimated through expected values computation and by exploiting
the strong law of large numbers. We demonstrate the efficiency of the proposed
approach with several academic examples. The method is shown to be extremely
effective in the situations where a large number of measurements is available;
cases in which previous approaches based on polynomial or mixed-integer
optimization cannot be applied due to very large computational burden.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07429</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07429</id><created>2018-04-19</created><authors><author><keyname>Stoddard</keyname><forenames>Jeremy G.</forenames></author><author><keyname>Welsh</keyname><forenames>James S.</forenames></author></authors><title>Volterra Kernel Identification using Regularized Orthonormal Basis
  Functions</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Volterra series is a powerful tool in modelling a broad range of
nonlinear dynamic systems. However, due to its nonparametric nature, the number
of parameters in the series increases rapidly with memory length and series
order, with the uncertainty in resulting model estimates increasing
accordingly. In this paper, we propose an identification method where the
Volterra kernels are estimated indirectly through orthonormal basis function
expansions, with regularization applied directly to the expansion coefficients
to reduce variance in the final model estimate and provide access to useful
models at previously unfeasible series orders. The higher dimensional kernel
expansions are regularized using a method that allows smoothness and decay to
be imposed on the entire hyper-surface. Numerical examples demonstrate improved
Volterra series estimation up to the 4th order using the regularized basis
function method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07442</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07442</id><created>2018-04-19</created><authors><author><keyname>Cheng</keyname><forenames>Wenchi</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Jing</keyname><forenames>Haiyue</forenames></author><author><keyname>Gao</keyname><forenames>Shanghua</forenames></author><author><keyname>Zhang</keyname><forenames>Hailin</forenames></author></authors><title>Orbital Angular Momentum for Wireless Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the traditional resources (frequency, time, space, etc.) are efficiently
utilized, it becomes more and more challenging to satisfy the ever-lasting
capacity-growing and users-boosting demand in wireless networks. Recently, the
electromagnetic (EM) wave was found to possess not only linear momentum, but
also angular momentum. The orbital angular momentum (OAM) is a kind of
wavefront with helical phase. The OAM-based vortex wave has different
topological charges, which are orthogonal to each other, bridging a new way for
multiple access in wireless communications. In this article, we introduce the
fundamental theory of OAM and the OAM based wireless communications. The
research challenges regarding OAM signal generation, OAM beam converging, and
OAM signal reception are discussed. Further, we propose a new multiuser access
with different OAM-modes in wireless networks, where multiple OAM-modes are
used as a new orthogonal dimension for interference avoidance. Simulation
results reveal the inherent property of OAM waves and show that OAM based radio
transmission can significantly increase the spectrum efficiency in wireless
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07529</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07529</id><created>2018-04-20</created><updated>2018-04-26</updated><authors><author><keyname>Magoarou</keyname><forenames>Luc Le</forenames><affiliation>IRT b-com</affiliation></author><author><keyname>Paquelet</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRT b-com</affiliation></author></authors><title>Bias-variance tradeoff in MIMO channel estimation</title><categories>eess.SP cs.IT cs.NI math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation is challenging in multi-antenna communication systems,
because of the large number of parameters to estimate. It is possible to
facilitate this task by using a physical model describing the multiple paths
constituting the channel, in the hope of reducing the number of unknowns in the
problem. Adjusting the number of estimated paths leads to a bias-variance
tradeoff. This paper explores this tradeoff, aiming to find the optimal number
of paths to estimate. Moreover, the approach based on a physical model is
compared to the classical least squares and Bayesian techniques. Finally, the
impact of channel estimation error on the system data rate is assessed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07553</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07553</id><created>2018-04-20</created><authors><author><keyname>Melnyk</keyname><forenames>Sergiy</forenames></author><author><keyname>Tesfay</keyname><forenames>Abraham Gebru</forenames></author><author><keyname>Alam</keyname><forenames>Khurshid</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author><author><keyname>Sark</keyname><forenames>Vladica</forenames></author><author><keyname>Maletic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Ramadan</keyname><forenames>Mohammed</forenames></author><author><keyname>Ehrig</keyname><forenames>Marcus</forenames></author><author><keyname>Augustin</keyname><forenames>Thomas</forenames></author><author><keyname>Franch</keyname><forenames>Norman</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Reliable Low Latency Wireless Communication Enabling Industrial Mobile
  Control and Safety Applications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advanced industrial applications for human-machine interaction such as
augmented reality support for maintenance works or mobile control panels for
operating production facility set high demands on underlying wireless
connectivity so- lution. Based on 802.11 standard, this paper proposes a
concept of a new system, which is capable of those requirements. For increasing
reliability, an agile triple-band (2.4 GHz, 5 GHz and 60 GHz) communication
system can be used. In order to deal with latency and deterministic channel
access, PHY and MAC techniques such as new waveforms or hybrid MAC schemes are
investigated. Integration of precise localization introduces new possibilities
for safety-critical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07610</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07610</id><created>2018-04-20</created><authors><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author></authors><title>A Rigorous Analysis of Least Squares Sine Fitting Using Quantized Data:
  the Random Phase Case</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers least-square based estimation of the amplitude and
square amplitude of a quantized sine wave, done by considering random initial
record phase. Using amplitude- and frequency-domain modeling techniques, it is
shown that the estimator is inconsistent, biased and has a variance that may be
underestimated if the simple model of quantization is applied. The effects of
both sine wave offset values and additive Gaussian noise are taken into
account. General estimator properties are derived, without making simplifying
assumptions on the role of the quantization process, to allow assessment of
measurement uncertainty, when this least-square procedure is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07661</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07661</id><created>2018-04-20</created><updated>2018-12-13</updated><authors><author><keyname>van Sloun</keyname><forenames>Ruud J. G.</forenames></author><author><keyname>Solomon</keyname><forenames>Oren</forenames></author><author><keyname>Bruce</keyname><forenames>Matthew</forenames></author><author><keyname>Khaing</keyname><forenames>Zin Z.</forenames></author><author><keyname>Wijkstra</keyname><forenames>Hessel</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Mischi</keyname><forenames>Massimo</forenames></author></authors><title>Super-resolution Ultrasound Localization Microscopy through Deep
  Learning</title><categories>eess.SP cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound localization microscopy has enabled super-resolution vascular
imaging through precise localization of individual ultrasound contrast agents
(microbubbles) across numerous imaging frames. However, analysis of
high-density regions with significant overlaps among the microbubble point
spread responses yields high localization errors, constraining the technique to
low-concentration conditions. As such, long acquisition times are required to
sufficiently cover the vascular bed. In this work, we present a fast and
precise method for obtaining super-resolution vascular images from high-density
contrast-enhanced ultrasound imaging data. This method, which we term Deep
Ultrasound Localization Microscopy (Deep-ULM), exploits modern deep learning
strategies and employs a convolutional neural network to perform localization
microscopy in dense scenarios. This end-to-end fully convolutional neural
network architecture is trained effectively using on-line synthesized data,
enabling robust inference in-vivo under a wide variety of imaging conditions.
We show that deep learning attains super-resolution with challenging
contrast-agent densities, both in-silico as well as in-vivo. Deep-ULM is
suitable for real-time applications, resolving about 70 high-resolution patches
(128x128 pixels) per second on a standard PC. Exploiting GPU computation, this
number increases to 1250 patches per second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07677</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07677</id><created>2018-04-20</created><authors><author><keyname>Ning</keyname><forenames>Shiyu</forenames></author><author><keyname>Xu</keyname><forenames>Hongteng</forenames></author><author><keyname>Song</keyname><forenames>Li</forenames></author><author><keyname>Xie</keyname><forenames>Rong</forenames></author><author><keyname>Zhang</keyname><forenames>Wenjun</forenames></author></authors><title>Learning an Inverse Tone Mapping Network with a Generative Adversarial
  Regularizer</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transferring a low-dynamic-range (LDR) image to a high-dynamic-range (HDR)
image, which is the so-called inverse tone mapping (iTM), is an important
imaging technique to improve visual effects of imaging devices. In this paper,
we propose a novel deep learning-based iTM method, which learns an inverse tone
mapping network with a generative adversarial regularizer. In the framework of
alternating optimization, we learn a U-Net-based HDR image generator to
transfer input LDR images to HDR ones, and a simple CNN-based discriminator to
classify the real HDR images and the generated ones. Specifically, when
learning the generator we consider the content-related loss and the generative
adversarial regularizer jointly to improve the stability and the robustness of
the generated HDR images. Using the learned generator as the proposed inverse
tone mapping network, we achieve superior iTM results to the state-of-the-art
methods consistently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07690</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07690</id><created>2018-04-20</created><authors><author><keyname>Abdelwahab</keyname><forenames>Mohammed</forenames></author><author><keyname>Busso</keyname><forenames>Carlos</forenames></author></authors><title>Domain Adversarial for Acoustic Emotion Recognition</title><categories>eess.AS cs.SD</categories><comments>submitted to IEEE transactions on signal processing</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The performance of speech emotion recognition is affected by the differences
in data distributions between train (source domain) and test (target domain)
sets used to build and evaluate the models. This is a common problem, as
multiple studies have shown that the performance of emotional classifiers drop
when they are exposed to data that does not match the distribution used to
build the emotion classifiers. The difference in data distributions becomes
very clear when the training and testing data come from different domains,
causing a large performance gap between validation and testing performance. Due
to the high cost of annotating new data and the abundance of unlabeled data, it
is crucial to extract as much useful information as possible from the available
unlabeled data. This study looks into the use of adversarial multitask training
to extract a common representation between train and test domains. The primary
task is to predict emotional attribute-based descriptors for arousal, valence,
or dominance. The secondary task is to learn a common representation where the
train and test domains cannot be distinguished. By using a gradient reversal
layer, the gradients coming from the domain classifier are used to bring the
source and target domain representations closer. We show that exploiting
unlabeled data consistently leads to better emotion recognition performance
across all emotional dimensions. We visualize the effect of adversarial
training on the feature representation across the proposed deep learning
architecture. The analysis shows that the data representations for the train
and test domains converge as the data is passed to deeper layers of the
network. We also evaluate the difference in performance when we use a shallow
neural network versus a \emph{deep neural network} (DNN) and the effect of the
number of shared layers used by the task and domain classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07701</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07701</id><created>2018-04-20</created><authors><author><keyname>De Angelis</keyname><forenames>Alessio</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author><author><keyname>Godfrey</keyname><forenames>Keith R.</forenames></author><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author></authors><title>Practical Issues in the Synthesis of Ternary Sequences</title><categories>eess.SP cs.NA cs.SY</categories><journal-ref>A. De Angelis, J. Schoukens, K. R. Godfrey and P. Carbone,
  &quot;Practical Issues in the Synthesis of Ternary Sequences,&quot; in IEEE
  Transactions on Instrumentation and Measurement, vol. 66, no. 2, pp. 212-222,
  Feb. 2017</journal-ref><doi>10.1109/TIM.2016.2622778</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several issues related to the practical synthesis of ternary sequences with
specified spectra are addressed in this paper. Specifically, sequences with
harmonic multiples of two and three suppressed are studied, given their
relevance when testing and characterizing nonlinear systems. In particular, the
effect of non-uniform Digital to Analog Converter (DAC) levels on the spectral
properties of the generated signal is analyzed. It is analytically shown that
the DAC non-uniform levels result in degraded harmonic suppression performance.
Moreover, a new approach is proposed for designing ternary sequences, which is
flexible and can be adapted to suit different requirements. The resulting
sequences, denoted as randomized constrained sequences, are characterized
theoretically by deriving an analytical expression of the power spectral
density. Furthermore, they are extensively compared with three synthesis
approaches proposed in the literature. The approach is validated by numerical
simulations and experimental results, showing the potential to achieve harmonic
suppression performance of approximately 100 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.07826</identifier>
 <datestamp>2019-03-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.07826</id><created>2018-04-20</created><updated>2019-03-21</updated><authors><author><keyname>Liang</keyname><forenames>Yuan</forenames></author><author><keyname>Ren</keyname><forenames>Jian</forenames></author><author><keyname>Li</keyname><forenames>Tongtong</forenames></author></authors><title>Secure OFDM System Design and Capacity Analysis under Disguised Jamming</title><categories>eess.SP</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a securely precoded OFDM (SP-OFDM) system for
efficient and reliable transmission under disguised jamming, where the jammer
intentionally misleads the receiver by mimicking the characteristics of the
authorized signal, and causes complete communication failure. More
specifically, we bring off a dynamic constellation by introducing secure shared
randomness between the legitimate transmitter and receiver, and hence break the
symmetricity between the authorized signal and the disguised jamming. We
analyze the channel capacities of both the traditional OFDM and SP-OFDM under
hostile jamming using the arbitrarily varying channel (AVC) model. It is shown
that the deterministic coding capacity of the traditional OFDM is zero under
the worst disguised jamming. On the other hand, due to the secure randomness
shared between the authorized transmitter and receiver, SP-OFDM can achieve a
positive capacity under disguised jamming since the AVC channel corresponding
to SP-OFDM is not symmetrizable. A remarkable feature of the proposed SP-OFDM
scheme is that while achieving strong jamming resistance, it has roughly the
same high spectral efficiency as the traditional OFDM system. The robustness of
the proposed SP-OFDM scheme under disguised jamming is demonstrated through
both theoretic and numerical analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08003</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08003</id><created>2018-04-21</created><authors><author><keyname>Samareh</keyname><forenames>Aven</forenames></author><author><keyname>Parizi</keyname><forenames>Mahshid Salemi</forenames></author></authors><title>Stability of the Stochastic Gradient Method for an Approximated Large
  Scale Kernel Machine</title><categories>eess.SP cs.LG stat.ML</categories><comments>Submitted to Journal of Signal Processing Systems (2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we measured the stability of stochastic gradient method (SGM)
for learning an approximated Fourier primal support vector machine. The
stability of an algorithm is considered by measuring the generalization error
in terms of the absolute difference between the test and the training error.
Our problem is to learn an approximated kernel function using random Fourier
features for a binary classification problem via online convex optimization
settings. For a convex, Lipschitz continuous and smooth loss function, given
reasonable number of iterations stochastic gradient method is stable. We showed
that with a high probability SGM generalizes well for an approximated kernel
under given assumptions.We empirically verified the theoretical findings for
different parameters using several data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08022</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08022</id><created>2018-04-21</created><authors><author><keyname>Negahdari</keyname><forenames>Amir</forenames></author></authors><title>Modeling and Experimental Verification of Adaptive 100% Stator Ground
  Fault Protection Schemes for Synchronous Generators</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Salient pole synchronous generators as the main component of an electricity
generation station should be carefully maintained and their operation has to be
monitored such that any damage on them is avoided. Otherwise, the generating
station might experience frequent shut downs which results in electricity
generation interruptions and high costs associated with repairing and
compensation of lack of energy. In this sense, many protective schemes focusing
on a variety of synchronous generator faults have already been proposed and are
still modified and developed to further enhance the quality of protection. In
this thesis, synchronous generator stator windings to ground fault is studied
as one of the most common and crucial faults in these machines. Numerous
methods of stator winding to ground fault protection schemes are also reported
in the literature. Third harmonic differential voltage and sub-harmonic schemes
are studied in this research. A novel adaptive scheme for both methods is
modelled and implemented in a comprehensive lab scale set-up where a real
generation unit is scaled down including all different components and
apparatus. The simulation model is also established based on simultaneous
finite element analysis (FEA) and coupled magnetic circuit to assist with
system configuration design and parameter selections. The adaptive scheme is
proved to be capable of detecting stator windings to ground faults based on
actual experimental data. Finally, the proposed adaptive scheme is compared
against other available non-adaptive protection schemes currently used in
industrial relays. Several important performance evaluation criteria in
protection schemes such as sensitivity and security of operation referred to as
reliability are considered. It is shown that the adaptive scheme offers higher
reliability than other schemes which emphasizes its credibility and
applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08081</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08081</id><created>2018-04-22</created><authors><author><keyname>Glazunov</keyname><forenames>Andr&#xe9;s Alay&#xf3;n</forenames></author><author><keyname>Lehne</keyname><forenames>Per Hjalmar</forenames></author></authors><title>A Spherical Probability Distribution Model of the User-Induced Mobile
  Phone Orientation</title><categories>eess.SP</categories><comments>9 pages, 7 figures (18 sub-figures), 25 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a statistical modeling approach of the real-life
user-induced randomness due to mobile phone orientations for different phone
usage types. As well-known, the radiated performance of a wireless device
depends on its orientation and position relative to the user. Therefore,
realistic handset usage models will lead to more accurate Over-The-Air
characterization measurements for antennas and wireless devices in general. We
introduce a phone usage classification based on the network access modes, e.g.,
voice (circuit switched) or nonvoice (packet switched) services, and the use of
accessories such as wired or Bluetooth handsets, or a speaker-phone during the
network access session. The random phone orientation is then modelled by the
spherical von Mises-Fisher distribution for each of the identified phone usage
types. A finite mixture model based on the individual probability distribution
functions and heuristic weights is also presented. The models are based on data
collected from built-in accelerometer measurements. Our approach offers a
straightforward modeling of the user-induced random orientation for different
phone usage types. The models can be used in the design of better handsets and
antenna systems as well as for the design and optimization of wireless
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08126</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08126</id><created>2018-04-22</created><updated>2018-08-09</updated><authors><author><keyname>Ghavamirad</keyname><forenames>Roohollah</forenames></author><author><keyname>Sebt</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Sidelobe Level Reduction in ACF of NLFM Waveform</title><categories>eess.SP</categories><journal-ref>IET Radar, Sonar &amp; Navigation 13 (2019) 74-80</journal-ref><doi>10.1049/iet-rsn.2018.5095</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an iterative method is proposed for nonlinear frequency
modulation (NLFM) waveform design based on a constrained optimization problem
using Lagrangian method. To date, NLFM waveform design methods have been
performed based on the stationary phase concept which we have already used it
in a previous work. The proposed method has been implemented for six windows of
Raised-Cosine, Taylor, Chebyshev, Gaussian, Poisson, and Kaiser. The results
reveals that the peak sidelobe level of autocorrelation function reduces about
an average of 5 dB in our proposed method compared with the stationary phase
method, and an optimum peak sidelobe level is achieved. The minimum error of
the proposed method decreases in each iteration which is demonstrated using
mathematical relations and simulation. The trend decrement of minimum error
guarantees convergence of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08167</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08167</id><created>2018-04-22</created><updated>2018-04-28</updated><authors><author><keyname>Elowsson</keyname><forenames>Anders</forenames></author></authors><title>Tempo-Invariant Processing of Rhythm with Convolutional Neural Networks</title><categories>cs.SD eess.AS</categories><comments>Included in doctoral dissertation &quot;Modeling Music: Studies of Music
  Transcription, Music Perception and Music Production&quot;. 26 pages, G5 format.
  Feedback always welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rhythm patterns can be performed with a wide variation of tempi. This
presents a challenge for many music information retrieval (MIR) systems;
ideally, perceptually similar rhythms should be represented and processed
similarly, regardless of the specific tempo at which they were performed.
Several recent systems for tempo estimation, beat tracking, and downbeat
tracking have therefore sought to process rhythm in a tempo-invariant way,
often by sampling input vectors according to a precomputed pulse level. This
paper describes how a log-frequency representation of rhythm-related
activations instead can promote tempo invariance when processed with
convolutional neural networks. The strategy incorporates invariance at a
fundamental level and can be useful for most tasks related to rhythm
processing. Different methods are described, relying on magnitude, phase
relationships of different rhythm channels, as well as raw phase information.
Several variations are explored to provide direction for future
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08300</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08300</id><created>2018-04-23</created><authors><author><keyname>Rafii</keyname><forenames>Zafar</forenames></author><author><keyname>Liutkus</keyname><forenames>Antoine</forenames></author><author><keyname>St&#xf6;ter</keyname><forenames>Fabian-Robert</forenames></author><author><keyname>Mimilakis</keyname><forenames>Stylianos Ioannis</forenames></author><author><keyname>FitzGerald</keyname><forenames>Derry</forenames></author><author><keyname>Pardo</keyname><forenames>Bryan</forenames></author></authors><title>An Overview of Lead and Accompaniment Separation in Music</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular music is often composed of an accompaniment and a lead component, the
latter typically consisting of vocals. Filtering such mixtures to extract one
or both components has many applications, such as automatic karaoke and
remixing. This particular case of source separation yields very specific
challenges and opportunities, including the particular complexity of musical
structures, but also relevant prior knowledge coming from acoustics, musicology
or sound engineering. Due to both its importance in applications and its
challenging difficulty, lead and accompaniment separation has been a popular
topic in signal processing for decades. In this article, we provide a
comprehensive review of this research topic, organizing the different
approaches according to whether they are model-based or data-centered. For
model-based methods, we organize them according to whether they concentrate on
the lead signal, the accompaniment, or both. For data-centered approaches, we
discuss the particular difficulty of obtaining data for learning lead
separation systems, and then review recent approaches, notably those based on
deep learning. Finally, we discuss the delicate problem of evaluating the
quality of music separation through adequate metrics and present the results of
the largest evaluation, to-date, of lead and accompaniment separation systems.
In conjunction with the above, a comprehensive list of references is provided,
along with relevant pointers to available implementations and repositories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08425</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08425</id><created>2018-04-19</created><updated>2018-06-19</updated><authors><author><keyname>Bashar</keyname><forenames>Manijeh</forenames></author><author><keyname>Cumanan</keyname><forenames>Kanapathippillai</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Mixed Quality of Service in Cell-Free Massive MIMO</title><categories>eess.SP cs.IT math.IT</categories><comments>2 figures. arXiv admin note: text overlap with arXiv:1801.10188,
  arXiv:1801.10190</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Cell-free massive multiple-input multiple-output (MIMO) is a potential key
technology for fifth generation wireless communication networks. A mixed
quality-of-service (QoS) problem is investigated in the uplink of a cell-free
massive MIMO system where the minimum rate of non-real time users is maximized
with per user power constraints whilst the rate of the real-time users (RTUs)
meet their target rates. First an approximated uplink user rate is derived
based on available channel statistics. Next, the original mixed QoS problem is
formulated in terms of receiver filter coefficients and user power allocations
which can iteratively be solved through two sub-problems, namely, receiver
filter coefficient design and power allocation, which are dealt with using a
generalized eigenvalue problem and geometric programming, respectively.
Numerical results show that with the proposed scheme, while the rates of RTUs
meet the QoS constraints, the $90\%$-likely throughput improves significantly,
compared to a simple benchmark scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08438</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08438</id><created>2018-04-23</created><updated>2018-09-04</updated><authors><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author><author><keyname>Lorenzo-Trueba</keyname><forenames>Jaime</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author><author><keyname>Saito</keyname><forenames>Daisuke</forenames></author><author><keyname>Villavicencio</keyname><forenames>Fernando</forenames></author><author><keyname>Ling</keyname><forenames>Zhenhua</forenames></author></authors><title>A Spoofing Benchmark for the 2018 Voice Conversion Challenge: Leveraging
  from Spoofing Countermeasures for Speech Artifact Assessment</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>Correction (bug fix) of a published ODYSSEY 2018 publication with the
  same title and author list; more details in footnote in page 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice conversion (VC) aims at conversion of speaker characteristic without
altering content. Due to training data limitations and modeling imperfections,
it is difficult to achieve believable speaker mimicry without introducing
processing artifacts; performance assessment of VC, therefore, usually involves
both speaker similarity and quality evaluation by a human panel. As a
time-consuming, expensive, and non-reproducible process, it hinders rapid
prototyping of new VC technology. We address artifact assessment using an
alternative, objective approach leveraging from prior work on spoofing
countermeasures (CMs) for automatic speaker verification. Therein, CMs are used
for rejecting `fake' inputs such as replayed, synthetic or converted speech but
their potential for automatic speech artifact assessment remains unknown. This
study serves to fill that gap. As a supplement to subjective results for the
2018 Voice Conversion Challenge (VCC'18) data, we configure a standard
constant-Q cepstral coefficient CM to quantify the extent of processing
artifacts. Equal error rate (EER) of the CM, a confusability index of VC
samples with real human speech, serves as our artifact measure. Two clusters of
VCC'18 entries are identified: low-quality ones with detectable artifacts (low
EERs), and higher quality ones with less artifacts. None of the VCC'18 systems,
however, is perfect: all EERs are &lt; 30 % (the `ideal' value would be 50 %). Our
preliminary findings suggest potential of CMs outside of their original
application, as a supplemental optimization and benchmarking tool to enhance VC
technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08461</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08461</id><created>2018-04-23</created><updated>2018-08-01</updated><authors><author><keyname>Cavalcante</keyname><forenames>Renato Luis Garrido</forenames></author><author><keyname>Miretti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author></authors><title>Error Bounds for FDD Massive MIMO Channel Covariance Conversion with
  Set-Theoretic Methods</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted at IEEE Global Communications Conference (GLOBECOM), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive novel bounds for the performance of algorithms that estimate the
downlink covariance matrix from the uplink covariance matrix in frequency
division duplex (FDD) massive multiple-input multiple-output (MIMO) systems.
The focus is on algorithms that use estimates of the angular power spectrum as
an intermediate step. Unlike previous results, the proposed bounds follow from
simple arguments in possibly infinite dimensional Hilbert spaces, and they do
not require strong assumptions on the array geometry or on the propagation
model. Furthermore, they are suitable for the analysis of set-theoretic methods
that can efficiently incorporate side information about the angular power
spectrum. This last feature enables us to derive simple techniques to enhance
set-theoretic methods without any heuristic arguments. In particular, we show
that the performance of a simple algorithm that requires only a simple
matrix-vector multiplication cannot be improved significantly in some practical
scenarios, especially if coarse information about the support of the angular
power spectrum is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08489</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08489</id><created>2018-04-20</created><authors><author><keyname>Geraci</keyname><forenames>Giovanni</forenames></author><author><keyname>Garcia-Rodriguez</keyname><forenames>Adrian</forenames></author><author><keyname>Giordano</keyname><forenames>Lorenzo Galati</forenames></author><author><keyname>L&#xf3;pez-P&#xe9;rez</keyname><forenames>David</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author></authors><title>Understanding UAV Cellular Communications: From Existing Networks to
  Massive MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1802.01527</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to bestow the reader with a timely study of
UAV cellular communications, bridging the gap between the 3GPP standardization
status quo and the more forward-looking research. Special emphasis is placed on
the downlink command and control (C&amp;C) channel to aerial users, whose
reliability is deemed of paramount technological importance for the commercial
success of UAV cellular communications. Through a realistic side-by-side
comparison of two network deployments -- a present-day cellular infrastructure
versus a next-generation massive MIMO system -- a plurality of key facts are
cast light upon, with the three main ones summarized as follows: (i) UAV cell
selection is essentially driven by the secondary lobes of a base station's
radiation pattern, causing UAVs to associate to far-flung cells; (ii) over a 10
MHz bandwidth, and for UAV heights of up to 300 m, massive MIMO networks can
support 100 kbps C&amp;C channels in 74% of the cases when the uplink pilots for
channel estimation are reused among base station sites, and in 96% of the cases
without pilot reuse across the network; (iii) supporting UAV C&amp;C channels can
considerably affect the performance of ground users on account of severe pilot
contamination, unless suitable power control policies are in place.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08545</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08545</id><created>2018-04-20</created><authors><author><keyname>Sherborne</keyname><forenames>Tom</forenames></author><author><keyname>Banks</keyname><forenames>Benjamin</forenames></author><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author><author><keyname>Lavery</keyname><forenames>Domani&#xe7;</forenames></author></authors><title>On the Impact of Fixed Point Hardware for Optical Fiber Nonlinearity
  Compensation Algorithms</title><categories>eess.SP</categories><comments>8 pages, 8 figures, journal submission</comments><doi>10.1109/JLT.2018.2868115</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Nonlinearity mitigation using digital signal processing has been shown to
increase the achievable data rates of optical fiber transmission links. One
especially effective technique is digital back propagation (DBP), an algorithm
capable of simultaneously compensating for linear and nonlinear channel
distortions. The most significant barrier to implementing this technique,
however, is its high computational complexity. In recent years, there have been
several proposed alternatives to DBP with reduced computational complexity,
although such techniques have not demonstrated performance benefits
commensurate with the complexity of implementation. In order to fully
characterize the computational requirements of DBP, there is a need to model
the algorithm behavior when constrained to the logic used in a digital coherent
receiver. Such a model allows for the analysis of any signal recovery algorithm
in terms of true hardware complexity which, crucially, includes the bit-depth
of the multiplication operation. With a limited bit depth, there is
quantization noise, introduced with each arithmetic operation, and it can no
longer be assumed that the conventional DBP algorithm will outperform its low
complexity alternatives. In this work, DBP and a single nonlinear step DBP
implementation, the \textit{Enhanced Split Step Fourier} method (ESSFM), were
compared with linear equalization using a generic software model of fixed point
hardware. The requirements of bit depth and fast Fourier transform (FFT) size
are discussed to examine the optimal operating regimes for these two schemes of
digital nonlinearity compensation. For a 1000 km transmission system, it was
found that (assuming an optimized FFT size), in terms of SNR, the ESSFM
algorithm outperformed the conventional DBP for all hardware resolutions up to
13 bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08595</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08595</id><created>2018-04-23</created><authors><author><keyname>Ahmed</keyname><forenames>I. Zakir</forenames></author><author><keyname>Sadjadpour</keyname><forenames>Hamid</forenames></author><author><keyname>Yousefi</keyname><forenames>Shahram</forenames></author></authors><title>Single-User mmWave Massive MIMO: SVD-based ADC Bit Allocation and
  Combiner Design</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in SPCOM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a Singular-Value-Decomposition-based
variable-resolution Analog to Digital Converter (ADC) bit allocation design for
a single-user Millimeter wave massive Multiple-Input Multiple-Output receiver.
We derive the optimality condition for bit allocation under a power constraint.
This condition ensures optimal receiver performance in the Mean Squared Error
(MSE) sense. We derive the MSE expression and show that it approaches the
Cramer-Rao Lower Bound (CRLB). The CRLB is seen to be a function of the analog
combiner, the digital combiner, and the bit allocation matrix. We attempt to
minimize the CRLB with respect to the bit allocation matrix by making suitable
assumptions regarding the structure of the combiners. In doing so, the bit
allocation design reduces to a set of simple inequalities consisting of ADC
bits, channel singular values and covariance of the quantization noise along
each RF path. This results in a simple and computationally efficient bit
allocation algorithm. Using simulations, we show that the MSE performance of
our proposed bit allocation is very close to that of the Full Search (FS) bit
allocation. We also show that the computational complexity of our proposed
method has an order of magnitude improvement compared to FS and Genetic
Algorithm based bit allocation of $\cite{Zakir1}$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08608</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08608</id><created>2018-04-23</created><authors><author><keyname>Gonz&#xe1;lez-Huici</keyname><forenames>M. A.</forenames></author><author><keyname>Mateos-N&#xfa;&#xf1;ez</keyname><forenames>D.</forenames></author><author><keyname>Greiff</keyname><forenames>C.</forenames></author><author><keyname>Simoni</keyname><forenames>R.</forenames></author></authors><title>Constrained optimal design of automotive radar arrays using the
  Weiss-Weinstein Bound</title><categories>eess.SP</categories><comments>2018 IEEE MTT-S International Conference on Microwaves for
  Intelligent Mobility (ICMIM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a design strategy for optimizing antenna positions in linear
arrays for far-field Direction of Arrival (DoA) estimation of narrow-band
sources in collocated MIMO radar. Our methodology allows to consider any
spatial constraints and number of antennas, using as optimization function the
Weiss- Weinstein bound formulated for an observation model with random target
phase and known SNR, over a pre-determined Field-of-View (FoV). Optimized
arrays are calculated for the typical case of a 77GHz MIMO radar of 3Tx and 4Rx
channels. Simulations demonstrate a performance improvement of the proposed
arrays compared to the corresponding uniform and minimum redundancy arrays for
a wide regime of SNR values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08640</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08640</id><created>2018-04-23</created><authors><author><keyname>Larew</keyname><forenames>Stephen G.</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author></authors><title>Adaptive Beam Tracking with the Unscented Kalman Filter for Millimeter
  Wave Communication</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2019.2944255</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) communication links for 5G cellular technology
require high beamforming gain to overcome channel impairments and achieve high
throughput. While much work has focused on estimating mmWave channels and
designing beamforming schemes, the time dynamic nature of mmWave channels
quickly renders estimates stale and increases sounding overhead. We model the
underlying time dynamic state space of mmWave channels and design sounding
beamformers suitable for tracking in a Kalman filtering framework. Given an
initial channel estimate, filtering efficiently leads to refined estimates and
allows forward prediction for higher sustained beamforming gain during data
transmission. From tracked prior channel estimates, adaptively chosen optimal
and constrained suboptimal beams reduce sounding overhead while minimizing
estimation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08663</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08663</id><created>2018-04-23</created><updated>2018-07-12</updated><authors><author><keyname>Willi</keyname><forenames>Megan M.</forenames></author><author><keyname>Borrie</keyname><forenames>Stephanie A.</forenames></author><author><keyname>Barrett</keyname><forenames>Tyson S.</forenames></author><author><keyname>Tu</keyname><forenames>Ming</forenames></author><author><keyname>Berisha</keyname><forenames>Visar</forenames></author></authors><title>A Discriminative Acoustic-Prosodic Approach for Measuring Local
  Entrainment</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic-prosodic entrainment describes the tendency of humans to align or
adapt their speech acoustics to each other in conversation. This alignment of
spoken behavior has important implications for conversational success. However,
modeling the subtle nature of entrainment in spoken dialogue continues to pose
a challenge. In this paper, we propose a straightforward definition for local
entrainment in the speech domain and operationalize an algorithm based on this:
acoustic-prosodic features that capture entrainment should be maximally
different between real conversations involving two partners and sham
conversations generated by randomly mixing the speaking turns from the original
two conversational partners. We propose an approach for measuring local
entrainment that quantifies alignment of behavior on a turn-by-turn basis,
projecting the differences between interlocutors' acoustic-prosodic features
for a given turn onto a discriminative feature subspace that maximizes the
difference between real and sham conversations. We evaluate the method using
the derived features to drive a classifier aiming to predict an objective
measure of conversational success (i.e., low versus high), on a corpus of
task-oriented conversations. The proposed entrainment approach achieves 72%
classification accuracy using a Naive Bayes classifier, outperforming three
previously established approaches evaluated on the same conversational corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08669</identifier>
 <datestamp>2018-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08669</id><created>2018-04-23</created><authors><author><keyname>Fahad</keyname><forenames>Muhammad</forenames></author><author><keyname>Guo</keyname><forenames>Yi</forenames></author><author><keyname>Bingham</keyname><forenames>Brian</forenames></author><author><keyname>Krasnosky</keyname><forenames>Kristopher</forenames></author><author><keyname>Fitzpatrick</keyname><forenames>Laura</forenames></author><author><keyname>Sanabria</keyname><forenames>Fernando A.</forenames></author></authors><title>Ocean Plume Tracking with Unmanned Surface Vessels: Algorithms and
  Experiments</title><categories>eess.SP cs.RO</categories><comments>This paper has been accepted at WCICA 2018 and will appear in the
  proceedings of that conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pollution plume monitoring using autonomous vehicles is important due to the
adverse effect of pollution plumes on the environment and associated monetary
losses. Using the advection-diffusion plume dispersion model, we present a
control law design to track dynamic concentration level curves. We also present
a gradient and divergence estimation method to enable this control law from
concentration measurement only. We then present the field testing results of
the control law to track concentration level curves in a plume generated using
Rhodamine dye as a pollution surrogate in a near-shore marine environment.
These plumes are then autonomously tracked using an unmanned surface vessel
equipped with fluorometer sensors. Field experimental results are shown to
evaluate the performance of the controller, and complexities of field
experiments in real-world marine environments are discussed in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08782</identifier>
 <datestamp>2019-04-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08782</id><created>2018-04-23</created><authors><author><keyname>Nasir</keyname><forenames>Md</forenames></author><author><keyname>Baucom</keyname><forenames>Brian</forenames></author><author><keyname>Narayanan</keyname><forenames>Shrikanth</forenames></author><author><keyname>Georgiou</keyname><forenames>Panayiotis</forenames></author></authors><title>Towards an Unsupervised Entrainment Distance in Conversational Speech
  using Deep Neural Networks</title><categories>eess.AS cs.CL cs.SD</categories><comments>submitted to Interspeech 2018</comments><doi>10.21437/Interspeech.2018-1395</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Entrainment is a known adaptation mechanism that causes interaction
participants to adapt or synchronize their acoustic characteristics.
Understanding how interlocutors tend to adapt to each other's speaking style
through entrainment involves measuring a range of acoustic features and
comparing those via multiple signal comparison methods. In this work, we
present a turn-level distance measure obtained in an unsupervised manner using
a Deep Neural Network (DNN) model, which we call Neural Entrainment Distance
(NED). This metric establishes a framework that learns an embedding from the
population-wide entrainment in an unlabeled training corpus. We use the
framework for a set of acoustic features and validate the measure
experimentally by showing its efficacy in distinguishing real conversations
from fake ones created by randomly shuffling speaker turns. Moreover, we show
real world evidence of the validity of the proposed measure. We find that high
value of NED is associated with high ratings of emotional bond in suicide
assessment interviews, which is consistent with prior studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08806</identifier>
 <datestamp>2018-12-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08806</id><created>2018-04-23</created><authors><author><keyname>Kanatsoulis</keyname><forenames>Charilaos I.</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author></authors><title>Structured SUMCOR Multiview Canonical Correlation Analysis for
  Large-Scale Data</title><categories>cs.LG cs.IR eess.SP stat.ML</categories><doi>10.1109/TSP.2018.2878544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum-of-correlations (SUMCOR) formulation of generalized canonical
correlation analysis (GCCA) seeks highly correlated low-dimensional
representations of different views via maximizing pairwise latent similarity of
the views. SUMCOR is considered arguably the most natural extension of
classical two-view CCA to the multiview case, and thus has numerous
applications in signal processing and data analytics. Recent work has proposed
effective algorithms for handling the SUMCOR problem at very large scale.
However, the existing scalable algorithms cannot incorporate structural
regularization and prior information -- which are critical for good performance
in real-world applications. In this work, we propose a new computational
framework for large-scale SUMCOR GCCA that can easily incorporate a suite of
structural regularizers which are frequently used in data analytics. The
updates of the proposed algorithm are lightweight and the memory complexity is
also low. In addition, the proposed algorithm can be readily implemented in a
parallel fashion. We show that the proposed algorithm converges to a
Karush-Kuhn-Tucker (KKT) point of the regularized SUMCOR problem. Judiciously
designed simulations and real-data experiments are employed to demonstrate the
effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08811</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08811</id><created>2018-04-23</created><updated>2019-01-22</updated><authors><author><keyname>Sakiyama</keyname><forenames>Akie</forenames></author><author><keyname>Watanabe</keyname><forenames>Kana</forenames></author><author><keyname>Tanaka</keyname><forenames>Yuichi</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Two-Channel Critically-Sampled Graph Filter Banks With Spectral Domain
  Sampling</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2892033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two-channel critically-sampled filter banks for signals on
undirected graphs that utilize spectral domain sampling. Unlike conventional
approaches based on vertex domain sampling, our transforms have the following
desirable properties: 1) perfect reconstruction regardless of the
characteristics of the underlying graphs and graph variation operators and 2) a
symmetric structure; i.e., both analysis and synthesis filter banks are built
using similar building blocks. Along with the structure of the filter banks,
this paper also proves the general criterion for perfect reconstruction and
theoretically shows that the vertex and spectral domain sampling coincide for a
special case. The effectiveness of our approach is evaluated by comparing its
performance in nonlinear approximation and denoising with various conventional
graph transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08839</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08839</id><created>2018-04-24</created><updated>2019-06-08</updated><authors><author><keyname>Chu</keyname><forenames>Lei</forenames></author><author><keyname>Wen</keyname><forenames>Fei</forenames></author><author><keyname>Li</keyname><forenames>Lily</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>Efficient Nonlinear Precoding for Massive MU-MIMO Downlink Systems with
  1-Bit DACs</title><categories>eess.SP math.OC</categories><comments>12 pages, 7 figures</comments><journal-ref>published in IEEE Transactions On Wireless Communications, 2019</journal-ref><doi>10.1109/TWC.2019.2920125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The power consumption of digital-to-analog converters (DACs) constitutes a
significant proportion of the total power consumption in a massive multiuser
multiple-input multiple-output (MU-MIMO) base station (BS). Using 1-bit DACs
can significantly reduce the power consumption. This paper addresses the
precoding problem for the massive narrow-band MU-MIMO downlink system equipped
with 1-bit DACs at each BS. In such a system, the precoding problem plays a
central role as the precoded symbols are affected by extra distortion
introduced by 1-bit DACs. In this paper, we develop a highly-efficient
nonlinear precoding algorithm based on the alternative direction method
framework. Unlike the classic algorithms, such as the semidefinite relaxation
(SDR) and squared-infinity norm Douglas-Rachford splitting (SQUID) algorithms,
which solve convex relaxed versions of the original precoding problem, the new
algorithm solves the original nonconvex problem directly. The new algorithm is
guaranteed to globally converge under some mild conditions. A sufficient
condition for its convergence has been derived. Experimental results in various
conditions demonstrated that, the new algorithm can achieve state-of-the-art
accuracy comparable to the SDR algorithm, while being much more efficient (more
than 300 times faster than the SDR algorithm).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08850</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08850</id><created>2018-04-24</created><updated>2018-05-01</updated><authors><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author><author><keyname>Hafermann</keyname><forenames>Hartmut</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Increasing Achievable Information Rates via Geometric Shaping</title><categories>cs.IT eess.SP math.IT</categories><comments>Additional references have been added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achievable information rates are used as a metric to design novel modulation
formats via geometric shaping. The proposed geometrically shaped 256-ary
constellation achieves SNR gains of up to 1.18 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.08910</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.08910</id><created>2018-04-24</created><updated>2018-05-28</updated><authors><author><keyname>Hautam&#xe4;ki</keyname><forenames>Rosa Gonz&#xe1;lez</forenames></author><author><keyname>Kanervisto</keyname><forenames>Anssi</forenames></author><author><keyname>Hautam&#xe4;ki</keyname><forenames>Ville</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author></authors><title>Perceptual Evaluation of the Effectiveness of Voice Disguise by Age
  Modification</title><categories>cs.SD cs.CY eess.AS</categories><comments>Accepted to Speaker Odyssey 2018: The Speaker and Language
  Recognition Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice disguise, purposeful modification of one's speaker identity with the
aim of avoiding being identified as oneself, is a low-effort way to fool
speaker recognition, whether performed by a human or an automatic speaker
verification (ASV) system. We present an evaluation of the effectiveness of age
stereotypes as a voice disguise strategy, as a follow up to our recent work
where 60 native Finnish speakers attempted to sound like an elderly and like a
child. In that study, we presented evidence that both ASV and human observers
could easily miss the target speaker but we did not address how believable the
presented vocal age stereotypes were; this study serves to fill that gap. The
interesting cases would be speakers who succeed in being missed by the ASV
system, and which a typical listener cannot detect as being a disguise. We
carry out a perceptual test to study the quality of the disguised speech
samples. The listening test was carried out both locally and with the help of
Amazon's Mechanical Turk (MT) crowd-workers. A total of 91 listeners
participated in the test and were instructed to estimate both the speaker's
chronological and intended age. The results indicate that age estimations for
the intended old and child voices for female speakers were towards the target
age groups, while for male speakers, the age estimations corresponded to the
direction of the target voice only for elderly voices. In the case of intended
child's voice, listeners estimated the age of male speakers to be older than
their chronological age for most of the speakers and not the intended target
age.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09123</identifier>
 <datestamp>2018-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09123</id><created>2018-04-24</created><authors><author><keyname>Montagna</keyname><forenames>Fabio</forenames></author><author><keyname>Rahimi</keyname><forenames>Abbas</forenames></author><author><keyname>Benatti</keyname><forenames>Simone</forenames></author><author><keyname>Rossi</keyname><forenames>Davide</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>PULP-HD: Accelerating Brain-Inspired High-Dimensional Computing on a
  Parallel Ultra-Low Power Platform</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing with high-dimensional (HD) vectors, also referred to as
$\textit{hypervectors}$, is a brain-inspired alternative to computing with
scalars. Key properties of HD computing include a well-defined set of
arithmetic operations on hypervectors, generality, scalability, robustness,
fast learning, and ubiquitous parallel operations. HD computing is about
manipulating and comparing large patterns-binary hypervectors with 10,000
dimensions-making its efficient realization on minimalistic ultra-low-power
platforms challenging. This paper describes HD computing's acceleration and its
optimization of memory accesses and operations on a silicon prototype of the
PULPv3 4-core platform (1.5mm$^2$, 2mW), surpassing the state-of-the-art
classification accuracy (on average 92.4%) with simultaneous 3.7$\times$
end-to-end speed-up and 2$\times$ energy saving compared to its single-core
execution. We further explore the scalability of our accelerator by increasing
the number of inputs and classification window on a new generation of the PULP
architecture featuring bit-manipulation instruction extensions and larger
number of 8 cores. These together enable a near ideal speed-up of 18.4$\times$
compared to the single-core PULPv3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09202</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09202</id><created>2018-04-24</created><authors><author><keyname>Su</keyname><forenames>Li</forenames></author></authors><title>Vocal melody extraction using patch-based CNN</title><categories>cs.SD eess.AS</categories><journal-ref>Proc. Int. Conf. Acoustic, Speech and Signal Processing (ICASSP),
  2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A patch-based convolutional neural network (CNN) model presented in this
paper for vocal melody extraction in polyphonic music is inspired from object
detection in image processing. The input of the model is a novel time-frequency
representation which enhances the pitch contours and suppresses the harmonic
components of a signal. This succinct data representation and the patch-based
CNN model enable an efficient training process with limited labeled data.
Experiments on various datasets show excellent speed and competitive accuracy
comparing to other deep learning approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09288</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09288</id><created>2018-04-24</created><authors><author><keyname>Shah</keyname><forenames>Ankit</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Hauptmann</keyname><forenames>Alexander G.</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>A Closer Look at Weak Label Learning for Audio Events</title><categories>cs.SD cs.LG cs.MM eess.AS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio content analysis in terms of sound events is an important research
problem for a variety of applications. Recently, the development of weak
labeling approaches for audio or sound event detection (AED) and availability
of large scale weakly labeled dataset have finally opened up the possibility of
large scale AED. However, a deeper understanding of how weak labels affect the
learning for sound events is still missing from literature. In this work, we
first describe a CNN based approach for weakly supervised training of audio
events. The approach follows some basic design principle desirable in a
learning method relying on weakly labeled audio. We then describe important
characteristics, which naturally arise in weakly supervised learning of sound
events. We show how these aspects of weak labels affect the generalization of
models. More specifically, we study how characteristics such as label density
and corruption of labels affects weakly supervised training for audio events.
We also study the feasibility of directly obtaining weak labeled data from the
web without any manual label and compare it with a dataset which has been
manually labeled. The analysis and understanding of these factors should be
taken into picture in the development of future weak label learning methods.
Audioset, a large scale weakly labeled dataset for sound events is used in our
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09291</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09291</id><created>2018-04-24</created><authors><author><keyname>Chen</keyname><forenames>Di</forenames></author><author><keyname>Fu</keyname><forenames>Chichen</forenames></author><author><keyname>Zhu</keyname><forenames>Fengqing</forenames></author></authors><title>AV1 Video Coding Using Texture Analysis With Convolutional Neural
  Networks</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern video codecs including the newly developed AOM/AV1 utilize hybrid
coding techniques to remove spatial and temporal redundancy. However, efficient
exploitation of statistical dependencies measured by a mean squared error (MSE)
does not always produce the best psychovisual result. One interesting approach
is to only encode visually relevant information and use a different coding
method for &quot;perceptually insignificant&quot; regions in the frame, which can lead to
substantial data rate reductions while maintaining visual quality. In this
paper, we introduce a texture analyzer before encoding the input sequences to
identify detail irrelevant texture regions in the frame using convolutional
neural networks. We designed and developed a new coding tool referred to as
texture mode for AV1, where if texture mode is selected at the encoder, no
inter-frame prediction is performed for the identified texture regions.
Instead, displacement of the entire region is modeled by just one set of motion
parameters. Therefore, only the model parameters are transmitted to the decoder
for reconstructing the texture regions. Non-texture regions in the frame are
coded conventionally. We show that for many standard test sets, the proposed
method achieved significant data rate reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09295</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09295</id><created>2018-04-24</created><updated>2018-11-21</updated><authors><author><keyname>Dai</keyname><forenames>Jisheng</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Joint Channel Estimation and User Grouping for Massive MIMO Systems</title><categories>eess.SP</categories><comments>15 pages, 11 figures, IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2018.2883852</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of joint downlink channel estimation and
user grouping in massive multiple-input multiple-output (MIMO) systems, where
the motivation comes from the fact that the channel estimation performance can
be improved if we exploit additional common sparsity among nearby users. In the
literature, a commonly used group sparsity model assumes that users in each
group share a uniform sparsity pattern. In practice, however, this
oversimplified assumption usually fails to hold, even for physically close
users. Outliers deviated from the uniform sparsity pattern in each group may
significantly degrade the effectiveness of common sparsity, and hence bring
limited (or negative) gain for channel estimation. To better capture the group
sparse structure in practice, we provide a general model having two sparsity
components: commonly shared sparsity and individual sparsity, where the
additional individual sparsity accounts for any outliers. Then, we propose a
novel sparse Bayesian learning (SBL)-based framework to address the joint
channel estimation and user grouping problem under the general sparsity model.
The framework can fully exploit the common sparsity among nearby users and
exclude the harmful effect from outliers simultaneously. Simulation results
reveal substantial performance gains over the existing state-of-the-art
baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09298</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09298</id><created>2018-04-24</created><updated>2018-04-26</updated><authors><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Li</keyname><forenames>Jinyu</forenames></author></authors><title>Recent Progresses in Deep Learning based Acoustic Models (Updated)</title><categories>eess.AS cs.CL cs.SD</categories><comments>This is an updated version with latest literature until ICASSP2018 of
  the paper: Dong Yu and Jinyu Li, &quot;Recent Progresses in Deep Learning based
  Acoustic Models,&quot; vol.4, no.3, IEEE/CAA Journal of Automatica Sinica, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we summarize recent progresses made in deep learning based
acoustic models and the motivation and insights behind the surveyed techniques.
We first discuss acoustic models that can effectively exploit variable-length
contextual information, such as recurrent neural networks (RNNs), convolutional
neural networks (CNNs), and their various combination with other models. We
then describe acoustic models that are optimized end-to-end with emphasis on
feature representations learned jointly with rest of the system, the
connectionist temporal classification (CTC) criterion, and the attention-based
sequence-to-sequence model. We further illustrate robustness issues in speech
recognition systems, and discuss acoustic model adaptation, speech enhancement
and separation, and robust training strategies. We also cover modeling
techniques that lead to more efficient decoding and discuss possible future
directions in acoustic model research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09310</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09310</id><created>2018-04-24</created><authors><author><keyname>Risbud</keyname><forenames>Paresh</forenames></author><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Taha</keyname><forenames>Ahmad</forenames></author></authors><title>Vulnerability Analysis of Smart Grids to GPS Spoofing</title><categories>cs.SY cs.CR eess.SP</categories><comments>Accepted for publication in the IEEE Transactions on Smart Grid</comments><doi>10.1109/TSG.2018.2830118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensors such as phasor measurement units (PMUs) endowed with GPS receivers
are ubiquitously installed providing real-time grid visibility. A number of
PMUs can cooperatively enable state estimation routines. However, GPS spoofing
attacks can notably alter the PMU measurements, mislead the network operator,
and drastically impact subsequent corrective control actions. Leveraging a
novel measurement model that explicitly accounts for the GPS spoofing attacks,
this paper formulates an optimization problem to identify the most vulnerable
PMUs in the network. A greedy algorithm is developed to solve the
aforementioned problem. Furthermore, the paper develops a computationally
efficient alternating minimization algorithm for joint state estimation and
attack reconstruction. Numerical tests on IEEE benchmark networks validate the
developed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09348</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09348</id><created>2018-04-25</created><authors><author><keyname>Wada</keyname><forenames>Tomoya</forenames></author><author><keyname>Fukumori</keyname><forenames>Kosuke</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshihisa</forenames></author><author><keyname>Fiori</keyname><forenames>Simone</forenames></author></authors><title>Generalized Gaussian Kernel Adaptive Filtering</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper proposes generalized Gaussian kernel adaptive filtering,
where the kernel parameters are adaptive and data-driven. The Gaussian kernel
is parametrized by a center vector and a symmetric positive definite (SPD)
precision matrix, which is regarded as a generalization of the scalar width
parameter. These parameters are adaptively updated on the basis of a proposed
least-square-type rule to minimize the estimation error. The main contribution
of this paper is to establish update rules for precision matrices on the SPD
manifold in order to keep their symmetric positive-definiteness. Different from
conventional kernel adaptive filters, the proposed regressor is a superposition
of Gaussian kernels with all different parameters, which makes such regressor
more flexible. The kernel adaptive filtering algorithm is established together
with a l1-regularized least squares to avoid overfitting and the increase of
dimensionality of the dictionary. Experimental results confirm the validity of
the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09396</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09396</id><created>2018-04-25</created><updated>2019-08-09</updated><authors><author><keyname>Ahn</keyname><forenames>Hyun-Seo</forenames></author><author><keyname>Park</keyname><forenames>Sung-Hong</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Quantitative Susceptibility Map Reconstruction Using Annihilating
  Filter-based Low-Rank Hankel Matrix Approach</title><categories>cs.CV eess.SP physics.med-ph</categories><comments>accepted for Magnetic Resonance in Medicine</comments><report-no>doi: 10.1002/mrm.27976</report-no><doi>10.1002/mrm.27976</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative susceptibility mapping (QSM) inevitably suffers from streaking
artifacts caused by zeros on the conical surface of the dipole kernel in
k-space. This work proposes a novel and accurate QSM reconstruction method
based on a direct k-space interpolation approach, avoiding problems of over
smoothing and streaking artifacts. Inspired by the recent theory of
annihilating filter-based low-rank Hankel matrix approach (ALOHA), QSM
reconstruction problem is formulated as deconvolution problem under low-rank
Hankel matrix constraint in the k-space. To reduce the computational complexity
and the memory requirement, the problem is formulated as successive
reconstruction of 2-D planes along three independent axes of the 3-D phase
image in Fourier domain. Extensive experiments were performed to verify and
compare the proposed method with existing QSM reconstruction methods. The
proposed ALOHA-QSM effectively reduced streaking artifacts and accurately
estimated susceptibility values in deep gray matter structures, compared to the
existing QSM methods. Our suggested ALOHA-QSM algorithm successfully solves the
three-dimensional QSM dipole inversion problem without additional anatomical
information or prior assumption and provides good image quality and
quantitative accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09399</identifier>
 <datestamp>2018-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09399</id><created>2018-04-25</created><updated>2018-10-06</updated><authors><author><keyname>Dong</keyname><forenames>Hao-Wen</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Convolutional Generative Adversarial Networks with Binary Neurons for
  Polyphonic Music Generation</title><categories>cs.LG cs.AI cs.SD eess.AS stat.ML</categories><comments>A preliminary version of this paper appeared in ISMIR 2018. In this
  version, we added an appendix to provide figures of sample results and
  remarks on the end-to-end models</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown recently that deep convolutional generative adversarial
networks (GANs) can learn to generate music in the form of piano-rolls, which
represent music by binary-valued time-pitch matrices. However, existing models
can only generate real-valued piano-rolls and require further post-processing,
such as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final
binary-valued results. In this paper, we study whether we can have a
convolutional GAN model that directly creates binary-valued piano-rolls by
using binary neurons. Specifically, we propose to append to the generator an
additional refiner network, which uses binary neurons at the output layer. The
whole network is trained in two stages. Firstly, the generator and the
discriminator are pretrained. Then, the refiner network is trained along with
the discriminator to learn to binarize the real-valued piano-rolls the
pretrained generator creates. Experimental results show that using binary
neurons instead of HT or BS indeed leads to better results in a number of
objective measures. Moreover, deterministic binary neurons perform better than
stochastic ones in both objective measures and a subjective test. The source
code, training data and audio examples of the generated results can be found at
https://salu133445.github.io/bmusegan/ .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09415</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09415</id><created>2018-04-25</created><authors><author><keyname>Hamzi</keyname><forenames>Boumediene</forenames></author><author><keyname>Kuehn</keyname><forenames>Christian</forenames></author><author><keyname>Mohamed</keyname><forenames>Sameh</forenames></author></authors><title>A Note on Kernel Methods for Multiscale Systems with Critical
  Transitions</title><categories>nlin.PS eess.SP math.DS physics.data-an stat.ML</categories><comments>15 pages, 4 figures; preprint, comments and suggestions very welcome!</comments><doi>10.1002/mma.5394</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the maximum mean discrepancy (MMD) in the context of critical
transitions modelled by fast-slow stochastic dynamical systems. We establish a
new link between the dynamical theory of critical transitions with the
statistical aspects of the MMD. In particular, we show that a formal
approximation of the MMD near fast subsystem bifurcation points can be computed
to leading-order. In particular, this leading order approximation shows that
the MMD depends intricately on the fast-slow systems parameters and one can
only expect to extract warning signs under rather stringent conditions.
However, the MMD turns out to be an excellent binary classifier to detect the
change point induced by the critical transition. We cross-validate our results
by numerical simulations for a van der Pol-type model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09497</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09497</id><created>2018-04-25</created><updated>2018-06-29</updated><authors><author><keyname>F&#xe9;votte</keyname><forenames>C&#xe9;dric</forenames></author><author><keyname>Kowalski</keyname><forenames>Matthieu</forenames></author></authors><title>Estimation with Low-Rank Time-Frequency Synthesis Models</title><categories>eess.SP cs.LG eess.AS</categories><journal-ref>C. F\'evotte and M. Kowalski. Estimation with low-rank
  time-frequency synthesis models. IEEE Transactions on Signal Processing,
  66(15):4121-4132, Aug. 2018</journal-ref><doi>10.1109/TSP.2018.2844159</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many state-of-the-art signal decomposition techniques rely on a low-rank
factorization of a time-frequency (t-f) transform. In particular, nonnegative
matrix factorization (NMF) of the spectrogram has been considered in many audio
applications. This is an analysis approach in the sense that the factorization
is applied to the squared magnitude of the analysis coefficients returned by
the t-f transform. In this paper we instead propose a synthesis approach, where
low-rankness is imposed to the synthesis coefficients of the data signal over a
given t-f dictionary (such as a Gabor frame). As such we offer a novel modeling
paradigm that bridges t-f synthesis modeling and traditional analysis-based NMF
approaches. The proposed generative model allows in turn to design more
sophisticated multi-layer representations that can efficiently capture diverse
forms of structure. Additionally, the generative modeling allows to exploit t-f
low-rankness for compressive sensing. We present efficient iterative shrinkage
algorithms to perform estimation in the proposed models and illustrate the
capabilities of the new modeling paradigm over audio signal processing
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09567</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09567</id><created>2018-04-25</created><updated>2018-08-14</updated><authors><author><keyname>Wang</keyname><forenames>Lu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhengwu</forenames></author><author><keyname>Dunson</keyname><forenames>David</forenames></author></authors><title>Symmetric Bilinear Regression for Signal Subgraph Estimation</title><categories>stat.ME eess.SP</categories><comments>12 pages, double columns, 18 figures</comments><doi>10.1109/TSP.2019.2899818</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is increasing interest in learning a set of small outcome-relevant
subgraphs in network-predictor regression. The extracted signal subgraphs can
greatly improve the interpretation of the association between the network
predictor and the response. In brain connectomics, the brain network for an
individual corresponds to a set of interconnections among brain regions and
there is a strong interest in linking the brain connectome to human cognitive
traits. Modern neuroimaging technology allows a very fine segmentation of the
brain, producing very large structural brain networks. Therefore, accurate and
efficient methods for identifying a set of small predictive subgraphs become
crucial, leading to discovery of key interconnected brain regions related to
the trait and important insights on the mechanism of variation in human
cognitive traits. We propose a symmetric bilinear model with $L_1$ penalty to
search for small clique subgraphs that contain useful information about the
response. A coordinate descent algorithm is developed to estimate the model
where we derive analytical solutions for a sequence of conditional convex
optimizations. Application of this method on human connectome and language
comprehension data shows interesting discovery of relevant interconnections
among several small sets of brain regions and better predictive performance
than competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09585</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09585</id><created>2018-04-25</created><authors><author><keyname>Mamaghani</keyname><forenames>Baabak</forenames></author><author><keyname>Sasaki</keyname><forenames>Geoffrey</forenames></author><author><keyname>Connal</keyname><forenames>Ryan</forenames></author><author><keyname>Kha</keyname><forenames>Kevin</forenames></author><author><keyname>Knappen</keyname><forenames>Jackson</forenames></author><author><keyname>Hartzell</keyname><forenames>Ryan</forenames></author><author><keyname>Marcellus</keyname><forenames>Evan</forenames></author><author><keyname>Bauch</keyname><forenames>Timothy</forenames></author><author><keyname>Raqueno</keyname><forenames>Nina</forenames></author><author><keyname>Salvaggio</keyname><forenames>Carl</forenames></author></authors><title>An initial exploration of vicarious and in-scene calibration techniques
  for small unmanned aircraft systems</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of small unmanned aircraft systems (sUAS) for applications in the
field of precision agriculture has demonstrated the need to produce temporally
consistent imagery to allow for quantitative comparisons. In order for these
aerial images to be used to identify actual changes on the ground, conversion
of raw digital count to reflectance, or to an atmospherically normalized space,
needs to be carried out. This paper will describe an experiment that compares
the use of reflectance calibration panels, for use with the empirical line
method (ELM), against a newly proposed ratio of the target radiance and the
downwelling radiance, to predict the reflectance of known targets in the scene.
We propose that the use of an on-board downwelling light sensor (DLS) may
provide the sUAS remote sensing practitioner with an approach that does not
require the expensive and time consuming task of placing known reflectance
standards in the scene. Three calibration methods were tested in this study:
2-Point ELM, 1-Point ELM, and At-altitude Radiance Ratio (AARR). Our study
indicates that the traditional 2-Point ELM produces the lowest mean error in
band effective reflectance factor, 0.0165. The 1-Point ELM and AARR produce
mean errors of 0.0343 and 0.0287 respectively. A modeling of the proposed AARR
approach indicates that the technique has the potential to perform better than
the 2-Point ELM method, with a 0.0026 mean error in band effective reflectance
factor, indicating that this newly proposed technique may prove to be a viable
alternative with suitable on-board sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09593</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09593</id><created>2018-04-25</created><authors><author><keyname>Juvela</keyname><forenames>Lauri</forenames></author><author><keyname>Tsiaras</keyname><forenames>Vassilis</forenames></author><author><keyname>Bollepalli</keyname><forenames>Bajibabu</forenames></author><author><keyname>Airaksinen</keyname><forenames>Manu</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Alku</keyname><forenames>Paavo</forenames></author></authors><title>Speaker-independent raw waveform model for glottal excitation</title><categories>eess.AS cs.SD stat.ML</categories><comments>Submitted to Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent speech technology research has seen a growing interest in using
WaveNets as statistical vocoders, i.e., generating speech waveforms from
acoustic features. These models have been shown to improve the generated speech
quality over classical vocoders in many tasks, such as text-to-speech synthesis
and voice conversion. Furthermore, conditioning WaveNets with acoustic features
allows sharing the waveform generator model across multiple speakers without
additional speaker codes. However, multi-speaker WaveNet models require large
amounts of training data and computation to cover the entire acoustic space.
This paper proposes leveraging the source-filter model of speech production to
more effectively train a speaker-independent waveform generator with limited
resources. We present a multi-speaker 'GlotNet' vocoder, which utilizes a
WaveNet to generate glottal excitation waveforms, which are then used to excite
the corresponding vocal tract filter to produce speech. Listening tests show
that the proposed model performs favourably to a direct WaveNet vocoder trained
with the same model architecture and data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09618</identifier>
 <datestamp>2019-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09618</id><created>2018-04-25</created><updated>2019-04-11</updated><authors><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author><author><keyname>Lee</keyname><forenames>Kong Aik</forenames></author><author><keyname>Delgado</keyname><forenames>Hector</forenames></author><author><keyname>Evans</keyname><forenames>Nicholas</forenames></author><author><keyname>Todisco</keyname><forenames>Massimiliano</forenames></author><author><keyname>Sahidullah</keyname><forenames>Md</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Reynolds</keyname><forenames>Douglas A.</forenames></author></authors><title>t-DCF: a Detection Cost Function for the Tandem Assessment of Spoofing
  Countermeasures and Automatic Speaker Verification</title><categories>eess.AS cs.CR cs.SD stat.ML</categories><comments>Published in Odyssey 2018: the Speaker and Language Recognition
  Workshop [cleaned up source files]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ASVspoof challenge series was born to spearhead research in anti-spoofing
for automatic speaker verification (ASV). The two challenge editions in 2015
and 2017 involved the assessment of spoofing countermeasures (CMs) in isolation
from ASV using an equal error rate (EER) metric. While a strategic approach to
assessment at the time, it has certain shortcomings. First, the CM EER is not
necessarily a reliable predictor of performance when ASV and CMs are combined.
Second, the EER operating point is ill-suited to user authentication
applications, e.g. telephone banking, characterised by a high target user prior
but a low spoofing attack prior. We aim to migrate from CM- to ASV-centric
assessment with the aid of a new tandem detection cost function (t-DCF) metric.
It extends the conventional DCF used in ASV research to scenarios involving
spoofing attacks. The t-DCF metric has 6 parameters: (i) false alarm and miss
costs for both systems, and (ii) prior probabilities of target and spoof trials
(with an implied third, nontarget prior). The study is intended to serve as a
self-contained, tutorial-like presentation. We analyse with the t-DCF a
selection of top-performing CM submissions to the 2015 and 2017 editions of
ASVspoof, with a focus on the spoofing attack prior. Whereas there is little to
choose between countermeasure systems for lower priors, system rankings derived
with the EER and t-DCF show differences for higher priors. We observe some
ranking changes. Findings support the adoption of the DCF-based metric into the
roadmap for future ASVspoof challenges, and possibly for other biometric
anti-spoofing evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09671</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09671</id><created>2018-04-25</created><updated>2018-04-28</updated><authors><author><keyname>Alsamhi</keyname><forenames>S. H.</forenames></author><author><keyname>Ma</keyname><forenames>Ou</forenames></author><author><keyname>Ansari</keyname><forenames>M. S.</forenames></author></authors><title>Artificial Intelligence-Based Techniques for Emerging Robotics
  Communication: A Survey and Future Perspectives</title><categories>eess.SP</categories><comments>11 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper reviews the current development of artificial intelligence (AI)
techniques for the application area of robot communication. The study of the
control and operation of multiple robots collaboratively toward a common goal
is fast growing. Communication among members of a robot team and even including
humans is becoming essential in many real-world applications. The survey
focuses on the AI techniques for robot communication to enhance the
communication capability of the multi-robot team, making more complex
activities, taking an appreciated decision, taking coordinated action, and
performing their tasks efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09680</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09680</id><created>2018-04-25</created><updated>2018-04-26</updated><authors><author><keyname>Chatterjee</keyname><forenames>Shubhajeet</forenames></author><author><keyname>Abdel-Rahman</keyname><forenames>Mohammad J</forenames></author><author><keyname>MacKenzie</keyname><forenames>Allen B.</forenames></author></authors><title>Optimal Virtualization Framework for Cellular Networks with Downlink
  Rate Coverage Probability Constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless network virtualization is emerging as an important technology for
next-generation (5G) wireless networks. A key advantage of introducing
virtualization in cellular networks is that service providers can robustly
share virtualized network resources (e.g., infrastructure and spectrum) to
extend coverage, increase capacity, and reduce costs. {However, the inherent
features of wireless networks, i.e., the uncertainty in user equipment (UE)
locations and channel conditions impose significant challenges on
virtualization and sharing of the network resources.} In this context, we
propose a stochastic optimization-based virtualization framework that enables
robust sharing of network resources. Our proposed scheme aims at
probabilistically guaranteeing UEs' Quality of Service (QoS) demand
satisfaction, while minimizing the cost for service providers, with reasonable
computational complexity and affordable network overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09713</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09713</id><created>2018-04-25</created><authors><author><keyname>Palaskar</keyname><forenames>Shruti</forenames></author><author><keyname>Sanabria</keyname><forenames>Ramon</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>End-to-End Multimodal Speech Recognition</title><categories>eess.AS cs.CL cs.LG</categories><comments>5 pages, 5 figures, Accepted at IEEE International Conference on
  Acoustics, Speech and Signal Processing 2018 (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transcription or sub-titling of open-domain videos is still a challenging
domain for Automatic Speech Recognition (ASR) due to the data's challenging
acoustics, variable signal processing and the essentially unrestricted domain
of the data. In previous work, we have shown that the visual channel --
specifically object and scene features -- can help to adapt the acoustic model
(AM) and language model (LM) of a recognizer, and we are now expanding this
work to end-to-end approaches. In the case of a Connectionist Temporal
Classification (CTC)-based approach, we retain the separation of AM and LM,
while for a sequence-to-sequence (S2S) approach, both information sources are
adapted together, in a single model. This paper also analyzes the behavior of
CTC and S2S models on noisy video data (How-To corpus), and compares it to
results on the clean Wall Street Journal (WSJ) corpus, providing insight into
the robustness of both approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09788</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09788</id><created>2018-04-25</created><updated>2018-07-25</updated><authors><author><keyname>Aberdam</keyname><forenames>Aviad</forenames></author><author><keyname>Sulam</keyname><forenames>Jeremias</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>Multi-Layer Sparse Coding: The Holistic Way</title><categories>eess.IV cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently proposed multi-layer sparse model has raised insightful
connections between sparse representations and convolutional neural networks
(CNN). In its original conception, this model was restricted to a cascade of
convolutional synthesis representations. In this paper, we start by addressing
a more general model, revealing interesting ties to fully connected networks.
We then show that this multi-layer construction admits a brand new
interpretation in a unique symbiosis between synthesis and analysis models:
while the deepest layer indeed provides a synthesis representation, the
mid-layers decompositions provide an analysis counterpart. This new perspective
exposes the suboptimality of previously proposed pursuit approaches, as they do
not fully leverage all the information comprised in the model constraints.
Armed with this understanding, we address fundamental theoretical issues,
revisiting previous analysis and expanding it. Motivated by the limitations of
previous algorithms, we then propose an integrated - holistic - alternative
that estimates all representations in the model simultaneously, and analyze all
these different schemes under stochastic noise assumptions. Inspired by the
synthesis-analysis duality, we further present a Holistic Pursuit algorithm,
which alternates between synthesis and analysis sparse coding steps, eventually
solving for the entire model as a whole, with provable improved performance.
Finally, we present numerical results that demonstrate the practical advantages
of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09808</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09808</id><created>2018-04-25</created><updated>2018-05-02</updated><authors><author><keyname>Borghuis</keyname><forenames>Tijn</forenames></author><author><keyname>Tibo</keyname><forenames>Alessandro</forenames></author><author><keyname>Conforti</keyname><forenames>Simone</forenames></author><author><keyname>Canciello</keyname><forenames>Luca</forenames></author><author><keyname>Brusci</keyname><forenames>Lorenzo</forenames></author><author><keyname>Frasconi</keyname><forenames>Paolo</forenames></author></authors><title>Off the Beaten Track: Using Deep Learning to Interpolate Between Music
  Genres</title><categories>cs.SD cs.LG cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a system based on deep learning that generates drum patterns in
the electronic dance music domain. Experimental results reveal that generated
patterns can be employed to produce musically sound and creative transitions
between different genres, and that the process of generation is of interest to
practitioners in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09816</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09816</id><created>2018-04-25</created><authors><author><keyname>Cloninger</keyname><forenames>Alexander</forenames></author><author><keyname>Steinerberger</keyname><forenames>Stefan</forenames></author></authors><title>On the Dual Geometry of Laplacian Eigenfunctions</title><categories>eess.SP cs.LG math.AP math.SP</categories><msc-class>35J05, 35P05, 42C10, 65T60, 81Q50, 94A11</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the geometry of Laplacian eigenfunctions $-\Delta \phi = \lambda
\phi$ on compact manifolds $(M,g)$ and combinatorial graphs $G=(V,E)$. The
'dual' geometry of Laplacian eigenfunctions is well understood on
$\mathbb{T}^d$ (identified with $\mathbb{Z}^d$) and $\mathbb{R}^n$ (which is
self-dual). The dual geometry is of tremendous role in various fields of pure
and applied mathematics. The purpose of our paper is to point out a notion of
similarity between eigenfunctions that allows to reconstruct that geometry. Our
measure of 'similarity' $ \alpha(\phi_{\lambda}, \phi_{\mu})$ between
eigenfunctions $\phi_{\lambda}$ and $\phi_{\mu}$ is given by a global average
of local correlations $$ \alpha(\phi_{\lambda}, \phi_{\mu})^2 = \|
\phi_{\lambda} \phi_{\mu} \|_{L^2}^{-2}\int_{M}{ \left( \int_{M}{ p(t,x,y)(
\phi_{\lambda}(y) - \phi_{\lambda}(x))( \phi_{\mu}(y) - \phi_{\mu}(x)) dy}
\right)^2 dx},$$ where $p(t,x,y)$ is the classical heat kernel and $e^{-t
\lambda} + e^{-t \mu} = 1$. This notion recovers all classical notions of
duality but is equally applicable to other (rough) geometries and graphs; many
numerical examples in different continuous and discrete settings illustrate the
result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09869</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09869</id><created>2018-04-25</created><updated>2019-01-09</updated><authors><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author><author><keyname>He</keyname><forenames>Tianyu</forenames></author><author><keyname>Jin</keyname><forenames>Xin</forenames></author><author><keyname>Wu</keyname><forenames>Feng</forenames></author></authors><title>Learning for Video Compression</title><categories>cs.MM eess.IV</categories><comments>Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology (TCSVT)</comments><doi>10.1109/TCSVT.2019.2892608</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One key challenge to learning-based video compression is that motion
predictive coding, a very effective tool for video compression, can hardly be
trained into a neural network. In this paper we propose the concept of
PixelMotionCNN (PMCNN) which includes motion extension and hybrid prediction
networks. PMCNN can model spatiotemporal coherence to effectively perform
predictive coding inside the learning network. On the basis of PMCNN, we
further explore a learning-based framework for video compression with
additional components of iterative analysis/synthesis, binarization, etc.
Experimental results demonstrate the effectiveness of the proposed scheme.
Although entropy coding and complex configurations are not employed in this
paper, we still demonstrate superior performance compared with MPEG-2 and
achieve comparable results with H.264 codec. The proposed learning-based scheme
provides a possible new direction to further improve compression efficiency and
functionalities of future video coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.09963</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.09963</id><created>2018-04-26</created><updated>2018-06-15</updated><authors><author><keyname>Choi</keyname><forenames>Hyomin</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author></authors><title>Near-Lossless Deep Feature Compression for Collaborative Intelligence</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative intelligence is a new paradigm for efficient deployment of deep
neural networks across the mobile-cloud infrastructure. By dividing the network
between the mobile and the cloud, it is possible to distribute the
computational workload such that the overall energy and/or latency of the
system is minimized. However, this necessitates sending deep feature data from
the mobile to the cloud in order to perform inference. In this work, we examine
the differences between the deep feature data and natural image data, and
propose a simple and effective near-lossless deep feature compressor. The
proposed method achieves up to 5% bit rate reduction compared to HEVC-Intra and
even more against other popular image codecs. Finally, we suggest an approach
for reconstructing the input image from compressed deep features in the cloud,
that could serve to supplement the inference performed by the deep model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10008</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10008</id><created>2018-04-26</created><authors><author><keyname>Czajkowski</keyname><forenames>Krzysztof M.</forenames></author><author><keyname>Pastuszczak</keyname><forenames>Anna</forenames></author><author><keyname>Kotynski</keyname><forenames>Rafal</forenames></author></authors><title>Real-time single-pixel video imaging with Fourier domain regularization</title><categories>eess.IV</categories><journal-ref>Opt. Express vol. 26(16), pp. 20009-20022, (2018)</journal-ref><doi>10.1364/OE.26.020009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a closed-form image reconstruction method for single pixel imaging
based on the generalized inverse of the measurement matrix. Its numerical cost
scales linearly with the number of measured samples. Regularization is obtained
by minimizing the norms of the convolution between the reconstructed image and
a set of spatial filters, and the final reconstruction formula can be expressed
in terms of matrix pseudoinverse. At high compression this approach is an
interesting alternative to the methods of compressive sensing based on l1-norm
optimization, which are too slow for real-time applications. For instance, we
demonstrate experimental single-pixel detection with real-time reconstruction
obtained in parallel with the measurement at the frame rate of $11$ Hz for
highly compressive measurements with the resolution of $256\times 256$. For
this purpose, we preselect the sampling functions to match the average spectrum
obtained with an image database. The sampling functions are selected from the
Walsh-Hadamard basis, from the discrete cosine basis, or from a subset of
Morlet wavelets convolved with white noise. We show that by incorporating the
quadratic criterion into the closed-form reconstruction formula, we are able to
use binary rather than continuous sampling reaching similar reconstruction
quality as is obtained by minimizing the total variation. This makes it
possible to use cosine or Morlet-based sampling with digital micromirror
devices without advanced binarization methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10015</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10015</id><created>2018-04-26</created><authors><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author></authors><title>Parametric System Identification Using Quantized Data</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation and Measurement, Year: 2015,
  Volume: 64, Issue: 8 Pages: 2312 - 2322</journal-ref><doi>10.1109/TIM.2015.2390833</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The estimation of signal parameters using quantized data is a recurrent
problem in electrical engineering. As an example, this includes the estimation
of a noisy constant value and of the parameters of a sinewave, that is, its
amplitude, initial record phase, and offset. Conventional algorithms, such as
the arithmetic mean, in the case of the estimation of a constant, are known not
to be optimal in the presence of quantization errors. They provide biased
estimates if particular conditions regarding the quantization process are not
met, as it usually happens in practice. In this paper, a quantile-based
estimator is presented, which is based on the Gauss-Markov theorem. The general
theory is first described and the estimator is then applied to both direct
current and alternate current input signals with unknown characteristics. Using
simulations and experimental results, it is shown that the new estimator
outperforms conventional estimators in both problems, by removing the
estimation bias.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10027</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10027</id><created>2018-04-26</created><authors><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author><author><keyname>Schuokens</keyname><forenames>Johan</forenames></author><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author></authors><title>Dynamic Signal Measurements Based on Quantized Data</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation and Measurement, Year: 2017,
  Volume: 66, Issue: 2 Pages: 223 - 233</journal-ref><doi>10.1109/TIM.2016.2627298</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The estimation of the parameters of a dynamic signal, such as a sine wave,
based on quantized data is customarily performed using the least-square
estimator (LSE), such as the sine fit. However, the characteristics of the
experiments and the measurement setup hardly satisfy the requirements ensuring
the LSE to be optimal in the minimum mean-square-error sense. This occurs if
the input signal is characterized by a large signal-to-noise ratio resulting in
the deterministic component of the quantization error dominating the random
error component and when the ADC transition levels are not uniformly
distributed over the quantizer input range. In this paper, it is first shown
that the LSE applied to quantized data does not perform as expected when the
quantizer is not uniform. Then, an estimator is introduced that overcomes these
limitations. It uses the values of the transition levels so that a prior
quantizer calibration phase is necessary. The estimator properties are analyzed
and both numerical and experimental results are described to illustrate its
performance. It is shown that the described estimator outperforms the LSE and
it also provides an estimate of the probability distribution function of the
noise before quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10040</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10040</id><created>2018-04-07</created><authors><author><keyname>Xu</keyname><forenames>Xingyuan</forenames></author><author><keyname>Wu</keyname><forenames>Jiayang</forenames></author><author><keyname>Shoeiby</keyname><forenames>Mehrdad</forenames></author><author><keyname>Chu</keyname><forenames>Sai T.</forenames></author><author><keyname>Little</keyname><forenames>Brent E.</forenames></author><author><keyname>Morandotti</keyname><forenames>Roberto</forenames></author><author><keyname>Mitchell</keyname><forenames>Arnan</forenames></author><author><keyname>Moss</keyname><forenames>David J.</forenames></author></authors><title>High-order Radio Frequency Differentiation via Photonic Signal
  Processing with an Integrated Micro-resonator Kerr Optical Frequency Comb
  Source</title><categories>physics.app-ph eess.SP physics.optics</categories><comments>8 pages, 7 figures, 46 References. arXiv admin note: substantial text
  overlap with arXiv:1512.01741, arXiv:1512.06301</comments><journal-ref>2017 Progress In Electromagnetics Research Symposium Fall (PIERS,
  FALL), Singapore, 19 to 22 November, Pages 2232 to 2236</journal-ref><doi>10.1109/PIERS-FALL.2017.8293510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the use of integrated micro-resonator based optical frequency
comb sources as the basis for transversal filtering functions for microwave and
radio frequency photonic filtering and advanced functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10049</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10049</id><created>2018-04-26</created><authors><author><keyname>Zhao</keyname><forenames>Sihao</forenames></author><author><keyname>Cui</keyname><forenames>Xiaowei</forenames></author><author><keyname>Xu</keyname><forenames>Shuang</forenames></author><author><keyname>Lu</keyname><forenames>Mingquan</forenames></author></authors><title>TOA Positioning for a TDMA Localization System</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Positioning with one single communication between base stations and user
devices can effectively save air time and thus expand the user volume to
infinite. However, this usually demands accurate synchronization between base
stations. Wireless synchronization between base stations can simplify the
deployment of the positioning system but requires accurate clock offset
estimation between base stations. A time division multiple access (TDMA)
localization system in which user devices only receive signals from base
stations to generate time of arrival (TOA) measurements to position themselves
and no cables are needed to interconnect base stations for clock
synchronization is proposed, implemented and tested. In this system, the user
devices can easily join in or exit without influence to other users and the
update rate of each user can be easily adjusted independently according to its
specific requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10070</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10070</id><created>2018-04-26</created><updated>2018-08-10</updated><authors><author><keyname>McFee</keyname><forenames>Brian</forenames></author><author><keyname>Salamon</keyname><forenames>Justin</forenames></author><author><keyname>Bello</keyname><forenames>Juan Pablo</forenames></author></authors><title>Adaptive pooling operators for weakly labeled sound event detection</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound event detection (SED) methods are tasked with labeling segments of
audio recordings by the presence of active sound sources. SED is typically
posed as a supervised machine learning problem, requiring strong annotations
for the presence or absence of each sound source at every time instant within
the recording. However, strong annotations of this type are both labor- and
cost-intensive for human annotators to produce, which limits the practical
scalability of SED methods.
  In this work, we treat SED as a multiple instance learning (MIL) problem,
where training labels are static over a short excerpt, indicating the presence
or absence of sound sources but not their temporal locality. The models,
however, must still produce temporally dynamic predictions, which must be
aggregated (pooled) when comparing against static labels during training. To
facilitate this aggregation, we develop a family of adaptive pooling
operators---referred to as auto-pool---which smoothly interpolate between
common pooling operators, such as min-, max-, or average-pooling, and
automatically adapt to the characteristics of the sound sources in question. We
evaluate the proposed pooling operators on three datasets, and demonstrate that
in each case, the proposed methods outperform non-adaptive pooling operators
for static prediction, and nearly match the performance of models trained with
strong, dynamic annotations. The proposed method is evaluated in conjunction
with convolutional neural networks, but can be readily applied to any
differentiable model for time-series label prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10080</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10080</id><created>2018-04-26</created><authors><author><keyname>Novoselov</keyname><forenames>Sergey</forenames></author><author><keyname>Shulipa</keyname><forenames>Andrey</forenames></author><author><keyname>Kremnev</keyname><forenames>Ivan</forenames></author><author><keyname>Kozlov</keyname><forenames>Alexandr</forenames></author><author><keyname>Shchemelinin</keyname><forenames>Vadim</forenames></author></authors><title>On deep speaker embeddings for text-independent speaker recognition</title><categories>cs.SD cs.CL eess.AS stat.ML</categories><comments>Submitted to Odyssey 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate deep neural network performance in the textindependent speaker
recognition task. We demonstrate that using angular softmax activation at the
last classification layer of a classification neural network instead of a
simple softmax activation allows to train a more generalized discriminative
speaker embedding extractor. Cosine similarity is an effective metric for
speaker verification in this embedding space. We also address the problem of
choosing an architecture for the extractor. We found that deep networks with
residual frame level connections outperform wide but relatively shallow
architectures. This paper also proposes several improvements for previous
DNN-based extractor systems to increase the speaker recognition accuracy. We
show that the discriminatively trained similarity metric learning approach
outperforms the standard LDA-PLDA method as an embedding backend. The results
obtained on Speakers in the Wild and NIST SRE 2016 evaluation sets demonstrate
robustness of the proposed systems when dealing with close to real-life
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10147</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10147</id><created>2018-04-26</created><updated>2019-07-09</updated><authors><author><keyname>Goyal</keyname><forenames>Mohit</forenames></author><author><keyname>Srivastava</keyname><forenames>Varun</forenames></author><author><keyname>P</keyname><forenames>Prathosh A.</forenames></author></authors><title>Detection of Glottal Closure Instants from Raw Speech using
  Convolutional Neural Networks</title><categories>cs.SD eess.AS</categories><comments>Updated submission. Figures Added. Accepted in Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Glottal Closure Instants (GCIs) correspond to the temporal locations of
significant excitation to the vocal tract occurring during the production of
voiced speech. GCI detection from speech signals is a well-studied problem
given its importance in speech processing. Most of the existing approaches for
GCI detection adopt a two-stage approach (i) Transformation of speech signal
into a representative signal where GCIs are localized better, (ii) extraction
of GCIs using the representative signal obtained in first stage. The former
stage is accomplished using signal processing techniques based on the
principles of speech production and the latter with heuristic-algorithms such
as dynamic-programming and peak-picking. These methods are thus task-specific
and rely on the methods used for representative signal extraction. However, in
this paper, we formulate the GCI detection problem from a representation
learning perspective where appropriate representation is implicitly learned
from the raw-speech data samples. Specifically, GCI detection is cast as a
supervised multi-task learning problem solved using a deep convolutional neural
network jointly optimizing a classification and regression cost. The learning
capability is demonstrated with several experiments on standard datasets. The
results compare well with the state-of-the-art algorithms while performing
better in the case of presence of real-world non-stationary noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10201</identifier>
 <datestamp>2018-09-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10201</id><created>2018-04-25</created><updated>2018-09-26</updated><authors><author><keyname>Davoudi</keyname><forenames>Anis</forenames></author><author><keyname>Malhotra</keyname><forenames>Kumar Rohit</forenames></author><author><keyname>Shickel</keyname><forenames>Benjamin</forenames></author><author><keyname>Siegel</keyname><forenames>Scott</forenames></author><author><keyname>Williams</keyname><forenames>Seth</forenames></author><author><keyname>Ruppert</keyname><forenames>Matthew</forenames></author><author><keyname>Bihorac</keyname><forenames>Emel</forenames></author><author><keyname>Ozrazgat-Baslanti</keyname><forenames>Tezcan</forenames></author><author><keyname>Tighe</keyname><forenames>Patrick J.</forenames></author><author><keyname>Bihorac</keyname><forenames>Azra</forenames></author><author><keyname>Rashidi</keyname><forenames>Parisa</forenames></author></authors><title>The Intelligent ICU Pilot Study: Using Artificial Intelligence
  Technology for Autonomous Patient Monitoring</title><categories>cs.HC cs.AI cs.CV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, many critical care indices are repetitively assessed and recorded
by overburdened nurses, e.g. physical function or facial pain expressions of
nonverbal patients. In addition, many essential information on patients and
their environment are not captured at all, or are captured in a non-granular
manner, e.g. sleep disturbance factors such as bright light, loud background
noise, or excessive visitations. In this pilot study, we examined the
feasibility of using pervasive sensing technology and artificial intelligence
for autonomous and granular monitoring of critically ill patients and their
environment in the Intensive Care Unit (ICU). As an exemplar prevalent
condition, we also characterized delirious and non-delirious patients and their
environment. We used wearable sensors, light and sound sensors, and a
high-resolution camera to collected data on patients and their environment. We
analyzed collected data using deep learning and statistical analysis. Our
system performed face detection, face recognition, facial action unit
detection, head pose detection, facial expression recognition, posture
recognition, actigraphy analysis, sound pressure and light level detection, and
visitation frequency detection. We were able to detect patient's face (Mean
average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their
postures (F1=0.94). We also found that all facial expressions, 11 activity
features, visitation frequency during the day, visitation frequency during the
night, light levels, and sound pressure levels during the night were
significantly different between delirious and non-delirious patients
(p-value&lt;0.05). In summary, we showed that granular and autonomous monitoring
of critically ill patients and their environment is feasible and can be used
for characterizing critical care conditions and related environment factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10204</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10204</id><created>2018-04-26</created><authors><author><keyname>Wang</keyname><forenames>Zhong-Qiu</forenames></author><author><keyname>Roux</keyname><forenames>Jonathan Le</forenames></author><author><keyname>Wang</keyname><forenames>DeLiang</forenames></author><author><keyname>Hershey</keyname><forenames>John R.</forenames></author></authors><title>End-to-End Speech Separation with Unfolded Iterative Phase
  Reconstruction</title><categories>cs.SD cs.CL cs.LG eess.AS stat.ML</categories><comments>Submitted to Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an end-to-end approach for single-channel
speaker-independent multi-speaker speech separation, where time-frequency (T-F)
masking, the short-time Fourier transform (STFT), and its inverse are
represented as layers within a deep network. Previous approaches, rather than
computing a loss on the reconstructed signal, used a surrogate loss based on
the target STFT magnitudes. This ignores reconstruction error introduced by
phase inconsistency. In our approach, the loss function is directly defined on
the reconstructed signals, which are optimized for best separation. In
addition, we train through unfolded iterations of a phase reconstruction
algorithm, represented as a series of STFT and inverse STFT layers. While mask
values are typically limited to lie between zero and one for approaches using
the mixture phase for reconstruction, this limitation is less relevant if the
estimated magnitudes are to be used together with phase reconstruction. We thus
propose several novel activation functions for the output layer of the T-F
masking, to allow mask values beyond one. On the publicly-available wsj0-2mix
dataset, our approach achieves state-of-the-art 12.6 dB scale-invariant
signal-to-distortion ratio (SI-SDR) and 13.1 dB SDR, revealing new
possibilities for deep learning based phase reconstruction and representing a
fundamental progress towards solving the notoriously-hard cocktail party
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10278</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10278</id><created>2018-04-26</created><authors><author><keyname>Das</keyname><forenames>Debayan</forenames></author><author><keyname>Maity</keyname><forenames>Shovan</forenames></author><author><keyname>Chatterjee</keyname><forenames>Baibhab</forenames></author><author><keyname>Sen</keyname><forenames>Shreyas</forenames></author></authors><title>In-field Remote Fingerprint Authentication using Human Body
  Communication and On-Hub Analytics</title><categories>eess.SP cs.CR</categories><comments>IEEE Engineering in Medicine and Biology Society (EMBC), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this emerging data-driven world, secure and ubiquitous authentication
mechanisms are necessary prior to any confidential information delivery.
Biometric authentication has been widely adopted as it provides a unique and
non-transferable solution for user authentication. In this article, the authors
envision the need for an in-field, remote and on-demand authentication system
for a highly mobile and tactical environment, such as critical information
delivery to soldiers in a battlefield. Fingerprint-based in-field biometric
authentication combined with the conventional password-based techniques would
ensure strong security of critical information delivery. The proposed in-field
fingerprint authentication system involves: (i) wearable fingerprint sensor,
(ii) template extraction (TE) algorithm, (iii) data encryption, (iv) on-body
and long-range communications, all of which are subject to energy constraints
due to the requirement of small form-factor wearable devices. This paper
explores the design space and provides an optimized solution for resource
allocation to enable energy-efficient in-field fingerprint-based
authentication. Using Human Body Communication (HBC) for the on-body data
transfer along with the analytics (TE algorithm) on the hub allows for the
maximum lifetime of the energy-sparse sensor. A custom-built hardware prototype
using COTS components demonstrates the feasibility of the in-field fingerprint
authentication framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10322</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10322</id><created>2018-04-26</created><authors><author><keyname>Moinnereau</keyname><forenames>Marc-Antoine</forenames></author><author><keyname>Brienne</keyname><forenames>Thomas</forenames></author><author><keyname>Brodeur</keyname><forenames>Simon</forenames></author><author><keyname>Rouat</keyname><forenames>Jean</forenames></author><author><keyname>Whittingstall</keyname><forenames>Kevin</forenames></author><author><keyname>Plourde</keyname><forenames>Eric</forenames></author></authors><title>Classification of auditory stimuli from EEG signals with a regulated
  recurrent neural network reservoir</title><categories>eess.SP cs.LG cs.NE cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of electroencephalogram (EEG) as the main input signal in
brain-machine interfaces has been widely proposed due to the non-invasive
nature of the EEG. Here we are specifically interested in interfaces that
extract information from the auditory system and more specifically in the task
of classifying heard speech from EEGs. To do so, we propose to limit the
preprocessing of the EEGs and use machine learning approaches to automatically
extract their meaningful characteristics. More specifically, we use a regulated
recurrent neural network (RNN) reservoir, which has been shown to outperform
classic machine learning approaches when applied to several different
bio-signals, and we compare it with a deep neural network approach. Moreover,
we also investigate the classification performance as a function of the number
of EEG electrodes. A set of 8 subjects were presented randomly with 3 different
auditory stimuli (English vowels a, i and u). We obtained an excellent
classification rate of 83.2% with the RNN when considering all 64 electrodes. A
rate of 81.7% was achieved with only 10 electrodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10325</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10325</id><created>2018-04-26</created><authors><author><keyname>Jiao</keyname><forenames>Yishan</forenames></author><author><keyname>Tu</keyname><forenames>Ming</forenames></author><author><keyname>Berisha</keyname><forenames>Visar</forenames></author><author><keyname>Liss</keyname><forenames>Julie</forenames></author></authors><title>Simulating dysarthric speech for training data augmentation in clinical
  speech applications</title><categories>eess.AS</categories><comments>Will appear in Proc. of ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training machine learning algorithms for speech applications requires large,
labeled training data sets. This is problematic for clinical applications where
obtaining such data is prohibitively expensive because of privacy concerns or
lack of access. As a result, clinical speech applications are typically
developed using small data sets with only tens of speakers. In this paper, we
propose a method for simulating training data for clinical applications by
transforming healthy speech to dysarthric speech using adversarial training. We
evaluate the efficacy of our approach using both objective and subjective
criteria. We present the transformed samples to five experienced
speech-language pathologists (SLPs) and ask them to identify the samples as
healthy or dysarthric. The results reveal that the SLPs identify the
transformed speech as dysarthric 65% of the time. In a pilot classification
experiment, we show that by using the simulated speech samples to balance an
existing dataset, the classification accuracy improves by about 10% after data
augmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10346</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10346</id><created>2018-04-27</created><updated>2018-05-01</updated><authors><author><keyname>Khodabandehlou</keyname><forenames>Hamid</forenames></author><author><keyname>Fadali</keyname><forenames>Mohammed Sami</forenames></author></authors><title>Nonlinear System Identification using Neural Networks and
  Trajectory-Based Optimization</title><categories>eess.SP</categories><comments>This paper is based upon work supported by the National Science
  Foundation under Grant No. IIA-1301726</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we study the identification of two challenging benchmark
problems using neural networks. Two different global optimization approaches
are used to train a recurrent neural network to identify two challenging
nonlinear models, the cascaded tanks, and the Bouc-Wen system. The first
approach, quotient gradient system (QGS), uses the trajectories of the
nonlinear dynamical system to find the local minima of the optimization
problem. The second approach, dynamical trajectory-based methodology, uses two
different nonlinear dynamical systems to find the connected components of the
feasible region and then searches the regions for local minima of the
optimization problem. Simulation results show that both approaches effectively
identify the model of the cascade tanks and the Bouc-Wen model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10402</identifier>
 <datestamp>2018-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10402</id><created>2018-04-27</created><authors><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author></authors><title>Information and Statistical Efficiency When Quantizing Noisy DC Values</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation and Measurement, Volume: 64,
  Issue: 2, Feb. 2015, pages 308-317</journal-ref><doi>10.1109/TIM.2014.2341372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers estimation of a quantized constant in noise when using
uniform and nonuniform quantizers. Estimators based on simple arithmetic
averages, on sample statistical moments and on the maximum-likelihood procedure
are considered. It provides expressions for the statistical efficiency of the
arithmetic mean by comparing its variance to the proper Cram\'er-Rao lower
bound. It is conjectured that the arithmetic mean is optimal among all
estimators with an exactly known bias. Conditions under which its statistical
performance are improved by the other estimation procedures when the exact bias
is not known are found and analyzed. Using simulations and analysis of
experimental data, it is shown that both moment-based and
maximum-likelihood-based estimators provide better results, when the noise
standard deviation is comparable with the quantization step and the noise model
of quantization can not be applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10422</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10422</id><created>2018-04-27</created><authors><author><keyname>Dinesh</keyname><forenames>Chinthaka</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author></authors><title>Adaptive Non-Rigid Inpainting of 3D Point Cloud Geometry</title><categories>eess.SP</categories><comments>5 pages, 2 figures, a short journal paper (letter)</comments><doi>10.1109/LSP.2018.2831621</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we introduce several algorithms for geometry inpainting of 3D
point clouds with large holes. The algorithms are examplar-based: hole filling
is performed iteratively using templates near the hole boundary to find the
best matching regions elsewhere in the cloud, from where existing points are
transferred to the hole. We propose two improvements over the previous work on
exemplar-based hole filling. The first one is adaptive template size selection
in each iteration, which simultaneously leads to higher accuracy and lower
execution time. The second improvement is a non-rigid transformation to better
align the candidate set of points with the template before the point transfer,
which leads to even higher accuracy. We demonstrate the algorithms' ability to
fill holes that are difficult or impossible to fill by existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10454</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10454</id><created>2018-04-27</created><updated>2019-01-21</updated><authors><author><keyname>Meinel</keyname><forenames>Andreas</forenames></author><author><keyname>Kolkhorst</keyname><forenames>Henrich</forenames></author><author><keyname>Tangermann</keyname><forenames>Michael</forenames></author></authors><title>Mining within-trial oscillatory brain dynamics to address the
  variability of optimized spatial filters</title><categories>eess.SP cs.LG q-bio.NC stat.AP stat.ML</categories><doi>10.1109/TNSRE.2019.2894914</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven spatial filtering algorithms optimize scores such as the contrast
between two conditions to extract oscillatory brain signal components. Most
machine learning approaches for filter estimation, however, disregard
within-trial temporal dynamics and are extremely sensitive to changes in
training data and involved hyperparameters. This leads to highly variable
solutions and impedes the selection of a suitable candidate for,
e.g.,~neurotechnological applications. Fostering component introspection, we
propose to embrace this variability by condensing the functional signatures of
a large set of oscillatory components into homogeneous clusters, each
representing specific within-trial envelope dynamics.
  The proposed method is exemplified by and evaluated on a complex hand force
task with a rich within-trial structure. Based on electroencephalography data
of 18 healthy subjects, we found that the components' distinct temporal
envelope dynamics are highly subject-specific. On average, we obtained seven
clusters per subject, which were strictly confined regarding their underlying
frequency bands. As the analysis method is not limited to a specific spatial
filtering algorithm, it could be utilized for a wide range of
neurotechnological applications, e.g., to select and monitor functionally
relevant features for brain-computer interface protocols in stroke
rehabilitation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10636</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10636</id><created>2018-04-27</created><updated>2018-07-18</updated><authors><author><keyname>Gataric</keyname><forenames>Milana</forenames></author><author><keyname>Gordon</keyname><forenames>George S. D.</forenames></author><author><keyname>Renna</keyname><forenames>Francesco</forenames></author><author><keyname>Ramos</keyname><forenames>Alberto Gil C. P.</forenames></author><author><keyname>Alcolea</keyname><forenames>Maria P.</forenames></author><author><keyname>Bohndiek</keyname><forenames>Sarah E.</forenames></author></authors><title>Reconstruction of optical vector-fields with applications in endoscopic
  imaging</title><categories>math.NA eess.IV physics.med-ph stat.AP</categories><doi>10.1109/TMI.2018.2875875</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a framework for the reconstruction of the amplitude, phase and
polarisation of an optical vector-field using calibration measurements acquired
by an imaging device with an unknown linear transformation. By incorporating
effective regularisation terms, this new approach is able to recover an optical
vector-field with respect to an arbitrary representation system, which may be
different from the one used in calibration. In particular, it enables the
recovery of an optical vector-field with respect to a Fourier basis, which is
shown to yield indicative features of increased scattering associated with
tissue abnormalities. We demonstrate the effectiveness of our approach using
synthetic holographic images as well as biological tissue samples in an
experimental setting where measurements of an optical vector-field are acquired
by a fibre endoscope, and observe that indeed the recovered Fourier
coefficients are useful in distinguishing healthy tissues from lesions in early
stages of oesophageal cancer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10669</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10669</id><created>2018-04-27</created><authors><author><keyname>Hetherly</keyname><forenames>Jeff</forenames></author><author><keyname>Gamble</keyname><forenames>Paul</forenames></author><author><keyname>Barrios</keyname><forenames>Maria</forenames></author><author><keyname>Stephenson</keyname><forenames>Cory</forenames></author><author><keyname>Ni</keyname><forenames>Karl</forenames></author></authors><title>Deep Speech Denoising with Vector Space Projections</title><categories>cs.SD cs.AI eess.AS</categories><comments>arXiv admin note: text overlap with arXiv:1705.04662</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose an algorithm to denoise speakers from a single microphone in the
presence of non-stationary and dynamic noise. Our approach is inspired by the
recent success of neural network models separating speakers from other speakers
and singers from instrumental accompaniment. Unlike prior art, we leverage
embedding spaces produced with source-contrastive estimation, a technique
derived from negative sampling techniques in natural language processing, while
simultaneously obtaining a continuous inference mask. Our embedding space
directly optimizes for the discrimination of speaker and noise by jointly
modeling their characteristics. This space is generalizable in that it is not
speaker or noise specific and is capable of denoising speech even if the model
has not seen the speaker in the training set. Parameters are trained with dual
objectives: one that promotes a selective bandpass filter that eliminates noise
at time-frequency positions that exceed signal power, and another that
proportionally splits time-frequency content between signal and noise. We
compare to state of the art algorithms as well as traditional sparse
non-negative matrix factorization solutions. The resulting algorithm avoids
severe computational burden by providing a more intuitive and easily optimized
approach, while achieving competitive accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10683</identifier>
 <datestamp>2018-12-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10683</id><created>2018-04-27</created><authors><author><keyname>Li</keyname><forenames>Shiyong</forenames></author><author><keyname>Zhao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Sun</keyname><forenames>Houjun</forenames></author><author><keyname>Amin</keyname><forenames>Moeness</forenames></author></authors><title>Compressive Sensing Imaging of 3-D Object by a Holographic Algorithm</title><categories>eess.SP</categories><comments>10 pages, 16 figures, submitted to IEEE transactions on Antennas and
  Propagation</comments><doi>10.1109/TAP.2018.2869660</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing three-dimensional (3-D) compressive sensing-based millimeter-wave
(MMW) imaging methods require a large-scale storage of the sensing matrix and
immense computations owing to the high dimension matrix-vector model employed
in the optimization. To overcome this shortcoming, we propose an efficient
compressive sensing (CS) method based on a holographic algorithm for near-field
3-D MMW imaging. An interpolation-free holographic imaging algorithm is
developed and used as a sensing operator, in lieu of the nominal sensing matrix
typically used in the CS iterative optimization procedure. In so doing, the
problem induced by the large-scale sensing matrix is avoided. With no
interpolations required, both the computational speed and the image quality can
be improved. Simulation and experimental results are provided to demonstrate
the performance of the proposed method in comparison with those of the Omega-K
based CS and the traditional Fourier-based imaging techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10716</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10716</id><created>2018-04-27</created><authors><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author><author><keyname>Koll&#xe1;r</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author></authors><title>Accurate Sine-Wave Amplitude Measurements Using Nonlinearly Quantized
  Data</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation and Measurement, Volume: 64,
  Issue: 12, Dec. 2015, pages 3201 - 3208</journal-ref><doi>10.1109/TIM.2015.2463331</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The estimation of the amplitude of a sine wave from the sequence of its
quantized samples is a typical problem in instrumentation and measurement. A
standard approach for its solution makes use of a least squares estimator (LSE)
that, however, does not perform optimally in the presence of quantization
errors. In fact, if the quantization error cannot be modeled as an additive
noise source, as it often happens in practice, the LSE returns biased
estimates. In this paper, we consider the estimation of the amplitude of a
noisy sine wave after quantization. The proposed technique is based on a
uniform distribution of signal phases and it does not require that the
quantizer has equally spaced transition levels. The experimental results show
that this technique removes the estimation bias associated with the usage of
the LSE and that it is sufficiently robust with respect to small uncertainties
in the known values of transition levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10752</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10752</id><created>2018-04-28</created><updated>2018-06-04</updated><authors><author><keyname>Zhou</keyname><forenames>Shiyu</forenames></author><author><keyname>Dong</keyname><forenames>Linhao</forenames></author><author><keyname>Xu</keyname><forenames>Shuang</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>Syllable-Based Sequence-to-Sequence Speech Recognition with the
  Transformer in Mandarin Chinese</title><categories>eess.AS cs.CL cs.SD</categories><comments>accepted by INTERSPEECH2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence attention-based models have recently shown very
promising results on automatic speech recognition (ASR) tasks, which integrate
an acoustic, pronunciation and language model into a single neural network. In
these models, the Transformer, a new sequence-to-sequence attention-based model
relying entirely on self-attention without using RNNs or convolutions, achieves
a new single-model state-of-the-art BLEU on neural machine translation (NMT)
tasks. Since the outstanding performance of the Transformer, we extend it to
speech and concentrate on it as the basic architecture of sequence-to-sequence
attention-based model on Mandarin Chinese ASR tasks. Furthermore, we
investigate a comparison between syllable based model and context-independent
phoneme (CI-phoneme) based model with the Transformer in Mandarin Chinese.
Additionally, a greedy cascading decoder with the Transformer is proposed for
mapping CI-phoneme sequences and syllable sequences into word sequences.
Experiments on HKUST datasets demonstrate that syllable based model with the
Transformer performs better than CI-phoneme based counterpart, and achieves a
character error rate (CER) of \emph{$28.77\%$}, which is competitive to the
state-of-the-art CER of $28.0\%$ by the joint CTC-attention based
encoder-decoder network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10800</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10800</id><created>2018-04-28</created><authors><author><keyname>Chan</keyname><forenames>Kevin K. M.</forenames></author><author><keyname>Oloumi</keyname><forenames>Daniel</forenames></author><author><keyname>Boulanger</keyname><forenames>Pierre</forenames></author><author><keyname>Rambabu</keyname><forenames>Karumudi</forenames></author></authors><title>SAR Focused Microwave Reflection Tomography for Biomedical Imaging</title><categories>physics.med-ph eess.IV</categories><comments>5 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the combination of SAR and microwave reflection
tomography for biomedical imaging applications. The proposed method can achieve
accuracies of less than 5mm and does not suffer from instability during
reconstruction. Fourier based reconstruction is adopted which makes it fast and
computationally efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10816</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10816</id><created>2018-04-28</created><authors><author><keyname>Parthasarathy</keyname><forenames>Srinivas</forenames></author><author><keyname>Busso</keyname><forenames>Carlos</forenames></author></authors><title>Ladder Networks for Emotion Recognition: Using Unsupervised Auxiliary
  Tasks to Improve Predictions of Emotional Attributes</title><categories>eess.AS cs.SD</categories><comments>Submitted to Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognizing emotions using few attribute dimensions such as arousal, valence
and dominance provides the flexibility to effectively represent complex range
of emotional behaviors. Conventional methods to learn these emotional
descriptors primarily focus on separate models to recognize each of these
attributes. Recent work has shown that learning these attributes together
regularizes the models, leading to better feature representations. This study
explores new forms of regularization by adding unsupervised auxiliary tasks to
reconstruct hidden layer representations. This auxiliary task requires the
denoising of hidden representations at every layer of an auto-encoder. The
framework relies on ladder networks that utilize skip connections between
encoder and decoder layers to learn powerful representations of emotional
dimensions. The results show that ladder networks improve the performance of
the system compared to baselines that individually learn each attribute, and
conventional denoising autoencoders. Furthermore, the unsupervised auxiliary
tasks have promising potential to be used in a semi-supervised setting, where
few labeled sentences are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10831</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10831</id><created>2018-04-28</created><authors><author><keyname>Dinesh</keyname><forenames>Chinthaka</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author><author><keyname>Yang</keyname><forenames>Cheng</forenames></author></authors><title>Fast 3D Point Cloud Denoising via Bipartite Graph Approximation &amp; Total
  Variation</title><categories>eess.SP</categories><comments>6 pages, 5 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquired 3D point cloud data, whether from active sensors directly or from
stereo-matching algorithms indirectly, typically contain non-negligible noise.
To address the point cloud denoising problem, we propose a fast graph-based
local algorithm. Specifically, given a k-nearest-neighbor graph of the 3D
points, we first approximate it with a bipartite graph(independent sets of red
and blue nodes) using a KL divergence criterion. For each partite of nodes (say
red), we first define surface normal of each red node using 3D coordinates of
neighboring blue nodes, so that red node normals n can be written as a linear
function of red node coordinates p. We then formulate a convex optimization
problem, with a quadratic fidelity term ||p-q||_2^2 given noisy observed red
coordinates q and a graph total variation (GTV) regularization term for surface
normals of neighboring red nodes. We minimize the resulting l2-l1-norm using
alternating direction method of multipliers (ADMM) and proximal gradient
descent. The two partites of nodes are alternately optimized until convergence.
Experimental results show that compared to state-of-the-art schemes with
similar complexity, our proposed algorithm achieves the best overall denoising
performance objectively and subjectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10917</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10917</id><created>2018-04-29</created><authors><author><keyname>Wen</keyname><forenames>Weisong</forenames></author><author><keyname>Zhang</keyname><forenames>Guohao</forenames></author><author><keyname>Hsu</keyname><forenames>Li-Ta</forenames></author></authors><title>Exclusion of GNSS NLOS Receptions Caused by Dynamic Objects in Heavy
  Traffic Urban Scenarios Using Real-Time 3D Point Cloud: An Approach without
  3D Maps</title><categories>cs.RO eess.SP</categories><comments>8 pages, accepted by the IEEE/ION PLANS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Absolute positioning is an essential factor for the arrival of autonomous
driving. Global Navigation Satellites System (GNSS) receiver provides absolute
localization for it. GNSS solution can provide satisfactory positioning in open
or sub-urban areas, however, its performance suffered in super-urbanized area
due to the phenomenon which are well-known as multipath effects and NLOS
receptions. The effects dominate GNSS positioning performance in the area. The
recent proposed 3D map aided (3DMA) GNSS can mitigate most of the multipath
effects and NLOS receptions caused by buildings based on 3D city models.
However, the same phenomenon caused by moving objects in urban area is
currently not modelled in the 3D geographic information system (GIS). Moving
objects with tall height, such as the double-decker bus, can also cause NLOS
receptions because of the blockage of GNSS signals by surface of objects.
Therefore, we present a novel method to exclude the NLOS receptions caused by
double-decker bus in highly urbanized area, Hong Kong. To estimate the geometry
dimension and orientation relative to GPS receiver, a Euclidean cluster
algorithm and a classification method are used to detect the double-decker
buses and calculate their relative locations. To increase the accuracy and
reliability of the proposed NLOS exclusion method, an NLOS exclusion criterion
is proposed to exclude the blocked satellites considering the elevation, signal
noise ratio (SNR) and horizontal dilution of precision (HDOP). Finally, GNSS
positioning is estimated by weighted least square (WLS) method using the
remaining satellites after the NLOS exclusion. A static experiment was
performed near a double-decker bus stop in Hong Kong, which verified the
effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10938</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10938</id><created>2018-04-29</created><updated>2019-02-01</updated><authors><author><keyname>Kollias</keyname><forenames>Dimitrios</forenames></author><author><keyname>Tzirakis</keyname><forenames>Panagiotis</forenames></author><author><keyname>Nicolaou</keyname><forenames>Mihalis A.</forenames></author><author><keyname>Papaioannou</keyname><forenames>Athanasios</forenames></author><author><keyname>Zhao</keyname><forenames>Guoying</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Kotsia</keyname><forenames>Irene</forenames></author><author><keyname>Zafeiriou</keyname><forenames>Stefanos</forenames></author></authors><title>Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge,
  Deep Architectures, and Beyond</title><categories>cs.CV cs.AI cs.HC eess.IV stat.ML</categories><doi>10.1007/s11263-019-01158-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic understanding of human affect using visual signals is of great
importance in everyday human-machine interactions. Appraising human emotional
states, behaviors and reactions displayed in real-world settings, can be
accomplished using latent continuous dimensions (e.g., the circumplex model of
affect). Valence (i.e., how positive or negative is an emotion) &amp; arousal
(i.e., power of the activation of the emotion) constitute popular and effective
affect representations. Nevertheless, the majority of collected datasets this
far, although containing naturalistic emotional states, have been captured in
highly controlled recording conditions. In this paper, we introduce the
Aff-Wild benchmark for training and evaluating affect recognition algorithms.
We also report on the results of the First Affect-in-the-wild Challenge that
was organized in conjunction with CVPR 2017 on the Aff-Wild database and was
the first ever challenge on the estimation of valence and arousal in-the-wild.
Furthermore, we design and extensively train an end-to-end deep neural
architecture which performs prediction of continuous emotion dimensions based
on visual cues. The proposed deep learning architecture, AffWildNet, includes
convolutional &amp; recurrent neural network layers, exploiting the invariant
properties of convolutional features, while also modeling temporal dynamics
that arise in human behavior via the recurrent layers. The AffWildNet produced
state-of-the-art results on the Aff-Wild Challenge. We then exploit the AffWild
database for learning features, which can be used as priors for achieving best
performances both for dimensional, as well as categorical emotion recognition,
using the RECOLA, AFEW-VA and EmotiW datasets, compared to all other methods
designed for the same goal. The database and emotion recognition models are
available at http://ibug.doc.ic.ac.uk/resources/first-affect-wild-challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10977</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10977</id><created>2018-04-29</created><updated>2018-07-17</updated><authors><author><keyname>Eftekharifar</keyname><forenames>Siavash</forenames></author><author><keyname>Rezaii</keyname><forenames>Tohid Yousefi</forenames></author><author><keyname>Beheshti</keyname><forenames>Soosan</forenames></author><author><keyname>Daneshvar</keyname><forenames>Sabalan</forenames></author></authors><title>Block Sparse Multi-lead ECG Compression Exploiting between-lead
  Collaboration</title><categories>eess.SP</categories><comments>12 pages, 8 figures, Submitted to iet signal processing</comments><doi>10.1049/iet-spr.2018.5076</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multilead ECG compression (MlEC) has attracted tremendous attention in
long-term monitoring of the patients heart behavior. This paper proposes a
method denoted by block sparse MlEC (BlS MlEC) in order to exploit between-lead
correlations to compress the signals in a more efficient way. This is due to
the fact that multi-lead ECG signals are multiple observations of the same
source (heart) from different locations. Consequently, they have high
correlation in terms of the support set of their sparse models which leads them
to share dominant common structure. In order to obtain the block sparse model,
the collaborative version of lasso estimator is applied. In addition, we have
shown that raised cosine kernel has advantages over conventional Gaussian and
wavelet (Daubechies family) due to its specific properties. It is demonstrated
that using raised cosine kernel in constructing the sparsifying basis matrix
gives a sparser model which results in higher compression ratio and lower
reconstruction error. The simulation results show the average improvement of
37%, 88% and 90-97% for BlS M-lEC compared to the non-collaborative case with
raised cosine kernel, Gaussian kernel and collaborative case with Daubechies
wavelet kernels, respectively, in terms of reconstruction error while the
compression ratio is considered fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10987</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.10987</id><created>2018-04-29</created><authors><author><keyname>Li</keyname><forenames>Kaipeng</forenames></author><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Cavallaro</keyname><forenames>Joseph R.</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Feedforward Architectures for Decentralized Precoding in Massive MU-MIMO
  Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multi-user multiple-input multiple-output (MU-MIMO) enables
significant gains in spectral efficiency and link reliability compared to
conventional small-scale MIMO technology. Furthermore, linear precoders, e.g.,
using zero forcing or Wiener filter (WF) precoding, are sufficient to achieve
excellent error-rate performance in the massive MU-MIMO downlink. However,
these methods necessitate centralized processing at the base-station (BS),
which causes (i) excessively high interconnect and chip input/output data
rates, and (ii) high implementation complexity. We propose two feedforward
architectures and corresponding decentralized WF precoders that parallelize
precoding across multiple computing fabrics, effectively mitigating the issues
of centralized approaches. To demonstrate the efficacy of our decentralized
precoders, we provide implementation results on a multi-GPU system, which show
that our solutions achieve throughputs in the Gbit/s regime while achieving
(near-)optimal error-rate performance in the massive MU-MIMO downlink.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11046</identifier>
 <datestamp>2018-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11046</id><created>2018-04-30</created><updated>2018-11-26</updated><authors><author><keyname>Haque</keyname><forenames>Albert</forenames></author><author><keyname>Fukushima</keyname><forenames>Corinna</forenames></author></authors><title>Automatic Documentation of ICD Codes with Far-Field Speech Recognition</title><categories>cs.SD cs.CL eess.AS</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018
  arXiv:1811.07216</comments><report-no>ML4H/2018/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Documentation errors increase healthcare costs and cause unnecessary patient
deaths. As the standard language for diagnoses and billing, ICD codes serve as
the foundation for medical documentation worldwide. Despite the prevalence of
electronic medical records, hospitals still witness high levels of ICD
miscoding. In this paper, we propose to automatically document ICD codes with
far-field speech recognition. Far-field speech occurs when the microphone is
located several meters from the source, as is common with smart homes and
security systems. Our method combines acoustic signal processing with recurrent
neural networks to recognize and document ICD codes in real time. To evaluate
our model, we collected a far-field speech dataset of ICD-10 codes and found
our model to achieve 87% accuracy with a BLEU score of 85%. By sampling from an
unsupervised medical language model, our method is able to outperform existing
methods. Overall, this work shows the potential of automatic speech recognition
to provide efficient, accurate, and cost-effective healthcare documentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11049</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11049</id><created>2018-04-30</created><authors><author><keyname>Dong</keyname><forenames>M.</forenames></author><author><keyname>Meira</keyname><forenames>P. C. M.</forenames></author><author><keyname>Xu</keyname><forenames>W.</forenames></author><author><keyname>Chung</keyname><forenames>C. Y.</forenames></author></authors><title>Non-Intrusive Signature Extraction for Major Residential Loads</title><categories>eess.SP cs.AI cs.CE</categories><comments>10 pages, 10 figures</comments><journal-ref>IEEE Transactions on Smart Grid, vol. 4, no. 3, pp. 1421-1430,
  Sept. 2013</journal-ref><doi>10.1109/TSG.2013.2245926</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The data collected by smart meters contain a lot of useful information. One
potential use of the data is to track the energy consumptions and operating
statuses of major home appliances.The results will enable homeowners to make
sound decisions on how to save energy and how to participate in demand response
programs. This paper presents a new method to breakdown the total power demand
measured by a smart meter to those used by individual appliances. A unique
feature of the proposed method is that it utilizes diverse signatures
associated with the entire operating window of an appliance for identification.
As a result, appliances with complicated middle process can be tracked. A novel
appliance registration device and scheme is also proposed to automate the
creation of appliance signature database and to eliminate the need of massive
training before identification. The software and system have been developed and
deployed to real houses in order to verify the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11055</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11055</id><created>2018-04-30</created><updated>2018-08-09</updated><authors><author><keyname>Wu</keyname><forenames>Yi-Chiao</forenames></author><author><keyname>Kobayashi</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Hayashi</keyname><forenames>Tomoki</forenames></author><author><keyname>Tobing</keyname><forenames>Patrick Lumban</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author></authors><title>Collapsed speech segment detection and suppression for WaveNet vocoder</title><categories>eess.AS cs.SD</categories><comments>5 pages, 6 figures. Proc. Interspeech, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a technique to alleviate the quality degradation
caused by collapsed speech segments sometimes generated by the WaveNet vocoder.
The effectiveness of the WaveNet vocoder for generating natural speech from
acoustic features has been proved in recent works. However, it sometimes
generates very noisy speech with collapsed speech segments when only a limited
amount of training data is available or significant acoustic mismatches exist
between the training and testing data. Such a limitation on the corpus and
limited ability of the model can easily occur in some speech generation
applications, such as voice conversion and speech enhancement. To address this
problem, we propose a technique to automatically detect collapsed speech
segments. Moreover, to refine the detected segments, we also propose a waveform
generation technique for WaveNet using a linear predictive coding constraint.
Verification and subjective tests are conducted to investigate the
effectiveness of the proposed techniques. The verification results indicate
that the detection technique can detect most collapsed segments. The subjective
evaluations of voice conversion demonstrate that the generation technique
significantly improves the speech quality while maintaining the same speaker
similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11120</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11120</id><created>2018-04-30</created><updated>2018-05-02</updated><authors><author><keyname>Yi</keyname><forenames>Steven</forenames></author><author><keyname>Lazzarini</keyname><forenames>Victor</forenames></author><author><keyname>Costello</keyname><forenames>Edward</forenames></author></authors><title>WAAW Csound</title><categories>cs.SD eess.AS</categories><comments>6 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper describes Web Assembly Audio Worklet (WAAW) Csound, one of the
implementations of WebAudio Csound. We begin by introducing the background to
this current implementation, stemming from the two first ports of Csound to the
web platform using Native Clients and asm.js. The technology of Web Assembly is
then introduced and discussed in its more relevant aspects. The AudioWorklet
interface of Web Audio API is explored, together with its use in WAAW Csound.
We complement this discussion by considering the overarching question of
support for multiple platforms, which implement different versions of Web
Audio. Some initial examples of the system are presented to illustrate various
potential applications. Finally, we complement the paper by discussing current
issues that are fundamental for this project and others that rely on the
development of a robust support for WASM-based audio computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11132</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11132</id><created>2018-04-30</created><authors><author><keyname>Uezato</keyname><forenames>Tatsumi</forenames></author><author><keyname>Fauvel</keyname><forenames>Mathieu</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author></authors><title>Hyperspectral unmixing with spectral variability using adaptive bundles
  and double sparsity</title><categories>eess.IV physics.data-an stat.ML</categories><doi>10.1109/TGRS.2018.2889256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral variability is one of the major issue when conducting hyperspectral
unmixing. Within a given image composed of some elementary materials (herein
referred to as endmember classes), the spectral signature characterizing these
classes may spatially vary due to intrinsic component fluctuations or external
factors (illumination). These redundant multiple endmember spectra within each
class adversely affect the performance of unmixing methods. This paper proposes
a mixing model that explicitly incorporates a hierarchical structure of
redundant multiple spectra representing each class. The proposed method is
designed to promote sparsity on the selection of both spectra and classes
within each pixel. The resulting unmixing algorithm is able to adaptively
recover several bundles of endmember spectra associated with each class and
robustly estimate abundances. In addition, its flexibility allows a variable
number of classes to be present within each pixel of the hyperspectral image to
be unmixed. The proposed method is compared with other state-of-the-art
unmixing methods that incorporate sparsity using both simulated and real
hyperspectral data. The results show that the proposed method can successfully
determine the variable number of classes present within each class and estimate
the corresponding class abundances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11184</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11184</id><created>2018-03-05</created><authors><author><keyname>Taebi</keyname><forenames>Amirtaha</forenames></author><author><keyname>Sandler</keyname><forenames>Richard H.</forenames></author><author><keyname>Kakavand</keyname><forenames>Bahram</forenames></author><author><keyname>Mansy</keyname><forenames>Hansen A.</forenames></author></authors><title>Seismocardiographic Signal Timing with Myocardial Strain</title><categories>eess.SP</categories><journal-ref>Signal Processing in Medicine and Biology (2017) 1-2</journal-ref><doi>10.1109/SPMB.2017.8257032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speckle Tracking Echocardiography (STE) is a relatively new method for
cardiac function evaluation. In the current study, STE was used to investigate
the timing of heart-induced mostly subaudible (i.e., below the frequency limit
of human hearing) chest-wall vibrations in relation to the longitudinal
myocardial strain. Such an approach may help elucidate the genesis of these
vibrations, thereby improving their diagnostic value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11185</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11185</id><created>2018-03-07</created><authors><author><keyname>Romagnoli</keyname><forenames>Raffaele</forenames></author><author><keyname>Garone</keyname><forenames>Emanuele</forenames></author></authors><title>Steady-state input calculation for achieving a desired steady-state
  output of a linear systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we provide an algorithm for the computation of the steady-state
input able to achieve the steady-state output tracking of any desired output
signal representable as a rational transfer function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11196</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11196</id><created>2018-04-25</created><authors><author><keyname>Zaeri-Amirani</keyname><forenames>Mohammad</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author><author><keyname>Mousavi</keyname><forenames>Sajad</forenames></author></authors><title>A Feature Selection Method Based on Shapley Value to False Alarm
  Reduction in ICUs, A Genetic-Algorithm Approach</title><categories>eess.SP cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High false alarm rate in intensive care units (ICUs) has been identified as
one of the most critical medical challenges in recent years. This often results
in overwhelming the clinical staff by numerous false or unurgent alarms and
decreasing the quality of care through enhancing the probability of missing
true alarms as well as causing delirium, stress, sleep deprivation and
depressed immune systems for patients. One major cause of false alarms in
clinical practice is that the collected signals from different devices are
processed individually to trigger an alarm, while there exists a considerable
chance that the signal collected from one device is corrupted by noise or
motion artifacts. In this paper, we propose a low-computational complexity yet
accurate game-theoretic feature selection method which is based on a genetic
algorithm that identifies the most informative biomarkers across the signals
collected from various monitoring devices and can considerably reduce the rate
of false alarms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11300</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11300</id><created>2018-04-30</created><authors><author><keyname>Grimm</keyname><forenames>Giso</forenames></author><author><keyname>Luberadzka</keyname><forenames>Joanna</forenames></author><author><keyname>Hohmann</keyname><forenames>Volker</forenames></author></authors><title>A toolbox for rendering virtual acoustic environments in the context of
  audiology</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A toolbox for creation and rendering of dynamic virtual acoustic environments
(TASCAR) that allows direct user interaction was developed for application in
hearing aid research and audiology. This technical paper describes the general
software structure and the time-domain simulation methods, i.e., transmission
model, image source model, and render formats, used to produce virtual acoustic
environments with moving objects. Implementation-specific properties are
described, and the computational performance of the system was measured as a
function of simulation complexity. Results show that on commercially available
commonly used hardware the simulation of several hundred virtual sound sources
is possible in the time domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.11328</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1804.11328</id><created>2018-04-30</created><authors><author><keyname>Belakaria</keyname><forenames>Syrine</forenames></author><author><keyname>Ammous</keyname><forenames>Mustafa</forenames></author><author><keyname>Sorour</keyname><forenames>Sameh</forenames></author><author><keyname>Abdel-Rahimyz</keyname><forenames>Ahmed</forenames></author></authors><title>Multi-Class Management with Sub-Class Service for Autonomous Electric
  Mobility On-Demand Systems</title><categories>eess.SP</categories><comments>9 pages, 3 Figures, Conference. arXiv admin note: substantial text
  overlap with arXiv:1705.03070</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the significant advances in vehicle automation and electrification,
the next-decade aspirations for massive deployments of autonomous electric
mobility on demand (AEMoD) services are still threatened by two major
bottlenecks, namely the computational and charging delays. This paper proposes
a solution for these two challenges by suggesting the use of fog computing for
AEMoD systems, and developing an optimized charging scheme for its vehicles
with and multi-class dispatching scheme for the customers. A queuing model
representing the proposed multi-class management scheme with sub-class service
is first introduced. The stability conditions of the system in a given city
zone are then derived. Decisions on the proportions of each class vehicles to
partially/fully charge, or directly serve customers of possible sub-classes are
then optimized in order to minimize the maximum response time of the system.
Results show the merits of our optimized model compared to a previously
proposed scheme and other non-optimized policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00061</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00061</id><created>2018-04-30</created><authors><author><keyname>Zhang</keyname><forenames>Qianqian</forenames></author><author><keyname>Mozaffari</keyname><forenames>Mohammad</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Machine Learning for Predictive On-Demand Deployment of UAVs for
  Wireless Communications</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel machine learning (ML) framework is proposed for
enabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs),
acting as aerial base stations (BSs), to provide on-demand wireless service to
cellular users. In order to have a comprehensive analysis of cellular traffic,
an ML framework based on a Gaussian mixture model (GMM) and a weighted
expectation maximization (WEM) algorithm is introduced to predict the potential
network congestion. Then, the optimal deployment of UAVs is studied to minimize
the transmit power needed to satisfy the communication demand of users in the
downlink, while also minimizing the power needed for UAV mobility, based on the
predicted cellular traffic. To this end, first, the optimal partition of
service areas of each UAV is derived, based on a fairness principle. Next, the
optimal location of each UAV that minimizes the total power consumption is
derived. Simulation results show that the proposed ML approach can reduce the
required downlink transmit power and improve the power efficiency by over 20%,
compared with an optimal deployment of UAVs with no ML prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00082</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00082</id><created>2018-04-30</created><authors><author><keyname>Nizami</keyname><forenames>S.</forenames></author><author><keyname>Bekele</keyname><forenames>A.</forenames></author><author><keyname>Hozayen</keyname><forenames>M.</forenames></author><author><keyname>Greenwood</keyname><forenames>K.</forenames></author><author><keyname>Harrold</keyname><forenames>J.</forenames></author><author><keyname>Green</keyname><forenames>J. R.</forenames></author></authors><title>Measuring uncertainty during respiratory rate estimation using
  pressure-sensitive mats</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation and Measurement, 2018</journal-ref><doi>10.1109/TIM.2018.2805154</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop and evaluate a respiratory rate estimation algorithm that utilizes
data from pressure-sensitive mat (PSM) technology for continuous patient
monitoring in neonatal intensive care units (NICU). An analysis of the random
effect of drift and systematic effect of creep in the PSM data is presented,
showing that these are essentially dependent on the applied load and contact
surface. Uncertainty measurements are pivotal when estimating physiologic
parameters. The standard uncertainty in the PSM data is here represented by the
percent drift. Next, we evaluate the applicability of PSM technology to
estimate RR in neonatal patient simulator trials under five mixed effects
including internally and externally induced motion, mattress type, grunting,
laying position, and different breathing rates. We analyze the limits of
agreement on the mixed effects model to derive the uncertainty in the estimated
RR obtained through two estimation techniques. In comparison with the gold
standard RR values, we achieved a mean bias of 0.56 breaths per minute (bpm)
with an error bounded by a 95% confidence interval of [-2.26, 3.37] bpm. These
results meet the clinical accuracy requirements of RR within +/-5 bpm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00083</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00083</id><created>2018-04-30</created><authors><author><keyname>Nizami</keyname><forenames>Shermeen</forenames></author><author><keyname>Bekele</keyname><forenames>Amente</forenames></author><author><keyname>Hozayen</keyname><forenames>Mohamed</forenames></author><author><keyname>Greenwood</keyname><forenames>Kim</forenames></author><author><keyname>Harrold</keyname><forenames>JoAnn</forenames></author><author><keyname>Green</keyname><forenames>James R.</forenames></author></authors><title>Comparing time and frequency domain estimation of neonatal respiratory
  rate using pressure-sensitive mats</title><categories>eess.SP</categories><journal-ref>Proc. of IEEE Int. Symp. Med. Meas. Appl. (MeMeA), Rochester, MN,
  USA, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pressure-sensitive mats (PSM) have proved to be useful in the estimation of
respiratory rates (RR) in adult patients. However, PSM technology has not been
extensively applied to derive physiologic parameters in infant and neonatal
patients. This research evaluates the applicability of the capacitive XSensor
PSM technology to estimate a range of RR in neonatal patient simulator trials
conducted under several experimental conditions. PSM data are analyzed in both
the time and frequency domain and comparative results are presented. For the
frequency-domain approach, in addition to estimating RR, a measure of
confidence is also derived from the relative height of peaks in the
periodogram. The study demonstrates that frequency domain analysis of
mean-shifted PSM data achieves the best possible RR estimation, with zero
percent error, as compared to the lowest achievable RMS error of 1.57 percent
in the time domain. The frequency domain approach outperforms the time domain
analysis whether examining raw data or those preprocessed by normalizing,
detrending and median filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00086</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00086</id><created>2018-04-30</created><authors><author><keyname>Nizami</keyname><forenames>Shermeen</forenames></author><author><keyname>Green</keyname><forenames>James R.</forenames></author><author><keyname>McGregor</keyname><forenames>Carolyn</forenames></author></authors><title>Implementation of Artifact Detection in Critical Care: A Methodological
  Review</title><categories>eess.SP</categories><journal-ref>IEEE Reviews in Biomedical Engineering, 2013</journal-ref><doi>10.1109/RBME.2013.2243724</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artifact Detection (AD) techniques minimize the impact of artifacts on
physiologic data acquired in Critical Care Units (CCU) by assessing quality of
data prior to Clinical Event Detection (CED) and Parameter Derivation (PD).
This methodological review introduces unique taxonomies to synthesize over 80
AD algorithms based on these six themes: (1) CCU; (2) Physiologic Data Source;
(3) Harvested data; (4) Data Analysis; (5) Clinical Evaluation; and (6)
Clinical Implementation. Review results show that most published algorithms:
(a) are designed for one specific type of CCU; (b) are validated on data
harvested only from one Original Equipment Manufacturer (OEM) monitor; (c)
generate Signal Quality Indicators (SQI) that are not yet formalised for useful
integration in clinical workflows; (d) operate either in standalone mode or
coupled with CED or PD applications; (e) are rarely evaluated in real-time; and
(f) are not implemented in clinical practice. In conclusion, it is recommended
that AD algorithms conform to generic input and output interfaces with commonly
defined data: (1) type; (2) frequency; (3) length; and (4) SQIs. This shall
promote (a) reusability of algorithms across different CCU domains; (b)
evaluation on different OEM monitor data; (c) fair comparison through
formalised SQIs; (d) meaningful integration with other AD, CED and PD
algorithms; and (e) real-time implementation in clinical workflows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00142</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00142</id><created>2018-04-30</created><updated>2018-05-07</updated><authors><author><keyname>Park</keyname><forenames>Jihong</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>URLLC-eMBB Slicing to Support VR Multimodal Perceptions over Wireless
  Cellular Systems</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>7 pages, 4 figures, submitted to IEEE GLOBECOM'18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual reality (VR) enables mobile wireless users to experience multimodal
perceptions in a virtual space. In this paper we investigate the problem of
concurrent support of visual and haptic perceptions over wireless cellular
networks, with a focus on the downlink transmission phase. While the visual
perception requires moderate reliability and maximized rate, the haptic
perception requires fixed rate and high reliability. Hence, the visuo-haptic VR
traffic necessitates the use of two different network slices: enhanced mobile
broadband (eMBB) for visual perception and ultra-reliable and low latency
communication (URLLC) for haptic perception. We investigate two methods by
which these two slices share the downlink resources orthogonally and
non-orthogonally, respectively. We compare these methods in terms of the
just-noticeable difference (JND), an established measure in psychophysics, and
show that non-orthogonal slicing becomes preferable under a higher target
integrated-perceptual resolution and/or a higher target rate for haptic
perceptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00146</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00146</id><created>2018-04-30</created><authors><author><keyname>Tran</keyname><forenames>Manh Le</forenames></author><author><keyname>Kim</keyname><forenames>Sunghwan</forenames></author><author><keyname>Ketseoglou</keyname><forenames>Thomas</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>LED Selection and MAP Detection for Generalized LED Index Modulation</title><categories>eess.SP</categories><doi>10.1109/LPT.2018.2865591</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose light-emitting diode (LED) selection that can be
applied not only to the conventional Multiple-Input Multiple-Output (MIMO)
case, but also to a larger MIMO configuration of generalized LED index
modulation (GLIM) system with optical orthogonal frequency division
multiplexing (OFDM) in visible light communication (VLC). Moreover, we derive a
simplified implementation of the maximum a posteriori (MAP) detector when the
number of LEDs is an even number larger than four. Simulation results show that
the performance of MAP and LED selection is better than other detection
algorithms for larger even numbers of LEDs and conventional GLIM for $4\times4$
transmission, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00165</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00165</id><created>2018-04-30</created><updated>2018-12-06</updated><authors><author><keyname>Gama</keyname><forenames>Fernando</forenames></author><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Convolutional Neural Network Architectures for Signals Supported on
  Graphs</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2018.2887403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two architectures that generalize convolutional neural networks (CNNs) for
the processing of signals supported on graphs are introduced. We start with the
selection graph neural network (GNN), which replaces linear time invariant
filters with linear shift invariant graph filters to generate convolutional
features and reinterprets pooling as a possibly nonlinear subsampling stage
where nearby nodes pool their information in a set of preselected sample nodes.
A key component of the architecture is to remember the position of sampled
nodes to permit computation of convolutional features at deeper layers. The
second architecture, dubbed aggregation GNN, diffuses the signal through the
graph and stores the sequence of diffused components observed by a designated
node. This procedure effectively aggregates all components into a stream of
information having temporal structure to which the convolution and pooling
stages of regular CNNs can be applied. A multinode version of aggregation GNNs
is further introduced for operation in large scale graphs. An important
property of selection and aggregation GNNs is that they reduce to conventional
CNNs when particularized to time signals reinterpreted as graph signals in a
circulant graph. Comparative numerical analyses are performed in a source
localization application over synthetic and real-world networks. Performance is
also evaluated for an authorship attribution problem and text category
classification. Multinode aggregation GNNs are consistently the best performing
GNN architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00169</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00169</id><created>2018-04-30</created><authors><author><keyname>Pinto</keyname><forenames>S. F. B.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Multi-Step Knowledge-Aided Iterative ESPRIT for Direction Finding</title><categories>eess.SP cs.LG stat.ML</categories><comments>7 figures. arXiv admin note: text overlap with arXiv:1703.10523</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a subspace-based algorithm for DOA estimation which
iteratively reduces the disturbance factors of the estimated data covariance
matrix and incorporates prior knowledge which is gradually obtained on line. An
analysis of the MSE of the reshaped data covariance matrix is carried out along
with comparisons between computational complexities of the proposed and
existing algorithms. Simulations focusing on closely-spaced sources, where they
are uncorrelated and correlated, illustrate the improvements achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00202</identifier>
 <datestamp>2019-03-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00202</id><created>2018-05-01</created><authors><author><keyname>Barbosa</keyname><forenames>Patricia R.</forenames></author><author><keyname>Sarkale</keyname><forenames>Yugandhar</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author><author><keyname>Li</keyname><forenames>Yun</forenames></author><author><keyname>Suvorova</keyname><forenames>Sofia</forenames></author><author><keyname>Moran</keyname><forenames>Bill</forenames></author></authors><title>Controlled Tracking in Urban Terrain: Closing the Loop</title><categories>eess.SP cs.SY</categories><comments>Submitted to Special Issue: Recent Advances on Data Fusion,
  Estimation in Navigation and Control in Asian Journal of Control</comments><journal-ref>Asian J Control. 2019; 1-14</journal-ref><doi>10.1002/asjc.2083</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the challenging problem of integrating detection, signal
processing, target tracking, and adaptive waveform scheduling with lookahead in
urban terrain. We propose a closed-loop active sensing system to address this
problem by exploiting three distinct levels of diversity: (1) spatial diversity
through the use of coordinated multistatic radars; (2) waveform diversity by
adaptively scheduling the transmitted waveform; and (3) motion model diversity
by using a bank of parallel filters matched to different motion models.
Specifically, at every radar scan, the waveform that yields the minimum trace
of the one-step-ahead error covariance matrix is transmitted; the received
signal goes through a matched-filter, and curve fitting is used to extract
range and range-rate measurements that feed the LMIPDA-VSIMM algorithm for data
association and filtering. Monte Carlo simulations demonstrate the
effectiveness of the proposed system in an urban scenario contaminated by dense
and uneven clutter, strong multipath, and limited line-of-sight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00222</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00222</id><created>2018-05-01</created><updated>2019-06-30</updated><authors><author><keyname>Adheem</keyname><forenames>Wameedh Riyadh Abdul</forenames></author><author><keyname>Ibraheem</keyname><forenames>Ibraheem Kasim</forenames></author></authors><title>Model-Free Active Input-Output Feedback Linearization of a Single-Link
  Flexible Joint Manipulator: An Improved ADRC Approach</title><categories>cs.SY cs.RO eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional Input-Output Feedback Linearization (IOFL) requires full
knowledge of system dynamics and assumes no disturbance at the input channel
and no system's uncertainties. In this paper, a model-free Active Input-Output
Feedback Linearization (AIOFL) technique based on an Improved Active
Disturbance Rejection Control (IADRC) paradigm is proposed to design feedback
linearization control law for a generalized nonlinear system with known
relative degree. The Linearization Control Law(LCL) is composed of a scaled
generalized disturbance estimated by an Improved Nonlinear Extended State
Observer (INLESO) with saturation-like behavior and the nominal control law
produced by an Improved Nonlinear State Error Feedback (INLSEF). The proposed
AIOFL cancels in real-time fashion the generalized disturbances which represent
all the unwanted dynamics, exogenous disturbances, and system uncertainties and
transforms the system into a chain of integrators up to the relative degree of
the system, the only information required about the nonlinear system. Stability
analysis has been conducted based on Lyapunov functions and revealed the
convergence of the INLESO and the asymptotic stability of the closed-loop
system. Verification of the outcomes has been achieved by applying the proposed
AIOFL technique on the Flexible Joint Single Link Manipulator (SLFJM). The
simulations results validated the effectiveness of the proposed AIOFL tool
based on IADRC as compared to the conventional ADRC based AIOFL and the
traditional IOFL techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00237</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00237</id><created>2018-05-01</created><updated>2019-02-14</updated><authors><author><keyname>Pons</keyname><forenames>Jordi</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Randomly weighted CNNs for (music) audio classification</title><categories>cs.SD eess.AS</categories><comments>In proceedings of the 44th IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP2019). Code:
  https://github.com/jordipons/elmarc</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The computer vision literature shows that randomly weighted neural networks
perform reasonably as feature extractors. Following this idea, we study how
non-trained (randomly weighted) convolutional neural networks perform as
feature extractors for (music) audio classification tasks. We use features
extracted from the embeddings of deep architectures as input to a classifier -
with the goal to compare classification accuracies when using different
randomly weighted architectures. By following this methodology, we run a
comprehensive evaluation of the current deep architectures for audio
classification, and provide evidence that the architectures alone are an
important piece for resolving (music) audio problems using deep neural
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00316</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00316</id><created>2018-05-01</created><updated>2018-06-18</updated><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Javidnia</keyname><forenames>Hossein</forenames></author><author><keyname>Corcoran</keyname><forenames>Peter</forenames></author></authors><title>Versatile Auxiliary Classifier with Generative Adversarial Network
  (VAC+GAN)</title><categories>eess.IV cs.CV cs.LG</categories><comments>This paper will be uploaded as two separate manuscripts</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most interesting challenges in Artificial Intelligence is to train
conditional generators which are able to provide labeled adversarial samples
drawn from a specific distribution. In this work, a new framework is presented
to train a deep conditional generator by placing a classifier in parallel with
the discriminator and back propagate the classification error through the
generator network. The method is versatile and is applicable to any variations
of Generative Adversarial Network (GAN) implementation, and also gives superior
results compared to similar methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00348</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00348</id><created>2018-04-30</created><authors><author><keyname>Cui</keyname><forenames>Yuqi</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Guo</keyname><forenames>Chenfeng</forenames></author><author><keyname>Wu</keyname><forenames>Dongrui</forenames></author></authors><title>OMG - Emotion Challenge Solution</title><categories>cs.CV cs.LG cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short paper describes our solution to the 2018 IEEE World Congress on
Computational Intelligence One-Minute Gradual-Emotional Behavior Challenge,
whose goal was to estimate continuous arousal and valence values from short
videos. We designed four base regression models using visual and audio
features, and then used a spectral approach to fuse them to obtain improved
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00359</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00359</id><created>2018-04-27</created><updated>2018-05-29</updated><authors><author><keyname>Nguyen</keyname><forenames>Duc-Phuc</forenames></author><author><keyname>Le</keyname><forenames>Dinh-Dung</forenames></author><author><keyname>Tran</keyname><forenames>Thi-Hong</forenames></author><author><keyname>Huynh</keyname><forenames>Huu-Thuan</forenames></author><author><keyname>Nakashima</keyname><forenames>Yasuhiko</forenames></author></authors><title>Hardware Implementation of A Non-RLL Soft-decoding Beacon-based Visible
  Light Communication Receiver</title><categories>eess.SP cs.AR</categories><comments>In review process of ATC'18, HCMC, Vietnam</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC)-based beacon systems, which usually
transmit identification (ID) information in small-size data frames are applied
widely in indoor localization applications. There is one fact that flicker of
LED light should be avoid in any VLC systems. Current flicker mitigation
solutions based on run-length limited (RLL) codes suffer from reduced code
rates, or are limited to hard-decoding forward error correction (FEC) decoders.
Recently, soft-decoding techniques of RLL-codes are proposed to support
soft-decoding FEC algorithms, but they contain potentials of high-complexity
and time-consuming computations. Fortunately, non-RLL direct current
(DC)-balance solutions can overcome the drawbacks of RLL-based algorithms,
however, they meet some difficulties in system latency or inferior
error-correction performances. Recently, non-RLL flicker mitigation solution
based on Polar code has proved to be an optimal approach due to its natural
equal probabilities of short runs of 1's and 0's with high error-correction
performance. However, we found that this solution can only maintain the DC
balance only when the data frame length is sufficiently long. Accordingly,
short beacon-based data frames might still be a big challenge for flicker
mitigation in such non-RLL cases. In this paper, we introduce a flicker
mitigation solution designed for VLC-based beacon systems that combines a
simple pre-scrambler with a Polar encoder which has a codeword smaller than the
previous work 8 times. We also propose a hardware architecture for the proposed
compact non-RLL VLC receiver for the first time. Also, a 3-bit soft-decision
filter is introduce to enable soft-decoding of Polar decoder to improve the
performance of the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00362</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00362</id><created>2018-04-29</created><updated>2019-07-31</updated><authors><author><keyname>Gao</keyname><forenames>Guangyu</forenames></author><author><keyname>Xiang</keyname><forenames>Xueshuang</forenames></author><author><keyname>Liang</keyname><forenames>Qijun</forenames></author><author><keyname>Liu</keyname><forenames>Naijin</forenames></author></authors><title>A code-free optical undersampling technique for broadband microwave
  spectrum measurement</title><categories>eess.SP</categories><comments>3 pages and 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel broadband microwave (MW) spectrum measurement (BMSM) scheme based on
code-free optical undersampling and homodyne detection is proposed. The fully
analog generation of optical pulses with a far-less-than-Nyquist rate is only
through modulating cascaded electrooptical modulators by a single RF tone
instead of any high-speed coding sequence modulation. Homodyne detection will
reduce the analysis bandwidth of BMSM and enhance the detection performance of
weak signal. A multi-band signal with 20 GHz spectral range and SNR = 61 dB is
used to investigate the BMSM performance of this scheme, and the results show
good performance for BMSM. The potentials for further optimization in practice
are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00363</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00363</id><created>2018-04-29</created><authors><author><keyname>Hoque</keyname><forenames>Mohammad A</forenames></author><author><keyname>Ahmed</keyname><forenames>Md Salman</forenames></author><author><keyname>Rios-Torres</keyname><forenames>Jackeline</forenames></author><author><keyname>Khattak</keyname><forenames>Asad</forenames></author><author><keyname>Arvin</keyname><forenames>Ramin</forenames></author></authors><title>Impact of Vehicle-to-Vehicle Communication Reliability on Safety
  Applications: An Experimental Study</title><categories>eess.SP</categories><comments>Annual Meeting of the Transportation Research Board, 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Vehicle-to-Vehicle (V2V) communication using Dedicated Short Range
Communications (DSRC) technology provides promising benefits for drastically
reducing vehicle collisions. A decentralized approach combined with DSRC allow
vehicles in a highly mobile and complex network to send and receive safety
messages with high reliability and low latency. Notably, there are many factors
that may cause the system to become unreliable due to communication failures.
While the reliability of V2V communication has been a subject of study by
researchers, there is still open questions regarding how the placement of DSRC
devices (inside or outside the host vehicle), the vehicle's interior elements
or the differences in altitude can affect the V2V communications. This paper
aims to provide experimental testing data and analysis to quantify the impact
of relative vehicle speeds, differences in altitudes between two vehicles, and
vehicle's interior obstacles (which can vary depending on the placement of DSRC
device and when communicating with front vs. rear vehicles) on the reliability
of V2V communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00367</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00367</id><created>2018-04-30</created><authors><author><keyname>Zhang</keyname><forenames>Chong</forenames></author><author><keyname>Hong</keyname><forenames>Geok Soon</forenames></author><author><keyname>Zhou</keyname><forenames>Jun-Hong</forenames></author><author><keyname>Tan</keyname><forenames>Kay Chen</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Hong</keyname><forenames>Jihoon</forenames></author><author><keyname>Chan</keyname><forenames>Hian-Leng</forenames></author></authors><title>A Multi-State Diagnosis and Prognosis Framework with Feature Learning
  for Tool Condition Monitoring</title><categories>eess.SP cs.LG</categories><comments>14 pages, 12 figures, 10 tables, submitted to IEEE Transactions on
  Cybernetics</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a multi-state diagnosis and prognosis (MDP) framework is
proposed for tool condition monitoring via a deep belief network based
multi-state approach (DBNMS). For fault diagnosis, a cost-sensitive deep belief
network (namely ECS-DBN) is applied to deal with the imbalanced data problem
for tool state estimation. An appropriate prognostic degradation model is then
applied for tool wear estimation based on the different tool states. The
proposed framework has the advantage of automatic feature representation
learning and shows better performance in accuracy and robustness. The
effectiveness of the proposed DBNMS is validated using a real-world dataset
obtained from the gun drilling process. This dataset contains a large amount of
measured signals involving different tool geometries under various operating
conditions. The DBNMS is examined for both the tool state estimation and tool
wear estimation tasks. In the experimental studies, the prediction results are
evaluated and compared with popular machine learning approaches, which show the
superior performance of the proposed DBNMS approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00372</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00372</id><created>2018-04-21</created><authors><author><keyname>Mishra</keyname><forenames>Sumita</forenames></author><author><keyname>Kumar</keyname><forenames>Sachin</forenames></author><author><keyname>Singh</keyname><forenames>Shivani</forenames></author><author><keyname>Asthana</keyname><forenames>Pallavi</forenames></author><author><keyname>Mathur</keyname><forenames>Nidhi</forenames></author></authors><title>Novel Hard Link-Switching Scheme using Pre-Scanning for Indoor VLC
  Networks</title><categories>eess.SP</categories><comments>This is author version of paper presented at 04th International
  Conference on Computing For Sustainable Global Development (14-16 March,
  2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  VLC is attracting a lot of attention as an emerging potential technology for
deployment in next generation indoor wireless networks. Use of efficient link
switching scheme among VLC access points is critical in indoor environment to
provide seamless connectivity to mobile users. This paper presents a novel
position prediction link switching scheme for indoor visible light
communication systems. The method exploits the fact that indoor scenario (light
fixtures/furniture) mostly remains unchanged, therefore, this information can
be stored at the coordinator end. Thus, the user is not required to search for
the best transmitter when RSS is reduced to a threshold value as in
conventional methods which cause substantial delay in switching process.
Simulation results show that the proposed scheme for indoor VLC System achieves
the dual purpose of adequate illumination and mobility to user in considered
indoor scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00407</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00407</id><created>2018-05-01</created><authors><author><keyname>Kelner</keyname><forenames>Jan M.</forenames><affiliation>Military University of Technology, Faculty of Electronics, Institute of Telecommunications, Warsaw, Poland</affiliation></author></authors><title>Cooperative system of emission source localization based on SDF</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 6 figures</comments><msc-class>94A40, 94A05, 94A12, 94A17</msc-class><acm-class>E.4; H.4.3</acm-class><journal-ref>Proceedings of 2018 19th International Conference on Military
  Communications and Information Systems (ICMCIS), Warsaw, Poland,
  22-23.05.2018., pp. 1-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient and precise location of emission sources in an urbanized
environment is very important in electronic warfare. Therefore, unmanned aerial
vehicles (UAVs) are increasingly used for such tasks. In this paper, we present
the cooperation of several UAVs creating a wireless sensor network (WSN) that
locates the emission source. In the proposed WSN, the location is based on
spectrum sensing and the signal Doppler frequency method. The paper presents
the concept of the system. Simulation studies are used to assess the efficiency
of the cooperative WSN. In this case, the location effectiveness for the WSN is
compared to the single UAV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00436</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00436</id><created>2018-05-01</created><authors><author><keyname>Peng</keyname><forenames>Tong</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>A Physical Layer Network Coding Design for 5G Network MIMO</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1801.07061</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a physical layer network coding (PNC) approach for
network MIMO (N-MIMO) systems to release the heavy burden of backhaul load. The
proposed PNC approach is applied for uplink scenario in binary systems, and the
design guideline serves multiple mobile terminals (MTs) and guarantees
unambiguous recovery of the message from each MT. We present a novel PNC design
criterion first based on binary matrix theories, followed by an adaptive
optimal mapping selection algorithm based on the proposed design criterion. In
order to reduce the real-time computational complexity, a two-stage search
algorithm for the optimal binary PNC mapping matrix is developed. Numerical
results show that the proposed scheme achieves lower outage probability with
reduced backhaul load compared to practical CoMP schemes which quantize the
estimated symbols from a log-likelihood ratio (LLR) based multiuser detector
into binary bits at each access point (AP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00505</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00505</id><created>2018-05-01</created><updated>2019-06-30</updated><authors><author><keyname>Abdul-Adheem</keyname><forenames>Wameedh R.</forenames></author><author><keyname>Ibraheem</keyname><forenames>Ibraheem K.</forenames></author></authors><title>Novel Active Disturbance Rejection Control Based on Nested Linear
  Extended State Observers</title><categories>cs.SY eess.SP math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a Novel Active Disturbance Rejection Control (N-ADRC) strategy
is proposed that replaces the Linear Extended state observer (LESO) used in
Conventional ADRC (C-ADRC) with a Nested LESO. In the nested LESO, the
inner-loop LESO actively estimates and eliminates the generalized disturbance.
Increasing the bandwidth improves the estimation accuracy which may tolerate
noise and conflict with H/W limitations and the sampling frequency of the
system. Therefore, an alternative scenario is offered without increasing the
bandwidth of the inner-loop LESO provided that the rate of change of the
generalized disturbance estimation error is upper bounded. This is achieved by
the placing an outer-loop LESO in parallel with the inner one, it estimates and
eliminates the remaining generalized disturbance that eluded from the
inner-loop LESO due to bandwidth limitations. The stability of LESO and nested
LESO is investigated using Lyapunov stability analysis. Simulations on
uncertain nonlinear SISO system with time-varying exogenous disturbance
revealed that the proposed nested LESO can successfully deal with a generalized
disturbance in both noisy and noise-free environments, where the Integral Time
Absolute Error (ITAE) of the tracking error for the nested LESO is reduced by
69.87% from that of the LESO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00510</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00510</id><created>2018-05-01</created><authors><author><keyname>Hadi</keyname><forenames>Ibraheem Kasim Ibraheem Salam Wisam</forenames></author></authors><title>Design and Implementation of a Low-Cost Secure Vehicle Tracking System</title><categories>eess.SP cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we used XBee wireless technology due to the privileges that it
provides in terms of low cost and a high level of security which gives a more
reliable information transfer, penetration avoidance, and unauthorized access,
without any cost in sending and receiving this information. The aim of this
work is to syndicate the XBee wireless technology and global positioning system
(GPS) for a low-cost real-time vehicle tracking system and displaying the
result on Google earth. The overall system involved two main modules, the
displaying module (monitoring station) and the following module (vehicle unit).
The following module consists of microcontroller (Arduino) platform, XBee, and
GPS for navigation purpose. The GPS delivers real-time data about the location
of the vehicle and directs the coordinate to the XBee via the Arduino platform.
The later is incorporated as a connecting buffer between the XBee transmission
unit and the GPS receiver. Receiving the location data of the tracked vehicle
and displaying them on Google earth is the responsibility of the monitoring
station. The designed system has been tested practically in both crowded and
open area environments, the overall system works well and displayed the vehicle
coordinates nevertheless the existence of noise and interference in the vehicle
area and regardless the obstacles like buildings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00524</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00524</id><created>2018-05-01</created><updated>2019-01-04</updated><authors><author><keyname>Haldar</keyname><forenames>Justin P.</forenames></author><author><keyname>Kim</keyname><forenames>Daeun</forenames></author></authors><title>OEDIPUS: An Experiment Design Framework for Sparsity-Constrained MRI</title><categories>eess.SP</categories><comments>Manuscript submitted to IEEE Transactions on Medical Imaging</comments><doi>10.1109/TMI.2019.2896180</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new estimation-theoretic framework for experiment
design in the context of MR image reconstruction under sparsity constraints.
The new framework is called OEDIPUS (Oracle-based Experiment Design for Imaging
Parsimoniously Under Sparsity constraints), and is based on combining the
constrained Cram\'{e}r-Rao bound with classical experiment design techniques.
Compared to popular random sampling approaches, OEDIPUS is fully deterministic
and automatically tailors the sampling pattern to the specific imaging context
of interest (i.e., accounting for coil geometry, anatomy, image contrast,
etc.). OEDIPUS-based experiment designs are evaluated using retrospectively
subsampled in vivo MRI data in several different contexts. Results demonstrate
that OEDIPUS-based experiment designs have some desirable characteristics
relative to conventional MRI sampling approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00579</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00579</id><created>2018-05-01</created><authors><author><keyname>Zhao</keyname><forenames>Han</forenames></author><author><keyname>Zarar</keyname><forenames>Shuayb</forenames></author><author><keyname>Tashev</keyname><forenames>Ivan</forenames></author><author><keyname>Lee</keyname><forenames>Chin-Hui</forenames></author></authors><title>Convolutional-Recurrent Neural Networks for Speech Enhancement</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an end-to-end model based on convolutional and recurrent neural
networks for speech enhancement. Our model is purely data-driven and does not
make any assumptions about the type or the stationarity of the noise. In
contrast to existing methods that use multilayer perceptrons (MLPs), we employ
both convolutional and recurrent neural network architectures. Thus, our
approach allows us to exploit local structures in both the frequency and
temporal domains. By incorporating prior knowledge of speech signals into the
design of model structures, we build a model that is more data-efficient and
achieves better generalization on both seen and unseen noise. Based on
experiments with synthetic data, we demonstrate that our model outperforms
existing methods, improving PESQ by up to 0.6 on seen noise and 0.64 on unseen
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00604</identifier>
 <datestamp>2018-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00604</id><created>2018-05-01</created><updated>2018-09-07</updated><authors><author><keyname>Mobiny</keyname><forenames>Aryan</forenames></author><author><keyname>Najarian</keyname><forenames>Mohammad</forenames></author></authors><title>Text-Independent Speaker Verification Using Long Short-Term Memory
  Networks</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an architecture based on Long Short-Term Memory Networks has
been proposed for the text-independent scenario which is aimed to capture the
temporal speaker-related information by operating over traditional speech
features. For speaker verification, at first, a background model must be
created for speaker representation. Then, in enrollment stage, the speaker
models will be created based on the enrollment utterances. For this work, the
model will be trained in an end-to-end fashion to combine the first two stages.
The main goal of end-to-end training is the model being optimized to be
consistent with the speaker verification protocol. The end- to-end training
jointly learns the background and speaker models by creating the representation
space. The LSTM architecture is trained to create a discrimination space for
validating the match and non-match pairs for speaker verification. The proposed
architecture demonstrate its superiority in the text-independent compared to
other traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00625</identifier>
 <datestamp>2018-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00625</id><created>2018-05-02</created><updated>2018-05-04</updated><authors><author><keyname>Deng</keyname><forenames>Didan</forenames></author><author><keyname>Zhou</keyname><forenames>Yuqian</forenames></author><author><keyname>Pi</keyname><forenames>Jimin</forenames></author><author><keyname>Shi</keyname><forenames>Bertram E.</forenames></author></authors><title>Multimodal Utterance-level Affect Analysis using Visual, Audio and Text
  Features</title><categories>eess.IV cs.CL cs.CV</categories><comments>5 pages, 1 figure, subject to the 2018 IJCNN challenge on One-Minute
  Gradual-Emotion Recognition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of information across multiple modalities and across time is
a promising way to enhance the emotion recognition performance of affective
systems. Much previous work has focused on instantaneous emotion recognition.
The 2018 One-Minute Gradual-Emotion Recognition (OMG-Emotion) challenge, which
was held in conjunction with the IEEE World Congress on Computational
Intelligence, encouraged participants to address long-term emotion recognition
by integrating cues from multiple modalities, including facial expression,
audio and language. Intuitively, a multi-modal inference network should be able
to leverage information from each modality and their correlations to improve
recognition over that achievable by a single modality network. We describe here
a multi-modal neural architecture that integrates visual information over time
using an LSTM, and combines it with utterance level audio and text cues to
recognize human sentiment from multimodal clips. Our model outperforms the
unimodal baseline, achieving the concordance correlation coefficients (CCC) of
0.400 on the arousal task, and 0.353 on the valence task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00681</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00681</id><created>2018-05-02</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Shi</keyname><forenames>Zhanglei</forenames></author><author><keyname>Leung</keyname><forenames>Chi-Sing</forenames></author><author><keyname>So</keyname><forenames>Hing Cheung</forenames></author></authors><title>ADMM-MCP Framework for Sparse Recovery with Global Convergence</title><categories>eess.SP math.OC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In compressed sensing, the l0-norm minimization of sparse signal
reconstruction is NP-hard. Recent work shows that compared with the best convex
relaxation (l1-norm), nonconvex penalties can better approximate the l0-norm
and can reconstruct the signal based on fewer observations. In this paper, the
original problem is relaxed by using minimax concave penalty (MCP). Then
alternating direction method of multipliers (ADMM) and modified iterative hard
thresholding method are used to solve the problem. Under certain reasonable
assumptions, the global convergence of the proposed method is proved. The
parameter setting is also discussed. Finally, through simulations and
comparisons with several state-of-the-art algorithms, the effectiveness of
proposed method is confirmed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00682</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00682</id><created>2018-05-02</created><authors><author><keyname>Uribe</keyname><forenames>David Oliva</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author><author><keyname>Stroop</keyname><forenames>Ralf</forenames></author></authors><title>Improved Tactile Resonance Sensor for Robotic Assisted Surgery</title><categories>physics.med-ph eess.SP</categories><comments>16 pages</comments><journal-ref>published in Mechanical Systems and Signal Processing 2018</journal-ref><doi>10.1016/j.ymssp.2017.07.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an improved tactile sensor using a piezoelectric bimorph
able to differentiate soft materials with similar mechanical characteristics.
The final aim is to develop intelligent surgical tools for brain tumour
resection using integrated sensors in order to improve tissue tumour
delineation and tissue differentiation. The bimorph sensor is driven using a
random phase multisine and the properties of contact between the sensor's tip
and a certain load are evaluated by means of the evaluation of the
nonparametric FRF. An analysis of the nonlinear contributions is presented to
show that the use of a linear model is feasible for the measurement conditions.
A series of gelatine phantoms were tested. The tactile sensor is able to
identify minimal differences in the consistency of the measured samples
considering viscoelastic behaviour. A variance analysis was performed to
evaluate the reliability of the sensors and to identify possible error sources
due to inconsistencies in the preparation method of the phantoms. The results
of the variance analysis are discussed showing that ability of the proposed
tactile sensor to perform high quality measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00687</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00687</id><created>2018-05-02</created><authors><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author><author><keyname>Schoukens</keyname><forenames>Johan</forenames></author><author><keyname>Koll&#xe1;r</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author></authors><title>Measuring the Noise Cumulative Distribution Function Using Quantized
  Data</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation and Measurement ( Volume: 65,
  Issue: 7, July 2016 ) pages 1540 - 1546</journal-ref><doi>10.1109/TIM.2016.2540865</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of estimating the cumulative distribution
function and probability density function of a random variable using data
quantized by uniform and non-uniform quantizers. A simple estimator is proposed
based on the empirical distribution function that also takes the values of the
quantizer transition levels into account. The properties of this estimator are
discussed and analyzed at first by simulations. Then by removing all
assumptions that are difficult to apply, a new procedure is described that does
not require neither the transition levels nor the input sequence used to source
the quantizer to be known. The experimental results obtained using a commercial
12-b data acquisition system show the applicability of this estimator to
real-world type of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00707</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00707</id><created>2018-05-02</created><authors><author><keyname>Gui</keyname><forenames>Linqing</forenames></author><author><keyname>Bao</keyname><forenames>Feifei</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaobo</forenames></author><author><keyname>Yu</keyname><forenames>Chunhua</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author></authors><title>Energy-Efficient Wireless Powered Secure Transmission with Cooperative
  Jamming for Public Transportation</title><categories>cs.CR eess.SP</categories><comments>13 pages, 6 figures, use algorithm.sty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, wireless power transfer and cooperative jamming (CJ) are
combined to enhance physical security in public transportation networks. First,
a new secure system model with both fixed and mobile jammers is proposed to
guarantee secrecy in the worst-case scenario. All jammers are endowed with
energy harvesting (EH) capability. Following this, two CJ based schemes, namely
B-CJ-SRM and B-CJ-TPM, are proposed, where SRM and TPM are short for secrecy
rate maximization and transmit power minimization, respectively. They
respectively maximize the secrecy rate (SR) with transmit power constraint and
minimize the transmit power of the BS with SR constraint, by optimizing
beamforming vector and artificial noise covariance matrix. To further reduce
the complexity of our proposed optimal schemes, their low-complexity (LC)
versions, called LC-B-CJ-SRM and LC-B-CJ-TPM are developed. Simulation results
show that our proposed schemes, B-CJ-SRM and B-CJ-TPM, achieve significant SR
performance improvement over existing zero-forcing and QoSD methods.
Additionally, the SR performance of the proposed LC schemes are close to those
of their original versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00744</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00744</id><created>2018-05-02</created><authors><author><keyname>Dervi&#x161;kadi&#x107;</keyname><forenames>Asja</forenames></author><author><keyname>Zuo</keyname><forenames>Yihui</forenames></author><author><keyname>Frigo</keyname><forenames>Guglielmo</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Under Frequency Load Shedding based on PMU Estimates of Frequency and
  ROCOF</title><categories>eess.SP</categories><comments>Submitted to 2018 IEEE PES Innovative Smart Grid Technologies
  Conference Europe (ISGT-Europe), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes a distributed under-frequency load shedding and load
restoration scheme, that exploits frequency and Rate-of-Change-of-Frequency
(ROCOF) measurements produced by Phasor Measurement Units (PMUs) as detectors
of a large contingency. The paper further discusses the appropriateness of
using the synchrophasor model for estimating ROCOF during fast transients
following a severe generation-load imbalance. The performance of the proposed
relaying scheme is compared with a frequency-only based strategy, by means of a
real-time digital simulator implementing the time-domain full-replica model of
the IEEE 39 bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00778</identifier>
 <datestamp>2018-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00778</id><created>2018-05-01</created><updated>2018-05-09</updated><authors><author><keyname>Zhang</keyname><forenames>Bo</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Hao</keyname><forenames>Jie</forenames></author><author><keyname>Li</keyname><forenames>Xiao-Li</forenames></author><author><keyname>Zhang</keyname><forenames>Meng</forenames></author></authors><title>Adversarial adaptive 1-D convolutional neural networks for bearing fault
  diagnosis under varying working condition</title><categories>eess.SP cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional intelligent fault diagnosis of rolling bearings work well only
under a common assumption that the labeled training data (source domain) and
unlabeled testing data (target domain) are drawn from the same distribution.
However, in many real-world applications, this assumption does not hold,
especially when the working condition varies. In this paper, a new adversarial
adaptive 1-D CNN called A2CNN is proposed to address this problem. A2CNN
consists of four parts, namely, a source feature extractor, a target feature
extractor, a label classifier and a domain discriminator. The layers between
the source and target feature extractor are partially untied during the
training stage to take both training efficiency and domain adaptation into
consideration. Experiments show that A2CNN has strong fault-discriminative and
domain-invariant capacity, and therefore can achieve high accuracy under
different working conditions. We also visualize the learned features and the
networks to explore the reasons behind the high performance of our proposed
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00844</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00844</id><created>2018-05-02</created><authors><author><keyname>Alsamhi</keyname><forenames>S. H.</forenames></author><author><keyname>Ma</keyname><forenames>Ou</forenames></author><author><keyname>Ansari</keyname><forenames>M. Samar</forenames></author><author><keyname>Meng</keyname><forenames>Qingliang</forenames></author></authors><title>Greening Internet of Things for Smart Everythings with A
  Green-Environment Life: A Survey and Future Prospects</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tremendous technology development in the field of Internet of Things (IoT)
has changed the way we work and live. Although the numerous advantages of IoT
are enriching our society, it should be reminded that the IoT also consumes
energy, embraces toxic pollution and E-waste. These place new stress on the
environments and smart world. In order to increase the benefits and reduce the
harm of IoT, there is an increasing desire to move toward green IoT. Green IoT
is seen as the future of IoT that is environmentally friendly. To achieve that,
it is necessary to put a lot of measures to reduce carbon footprint, conserve
fewer resources, and promote efficient techniques for energy usage. It is the
reason for moving towards green IoT, where the machines, communications,
sensors, clouds, and internet are alongside energy efficiency and reducing
carbon emission. This paper presents a thorough survey of the current on-going
research work and potential technologies of green IoT with an intention to
provide some clues for future green IoT research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.00889</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.00889</id><created>2018-05-02</created><updated>2018-05-18</updated><authors><author><keyname>Bello</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Silva</keyname><forenames>Claudio</forenames></author><author><keyname>Nov</keyname><forenames>Oded</forenames></author><author><keyname>DuBois</keyname><forenames>R. Luke</forenames></author><author><keyname>Arora</keyname><forenames>Anish</forenames></author><author><keyname>Salamon</keyname><forenames>Justin</forenames></author><author><keyname>Mydlarz</keyname><forenames>Charles</forenames></author><author><keyname>Doraiswamy</keyname><forenames>Harish</forenames></author></authors><title>SONYC: A System for the Monitoring, Analysis and Mitigation of Urban
  Noise Pollution</title><categories>cs.SD cs.CY cs.HC eess.AS</categories><comments>Accepted May 2018, Communications of the ACM. This is the author's
  version of the work. It is posted here for your personal use. Not for
  redistribution. The definitive Version of Record will be published in
  Communications of the ACM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the Sounds of New York City (SONYC) project, a smart cities
initiative focused on developing a cyber-physical system for the monitoring,
analysis and mitigation of urban noise pollution. Noise pollution is one of the
topmost quality of life issues for urban residents in the U.S. with proven
effects on health, education, the economy, and the environment. Yet, most
cities lack the resources to continuously monitor noise and understand the
contribution of individual sources, the tools to analyze patterns of noise
pollution at city-scale, and the means to empower city agencies to take
effective, data-driven action for noise mitigation. The SONYC project advances
novel technological and socio-technical solutions that help address these
needs.
  SONYC includes a distributed network of both sensors and people for
large-scale noise monitoring. The sensors use low-cost, low-power technology,
and cutting-edge machine listening techniques, to produce calibrated acoustic
measurements and recognize individual sound sources in real time. Citizen
science methods are used to help urban residents connect to city agencies and
each other, understand their noise footprint, and facilitate reporting and
self-regulation. Crucially, SONYC utilizes big data solutions to analyze,
retrieve and visualize information from sensors and citizens, creating a
comprehensive acoustic model of the city that can be used to identify
significant patterns of noise pollution. These data can be used to drive the
strategic application of noise code enforcement by city agencies to optimize
the reduction of noise pollution. The entire system, integrating cyber,
physical and social infrastructure, forms a closed loop of continuous sensing,
analysis and actuation on the environment.
  SONYC provides a blueprint for the mitigation of noise pollution that can
potentially be applied to other cities in the US and abroad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01048</identifier>
 <datestamp>2018-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01048</id><created>2018-05-02</created><authors><author><keyname>Chatterjee</keyname><forenames>Baibhab</forenames></author><author><keyname>Das</keyname><forenames>Debayan</forenames></author><author><keyname>Sen</keyname><forenames>Shreyas</forenames></author></authors><title>RF-PUF: IoT Security Enhancement through Authentication of Wireless
  Nodes using In-situ Machine Learning</title><categories>cs.CR cs.AI cs.NE eess.SP</categories><comments>Presented in Hardware Oriented Security and Trust (HOST), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical unclonable functions (PUF) in silicon exploit die-to-die
manufacturing variations during fabrication for uniquely identifying each die.
Since it is practically a hard problem to recreate exact silicon features
across dies, a PUFbased authentication system is robust, secure and
cost-effective, as long as bias removal and error correction are taken into
account. In this work, we utilize the effects of inherent process variation on
analog and radio-frequency (RF) properties of multiple wireless transmitters
(Tx) in a sensor network, and detect the features at the receiver (Rx) using a
deep neural network based framework. The proposed mechanism/framework, called
RF-PUF, harnesses already existing RF communication hardware and does not
require any additional PUF-generation circuitry in the Tx for practical
implementation. Simulation results indicate that the RF-PUF framework can
distinguish up to 10000 transmitters (with standard foundry defined variations
for a 65 nm process, leading to non-idealities such as LO offset and I-Q
imbalance) under varying channel conditions, with a probability of false
detection &lt; 10e-3
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01111</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01111</id><created>2018-05-03</created><authors><author><keyname>Du</keyname><forenames>Zhe</forenames></author><author><keyname>Ozay</keyname><forenames>Necmiye</forenames></author><author><keyname>Balzano</keyname><forenames>Laura</forenames></author></authors><title>A Robust Algorithm for Online Switched System Identification</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of online identification of Switched
AutoRegressive eXogenous (SARX) systems, where the goal is to estimate the
parameters of each subsystem and identify the switching sequence as data are
obtained in a streaming fashion. Previous works in this area are sensitive to
initialization and lack theoretical guarantees. We overcome these drawbacks
with our two-step algorithm: (i) every time we receive new data, we first
assign this data to one candidate subsystem based on a novel robust criterion
that incorporates both the residual error and an upper bound of subsystem
estimation error, and (ii) we use a randomized algorithm to update the
parameter estimate of chosen candidate. We provide a theoretical guarantee on
the local convergence of our algorithm. Though our theory only guarantees
convergence with a good initialization, simulation results show that even with
random initialization, our algorithm still has excellent performance. Finally,
we show, through simulations, that our algorithm outperforms existing methods
and exhibits robust performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01122</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01122</id><created>2018-05-03</created><authors><author><keyname>Gowse</keyname><forenames>Venkadessan Ramiya</forenames></author><author><keyname>Palanivel</keyname><forenames>Balan</forenames></author><author><keyname>Sivaprakasam</keyname><forenames>Sivaraman</forenames></author></authors><title>Co-existence of synchronization and anti-synchronization in Generalized
  Lorenz System with application to secure communications</title><categories>eess.SP nlin.CD</categories><comments>This article contains 25 pages with 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synchronization and anti- Synchronization between two Generalized Lorenz
Systems coupled in a master slave configuration is investigated. Coupling
between the master and slave is enabled through a non-linear control mechanism.
Synchronization between the state variables of master and slave is achieved by
appropriate choice of parameters. When one of the control parameter is varied,
a continuous change-over from synchronization to anti-synchronization is
observed. Anti-synchronization between master and slave is achieved for two of
the state variables while the third state variable exhibits synchronization. A
study of encoding and decoding of messages in this system is carried out.
Messages of distinct frequencies are encoded at each of the state variables of
master. These messages are decoded and recovered at slave for both states of
synchronization viz synchronized and anti-synchronized states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01125</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01125</id><created>2018-05-03</created><updated>2019-05-20</updated><authors><author><keyname>G&#xf6;ken</keyname><forenames>&#xc7;a&#x11f;r&#x131;</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Alptekin</forenames></author><author><keyname>Dizdar</keyname><forenames>Onur</forenames></author></authors><title>Evaluation of 5G New Radio Non-orthogonal Multiple Access Methods for
  Military Applications</title><categories>eess.SP</categories><comments>6 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) is an enabling technique to support
massive connectivity and utilize the radio resources more efficiently. A number
of novel NOMA schemes have been proposed for 5G New Radio (NR) standards. In
this study, we evaluate various 5G NOMA methods for different military
communications scenarios. First, we provide the description of basic principles
in each evaluated scheme, then we investigate and compare their performances
under different system parameters such as spectral efficiency, overload factor
and antenna numbers in various channel models. Finally, we provide the
discussions and insights on the suitability of the evaluated schemes for the
considered military scenarios based on simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01143</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01143</id><created>2018-05-03</created><authors><author><keyname>Boluki</keyname><forenames>Shahin</forenames></author><author><keyname>Qian</keyname><forenames>Xiaoning</forenames></author><author><keyname>Dougherty</keyname><forenames>Edward R.</forenames></author></authors><title>Experimental Design via Generalized Mean Objective Cost of Uncertainty</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mean objective cost of uncertainty (MOCU) quantifies the performance cost
of using an operator that is optimal across an uncertainty class of systems as
opposed to using an operator that is optimal for a particular system.
MOCU-based experimental design selects an experiment to maximally reduce MOCU,
thereby gaining the greatest reduction of uncertainty impacting the operational
objective. The original formulation applied to finding optimal system
operators, where optimality is with respect to a cost function, such as
mean-square error; and the prior distribution governing the uncertainty class
relates directly to the underlying physical system. Here we provide a
generalized MOCU and the corresponding experimental design. We then demonstrate
how this new formulation includes as special cases MOCU-based experimental
design methods developed for materials science and genomic networks when there
is experimental error. Most importantly, we show that the classical Knowledge
Gradient and Efficient Global Optimization experimental design procedures are
actually implementations of MOCU-based experimental design under their modeling
assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01156</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01156</id><created>2018-05-03</created><authors><author><keyname>Vestman</keyname><forenames>Ville</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author></authors><title>Supervector Compression Strategies to Speed up I-Vector System
  Development</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>To appear in Speaker Odyssey 2018: The Speaker and Language
  Recognition Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The front-end factor analysis (FEFA), an extension of principal component
analysis (PPCA) tailored to be used with Gaussian mixture models (GMMs), is
currently the prevalent approach to extract compact utterance-level features
(i-vectors) for automatic speaker verification (ASV) systems. Little research
has been conducted comparing FEFA to the conventional PPCA applied to maximum a
posteriori (MAP) adapted GMM supervectors. We study several alternative
methods, including PPCA, factor analysis (FA), and two supervised approaches,
supervised PPCA (SPPCA) and the recently proposed probabilistic partial least
squares (PPLS), to compress MAP-adapted GMM supervectors. The resulting
i-vectors are used in ASV tasks with a probabilistic linear discriminant
analysis (PLDA) back-end. We experiment on two different datasets, on the
telephone condition of NIST SRE 2010 and on the recent VoxCeleb corpus
collected from YouTube videos containing celebrity interviews recorded in
various acoustical and technical conditions. The results suggest that, in terms
of ASV accuracy, the supervector compression approaches are on a par with FEFA.
The supervised approaches did not result in improved performance. In comparison
to FEFA, we obtained more than hundred-fold (100x) speedups in the total
variability model (TVM) training using the PPCA and FA supervector compression
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01198</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01198</id><created>2018-05-03</created><authors><author><keyname>Aubreville</keyname><forenames>Marc</forenames></author><author><keyname>Ehrensperger</keyname><forenames>Kai</forenames></author><author><keyname>Rosenkranz</keyname><forenames>Tobias</forenames></author><author><keyname>Graf</keyname><forenames>Benjamin</forenames></author><author><keyname>Puder</keyname><forenames>Henning</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Deep Denoising for Hearing Aid Applications</title><categories>eess.AS cs.SD</categories><comments>submitted to IWAENC 2018</comments><journal-ref>2018 16th International Workshop on Acoustic Signal Enhancement
  (IWAENC), pp. 361-365</journal-ref><doi>10.1109/IWAENC.2018.8521369</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reduction of unwanted environmental noises is an important feature of today's
hearing aids (HA), which is why noise reduction is nowadays included in almost
every commercially available device. The majority of these algorithms, however,
is restricted to the reduction of stationary noises. In this work, we propose a
denoising approach based on a three hidden layer fully connected deep learning
network that aims to predict a Wiener filtering gain with an asymmetric input
context, enabling real-time applications with high constraints on signal delay.
The approach is employing a hearing instrument-grade filter bank and complies
with typical hearing aid demands, such as low latency and on-line processing.
It can further be well integrated with other algorithms in an existing HA
signal processing chain. We can show on a database of real world noise signals
that our algorithm is able to outperform a state of the art baseline approach,
both using objective metrics and subject tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01201</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01201</id><created>2018-05-03</created><authors><author><keyname>Fourer</keyname><forenames>Dominique</forenames></author><author><keyname>Peeters</keyname><forenames>Geoffroy</forenames></author></authors><title>Single-Channel Blind Source Separation for Singing Voice Detection: A
  Comparative Study</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose a novel unsupervised singing voice detection method which use
single-channel Blind Audio Source Separation (BASS) algorithm as a preliminary
step. To reach this goal, we investigate three promising BASS approaches which
operate through a morphological filtering of the analyzed mixture spectrogram.
The contributions of this paper are manyfold. First, the investigated BASS
methods are reworded with the same formalism and we investigate their
respective hyperparameters by numerical simulations. Second, we propose an
extension of the KAM method for which we propose a novel training algorithm
used to compute a source-specific kernel from a given isolated source signal.
Second, the BASS methods are compared together in terms of source separation
accuracy and in terms of singing voice detection accuracy when they are used in
our new singing voice detection framework. Finally, we do an exhaustive singing
voice detection evaluation for which we compare both supervised and
unsupervised singing voice detection methods. Our comparison explores different
combination of the proposed BASS methods with new features such as the new
proposed KAM features and the scattering transform through a machine learning
framework and also considers convolutional neural networks methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01222</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01222</id><created>2018-05-03</created><authors><author><keyname>Triantafyllopoulos</keyname><forenames>Andreas</forenames></author><author><keyname>Sagha</keyname><forenames>Hesam</forenames></author><author><keyname>Eyben</keyname><forenames>Florian</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>audEERING's approach to the One-Minute-Gradual Emotion Challenge</title><categories>cs.CV cs.LG cs.SD eess.AS stat.ML</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes audEERING's submissions as well as additional
evaluations for the One-Minute-Gradual (OMG) emotion recognition challenge. We
provide the results for audio and video processing on subject (in)dependent
evaluations. On the provided Development set, we achieved 0.343 Concordance
Correlation Coefficient (CCC) for arousal (from audio) and .401 for valence
(from video).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01236</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01236</id><created>2018-05-03</created><authors><author><keyname>Fliedner</keyname><forenames>Niels Hendrik</forenames></author><author><keyname>Block</keyname><forenames>Dimitri</forenames></author><author><keyname>Meier</keyname><forenames>Uwe</forenames></author></authors><title>A Software-Defined Channel Sounder for Industrial Environments with Fast
  Time Variance</title><categories>eess.SP</categories><comments>Submitted to the 15th International Symposium on Wireless
  Communication Systems (ISWCS 2018)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Novel industrial wireless applications require wideband, real-time channel
characterization due to complex multipath propagation. Rapid machine motion
leads to fast time variance of the channel's reflective behavior, which must be
captured for radio channel characterization. Additionally, inhomogeneous radio
channels demand highly flexible measurements. Existing approaches for radio
channel measurements either lack flexibility or wide-band, real-time
performance with fast time variance. In this paper, we propose a correlative
channel sounding approach utilizing a software-defined architecture. The
approach enables real-time, wide-band measurements with fast time variance
immune to active interference. The desired performance is validated with a
demanding industrial application example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01259</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01259</id><created>2018-05-03</created><authors><author><keyname>Song</keyname><forenames>Siyang</forenames></author><author><keyname>Zhang</keyname><forenames>Shuimei</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Shen</keyname><forenames>Linlin</forenames></author><author><keyname>Valstar</keyname><forenames>Michel</forenames></author></authors><title>Noise Invariant Frame Selection: A Simple Method to Address the
  Background Noise Problem for Text-independent Speaker Verification</title><categories>cs.SD cs.CV eess.AS</categories><comments>Paper accepted in IJCNN 2018</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of speaker-related systems usually degrades heavily in
practical applications largely due to the presence of background noise. To
improve the robustness of such systems in unknown noisy environments, this
paper proposes a simple pre-processing method called Noise Invariant Frame
Selection (NIFS). Based on several noisy constraints, it selects noise
invariant frames from utterances to represent speakers. Experiments conducted
on the TIMIT database showed that the NIFS can significantly improve the
performance of Vector Quantization (VQ), Gaussian Mixture Model-Universal
Background Model (GMM-UBM) and i-vector-based speaker verification systems in
different unknown noisy environments with different SNRs, in comparison to
their baselines. Meanwhile, the proposed NIFS-based speaker verification
systems achieves similar performance when we change the constraints
(hyper-parameters) or features, which indicates that it is robust and easy to
reproduce. Since NIFS is designed as a general algorithm, it could be further
applied to other similar tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01266</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01266</id><created>2018-05-03</created><authors><author><keyname>G&#xf6;zc&#xfc;</keyname><forenames>Baran</forenames></author><author><keyname>Mahabadi</keyname><forenames>Rabeeh Karimi</forenames></author><author><keyname>Li</keyname><forenames>Yen-Huan</forenames></author><author><keyname>Il&#x131;cak</keyname><forenames>Efe</forenames></author><author><keyname>&#xc7;ukur</keyname><forenames>Tolga</forenames></author><author><keyname>Scarlett</keyname><forenames>Jonathan</forenames></author><author><keyname>Cevher</keyname><forenames>Volkan</forenames></author></authors><title>Learning-Based Compressive MRI</title><categories>eess.IV cs.CV</categories><comments>13 pages, 6 figures. IEEE TMI (Transactions of Medical Imaging)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the area of magnetic resonance imaging (MRI), an extensive range of
non-linear reconstruction algorithms have been proposed that can be used with
general Fourier subsampling patterns. However, the design of these subsampling
patterns has typically been considered in isolation from the reconstruction
rule and the anatomy under consideration. In this paper, we propose a
learning-based framework for optimizing MRI subsampling patterns for a specific
reconstruction rule and anatomy, considering both the noiseless and noisy
settings. Our learning algorithm has access to a representative set of training
signals, and searches for a sampling pattern that performs well on average for
the signals in this set. We present a novel parameter-free greedy mask
selection method, and show it to be effective for a variety of reconstruction
rules and performance metrics. Moreover we also support our numerical findings
by providing a rigorous justification of our framework via statistical learning
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01297</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01297</id><created>2018-05-02</created><authors><author><keyname>Mann</keyname><forenames>Richard</forenames></author><author><keyname>Mann</keyname><forenames>William</forenames></author></authors><title>Generation of Infra sound to replicate a wind turbine</title><categories>cs.SD eess.AS physics.med-ph</categories><comments>Keywords: Infra sound, wind turbines, acoustics, sound measurement,
  sound generation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have successfully produced infrasound, as a duplicate of that produced by
Industrial Wind Turbines. We have been able to produce this Infrasound inside a
research chamber, capable of accommodating a human test subject. It is our
vision that this project will permit others, with appropriate medical training
and ethical oversight, to research human thresholds and the effects of this
infrasound on humans. Our role has focused on producing the tools, systems, and
hardware required, to permit this research to go forward. This paper describes
the evolution of our project from the original vision, through the construction
of proof of concept prototypes, a series of improved models and their
associated accessories /operating systems, to the final test chamber as it
stands now ready to deploy. Also included are the mathematical and
computational data supporting our claim that infrasound conditions inside the
chamber can be made to duplicate those from actual Industrial wind turbines at
approved setback distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01317</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01317</id><created>2018-05-03</created><updated>2018-05-04</updated><authors><author><keyname>Ma</keyname><forenames>Yunlong</forenames></author><author><keyname>Wang</keyname><forenames>Chunyan</forenames></author></authors><title>SdcNet: A Computation-Efficient CNN for Object Recognition</title><categories>eess.IV cs.CV</categories><comments>5 pages,3 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting features from a huge amount of data for object recognition is a
challenging task. Convolution neural network can be used to meet the challenge,
but it often requires a large number of computation resources. In this paper, a
computation-efficient convolutional module, named SdcBlock, is proposed and
based on it, the convolution network SdcNet is introduced for object
recognition tasks. In the proposed module, optimized successive depthwise
convolutions supported by appropriate data management is applied in order to
generate vectors containing high density and more varieties of feature
information. The hyperparameters can be easily adjusted to suit varieties of
tasks under different computation restrictions without significantly
jeopardizing the performance. The experiments have shown that SdcNet achieved
an error rate of 5.60% in CIFAR-10 with only 55M Flops and also reduced further
the error rate to 5.24% using a moderate volume of 103M Flops. The expected
computation efficiency of the SdcNet has been confirmed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01344</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01344</id><created>2018-05-03</created><authors><author><keyname>Wang</keyname><forenames>Shuai</forenames></author><author><keyname>Huang</keyname><forenames>Zili</forenames></author><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author></authors><title>Deep Discriminant Analysis for i-vector Based Robust Speaker Recognition</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear Discriminant Analysis (LDA) has been used as a standard
post-processing procedure in many state-of-the-art speaker recognition tasks.
Through maximizing the inter-speaker difference and minimizing the
intra-speaker variation, LDA projects i-vectors to a lower-dimensional and more
discriminative sub-space. In this paper, we propose a neural network based
compensation scheme(termed as deep discriminant analysis, DDA) for i-vector
based speaker recognition, which shares the spirit with LDA. Optimized against
softmax loss and center loss at the same time, the proposed method learns a
more compact and discriminative embedding space. Compared with the Gaussian
distribution assumption of data and the learnt linear projection in LDA, the
proposed method doesn't pose any assumptions on data and can learn a non-linear
projection function. Experiments are carried out on a short-duration
text-independent dataset based on the SRE Corpus, noticeable performance
improvement can be observed against the normal LDA or PLDA methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01355</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01355</id><created>2018-05-01</created><updated>2018-05-05</updated><authors><author><keyname>Tatwawadi</keyname><forenames>Kedar Shriram</forenames></author><author><keyname>Jiao</keyname><forenames>Jiantao</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Minimax redundancy for Markov chains with large state space</title><categories>cs.IT eess.SP math.IT</categories><comments>22 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For any Markov source, there exist universal codes whose normalized
codelength approaches the Shannon limit asymptotically as the number of samples
goes to infinity. This paper investigates how fast the gap between the
normalized codelength of the &quot;best&quot; universal compressor and the Shannon limit
(i.e. the compression redundancy) vanishes non-asymptotically in terms of the
alphabet size and mixing time of the Markov source. We show that, for Markov
sources whose relaxation time is at least $1 + \frac{(2+c)}{\sqrt{k}}$, where
$k$ is the state space size (and $c&gt;0$ is a constant), the phase transition for
the number of samples required to achieve vanishing compression redundancy is
precisely $\Theta(k^2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01357</identifier>
 <datestamp>2018-05-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01357</id><created>2018-05-02</created><authors><author><keyname>Liu</keyname><forenames>Bin</forenames></author><author><keyname>Nie</keyname><forenames>Shuai</forenames></author><author><keyname>Zhang</keyname><forenames>Yaping</forenames></author><author><keyname>Ke</keyname><forenames>Dengfeng</forenames></author><author><keyname>Liang</keyname><forenames>Shan</forenames></author><author><keyname>Liu1</keyname><forenames>Wenju</forenames></author></authors><title>Boosting Noise Robustness of Acoustic Model via Deep Adversarial
  Training</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In realistic environments, speech is usually interfered by various noise and
reverberation, which dramatically degrades the performance of automatic speech
recognition (ASR) systems. To alleviate this issue, the commonest way is to use
a well-designed speech enhancement approach as the front-end of ASR. However,
more complex pipelines, more computations and even higher hardware costs
(microphone array) are additionally consumed for this kind of methods. In
addition, speech enhancement would result in speech distortions and mismatches
to training. In this paper, we propose an adversarial training method to
directly boost noise robustness of acoustic model. Specifically, a jointly
compositional scheme of generative adversarial net (GAN) and neural
network-based acoustic model (AM) is used in the training phase. GAN is used to
generate clean feature representations from noisy features by the guidance of a
discriminator that tries to distinguish between the true clean signals and
generated signals. The joint optimization of generator, discriminator and AM
concentrates the strengths of both GAN and AM for speech recognition.
Systematic experiments on CHiME-4 show that the proposed method significantly
improves the noise robustness of AM and achieves the average relative error
rate reduction of 23.38% and 11.54% on the development and test set,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01364</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01364</id><created>2018-05-02</created><authors><author><keyname>Kozarcanin</keyname><forenames>Smail</forenames></author><author><keyname>Liu</keyname><forenames>Hailiang</forenames></author><author><keyname>Andresen</keyname><forenames>Gorm Bruun</forenames></author></authors><title>Climate change impacts on large-scale electricity system design
  decisions for the 21st Century</title><categories>eess.SP</categories><journal-ref>Joule 3(4) (2019) 992-1005</journal-ref><doi>10.1016/j.joule.2019.02.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efforts to reduce climate change, but also falling prices and significant
technology developments currently drive an increased weather-dependent
electricity production from renewable electricity sources. In light of the
changing climate, it is highly relevant to investigate the extent of weather
changes that directly impacts the best system design decisions for these
weather-dependent technologies. Here, we use three IPCC representative CO2
concentrations pathways for the period 2006--2100 with six high-resolution
climate experiments for the European domain. Climate elements are used to
calculate bias adjusted 3-hourly time series of wind and solar generation, and
temperature corrected demand time series for 30 European countries using
state-of-the-art methodology. Weather-driven electricity system analysis
methodology is then applied to compare four key metrics of highly renewable
electricity systems. We find that climate change does not have a discernible
impact on the key metrics of the combined electricity system dynamics, and
conclude that the effect on important system design parameters can likely be
ignored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01374</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01374</id><created>2018-05-03</created><updated>2018-06-18</updated><authors><author><keyname>Chatterjee</keyname><forenames>Baibhab</forenames></author><author><keyname>Das</keyname><forenames>Debayan</forenames></author><author><keyname>Maity</keyname><forenames>Shovan</forenames></author><author><keyname>Sen</keyname><forenames>Shreyas</forenames></author></authors><title>RF-PUF: Enhancing IoT Security through Authentication of Wireless Nodes
  using In-situ Machine Learning</title><categories>cs.CR cs.AI cs.NE eess.SP</categories><comments>Accepted: in the IEEE Internet of Things Journal (JIoT), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional authentication in radio-frequency (RF) systems enable secure data
communication within a network through techniques such as digital signatures
and hash-based message authentication codes (HMAC), which suffer from key
recovery attacks. State-of-the-art IoT networks such as Nest also use Open
Authentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery
forgery (CSRF), which shows that these techniques may not prevent an adversary
from copying or modeling the secret IDs or encryption keys using invasive, side
channel, learning or software attacks. Physical unclonable functions (PUF), on
the other hand, can exploit manufacturing process variations to uniquely
identify silicon chips which makes a PUF-based system extremely robust and
secure at low cost, as it is practically impossible to replicate the same
silicon characteristics across dies. Taking inspiration from human
communication, which utilizes inherent variations in the voice signatures to
identify a certain speaker, we present RF- PUF: a deep neural network-based
framework that allows real-time authentication of wireless nodes, using the
effects of inherent process variation on RF properties of the wireless
transmitters (Tx), detected through in-situ machine learning at the receiver
(Rx) end. The proposed method utilizes the already-existing asymmetric RF
communication framework and does not require any additional circuitry for PUF
generation or feature extraction. Simulation results involving the process
variations in a standard 65 nm technology node, and features such as LO offset
and I-Q imbalance detected with a neural network having 50 neurons in the
hidden layer indicate that the framework can distinguish up to 4800
transmitters with an accuracy of 99.9% (~ 99% for 10,000 transmitters) under
varying channel conditions, and without the need for traditional preambles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01379</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01379</id><created>2018-05-03</created><authors><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Henry</keyname><forenames>Manus</forenames></author></authors><title>Complex Signal Processing for Coriolis Mass Flow Metering in Two-Phase
  Flow</title><categories>eess.SP</categories><doi>10.1016/j.flowmeasinst.2018.10.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new signal processing method based on Complex Bandpass
Filtering (CBF) applied to the Coriolis Mass Flowmeter (CMF). CBF can be
utilized to suppress the negative frequency component of each sensor signal to
produce the corresponding analytic form with reduced tracking delay. Further
processing of the analytic form yields the amplitude, frequency, phase and
phase difference of the sensor signals. In comparison with previously published
methods, CBF offers short delay, high noise suppression, high accuracy and low
computational cost. A reduced delay is useful in CMF signal processing
especially for maintaining flowtube oscillation in two/multi-phase flow
conditions. The central frequency and the frequency range of the CBF method are
selectable so that they can be customized for different flowtube designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01449</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01449</id><created>2018-05-03</created><updated>2018-08-23</updated><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Shin</keyname><forenames>Wonjae</forenames></author><author><keyname>Vaezi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Securing Downlink Non-Orthogonal Multiple Access Systems by Trusted
  Relays</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>To appear in IEEE Globecom 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A downlink single-input single-output non-orthogonal multiple access system
is considered in which a base station (BS) is communicating with two legitimate
users in the presence of an external eavesdropper. A group of trusted
cooperative half-duplex relay nodes, powered by the BS, is employed to assist
the BS's transmission. The goal is to design relaying schemes such that the
legitimate users' secrecy rate region is maximized subject to a total power
constraint on the BS and the relays' transmissions. Three relaying schemes are
investigated: cooperative jamming, decode-and-forward, and amplify-and-forward.
Depending on the scheme, secure beamforming signals are carefully designed for
the relay nodes that either diminish the eavesdropper's rate without affecting
that of the legitimate users, or increase the legitimate users' rates without
increasing that of the eavesdropper. The results show that there is no relaying
scheme that fits all conditions; the best relaying scheme depends on the system
parameters, namely, the relays' and eavesdropper's distances from the BS, and
the number of relays. They also show that the relatively simple cooperative
jamming scheme outperforms other schemes when the relays are far from the BS
and/or close to the eavesdropper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01452</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01452</id><created>2018-05-03</created><updated>2019-12-13</updated><authors><author><keyname>Kollias</keyname><forenames>Dimitrios</forenames></author><author><keyname>Zafeiriou</keyname><forenames>Stefanos</forenames></author></authors><title>A Multi-component CNN-RNN Approach for Dimensional Emotion Recognition
  in-the-wild</title><categories>cs.CV cs.AI cs.HC eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents our approach to the One-Minute Gradual-Emotion
Recognition (OMG-Emotion) Challenge, focusing on dimensional emotion
recognition through visual analysis of the provided emotion videos. The
approach is based on a Convolutional and Recurrent (CNN-RNN) deep neural
architecture we have developed for the relevant large AffWild Emotion Database.
We extended and adapted this architecture, by letting a combination of multiple
features generated in the CNN component be explored by RNN subnets. Our target
has been to obtain best performance on the OMG-Emotion visual validation data
set, while learning the respective visual training data set. Extended
experimentation has led to best architectures for the estimation of the values
of the valence and arousal emotion dimensions over these data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01503</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01503</id><created>2018-05-03</created><authors><author><keyname>Karthik</keyname><forenames>Anantha K.</forenames></author><author><keyname>Blum</keyname><forenames>Rick S.</forenames></author></authors><title>Improved Detection Performance of Passive Radars Exploiting Known
  Communication Signal Form</title><categories>eess.SP</categories><comments>10 pages, 12 figures</comments><doi>10.1109/LSP.2018.2870341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of target detection in passive
multiple-input-multiple-output (MIMO) radar networks. A generalized likelihood
ratio test is derived, assuming prior knowledge of the signal format used in
the non-cooperative transmit stations. We consider scenarios in which the
unknown transmitted signal uses either a linear digital modulation scheme or
the Orthogonal Frequency-Division Multiplexing (OFDM) modulation scheme. These
digital modulation schemes are used in popular standards including
Code-Division Multiple Access (CDMA), Digital Video Broadcasting-Terrestrial
(DVB-T) and Long Term Evaluation (LTE). The performance of the generalized
likelihood ratio test in the known signal format case is often significantly
more favorable when compared to the case that does not exploit this
information. Further, the performance improves with increasing number of
samples per symbol and, for a sufficiently large number of samples per symbol,
the performance closely approximates that of an active radar with a known
transmitted signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01511</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01511</id><created>2018-05-03</created><updated>2019-05-22</updated><authors><author><keyname>Liu</keyname><forenames>Yongjun</forenames></author><author><keyname>Liao</keyname><forenames>Guisheng</forenames></author><author><keyname>Yang</keyname><forenames>Zhiwei</forenames></author></authors><title>Robust OFDM integrated radar and communications waveform design based on
  information theory</title><categories>eess.SP</categories><comments>30 pages. 10 figures</comments><journal-ref>Signal Processing 2019</journal-ref><doi>10.1016/j.sigpro.2019.05.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An integrated radar and communications system (IRCS) where a monostatic radar
transceiver is employed for target classification while simultaneously used as
a communications transmitter is considered. The radar combined
propagation-target response (joint response of the radar propagation channel
and target) and communications channel response are generally frequency
selective but the corresponding frequency response functions are not exactly
known. In particular, these frequency response functions are only known to lie
in an uncertainty class. To ensure the IRCS simultaneously provides acceptable
target classification performance and communications rate, a robust orthogonal
frequency division multiplexing (OFDM) integrated radar and communications
waveform (IRCW) design method is proposed. The approach finds a waveform that
simultaneously provides a sufficiently large weighted sum of the communications
data information rate (DIR) and the conditional mutual information (MI) between
the observed signal and the radar target over the entire uncertainty class.
First, the conditional MI and DIR based on the integrated OFDM radar and
communications waveform are derived. Then, a robust OFDM IRCW optimization
problem based on the minimax design philosophy is developed such that
closed-form solution is derived. Finally, several numerical results are
presented to demonstrate the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01533</identifier>
 <datestamp>2018-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01533</id><created>2018-05-03</created><authors><author><keyname>Chen</keyname><forenames>Yicheng</forenames></author><author><keyname>Blum</keyname><forenames>Rick S.</forenames></author></authors><title>On the Impact of Unknown Signals in Passive Radar with Direct Path and
  Reflected Path Observations</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the closed form Cramer-Rao bound (CRB) expressions for joint
estimation of time delay and Doppler shift with unknown signals with possibly
known structure. The results are especially useful for passive radar where
direct path and reflected path signals are present. Time delay and Doppler
shift estimation is an important fundamental tool in signal processing which
has received extensive study for cases with known transmitted signals, but
little study for unknown transmitted signals. The presented results generalize
previous results for known transmitted signals and show how many looks from the
direct path and the reflected path we need to derive an accurate joint
estimation of time delay and Doppler shift. After analysis under a simple
common signal-to-clutter-plus-noise ratio (SCNR) model with separated direct
and reflected path signals, white clutter-plus-noise and line of sight
propagation, extensions to cases with different direct and reflected path
SCNRs, correlated clutter-plus-noise, nonseparated direct and reflected path
signals and multipath propagation are discussed to support the utility of the
CRB with unknown signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01534</identifier>
 <datestamp>2018-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01534</id><created>2018-05-03</created><authors><author><keyname>Huo</keyname><forenames>Yiming</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>Lu</keyname><forenames>Tao</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Yuen</keyname><forenames>Marvin</forenames></author></authors><title>Distributed and Multi-layer UAV Network for the Next-generation Wireless
  Communication</title><categories>eess.SP</categories><comments>13 pages, 5 figures, 1 table. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) for wireless communications has rapidly grown
into a research hotspot as the mass production of high-performance, low-cost,
intelligent UAVs become more practical and feasible. In the meantime, fifth
generation (5G) wireless communications is being standardized and planned for
deployment globally. During this process, UAVs are gradually being considered
as an important part of 5G and expected to play a critical role in enabling
more functional diversity for 5G communications. In this article, we conduct an
in-depth investigation of mainstream UAV designs and state-of-the-art UAV
enabled wireless communication systems.We propose a hierarchical architecture
of UAVs with multi-layer and distributed features to facilitate a smooth
integration of different mainstream UAVs into the next-generation wireless
communication networks. Furthermore, we unveil the critical comprehensive
design tradeoffs, in light of both communication and aerodynamic principles.
Empirical models and satellite measurement data are used to conduct numerical
analysis of the meteorological impacts of UAV enabled, 5G high bands
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01576</identifier>
 <datestamp>2018-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01576</id><created>2018-05-02</created><authors><author><keyname>Pereira</keyname><forenames>Ingryd</forenames></author><author><keyname>Santos</keyname><forenames>Diego</forenames></author></authors><title>OMG Emotion Challenge - ExCouple Team</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proposed model is only for the audio module. All videos in the OMG
Emotion Dataset are converted to WAV files. The proposed model makes use of
semi-supervised learning for the emotion recognition. A GAN is trained with
unsupervised learning, with another database (IEMOCAP), and part of the GAN
structure (part of the autoencoder) will be used for the audio representation.
The audio spectrogram will be extracted in 1-second windows of 16khz frequency,
and this will serve as input to the model of audio representation trained with
another database in an unsupervised way. This audio representation will serve
as input to a convolutional network and a Dense layer with 'tanh' activation
that performs the prediction of Arousal and Valence values. For joining the
1-second pieces of audio, the median of the predicted values of a given
utterance will be taken.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01692</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01692</id><created>2018-05-04</created><authors><author><keyname>Koutrouvelis</keyname><forenames>Andreas I.</forenames></author><author><keyname>Hendriks</keyname><forenames>Richard C.</forenames></author><author><keyname>Heusdens</keyname><forenames>Richard</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>A Convex Approximation of the Relaxed Binaural Beamforming Optimization
  Problem</title><categories>cs.SD cs.IT eess.AS math.IT</categories><journal-ref>IEEE/ACM Transactions on Audio, Speech and Language Processing,
  27(2), 321-331, 2019</journal-ref><doi>10.1109/TASLP.2018.2878618</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently proposed relaxed binaural beamforming (RBB) optimization problem
provides a flexible trade-off between noise suppression and binaural-cue
preservation of the sound sources in the acoustic scene. It minimizes the
output noise power, under the constraints which guarantee that the target
remains unchanged after processing and the binaural-cue distortions of the
acoustic sources will be less than a user-defined threshold. However, the RBB
problem is a computationally demanding non-convex optimization problem. The
only existing suboptimal method which approximately solves the RBB is a
successive convex optimization (SCO) method which, typically, requires to solve
multiple convex optimization problems per frequency bin, in order to converge.
Convergence is achieved when all constraints of the RBB optimization problem
are satisfied. In this paper, we propose a semi-definite convex relaxation
(SDCR) of the RBB optimization problem. The proposed suboptimal SDCR method
solves a single convex optimization problem per frequency bin, resulting in a
much lower computational complexity than the SCO method. Unlike the SCO method,
the SDCR method does not guarantee user-controlled upper-bounded binaural-cue
distortions. To tackle this problem we also propose a suboptimal hybrid method
which combines the SDCR and SCO methods. Instrumental measures combined with a
listening test show that the SDCR and hybrid methods achieve significantly
lower computational complexity than the SCO method, and in most cases better
trade-off between predicted intelligibility and binaural-cue preservation than
the SCO method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01743</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01743</id><created>2018-05-04</created><authors><author><keyname>Ahmadi</keyname><forenames>Amirmasoud</forenames></author><author><keyname>Behroozi</keyname><forenames>Mahsa</forenames></author><author><keyname>Shalchyan</keyname><forenames>Vahid</forenames></author><author><keyname>Daliri</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Classification of Epileptic EEG Signals by Wavelet based CFC</title><categories>eess.SP q-bio.NC stat.ML</categories><comments>Electroencephalogram; Wavelet Decomposition; Cross Frequency
  Coupling;Quadratic Discriminant Analysis; T-test Feature Selection</comments><journal-ref>Electrical-Electronics &amp; Biomedical Engineering and Computer
  Science in 2018 (EBBT 2018)</journal-ref><doi>10.1109/EBBT.2018.8391471</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalogram, an influential equipment for analyzing humans
activities and recognition of seizure attacks can play a crucial role in
designing accurate systems which can distinguish ictal seizures from regular
brain alertness, since it is the first step towards accomplishing a high
accuracy computer aided diagnosis system (CAD). In this article a novel
approach for classification of ictal signals with wavelet based cross frequency
coupling (CFC) is suggested. After extracting features by wavelet based CFC,
optimal features have been selected by t-test and quadratic discriminant
analysis (QDA) have completed the Classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01759</identifier>
 <datestamp>2018-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01759</id><created>2018-05-04</created><authors><author><keyname>Shi</keyname><forenames>Yilei</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Bamler</keyname><forenames>Richard</forenames></author></authors><title>A fast and accurate basis pursuit denoising algorithm with application
  to super-resolving tomographic SAR</title><categories>eess.IV</categories><comments>11 pages, IEEE Transactions on Geoscience and Remote Sensing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  $L_1$ regularization is used for finding sparse solutions to an
underdetermined linear system. As sparse signals are widely expected in remote
sensing, this type of regularization scheme and its extensions have been widely
employed in many remote sensing problems, such as image fusion, target
detection, image super-resolution, and others and have led to promising
results. However, solving such sparse reconstruction problems is
computationally expensive and has limitations in its practical use. In this
paper, we proposed a novel efficient algorithm for solving the complex-valued
$L_1$ regularized least squares problem. Taking the high-dimensional
tomographic synthetic aperture radar (TomoSAR) as a practical example, we
carried out extensive experiments, both with simulation data and real data, to
demonstrate that the proposed approach can retain the accuracy of second order
methods while dramatically speeding up the processing by one or two orders.
Although we have chosen TomoSAR as the example, the proposed method can be
generally applied to any spectral estimation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01831</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01831</id><created>2018-05-04</created><updated>2019-05-14</updated><authors><author><keyname>Palossi</keyname><forenames>Daniele</forenames></author><author><keyname>Loquercio</keyname><forenames>Antonio</forenames></author><author><keyname>Conti</keyname><forenames>Francesco</forenames></author><author><keyname>Flamand</keyname><forenames>Eric</forenames></author><author><keyname>Scaramuzza</keyname><forenames>Davide</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>A 64mW DNN-based Visual Navigation Engine for Autonomous Nano-Drones</title><categories>cs.RO cs.AI cs.NE eess.SP</categories><comments>15 pages, 13 figures, 5 tables, 2 listings, accepted for publication
  in the IEEE Internet of Things Journal (IEEE IOTJ)</comments><doi>10.1109/JIOT.2019.2917066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully-autonomous miniaturized robots (e.g., drones), with artificial
intelligence (AI) based visual navigation capabilities are extremely
challenging drivers of Internet-of-Things edge intelligence capabilities.
Visual navigation based on AI approaches, such as deep neural networks (DNNs)
are becoming pervasive for standard-size drones, but are considered out of
reach for nanodrones with size of a few cm${}^\mathrm{2}$. In this work, we
present the first (to the best of our knowledge) demonstration of a navigation
engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based
visual navigation. To achieve this goal we developed a complete methodology for
parallel execution of complex DNNs directly on-bard of resource-constrained
milliwatt-scale nodes. Our system is based on GAP8, a novel parallel
ultra-low-power computing platform, and a 27 g commercial, open-source
CrazyFlie 2.0 nano-quadrotor. As part of our general methodology we discuss the
software mapping techniques that enable the state-of-the-art deep convolutional
neural network presented in [1] to be fully executed on-board within a strict 6
fps real-time constraint with no compromise in terms of flight results, while
all processing is done with only 64 mW on average. Our navigation engine is
flexible and can be used to span a wide performance range: at its peak
performance corner it achieves 18 fps while still consuming on average just
3.5% of the power envelope of the deployed nano-aircraft.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01945</identifier>
 <datestamp>2018-12-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01945</id><created>2018-05-04</created><updated>2018-08-08</updated><authors><author><keyname>Kord</keyname><forenames>Ahmed</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios L.</forenames></author><author><keyname>Xiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Alu</keyname><forenames>Andrea</forenames></author></authors><title>Broadband Cyclic-Symmetric Magnet-less Circulators and Theoretical
  Bounds on their Bandwidth</title><categories>eess.SP</categories><comments>Submitted to IEEE TMTT, under review</comments><doi>10.1109/TMTT.2018.2860023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore theoretically and experimentally broadband
spatiotemporally modulated (STM) magnet-less circulators realized by combining
three-port non-reciprocal junctions with three identical bandpass filters. We
develop a rigorous theory for the proposed circuit, which allows to optimize
their design and to derive a global bound on the maximum possible bandwidth
(BW) for cyclic-symmetric magnetless circulators. We verify our theory with
simulations and measurements of a printed circuit board (PCB) prototype based
on a differential wye junction and second-order Chebyshev bandpass filters,
resulting in a measured fractional BW of 13.9% at a center frequency of 1 GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01967</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.01967</id><created>2018-05-04</created><authors><author><keyname>Susuki</keyname><forenames>Yoshihiko</forenames></author><author><keyname>Hamasaki</keyname><forenames>Ryo</forenames></author><author><keyname>Ishigame</keyname><forenames>Atsushi</forenames></author></authors><title>Estimation of Power System Inertia Using Nonlinear Koopman Modes</title><categories>eess.SP cs.SY math.DS math.OC</categories><comments>10 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a new approach to estimating power system inertia directly from
time-series data on power system dynamics. The approach is based on the
so-called Koopman Mode Decomposition (KMD) of such dynamic data, which is a
nonlinear generalization of linear modal decomposition through spectral
analysis of the Koopman operator for nonlinear dynamical systems. The KMD-based
approach is thus applicable to dynamic data that evolve in nonlinear regime of
power system characteristics. Its effectiveness is numerically evaluated with
transient stability simulations of the IEEE New England test system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02043</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02043</id><created>2018-05-05</created><updated>2019-01-12</updated><authors><author><keyname>Kim</keyname><forenames>Jaehun</forenames></author><author><keyname>Won</keyname><forenames>Minz</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author><author><keyname>Liem</keyname><forenames>Cynthia C. S.</forenames></author></authors><title>Transfer Learning of Artist Group Factors to Musical Genre
  Classification</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>The Web Conference 2018</comments><doi>10.1145/3184558.3191823</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The automated recognition of music genres from audio information is a
challenging problem, as genre labels are subjective and noisy. Artist labels
are less subjective and less noisy, while certain artists may relate more
strongly to certain genres. At the same time, at prediction time, it is not
guaranteed that artist labels are available for a given audio segment.
Therefore, in this work, we propose to apply the transfer learning framework,
learning artist-related information which will be used at inference time for
genre classification. We consider different types of artist-related
information, expressed through artist group factors, which will allow for more
efficient learning and stronger robustness to potential label noise.
Furthermore, we investigate how to achieve the highest validation accuracy on
the given FMA dataset, by experimenting with various kinds of transfer methods,
including single-task transfer, multi-task transfer and finally multi-task
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02099</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02099</id><created>2018-05-05</created><updated>2018-05-28</updated><authors><author><keyname>Medhi</keyname><forenames>Biswajit</forenames></author><author><keyname>Hegde</keyname><forenames>Gopalakrishna M.</forenames></author><author><keyname>Reddy</keyname><forenames>Kalidevapura Jagannath</forenames></author><author><keyname>Roy</keyname><forenames>Debasish</forenames></author><author><keyname>Vasu</keyname><forenames>Ram Mohan</forenames></author></authors><title>Time-resolved quantitative visualization of complex flow field emanating
  from an open-ended shock tube by using wavefront measuring camera</title><categories>physics.flu-dyn eess.IV physics.ins-det</categories><comments>12 pages, 7 figures</comments><doi>10.1016/j.optlaseng.2019.06.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative visualization of shock-induced complex flow field emanating from
the open end of a miniaturized hand-driven shock tube (Reddy tube) is
presented. During operation, the planar shock wave of Mach number Mi=1.3 is
discharged through the low-pressure driven-section, kept open to ambient
atmosphere. From the moment of shock discharge, its aftereffects of evolving
flow field are recorded quantitatively for 300us near the exit of the tube by
using our newly developed high resolution (16Mpixel) in-house developed
wavefront measuring camera setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02199</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02199</id><created>2018-05-06</created><updated>2019-01-21</updated><authors><author><keyname>Wang</keyname><forenames>Guanchu</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Jiang</keyname><forenames>Zhimeng</forenames></author><author><keyname>Xu</keyname><forenames>Zhengyuan</forenames></author></authors><title>Asynchronous Multiple Access in Optical Wireless Scattering
  Communication: Achievable Transmission Rates and Receiver Design</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the asynchronous multiple user access communication in optical
wireless scattering communication, where different users transmit signals
without perfect alignment in the time domain. Firstly, we characterize the
received signal based on hidden markov model (HMM) such that the misalignment
among different users can be characterized by the state transition. Then, we
investigate the achievable rates based on that of the HMM and obtain the
approximated solution using Monte Carlo method. We propose the channel
estimation based on expectation-maximization (EM) algorithm. Furthermore, we
adopt Viterbi and Bahl-Cocke-Jelinek-Raviv (BCJR) algorithms for joint
iterative multi-user decoding. Numerical and experimental results illustrate
the performance of proposed channel estimation, joint detection and decoding.
It is seen from the experimental results that the proposed approaches perform
close to the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02223</identifier>
 <datestamp>2018-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02223</id><created>2018-05-06</created><updated>2018-10-26</updated><authors><author><keyname>Qian</keyname><forenames>Cheng</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author><author><keyname>Yang</keyname><forenames>Ye</forenames></author></authors><title>Tensor-Based Channel Estimation for Dual-Polarized Massive MIMO Systems</title><categories>eess.SP</categories><comments>matlab code is available at:
  https://www.mathworks.com/matlabcentral/fileexchange/69176-tensor-based-channel-estimation-for-dual-polarized-mimo</comments><doi>10.1109/TSP.2018.2873506</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3GPP suggests to combine dual polarized (DP) antenna arrays with the
double directional (DD) channel model for downlink channel estimation. This
combination strikes a good balance between high-capacity communications and
parsimonious channel modeling, and also brings limited feedback schemes for
downlink channel state information within reach---since such channel can be
fully characterized by several key parameters. However, most existing channel
estimation work under the DD model has not yet considered DP arrays, perhaps
because of the complex array manifold and the resulting difficulty in algorithm
design. In this paper, we first reveal that the DD channel with DP arrays at
the transmitter and receiver can be naturally modeled as a low-rank tensor, and
thus the key parameters of the channel can be effectively estimated via tensor
decomposition algorithms.
  On the theory side, we show that the DD-DP parameters are identifiable under
very mild conditions, by leveraging identifiability of low-rank tensors.
Furthermore, a compressed tensor decomposition algorithm is developed for
alleviating the downlink training overhead. We show that, by using judiciously
designed pilot structure, the channel parameters are still guaranteed to be
identified via the compressed tensor decomposition formulation even when the
size of the pilot sequence is much smaller than what is needed for conventional
channel identification methods, such as linear least squares and matched
filtering.
  Numerical simulations are presented to showcase the effectiveness of the
proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02355</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02355</id><created>2018-05-07</created><updated>2018-05-07</updated><authors><author><keyname>Anghan</keyname><forenames>Mehul</forenames></author><author><keyname>Nambath</keyname><forenames>Nandkumar</forenames></author><author><keyname>Kamran</keyname><forenames>Rashmi</forenames></author><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author></authors><title>Adaptive Polarization Control for Coherent Optical Links with
  Polarization Multiplexed Carrier</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-homodyne systems with polarization multiplexed carrier offer an LO-less
coherent receiver with simplified signal processing requirement that can be a
good candidate for high-speed short-reach data center interconnects. The
practical implementation of these systems is limited by the requirement of
polarization control at the receiver end for separating the carrier and the
modulated signal. In this paper, effect of polarization impairments in
polarization diversity based systems is studied and modeled. A novel and
practical adaptive polarization control technique based on optical power
feedback from one polarization is proposed for polarization multiplexed carrier
based systems and verified through simulation results. The application of the
proposed concept is experimentally demonstrated also for a QPSK system with
polarization multiplexed carrier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02395</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02395</id><created>2018-05-07</created><updated>2018-08-12</updated><authors><author><keyname>Haqiqatnejad</keyname><forenames>Alireza</forenames></author><author><keyname>Kayhan</keyname><forenames>Farbod</forenames></author><author><keyname>Ottersten</keyname><forenames>Bjorn</forenames></author></authors><title>Robust Design of Power Minimizing Symbol-Level Precoder under Channel
  Uncertainty</title><categories>eess.SP cs.IT math.IT</categories><comments>9 pages, 3 figures, submitted to GLOBECOM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the downlink transmission of a multiuser
multiple-input single-output (MISO) channel under a symbol-level precoding
(SLP) scheme, having imperfect channel knowledge at the transmitter. In
defining the SLP problem, a general category of constructive interference
regions (CIR) called distance preserving CIR (DPCIR) is adopted. In particular,
we are interested in the robust SLP design minimizing the total transmit power
while satisfying the users' quality-of-service (QoS) requirements. We consider
two common models for the channel uncertainty region, namely, norm-bounded
spherical and stochastic. For the spherical uncertainty model, a worst-case
robust precoder is proposed, while for the stochastic uncertainties, we define
a convex optimization problem with probabilistic constraints. We simulate the
performance of the proposed robust approaches, and compare them with the
existing methods. Through the simulation results, we also show that there is an
essential trade-off between the two robust approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02410</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02410</id><created>2018-05-07</created><updated>2018-05-29</updated><authors><author><keyname>Takahashi</keyname><forenames>Naoya</forenames></author><author><keyname>Goswami</keyname><forenames>Nabarun</forenames></author><author><keyname>Mitsufuji</keyname><forenames>Yuki</forenames></author></authors><title>MMDenseLSTM: An efficient combination of convolutional and recurrent
  neural networks for audio source separation</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have become an indispensable technique for audio source
separation (ASS). It was recently reported that a variant of CNN architecture
called MMDenseNet was successfully employed to solve the ASS problem of
estimating source amplitudes, and state-of-the-art results were obtained for
DSD100 dataset. To further enhance MMDenseNet, here we propose a novel
architecture that integrates long short-term memory (LSTM) in multiple scales
with skip connections to efficiently model long-term structures within an audio
context. The experimental results show that the proposed method outperforms
MMDenseNet, LSTM and a blend of the two networks. The number of parameters and
processing time of the proposed model are significantly less than those for
simple blending. Furthermore, the proposed method yields better results than
those obtained using ideal binary masks for a singing voice separation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02489</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02489</id><created>2018-05-03</created><updated>2018-05-30</updated><authors><author><keyname>Delbrouck</keyname><forenames>Jean-Benoit</forenames></author></authors><title>Transformer for Emotion Recognition</title><categories>cs.HC cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the UMONS solution for the OMG-Emotion Challenge. We
explore a context-dependent architecture where the arousal and valence of an
utterance are predicted according to its surrounding context (i.e. the
preceding and following utterances of the video). We report an improvement when
taking into account context for both unimodal and multimodal predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02500</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02500</id><created>2018-05-07</created><updated>2018-08-17</updated><authors><author><keyname>Jamal</keyname><forenames>Hosseinali</forenames></author><author><keyname>Matolak</keyname><forenames>David W.</forenames></author></authors><title>Dual-Polarization FBMC for Improved Performance in Wireless
  Communication Systems</title><categories>eess.SP</categories><comments>This paper has been submitted to the IEEE Transactions on Vehicular
  Technology (TVT) for possible publication, as well as a U.S. patent
  application. Right now this paper is under revision, and this new submitted
  version is the revised paper addressing all the reviewers' comments</comments><doi>10.1109/TVT.2018.2879573</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filter bank multi-carrier (FBMC) offers superior spectral properties compared
to cyclic-prefix orthogonal frequency-division multiplexing (CP-OFDM), at the
cost of an inherent shortcoming in dispersive channels called intrinsic
imaginary interference. In this paper we propose a new FBMC based communication
system using two orthogonal polarizations for wireless communication systems:
dual-polarization FBMC (DP-FBMC). Using this system we can significantly
suppress the FBMC intrinsic interference. Therefore in DP-FBMC all the
multicarrier techniques used in CP-OFDM systems such as channel equalization,
etc., should be applicable without using the complex processing methods
required for conventional FBMC. DP-FBMC also has other interesting advantages
over CP-OFDM and FBMC: it is more robust in highly dispersive channels, and
also to receiver carrier frequency offset (CFO) and timing offset (TO). In our
DP-FBMC system we propose three different structures based on different
multiplexing techniques. We show that compared to conventional FBMC, one of
these DP-FBMC structures has equivalent complexity and equipment requirements.
We compare DP-FBMC with other systems through simulations. According to our
results DP-FBMC has potential as a promising candidate for future wireless
communication networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02603</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02603</id><created>2018-05-07</created><authors><author><keyname>Wager</keyname><forenames>Sanna</forenames></author><author><keyname>Guo</keyname><forenames>Lijiang</forenames></author><author><keyname>Sivaraman</keyname><forenames>Aswin</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>A Data-Driven Approach to Smooth Pitch Correction for Singing Voice in
  Pop Music</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a machine-learning approach to pitch correction for
voice in a karaoke setting, where the vocals and accompaniment are on separate
tracks and time-aligned. The network takes as input the time-frequency
representation of the two tracks and predicts the amount of pitch-shifting in
cents required to make the voice sound in-tune with the accompaniment. It is
trained on examples of semi-professional singing. The proposed approach differs
from existing real-time pitch correction methods by replacing pitch tracking
and mapping to a discrete set of notes---for example, the twelve classes of the
equal-tempered scale---with learning a correction that is continuous both in
frequency and in time directly from the harmonics of the vocal and
accompaniment tracks. A Recurrent Neural Network (RNN) model provides a
correction that takes context into account, preserving expressive pitch bending
and vibrato. This method can be extended into unsupervised pitch correction of
a vocal performance---popularly referred to as autotuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02642</identifier>
 <datestamp>2019-05-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02642</id><created>2018-05-07</created><updated>2019-05-03</updated><authors><author><keyname>Dekel</keyname><forenames>Shai</forenames></author><author><keyname>Elisha</keyname><forenames>Oren</forenames></author><author><keyname>Morgan</keyname><forenames>Ohad</forenames></author></authors><title>Wavelet Decomposition of Gradient Boosting</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a significant improvement to the popular
tree-based Stochastic Gradient Boosting algorithm using a wavelet decomposition
of the trees. This approach is based on harmonic analysis and approximation
theoretical elements, and as we show through extensive experimentation, our
wavelet based method generally outperforms existing methods, particularly in
difficult scenarios of class unbalance and mislabeling in the training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02842</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02842</id><created>2018-05-08</created><updated>2019-06-13</updated><authors><author><keyname>Yazar</keyname><forenames>Ahmet</forenames></author><author><keyname>Pek&#xf6;z</keyname><forenames>Berker</forenames></author><author><keyname>Arslan</keyname><forenames>H&#xfc;seyin</forenames></author></authors><title>Fundamentals of Multi-Numerology 5G New Radio</title><categories>eess.SP</categories><comments>The extended and updated version of this work was published in River
  Publishers Journal of Mobile Multimedia. DOI: 10.13052/jmm1550-4646.1442</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The physical layer of 5G cellular communications systems is designed to
achieve better flexibility in an effort to support diverse services and user
requirements. OFDM waveform parameters are enriched with flexible
multi-numerology structures. This paper describes the differences between Long
Term Evolution (LTE) systems and new radio (NR) from the flexibility
perspective. Research opportunities for multi-numerology systems are presented
in a structured manner. Finally, inter-numerology interference (INI) results as
a function of guard allocation and multi-numerology parameters are obtained
through simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02850</identifier>
 <datestamp>2018-09-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02850</id><created>2018-05-08</created><updated>2018-09-06</updated><authors><author><keyname>Ram</keyname><forenames>Sundaresh</forenames></author><author><keyname>Nguyen</keyname><forenames>Vicky T.</forenames></author><author><keyname>Limesand</keyname><forenames>Kirsten H.</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author></authors><title>Joint Cell Nuclei Detection and Segmentation in Microscopy Images Using
  3D Convolutional Networks</title><categories>eess.IV cs.CV</categories><comments>We were not able to reproduce the results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a 3D convolutional neural network to simultaneously segment and
detect cell nuclei in confocal microscopy images. Mirroring the co-dependency
of these tasks, our proposed model consists of two serial components: the first
part computes a segmentation of cell bodies, while the second module identifies
the centers of these cells. Our model is trained end-to-end from scratch on a
mouse parotid salivary gland stem cell nuclei dataset comprising 107 image
stacks from three independent cell preparations, each containing several
hundred individual cell nuclei in 3D. In our experiments, we conduct a thorough
evaluation of both detection accuracy and segmentation quality, on two
different datasets. The results show that the proposed method provides
significantly improved detection and segmentation accuracy compared to
state-of-the-art and benchmark algorithms. Finally, we use a previously
described test-time drop-out strategy to obtain uncertainty estimates on our
predictions and validate these estimates by demonstrating that they are
strongly correlated with accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02852</identifier>
 <datestamp>2018-09-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02852</id><created>2018-05-08</created><updated>2018-09-06</updated><authors><author><keyname>Ram</keyname><forenames>Sundaresh</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author></authors><title>Conditional Entropy as a Supervised Primitive Segmentation Loss Function</title><categories>eess.IV</categories><comments>There are errors in the protocol-adaption section and we were unable
  to regenerate the results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised image segmentation assigns image voxels to a set of labels, as
defined by a specific labeling protocol. In this paper, we decompose
segmentation into two steps. The first step is what we call &quot;primitive
segmentation&quot;, where voxels that form sub-parts (primitives) of the various
segmentation labels available in the training data, are grouped together. The
second step involves computing a protocol-specific label map based on the
primitive segmentation. Our core contribution is a novel loss function for the
first step, where a primitive segmentation model is trained. The proposed loss
function is the entropy of the (protocol-specific) &quot;ground truth&quot; label map
conditioned on the primitive segmentation. The conditional entropy loss enables
combining training datasets that have been manually labeled with different
protocols. Furthermore, as we show empirically, it facilitates an efficient
strategy for transfer learning via a lightweight protocol adaptation model that
can be trained with little manually labeled data. We apply the proposed
approach to the volumetric segmentation of brain MRI scans, where we achieve
promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02916</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02916</id><created>2018-05-08</created><authors><author><keyname>Xia</keyname><forenames>ChenYang</forenames></author><author><keyname>Chen</keyname><forenames>Ji</forenames></author><author><keyname>Fan</keyname><forenames>YouZhe</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-ying</forenames></author><author><keyname>Jin</keyname><forenames>Jie</forenames></author><author><keyname>Shen</keyname><forenames>Hui</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author></authors><title>A High-Throughput Architecture of List Successive Cancellation Polar
  Codes Decoder with Large List Size</title><categories>eess.SP cs.AR</categories><comments>16 pages, 13 figures, 8 tables, accepted by IEEE Transactions on
  Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing ( Volume: 66, Issue: 14,
  2018 )</journal-ref><doi>10.1109/TSP.2018.2838554</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the first kind of forward error correction (FEC) codes that achieve
channel capacity, polar codes have attracted much research interest recently.
Compared with other popular FEC codes, polar codes decoded by list successive
cancellation decoding (LSCD) with a large list size have better error
correction performance. However, due to the serial decoding nature of LSCD and
the high complexity of list management (LM), the decoding latency is high,
which limits the usage of polar codes in practical applications that require
low latency and high throughput. In this work, we study the high-throughput
implementation of LSCD with a large list size. Specifically, at the algorithmic
level, to achieve a low decoding latency with moderate hardware complexity, two
decoding schemes, a multi-bit double thresholding scheme and a partial G-node
look-ahead scheme, are proposed. Then, a high-throughput VLSI architecture
implementing the proposed algorithms is developed with optimizations on
different computation modules. From the implementation results on UMC 90 nm
CMOS technology, the proposed architecture achieves decoding throughputs of
1.103 Gbps, 977 Mbps and 827 Mbps when the list sizes are 8, 16 and 32,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02922</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02922</id><created>2018-05-08</created><authors><author><keyname>Renkens</keyname><forenames>Vincent</forenames></author><author><keyname>Van hamme</keyname><forenames>Hugo</forenames></author></authors><title>Capsule Networks for Low Resource Spoken Language Understanding</title><categories>eess.AS cs.SD</categories><comments>Submitted to INTERSPEECH 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing a spoken language understanding system for command-and-control
applications can be challenging because of a wide variety of domains and users
or because of a lack of training data. In this paper we discuss a system that
learns from scratch from user demonstrations. This method has the advantage
that the same system can be used for many domains and users without
modifications and that no training data is required prior to deployment. The
user is required to train the system, so for a user friendly experience it is
crucial to minimize the required amount of data. In this paper we investigate
whether a capsule network can make efficient use of the limited amount of
available training data. We compare the proposed model to an approach based on
Non-negative Matrix Factorisation which is the state-of-the-art in this setting
and another deep learning approach that was recently introduced for end-to-end
spoken language understanding. We show that the proposed model outperforms the
baseline models for three command-and-control applications: controlling a small
robot, a vocally guided card game and a home automation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02924</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02924</id><created>2018-05-08</created><authors><author><keyname>Thangthai</keyname><forenames>Kwanchiva</forenames></author><author><keyname>Bear</keyname><forenames>Helen L</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author></authors><title>Comparing phonemes and visemes with DNN-based lipreading</title><categories>cs.CV cs.CL cs.SD eess.AS eess.IV</categories><journal-ref>BMVC Lipreading Workshop 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is debate if phoneme or viseme units are the most effective for a
lipreading system. Some studies use phoneme units even though phonemes describe
unique short sounds; other studies tried to improve lipreading accuracy by
focusing on visemes with varying results. We compare the performance of a
lipreading system by modeling visual speech using either 13 viseme or 38
phoneme units. We report the accuracy of our system at both word and unit
levels. The evaluation task is large vocabulary continuous speech using the
TCD-TIMIT corpus. We complete our visual speech modeling via hybrid DNN-HMMs
and our visual speech decoder is a Weighted Finite-State Transducer (WFST). We
use DCT and Eigenlips as a representation of mouth ROI image. The phoneme
lipreading system word accuracy outperforms the viseme based system word
accuracy. However, the phoneme system achieved lower accuracy at the unit level
which shows the importance of the dictionary for decoding classification
outputs into words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02934</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02934</id><created>2018-05-08</created><authors><author><keyname>Bear</keyname><forenames>Helen L</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author></authors><title>Phoneme-to-viseme mappings: the good, the bad, and the ugly</title><categories>cs.CV cs.SD eess.AS eess.IV</categories><journal-ref>Speech Communication, Special Issue on AV expressive speech. 2017</journal-ref><doi>10.1016/j.specom.2017.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visemes are the visual equivalent of phonemes. Although not precisely
defined, a working definition of a viseme is &quot;a set of phonemes which have
identical appearance on the lips&quot;. Therefore a phoneme falls into one viseme
class but a viseme may represent many phonemes: a many to one mapping. This
mapping introduces ambiguity between phonemes when using viseme classifiers.
Not only is this ambiguity damaging to the performance of audio-visual
classifiers operating on real expressive speech, there is also considerable
choice between possible mappings. In this paper we explore the issue of this
choice of viseme-to-phoneme map. We show that there is definite difference in
performance between viseme-to-phoneme mappings and explore why some maps appear
to work better than others. We also devise a new algorithm for constructing
phoneme-to-viseme mappings from labeled speech data. These new visemes, `Bear'
visemes, are shown to perform better than previously known units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02948</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02948</id><created>2018-05-08</created><authors><author><keyname>Bear</keyname><forenames>Helen L</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author></authors><title>Comparing heterogeneous visual gestures for measuring the diversity of
  visual speech signals</title><categories>eess.IV cs.CV cs.SD eess.AS</categories><journal-ref>Computer Speech and Language, May 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual lip gestures observed whilst lipreading have a few working
definitions, the most common two are; `the visual equivalent of a phoneme' and
`phonemes which are indistinguishable on the lips'. To date there is no formal
definition, in part because to date we have not established a two-way
relationship or mapping between visemes and phonemes. Some evidence suggests
that visual speech is highly dependent upon the speaker. So here, we use a
phoneme-clustering method to form new phoneme-to-viseme maps for both
individual and multiple speakers. We test these phoneme to viseme maps to
examine how similarly speakers talk visually and we use signed rank tests to
measure the distance between individuals. We conclude that broadly speaking,
speakers have the same repertoire of mouth gestures, where they differ is in
the use of the gestures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02958</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02958</id><created>2018-05-08</created><authors><author><keyname>Kato</keyname><forenames>Akihiro</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author></authors><title>A Regression Model of Recurrent Deep Neural Networks for Noise Robust
  Estimation of the Fundamental Frequency Contour of Speech</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental frequency (F0) contour of speech is a key aspect to represent
speech prosody that finds use in speech and spoken language analysis such as
voice conversion and speech synthesis as well as speaker and language
identification. This work proposes new methods to estimate the F0 contour of
speech using deep neural networks (DNNs) and recurrent neural networks (RNNs).
They are trained using supervised learning with the ground truth of F0
contours. The latest prior research addresses this problem first as a
frame-by-frame-classification problem followed by sequence tracking using deep
neural network hidden Markov model (DNN-HMM) hybrid architecture. This study,
however, tackles the problem as a regression problem instead, in order to
obtain F0 contours with higher frequency resolution from clean and noisy
speech. Experiments using PTDB-TUG corpus contaminated with additive noise
(NOISEX-92) show the proposed method improves gross pitch error (GPE) by more
than 25 % at signal-to-noise ratios (SNRs) between -10 dB and +10 dB as
compared with one of the most noise-robust F0 trackers, PEFAC. Furthermore, the
performance on fine pitch error (FPE) is improved by approximately 20 % against
a state-of-the-art DNN-HMM-based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.02996</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.02996</id><created>2018-05-08</created><authors><author><keyname>Sun</keyname><forenames>Yujing</forenames></author><author><keyname>Yu</keyname><forenames>Yizhou</forenames></author><author><keyname>Wang</keyname><forenames>Wenping</forenames></author></authors><title>Moir\'{e} Photo Restoration Using Multiresolution Convolutional Neural
  Networks</title><categories>cs.CV eess.IV</categories><comments>13 pages, 19 figures, accepted to appear in IEEE Transactions on
  Image Processing</comments><doi>10.1109/TIP.2018.2834737</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital cameras and mobile phones enable us to conveniently record precious
moments. While digital image quality is constantly being improved, taking
high-quality photos of digital screens still remains challenging because the
photos are often contaminated with moir\'{e} patterns, a result of the
interference between the pixel grids of the camera sensor and the device
screen. Moir\'{e} patterns can severely damage the visual quality of photos.
However, few studies have aimed to solve this problem. In this paper, we
introduce a novel multiresolution fully convolutional network for automatically
removing moir\'{e} patterns from photos. Since a moir\'{e} pattern spans over a
wide range of frequencies, our proposed network performs a nonlinear
multiresolution analysis of the input image before computing how to cancel
moir\'{e} artefacts within every frequency band. We also create a large-scale
benchmark dataset with $100,000^+$ image pairs for investigating and evaluating
moir\'{e} pattern removal algorithms. Our network achieves state-of-the-art
performance on this dataset in comparison to existing learning architectures
for image restoration problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03000</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03000</id><created>2018-05-08</created><authors><author><keyname>Xia</keyname><forenames>ChenYang</forenames></author><author><keyname>Fan</keyname><forenames>YouZhe</forenames></author><author><keyname>Chen</keyname><forenames>Ji</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-ying</forenames></author><author><keyname>Zeng</keyname><forenames>ChongYang</forenames></author><author><keyname>Jin</keyname><forenames>Jie</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author></authors><title>An Implementation of List Successive Cancellation Decoder with Large
  List Size for Polar Codes</title><categories>eess.SP</categories><comments>4 pages, 4 figures, 4 tables, Published in 27th International
  Conference on Field Programmable Logic and Applications (FPL), 2017</comments><doi>10.23919/FPL.2017.8056843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes are the first class of forward error correction (FEC) codes with
a provably capacity-achieving capability. Using list successive cancellation
decoding (LSCD) with a large list size, the error correction performance of
polar codes exceeds other well-known FEC codes. However, the hardware
complexity of LSCD rapidly increases with the list size, which incurs high
usage of the resources on the field programmable gate array (FPGA) and
significantly impedes the practical deployment of polar codes. To alleviate the
high complexity, in this paper, two low-complexity decoding schemes and the
corresponding architectures for LSCD targeting FPGA implementation are
proposed. The architecture is implemented in an Altera Stratix V FPGA.
Measurement results show that, even with a list size of 32, the architecture is
able to decode a codeword of 4096-bit polar code within 150 us, achieving a
throughput of 27Mbps
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03011</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03011</id><created>2018-04-28</created><authors><author><keyname>Mehrnoush</keyname><forenames>Morteza</forenames></author><author><keyname>Patidar</keyname><forenames>Rohan</forenames></author><author><keyname>Roy</keyname><forenames>Sumit</forenames></author><author><keyname>Henderson</keyname><forenames>Thomas</forenames></author></authors><title>Modeling, Simulation and Fairness Analysis of Wi-Fi and Unlicensed LTE
  Coexistence</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coexistence of small-cell LTE and Wi-Fi networks in unlicensed bands at $5$
GHz is a topic of active interest, primarily driven by industry groups
affiliated with the two (cellular and Wi-Fi) segments. A notable alternative to
the 3GPP Rel. 13 defined LTE-Licensed Assisted Access (LTE-LAA) mechanism for
coexistence is the unlicensed LTE (LTE-U) Forum \cite{lteuforum} that
prescribed Carrier Sense Adaptive Transmission (CSAT) whereby LTE utilizes the
unlicensed band as a supplemental downlink unlicensed carrier (to enhance
downlink data rate) to normal operation using licensed spectrum. In this work,
we provide a new analytical model for performance analysis of unlicensed LTE
with fixed duty cycling (LTE-DC) in coexistence with Wi-Fi. Further, the
analytical results are cross-validated with ns-3 (www.nsnam.org) based
simulation results using a newly developed coexistence stack. Thereafter,
notions of {\em fair coexistence} are investigated that can be achieved by
tuning the LTE duty cycle. The results show that as the number of Wi-Fi nodes
increases, the Wi-Fi network in coexistence with LTE-DC with 0.5 duty cycling
achieves a higher throughput than with an identical Wi-Fi network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03024</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03024</id><created>2018-05-08</created><authors><author><keyname>Wang</keyname><forenames>Guanyu</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Xu</keyname><forenames>Zhiwei</forenames></author></authors><title>Asymptotically Optimal One-Bit Quantizer Design for Weak-signal
  Detection in Generalized Gaussian Noise and Lossy Binary Communication
  Channel</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, quantizer design for weak-signal detection under arbitrary
binary channel in generalized Gaussian noise is studied. Since the performances
of the generalized likelihood ratio test (GLRT) and Rao test are asymptotically
characterized by the noncentral chi-squared probability density function (PDF),
the threshold design problem can be formulated as a noncentrality parameter
maximization problem. The theoretical property of the noncentrality parameter
with respect to the threshold is investigated, and the optimal threshold is
shown to be found in polynomial time with appropriate numerical algorithm and
proper initializations. In certain cases, the optimal threshold is proved to be
zero. Finally, numerical experiments are conducted to substantiate the
theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03168</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03168</id><created>2018-05-08</created><authors><author><keyname>Gregory</keyname><forenames>Kalogiannis</forenames></author><author><keyname>Nikolaos</keyname><forenames>Karampelas</forenames></author><author><keyname>George</keyname><forenames>Hassapis</forenames></author></authors><title>A reworked SOBI algorithm based on SCHUR Decomposition for EEG data
  processing</title><categories>cs.HC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In brain machine interfaces (BMI) that are used to control motor
rehabilitation devices there is the need to process the monitored brain signals
with the purpose of recognizing patient's intentions to move his hands or limbs
and reject artifact and noise superimposed on these signals. This kind of
processing has to take place within time limits imposed by the on-line control
requirements of such devices. A widely-used algorithm is the Second Order Blind
Identification (SOBI) independent component analysis (ICA) algorithm. This
algorithm, however, presents long processing time and therefor it not suitable
for use in the brain-based control of rehabilitation devices. A rework of this
algorithm that is presented in this paper and based on SCHUR decomposition
results to significantly reduced processing time. This new algorithm is quite
appropriate for use in brain-based control of rehabilitation devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03169</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03169</id><created>2018-05-08</created><authors><author><keyname>Gregory</keyname><forenames>Kalogiannis</forenames></author><author><keyname>George</keyname><forenames>Kapsimanis</forenames></author><author><keyname>George</keyname><forenames>Hassapis</forenames></author></authors><title>An EEG pre-processing technique for the fast recognition of motor
  imagery movements</title><categories>physics.med-ph eess.SP</categories><comments>4 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a new pre-processing technique of
Electroencephalography (EEG) signals produced by motor imagery movements. This
technique results to an accelerated determination of the imagery movement and
the command to carry it out, within the time limits imposed by the requirements
of brain-based real-time control of rehabilitation devices, making thus
feasible to drive these devices according to patient's will. Based on event
related desynchronization and synchronization (ERD/ERS) of motor imagery, the
received patient signal is first subjected to the removal of environmental,
system and interference noise which correspond to normal human activities such
as eye-blinking and cardiac motion. Next, power and energy features of the
processed signal are compared with the same features of classified signals from
an available database and the class to which the processed signal belongs, is
identified. The database classification is done off-line by using the SVM
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03322</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03322</id><created>2018-05-08</created><authors><author><keyname>Shivakumar</keyname><forenames>Prashanth Gurunath</forenames></author><author><keyname>Georgiou</keyname><forenames>Panayiotis</forenames></author></authors><title>Transfer Learning from Adult to Children for Speech Recognition:
  Evaluation, Analysis and Recommendations</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Children speech recognition is challenging mainly due to the inherent high
variability in children's physical and articulatory characteristics and
expressions. This variability manifests in both acoustic constructs and
linguistic usage due to the rapidly changing developmental stage in children's
life. Part of the challenge is due to the lack of large amounts of available
children speech data for efficient modeling. This work attempts to address the
key challenges using transfer learning from adult's models to children's models
in a Deep Neural Network (DNN) framework for children's Automatic Speech
Recognition (ASR) task evaluating on multiple children's speech corpora with a
large vocabulary. The paper presents a systematic and an extensive analysis of
the proposed transfer learning technique considering the key factors affecting
children's speech recognition from prior literature. Evaluations are presented
on (i) comparisons of earlier GMM-HMM and the newer DNN Models, (ii)
effectiveness of standard adaptation techniques versus transfer learning, (iii)
various adaptation configurations in tackling the variabilities present in
children speech, in terms of (a) acoustic spectral variability, and (b)
pronunciation variability and linguistic constraints. Our Analysis spans over
(i) number of DNN model parameters (for adaptation), (ii) amount of adaptation
data, (iii) ages of children, (iv) age dependent-independent adaptation.
Finally, we provide Recommendations on (i) the favorable strategies over
various aforementioned - analyzed parameters, and (ii) potential future
research directions and relevant challenges/problems persisting in DNN based
ASR for children's speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03398</identifier>
 <datestamp>2018-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03398</id><created>2018-05-09</created><authors><author><keyname>Nguyen</keyname><forenames>Duc-Phuc</forenames></author><author><keyname>Le</keyname><forenames>Dinh-Dung</forenames></author><author><keyname>Tran</keyname><forenames>Thi-Hong</forenames></author><author><keyname>Huynh</keyname><forenames>Huu-Thuan</forenames></author><author><keyname>Nakashima</keyname><forenames>Yasuhiko</forenames></author></authors><title>VLSI Architecture of Compact Non-RLL Beacon-based Visible Light
  Communication Transmitter and Receiver</title><categories>eess.SP</categories><comments>Being reviewd by EURASIP Journal of Wireless Communication and
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a couple of hardware implementations of compact
VLC transmitter and receiver for the first time. Compared with related works,
our VLC transmitter is non-RLL one, that means flicker mitigation can be
guaranteed even without RLL codes. In particular, we have utilized a
centralized bit probability distribution of a prescrambler and a Polar encoder
to create a non-RLL flicker mitigation solution. Moreover, at the receiver, a
3-bit soft-decision filter is proposed to analyze signals received from real
VLC channel to extract log-likelihood ratio (LLR) values and feed them to the
FEC decoder. Therefore, soft-decoding of Polar decoder can be implemented to
improve the bit-error-rate (BER) performance of the VLC system. Finally, we
introduce a novel very large scale integration (VLSI) architecture for the
compact VLC transmitter and receiver; and synthesis our design under FPGA/ASIC
synthesis tools. Due to the non-RLL basic, our system has an evidently good
code-rate and a reduced-complexity compared with other RLL-based receiver
works. Also, we present FPGA and ASIC synthesis results of the proposed
architecture with evaluations of power consumption, area, energy-per-bits and
so on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03500</identifier>
 <datestamp>2018-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03500</id><created>2018-05-09</created><authors><author><keyname>Ko&#xe7;</keyname><forenames>Aykut</forenames></author><author><keyname>Bartan</keyname><forenames>Burak</forenames></author><author><keyname>Ozaktas</keyname><forenames>Haldun M.</forenames></author></authors><title>Discrete Scaling Based on Operator Theory</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal scaling is a fundamental operation of practical importance in which a
signal is enlarged or shrunk in the coordinate direction(s). Scaling or
magnification is not trivial for signals of a discrete variable since the
signal values may not fall onto the discrete coordinate points. One approach is
to consider the discretely-spaced values as the samples of a signal of a real
variable, find that signal by interpolation, scale it, and then re-sample.
However, this approach comes with complications of interpretation. We review a
previously proposed alternative and more elegant approach, and then propose a
new approach based on hyperdifferential operator theory that we find most
satisfactory in terms of obtaining a self-consistent, pure, and elegant
definition of discrete scaling that is fully consistent with the theory of the
discrete Fourier transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03501</identifier>
 <datestamp>2018-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03501</id><created>2018-04-28</created><authors><author><keyname>Mehrnoush</keyname><forenames>Morteza</forenames></author><author><keyname>Roy</keyname><forenames>Sumit</forenames></author></authors><title>On the Fairness of Wi-Fi and LTE-LAA Coexistence</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1803.02444</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With both small-cell LTE and 802.11 networks now available as alternatives
for deployment in unlicensed bands at 5 GHz, investigation into their
coexistence is a topic of great interest. 3GPP Rel. 14 has standardized LTE
licensed assisted access (LAA) that seeks to make LTE more coexistence friendly
with Wi-Fi by incorporating listen before talk (LBT). However, the fairness of
Wi-Fi and LTE-LAA sharing is a topic that has not been adequately explored. In
this work, we first investigate the 3GPP definition of fair coexistence in [1]
via new analytical models. By tuning the LTE-LAA parameters, we exemplify
scenarios when the 3GPP notion of fairness is achieved and conversely, when not
achieved. The formal notions of access and proportional fairness is then
considered for these scenarios to compare and contrast with the 3GPP
definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03647</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03647</id><created>2018-05-09</created><authors><author><keyname>&#xc7;ak&#x131;r</keyname><forenames>Emre</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>End-to-End Polyphonic Sound Event Detection Using Convolutional
  Recurrent Neural Networks with Learned Time-Frequency Representation Input</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>accepted to IJCNN 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound event detection systems typically consist of two stages: extracting
hand-crafted features from the raw audio waveform, and learning a mapping
between these features and the target sound events using a classifier.
Recently, the focus of sound event detection research has been mostly shifted
to the latter stage using standard features such as mel spectrogram as the
input for classifiers such as deep neural networks. In this work, we utilize
end-to-end approach and propose to combine these two stages in a single deep
neural network classifier. The feature extraction over the raw waveform is
conducted by a feedforward layer block, whose parameters are initialized to
extract the time-frequency representations. The feature extraction parameters
are updated during training, resulting with a representation that is optimized
for the specific task. This feature extraction block is followed by (and
jointly trained with) a convolutional recurrent network, which has recently
given state-of-the-art results in many sound recognition tasks. The proposed
system does not outperform a convolutional recurrent network with fixed
hand-crafted features. The final magnitude spectrum characteristics of the
feature extraction block parameters indicate that the most relevant information
for the given task is contained in 0 - 3 kHz frequency range, and this is also
supported by the empirical results on the SED performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03769</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03769</id><created>2018-05-09</created><updated>2019-01-07</updated><authors><author><keyname>Liu</keyname><forenames>Xian</forenames></author><author><keyname>Davarikia</keyname><forenames>Hamzeh</forenames></author></authors><title>Optimal Power Flow with Disjoint Prohibited Zones: New Formulation and
  Solutions</title><categories>eess.SP</categories><comments>Accepted in 2019 IEEE TPEC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The constraints induced by prohibited zones (PZs) were traditionally
formulated as multiple disjoint regions. It was difficult to solve the optimal
power flow (OPF) problems subject to the disjoint constraints. This paper
proposes a new formulation for the OPF problem with PZs. The proposed
formulation significantly expedites the algorithm implementation. The
effectiveness of the new approach is verified by different methods including
traditional optimization methods, PSO and particle swarm optimization with
adaptive parameter control which is conducted on the IEEE 30-bus test system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03783</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03783</id><created>2018-05-09</created><authors><author><keyname>Ebrahimi</keyname><forenames>Amir</forenames></author><author><keyname>Baum</keyname><forenames>Thomas</forenames></author><author><keyname>Scott</keyname><forenames>James</forenames></author><author><keyname>Ghorbani</keyname><forenames>Kamran</forenames></author></authors><title>Continuously Tunable Dual-mode Bandstop Filter</title><categories>eess.SP</categories><comments>3 pages</comments><journal-ref>IEEE Microwave and Wireless Components Letters, 2018</journal-ref><doi>10.1109/LMWC.2018.2821841</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A varactor-based tunable bandstop filter has been proposed in this article.
The proposed filter is based on a dualmode circuit developed by introducing
inductive and capacitive couplings into a notch filter. The frequency
tunability is achieved by using varactor diodes instead of the lumped
capacitors in the circuit. Next, the equivalent circuit model has been
implemented in planar microstrip technology using thin inductive traces and
varactor diodes. The fabricated filter prototype shows a continuous center
frequency tuning range of 0.66 - 0.99 GHz with a compact size of 0.12lg*0:16lg,
where lg is the guided wavelength at the middle frequency of the tuning range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03787</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03787</id><created>2018-05-09</created><authors><author><keyname>Ren</keyname><forenames>Chenglin</forenames></author><author><keyname>liu</keyname><forenames>Fan</forenames></author><author><keyname>Zhou</keyname><forenames>Longfei</forenames></author><author><keyname>Zhou</keyname><forenames>Jianming</forenames></author><author><keyname>Luo</keyname><forenames>Wu</forenames></author><author><keyname>Yang</keyname><forenames>Shengzhi</forenames></author></authors><title>MIMO radar waveform design with practical constraints: A low-complexity
  approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the multiple-input multiple-output (MIMO) radar
waveform design in the presence of signal-dependent clutters and additive white
Gaussian noise. By imposing the constant modulus constraint (CMC) and waveform
similarity constraint (SC), the signal-to-interference-plus-noise (SINR)
maximization problem is non-convex and NP-hard in general, which can be
transformed into a sequence of convex quadratically constrained quadratic
programming (QCQP) subproblems. Aiming at solving each subproblem efficiently,
we propose a low-complexity method termed Accelerated Gradient Projection
(AGP). In contrast to the conventional IPM based method, our proposed algorithm
achieves the same performance in terms of the receive SINR and the beampattern,
while notably reduces computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03832</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03832</id><created>2018-05-10</created><updated>2018-05-13</updated><authors><author><keyname>Zou</keyname><forenames>Wei</forenames></author><author><keyname>Jiang</keyname><forenames>Dongwei</forenames></author><author><keyname>Zhao</keyname><forenames>Shuaijiang</forenames></author><author><keyname>Li</keyname><forenames>Xiangang</forenames></author></authors><title>A comparable study of modeling units for end-to-end Mandarin speech
  recognition</title><categories>cs.CL eess.AS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-To-End speech recognition have become increasingly popular in mandarin
speech recognition and achieved delightful performance.
  Mandarin is a tonal language which is different from English and requires
special treatment for the acoustic modeling units. There have been several
different kinds of modeling units for mandarin such as phoneme, syllable and
Chinese character.
  In this work, we explore two major end-to-end models: connectionist temporal
classification (CTC) model and attention based encoder-decoder model for
mandarin speech recognition. We compare the performance of three different
scaled modeling units: context dependent phoneme(CDP), syllable with tone and
Chinese character.
  We find that all types of modeling units can achieve approximate character
error rate (CER) in CTC model and the performance of Chinese character
attention model is better than syllable attention model. Furthermore, we find
that Chinese character is a reasonable unit for mandarin speech recognition. On
DidiCallcenter task, Chinese character attention model achieves a CER of 5.68%
and CTC model gets a CER of 7.29%, on the other DidiReading task, CER are 4.89%
and 5.79%, respectively. Moreover, attention model achieves a better
performance than CTC model on both datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03853</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03853</id><created>2018-05-10</created><authors><author><keyname>Xiong</keyname><forenames>Dan</forenames></author><author><keyname>Chai</keyname><forenames>Li</forenames></author><author><keyname>Zhang</keyname><forenames>Jingxin</forenames></author></authors><title>Sparse System Identification in Pairs of FIR and TM Bases</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the reconstruction of a sparse coefficient vector
{\theta} for a rational transfer function, under a pair of FIR and
Takenaka-Malmquist (TM) bases and from a limited number of linear
frequency-domain measurements. We propose to concatenate a limited number of
FIR and TM basis functions in the representation of the transfer function, and
prove the uniqueness of the sparse representation defined in the infinite
dimensional function space with pairs of FIR and TM bases. The sufficient
condition is given for replacing the l_0 optimal solution by the l_1 optimal
solution using FIR and TM bases with random samples on the upper unit circle,
as the foundation of reconstruction. The simulations verify that l_1
minimization can reconstruct the coefficient vector {\theta} with high
probability. It is shown that the concatenated FIR and TM bases give a much
sparser representation, with much lower reconstruction order than using only
FIR basis functions and less dependency on the knowledge of the true system
poles than using only TM basis functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03973</identifier>
 <datestamp>2018-05-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.03973</id><created>2018-05-10</created><authors><author><keyname>Wang</keyname><forenames>Feilong</forenames></author><author><keyname>Zhang</keyname><forenames>Yuyan</forenames></author><author><keyname>Zhao</keyname><forenames>Hui</forenames></author><author><keyname>Huang</keyname><forenames>Hanyuan</forenames></author><author><keyname>Li</keyname><forenames>Jing</forenames></author></authors><title>Active User Detection of Uplink Grant-Free SCMA in Frequency Selective
  Channel</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive machine type communication (mMTC) is one of the three fifth
generation mobile networking (5G) key usage scenarios, which is characterized
by a very large number of connected devices typically transmitting a relatively
low volume of non-delay sensitive data. To support the mMTC communication, an
uplink (UL) grant-free sparse code multiple access (SCMA) system has been
proposed. In this system, the knowledge of user equipments' (UEs') status
should be obtained before decoding the data by a message passing algorithm
(MPA). An existing solution is to use the compressive sensing (CS) theory to
detect active UEs under the assumed condition of flat fading channel. But the
assumed condition is not suitable for the frequency selective channel and will
decrease the accuracy of active UEs detection. This paper proposes a new simple
module named refined active UE detector (RAUD), which is based on frequency
selective channel gain analyzing. By making full use of the channel gain and
analyzing the difference between characteristic values of the two status of
UEs, RAUD module can enhance the active UEs detection accuracy. Meanwhile, the
addition of the proposed module has a negligible effect on the complexity of UL
grant-free SCMA receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04152</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04152</id><created>2018-05-10</created><authors><author><keyname>Khodabandehlou</keyname><forenames>Hamid</forenames></author><author><keyname>Fadali</keyname><forenames>M. Sami</forenames></author></authors><title>Training Recurrent Neural Networks via Dynamical Trajectory-Based
  Optimization</title><categories>eess.SP cs.NE</categories><doi>10.1016/j.neucom.2019.08.058</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces a new method to train recurrent neural networks using
dynamical trajectory-based optimization. The optimization method utilizes a
projected gradient system (PGS) and a quotient gradient system (QGS) to
determine the feasible regions of an optimization problem and search the
feasible regions for local minima. By exploring the feasible regions, local
minima are identified and the local minimum with the lowest cost is chosen as
the global minimum of the optimization problem. Lyapunov theory is used to
prove the stability of the local minima and their stability in the presence of
measurement errors. Numerical examples show that the new approach provides
better results than genetic algorithm and error backpropagation (EBP) trained
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04157</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04157</id><created>2018-05-10</created><updated>2018-08-02</updated><authors><author><keyname>Aznan</keyname><forenames>Nik Khadijah Nik</forenames></author><author><keyname>Bonner</keyname><forenames>Stephen</forenames></author><author><keyname>Connolly</keyname><forenames>Jason D.</forenames></author><author><keyname>Moubayed</keyname><forenames>Noura Al</forenames></author><author><keyname>Breckon</keyname><forenames>Toby P.</forenames></author></authors><title>On the Classification of SSVEP-Based Dry-EEG Signals via Convolutional
  Neural Networks</title><categories>cs.HC eess.SP q-bio.NC</categories><comments>Accepted as a full paper at the 2018 IEEE International Conference on
  Systems, Man, and Cybernetics (SMC2018)</comments><doi>10.1109/SMC.2018.00631</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel Convolutional Neural Network (CNN) approach
for the classification of raw dry-EEG signals without any data pre-processing.
To illustrate the effectiveness of our approach, we utilise the Steady State
Visual Evoked Potential (SSVEP) paradigm as our use case. SSVEP can be utilised
to allow people with severe physical disabilities such as Complete Locked-In
Syndrome or Amyotrophic Lateral Sclerosis to be aided via BCI applications, as
it requires only the subject to fixate upon the sensory stimuli of interest.
Here we utilise SSVEP flicker frequencies between 10 to 30 Hz, which we record
as subject cortical waveforms via the dry-EEG headset. Our proposed end-to-end
CNN allows us to automatically and accurately classify SSVEP stimulation
directly from the dry-EEG waveforms. Our CNN architecture utilises a common
SSVEP Convolutional Unit (SCU), comprising of a 1D convolutional layer, batch
normalization and max pooling. Furthermore, we compare several deep learning
neural network variants with our primary CNN architecture, in addition to
traditional machine learning classification approaches. Experimental evaluation
shows our CNN architecture to be significantly better than competing
approaches, achieving a classification accuracy of 96% whilst demonstrating
superior cross-subject performance and even being able to generalise well to
unseen subjects whose data is entirely absent from the training process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04168</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04168</id><created>2018-05-10</created><authors><author><keyname>Luu</keyname><forenames>Diu Khue</forenames></author><author><keyname>Nguyen</keyname><forenames>Anh Tuan</forenames></author><author><keyname>Yang</keyname><forenames>Zhi</forenames></author></authors><title>Achieving Super-Resolution with Redundant Sensing</title><categories>cs.IT cs.ET eess.SP math.IT</categories><journal-ref>IEEE Transactions on Biomedical Engineering (2018)</journal-ref><doi>10.1109/TBME.2018.2885523</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog-to-digital (quantization) and digital-to-analog (de-quantization)
conversion are fundamental operations of many information processing systems.
In practice, the precision of these operations is always bounded, first by the
random mismatch error (ME) occurred during system implementation, and
subsequently by the intrinsic quantization error (QE) determined by the system
architecture itself. In this manuscript, we present a new mathematical
interpretation of the previously proposed redundant sensing (RS) architecture
that not only suppresses ME but also allows achieving an effective resolution
exceeding the system's intrinsic resolution, i.e. super-resolution (SR). SR is
enabled by an endogenous property of redundant structures regarded as &quot;code
diffusion&quot; where the references' value spreads into the neighbor sample space
as a result of ME. The proposed concept opens the possibility for a wide range
of applications in low-power fully-integrated sensors and devices where the
cost-accuracy trade-off is inevitable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04242</identifier>
 <datestamp>2018-09-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04242</id><created>2018-05-11</created><updated>2018-09-19</updated><authors><author><keyname>Yang</keyname><forenames>Tianci</forenames></author><author><keyname>Murguia</keyname><forenames>Carlos</forenames></author><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author><author><keyname>Ne&#x161;i&#x107;</keyname><forenames>Dragan</forenames></author></authors><title>A Robust Circle-criterion Observer-based Estimator for Discrete-time
  Nonlinear Systems in the Presence of Sensor Attacks and Measurement Noise</title><categories>eess.SP cs.SY</categories><comments>arXiv admin note: text overlap with arXiv:1806.06484</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of robust state estimation of a class of discrete-time
nonlinear systems with positive-slope nonlinearities when the sensors are
corrupted by (potentially unbounded) attack signals and bounded measurement
noise. We propose an observer-based estimator, using a bank of circle-criterion
observers, which provides a robust estimate of the system state in spite of
sensor attacks and measurement noise. We first consider the attack-free case
where there is measurement noise and we provide a design method for a robust
circle-criterion observer. Then, we consider the case when a sufficiently small
subset of sensors are subject to attacks and all sensors are affected by
measurement noise. We use our robust circle-criterion observer as the main
ingredient in building an estimator that provides robust state estimation in
this case. Finally, we propose an algorithm for isolating attacked sensors in
the case of bounded measurement noise. We test this algorithm through
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04278</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04278</id><created>2018-05-11</created><authors><author><keyname>Bolletta</keyname><forenames>Paolo</forenames></author><author><keyname>Carboni</keyname><forenames>Massimo</forenames></author><author><keyname>Vuagnin</keyname><forenames>Gloria</forenames></author></authors><title>Field Trial of Alien Wavelengths on GARR Optical Network</title><categories>eess.SP cs.NI</categories><comments>This paper has been accepted and will be presented at the 41st
  International Conference on Telecommunications and Signal Processing TSP2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GARR optical network is composed of two separate optical network domains at
the national level. With the aim to integrate them we implemented alien
wavelengths to deliver high-performance services improving the overall network
efficiency. This paper describes the path followed to deploy the alien
wavelengths in the GARR operational infrastructure from the planning phase to
the production network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04309</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04309</id><created>2018-05-11</created><authors><author><keyname>Yang</keyname><forenames>Zhi</forenames></author><author><keyname>Zhou</keyname><forenames>Lai</forenames></author><author><keyname>Zhao</keyname><forenames>Guangyue</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author></authors><title>Blockage Modeling for Inter-layer UAVs Communications in Urban
  Environments</title><categories>cs.IT eess.SP math.IT</categories><comments>to appear in International Conference on Telecommunications (ICT),
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The impact of buildings blockage on the UAVs communications in different UAVs
heights is studied, when UAVs fly in a given rectangular urban area. This paper
analyzes the properties of blockage behavior of communication links between
UAVs from layers of different heights, including two main stochastic
properties, namely the blockage (or LOS) probabilities, and the state
transition models (birth-death process of LOS propagation). Based on stochastic
geometry methods, the relation between LOS probability and the parameters of
the region and the buildings is derived and verified with simulations.
Furthermore, based on the simulations of the channel state transition process,
we also find the birth-death process can be modeled as a distance continuous
Markov process, and the transition rates are also extracted with their relation
with the height of layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04328</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04328</id><created>2018-05-11</created><authors><author><keyname>Yang</keyname><forenames>Zhi</forenames></author><author><keyname>Zhou</keyname><forenames>Lai</forenames></author><author><keyname>Zhao</keyname><forenames>Guangyue</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author></authors><title>Channel Model in Urban Environment for Unmanned Aerial Vehicle
  Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>to prepare in European Conference on Antennas and Propagetion
  (EUCAP), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to develop and analyze reliable communications links for unmanned
aerial vehicles (UAVs), accurate models for the propagation channel are
required. The radio channel properties in the urban scenario are different from
those in the suburb scenario and open area due to so many scattering paths from
office buildings, especially when the UAV flies in the low altitude. We took
some measurement campaigns on the campus of Tsinghua University with crowded
apartments and office buildings. Based on the measurement result we extract the
main parameters of pathloss model, and propose a simplified Saleh-Valenzuela
(SV) model with specific parameters. The typical scene of central lawn is
compared with the office buildings in the analysis of K-factor and
root-mean-square (RMS) delay spread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04364</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04364</id><created>2018-05-11</created><authors><author><keyname>Zhan</keyname><forenames>Cheng</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Trajectory Design for Distributed Estimation in UAV Enabled Wireless
  Sensor Network</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 4 figures, submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study an unmanned aerial vehicle(UAV)-enabled wireless
sensor network, where a UAV is dispatched to collect the sensed data from
distributed sensor nodes (SNs) for estimating an unknown parameter. It is
revealed that in order to minimize the mean square error (MSE) for the
estimation, the UAV should collect the data from as many SNs as possible, based
on which an optimization problem is formulated to design the UAV's trajectory
subject to its practical mobility constraints. Although the problem is
non-convex and NP-hard, we show that the optimal UAV trajectory consists of
connected line segments only. With this simplification, an efficient suboptimal
solution is proposed by leveraging the classic traveling salesman problem (TSP)
method and applying convex optimization techniques. Simulation results show
that the proposed trajectory design achieves significant performance gains in
terms of the number of SNs whose data are successfully collected, as compared
to other benchmark schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04474</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04474</id><created>2018-05-10</created><authors><author><keyname>Risso</keyname><forenames>Claudio</forenames></author><author><keyname>Guerberoff</keyname><forenames>Gustavo</forenames></author></authors><title>Nonparametric optimization of short-term confidence bands for wind power
  generation</title><categories>eess.SP</categories><comments>13 pages, 8 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing rate of penetration of non-conventional renewable energies is
affecting the traditional assumption of controllability over energy sources.
Power dispatching scheduling methods need to integrate the intrinsic randomness
of some new sources, among which, wind energy is particularly difficult to
treat. This work aims on the construction of confidence bands around wind
energy forecasts. Complementarily, the proposed technique can be extended to
integrate multiple forecasts into a single one, whose band's width is narrower
at the same level of confidence. The work is based upon a real-world
application case, developed for the Uruguayan Electricity Market, a world
leader country in the penetration of renewable energies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04518</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04518</id><created>2018-05-11</created><authors><author><keyname>Jin</keyname><forenames>Chenfei</forenames></author><author><keyname>Xie</keyname><forenames>Jiaheng</forenames></author><author><keyname>Zhang</keyname><forenames>Siqi</forenames></author><author><keyname>Zhang</keyname><forenames>Zijing</forenames></author><author><keyname>Zhao</keyname><forenames>Yuan</forenames></author></authors><title>Reconstruction of multiple non-line-of-sight objects using back
  projection based on ellipsoid mode decomposition</title><categories>eess.IV physics.optics</categories><comments>12 pages, 8 figures</comments><doi>10.1364/OE.26.020089</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-line-of-sight imaging has attracted more attentions for its wide
applications.Even though ultrasensitive cameras or detectors with high
time-resolution are available, current back-projection methods are still
powerless to acquire a satisfying reconstruction of multiple hidden objects due
to severe aliasing artifacts. Here, a novel back-projection method is developed
to reconstruct multiple hidden objects. Our method considers decomposing all
the ellipsoids in a confidence map into several clusters belonging to different
objects (namely ellipsoid mode decomposition), and then reconstructing the
objects individually from their ellipsoid modes by filtering and thresholding,
respectively. Importantly, the simulated and experimental results demonstrate
that this method can effectively eliminate the impacts of aliasing artifacts
and exhibits potential advantages in separating, locating and recovering
multiple hidden objects, which might be a good base for reconstructing complex
non-line-ofsight scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04549</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04549</id><created>2018-05-11</created><authors><author><keyname>Khodabandehlou</keyname><forenames>H.</forenames></author><author><keyname>Fadali</keyname><forenames>M. Sami</forenames></author></authors><title>Networked Model Predictive Control Using a Wavelet Neural Network</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this study, we use a wavelet neural network with a feedforward component
and a model predictive controller for online nonlinear system identification
over a communication network. The wavelet neural network (WNN) performs the
online identification of the nonlinear system. The model predictive controller
(MPC) uses the model to predict the future outputs of the system over an
extended prediction horizon and calculates the optimal future inputs by
minimizing a controller cost function. The Lyapunov theory is used to prove the
stability of the MPC. We apply the methodology to the online identification and
control of an unmanned autonomous vehicle. Simulation results show that the MPC
with extended prediction horizon can effectively control the system in the
presence of fixed or random network delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04656</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04656</id><created>2018-05-12</created><authors><author><keyname>Huang</keyname><forenames>Yongwei</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>An Inner SOCP Approximate Algorithm for Robust Adaptive Beamforming for
  General-Rank Signal Model</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The worst-case robust adaptive beamforming problem for general-rank signal
model is considered. Its formulation is to maximize the worst-case
signal-to-interference-plus-noise ratio (SINR), incorporating a positive
semidefinite constraint on the actual covariance matrix of the desired signal.
In the literature, semidefinite program (SDP) techniques, together with others,
have been applied to approximately solve this problem. Herein an inner
second-order cone program (SOCP) approximate algorithm is proposed to solve it.
In particular, a sequence of SOCPs are constructed and solved, while the SOCPs
have the nondecreasing optimal values and converge to a locally optimal value
(it is in fact a globally optimal value through our extensive simulations). As
a result, our algorithm does not use computationally heavy SDP relaxation
technique. To validate our inner approximation results, simulation examples are
presented, and they demonstrate the improved performance of the new robust
beamformer in terms of the averaged cpu-time (indicating how fast the
algorithms converge) in a high signal-to-noise region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04703</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04703</id><created>2018-05-12</created><authors><author><keyname>Ahmadi</keyname><forenames>Amirmasoud</forenames></author><author><keyname>Shalchyan</keyname><forenames>Vahid</forenames></author><author><keyname>Daliri</keyname><forenames>Mohammad Reza</forenames></author></authors><title>A New Method for Epileptic Seizure Classification in EEG Using Adapted
  Wavelet Packets</title><categories>eess.SP</categories><comments>Electroencephalography, Wavelet packets transform (WPT), Support
  vector machines (SVMs), Electric Electronics, Computer Science, Biomedical
  Engineerings' Meeting (EBBT), 2017</comments><doi>10.1109/EBBT.2017.7956756</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG), as the most common tool for epileptic seizure
classification, contains useful information about different physiological
states of the brain. Seizure related features in EEG signals can be better
identified when localized in time frequency basis projections. In this work, a
novel method for epileptic seizure classification based on wavelet packets
(WPs) is presented in which both mother wavelet function and WP bases are
adapted a posteriori to improve the seizure classification. A support vector
machine (SVM) as classifier is used for seizure versus non-seizure EEG segment
classification. In order to evaluate the proposed algorithm, a publicly
available dataset containing different groups patient with epilepsy and healthy
individuals are used. The obtained results indicate that the proposed method
outperforms some previously proposed algorithms in epileptic seizure
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04792</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04792</id><created>2018-05-12</created><authors><author><keyname>Li</keyname><forenames>Dingzeyu</forenames></author><author><keyname>Langlois</keyname><forenames>Timothy R.</forenames></author><author><keyname>Zheng</keyname><forenames>Changxi</forenames></author></authors><title>Scene-Aware Audio for 360\textdegree{} Videos</title><categories>cs.GR cs.CV cs.ET cs.SD eess.AS</categories><comments>SIGGRAPH 2018, Technical Papers, 12 pages, 17 figures,
  http://www.cs.columbia.edu/cg/360audio/</comments><doi>10.1145/3197517.3201391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although 360\textdegree{} cameras ease the capture of panoramic footage, it
remains challenging to add realistic 360\textdegree{} audio that blends into
the captured scene and is synchronized with the camera motion. We present a
method for adding scene-aware spatial audio to 360\textdegree{} videos in
typical indoor scenes, using only a conventional mono-channel microphone and a
speaker. We observe that the late reverberation of a room's impulse response is
usually diffuse spatially and directionally. Exploiting this fact, we propose a
method that synthesizes the directional impulse response between any source and
listening locations by combining a synthesized early reverberation part and a
measured late reverberation tail. The early reverberation is simulated using a
geometric acoustic simulation and then enhanced using a frequency modulation
method to capture room resonances. The late reverberation is extracted from a
recorded impulse response, with a carefully chosen time duration that separates
out the late reverberation from the early reverberation. In our validations, we
show that our synthesized spatial audio matches closely with recordings using
ambisonic microphones. Lastly, we demonstrate the strength of our method in
several applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04922</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04922</id><created>2018-05-13</created><authors><author><keyname>Chen</keyname><forenames>Leian</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>An Enhanced MPPT Method based on ANN-assisted Sequential Monte Carlo and
  Quickest Change Detection</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of a photovoltaic system is subject to varying environmental
conditions, and it becomes more challenging to track the maximum power point
(MPP) and maintain the optimal performance when partial shading occurs. In this
paper, we propose an enhanced maximum power point tracking (MPPT) method
utilizing the state estimation by the sequential Monte Carlo (SMC) filtering
which is assisted by the prediction of MPP via an artificial neural network
(ANN). A state-space model for the sequential estimation of MPP is proposed in
the framework of incremental conductance (I-C) MPPT approach, and the ANN model
based on the observed voltage and current or irradiance data predicts the
global MPP (GMPP) to refine the estimation by SMC. Moreover, a quick
irrandiance change detection method is applied, such that the SMC-based MPPT
method resorts to the assistance from ANN only when partial shading is
detected. Simulation results show that the proposed enhanced MPPT method
achieves high efficiency and is robust to rapid irradiance change under
different noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04979</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.04979</id><created>2018-05-13</created><authors><author><keyname>Khodabandehlou</keyname><forenames>Hamid</forenames></author><author><keyname>Niazazari</keyname><forenames>Iman</forenames></author><author><keyname>Livani</keyname><forenames>Hanif</forenames></author><author><keyname>Fadali</keyname><forenames>M. Sami</forenames></author></authors><title>Anomaly Classification in Distribution Networks Using a Quotient
  Gradient System</title><categories>eess.SP</categories><comments>8 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The classification of anomalies or sudden changes in power networks versus
normal abrupt changes or switching actions is essential to take appropriate
maintenance actions that guarantee the quality of power delivery. This issue
has increased in importance and has become more complicated with the
proliferation of volatile resources that introduce variability, uncertainty,
and intermittency in circuit behavior that can be observed as variations in
voltage and current phasors. This makes diagnostics applications more
challenging. This paper proposes using quotient gradient system (QGS) to train
two-stage partially recurrent neural network to improve anomaly classification
rate in power distribution networks using high-fidelity data from micro-phasor
measurement units (PMUs). QGS is a systematic approach to finding solutions of
constraint satisfaction problems. We transform the PMUs data from the power
network into a constraint satisfaction problem and use QGS to train a neural
network by solving the resulting optimization problem. Simulation results show
that the proposed supervised classification method can reliably distinguish
between different anomalies in power distribution networks. Comparison with
other neural network classifiers shows that QGS trained networks provide
significantly better classification. Sensitivity analysis is performed
concerning the number of PMUs, reporting rates, noise level and early versus
late data stream fusion frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05013</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05013</id><created>2018-05-14</created><authors><author><keyname>Hu</keyname><forenames>Yue</forenames></author><author><keyname>Liu</keyname><forenames>Xiaohan</forenames></author><author><keyname>Jacob</keyname><forenames>Mathews</forenames></author></authors><title>Adaptive structured low rank algorithm for MR image recovery</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an adaptive structured low rank algorithm to recover MR images
from their undersampled Fourier coefficients. The image is modeled as a
combination of a piecewise constant component and a piecewise linear component.
The Fourier coefficients of each component satisfy an annihilation relation,
which results in a structured Toeplitz matrix. We exploit the low rank property
of the matrices to formulate a combined regularized optimization problem, which
can be solved efficiently. Numerical experiments indicate that the proposed
algorithm provides improved recovery performance over the previously proposed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05065</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05065</id><created>2018-05-14</created><updated>2019-01-10</updated><authors><author><keyname>Santos</keyname><forenames>Irene</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author></authors><title>Self and turbo iterations for MIMO receivers and large-scale systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a turbo soft detector based on the expectation propagation
(EP) algorithm for large-scale multiple-input multiple-output (MIMO) systems.
Optimal detection in MIMO systems becomes computationally unfeasible for
high-order modulations and/or large number of antennas. In this situation, the
linear minimum mean square error (LMMSE) exhibits a low-complexity with a good
performance, however far from optimal. To improve the performance, the EP
algorithm can be used. In this paper, we review previous EP-based detectors and
enhance their estimation in terms of complexity and performance. Specifically,
we improve the convergence of the self-iterated EP stage by replacing the
uniform prior by a non-uniform one, which better characterizes the information
returned by the decoder once the turbo procedure starts. We also review the EP
parameters to avoid instabilities when using high-order modulations and to
reduce the computational complexity. Simulation results illustrate the
robustness and enhanced performance of this novel detector in comparison with
previous approaches found in the literature. Results also show that the
proposed detector is robust in the presence of imperfect channel state
information (CSI).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05254</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05254</id><created>2018-05-14</created><updated>2019-01-17</updated><authors><author><keyname>Jamal</keyname><forenames>Hosseinali</forenames></author><author><keyname>Matolak</keyname><forenames>David W.</forenames></author></authors><title>PAPR Analysis for Dual-Polarization FBMC</title><categories>eess.SP</categories><comments>This paper has been published in IEEE MILCOM Conference 2018. Some
  results has been changed from first version</comments><doi>10.1109/MILCOM.2018.8599689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent work we proposed a new radio access technique based on filter
bank multi-carrier (FBMC) modulation using two orthogonal polarizations:
dual-polarization FBMC (DP-FBMC). We showed that with good cross-polarization
discrimination (XPD), DP-FBMC solves the intrinsic imaginary interference
shortcoming of FBMC without extra processing. DP-FBMC also has other
interesting advantages over cyclic prefix orthogonal frequency-division
multiplexing (CP-OFDM) and FBMC such as more robustness in dispersive channels,
and it is also more robust to receiver carrier frequency offset (CFO) and
timing offset (TO). In this paper we analyze the peak to average power ratio
(PAPR) of DP-FBMC and compare PAPR simulation results with that of conventional
FBMC, for different prototype filters and overlapping factors. According to the
analysis and results, with a proper choice of prototype filter, DP-FBMC has
comparable PAPR to FBMC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05324</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05324</id><created>2018-05-12</created><authors><author><keyname>Raissi</keyname><forenames>Tina</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Tibo</keyname><forenames>Alessandro</forenames><affiliation>University of Florence</affiliation></author><author><keyname>Bientinesi</keyname><forenames>Paolo</forenames><affiliation>RWTH Aachen University</affiliation></author></authors><title>Extended pipeline for content-based feature engineering in music genre
  recognition</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a feature engineering pipeline for the construction of musical
signal characteristics, to be used for the design of a supervised model for
musical genre identification. The key idea is to extend the traditional
two-step process of extraction and classification with additive stand-alone
phases which are no longer organized in a waterfall scheme. The whole system is
realized by traversing backtrack arrows and cycles between various stages. In
order to give a compact and effective representation of the features, the
standard early temporal integration is combined with other selection and
extraction phases: on the one hand, the selection of the most meaningful
characteristics based on information gain, and on the other hand, the inclusion
of the nonlinear correlation between this subset of features, determined by an
autoencoder. The results of the experiments conducted on GTZAN dataset reveal a
noticeable contribution of this methodology towards the model's performance in
classification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05500</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05500</id><created>2018-05-14</created><authors><author><keyname>Rosas</keyname><forenames>Fernando</forenames></author><author><keyname>Chen</keyname><forenames>Kwang-Cheng</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author></authors><title>Social diversity for reducing the impact of information cascades on
  social learning</title><categories>eess.SP</categories><comments>10 pages, 4 figures, SITB2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collective behavior in online social media and networks is known to be
capable of generating non-intuitive dynamics associated with crowd wisdom and
herd behaviour. Even though these topics have been well-studied in social
science, the explosive growth of Internet computing and e-commerce makes urgent
to understand their effects within the digital society. In this work we explore
how the stochasticity introduced by social diversity can help agents involved
in a inference process to improve their collective performance. Our results
show how social diversity can reduce the undesirable effects of information
cascades, in which rational agents choose to ignore personal knowledge in order
to follow a predominant social behaviour. Situations where social diversity is
never desirable are also distinguished, and consequences of these findings for
engineering and social scenarios are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05502</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05502</id><created>2018-05-14</created><updated>2018-12-04</updated><authors><author><keyname>Chen</keyname><forenames>Jia</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Nonlinear Dimensionality Reduction for Discriminative Analytics of
  Multiple Datasets</title><categories>cs.LG eess.SP stat.AP stat.ML</categories><comments>final version</comments><doi>10.1109/TSP.2018.2885478</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal component analysis (PCA) is widely used for feature extraction and
dimensionality reduction, with documented merits in diverse tasks involving
high-dimensional data. Standard PCA copes with one dataset at a time, but it is
challenged when it comes to analyzing multiple datasets jointly. In certain
data science settings however, one is often interested in extracting the most
discriminative information from one dataset of particular interest (a.k.a.
target data) relative to the other(s) (a.k.a. background data). To this end,
this paper puts forth a novel approach, termed discriminative (d) PCA, for such
discriminative analytics of multiple datasets. Under certain conditions, dPCA
is proved to be least-squares optimal in recovering the component vector unique
to the target data relative to background data. To account for nonlinear data
correlations, (linear) dPCA models for one or multiple background datasets are
generalized through kernel-based learning. Interestingly, all dPCA variants
admit an analytical solution obtainable with a single (generalized) eigenvalue
decomposition. Finally, corroborating dimensionality reduction tests using both
synthetic and real datasets are provided to validate the effectiveness of the
proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05533</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05533</id><created>2018-05-14</created><updated>2020-01-24</updated><authors><author><keyname>Bamieh</keyname><forenames>Bassam</forenames></author></authors><title>Discovering Transforms: A Tutorial on Circulant Matrices, Circular
  Convolution, and the Discrete Fourier Transform</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How could the Fourier and other transforms be naturally discovered if one
didn't know how to postulate them? In the case of the Discrete Fourier
Transform (DFT), we show how it arises naturally out of analysis of circulant
matrices. In particular, the DFT can be derived as the change of basis that
simultaneously diagonalizes all circulant matrices. In this way, the DFT arises
naturally from a linear algebra question about a set of matrices. Rather than
thinking of the DFT as a signal transform, it is more natural to think of it as
a single change of basis that renders an entire set of mutually-commuting
matrices into simple, diagonal forms. The DFT can then be ``discovered'' by
solving the eigenvalue/eigenvector problem for a special element in that set. A
brief outline is given of how this line of thinking can be generalized to
families of linear operators, leading to the discovery of the other common
Fourier-type transforms, as well as its connections with group representations
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05574</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05574</id><created>2018-05-15</created><authors><author><keyname>He</keyname><forenames>Di</forenames></author><author><keyname>Lim</keyname><forenames>Boon Pang</forenames></author><author><keyname>Yang</keyname><forenames>Xuesong</forenames></author><author><keyname>Hasegawa-Johnson</keyname><forenames>Mark</forenames></author><author><keyname>Chen</keyname><forenames>Deming</forenames></author></authors><title>Improved ASR for Under-Resourced Languages Through Multi-Task Learning
  with Acoustic Landmarks</title><categories>cs.CL cs.SD eess.AS</categories><comments>Submitted in Interspeech2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Furui first demonstrated that the identity of both consonant and vowel can be
perceived from the C-V transition; later, Stevens proposed that acoustic
landmarks are the primary cues for speech perception, and that steady-state
regions are secondary or supplemental. Acoustic landmarks are perceptually
salient, even in a language one doesn't speak, and it has been demonstrated
that non-speakers of the language can identify features such as the primary
articulator of the landmark. These factors suggest a strategy for developing
language-independent automatic speech recognition: landmarks can potentially be
learned once from a suitably labeled corpus and rapidly applied to many other
languages. This paper proposes enhancing the cross-lingual portability of a
neural network by using landmarks as the secondary task in multi-task learning
(MTL). The network is trained in a well-resourced source language with both
phone and landmark labels (English), then adapted to an under-resourced target
language with only word labels (Iban). Landmark-tasked MTL reduces
source-language phone error rate by 2.9% relative, and reduces target-language
word error rate by 1.9%-5.9% depending on the amount of target-language
training data. These results suggest that landmark-tasked MTL causes the DNN to
learn hidden-node features that are useful for cross-lingual adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05786</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05786</id><created>2018-05-15</created><authors><author><keyname>Peng</keyname><forenames>Tong</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>An Adaptive Optimal Mapping Selection Algorithm for PNC using Variable
  QAM Modulation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifth generation (5G) wireless networks will need to serve much higher user
densities than existing 4G networks, and will therefore require an enhanced
radio access network (RAN) infrastructure. Physical layer network coding (PNC)
has been shown to enable such high densities with much lower backhaul load than
approaches such as Cloud-RAN and coordinated multipoint (CoMP). In this letter,
we present an engineering applicable PNC scheme which allows different
cooperating users to use different modulation schemes, according to the
relative strength of their channels to a given access point. This is in
contrast with compute-and-forward and previous PNC schemes which are designed
for two-way relay channel. A two-stage search algorithm to identify the optimum
PNC mappings for given channel state information and modulation is proposed in
this letter. Numerical results show that the proposed scheme achieves low bit
error rate with reduced backhaul load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05811</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05811</id><created>2018-05-14</created><authors><author><keyname>Bolletta</keyname><forenames>Paolo</forenames></author><author><keyname>Carboni</keyname><forenames>Massimo</forenames></author><author><keyname>Di Peo</keyname><forenames>Andrea</forenames></author><author><keyname>Gervasi</keyname><forenames>Americo</forenames></author><author><keyname>Puccio</keyname><forenames>Lorenzo</forenames></author><author><keyname>Vuagnin</keyname><forenames>Gloria</forenames></author></authors><title>Alien wavelength technique to enhance garr optical network</title><categories>cs.NI eess.SP</categories><comments>This paper has been accepted and will be presented at Fotonica 2018.
  arXiv admin note: text overlap with arXiv:1805.04278</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GARR optical network used to be composed of two separate optical network
domains on its national infrastructure. With the aim to integrate these two
domains and deliver high performance services all over its infrastructure, we
implemented the so called alien wavelength technique, thus improving the
overall efficiency of the Italian research and education network in a
cost-effective way. This paper describes the activity, results, and our
experience in the integration of alien wavelengths in a production environment,
with a special emphasis on deployment and operational issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05826</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05826</id><created>2018-05-15</created><authors><author><keyname>Seki</keyname><forenames>Hiroshi</forenames></author><author><keyname>Hori</keyname><forenames>Takaaki</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Roux</keyname><forenames>Jonathan Le</forenames></author><author><keyname>Hershey</keyname><forenames>John R.</forenames></author></authors><title>A Purely End-to-end System for Multi-speaker Speech Recognition</title><categories>cs.SD cs.CL eess.AS stat.ML</categories><comments>ACL 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there has been growing interest in multi-speaker speech
recognition, where the utterances of multiple speakers are recognized from
their mixture. Promising techniques have been proposed for this task, but
earlier works have required additional training data such as isolated source
signals or senone alignments for effective learning. In this paper, we propose
a new sequence-to-sequence framework to directly decode multiple label
sequences from a single speech sequence by unifying source separation and
speech recognition functions in an end-to-end manner. We further propose a new
objective function to improve the contrast between the hidden vectors to avoid
generating similar hypotheses. Experimental results show that the model is
directly able to learn a mapping from a speech mixture to multiple label
sequences, achieving 83.1 % relative improvement compared to a model trained
without the proposed objective. Interestingly, the results are comparable to
those produced by previous end-to-end works featuring explicit separation and
recognition modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05836</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05836</id><created>2018-05-07</created><authors><author><keyname>Raee</keyname><forenames>Vahid Maleki</forenames></author><author><keyname>Naboulsi</keyname><forenames>Diala</forenames></author><author><keyname>Glitho</keyname><forenames>Roch</forenames></author></authors><title>Energy Efficient Task Assignment in Virtualized Wireless Sensor Networks</title><categories>eess.SP cs.DC cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) are being used extensively today in various
domains. However, they are traditionally deployed with applications embedded in
them which precludes their re-use for new applications. Nowadays,
virtualization enables several applications on a same WSN by abstracting the
physical resources (i.e. sensing capabilities) into logical ones. However, this
comes at a cost, including an energy cost. It is therefore critical to ensure
the efficient allocation of these resources. In this paper, we study the
problem of assigning application sensing tasks to sensor devices, in
virtualized WSNs. Our goal is to minimize the overall energy consumption
resulting from the assignment. We focus on the static version of the problem
and formulate it using Integer Linear Programming (ILP), while accounting for
sensor nodes' available energy and virtualization overhead. We solve the
problem over different scenarios and compare the obtained solution to the case
of a traditional WSN, i.e. one with no support for virtualization. Our results
show that significant energy can be saved when tasks are appropriately assigned
in a WSN that supports virtualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05837</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05837</id><created>2018-05-03</created><authors><author><keyname>Alhindi</keyname><forenames>Taha J.</forenames></author><author><keyname>Kalra</keyname><forenames>Shivam</forenames></author><author><keyname>Ng</keyname><forenames>Ka Hin</forenames></author><author><keyname>Afrin</keyname><forenames>Anika</forenames></author><author><keyname>Tizhoosh</keyname><forenames>Hamid R.</forenames></author></authors><title>Comparing LBP, HOG and Deep Features for Classification of
  Histopathology Images</title><categories>eess.IV</categories><comments>Accepted for publication in proceedings of the IEEE World Congress on
  Computational Intelligence (IEEE WCCI), Rio de Janeiro, Brazil, 8-3 July,
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical image analysis has become a topic under the spotlight in recent
years. There is a significant progress in medical image research concerning the
usage of machine learning. However, there are still numerous questions and
problems awaiting answers and solutions, respectively. In the present study,
comparison of three classification models is conducted using features extracted
using local binary patterns, the histogram of gradients, and a pre-trained deep
network. Three common image classification methods, including support vector
machines, decision trees, and artificial neural networks are used to classify
feature vectors obtained by different feature extractors. We use KIMIA Path960,
a publicly available dataset of $960$ histopathology images extracted from $20$
different tissue scans to test the accuracy of classification and feature
extractions models used in the study, specifically for the histopathology
images. SVM achieves the highest accuracy of $90.52\%$ using local binary
patterns as features which surpasses the accuracy obtained by deep features,
namely $81.14\%$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05840</identifier>
 <datestamp>2018-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05840</id><created>2018-04-30</created><authors><author><keyname>Carrara</keyname><forenames>Sandro</forenames></author><author><keyname>Georgiou</keyname><forenames>Pantelis</forenames></author></authors><title>Body Dust: Miniaturized Highly-integrated Low Power Sensing for Remotely
  Powered Drinkable CMOS Bioelectronics</title><categories>physics.app-ph eess.SP physics.bio-ph physics.med-ph</categories><comments>9 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to introduce current advances in technology that
could enable the development of fully drinkable and autonomous bio-electronic
CMOS sensors in the form of dust particles, capable of identifying the source
of a disease by targeting a specific region in organs and tissue such as a
tumor mass and automatically sending diagnostic information wirelessly outside
the body. We call this swarm of sensing dust particles Body Dust. A diagnostic
system in the form of Body Dust would need to be small enough to support free
circulation in human tissues, which requires a total size of less than 10 um3,
in order to mimic the typical sizes of a blood cell (e.g., red cells have the
diameter around 7 {\mu}m). Whilst with present state-of-the-art in CMOS
technology, this requirement in terms of size is currently un-feasible, recent
research has advanced technology such that we can begin to work towards such an
approach. Therefore, we present here the current limits of CMOS technology as
well as the challenges related to the development of such a system. Towards
this goal, this article presents the theoretical feasibility to obtain the
first ever-conceived sub-10-um Bio/CMOS integrated circuit with biosensing
capability to provide diagnostic telemetry once self-located in human tissue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05884</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05884</id><created>2018-05-15</created><authors><author><keyname>Reiskarimian</keyname><forenames>Negar</forenames></author><author><keyname>Dastjerdi</keyname><forenames>Mahmood Baraani</forenames></author><author><keyname>Zhou</keyname><forenames>Jin</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Harish</forenames></author></authors><title>Analysis and Design of Commutation-Based Circulator-Receivers for
  Integrated Full-Duplex Wireless</title><categories>eess.SP</categories><comments>Submitted to IEEE Journal of Solid-State Circuits (JSSC). This is the
  initial submission version. The final version has been recently accepted for
  publication</comments><doi>10.1109/JSSC.2018.2828827</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previously, we presented a non-magnetic, nonreciprocal N-path-filter-based
circulator-receiver (circ.-RX) architecture for full-duplex (FD) wireless which
merges a commutation-based linear periodically-time-varying (LPTV) non-magnetic
circulator with a down-converting mixer and directly provides the baseband (BB)
receiver signals at its output, while suppressing the noise contribution of one
set of the commutating switches. The architecture also incorporates an on-chip
balance network to enhance the transmitter (TX)-receiver (RX) isolation. In
this paper, we present a detailed analysis of the architecture, including a
noise analysis and an analysis of the effect of the balance network. The
analyses are verified by simulation and measurement results of a 65 nm CMOS 750
MHz circulator-receiver prototype. The circulator-receiver can handle up to +8
dBm of TX power, with 8 dB noise figure (NF) and 40 dB average isolation over
20 MHz RF bandwidth (BW). In conjunction with digital self-interference (SI)
and its third-order intermodulation (IM3) cancellation, the FD circ.-RX
demonstrates 80 dB overall SI suppression for up to +8 dBm TX average output
power. The claims are also verified through an FD demonstration where a -50 dBm
weak desired received signal is recovered while transmitting a 0 dBm
average-power OFDM-like TX signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05902</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05902</id><created>2018-05-15</created><updated>2018-12-19</updated><authors><author><keyname>Lunglmayr</keyname><forenames>Michael</forenames></author><author><keyname>Amaral</keyname><forenames>Gustavo C.</forenames></author></authors><title>Linearized Bregman Iterations for Automatic Optical Fiber Fault Analysis</title><categories>eess.SP</categories><comments>33 pages, 9 figures</comments><journal-ref>IEEE Transactions on Instrumentation and Measurement, 2018</journal-ref><doi>10.1109/TIM.2018.2882258</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervision of the physical layer of optical networks is an extremely
relevant subject. To detect fiber faults, single-ended solutions such as the
Optical Time Domain Reflectometer (OTDR) allow for precise measurements of
fault profiles. Combining the OTDR with a signal processing approach for
high-dimensional sparse parameter estimation allows for automated and reliable
results in reduced time. In this work, a measurement system composed of a
Photon-Counting OTDR data acquisition unit and a processing unit based on a
Linearized Bregman Iterations algorithm for automatic fault finding is
proposed. An in-depth comparative study of the proposed algorithm's
fault-finding prowess in the presence of noise is presented. Characteristics
such as sensitivity, specificity, processing time, and complexity, are analysed
in simulated environments. Real-life measurements that are conducted using the
Photon-Counting OTDR subsystem for data acquisition and the Linearized
Bregman-based processing unit for automated data analysis demonstrated accurate
results. It is concluded that the proposed measurement system is particularly
well suited to the task of fault finding. The natural characteristic of the
algorithm fosters embedding the solution in digital hardware, allowing for
reduced costs and processing time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05913</identifier>
 <datestamp>2018-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05913</id><created>2018-05-15</created><authors><author><keyname>Asl</keyname><forenames>Masoud Elhami</forenames></author><author><keyname>Rahimpour</keyname><forenames>Masoomeh</forenames></author><author><keyname>Merati</keyname><forenames>Mahmoud Reza</forenames></author><author><keyname>Panahi</keyname><forenames>Amir Hossein</forenames></author><author><keyname>Gholami</keyname><forenames>Kamran</forenames></author></authors><title>Pre-Hospital Management of Acute Myocardial Infarction Using
  Tele-Electrocardiography System</title><categories>eess.SP</categories><comments>2nd Conference on Novel Approaches of Biomedical Engineering in
  Cardiovascular Diseases</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comprehensive survey revealed that many patients of Acute Myocardial
Infarction reach to the hospital so late to deliver an effective treatment.
This leads to poor treatment outcome which increases the mortality rates.
Multiple reasons such as lack of diagnostic facilities in the rural health care
centers and absence of cardiologists in Emergency Rooms inhibit the timely
treatment. In this study, we aimed to develop an effective system to
pre-hospital management of Acute Myocardial Infarction. The effectiveness of
early thrombolysis in Myocardial Infarction is well established, particularly
with regard to its positive effect on reducing the mortality rates. Our
proposed system by using tele-electrocardiography technology enables
cardiologist to analyze the patient's signal far away from a medical center.
This system transmits the collected ECG signal as well some vital signs to the
medical center by using internet network. In order to review and analyze the
recorded data, an ECG Viewer software is added to this system. The automatic
measurement algorithm and some additional tools embedded in the ECG Viewer
provide a convenient platform for ECG signal analysis by the cardiologist in
the medical center. The designed system has been tested as a prototype in
Tehran Emergency Service Center. The evaluation of the proposed system shows
acceptable results in recording, transmission, and accurate analysis of ECG
signals to early diagnosis of Acute Myocardial Infarction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05929</identifier>
 <datestamp>2018-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.05929</id><created>2018-05-11</created><updated>2018-09-21</updated><authors><author><keyname>Chu</keyname><forenames>Man</forenames></author><author><keyname>Li</keyname><forenames>Hang</forenames></author><author><keyname>Liao</keyname><forenames>Xuewen</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Reinforcement Learning based Multi-Access Control and Battery Prediction
  with Energy Harvesting in IoT Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy harvesting (EH) is a promising technique to fulfill the long-term and
self-sustainable operations for Internet of things (IoT) systems. In this
paper, we study the joint access control and battery prediction problems in a
small-cell IoT system including multiple EH user equipments (UEs) and one base
station (BS) with limited uplink access channels. Each UE has a rechargeable
battery with finite capacity. The system control is modeled as a Markov
decision process without complete prior knowledge assumed at the BS, which also
deals with large sizes in both state and action spaces. First, to handle the
access control problem assuming causal battery and channel state information,
we propose a scheduling algorithm that maximizes the uplink transmission sum
rate based on reinforcement learning (RL) with deep Q-network (DQN)
enhancement. Second, for the battery prediction problem, with a fixed
round-robin access control policy adopted, we develop a RL based algorithm to
minimize the prediction loss (error) without any model knowledge about the
energy source and energy arrival process. Finally, the joint access control and
battery prediction problem is investigated, where we propose a two-layer RL
network to simultaneously deal with maximizing the sum rate and minimizing the
prediction loss: the first layer is for battery prediction, the second layer
generates the access policy based on the output from the first layer.
Experiment results show that the three proposed RL algorithms can achieve
better performances compared with existing benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06095</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06095</id><created>2018-05-15</created><authors><author><keyname>Ioannidis</keyname><forenames>Vassilis N.</forenames></author><author><keyname>Shen</keyname><forenames>Yanning</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Semi-Blind Inference of Topologies and Dynamical Processes over Graphs</title><categories>cs.LG eess.SP stat.ML</categories><doi>10.1109/TSP.2019.2903025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network science provides valuable insights across numerous disciplines
including sociology, biology, neuroscience and engineering. A task of major
practical importance in these application domains is inferring the network
structure from noisy observations at a subset of nodes. Available methods for
topology inference typically assume that the process over the network is
observed at all nodes. However, application-specific constraints may prevent
acquiring network-wide observations. Alleviating the limited flexibility of
existing approaches, this work advocates structural models for graph processes
and develops novel algorithms for joint inference of the network topology and
processes from partial nodal observations. Structural equation models (SEMs)
and structural vector autoregressive models (SVARMs) have well-documented
merits in identifying even directed topologies of complex graphs; while SEMs
capture contemporaneous causal dependencies among nodes, SVARMs further account
for time-lagged influences. This paper develops algorithms that iterate between
inferring directed graphs that &quot;best&quot; fit the data, and estimating the network
processes at reduced computational complexity by leveraging tools related to
Kalman smoothing. To further accommodate delay-sensitive applications, an
online joint inference approach is put forth that even tracks time-evolving
topologies. Furthermore, conditions for identifying the network topology given
partial observations are specified. It is proved that the required number of
observations for unique identification reduces significantly when the network
structure is sparse. Numerical tests with synthetic as well as real datasets
corroborate the effectiveness of the novel approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06236</identifier>
 <datestamp>2018-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06236</id><created>2018-05-16</created><authors><author><keyname>Ghadiri</keyname><forenames>Hossein</forenames></author><author><keyname>Fouladi</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Rahmim</keyname><forenames>Arman</forenames></author></authors><title>An Analysis Scheme for Investigation of Effects of Various Parameters on
  Signals in Acoustic-Resolution Photoacoustic Microscopy of Mice Brain: a
  Simulation Study</title><categories>cs.CE eess.SP</categories><comments>11 pages, 12 figure, 36 references</comments><journal-ref>Frontiers in Biomedical Technologies 4, no. 3-4 (2018): 59-69</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Photoacoustic spectral analysis is a novel tool for studying various
parameters affecting signals in Photoacoustic microscopy. But only observing
frequency components of photoacoustic signals doesn't make enough data for a
desirable analysis. Thus a hybrid time-domain and frequency-domain analysis
scheme has been proposed to investigate effects of various parameters like
depth of microscopy, laser focal spot size and contrast agent concentration on
Photoacoustic signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06239</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06239</id><created>2018-05-16</created><updated>2018-05-18</updated><authors><author><keyname>Zhou</keyname><forenames>Shiyu</forenames></author><author><keyname>Dong</keyname><forenames>Linhao</forenames></author><author><keyname>Xu</keyname><forenames>Shuang</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>A Comparison of Modeling Units in Sequence-to-Sequence Speech
  Recognition with the Transformer on Mandarin Chinese</title><categories>eess.AS cs.CL cs.SD</categories><comments>arXiv admin note: substantial text overlap with arXiv:1804.10752</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The choice of modeling units is critical to automatic speech recognition
(ASR) tasks. Conventional ASR systems typically choose context-dependent states
(CD-states) or context-dependent phonemes (CD-phonemes) as their modeling
units. However, it has been challenged by sequence-to-sequence attention-based
models, which integrate an acoustic, pronunciation and language model into a
single neural network. On English ASR tasks, previous attempts have already
shown that the modeling unit of graphemes can outperform that of phonemes by
sequence-to-sequence attention-based model.
  In this paper, we are concerned with modeling units on Mandarin Chinese ASR
tasks using sequence-to-sequence attention-based models with the Transformer.
Five modeling units are explored including context-independent phonemes
(CI-phonemes), syllables, words, sub-words and characters. Experiments on HKUST
datasets demonstrate that the lexicon free modeling units can outperform
lexicon related modeling units in terms of character error rate (CER). Among
five modeling units, character based model performs best and establishes a new
state-of-the-art CER of $26.64\%$ on HKUST datasets without a hand-designed
lexicon and an extra language model integration, which corresponds to a $4.8\%$
relative improvement over the existing best CER of $28.0\%$ by the joint
CTC-attention based encoder-decoder network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06343</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06343</id><created>2018-05-16</created><authors><author><keyname>Guaragnella</keyname><forenames>Cataldo</forenames></author><author><keyname>D'Orazio</keyname><forenames>Tiziana</forenames></author></authors><title>B.SAR - Blind SAR Data Focusing</title><categories>eess.SP</categories><report-no>ACCEPTED (10789-40): ERS18-RS107-23. Remote Sensing 2018, Berlin,
  Germany, 10-13 September</report-no><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Synthetic Aperture RADAR is a radar imaging technique in which the relative
motion of the sensor is used to synthesize a very long antenna and obtain high
spatial resolution. The increasing interest of the scientific community to
simplify SAR sensors and develop automatic system to quickly obtain a
sufficiently good precision image is fostered by the will of developing
low-cost/light-weight SAR systems to be carried by drones. Standard SAR raw
data processing techniques assume uniform motion of the satellite and a fixed
antenna beam pointing sideway orthogonally to the motion path, assumed
rectilinear. In the same hypothesis, a novel blind data focusing technique is
presented, able to obtain good quality images of the inspected area without the
use of ancillary data information. Despite SAR data processing is a well
established imaging technology that has become fundamental in several fields
and applications, in this paper a novel approach has been used to exploit
coherent illumination, demonstrating the possibility of extracting a large part
of the ancillary data information from the raw data itself, to be used in the
focusing procedure. Preliminary results are presented for ERS raw data
focusing. The proposed Matlab software is distributed under the Noncommercial,
Share Alike 4.0, International Creative Common license by the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06350</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06350</id><created>2018-05-16</created><updated>2018-08-20</updated><authors><author><keyname>O'Shea</keyname><forenames>Timothy J.</forenames></author><author><keyname>Roy</keyname><forenames>Tamoghna</forenames></author><author><keyname>West</keyname><forenames>Nathan</forenames></author></authors><title>Approximating the Void: Learning Stochastic Channel Models from
  Observation with Variational Generative Adversarial Networks</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel modeling is a critical topic when considering designing, learning, or
evaluating the performance of any communications system. Most prior work in
designing or learning new modulation schemes has focused on using highly
simplified analytic channel models such as additive white Gaussian noise
(AWGN), Rayleigh fading channels or similar. Recently, we proposed the usage of
a generative adversarial networks (GANs) to jointly approximate a wireless
channel response model (e.g. from real black box measurements) and optimize for
an efficient modulation scheme over it using machine learning. This approach
worked to some degree, but was unable to produce accurate probability
distribution functions (PDFs) representing the stochastic channel response. In
this paper, we focus specifically on the problem of accurately learning a
channel PDF using a variational GAN, introducing an architecture and loss
function which can accurately capture stochastic behavior. We illustrate where
our prior method failed and share results capturing the performance of such as
system over a range of realistic channel distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06403</identifier>
 <datestamp>2018-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06403</id><created>2018-05-01</created><authors><author><keyname>Khasawneh</keyname><forenames>Firas A.</forenames></author><author><keyname>Munch</keyname><forenames>Elizabeth</forenames></author></authors><title>Topological Data Analysis for True Step Detection in Piecewise Constant
  Signals</title><categories>eess.SP cs.CG</categories><doi>10.1098/rspa.2018.0027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a simple yet powerful approach based on topological
data analysis (TDA) for detecting the true steps in a piecewise constant (PWC)
signal. The signal is a two-state square wave with randomly varying
in-between-pulse spacing, and subject to spurious steps at the rising or
falling edges which we refer to as digital ringing. We use persistent homology
to derive mathematical guarantees for the resulting change detection which
enables accurate identification and counting of the true pulses. The approach
is described and tested using both synthetic and experimental data obtained
using an engine lathe instrumented with a laser tachometer. The described
algorithm enables the accurate calculation of the spindle speed with the
appropriate error bounds. The results of the described approach are compared to
the frequency domain approach via Fourier transform. It is found that both our
approach and the Fourier analysis yield comparable results for numerical and
experimental pulses with regular spacing and digital ringing. However, the
described approach significantly outperforms Fourier analysis when the spacing
between the peaks is varied. We also generalize the approach to higher
dimensional PWC signals, although utilizing this extension remains an
interesting question for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06481</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06481</id><created>2018-05-04</created><authors><author><keyname>Bo</keyname><forenames>Zunwang</forenames></author><author><keyname>Gong</keyname><forenames>Wenlin</forenames></author><author><keyname>Han</keyname><forenames>Shensheng</forenames></author></authors><title>A new focal-plane 3D imaging method based on temporal ghost imaging</title><categories>eess.IV</categories><comments>3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new focal-plane three-dimensional (3D) imaging method based on temporal
ghost imaging is proposed and demonstrated. By exploiting the advantages of
temporal ghost imaging, this method enables slow integrating cameras have an
ability of 3D surface imaging in the framework of sequential flood-illumination
and focal-plane detection. The depth information of 3D objects is easily lost
when imaging with traditional cameras, but it can be reconstructed with
high-resolution by temporal correlation between received signals and reference
signals. Combining with a two-dimensional (2D) projection image obtained by one
single shot, a 3D image of the object can be achieved. The feasibility and
performance of this focal-plane 3D imaging method have been verified through
theoretical analysis and numerical experiments in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06499</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06499</id><created>2018-05-16</created><authors><author><keyname>Abarghouyi</keyname><forenames>Hadis</forenames></author><author><keyname>Razavizadeh</keyname><forenames>S. Mohammad</forenames></author><author><keyname>Bjornson</keyname><forenames>Emil</forenames></author></authors><title>QoE-Aware Beamforming Design for Massive MIMO Heterogeneous Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main goals of the future wireless networks is improving the users
quality of experience (QoE). In this paper, we consider the problem of
QoE-based resource allocation in the downlink of a massive multiple-input
multiple-output (MIMO) heterogeneous network (HetNet). The network consists of
a macro cell with a number of small cells embedded in it. The small cells base
stations (BSs) are equipped with a few antennas, while the macro BS is equipped
with a massive number of antennas. We consider the two services Video and Web
Browsing and design the beamforming vectors at the BSs. The objective is to
maximize the aggregated Mean Opinion Score (MOS) of the users under constraints
on the BSs powers and the required quality of service (QoS) of the users. We
also consider extra constraints on the QoE of users to more strongly enforce
the QoE in the beamforming design. To reduce the complexity of the optimization
problem, we suggest suboptimal and computationally efficient solutions. Our
results illustrate that increasing the number of antennas at the BSs and also
increasing the number of small cells antennas in the network leads to a higher
user satisfaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06550</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06550</id><created>2018-05-16</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Graph-Based Resource Allocation with Conflict Avoidance for V2V
  Broadcast Communications</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we present a graph-based resource allocation scheme for
sidelink broadcast vehicle-to-vehicle (V2V) communications. Harnessing
available information on the geographical position of vehicles and spectrum
resources utilization, eNodeBs are capable of allotting the same set of
sidelink resources to several different vehicles in order for them to broadcast
their signals. Hence, vehicles sharing the same resources would ideally be in
different communications clusters for the interference level-generated due to
resource repurposing-to be maintained under control. Within a communications
cluster, it is crucial that vehicles transmit in orthogonal time resources to
prevent conflicts as vehicles-with half-duplex radio interfaces--cannot
transmit and receive simultaneously. In this research, we have envisaged a
solution based on a bipartite graph, where vehicles and spectrum resources are
represented by vertices whereas the edges represent the achievable rate in each
resource based on the signal-to-interference-plus-noise ratio (SINR) that
vehicles perceive. The aforementioned constraint on time orthogonality of
allocated resources can be approached by aggregating conflicting vertices into
macro-vertices which, in addition, narrows the search space yielding a solution
with computational complexity equivalent to the conventional graph matching
problem. We show mathematically and through simulations that the proposed
approach yields an optimal solution. In addition, we provide simulations
showing that the proposed method outperforms other competing approaches,
specially in scenarios with high vehicular density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06567</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06567</id><created>2018-05-16</created><authors><author><keyname>Glendinning</keyname><forenames>Ian</forenames></author><author><keyname>N&#xf6;lle</keyname><forenames>Michael</forenames></author><author><keyname>Hausleitner</keyname><forenames>Christian</forenames></author><author><keyname>Greilinger</keyname><forenames>Erwin</forenames></author></authors><title>Identification of the source of an interferer by comparison with known
  carriers using a single satellite</title><categories>eess.SP</categories><journal-ref>International Journal of Satellite Communications and Networking
  2019;37:269-282</journal-ref><doi>10.1002/sat.1284</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a method for identifying the source of a satellite interferer
using a single satellite. The technique relies on the fact that the strength of
a carrier signal measured at the downlink station varies with time due to a
number of factors, and we use a quantum-inspired algorithm to compute a
'signature' for a signal, which captures part of the pattern of variation that
is characteristic of the uplink antenna. We define a distance measure to
numerically quantify the degree of similarity between two signatures, and by
computing the distances between the signature for an interfering carrier and
the signatures of the known carriers being relayed by the same satellite at the
same time, we can identify the antenna that the interferer originated from, if
a known carrier is being relayed from it. As a proof of concept we evaluate the
performance of the technique using a simple statistical model applied to
measured carrier data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06572</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06572</id><created>2018-05-16</created><authors><author><keyname>Ito</keyname><forenames>Nobutaka</forenames></author><author><keyname>Araki</keyname><forenames>Shoko</forenames></author><author><keyname>Nakatani</keyname><forenames>Tomohiro</forenames></author></authors><title>FastFCA: A Joint Diagonalization Based Fast Algorithm for Audio Source
  Separation Using A Full-Rank Spatial Covariance Model</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A source separation method using a full-rank spatial covariance model has
been proposed by Duong et al. [&quot;Under-determined Reverberant Audio Source
Separation Using a Full-rank Spatial Covariance Model,&quot; IEEE Trans. ASLP, vol.
18, no. 7, pp. 1830-1840, Sep. 2010], which is referred to as full-rank spatial
covariance analysis (FCA) in this paper. Here we propose a fast algorithm for
estimating the model parameters of the FCA, which is named Fast-FCA, and
applicable to the two-source case. Though quite effective in source separation,
the conventional FCA has a major drawback of expensive computation. Indeed, the
conventional algorithm for estimating the model parameters of the FCA requires
frame-wise matrix inversion and matrix multiplication. Therefore, the
conventional FCA may be infeasible in applications with restricted
computational resources. In contrast, the proposed FastFCA bypasses matrix
inversion and matrix multiplication owing to joint diagonalization based on the
generalized eigenvalue problem. Furthermore, the FastFCA is strictly equivalent
to the conventional algorithm. An experiment has shown that the FastFCA was
over 250 times faster than the conventional algorithm with virtually the same
source separation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06611</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06611</id><created>2018-05-17</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Renaudin</keyname><forenames>Olivier</forenames></author><author><keyname>Bas</keyname><forenames>C. Umit</forenames></author><author><keyname>Sangodoyin</keyname><forenames>Seun</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Antenna Switching Sequence Design for Channel Sounding in a Fast
  Time-varying Channel</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, accepted to IEEE International Conference on Communications
  (ICC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the impact of array switching patterns on the
accuracy of parameter estimation of multipath components for a time division
multiplexed (TDM) channel sounder. To measure fast time-varying channels, the
conventional uniform array switching pattern poses a fundamental limit of the
number of antennas that a TDM channel sounder can utilize. We propose a method,
which is based on the simulated annealing algorithm, to find non-uniform array
switching patterns for realistic antenna arrays, so that we can extend the
Doppler estimation range of the channel sounder by suppressing the high
sidelobes in the spatio-temporal ambiguity function. Monte Carlo simulations
demonstrate that the optimal switching sequence leads to significantly smaller
root mean square errors of both direction of departure and Doppler. Results can
be applied in both vehicle-to-vehicle and mobile millimeter wave MIMO channel
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06622</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06622</id><created>2018-05-17</created><updated>2018-05-19</updated><authors><author><keyname>Abzhanova</keyname><forenames>Togzhan</forenames></author><author><keyname>Dolzhikova</keyname><forenames>Irina</forenames></author><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author></authors><title>Implementation of True Random Number Generator based on Double-Scroll
  Attractor circuit with GST memristor emulator</title><categories>eess.SP cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cryptographic security provided by various techniques of random number
generator (RNG) construction is one of the developing researches areas today.
Among various types of RNG, the true random bit generator (TRBG) can be
considered as the most unpredictable and most secured because its randomness
seed is generated from chaotic sources. This paper proposes a design of TRBG
model based on double-scroll attractors circuits with GST memristor. After
implementation and simulation of the chaotic circuit with GST memristor
emulator, the chaotic behavior of the output voltage and inductor current were
received. Moreover, their dependence on the input voltage revealed the close to
double-scroll form. The randomness generated from the proposed circuit was
tested by receiving Fast Fourier Transform (FFT) and Lyapunov exponents of the
output voltage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06626</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06626</id><created>2018-05-17</created><updated>2018-05-19</updated><authors><author><keyname>Kulmukhanova</keyname><forenames>Nazerke</forenames></author><author><keyname>Dolzhikova</keyname><forenames>Irina</forenames></author></authors><title>Analysis of Noise in Current Mirrors with memristive Device</title><categories>eess.SP cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents an analysis of noise in a cascode current mirror with
CMOS-memristive device done by comparison with the basic current mirror. The
analysis is completed based on THD for different frequency and channel length
values by means of computer-aided design. AC and DC analyses are presented for
both balanced and unbalanced current mirrors. While the change in the channel
length has similar effect in both circuits, memristor in a circuit decreases
noise significantly at high frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06628</identifier>
 <datestamp>2019-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06628</id><created>2018-05-17</created><updated>2019-04-23</updated><authors><author><keyname>Lu</keyname><forenames>Xiaozhen</forenames></author><author><keyname>Xiao</keyname><forenames>Liang</forenames></author><author><keyname>Dai</keyname><forenames>Canhuang</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author></authors><title>UAV-Aided Cellular Communications with Deep Reinforcement Learning
  Against Jamming</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular systems are vulnerable to jamming attacks, especially smart jammers
that choose their jamming policies such as the jamming channel frequencies and
power based on the ongoing communication policies and network states. In this
article, we present an unmanned aerial vehicle (UAV) aided cellular
communication framework against jamming. In this scheme, UAVs use reinforcement
learning methods to choose the relay policy for mobile users in cellular
systems, if the serving base station is heavily jammed. More specifically, we
propose a deep reinforcement learning based UAV relay scheme to help cellular
systems resist smart jamming without being aware of the jamming model and the
network model in the dynamic game based on the previous anti-jamming relay
experiences and the observed current network status. This scheme can achieve
the optimal performance after enough interactions with the jammer. Simulation
results show that this scheme can reduce the bit error rate of the messages and
save energy for the cellular system compared with the existing scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06631</identifier>
 <datestamp>2018-06-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06631</id><created>2018-05-17</created><updated>2018-05-31</updated><authors><author><keyname>Daribay</keyname><forenames>Amanzhol</forenames></author><author><keyname>Dolzhikova</keyname><forenames>Irina</forenames></author></authors><title>Widlar Current Mirror Design Using BJT-Memristor Circuits</title><categories>eess.SP cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a description of basic current mirror (CM), Widlar
current mirror, fourth circuit element (memristor) and an analysis of Widlar
Configuration with integrated memristor. The analysis has been performed by
comparing a modified configuration with a simple circuit of Widlar CM. The
focus of analysis were a power dissipation, a Total Harmonic Distortion and a
chip-surface. The results has shown that a presence of memristor in the Widlar
CM decreases the chip-surface area and the deviation of the signal in the
circuit from a fundamental frequency. Although the analysis of power
dissipation has also been conducted, there is no definite conclusion about the
power losses in the circuit because of the memristor model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06637</identifier>
 <datestamp>2020-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06637</id><created>2018-05-17</created><updated>2020-02-04</updated><authors><author><keyname>Rachad</keyname><forenames>Jalal</forenames><affiliation>LTCI</affiliation></author><author><keyname>Nasri</keyname><forenames>Ridha</forenames><affiliation>LTCI</affiliation></author><author><keyname>Decreusefond</keyname><forenames>Laurent</forenames><affiliation>LTCI</affiliation></author></authors><title>How To Dimension Radio Resources When Users Are Distributed on Roads
  Modeled by Poisson Line Process</title><categories>cs.NI eess.SP</categories><proxy>ccsd</proxy><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Resources dimensioning aims at finding the number of radio resources required
to carry a forecast data traffic at a target users Quality of Services (QoS).
The present paper attempts to provide a new approach of radio resources
dimensioning considering the congestion probability, qualified as a relevant
metric for QoS evaluation. Users are assumed to be distributed according to a
linear Poisson Point Process (PPP) in a random system of roads modeled by
Poisson Line Process (PLP) instead of the widely-used spatial PPP. We derive
the analytical expression of the congestion probability for analyzing its
behavior as a function of network parameters. Finally we show how to dimension
radio resources by setting a value of the congestion probability, often
targeted by the operator, in order to find the relation between the necessary
resources and the forecast data traffic expressed in terms of cell throughput.
Different numerical results are presented to justify this dimensioning
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06643</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06643</id><created>2018-05-17</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author><author><keyname>Zhambyl</keyname><forenames>Aidyn</forenames></author><author><keyname>Nandakumar</keyname><forenames>Anju</forenames></author></authors><title>Memristor-based Approximation of Gaussian Filter</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Gaussian filter is a filter with impulse response of Gaussian function.
These filters are useful in image processing of 2D signals, as it removes
unnecessary noise. Also, they could be helpful for data transmission (e.g. GMSK
modulation). In practice, the Gaussian filters could be approximately designed
by several methods. One of these methods are to construct Gaussian-like filter
with the help of memristors and RLC circuits. Therefore, the objective of this
project is to find and design appropriate model of Gaussian-like filter, by
using mentioned devices. Finally, one possible model of Gaussian-like filter
based on memristor designed and analysed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.06646</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.06646</id><created>2018-05-17</created><authors><author><keyname>Torebayev</keyname><forenames>Galymzhan</forenames></author><author><keyname>Nandakumar</keyname><forenames>Anju</forenames></author></authors><title>Implementation of Memristor in Bessel filter with RLC components</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bessel filters are optimized to collect competent transient response due
to a linear phase in the passband. In other words, during the filtering
process, there will be comparatively impoverished frequency response with lower
amplitude inequity. Memristor is asserted as a passive, two-terminal essential
component of the circuit and the use of such element in schemes as an
adjustable resistance allows the realization of the memory resistor based
analog circuits, which achieve the wide range of specific parameters. The
application of RLC circuit for Bessel filter prototype is theoretically
expected to behave in a positive way, however, the further simulations with
software and analysis of the results will reveal the nature of the effect
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07003</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07003</id><created>2018-05-17</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Subchannel Allocation for Vehicle-to-Vehicle Broadcast Communications in
  Mode-3</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conversely to mainstream cellular networks where uplink / downlink data
traffic is centrally managed by eNodeBs, in vehicle-to-vehicle (V2V) broadcast
communications \textit{mode-3} eNodeBs engage solely in subchannel assignment
but ultimately do not intervene in data traffic control. Accordingly, vehicles
communicate directly with their counterparts utilizing the allotted
subchannels. Due to its loosely controlled one-to-all nature, V2V
\textit{mode-3} is advantageous for time-critical applications. Nevertheless,
it is imperative that the assignment of subchannels is accomplished without
conflicts while at the same time satisfying quality of service (QoS)
requirements. To the best of our knowledge, there exists no unified framework
for V2V \textit{mode-3} that contemplates both prevention of allocation
conflicts and fulfillment of QoS. Thus, four types of conditions that are of
forceful character for attaining QoS-aware conflict-free allocations have been
identified: $(i)$ assure differentiated QoS per vehicle, $(ii)$ preclude
intra-cluster subframe conflicts, $(iii)$ secure minimal time dispersion of
allotted subchannels and $(iv)$ forestall one-hop inter-cluster subchannel
conflicts. Such conditions have been systematized and merged in an holistic
manner allowing non-complex manipulation to perform subchannel allocation
optimization. In addition, we propose a surrogate relaxation of the problem
that does not affect optimality provided that certain requisites are satisfied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07012</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07012</id><created>2018-05-17</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Parallel and Successive Resource Allocation for V2V Communications in
  Overlapping Clusters</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The 3rd Generation Partnership Project (3GPP) has introduced in Rel. 14 a
novel technology referred to as vehicle--to--vehicle (V2V) \textit{mode-3}.
Under this scheme, the eNodeB assists in the resource allocation process
allotting sidelink subchannels to vehicles. Thereupon, vehicles transmit their
signals in a broadcast manner without the intervention of the former one.
eNodeBs will thereby play a determinative role in the assignment of subchannels
as they can effectively manage V2V traffic and prevent allocation conflicts.
The latter is a crucial aspect to be enforced in order for the signals to be
received reliably by other vehicles. To this purpose, we propose two resource
allocation schemes namely bipartite graph matching-based successive allocation
(BGM-SA) and bipartite graph matching-based parallel allocation (BGM-PA) which
are suboptimal approaches with lesser complexity than exhaustive search. Both
schemes incorporate constraints to prevent allocation conflicts from emerging.
In this research, we consider overlapping clusters only, which could be formed
at intersections or merging highways. We show through simulations that BGM-SA
can attain near-optimal performance whereas BGM-PA is subpar but less complex.
Additionally, since BGM-PA is based on inter-cluster vehicle pre-grouping, we
explore different metrics that could effectively portray the overall channel
conditions of pre-grouped vehicles. This is of course not optimal in terms of
maximizing the system capacity---since the allocation process would be based on
simplified surrogate information---but it reduces the computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07024</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07024</id><created>2018-05-17</created><authors><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Wang</keyname><forenames>Xiaorui</forenames></author><author><keyname>Zhao</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Li</keyname><forenames>Yan</forenames></author></authors><title>Gated Recurrent Unit Based Acoustic Modeling with Future Context</title><categories>cs.CL cs.SD eess.AS</categories><comments>Submitted to INTERSPEECH 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of future contextual information is typically shown to be helpful for
acoustic modeling. However, for the recurrent neural network (RNN), it's not so
easy to model the future temporal context effectively, meanwhile keep lower
model latency. In this paper, we attempt to design a RNN acoustic model that
being capable of utilizing the future context effectively and directly, with
the model latency and computation cost as low as possible. The proposed model
is based on the minimal gated recurrent unit (mGRU) with an input projection
layer inserted in it. Two context modules, temporal encoding and temporal
convolution, are specifically designed for this architecture to model the
future context. Experimental results on the Switchboard task and an internal
Mandarin ASR task show that, the proposed model performs much better than long
short-term memory (LSTM) and mGRU models, whereas enables online decoding with
a maximum latency of 170 ms. This model even outperforms a very strong
baseline, TDNN-LSTM, with smaller model latency and almost half less
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07103</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07103</id><created>2018-05-18</created><updated>2018-08-20</updated><authors><author><keyname>Wasserthal</keyname><forenames>Jakob</forenames></author><author><keyname>Neher</keyname><forenames>Peter</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Klaus H.</forenames></author></authors><title>TractSeg - Fast and accurate white matter tract segmentation</title><categories>cs.CV eess.IV</categories><journal-ref>Wasserthal, J., Neher, P., Maier-Hein, K.H., 2018. TractSeg - Fast
  and accurate white matter tract segmentation. NeuroImage</journal-ref><doi>10.1016/j.neuroimage.2018.07.070</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The individual course of white matter fiber tracts is an important key for
analysis of white matter characteristics in healthy and diseased brains.
Uniquely, diffusion-weighted MRI tractography in combination with region-based
or clustering-based selection of streamlines allows for the in-vivo delineation
and analysis of anatomically well known tracts. This, however, currently
requires complex, computationally intensive and tedious-to-set-up processing
pipelines. TractSeg is a novel convolutional neural network-based approach that
directly segments tracts in the field of fiber orientation distribution
function (fODF) peaks without requiring tractography, image registration or
parcellation. We demonstrate in 105 subjects from the Human Connectome Project
that the proposed approach is much faster than existing methods while providing
unprecedented accuracy. The code and data are openly available at
https://github.com/MIC-DKFZ/TractSeg/ and
https://doi.org/10.5281/zenodo.1088277, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07224</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07224</id><created>2018-05-16</created><authors><author><keyname>Danielson</keyname><forenames>Magnus</forenames></author></authors><title>AM to PM conversion of linear filters</title><categories>eess.SP physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conversion between amplitude modulation and phase modulation as a
modulated signal goes thrugh a filter is analyzed. The difference in how the
modulated sideband ampitude experience the filter, and how AM and PM has
opposite signs for one of their sidebands interact. The conversion between AM
and PM is modelled, providing a scatter model and evaluation of two functions
based on the linear filters transfer function. The system bandwidth effects is
analyzed and rule of thumb developed to ensure AM and PM isolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07259</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07259</id><created>2018-05-11</created><authors><author><keyname>Fartookzadeh</keyname><forenames>Mahdi</forenames></author></authors><title>Comments on Frequency Diverse Array Antenna Using Time-Modulated
  Optimized Frequency Offset to Obtain Time-Invariant Spatial Fine Focusing
  Beampattern</title><categories>eess.SP</categories><comments>This is an accepted IEEE paper</comments><doi>10.1109/TAP.2019.2955155</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent papers [1-4] including above paper time modulated frequency
diverse arrays (FDAs) have been presented to obtain time invariant spatial
patterns. The presented FDAs in [1-3] have the feature of time-invariant
spatial focusing which means they have a constant maximum in a time duration,
T, at a point with desired range, r, and angle, {\theta}. In [4] the pattern is
time invariant, yet, not focused. However, in this communication it is
indicated that the patterns are obtained using incorrect definition of time in
some equations. The equation system of [3] is explained here that can be
extended to [1, 2, 4], explicitly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07300</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07300</id><created>2018-05-18</created><authors><author><keyname>Chlon</keyname><forenames>Leon</forenames></author><author><keyname>Song</keyname><forenames>Andrew</forenames></author><author><keyname>Subramanian</keyname><forenames>Sandya</forenames></author><author><keyname>Soulat</keyname><forenames>Hugo</forenames></author><author><keyname>Tauber</keyname><forenames>John</forenames></author><author><keyname>Ba</keyname><forenames>Demba</forenames></author><author><keyname>Prerau</keyname><forenames>Michael</forenames></author></authors><title>Multitaper Spectral Estimation HDP-HMMs for EEG Sleep Inference</title><categories>stat.ML cs.LG eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalographic (EEG) monitoring of neural activity is widely used
for sleep disorder diagnostics and research. The standard of care is to
manually classify 30-second epochs of EEG time-domain traces into 5 discrete
sleep stages. Unfortunately, this scoring process is subjective and
time-consuming, and the defined stages do not capture the heterogeneous
landscape of healthy and clinical neural dynamics. This motivates the search
for a data-driven and principled way to identify the number and composition of
salient, reoccurring brain states present during sleep. To this end, we propose
a Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM), combined with
wide-sense stationary (WSS) time series spectral estimation to construct a
generative model for personalized subject sleep states. In addition, we employ
multitaper spectral estimation to further reduce the large variance of the
spectral estimates inherent to finite-length EEG measurements. By applying our
method to both simulated and human sleep data, we arrive at three main results:
1) a Bayesian nonparametric automated algorithm that recovers general temporal
dynamics of sleep, 2) identification of subject-specific &quot;microstates&quot; within
canonical sleep stages, and 3) discovery of stage-dependent sub-oscillations
with shared spectral signatures across subjects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07429</identifier>
 <datestamp>2019-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07429</id><created>2018-05-18</created><updated>2019-04-23</updated><authors><author><keyname>Wu</keyname><forenames>Chai Wah</forenames></author></authors><title>Designing communication systems via iterative improvement: error
  correction coding with Bayes decoder and codebook optimized for source symbol
  error</title><categories>eess.SP cs.AI</categories><comments>18 pages, added Section 7</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most error correction coding (ECC) frameworks, the typical error metric is
the bit error rate (BER) which measures the number of bit errors. For this
metric, the positions of the bits are not relevant to the decoding, and in many
noise models, not relevant to the BER either. In many applications this is
unsatisfactory as typically all bits are not equal and have different
significance. We look at ECC from a Bayesian perspective and introduce Bayes
estimators with general loss functions to take into account the bit
significance. We propose ECC schemes that optimize this error metric. As the
problem is highly nonlinear, traditional ECC construction techniques are not
applicable. Using exhaustive search is cost prohibitive, and thus we use
iterative improvement search techniques to find good codebooks. We optimize
both general codebooks and linear codes. We provide numerical experiments to
show that they can be superior to classical linear block codes such as Hamming
codes and decoding methods such as minimum distance decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07432</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07432</id><created>2018-05-18</created><authors><author><keyname>Tchuisseu</keyname><forenames>Eder Batista Tchawou</forenames></author><author><keyname>Gomila</keyname><forenames>Dami&#xe0;</forenames></author><author><keyname>Colet</keyname><forenames>Pere</forenames></author></authors><title>Reduction of power grid fluctuations by communication between smart
  devices</title><categories>cs.SY eess.SP physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increase of electric demand and the progressive integration of renewable
sources threatens the stability of the power grid. To solve this issue, several
methods have been proposed to control the demand side instead of increasing the
spinning reserve on the supply side. Here we focus on dynamic demand control
(DDC), a method in which appliances can delay its scheduled operation if the
electric frequency is outside a suitable range. We have recently shown that DDC
effectively reduces small and medium-size frequency fluctuations but, due to
the need of recovering pending tasks, the probability of large demand peaks,
and hence large frequency fluctuations, may actually increase. Although these
events are very rare they can potentially trigger a failure of the system and
therefore strategies to avoid them have to be addressed. In this work, we
introduce a new method including communication among DDC devices belonging to a
given group, such that they can coordinate opposite actions to keep the group
demand more stable. We show that for this method the amount of pending tasks
decreases by a factor 10 while large frequency fluctuations are significantly
reduced or even completely avoided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07467</identifier>
 <datestamp>2018-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07467</id><created>2018-05-18</created><updated>2018-09-20</updated><authors><author><keyname>Chung</keyname><forenames>Yu-An</forenames></author><author><keyname>Weng</keyname><forenames>Wei-Hung</forenames></author><author><keyname>Tong</keyname><forenames>Schrasing</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to NIPS 2018. v2 added the majority word baseline results
  and other minor fixes. arXiv admin note: text overlap with arXiv:1710.04087
  by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has shown that word embedding spaces learned from text
corpora of different languages can be aligned without any parallel data
supervision. Inspired by the success in unsupervised cross-lingual word
embeddings, in this paper we target learning a cross-modal alignment between
the embedding spaces of speech and text learned from corpora of their
respective modalities in an unsupervised fashion. The proposed framework learns
the individual speech and text embedding spaces, and attempts to align the two
spaces via adversarial training, followed by a refinement procedure. We show
how our framework could be used to perform spoken word classification and
translation, and the results on these two tasks demonstrate that the
performance of our unsupervised alignment approach is comparable to its
supervised counterpart. Our framework is especially useful for developing
automatic speech recognition (ASR) and speech-to-text translation systems for
low- or zero-resource languages, which have little parallel audio-text data for
training modern supervised ASR and speech-to-text translation models, but
account for the majority of the languages spoken across the world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07493</identifier>
 <datestamp>2019-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07493</id><created>2018-05-18</created><updated>2018-06-12</updated><authors><author><keyname>Kibria</keyname><forenames>Md. Golam</forenames></author><author><keyname>Rivaz</keyname><forenames>Hassan</forenames></author></authors><title>Global Ultrasound Elastography Using Convolutional Neural Network</title><categories>eess.IV</categories><comments>4 pages, 4 figures; added acknowledgment section, submission type
  latex</comments><doi>10.1007/978-3-030-01045-4_3</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Displacement estimation is very important in ultrasound elastography and
failing to estimate displacement correctly results in failure in generating
strain images. As conventional ultrasound elastography techniques suffer from
decorrelation noise, they are prone to fail in estimating displacement between
echo signals obtained during tissue distortions. This study proposes a novel
elastography technique which addresses the decorrelation in estimating
displacement field. We call our method GLUENet (GLobal Ultrasound Elastography
Network) which uses deep Convolutional Neural Network (CNN) to get a coarse
time-delay estimation between two ultrasound images. This displacement is later
used for formulating a nonlinear cost function which incorporates similarity of
RF data intensity and prior information of estimated displacement. By
optimizing this cost function, we calculate the finer displacement by
exploiting all the information of all the samples of RF data simultaneously.
The Contrast to Noise Ratio (CNR) and Signal to Noise Ratio (SNR) of the strain
images from our technique is very much close to that of strain images from
GLUE. While most elastography algorithms are sensitive to parameter tuning, our
robust algorithm is substantially less sensitive to parameter tuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07614</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07614</id><created>2018-05-19</created><authors><author><keyname>Alsamhi</keyname><forenames>S. H.</forenames></author><author><keyname>Ma</keyname><forenames>Ou</forenames></author><author><keyname>Ansari</keyname><forenames>M. S.</forenames></author></authors><title>Predictive Estimation of the Optimal Signal Strength from Unmanned
  Aerial Vehicle over Internet of Things Using ANN</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper proposes an intelligent technique for maximizing the network
connectivity and provisioning desired quality of service (QoS) of integration
of internet of things (IoT) and unmanned aerial vehicle (UAV). Prediction of
the signal strength and fading channel conditions enable adaptive data
transmission which turn enhances the QoS for the end users/ devices with
reducing the power consumption for data transmissions. UAV is data gathering
robot from the difficult or impossible area for humans to reach. Hence,
Atmospheric dynamics and environment influence the signal strength during
traveling in space among UAV, IoT devices, and humankind. Therefore, Signal
moving from the smart UAV is sensitive to the effects of attenuation,
reflection, diffraction, scattering, and shadowing. We analysis the ability ANN
to predictively estimate the signal strength and channel propagation from the
drone and physical medium parameters, using ANN. Moreover, the results show
that the distortion of the signal can be reduced and enhanced significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07628</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07628</id><created>2018-05-19</created><updated>2018-08-09</updated><authors><author><keyname>Sedighi</keyname><forenames>Sara</forenames></author><author><keyname>Ramhormozi</keyname><forenames>Shayan</forenames></author></authors><title>Sparse Architectures for Text-Independent Speaker Verification Using
  Deep Neural Networks</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network pruning is of great importance due to the elimination of the
unimportant weights or features activated due to the network
over-parametrization. Advantages of sparsity enforcement include preventing the
overfitting and speedup. Considering a large number of parameters in deep
architectures, network compression becomes of critical importance due to the
required huge amount of computational power. In this work, we impose structured
sparsity for speaker verification which is the validation of the query speaker
compared to the speaker gallery. We will show that the mere sparsity
enforcement can improve the verification results due to the possible initial
overfitting in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07643</identifier>
 <datestamp>2018-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07643</id><created>2018-05-19</created><updated>2018-09-07</updated><authors><author><keyname>Chang</keyname><forenames>Yan</forenames></author><author><keyname>Yang</keyname><forenames>Weiqing</forenames></author><author><keyname>Zhao</keyname><forenames>Ding</forenames></author></authors><title>Energy Efficiency and Emission Testing for Connected and Automated
  Vehicles Using Real-World Driving Data</title><categories>cs.OH eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using the onboard sensing and external connectivity technology, connected
and automated vehicles (CAV) could lead to improved energy efficiency, better
routing, and lower traffic congestion. With the rapid development of the
technology and adaptation of CAV, it is more critical to develop the universal
evaluation method and the testing standard which could evaluate the impacts on
energy consumption and environmental pollution of CAV fairly, especially under
the various traffic conditions. In this paper, we proposed a new method and
framework to evaluate the energy efficiency and emission of the vehicle based
on the unsupervised learning methods. Both the real-world driving data of the
evaluated vehicle and the large naturalistic driving dataset are used to
perform the driving primitive analysis and coupling. Then the linear weighted
estimation method could be used to calculate the testing result of the
evaluated vehicle. The results show that this method can successfully identify
the typical driving primitives. The couples of the driving primitives from the
evaluated vehicle and the typical driving primitives from the large real-world
driving dataset coincide with each other very well. This new method could
enhance the standard development of the energy efficiency and emission testing
of CAV and other off-cycle credits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07766</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07766</id><created>2018-05-20</created><authors><author><keyname>Zheng</keyname><forenames>Guangtao</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Xu</keyname><forenames>Zhengyuan</forenames></author></authors><title>Constrained Partial Group Decoding with Max-Min Fairness for Multi-color
  Multi-user Visible Light Communication</title><categories>eess.SP</categories><comments>28 pages, 12 figures, submitted to TCOM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A visible light communication (VLC) system can adopt multi-color light
emitting diode (LED) arrays to support multiple users. In this paper, a
multi-layer coding and constrained partial group decoding (CPGD) method is
proposed to tackle strong color interference and increase the system
throughput. After channel model formulation, user information rates are
allocated and decoding order for all the received data layers is obtained by
solving a max-min fairness problem using a greedy algorithm. An achievable rate
is derived under the truncated Gaussian input distribution. To reduce the
decoding complexity, a map on the decoding order and rate allocation is
constructed for all positions of interest on the receiver plane and its size is
reduced by a classification-based algorithm. Meanwhile, the symmetrical
geometry of LED arrays is exploited. Finally, the transmitter-user association
problem is formulated and solved by a genetic algorithm. It is observed that
the system throughput increases as the receivers are slightly misaligned with
corresponding LED arrays due to the reduced interference level, but decreases
afterwards due to the weakened link gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07796</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07796</id><created>2018-05-20</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Lops</keyname><forenames>Marco</forenames></author><author><keyname>D'Andrea</keyname><forenames>Carmen</forenames></author><author><keyname>D'Elia</keyname><forenames>Ciro</forenames></author></authors><title>Co-existence Between a Radar System and a Massive MIMO Wireless Cellular
  System</title><categories>cs.IT eess.SP math.IT</categories><comments>To be presented at 2018 IEEE SPAWC, Kalamata, Greece, June 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the uplink of a massive MIMO communication system
using 5G New Radio-compliant multiple access, which is to co-exist with a radar
system using the same frequency band. We propose a system model taking into
account the reverberation (clutter) produced by the radar system at the massive
MIMO receiver. Then, we propose several linear receivers for uplink
data-detection, ranging by the simple channel-matched beamformer to the
zero-forcing and linear minimum mean square error receivers for clutter
disturbance rejection. Our results show that the clutter may have a strong
effect on the performance of the cellular communication system, but the use of
large-scale antenna arrays at the base station is key to provide increased
robustness against it, at least as far as data-detection is concerned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.07820</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.07820</id><created>2018-05-20</created><updated>2019-08-19</updated><authors><author><keyname>Taori</keyname><forenames>Rohan</forenames></author><author><keyname>Kamsetty</keyname><forenames>Amog</forenames></author><author><keyname>Chu</keyname><forenames>Brenton</forenames></author><author><keyname>Vemuri</keyname><forenames>Nikita</forenames></author></authors><title>Targeted Adversarial Examples for Black Box Audio Systems</title><categories>cs.LG cs.CR cs.SD eess.AS stat.ML</categories><comments>IEEE Deep Learning and Security Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The application of deep recurrent networks to audio transcription has led to
impressive gains in automatic speech recognition (ASR) systems. Many have
demonstrated that small adversarial perturbations can fool deep neural networks
into incorrectly predicting a specified target with high confidence. Current
work on fooling ASR systems have focused on white-box attacks, in which the
model architecture and parameters are known. In this paper, we adopt a
black-box approach to adversarial generation, combining the approaches of both
genetic algorithms and gradient estimation to solve the task. We achieve a
89.25% targeted attack similarity after 3000 generations while maintaining
94.6% audio file similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08025</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08025</id><created>2018-05-21</created><updated>2018-06-12</updated><authors><author><keyname>Licea</keyname><forenames>Daniel Bonilla</forenames></author><author><keyname>Nurellari</keyname><forenames>Edmond</forenames></author><author><keyname>Ghogho</keyname><forenames>Mounir</forenames></author></authors><title>Energy balancing for robotic aided clustered wireless sensor networks
  using mobility diversity algorithms</title><categories>cs.DC eess.SP</categories><comments>5 pages, 26th European Signal Processing Conference (EUSIPCO 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of energy balancing in a clustered wireless sensor
network (WSN) deployed randomly in a large field and aided by a mobile robot
(MR). The sensor nodes (SNs) are tasked to monitor a region of interest (ROI)
and report their test statistics to the cluster heads (CHs), which subsequently
report to the fusion center (FC) over a wireless fading channel. To maximize
the lifetime of the WSN, the MR is deployed to act as an adaptive relay between
a subset of the CHs and the FC. To achieve this we develop a multiple-link
mobility diversity algorithm (MDA) executed by the MR that will allow to
compensate simultaneously for the small-scale fading at the established
wireless links (i.e., the MR-to-FC as well as various CH-to-MR communication
links). Simulation results show that the proposed MR aided technique is able to
significantly reduce the transmission power required and thus extend the
operational lifetime of the WSN. We also show how the effect of small-scale
fading at various wireless links is mitigated by using the proposed
multiple-link MDA executed by a MR equipped with a single antenna.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08045</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08045</id><created>2018-05-21</created><updated>2020-01-12</updated><authors><author><keyname>Li</keyname><forenames>Shengxi</forenames></author><author><keyname>Yu</keyname><forenames>Zeyang</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo</forenames></author></authors><title>A universal framework for learning the elliptical mixture model</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mixture modelling using elliptical distributions promises enhanced
robustness, flexibility and stability over the widely employed Gaussian mixture
model (GMM). However, existing studies based on the elliptical mixture model
(EMM) are restricted to several specific types of elliptical probability
density functions, which are not supported by general solutions or systematic
analysis frameworks; this significantly limits the rigour and the power of EMMs
in applications. To this end, we propose a novel general framework for
estimating and analysing the EMMs, achieved through Riemannian manifold
optimisation. First, we investigate the relationships between Riemannian
manifolds and elliptical distributions, and the so established connection
between the original manifold and a reformulated one indicates a mismatch
between those manifolds, the major cause of failure of the existing
optimisation for solving general EMMs. We next propose a universal solver which
is based on the optimisation of a re-designed cost and prove the existence of
the same optimum as in the original problem; this is achieved in a simple, fast
and stable way. We further calculate the influence functions of the EMM as
theoretical bounds to quantify robustness to outliers. Comprehensive numerical
results demonstrate the ability of the proposed framework to accommodate EMMs
with different properties of individual functions in a stable way and with fast
convergence speed. Finally, the enhanced robustness and flexibility of the
proposed framework over the standard GMM are demonstrated both analytically and
through comprehensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08060</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08060</id><created>2018-05-21</created><authors><author><keyname>Yesilkaya</keyname><forenames>Anil</forenames></author><author><keyname>Karatalay</keyname><forenames>Onur</forenames></author><author><keyname>Ogrenci</keyname><forenames>Arif Selcuk</forenames></author><author><keyname>Panayirci</keyname><forenames>Erdal</forenames></author></authors><title>Channel Estimation for Visible Light Communications Using Neural
  Networks</title><categories>cs.NE cs.IT eess.SP math.IT</categories><doi>10.1109/IJCNN.2016.7727215</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communications (VLC) is an emerging field in technology and
research. Estimating the channel taps is a major requirement for designing
reliable communication systems. Due to the nonlinear characteristics of the VLC
channel those parameters cannot be derived easily. They can be calculated by
means of software simulation. In this work, a novel methodology is proposed for
the prediction of channel parameters using neural networks. Measurements
conducted in a controlled experimental setup are used to train neural networks
for channel tap prediction. Our experiment results indicate that neural
networks can be effectively trained to predict channel taps under different
environmental conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08068</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08068</id><created>2018-05-17</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Poster: Resource Allocation with Conflict Resolution for Vehicular
  Sidelink Broadcast Communications</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1805.06550</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we present a graph-based resource allocation scheme for
sidelink broadcast V2V communications. Harnessing available information on
geographical position of vehicles and spectrum resources utilization, eNodeBs
are capable of allotting the same set of sidelink resources to different
vehicles distributed among several communications clusters. Within a
communications cluster, it is crucial to prevent time-domain allocation
conflicts since vehicles cannot transmit and receive simultaneously, i.e., they
must transmit in orthogonal time resources. In this research, we present a
solution based on a bipartite graph, where vehicles and spectrum resources are
represented by vertices whereas the edges represent the achievable rate in each
resource based on the SINR that each vehicle perceives. The aforementioned time
orthogonality constraint can be approached by aggregating conflicting vertices
into macro-vertices which, in addition, reduces the search complexity. We show
mathematically and through simulations that the proposed approach yields an
optimal solution. In addition, we provide simulations showing that the proposed
method outperforms other competing approaches, specially in scenarios with high
vehicular density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08081</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08081</id><created>2018-05-18</created><authors><author><keyname>Abdirash</keyname><forenames>Muratkhan</forenames></author><author><keyname>Dolzhikova</keyname><forenames>Irina</forenames></author><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author></authors><title>Implementation of Chua's chaotic oscillator with an HP memristor</title><categories>cs.ET eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an innovative chaotic circuit based on Chua's oscillator.
It combines traditional realization of a non-linear resistor in Chua's chaotic
oscillator with a promising memristive circuitry. This mixed implementation
connects old research works that were focused on diodes with relatively new
research papers that are, now, concentrated on memristors. As a result, more
reliable chaotic circuit with an HP memristor is obtained that could be used as
a source of randomness. Dynamic behavior of the circuit is studied by obtaining
fft analysis, different chaotic attractors and Lyapunov exponent spectrum. The
results show that the addition of a memristor enhances chaotic behavior of the
circuit while maintaining the same power dissipation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08120</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08120</id><created>2018-05-21</created><authors><author><keyname>Collins</keyname><forenames>Michael D.</forenames></author><author><keyname>Johnson</keyname><forenames>William B.</forenames></author></authors><title>Impulsive Noise Immunity of Multidimensional Pulse Position Modulation</title><categories>eess.SP</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe block oriented multidimensional pulse position modulation and its
resilience against impulsive noise. The modulation implements the encoder and
part of the decoder of the BBC algorithm. We tested the modulation on circuits
that send and detect a pulse based signal in the presence of impulsive noise.
We measured the packet error rate vs. signal to noise ratio and we compared it
with published error rates for OFDM. We found an error rate of 2 x 10^(-5) at a
signal to noise ratio of 16 dB without forward error correction and a data rate
of 64 kbit /sec.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08309</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08309</id><created>2018-05-21</created><authors><author><keyname>He</keyname><forenames>Xin</forenames></author><author><keyname>Ke</keyname><forenames>Liu</forenames></author><author><keyname>Lu</keyname><forenames>Wenyan</forenames></author><author><keyname>Yan</keyname><forenames>Guihai</forenames></author><author><keyname>Zhang</keyname><forenames>Xuan</forenames></author></authors><title>AxTrain: Hardware-Oriented Neural Network Training for Approximate
  Inference</title><categories>cs.LG cs.DC eess.IV stat.ML</categories><comments>In International Symposium on Low Power Electronics and Design
  (ISLPED) 2018</comments><doi>10.1145/3218603.3218643</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intrinsic error tolerance of neural network (NN) makes approximate
computing a promising technique to improve the energy efficiency of NN
inference. Conventional approximate computing focuses on balancing the
efficiency-accuracy trade-off for existing pre-trained networks, which can lead
to suboptimal solutions. In this paper, we propose AxTrain, a hardware-oriented
training framework to facilitate approximate computing for NN inference.
Specifically, AxTrain leverages the synergy between two orthogonal
methods---one actively searches for a network parameters distribution with high
error tolerance, and the other passively learns resilient weights by
numerically incorporating the noise distributions of the approximate hardware
in the forward pass during the training phase. Experimental results from
various datasets with near-threshold computing and approximation multiplication
strategies demonstrate AxTrain's ability to obtain resilient neural network
parameters and system energy efficiency improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08501</identifier>
 <datestamp>2018-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08501</id><created>2018-05-22</created><updated>2018-10-01</updated><authors><author><keyname>Esling</keyname><forenames>Philippe</forenames></author><author><keyname>Chemla--Romeu-Santos</keyname><forenames>Axel</forenames></author><author><keyname>Bitton</keyname><forenames>Adrien</forenames></author></authors><title>Generative timbre spaces: regularizing variational auto-encoders with
  perceptual metrics</title><categories>cs.SD eess.AS</categories><comments>Digital Audio Conference (DaFX 2018)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Timbre spaces have been used in music perception to study the perceptual
relationships between instruments based on dissimilarity ratings. However,
these spaces do not generalize to novel examples and do not provide an
invertible mapping, preventing audio synthesis. In parallel, generative models
have aimed to provide methods for synthesizing novel timbres. However, these
systems do not provide an understanding of their inner workings and are usually
not related to any perceptually relevant information. Here, we show that
Variational Auto-Encoders (VAE) can alleviate all of these limitations by
constructing generative timbre spaces. To do so, we adapt VAEs to learn an
audio latent space, while using perceptual ratings from timbre studies to
regularize the organization of this space. The resulting space allows us to
analyze novel instruments, while being able to synthesize audio from any point
of this space. We introduce a specific regularization allowing to enforce any
given similarity distances onto these spaces. We show that the resulting space
provide almost similar distance relationships as timbre spaces. We evaluate
several spectral transforms and show that the Non-Stationary Gabor Transform
(NSGT) provides the highest correlation to timbre spaces and the best quality
of synthesis. Furthermore, we show that these spaces can generalize to novel
instruments and can generate any path between instruments to understand their
timbre relationships. As these spaces are continuous, we study how audio
descriptors behave along the latent dimensions. We show that even though
descriptors have an overall non-linear topology, they follow a locally smooth
evolution. Based on this, we introduce a method for descriptor-based synthesis
and show that we can control the descriptors of an instrument while keeping its
timbre structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08521</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08521</id><created>2018-05-22</created><authors><author><keyname>Anavangot</keyname><forenames>Vijay</forenames></author><author><keyname>Kumar</keyname><forenames>Animesh</forenames></author></authors><title>On Distributed Nonlinear Signal Analytics : Bandwidth and Approximation
  Error Tradeoffs</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytics will be a part of the upcoming smart city and Internet of Things
(IoT). The focus of this work is approximate distributed signal analytics. It
is envisaged that distributed IoT devices will record signals, which may be of
interest to the IoT cloud. Communication of these signals from IoT devices to
the IoT cloud will require (lowpass) approximations. Linear signal
approximations are well known in the literature. It will be outlined that in
many IoT analytics problems, it is desirable that the approximated signals (or
their analytics) should always over-predict the exact signals (or their
analytics). This distributed nonlinear approximation problem has not been
studied before. An algorithm to perform distributed over-predictive signal
analytics in the IoT cloud, based on signal approximations by IoT devices, is
proposed. The fundamental tradeoff between the signal approximation bandwidth
used by IoT devices and the approximation error in signal analytics at the IoT
cloud is quantified for the class of differentiable signals. Simulation results
are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08545</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08545</id><created>2018-05-22</created><authors><author><keyname>Marban</keyname><forenames>Arturo</forenames></author><author><keyname>Srinivasan</keyname><forenames>Vignesh</forenames></author><author><keyname>Samek</keyname><forenames>Wojciech</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Josep</forenames></author><author><keyname>Casals</keyname><forenames>Alicia</forenames></author></authors><title>A Recurrent Convolutional Neural Network Approach for Sensorless Force
  Estimation in Robotic Surgery</title><categories>cs.CV cs.NE eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing force feedback as relevant information in current Robot-Assisted
Minimally Invasive Surgery systems constitutes a technological challenge due to
the constraints imposed by the surgical environment. In this context,
Sensorless Force Estimation techniques represent a potential solution, enabling
to sense the interaction forces between the surgical instruments and
soft-tissues. Specifically, if visual feedback is available for observing
soft-tissues' deformation, this feedback can be used to estimate the forces
applied to these tissues. To this end, a force estimation model, based on
Convolutional Neural Networks and Long-Short Term Memory networks, is proposed
in this work. This model is designed to process both, the spatiotemporal
information present in video sequences and the temporal structure of tool data
(the surgical tool-tip trajectory and its grasping status). A series of
analyses are carried out to reveal the advantages of the proposal and the
challenges that remain for real applications. This research work focuses on two
surgical task scenarios, referred to as pushing and pulling tissue. For these
two scenarios, different input data modalities and their effect on the force
estimation quality are investigated. These input data modalities are tool data,
video sequences and a combination of both. The results suggest that the force
estimation quality is better when both, the tool data and video sequences, are
processed by the neural network model. Moreover, this study reveals the need
for a loss function, designed to promote the modeling of smooth and sharp
details found in force signals. Finally, the results show that the modeling of
forces due to pulling tasks is more challenging than for the simplest pushing
actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08559</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08559</id><created>2018-05-22</created><updated>2018-06-22</updated><authors><author><keyname>Park</keyname><forenames>Sungheon</forenames></author><author><keyname>Kim</keyname><forenames>Taehoon</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author><author><keyname>Kwak</keyname><forenames>Nojun</forenames></author></authors><title>Music Source Separation Using Stacked Hourglass Networks</title><categories>cs.SD eess.AS</categories><comments>ISMIR 2018, source code:
  https://github.com/sungheonpark/music_source_sepearation_SH_net</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a simple yet effective method for multiple music
source separation using convolutional neural networks. Stacked hourglass
network, which was originally designed for human pose estimation in natural
images, is applied to a music source separation task. The network learns
features from a spectrogram image across multiple scales and generates masks
for each music source. The estimated mask is refined as it passes over stacked
hourglass modules. The proposed framework is able to separate multiple music
sources using a single network. Experimental results on MIR-1K and DSD100
datasets validate that the proposed method achieves competitive results
comparable to the state-of-the-art methods in multiple music source separation
and singing voice separation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08615</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08615</id><created>2018-05-21</created><authors><author><keyname>Tripathi</keyname><forenames>Aditay</forenames></author><author><keyname>Mohan</keyname><forenames>Aanchan</forenames></author><author><keyname>Anand</keyname><forenames>Saket</forenames></author><author><keyname>Singh</keyname><forenames>Maneesh</forenames></author></authors><title>Adversarial Learning of Raw Speech Features for Domain Invariant Speech
  Recognition</title><categories>eess.AS cs.SD</categories><comments>5 pages, 1 figure, 2 tabels, ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in neural network based acoustic modelling have shown
significant improvements in automatic speech recognition (ASR) performance. In
order for acoustic models to be able to handle large acoustic variability,
large amounts of labeled data is necessary, which are often expensive to
obtain. This paper explores the application of adversarial training to learn
features from raw speech that are invariant to acoustic variability. This
acoustic variability is referred to as a domain shift in this paper. The
experimental study presented in this paper leverages the architecture of Domain
Adversarial Neural Networks (DANNs) [1] which uses data from two different
domains. The DANN is a Y-shaped network that consists of a multi-layer CNN
feature extractor module that is common to a label (senone) classifier and a
so-called domain classifier. The utility of DANNs is evaluated on multiple
datasets with domain shifts caused due to differences in gender and speaker
accents. Promising empirical results indicate the strength of adversarial
training for unsupervised domain adaptation in ASR, thereby emphasizing the
ability of DANNs to learn domain invariant features from raw speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08626</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08626</id><created>2018-05-20</created><authors><author><keyname>De Blasi</keyname><forenames>Stefano</forenames></author></authors><title>Simulation of Large Scale Neural Networks for Evaluation Applications</title><categories>q-bio.NC eess.SP</categories><comments>Poster 2018, Prague May 10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the complexity of biological neural networks like the human
brain is one of the scientific challenges of our century. The organization of
the brain can be described at different levels, ranging from small neural
networks to entire brain regions. Existing methods for the description of
functionally or effective connectivity are based on the analysis of relations
between the activities of different neural units by detecting correlations or
information flow. This is a crucial step in understanding neural disorders like
Alzheimers disease and their causative factors. To evaluate these estimation
methods, it is necessary to refer to a neural network with known connectivity,
which is typically unknown for natural biological neural networks. Therefore,
network simulations, also in silico, are available. In this work, the in silico
simulation of large scale neural networks is established and the influence of
different topologies on the generated patterns of neuronal signals is
investigated. The goal is to develop standard evaluation methods for
neurocomputational algorithms with a realistic large scale model to enable
benchmarking and comparability of different studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08633</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08633</id><created>2018-05-21</created><updated>2018-06-22</updated><authors><author><keyname>George</keyname><forenames>Jithin Donny</forenames></author></authors><title>The right way to teach the FFT</title><categories>eess.SP math.NA</categories><comments>Corrected typos and added more details</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The algorithm behind the Fast Fourier Transform has a simple yet beautiful
geometric interpretation that is often lost in translation in a classroom. This
article provides a visual perspective which aims to capture the essence of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08641</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08641</id><created>2018-05-21</created><authors><author><keyname>Hibraj</keyname><forenames>Feliks</forenames></author><author><keyname>Vascon</keyname><forenames>Sebastiano</forenames></author><author><keyname>Stadelmann</keyname><forenames>Thilo</forenames></author><author><keyname>Pelillo</keyname><forenames>Marcello</forenames></author></authors><title>Speaker Clustering Using Dominant Sets</title><categories>cs.SD eess.AS</categories><comments>ICPR 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker clustering is the task of forming speaker-specific groups based on a
set of utterances. In this paper, we address this task by using Dominant Sets
(DS). DS is a graph-based clustering algorithm with interesting properties that
fits well to our problem and has never been applied before to speaker
clustering. We report on a comprehensive set of experiments on the TIMIT
dataset against standard clustering techniques and specific speaker clustering
methods. Moreover, we compare performances under different features by using
ones learned via deep neural network directly on TIMIT and other ones extracted
from a pre-trained VGGVox net. To asses the stability, we perform a sensitivity
analysis on the free parameters of our method, showing that performance is
stable under parameter changes. The extensive experimentation carried out
confirms the validity of the proposed method, reporting state-of-the-art
results under three different standard metrics. We also report reference
baseline results for speaker clustering on the entire TIMIT dataset for the
first time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08734</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08734</id><created>2018-05-22</created><authors><author><keyname>Quadri</keyname><forenames>Adnan</forenames></author></authors><title>A Utility-Based Channel Ranking for Cognitive Radio Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Growing number of wireless devices and networks has increased the demand for
the scarce resource, radio spectrum. Next generation communication
technologies, such as Cognitive Radio provides a promising solution to
efficiently utilize radio spectrum whilst delivering improved data
communication rate, service, and security. A cognitive radio system will be
able to sense the availability of radio frequencies, analyze the condition of
the sensed channels, and decide the best option for optimal communication. To
select the best option out of the overwhelming amount of information, a channel
ranking mechanism can be employed. While several channel ranking techniques
have been proposed, most of them only consider the occupancy rate of the sensed
channels. However, there are other significantly important parameters that
provide information on the condition of channels and should also be considered
during the ranking process. This paper proposes a utility-based channel ranking
mechanism that takes into account signal-to-noise ratio and the occupancy rate
of the channels to determine their usefulness or preference. The paper at first
discusses the need for channel ranking and the involved process. Then the
suitability of different mathematical functions is investigated for utility
modeling of the channel based on its SNR and occupancy. Finally, results are
provided that show improved channel ranking compared to that of spectrum
occupancy based ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08833</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08833</id><created>2018-04-30</created><authors><author><keyname>Kumar</keyname><forenames>Meghana Dinesh</forenames></author><author><keyname>Babaie</keyname><forenames>Morteza</forenames></author><author><keyname>Tizhoosh</keyname><forenames>Hamid</forenames></author></authors><title>Deep Barcodes for Fast Retrieval of Histopathology Scans</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted for publication in proceedings of the IEEE World Congress on
  Computational Intelligence (IEEE WCCI), Rio de Janeiro, Brazil, 8-3 July,
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the concept of deep barcodes and propose two methods to
generate them in order to expedite the process of classification and retrieval
of histopathology images. Since binary search is computationally less
expensive, in terms of both speed and storage, deep barcodes could be useful
when dealing with big data retrieval. Our experiments use the dataset Kimia
Path24 to test three pre-trained networks for image retrieval. The dataset
consists of 27,055 training images in 24 different classes with large
variability, and 1,325 test images for testing. Apart from the high-speed and
efficiency, results show a surprising retrieval accuracy of 71.62% for deep
barcodes, as compared to 68.91% for deep features and 68.53% for compressed
deep features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08855</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08855</id><created>2018-05-22</created><updated>2019-04-06</updated><authors><author><keyname>Heckel</keyname><forenames>Reinhard</forenames></author><author><keyname>Huang</keyname><forenames>Wen</forenames></author><author><keyname>Hand</keyname><forenames>Paul</forenames></author><author><keyname>Voroninski</keyname><forenames>Vladislav</forenames></author></authors><title>Rate-Optimal Denoising with Deep Neural Networks</title><categories>cs.IT cs.LG eess.SP math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks provide state-of-the-art performance for image
denoising, where the goal is to recover a near noise-free image from a noisy
observation. The underlying principle is that neural networks trained on large
datasets have empirically been shown to be able to generate natural images well
from a low-dimensional latent representation of the image. Given such a
generator network, a noisy image can be denoised by i) finding the closest
image in the range of the generator or by ii) passing it through an
encoder-generator architecture (known as an autoencoder). However, there is
little theory to justify this success, let alone to predict the denoising
performance as a function of the network parameters. In this paper we consider
the problem of denoising an image from additive Gaussian noise using the two
generator based approaches. In both cases, we assume the image is well
described by a deep neural network with ReLU activations functions, mapping a
$k$-dimensional code to an $n$-dimensional image. In the case of the
autoencoder, we show that the feedforward network reduces noise energy by a
factor of $O(k/n)$. In the case of optimizing over the range of a generative
model, we state and analyze a simple gradient algorithm that minimizes a
non-convex loss function, and provably reduces noise energy by a factor of
$O(k/n)$. We also demonstrate in numerical experiments that this denoising
performance is, indeed, achieved by generative priors learned from data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08865</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08865</id><created>2018-05-09</created><authors><author><keyname>Banerjee</keyname><forenames>Adrish</forenames></author><author><keyname>Dubey</keyname><forenames>Akash</forenames></author><author><keyname>Menon</keyname><forenames>Abhishek</forenames></author><author><keyname>Nanda</keyname><forenames>Shubham</forenames></author><author><keyname>Nandi</keyname><forenames>Gora Chand</forenames></author></authors><title>Speaker Recognition using Deep Belief Networks</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short time spectral features such as mel frequency cepstral
coefficients(MFCCs) have been previously deployed in state of the art speaker
recognition systems, however lesser heed has been paid to short term spectral
features that can be learned by generative learning models from speech signals.
Higher dimensional encoders such as deep belief networks (DBNs) could improve
performance in speaker recognition tasks by better modelling the statistical
structure of sound waves. In this paper, we use short term spectral features
learnt from the DBN augmented with MFCC features to perform the task of speaker
recognition. Using our features, we achieved a recognition accuracy of 0.95 as
compared to 0.90 when using standalone MFCC features on the ELSDSR dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08867</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.08867</id><created>2018-05-22</created><updated>2020-01-15</updated><authors><author><keyname>Zevenhoven</keyname><forenames>Koos C. J.</forenames></author><author><keyname>M&#xe4;kinen</keyname><forenames>Antti J.</forenames></author><author><keyname>Ilmoniemi</keyname><forenames>Risto J.</forenames></author></authors><title>Superconducting receiver arrays for magnetic resonance imaging</title><categories>physics.ins-det cond-mat.supr-con eess.IV eess.SP physics.app-ph</categories><journal-ref>Biomedical Physics &amp; Engineering Express 6:015016 (2020)</journal-ref><doi>10.1088/2057-1976/ab5c61</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superconducting QUantum-Interference Devices (SQUIDs) make magnetic resonance
imaging (MRI) possible in ultra-low microtesla-range magnetic fields. In this
work, we investigate the design parameters affecting the signal and noise
performance of SQUID-based sensors and multichannel magnetometers for MRI of
the brain. Besides sensor intrinsics, various noise sources along with the
size, geometry and number of superconducting detector coils are important
factors affecting the image quality. We derive figures of merit based on
optimal combination of multichannel data, analyze different sensor array
designs, and provide tools for understanding the signal detection and the
different noise mechanisms. The work forms a guide to making design decisions
for both imagingand sensor-oriented readers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09110</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09110</id><created>2018-05-22</created><updated>2019-07-16</updated><authors><author><keyname>Tierny</keyname><forenames>Julien</forenames></author><author><keyname>Favelier</keyname><forenames>Guillaume</forenames></author><author><keyname>Levine</keyname><forenames>Joshua A.</forenames></author><author><keyname>Gueunet</keyname><forenames>Charles</forenames></author><author><keyname>Michaux</keyname><forenames>Michael</forenames></author></authors><title>The Topology ToolKit</title><categories>cs.GR cs.CG cs.CV eess.IV</categories><journal-ref>IEEE Trans. Vis. Comput. Graph. 24(1) (2018) 832-842</journal-ref><doi>10.1109/TVCG.2017.2743938</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This system paper presents the Topology ToolKit (TTK), a software platform
designed for topological data analysis in scientific visualization. TTK
provides a unified, generic, efficient, and robust implementation of key
algorithms for the topological analysis of scalar data, including: critical
points, integral lines, persistence diagrams, persistence curves, merge trees,
contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots,
Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due
to a tight integration with ParaView. It is also easily accessible to
developers through a variety of bindings (Python, VTK/C++) for fast prototyping
or through direct, dependence-free, C++, to ease integration into pre-existing
complex systems. While developing TTK, we faced several algorithmic and
software engineering challenges, which we document in this paper. In
particular, we present an algorithm for the construction of a discrete gradient
that complies to the critical points extracted in the piecewise-linear setting.
This algorithm guarantees a combinatorial consistency across the topological
abstractions supported by TTK, and importantly, a unified implementation of
topological data simplification for multi-scale exploration and analysis. We
also present a cached triangulation data structure, that supports time
efficient and generic traversals, which self-adjusts its memory usage on demand
for input simplicial meshes and which implicitly emulates a triangulation for
regular grids with no memory overhead. Finally, we describe an original
software architecture, which guarantees memory efficient and direct accesses to
TTK features, while still allowing for researchers powerful and easy bindings
and extensions. TTK is open source (BSD license) and its code, online
documentation and video tutorials are available on TTK's website.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09146</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09146</id><created>2018-05-23</created><authors><author><keyname>Sandri</keyname><forenames>Gustavo</forenames></author><author><keyname>de Queiroz</keyname><forenames>Ricado L.</forenames></author><author><keyname>Chou</keyname><forenames>Philip A.</forenames></author></authors><title>Comments on &quot;Compression of 3D Point Clouds Using a Region-Adaptive
  Hierarchical Transform&quot;</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently introduced coder based on region-adaptive hierarchical transform
(RAHT) for the compression of point clouds attributes, was shown to have a
performance competitive with the state-of-the-art, while being much less
complex. In the paper &quot;Compression of 3D Point Clouds Using a Region-Adaptive
Hierarchical Transform&quot;, top performance was achieved using arithmetic coding
(AC), while adaptive run-length Golomb-Rice (RLGR) coding was presented as a
lower-performance lower-complexity alternative. However, we have found that by
reordering the RAHT coefficients we can largely increase the runs of zeros and
significantly increase the performance of the RLGR-based RAHT coder. As a
result, the new coder, using ordered coefficients, was shown to outperform all
other coders, including AC-based RAHT, at an even lower computational cost. We
present new results and plots that should enhance those in the work of Queiroz
and Chou to include the new results for RLGR-RAHT. We risk to say, based on the
results herein, that RLGR-RAHT with sorted coefficients is the new
state-of-the-art in point cloud compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09164</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09164</id><created>2018-05-22</created><authors><author><keyname>Chettri</keyname><forenames>Bhusan</forenames></author><author><keyname>Mishra</keyname><forenames>Saumitra</forenames></author><author><keyname>Sturm</keyname><forenames>Bob L.</forenames></author><author><keyname>Benetos</keyname><forenames>Emmanouil</forenames></author></authors><title>A Study On Convolutional Neural Network Based End-To-End Replay
  Anti-Spoofing</title><categories>eess.AS cs.SD</categories><comments>6 pages</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The second Automatic Speaker Verification Spoofing and Countermeasures
challenge (ASVspoof 2017) focused on &quot;replay attack&quot; detection. The best
deep-learning systems to compete in ASVspoof 2017 used Convolutional Neural
Networks (CNNs) as a feature extractor. In this paper, we study their
performance in an end-to-end setting. We find that these architectures show
poor generalization in the evaluation dataset, but find a compact architecture
that shows good generalization on the development data. We demonstrate that for
this dataset it is not easy to obtain a similar level of generalization on both
the development and evaluation data. This leads to a variety of open questions
about what the differences are in the data; why these are more evident in an
end-to-end setting; and how these issues can be overcome by increasing the
training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09181</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09181</id><created>2018-05-23</created><updated>2018-06-15</updated><authors><author><keyname>Ram&#xed;rez-Espinosa</keyname><forenames>Pablo</forenames></author><author><keyname>Moreno-Pozas</keyname><forenames>Laureano</forenames></author><author><keyname>Paris</keyname><forenames>Jos&#xe9; F.</forenames></author><author><keyname>Cort&#xe9;s</keyname><forenames>Jos&#xe9; A.</forenames></author><author><keyname>Martos-Naya</keyname><forenames>Eduardo</forenames></author></authors><title>A New Approach to the Statistical Analysis of Non-Central Complex
  Gaussian Quadratic Forms with Applications</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel approach to the statistical characterization of
non-central complex Gaussian quadratic forms (CGQFs). Its key strategy is the
generation of an auxiliary random variable (RV) that converges in distribution
to the original CGQF. Since the mean squared error between both is given in a
simple closed-form formulation, the auxiliary RV can be particularized to
achieve the required accuracy. The technique is valid for both definite and
indefinite CGQFs and yields simple expressions of the probability density
function (PDF) and the cumulative distribution function (CDF) that involve only
elementary functions. This overcomes a major limitation of previous approaches,
in which the complexity of the resulting PDF and CDF prevents from using them
for subsequent calculations. To illustrate this end, the proposed method is
applied to maximal ratio combining systems over correlated Rician channels, for
which the outage probability and the average bit error rate are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09197</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09197</id><created>2018-05-23</created><updated>2018-06-01</updated><authors><author><keyname>Tits</keyname><forenames>No&#xe9;</forenames></author><author><keyname>Haddad</keyname><forenames>Kevin El</forenames></author><author><keyname>Dutoit</keyname><forenames>Thierry</forenames></author></authors><title>ASR-based Features for Emotion Recognition: A Transfer Learning Approach</title><categories>eess.AS cs.AI cs.CL cs.SD</categories><comments>Accepted to be published in the First Workshop on Computational
  Modeling of Human Multimodal Language - ACL 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last decade, the applications of signal processing have
drastically improved with deep learning. However areas of affecting computing
such as emotional speech synthesis or emotion recognition from spoken language
remains challenging. In this paper, we investigate the use of a neural
Automatic Speech Recognition (ASR) as a feature extractor for emotion
recognition. We show that these features outperform the eGeMAPS feature set to
predict the valence and arousal emotional dimensions, which means that the
audio-to-text mapping learning by the ASR system contain information related to
the emotional dimensions in spontaneous speech. We also examine the
relationship between first layers (closer to speech) and last layers (closer to
text) of the ASR and valence/arousal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09260</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09260</id><created>2018-05-23</created><authors><author><keyname>Badarneh</keyname><forenames>Osamah S.</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author><author><keyname>Cotton</keyname><forenames>Simon L.</forenames></author><author><keyname>Rabie</keyname><forenames>Khaled</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>On the Secrecy Capacity of Fisher-Snedecor F Fading Channels</title><categories>eess.SP</categories><comments>Submitted to GloemCom2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of physical-layer security of the classic Wyner's wiretap
model over Fisher-Snedecor F composite fading channels is considered in this
work. Specifically, the main channel (i.e., between the source and the
legitimate destination) and the eavesdropper's channel (i.e., between the
source and the illegitimate destination) are assumed to experience independent
quasi-static Fisher-Snedecor F fading conditions, which have been shown to be
encountered in realistic wireless transmission scenarios in conventional and
emerging communication systems. In this context, exact closed-form expressions
for the average secrecy capacity (ASC) and the probability of non-zero secrecy
capacity (PNSC) are derived. Additionally, an asymptotic analytical expression
for the ASC is also presented. The impact of shadowing and multipath fading on
the secrecy performance is investigated. Our results show that increasing the
fading parameter of the main channel and or the shadowing parameter of the
eavesdropper's channel improves the secrecy performance. The analytical results
are compared with Monte-Carlo simulations to validate the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09313</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09313</id><created>2018-05-23</created><updated>2018-07-19</updated><authors><author><keyname>Vougioukas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Petridis</keyname><forenames>Stavros</forenames></author><author><keyname>Pantic</keyname><forenames>Maja</forenames></author></authors><title>End-to-End Speech-Driven Facial Animation with Temporal GANs</title><categories>eess.AS cs.CV cs.SD eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech-driven facial animation is the process which uses speech signals to
automatically synthesize a talking character. The majority of work in this
domain creates a mapping from audio features to visual features. This often
requires post-processing using computer graphics techniques to produce
realistic albeit subject dependent results. We present a system for generating
videos of a talking head, using a still image of a person and an audio clip
containing speech, that doesn't rely on any handcrafted intermediate features.
To the best of our knowledge, this is the first method capable of generating
subject independent realistic videos directly from raw audio. Our method can
generate videos which have (a) lip movements that are in sync with the audio
and (b) natural facial expressions such as blinks and eyebrow movements. We
achieve this by using a temporal GAN with 2 discriminators, which are capable
of capturing different aspects of the video. The effect of each component in
our system is quantified through an ablation study. The generated videos are
evaluated based on their sharpness, reconstruction quality, and lip-reading
accuracy. Finally, a user study is conducted, confirming that temporal GANs
lead to more natural sequences than a static GAN-based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09366</identifier>
 <datestamp>2018-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09366</id><created>2018-05-23</created><updated>2018-11-19</updated><authors><author><keyname>Zhu</keyname><forenames>Zining</forenames></author><author><keyname>Novikova</keyname><forenames>Jekaterina</forenames></author><author><keyname>Rudzicz</keyname><forenames>Frank</forenames></author></authors><title>Semi-supervised classification by reaching consensus among modalities</title><categories>cs.LG cs.MM cs.SD eess.AS eess.SP stat.ML</categories><comments>NIPS IRASL Workshop 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has demonstrated abilities to learn complex structures, but
they can be restricted by available data. Recently, Consensus Networks (CNs)
were proposed to alleviate data sparsity by utilizing features from multiple
modalities, but they too have been limited by the size of labeled data. In this
paper, we extend CN to Transductive Consensus Networks (TCNs), suitable for
semi-supervised learning. In TCNs, different modalities of input are compressed
into latent representations, which we encourage to become indistinguishable
during iterative adversarial training. To understand TCNs two mechanisms,
consensus and classification, we put forward its three variants in ablation
studies on these mechanisms. To further investigate TCN models, we treat the
latent representations as probability distributions and measure their
similarities as the negative relative Jensen-Shannon divergences. We show that
a consensus state beneficial for classification desires a stable but imperfect
similarity between the representations. Overall, TCNs outperform or align with
the best benchmark algorithms given 20 to 200 labeled samples on the Bank
Marketing and the DementiaBank datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09498</identifier>
 <datestamp>2018-05-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09498</id><created>2018-05-23</created><authors><author><keyname>Ito</keyname><forenames>Nobutaka</forenames></author><author><keyname>Nakatani</keyname><forenames>Tomohiro</forenames></author></authors><title>FastFCA-AS: Joint Diagonalization Based Acceleration of Full-Rank
  Spatial Covariance Analysis for Separating Any Number of Sources</title><categories>cs.SD eess.AS</categories><comments>Submitted to IWAENC2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we propose FastFCA-AS, an accelerated algorithm for Full-rank spatial
Covariance Analysis (FCA), which is a robust audio source separation method
proposed by Duong et al. [&quot;Under-determined reverberant audio source separation
using a full-rank spatial covariance model,&quot; IEEE Trans. ASLP, vol. 18, no. 7,
pp. 1830-1840, Sept. 2010]. In the conventional FCA, matrix inversion and
matrix multiplication are required at each time-frequency point in each
iteration of an iterative parameter estimation algorithm. This causes a heavy
computational load, thereby rendering the FCA infeasible in many applications.
To overcome this drawback, we take a joint diagonalization approach, whereby
matrix inversion and matrix multiplication are reduced to mere inversion and
multiplication of diagonal entries. This makes the FastFCA-AS significantly
faster than the FCA and even applicable to observed data of long duration or a
situation with restricted computational resources. Although we have already
proposed another acceleration of the FCA for two sources, the proposed
FastFCA-AS is applicable to an arbitrary number of sources. In an experiment
with three sources and three microphones, the FastFCA-AS was over 420 times
faster than the FCA with a slightly better source separation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09633</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09633</id><created>2018-05-24</created><updated>2019-09-01</updated><authors><author><keyname>Tallamraju</keyname><forenames>Rahul</forenames></author><author><keyname>Rajappa</keyname><forenames>Sujit</forenames></author><author><keyname>Black</keyname><forenames>Michael</forenames></author><author><keyname>Karlapalem</keyname><forenames>Kamalakar</forenames></author><author><keyname>Ahmad</keyname><forenames>Aamir</forenames></author></authors><title>Decentralized MPC based Obstacle Avoidance for Multi-Robot Target
  Tracking Scenarios</title><categories>cs.RO cs.MA cs.SY eess.SY</categories><journal-ref>2018 IEEE SSRR, Philadelphia, PA, 2018, pp. 1-8</journal-ref><doi>10.1109/SSRR.2018.8468655</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the problem of decentralized multi-robot target
tracking and obstacle avoidance in dynamic environments. Each robot executes a
local motion planning algorithm which is based on model predictive control
(MPC). The planner is designed as a quadratic program, subject to constraints
on robot dynamics and obstacle avoidance. Repulsive potential field functions
are employed to avoid obstacles. The novelty of our approach lies in embedding
these non-linear potential field functions as constraints within a convex
optimization framework. Our method convexifies non-convex constraints and
dependencies, by replacing them as pre-computed external input forces in robot
dynamics. The proposed algorithm additionally incorporates different methods to
avoid field local minima problems associated with using potential field
functions in planning. The motion planner does not enforce predefined
trajectories or any formation geometry on the robots and is a comprehensive
solution for cooperative obstacle avoidance in the context of multi-robot
target tracking. We perform simulation studies in different environmental
scenarios to showcase the convergence and efficacy of the proposed algorithm.
Video of simulation studies: \url{https://youtu.be/umkdm82Tt0M}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09654</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09654</id><created>2018-05-24</created><updated>2018-05-26</updated><authors><author><keyname>La Tour</keyname><forenames>Tom Dupr&#xe9;</forenames></author><author><keyname>Moreau</keyname><forenames>Thomas</forenames></author><author><keyname>Jas</keyname><forenames>Mainak</forenames></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames></author></authors><title>Multivariate Convolutional Sparse Coding for Electromagnetic Brain
  Signals</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency-specific patterns of neural activity are traditionally interpreted
as sustained rhythmic oscillations, and related to cognitive mechanisms such as
attention, high level visual processing or motor control. While alpha waves
(8-12 Hz) are known to closely resemble short sinusoids, and thus are revealed
by Fourier analysis or wavelet transforms, there is an evolving debate that
electromagnetic neural signals are composed of more complex waveforms that
cannot be analyzed by linear filters and traditional signal representations. In
this paper, we propose to learn dedicated representations of such recordings
using a multivariate convolutional sparse coding (CSC) algorithm. Applied to
electroencephalography (EEG) or magnetoencephalography (MEG) data, this method
is able to learn not only prototypical temporal waveforms, but also associated
spatial patterns so their origin can be localized in the brain. Our algorithm
is based on alternated minimization and a greedy coordinate descent solver that
leads to state-of-the-art running time on long time series. To demonstrate the
implications of this method, we apply it to MEG data and show that it is able
to recover biological artifacts. More remarkably, our approach also reveals the
presence of non-sinusoidal mu-shaped patterns, along with their topographic
maps related to the somatosensory cortex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09679</identifier>
 <datestamp>2019-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09679</id><created>2018-05-24</created><updated>2018-07-23</updated><authors><author><keyname>Mirabilii</keyname><forenames>Daniele</forenames></author><author><keyname>Habets</keyname><forenames>Emanu&#xeb;l A. P.</forenames></author></authors><title>Simulating Multi-channel Wind Noise Based on the Corcos Model</title><categories>eess.AS cs.SD</categories><comments>5 pages, 2 figures, IWAENC 2018</comments><doi>10.1109/IWAENC.2018.8521302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel multi-channel artificial wind noise generator based on a fluid
dynamics model, namely the Corcos model, is proposed. In particular, the model
is used to approximate the complex coherence function of wind noise signals
measured with closely-spaced microphones in the free-field and for
time-invariant wind stream direction and speed. Preliminary experiments focus
on a spatial analysis of recorded wind noise signals and the validation of the
Corcos model for diverse measurement set-ups. Subsequently, the Corcos model is
used to synthetically generate wind noise signals exhibiting the desired
complex coherence. The multi-channel generator is designed extending an
existing single-channel generator to create N mutually uncorrelated signals,
while the predefined complex coherence function is obtained exploiting an
algorithm developed to generate multi-channel non-stationary noise signals
under a complex coherence constraint. Temporal, spectral and spatial
characteristics of synthetic signals match with those observed in measured wind
noise. The artificial generation overcomes the time-consuming challenge of
collecting pure wind noise samples for noise reduction evaluations and provides
flexibility in the number of generated signals used in the simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09752</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09752</id><created>2018-05-24</created><updated>2018-06-13</updated><authors><author><keyname>Zhu</keyname><forenames>Boqing</forenames></author><author><keyname>Xu</keyname><forenames>Kele</forenames></author><author><keyname>Wang</keyname><forenames>Dezhi</forenames></author><author><keyname>Zhang</keyname><forenames>Lilun</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Peng</keyname><forenames>Yuxing</forenames></author></authors><title>Environmental Sound Classification Based on Multi-temporal Resolution
  Convolutional Neural Network Combining with Multi-level Features</title><categories>cs.SD eess.AS</categories><comments>Submit to PCM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the fact that characteristics of different sound classes are
highly diverse in different temporal scales and hierarchical levels, a novel
deep convolutional neural network (CNN) architecture is proposed for the
environmental sound classification task. This network architecture takes raw
waveforms as input, and a set of separated parallel CNNs are utilized with
different convolutional filter sizes and strides, in order to learn feature
representations with multi-temporal resolutions. On the other hand, the
proposed architecture also aggregates hierarchical features from multi-level
CNN layers for classification using direct connections between convolutional
layers, which is beyond the typical single-level CNN features employed by the
majority of previous studies. This network architecture also improves the flow
of information and avoids vanishing gradient problem. The combination of
multi-level features boosts the classification performance significantly.
Comparative experiments are conducted on two datasets: the environmental sound
classification dataset (ESC-50), and DCASE 2017 audio scene classification
dataset. Results demonstrate that the proposed method is highly effective in
the classification tasks by employing multi-temporal resolution and multi-level
features, and it outperforms the previous methods which only account for
single-level features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09779</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09779</id><created>2018-05-24</created><authors><author><keyname>Mohammadi</keyname><forenames>Ali</forenames></author><author><keyname>Mehrtash</keyname><forenames>Mahdi</forenames></author><author><keyname>Kargarian</keyname><forenames>Amin</forenames></author><author><keyname>Barati</keyname><forenames>Masoud</forenames></author></authors><title>Tie-Line Characteristics based Partitioning for Distributed Optimization
  of Power Systems</title><categories>eess.SP</categories><doi>10.1109/PESGM.2018.8586072</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The convergence performance of distributed optimization algorithms is of
significant importance to solve optimal power flow (OPF) in a distributed
fashion. In this paper, we aim to provide some insights on how to partition a
power system to achieve a high convergence rate of distributed algorithms for
the solution of an OPF problem. We analyzed several features of the power
network to find a set of suitable partitions with the aim of convergence
performance improvement. We model the grid as a graph and decompose it based on
the edge betweenness graph clustering. This technique provides several
partitions. To find an effective partitioning, we merge the partitions obtained
by clustering technique and analyze them based on characteristics of tie-lines
connecting neighboring partitions. The main goal is to find the best set of
partitions with respect to the convergence speed. We deploy analytical target
cascading (ATC) method to distributedly solve optimization subproblems. We test
the proposed algorithm on the IEEE 118-bus system. The results show that the
algorithm converges faster with a proper partitioning, whereas improper
partitioning leads to a large number of iterations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09846</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09846</id><created>2018-05-24</created><updated>2018-07-11</updated><authors><author><keyname>Du</keyname><forenames>Ming</forenames></author><author><keyname>Vescovi</keyname><forenames>Rafael</forenames></author><author><keyname>Fezzaa</keyname><forenames>Kamel</forenames></author><author><keyname>Jacobsen</keyname><forenames>Chris</forenames></author><author><keyname>Gursoy</keyname><forenames>Doga</forenames></author></authors><title>X-ray tomography of extended objects: a comparison of data acquisition
  approaches</title><categories>eess.IV</categories><comments>Under review</comments><doi>10.1364/JOSAA.35.001871</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The penetration power of x-rays allows one to image large objects. For
example, centimeter-sized specimens can be imaged with micron-level resolution
using synchrotron sources. In this case, however, the limited beam diameter and
detector size preclude the acquisition of the full sample in a single take,
necessitating strategies for combining data from multiple regions. Object
stitching involves the combination of local tomography data from overlapping
regions, while projection stitching involves the collection of projections at
multiple offset positions from the rotation axis followed by data merging and
reconstruction. We compare these two approaches in terms of radiation dose
applied to the specimen, and reconstructed image quality. Object stitching
involves an easier data alignment problem, and immediate viewing of subregions
before the entire dataset has been acquired. Projection stitching is more
dose-efficient, and avoids certain artifacts of local tomography; however, it
also involves a more difficult data assembly and alignment procedure, in that
it is more sensitive to accumulative registration error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09913</identifier>
 <datestamp>2018-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09913</id><created>2018-05-24</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Periyasamy</keyname><forenames>Vijitha</forenames></author><author><keyname>Pramanik</keyname><forenames>Manojit</forenames></author><author><keyname>Makkiabadi</keyname><forenames>Bahador</forenames></author></authors><title>An Efficient Nonlinear Beamformer Based on P^{th} Root of Detected
  Signals for Linear-Array Photoacoustic Tomography: Application to Sentinel
  Lymph Node Imaging</title><categories>eess.SP physics.ins-det physics.med-ph</categories><journal-ref>Journal of Biomedical Optics, 23(12), 121604 (2018)</journal-ref><doi>10.1117/1.JBO.23.12.121604</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In linear-array transducer based photoacoustic (PA) imaging, B-scan PA images
are formed using the raw channel PA signals. Delay-and-Sum (DAS) is the most
prevalent algorithm due to its simple implementation, but it leads to low
quality images. Delay-Multiply-and-Sum (DMAS) provides a higher image quality
in comparison with DAS while it imposes a computational burden of O(M^2). In
this work, we introduce a nonlinear (NL) beamformer for linear-array PA
imaging, which uses the p^{th} root of the detected signals and imposes the
complexity of DAS (O(M)). The proposed algorithm is evaluated numerically and
experimentally (wire-target and in vivo sentinel lymph node (SLN) imaging), and
the effects of the parameter p are investigated. The results show that the NL
algorithm, using a root of p (NL_p), leads to lower sidelobes and higher
signal-to-noise ratio (SNR) compared to DAS and DMAS, for (p &gt; 2). The
sidelobes level (for the wire-target phantom), at the depth of 11.4 mm, are
about -31 dB, -52 dB, -52 dB, -67 dB, -88 dB and -109 dB, for DAS, DMAS, NL_2,
NL_3, NL_4 and NL_5, respectively, indicating the superiority of the NL_p
algorithm. In addition, the best value of p for SLN imaging is reported to be
12.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.09923</identifier>
 <datestamp>2019-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.09923</id><created>2018-05-24</created><updated>2019-04-16</updated><authors><author><keyname>Yang</keyname><forenames>Hong-Chuan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Wireless Transmission of Big Data: Data-oriented Performance Limits and
  Their Applications</title><categories>eess.SP cs.IT math.IT</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing popularity of big data and Internet of Things (IoT) applications
bring new challenges to the wireless communication community. Wireless
transmission systems should more efficiently support the large amount of data
traffics from diverse types of information sources. In this article, we
introduce a novel data-oriented approach for the design and optimization of
wireless transmission strategies. Specifically, we define new performance
metrics for individual data transmission session and apply them to compare two
popular channel-adaptive transmission strategies. We develop several
interesting and somewhat counterintuitive observations on these transmission
strategies, which would not be possible with conventional approach. We also
present several interesting future research directions that are worth pursuing
with the data-oriented approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10004</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10004</id><created>2018-05-25</created><updated>2019-04-27</updated><authors><author><keyname>Medhat</keyname><forenames>Fady</forenames></author><author><keyname>Chesmore</keyname><forenames>David</forenames></author><author><keyname>Robinson</keyname><forenames>John</forenames></author></authors><title>Masked Conditional Neural Networks for Environmental Sound
  Classification</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Conditional Neural Networks, CLNN, Masked Conditional Neural
  Networks, MCLNN, Restricted Boltzmann Machine, RBM, Conditional Restricted
  Boltz-mann Machine, CRBM, Deep Belief Nets, Environmental Sound Recognition,
  ESR, YorNoise</comments><journal-ref>Artificial Intelligence XXXIV. SGAI 2017</journal-ref><doi>10.1007/978-3-319-71078-5_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ConditionaL Neural Network (CLNN) exploits the nature of the temporal
sequencing of the sound signal represented in a spectrogram, and its variant
the Masked ConditionaL Neural Network (MCLNN) induces the network to learn in
frequency bands by embedding a filterbank-like sparseness over the network's
links using a binary mask. Additionally, the masking automates the exploration
of different feature combinations concurrently analogous to handcrafting the
optimum combination of features for a recognition task. We have evaluated the
MCLNN performance using the Urbansound8k dataset of environmental sounds.
Additionally, we present a collection of manually recorded sounds for rail and
road traffic, YorNoise, to investigate the confusion rates among machine
generated sounds possessing low-frequency components. MCLNN has achieved
competitive results without augmentation and using 12% of the trainable
parameters utilized by an equivalent model based on state-of-the-art
Convolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k
dataset with YorNoise, where experiments have shown that common tonal
properties affect the classification performance.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="1000" completeListSize="16166">4250076|2001</resumptionToken>
</ListRecords>
</OAI-PMH>
