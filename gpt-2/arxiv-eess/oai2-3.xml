<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T06:57:56Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|2001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10185</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10185</id><created>2018-05-25</created><authors><author><keyname>Safdarian</keyname><forenames>Farnaz</forenames></author><author><keyname>Ciftci</keyname><forenames>Okan</forenames></author><author><keyname>Kargarian</keyname><forenames>Amin</forenames></author></authors><title>A Time Decomposition and Coordination Strategy for Power System
  Multi-Interval Operation</title><categories>eess.SP</categories><comments>5 pages, 4 figures, IEEE PES General Meeting (GM), August 5-9 2018,
  Portland, Oregon, USA</comments><doi>10.1109/PESGM.2018.8585766</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a time decomposition strategy to reduce the computational
complexity of power system multi-interval operation problems. We focus on the
economic dispatch problem. The considered scheduling horizon is decomposed into
multiple smaller sub-horizons. The first time interval of each sub-horizon is
modeled as the coupling interval between two consecutive sub-horizons. The
interdependencies between the sub-horizons are mathematically modeled using
ramp rates of generating units. A distributed coordination strategy, which is
based on auxiliary problem principle, is developed to coordinate the economic
dispatch solutions of the sub-horizons to find an optimal solution for the
whole operation horizon. We also propose an initializing technique to start the
iterative coordination algorithm from a good-enough point. This technique
enhances the convergence rate significantly. The proposed algorithm is deployed
to solve a week-ahead economic dispatch problem on the IEEE 118-bus system, and
promising results are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10198</identifier>
 <datestamp>2018-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10198</id><created>2018-05-25</created><authors><author><keyname>Burr</keyname><forenames>Alister</forenames></author><author><keyname>Bashar</keyname><forenames>Manijeh</forenames></author><author><keyname>Maryopi</keyname><forenames>Dick</forenames></author></authors><title>Cooperative access networks: Optimum fronthaul quantization in
  distributed Massive MIMO and cloud RAN</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages</comments><journal-ref>VTC 2018</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We consider cooperative radio access network architectures, especially
distributed massive MIMO and Cloud RAN, considering their similarities and
differences. We address in particular the major challenge posed to both by the
implementation of a high capacity fronthaul network to link the distributed
access points to the central processing unit, and consider the effect on uplink
performance of quantization of received signals in order to limit fronthaul
load. We use the Bussgang decomposition along with a new approach to MMSE
estimation of both channel and data to provide the basis of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10232</identifier>
 <datestamp>2019-03-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10232</id><created>2018-05-25</created><updated>2019-03-28</updated><authors><author><keyname>Drumetz</keyname><forenames>Lucas</forenames></author><author><keyname>Meyer</keyname><forenames>Travis R.</forenames></author><author><keyname>Chanussot</keyname><forenames>Jocelyn</forenames></author><author><keyname>Bertozzi</keyname><forenames>Andrea L.</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Hyperspectral Image Unmixing with Endmember Bundles and Group Sparsity
  Inducing Mixed Norms</title><categories>eess.IV</categories><comments>in IEEE Transactions on Image Processing,2019</comments><doi>10.1109/TIP.2019.2897254</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral images provide much more information than conventional imaging
techniques, allowing a precise identification of the materials in the observed
scene, but because of the limited spatial resolution, the observations are
usually mixtures of the contributions of several materials. The spectral
unmixing problem aims at recovering the spectra of the pure materials of the
scene (endmembers), along with their proportions (abundances) in each pixel. In
order to deal with the intra-class variability of the materials and the induced
spectral variability of the endmembers, several spectra per material,
constituting endmember bundles, can be considered. However, the usual abundance
estimation techniques do not take advantage of the particular structure of
these bundles, organized into groups of spectra. In this paper, we propose to
use group sparsity by introducing mixed norms in the abundance estimation
optimization problem. In particular, we propose a new penalty which
simultaneously enforces group and within group sparsity, to the cost of being
nonconvex. All the proposed penalties are compatible with the abundance
sum-to-one constraint, which is not the case with traditional sparse
regression. We show on simulated and real datasets that well chosen penalties
can significantly improve the unmixing performance compared to the naive bundle
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10333</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10333</id><created>2018-05-25</created><updated>2018-07-12</updated><authors><author><keyname>G&#xf6;&#xdf;ling</keyname><forenames>N.</forenames></author><author><keyname>Doclo</keyname><forenames>S.</forenames></author></authors><title>Relative Transfer Function Estimation Exploiting Spatially Separated
  Microphones in a Diffuse Noise Field</title><categories>eess.AS cs.SD</categories><comments>To appear in the Proc. of IWAENC2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many multi-microphone speech enhancement algorithms require the relative
transfer function (RTF) vector of the desired speech source, relating the
acoustic transfer functions of all array microphones to a reference microphone.
In this paper, we propose a computationally efficient method to estimate the
RTF vector in a diffuse noise field, which requires an additional microphone
that is spatially separated from the microphone array, such that the spatial
coherence between the noise components in the microphone array signals and the
additional microphone signal is low. Assuming this spatial coherence to be
zero, we show that an unbiased estimate of the RTF vector can be obtained.
Based on real-world recordings experimental results show that the proposed RTF
estimator outperforms state-of-the-art estimators using only the microphone
array signals in terms of estimation accuracy and noise reduction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10339</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10339</id><created>2018-05-25</created><authors><author><keyname>Lotfian</keyname><forenames>Reza</forenames></author><author><keyname>Busso</keyname><forenames>Carlos</forenames></author></authors><title>Curriculum Learning for Speech Emotion Recognition from Crowdsourced
  Labels</title><categories>eess.AS cs.SD</categories><comments>Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study introduces a method to design a curriculum for machine-learning to
maximize the efficiency during the training process of deep neural networks
(DNNs) for speech emotion recognition. Previous studies in other
machine-learning problems have shown the benefits of training a classifier
following a curriculum where samples are gradually presented in increasing
level of difficulty. For speech emotion recognition, the challenge is to
establish a natural order of difficulty in the training set to create the
curriculum. We address this problem by assuming that ambiguous samples for
humans are also ambiguous for computers. Speech samples are often annotated by
multiple evaluators to account for differences in emotion perception across
individuals. While some sentences with clear emotional content are consistently
annotated, sentences with more ambiguous emotional content present important
disagreement between individual evaluations. We propose to use the disagreement
between evaluators as a measure of difficulty for the classification task. We
propose metrics that quantify the inter-evaluation agreement to define the
curriculum for regression problems and binary and multi-class classification
problems. The experimental results consistently show that relying on a
curriculum based on agreement between human judgments leads to statistically
significant improvements over baselines trained without a curriculum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10379</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10379</id><created>2018-05-25</created><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author></authors><title>UWB Channel Sounding and Modeling for UAV Air-to-Ground Propagation
  Channels</title><categories>eess.SP</categories><comments>IEEE Globecom 2016 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) are expected to be used extensively in the
near future in applications such as aerial surveillance, transportation, and
disaster assistance. The conditions under which UAVs operate are different from
those of conventional piloted aircrafts. This necessitates development of new
air-to-ground (AG) propagation channel models for UAVs. To our best knowledge,
there are limited studies in the literature on sounding and modeling of
ultrawideband (UWB) AG propagation channels. In this work, comprehensive UWB
measurements are conducted for various UAV communication scenarios using Time
Domain P410 UWB kits. Both time and frequency domain analysis of the measured
data are carried out. Based on the measured data, stochastic path loss and
multipath channel models are developed to characterize AG UWB propagation
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10498</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10498</id><created>2018-05-26</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author></authors><title>Automatic context window composition for distant speech recognition</title><categories>eess.AS cs.LG cs.NE cs.SD</categories><comments>This is a preprint version of the paper published on Speech
  Communication Journal, 2018. Please see
  https://www.sciencedirect.com/science/article/pii/S0167639318300128 for the
  published version of this article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distant speech recognition is being revolutionized by deep learning, that has
contributed to significantly outperform previous HMM-GMM systems. A key aspect
behind the rapid rise and success of DNNs is their ability to better manage
large time contexts. With this regard, asymmetric context windows that embed
more past than future frames have been recently used with feed-forward neural
networks. This context configuration turns out to be useful not only to address
low-latency speech recognition, but also to boost the recognition performance
under reverberant conditions. This paper investigates on the mechanisms
occurring inside DNNs, which lead to an effective application of asymmetric
contexts.In particular, we propose a novel method for automatic context window
composition based on a gradient analysis. The experiments, performed with
different acoustic environments, features, DNN architectures, microphone
settings, and recognition tasks show that our simple and efficient strategy
leads to a less redundant frame configuration, which makes DNN training more
effective in reverberant scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10545</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10545</id><created>2018-05-26</created><authors><author><keyname>Baier</keyname><forenames>Gerald</forenames></author><author><keyname>Rossi</keyname><forenames>Cristian</forenames></author><author><keyname>Lachaise</keyname><forenames>Marie</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author><author><keyname>Bamler</keyname><forenames>Richard</forenames></author></authors><title>A Nonlocal InSAR Filter for High-Resolution DEM Generation from TanDEM-X
  Interferograms</title><categories>eess.IV eess.SP</categories><comments>Paper has been accepted to be published in IEEE Transaction on
  Geoscience and Remote Sensing</comments><doi>10.1109/TGRS.2018.2839027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a nonlocal InSAR filter with the goal of generating
digital elevation models of higher resolution and accuracy from bistatic
TanDEM-X strip map interferograms than with the processing chain used in
production. The currently employed boxcar multilooking filter naturally
decreases the resolution and has inherent limitations on what level of noise
reduction can be achieved. The proposed filter is specifically designed to
account for the inherent diversity of natural terrain by setting several
filtering parameters adaptively. In particular, it considers the local fringe
frequency and scene heterogeneity, ensuring proper denoising of interferograms
with considerable underlying topography as well as urban areas. A comparison
using synthetic and TanDEM-X bistatic strip map datasets with existing InSAR
filters shows the effectiveness of the proposed techniques, most of which could
readily be integrated into existing nonlocal filters. The resulting digital
elevation models outclass the ones produced with the existing global TanDEM-X
DEM processing chain by effectively increasing the resolution from 12m to 6m
and lowering the noise level by roughly a factor of two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10641</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10641</id><created>2018-05-27</created><authors><author><keyname>Tohidi</keyname><forenames>Ehsan</forenames></author><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Behroozi</keyname><forenames>Hamid</forenames></author><author><keyname>Nayebi</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Sparse Antenna and Pulse Placement for Colocated MIMO Radar</title><categories>eess.SP</categories><doi>10.1109/TSP.2018.2881656</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple input multiple output (MIMO) radar is known for its superiority over
conventional radar due to its antenna and waveform diversity. Although higher
angular resolution, improved parameter identifiability, and better target
detection are achieved, the hardware costs (due to multiple transmitters and
multiple receivers) and high energy consumption (multiple pulses) limit the
usage of MIMO radars in large scale networks. On one hand, higher angle and
velocity estimation accuracy is required, but on the other hand, a lower number
of antennas/pulses is desirable. To achieve such a compromise, in this work,
the Cram'er-Rao lower bound (CRLB) for the angle and velocity estimator is
employed as a performance metric to design the antenna and pulse placement. It
is shown that the CRLB derived for two targets is a more appropriate criterion
in comparison with the single-target CRLB since the two-target CRLB takes into
account both the mainlobe width and sidelobe level of the ambiguity function.
In this paper, several algorithms for antenna and pulse selection based on
convex and submodular optimization are proposed. Numerical experiments are
provided to illustrate the developed theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10644</identifier>
 <datestamp>2018-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10644</id><created>2018-05-27</created><authors><author><keyname>S.</keyname><forenames>Douglas Winston. R.</forenames></author><author><keyname>Laureano</keyname><forenames>Gustavo T.</forenames></author><author><keyname>Camilo</keyname><forenames>Celso G.</forenames><suffix>Jr</suffix></author></authors><title>Comparison of VCA and GAEE algorithms for Endmember Extraction</title><categories>cs.NE eess.IV</categories><comments>Accepted by IEEE CEC 2018: IEEE Congress on Evolutionary Computation</comments><msc-class>68T20, 68U10</msc-class><doi>10.1109/CEC.2018.8477743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Endmember Extraction is a critical step in hyperspectral image analysis and
classification. It is an useful method to decompose a mixed spectrum into a
collection of spectra and their corresponding proportions. In this paper, we
solve a linear endmember extraction problem as an evolutionary optimization
task, maximizing the Simplex Volume in the endmember space. We propose a
standard genetic algorithm and a variation with In Vitro Fertilization module
(IVFm) to find the best solutions and compare the results with the state-of-art
Vertex Component Analysis (VCA) method and the traditional algorithms Pixel
Purity Index (PPI) and N-FINDR. The experimental results on real and synthetic
hyperspectral data confirms the overcome in performance and accuracy of the
proposed approaches over the mentioned algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10731</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10731</id><created>2018-05-27</created><authors><author><keyname>Park</keyname><forenames>Tae Jin</forenames></author><author><keyname>Georgiou</keyname><forenames>Panayiotis</forenames></author></authors><title>Multimodal Speaker Segmentation and Diarization using Lexical and
  Acoustic Cues via Sequence to Sequence Neural Networks</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there has been substantial amount of work in speaker diarization
recently, there are few efforts in jointly employing lexical and acoustic
information for speaker segmentation. Towards that, we investigate a speaker
diarization system using a sequence-to-sequence neural network trained on both
lexical and acoustic features. We also propose a loss function that allows for
selecting not only the speaker change points but also the best speaker at any
time by allowing for different speaker groupings. We incorporate Mel Frequency
Cepstral Coefficients (MFCC) as an acoustic feature alongside lexical
information that are obtained from conversations from the Fisher dataset. Thus,
we show that acoustics provide complementary information to the lexical
modality. The experimental results show that sequence-to-sequence system
trained on both word sequences and MFCC can improve on speaker diarization
result compared to the system that only relies on lexical modality or the
baseline MFCC-based system. In addition, we test the performance of our
proposed method with Automatic Speech Recognition (ASR) transcripts. While the
performance on ASR transcripts drops, the Diarization Error Rate (DER) of our
proposed method still outperforms the traditional method based on Bayesian
Information Criterion (BIC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10808</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10808</id><created>2018-05-28</created><updated>2018-05-29</updated><authors><author><keyname>Wyse</keyname><forenames>Lonce</forenames></author></authors><title>Real-valued parametric conditioning of an RNN for interactive sound
  synthesis</title><categories>cs.SD cs.LG eess.AS</categories><comments>Wyse, Lonce. (2018), Real-valued parametric conditioning of an RNN
  for real-time interactive sound synthesis. 6th International Workshop on
  Musical Metacreation, International Conference on Computational Creativity
  (ICCC) June 25-26, 2018, Salamanca, Spain</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A Recurrent Neural Network (RNN) for audio synthesis is trained by augmenting
the audio input with information about signal characteristics such as pitch,
amplitude, and instrument. The result after training is an audio synthesizer
that is played like a musical instrument with the desired musical
characteristics provided as continuous parametric control. The focus of this
paper is on conditioning data-driven synthesis models with real-valued
parameters, and in particular, on the ability of the system a) to generalize
and b) to be responsive to parameter values and sequences not seen during
training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10864</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10864</id><created>2018-05-28</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Corcoran</keyname><forenames>Peter</forenames></author></authors><title>Versatile Auxiliary Regressor with Generative Adversarial network
  (VAR+GAN)</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being able to generate constrained samples is one of the most appealing
applications of the deep generators. Conditional generators are one of the
successful implementations of such models wherein the created samples are
constrained to a specific class. In this work, the application of these
networks is extended to regression problems wherein the conditional generator
is restrained to any continuous aspect of the data. A new loss function is
presented for the regression network and also implementations for generating
faces with any particular set of landmarks is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.10880</identifier>
 <datestamp>2018-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.10880</id><created>2018-05-28</created><authors><author><keyname>Kelz</keyname><forenames>Rainer</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Investigating Label Noise Sensitivity of Convolutional Neural Networks
  for Fine Grained Audio Signal Labelling</title><categories>cs.SD cs.LG eess.AS</categories><comments>accepted at ICASSP 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We measure the effect of small amounts of systematic and random label noise
caused by slightly misaligned ground truth labels in a fine grained audio
signal labeling task. The task we choose to demonstrate these effects on is
also known as framewise polyphonic transcription or note quantized multi-f0
estimation, and transforms a monaural audio signal into a sequence of note
indicator labels. It will be shown that even slight misalignments have clearly
apparent effects, demonstrating a great sensitivity of convolutional neural
networks to label noise. The implications are clear: when using convolutional
neural networks for fine grained audio signal labeling tasks, great care has to
be taken to ensure that the annotations have precise timing, and are free from
systematic or random error as much as possible - even small misalignments will
have a noticeable impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11087</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11087</id><created>2018-05-26</created><authors><author><keyname>Mohanty</keyname><forenames>Vaibhav</forenames></author></authors><title>Dodecatonic Cycles and Parsimonious Voice-Leading in the Mystic-Wozzeck
  Genus</title><categories>math.HO cs.SD eess.AS</categories><comments>13 pages, 17 figures, 1 table</comments><msc-class>00A65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a unified voice-leading model for the genus of mystic and
Wozzeck chords. These voice-leading regions are constructed by perturbing
symmetric partitions of the octave, and new Neo-Riemannian transformations
between nearly symmetric hexachords are defined. The behaviors of these
transformations are shown within visual representations of the voice-leading
regions for the mystic-Wozzeck genus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11171</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11171</id><created>2018-05-28</created><authors><author><keyname>Janaswamy</keyname><forenames>Ramakrishna</forenames></author><author><keyname>Loring</keyname><forenames>Pamela</forenames></author><author><keyname>McLaren</keyname><forenames>James</forenames></author></authors><title>A State Space Technique for Wildlife Position Estimation Using
  Non-Simultaneous Signal Strength Measurements</title><categories>eess.SP</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel state-space technique is presented to estimate the location and
airborne movements of VHF tagged wildlife individuals with fixed VHF arrays.
The approach combines a movement model (Ornstein- Uhlenbeck random process in
the transverse (horizontal) plane and a Cox- Ingersoll-Ross process in the
vertical direction) to ensure biologically-consistent trajectories in
three-dimensions, and an observation model to account for the effect of range,
altitude and bearing angle on the received signal strength. The observation
model of received signals accounts for low-end saturation from receiver noise,
high-end saturation from receiver non-linearities as well as a wireless
multipath phenomena, which modulates the received signal according to range,
the altitude and radiation characteristics of the Yagi array. A pattern
function for the Yagi array is synthesized that facilitates linearization of
the received signals and subsequent application of Kalman filtering.
  We first validate the model using a simulated trajectory and then estimate
the space-time trajectory of a migrating VHF-tagged shorebird, which was
tracked with a regional automated radio telemetry network. The algorithm
accurately predicted the average movement trajectory given the system
parameters and the initial conditions (average error $&lt;$ 1 km). The modeled
shorebird track represents a first estimate in three-dimensional (3D) of a
radio tagged bird using a fixed telemetry array, and was qualitatively
reasonable, but exhibited some sensitivity in the vertical plane and to initial
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11207</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11207</id><created>2018-05-28</created><authors><author><keyname>Yang</keyname><forenames>Yansong</forenames></author><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Manzaneque</keyname><forenames>Tomas</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>Toward Ka Band Acoustics: Lithium Niobate Asymmetrical Mode
  Piezoelectric MEMS Resonators</title><categories>physics.app-ph eess.SP</categories><comments>5 pages, 7 figures, 2018 IEEE International Frequency Control
  Symposium</comments><doi>10.1109/FCS.2018.8597475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a new class of micro-electro-mechanical system (MEMS)
resonators toward Ka band (26.5-40GHz) for fifth-generation (5G) wireless
communication. Resonant frequencies of 21.4 and 29.9 GHz have been achieved
using the fifth and seventh order asymmetric (A5 and A7) Lamb-wave modes in a
suspended Z-cut lithium niobate (LiNbO3) thin film. The fabricated device has
demonstrated an electromechanical coupling (kt2) of 1.5% and 0.94% and
extracted mechanical Qs of 406 and 474 for A5 and A7 respectively. The quality
factors are the highest reported for piezoelectric MEMS resonators operating at
this frequency range. The demonstrated performance has shown the strong
potential of LiNbO3 asymmetric mode devices to meet the front-end filtering
requirements of 5G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11208</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11208</id><created>2018-05-28</created><authors><author><keyname>Ruble</keyname><forenames>Macey</forenames></author><author><keyname>Guvenc</keyname><forenames>Dr. Ismail</forenames></author></authors><title>Wireless Localization for mmWave Networks in Urban Environments</title><categories>eess.SP</categories><doi>10.1186/s13634-018-0556-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) technology is expected to be a major component of 5G
wireless networks. Ultra-wide bandwidths of mmWave signals and the possibility
of utilizing large number of antennas at the transmitter and the receiver allow
accurate identification of multipath components in temporal and angular
domains, making mmWave systems advantageous for localization applications. In
this paper, we analyze the performance of a two-step mmWave localization
approach that can utilize time-of-arrival, angle-of-arrival, and
angle-of-departure from multiple nodes in an urban environment with both
line-of-sight (LOS) and non-LOS (NLOS) links. Networks with/without
radio-environmental mapping (REM) are considered, where a network with REM is
able to localize nearby scatterers. Estimation of a UE location is challenging
due to large numbers of local optima in the likelihood function. To address
this problem, a gradient-assisted particle filter (GAPF) estimator is proposed
to accurately estimate a user equipment (UE) location as well as the locations
of nearby scatterers. Monte Carlo simulations show that the GAPF estimator
performance matches the Cramer-Rao bound (CRB). The estimator is also used to
create an REM. It is seen that significant localization gains can be achieved
by increasing beam directionality or by utilizing REM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11264</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11264</id><created>2018-05-29</created><authors><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Disentangling by Partitioning: A Representation Learning Framework for
  Multimodal Sensory Data</title><categories>stat.ML cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal sensory data resembles the form of information perceived by humans
for learning, and are easy to obtain in large quantities. Compared to unimodal
data, synchronization of concepts between modalities in such data provides
supervision for disentangling the underlying explanatory factors of each
modality. Previous work leveraging multimodal data has mainly focused on
retaining only the modality-invariant factors while discarding the rest. In
this paper, we present a partitioned variational autoencoder (PVAE) and several
training objectives to learn disentangled representations, which encode not
only the shared factors, but also modality-dependent ones, into separate latent
variables. Specifically, PVAE integrates a variational inference framework and
a multimodal generative model that partitions the explanatory factors and
conditions only on the relevant subset of them for generation. We evaluate our
model on two parallel speech/image datasets, and demonstrate its ability to
learn disentangled representations by qualitatively exploring within-modality
and cross-modality conditional generation with semantics and styles specified
by examples. For quantitative analysis, we evaluate the classification accuracy
of automatically discovered semantic units. Our PVAE can achieve over 99%
accuracy on both modalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11358</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11358</id><created>2018-05-29</created><authors><author><keyname>Swami</keyname><forenames>Pragya</forenames></author><author><keyname>Bhatia</keyname><forenames>Vimal</forenames></author><author><keyname>Vuppala</keyname><forenames>Satyanarayana</forenames></author><author><keyname>Ratnarajah</keyname><forenames>Tharmalingam</forenames></author></authors><title>Offloading of Users in NOMA-HetNet Using Repulsive Point Process</title><categories>eess.SP</categories><doi>10.1109/JSYST.2018.2874310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ever increasing number of cellular users and their high data requirements,
necessitates need for improvement in the present heterogeneous cellular
networks (HetNet). Carrier sensing prevents base stations within a certain
range of the transmitter from transmitting and hence aids in reducing the
interference. Non-orthogonal multiple access (NOMA) has proven its superiority
for the 5th generation (5G) networks. This work proposes a mathematical model
for an improved HetNet with macro base station (MBS) and femto base station
(FBS) tier. The FBS tier is equipped to support NOMA and carrier sensing for
its transmissions. Offloading is performed for load balancing in HetNet where
the macro users (MU) from congested MBS tier are offloaded to the FBS tier. The
FBS tier pairs the offloaded MU (OMU) with an appropriate pairing user (PU) to
perform NOMA. The performance of the OMU is studied under different channel
conditions with respect to the available PU at the FBS and some useful
observations are drawn. A decrease in outage probability by $74.04\%$ for cell
center user (CCU) and $48.65\%$ for cell edge user (CEU) is observed for low
density FBS. The outage probability decreases by $99.60\%$, for both the CCU
and CEU, for high density FBS using the proposed carrier sensing in NOMA. The
results are validated using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11416</identifier>
 <datestamp>2019-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11416</id><created>2018-05-28</created><updated>2019-02-13</updated><authors><author><keyname>Ko&#xe7;</keyname><forenames>Aykut</forenames></author><author><keyname>Bartan</keyname><forenames>Burak</forenames></author><author><keyname>Ozaktas</keyname><forenames>Haldun M.</forenames></author></authors><title>Discrete Linear Canonical Transform Based on Hyperdifferential Operators</title><categories>eess.SP</categories><comments>18 pages, 1 figure</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 67, no. 9, pp.
  2237-2248, May 1, 2019</journal-ref><doi>10.1109/TSP.2019.2903031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear canonical transforms (LCTs) are of importance in many areas of science
and engineering with many applications. Therefore a satisfactory discrete
implementation is of considerable interest. Although there are methods that
link the samples of the input signal to the samples of the linear canonical
transformed output signal, no widely-accepted definition of the discrete LCT
has been established. We introduce a new approach to defining the discrete
linear canonical transform (DLCT) by employing operator theory. Operators are
abstract entities that can have both continuous and discrete concrete
manifestations. Generating the continuous and discrete manifestations of LCTs
from the same abstract operator framework allows us to define the continuous
and discrete transforms in a structurally analogous manner. By utilizing
hyperdifferential operators, we obtain a DLCT matrix which is totally
compatible with the theory of the discrete Fourier transform (DFT) and its dual
and circulant structure, which makes further analytical manipulations and
progress possible. The proposed DLCT is to the continuous LCT, what the DFT is
to the continuous Fourier transform (FT). The DLCT of the signal is obtained
simply by multiplying the vector holding the samples of the input signal by the
DLCT matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11433</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11433</id><created>2018-05-27</created><authors><author><keyname>Al-helaly</keyname><forenames>Emad Ali</forenames></author><author><keyname>Al-Helaly</keyname><forenames>Noor Ali</forenames></author></authors><title>A Count of Palm Trees from Satellite Image</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this research the number of palm trees was calculated from the satellite
image programmatically, taking advantage of the accuracy of the spatial
resolution of satellite image, the abilities of software recognition, and
characteristics of the palm tree, which give it a systematic top view can be
distinguished from the satellite image and the manner of cultivation and
vertical growth and stability form for long periods of time. While other trees
are irregular in shape mostly because of their twisted branches. Palm trees
consist of a long stem, a large head, and a large flare that is almost circular
and consists of large tufts. The palms have large self-shadows other than
ordinary leaves. The large shadows and the circular shape of the upper view
give it a special feature that we could use to design a program that
distinguishes the shape of the palm without all the trees. Then it counts the
number of palms in any field shown in the satellite image. This method is
useful in counting the number of palm trees for commercial, agricultural or
environmental purposes. It is also can be applied to high-resolution satellite
imagery such as QuickBird because the resolution of the images is 0.6 meters.
Less accurate images such as the 10-meter SPOT do not show the interior shadows
of the top view of the palm enough, nor the accurate satellites (5 meters),
while the interior shadows appear in high-resolution images only (0.6 meters)
or below. It can also be applied to aerial images of less capacity because they
are more accurate of course. Satellite images can be obtained free from Google
Earth explorer, which can be downloaded free from the Google website. It
connects the user to a global database of high-resolution images for all
regions of the world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11446</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11446</id><created>2018-05-29</created><updated>2018-09-18</updated><authors><author><keyname>Cao</keyname><forenames>Zehong</forenames></author><author><keyname>Lin</keyname><forenames>Chin-Teng</forenames></author><author><keyname>Ding</keyname><forenames>Weiping</forenames></author><author><keyname>Chen</keyname><forenames>Mu-Hong</forenames></author><author><keyname>Li</keyname><forenames>Cheng-Ta</forenames></author><author><keyname>Su</keyname><forenames>Tung-Ping</forenames></author></authors><title>Identifying Ketamine Responses in Treatment-Resistant Depression Using a
  Wearable Forehead EEG</title><categories>eess.SP</categories><comments>This revised article is submitting to IEEE TBME</comments><journal-ref>IEEE Transactions on Biomedical Engineering (Page(s): 1668 - 1679,
  Volume: 66 , Issue: 6 , June 2019 )</journal-ref><doi>10.1109/TBME.2018.2877651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study explores the responses to ketamine in patients with
treatment-resistant depression (TRD) using a wearable forehead
electroencephalography (EEG) device. We recruited fifty-five outpatients with
TRD who were randomised into three approximately equal-sized groups (A: 0.5
mg/kg ketamine; B: 0.2 mg/kg ketamine; and C: normal saline) under double-blind
conditions. The ketamine responses were measured by EEG signals and Hamilton
Depression Rating Scale (HDRS) scores. At baseline, responders showed a
significantly weaker EEG theta power than did non- responders (p &lt; 0.05).
Responders exhibited a higher EEG alpha power but lower EEG alpha asymmetry and
theta cordance at post-treatment than at baseline (p &lt; 0.05). Furthermore, our
baseline EEG predictor classified responders and non-responders with 81.3 +-
9.5% accuracy, 82.1 +- 8.6% sensitivity and 91.9 +- 7.4% specificity. In
conclusion, the rapid antidepressant effects of mixed doses of ketamine are
associated with prefrontal EEG power, asymmetry and cordance at baseline and
early post-treatment changes. The prefrontal EEG patterns at baseline may
account for recognising ketamine effects in advance. Our randomised, double-
blind, placebo-controlled study provides information regarding clinical impacts
on the potential targets underlying baseline identification and early changes
from the effects of ketamine in patients with TRD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11526</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11526</id><created>2018-05-29</created><authors><author><keyname>Kelz</keyname><forenames>Rainer</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Learning to Transcribe by Ear</title><categories>cs.SD cs.LG eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Rethinking how to model polyphonic transcription formally, we frame it as a
reinforcement learning task. Such a task formulation encompasses the notion of
a musical agent and an environment containing an instrument as well as the
sound source to be transcribed. Within this conceptual framework, the
transcription process can be described as the agent interacting with the
instrument in the environment, and obtaining reward by playing along with what
it hears. Choosing from a discrete set of actions - the notes to play on its
instrument - the amount of reward the agent experiences depends on which notes
it plays and when. This process resembles how a human musician might approach
the task of transcription, and the satisfaction she achieves by closely
mimicking the sound source to transcribe on her instrument. Following a
discussion of the theoretical framework and the benefits of modelling the
problem in this way, we focus our attention on several practical considerations
and address the difficulties in training an agent to acceptable performance on
a set of tasks with increasing difficulty. We demonstrate promising results in
partially constrained environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11533</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11533</id><created>2018-05-29</created><updated>2018-11-24</updated><authors><author><keyname>Morales</keyname><forenames>Nicolas</forenames></author><author><keyname>Tang</keyname><forenames>Zhenyu</forenames></author><author><keyname>Manocha</keyname><forenames>Dinesh</forenames></author></authors><title>Receiver Placement for Speech Enhancement using Sound Propagation
  Optimization</title><categories>cs.SD eess.AS</categories><journal-ref>Applied Acoustics Volume 155, 1 December 2019, Pages 53-62</journal-ref><doi>10.1016/j.apacoust.2019.04.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common problem in acoustic design is the placement of speakers or receivers
for public address systems, telecommunications, and home smart speakers or
digital personal assistants. We present a novel algorithm to automatically
place a speaker or receiver in a room to improve the intelligibility of spoken
phrases in a design. Our technique uses a sound propagation optimization
formulation to maximize the Speech Transmission Index (STI) by computing an
optimal location of the sound receiver. We use an efficient and accurate hybrid
sound propagation technique on complex 3D models to compute the Room Impulse
Responses (RIR) and evaluate their impact on the STI. The overall algorithm
computes a globally optimal position of the receiver that reduces the effects
of reverberation and noise over many source positions. We evaluate our
algorithm on various indoor 3D models, all showing significant improvement in
STI, based on accurate sound propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11662</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11662</id><created>2018-05-15</created><authors><author><keyname>Reiskarimian</keyname><forenames>Negar</forenames></author><author><keyname>Nagulu</keyname><forenames>Aravind</forenames></author><author><keyname>Dinc</keyname><forenames>Tolga</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Harish</forenames></author></authors><title>Integrated Conductivity-Modulation-Based RF Magnetic-Free Non-Reciprocal
  Components: Recent Results and Benchmarking</title><categories>physics.app-ph eess.SP</categories><comments>Submitted to IEEE Antennas AND Wireless Propagation Letters (AWPL)</comments><doi>10.1109/LAWP.2018.2849654</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving non-reciprocity and building nonreciprocal components through
spatio-temporal modulation of material properties has attracted a lot of
attention in the recent past as an alternative to the more traditional approach
of exploiting Faraday rotation in magnetic materials. In this letter, we review
recent research on spatio-temporal conductivity-modulation, which enables
low-loss, small-footprint, wide-bandwidth and high-power-handling
non-reciprocal components operating from radio frequencies (RF) to
millimeter-waves (mm-waves) and integrated in a CMOS platform. Four generations
of non-reciprocal circulators and circulator-based systems will be reviewed. We
will also discuss metrics of performance that are important for wireless
applications and standards, and introduce a new antenna (ANT) interface
efficiency figure of merit ($\eta_{ANT}$) to enable a fair comparison between
various types of antenna interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11685</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11685</id><created>2018-05-29</created><authors><author><keyname>Sterpu</keyname><forenames>George</forenames></author><author><keyname>Saam</keyname><forenames>Christian</forenames></author><author><keyname>Harte</keyname><forenames>Naomi</forenames></author></authors><title>Can DNNs Learn to Lipread Full Sentences?</title><categories>eess.IV cs.CV eess.AS</categories><comments>Accepted at the 2018 IEEE International Conference on Image
  Processing (ICIP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding visual features and suitable models for lipreading tasks that are
more complex than a well-constrained vocabulary has proven challenging. This
paper explores state-of-the-art Deep Neural Network architectures for
lipreading based on a Sequence to Sequence Recurrent Neural Network. We report
results for both hand-crafted and 2D/3D Convolutional Neural Network visual
front-ends, online monotonic attention, and a joint Connectionist Temporal
Classification-Sequence-to-Sequence loss. The system is evaluated on the
publicly available TCD-TIMIT dataset, with 59 speakers and a vocabulary of over
6000 words. Results show a major improvement on a Hidden Markov Model
framework. A fuller analysis of performance across visemes demonstrates that
the network is not only learning the language model, but actually learning to
lipread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11688</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11688</id><created>2018-05-29</created><authors><author><keyname>Sterpu</keyname><forenames>George</forenames></author><author><keyname>Harte</keyname><forenames>Naomi</forenames></author></authors><title>Towards Lipreading Sentences with Active Appearance Models</title><categories>eess.IV eess.AS</categories><comments>Presented at The 14th International Conference on Auditory-Visual
  Speech Processing (AVSP 2017)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic lipreading has major potential impact for speech recognition,
supplementing and complementing the acoustic modality. Most attempts at
lipreading have been performed on small vocabulary tasks, due to a shortfall of
appropriate audio-visual datasets. In this work we use the publicly available
TCD-TIMIT database, designed for large vocabulary continuous audio-visual
speech recognition. We compare the viseme recognition performance of the most
widely used features for lipreading, Discrete Cosine Transform (DCT) and Active
Appearance Models (AAM), in a traditional Hidden Markov Model (HMM) framework.
We also exploit recent advances in AAM fitting. We found the DCT to outperform
AAM by more than 6% for a viseme recognition task with 56 speakers. The overall
accuracy of the DCT is quite low (32-34%). We conclude that a fundamental
rethink of the modelling of visual features may be needed for this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11718</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11718</id><created>2018-05-29</created><updated>2018-12-05</updated><authors><author><keyname>Gupta</keyname><forenames>Sidharth</forenames></author><author><keyname>Kothari</keyname><forenames>Konik</forenames></author><author><keyname>de Hoop</keyname><forenames>Maarten V.</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Random mesh projectors for inverse problems</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>S. Gupta and K. Kothari contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new learning-based approach to solve ill-posed inverse problems
in imaging. We address the case where ground truth training samples are rare
and the problem is severely ill-posed - both because of the underlying physics
and because we can only get few measurements. This setting is common in
geophysical imaging and remote sensing. We show that in this case the common
approach to directly learn the mapping from the measured data to the
reconstruction becomes unstable. Instead, we propose to first learn an ensemble
of simpler mappings from the data to projections of the unknown image into
random piecewise-constant subspaces. We then combine the projections to form a
final reconstruction by solving a deconvolution-like problem. We show
experimentally that the proposed method is more robust to measurement noise and
corruptions not seen during training than a directly learned inverse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11725</identifier>
 <datestamp>2019-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11725</id><created>2018-05-29</created><updated>2019-04-16</updated><authors><author><keyname>Yang</keyname><forenames>Hong-Chuan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Characterizing Energy Efficiency of Wireless Transmission for Green
  Internet of Things: A Data-Oriented Approach</title><categories>cs.IT eess.SP math.IT</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing popularity of Internet of Things (IoT) applications brings new
challenges to the wireless communication community. Numerous smart devices and
sensors within IoT will generate a massive amount of short data packets. Future
wireless transmission systems need to support the reliable transmission of such
small data with extremely high energy efficiency. In this article, we introduce
a novel data-oriented approach for characterizing the energy efficiency of
wireless transmission strategies for IoT applications. Specifically, we present
new energy efficiency performance limits targeting at individual data
transmission sessions. Through preliminary analysis on two channel-adaptive
transmission strategies, we develop several important design guidelines on
green transmission of small data. We also present several promising future
applications of the proposed data-oriented energy efficiency characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11779</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11779</id><created>2018-05-29</created><authors><author><keyname>Zhang</keyname><forenames>Shuhang</forenames></author><author><keyname>Zhang</keyname><forenames>Hongliang</forenames></author><author><keyname>Di</keyname><forenames>Boya</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author></authors><title>Cellular Controlled Cooperative Unmanned Aerial Vehicle Networks with
  Sense-and-Send Protocol</title><categories>cs.SY eess.SP</categories><comments>13 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a cellular controlled unmanned aerial vehicle
(UAV) sensing network in which multiple UAVs cooperatively complete each
sensing task. We first propose a sense-and-send protocol where the UAVs collect
sensory data of the tasks and transmit the collected data to the base station.
We then formulate a joint trajectory, sensing location, and UAV scheduling
optimization problem that minimizes the completion time for all the sensing
tasks in the network. To solve this NP-hard problem efficiently, we decouple it
into three sub-problems: trajectory optimization, sensing location
optimization, and UAV scheduling. An iterative trajectory, sensing, and
scheduling optimization (ITSSO) algorithm is proposed to solve these
sub-problems jointly. The convergence and complexity of the ITSSO algorithm,
together with the system performance are analysed. Simulation results show that
the proposed ITSSO algorithm saves the task completion time by 15% compared to
the non-cooperative scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11782</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11782</id><created>2018-05-29</created><updated>2018-07-08</updated><authors><author><keyname>Imoto</keyname><forenames>Keisuke</forenames></author></authors><title>Acoustic Scene Analysis Using Partially Connected Microphones Based on
  Graph Cepstrum</title><categories>cs.SD eess.AS</categories><comments>Accepted to EUSIPCO 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an effective and robust method for acoustic scene
analysis based on spatial information extracted from partially synchronized
and/or closely located distributed microphones. In the proposed method, to
extract spatial information from distributed microphones while taking into
account whether any pairs of microphones are synchronized and/or closely
located, we derive a new cepstrum feature utilizing a graph-based basis
transformation. Specifically, in the proposed graph-based cepstrum, the
logarithm of the amplitude in a multichannel observation is converted to a
feature vector by an inverse graph Fourier transform, which can consider
whether any pair of microphones is connected. Our experimental results indicate
that the proposed graph-based cepstrum effectively extracts spatial information
with consideration of the microphone connections. Moreover, the results show
that the proposed method more robustly classifies acoustic scenes than
conventional spatial features when the observed sounds have a large
synchronization mismatch between partially synchronized microphone groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11852</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11852</id><created>2018-05-30</created><authors><author><keyname>Das</keyname><forenames>Nilaksh</forenames></author><author><keyname>Shanbhogue</keyname><forenames>Madhuri</forenames></author><author><keyname>Chen</keyname><forenames>Shang-Tse</forenames></author><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Kounavis</keyname><forenames>Michael E.</forenames></author><author><keyname>Chau</keyname><forenames>Duen Horng</forenames></author></authors><title>ADAGIO: Interactive Experimentation with Adversarial Attack and Defense
  for Audio</title><categories>cs.LG cs.CR cs.SD eess.AS</categories><comments>Demo paper; for supplementary video, see https://youtu.be/0W2BKMwSfVQ</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial machine learning research has recently demonstrated the
feasibility to confuse automatic speech recognition (ASR) models by introducing
acoustically imperceptible perturbations to audio samples. To help researchers
and practitioners gain better understanding of the impact of such attacks, and
to provide them with tools to help them more easily evaluate and craft strong
defenses for their models, we present ADAGIO, the first tool designed to allow
interactive experimentation with adversarial attacks and defenses on an ASR
model in real time, both visually and aurally. ADAGIO incorporates AMR and MP3
audio compression techniques as defenses, which users can interactively apply
to attacked audio samples. We show that these techniques, which are based on
psychoacoustic principles, effectively eliminate targeted attacks, reducing the
attack success rate from 92.5% to 0%. We will demonstrate ADAGIO and invite the
audience to try it on the Mozilla Common Voice dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11875</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11875</id><created>2018-05-30</created><authors><author><keyname>Zhang</keyname><forenames>Xuewei</forenames></author><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author><author><keyname>Ni</keyname><forenames>Wei</forenames></author><author><keyname>Cioffi</keyname><forenames>John M.</forenames></author><author><keyname>Beaulieu</keyname><forenames>Norman C.</forenames></author><author><keyname>Guo</keyname><forenames>Y. Jay</forenames></author></authors><title>Energy-Efficient Caching for Scalable Videos in Heterogeneous Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted by IEEE Journal on Selected Areas in Communications (JSAC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By suppressing repeated content deliveries, wireless caching has the
potential to substantially improve the energy efficiency (EE) of the fifth
generation (5G) communication networks. In this paper, we propose two novel
energy-efficient caching schemes in heterogeneous networks, namely, scalable
video coding (SVC)-based fractional caching and SVC-based random caching, which
can provide on-demand video services with different perceptual qualities. We
derive the expressions for successful transmission probabilities and ergodic
service rates. Based on the derivations and the established power consumption
models, the EE maximization problems are formulated for the two proposed
caching schemes. By taking logarithmic approximations of the l0-norm, the
problems are efficiently solved by the standard gradient projection method.
Numerical results validate the theoretical analysis and demonstrate the
superiority of our proposed caching schemes, compared to three benchmark
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11946</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11946</id><created>2018-05-30</created><updated>2019-05-29</updated><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Kim</keyname><forenames>Taejoon</forenames></author><author><keyname>Xiong</keyname><forenames>Guojun</forenames></author><author><keyname>Leung</keyname><forenames>Shu-Hung</forenames></author></authors><title>Leveraging Subspace Information for Low-Rank Matrix Reconstruction</title><categories>eess.SP</categories><journal-ref>https://doi.org/10.1016/j.sigpro.2019.05.013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of low-rank matrix reconstruction arises in various applications
in communications and signal processing. The state of the art research largely
focuses on the recovery techniques that utilize affine maps satisfying the
restricted isometry property (RIP). However, the affine map design and
reconstruction under a priori information, i.e., column or row subspace
information, has not been thoroughly investigated. To this end, we present
designs of affine maps and reconstruction algorithms that fully exploit the
low-rank matrix subspace information. Compared to the randomly generated affine
map, the proposed affine map design permits an enhanced reconstruction. In
addition, we derive an optimal representation of low-rank matrices, which is
exploited to optimize the rank and subspace of the estimate by adapting them to
the noise level in order to achieve the minimum mean square error (MSE).
Moreover, in the case when the subspace information is not a priori available,
we propose a two-step algorithm, where, in the first step, it estimates the
column subspace of a low-rank matrix, and in the second step, it exploits the
estimated information to complete the reconstruction. The simulation results
show that the proposed algorithm achieves robust performance with much lower
complexity than existing reconstruction algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11949</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11949</id><created>2018-05-30</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Feng</keyname><forenames>Ruibin</forenames></author><author><keyname>Leung</keyname><forenames>Chi-Sing</forenames></author></authors><title>Fast L1-Minimization Algorithm for Sparse Approximation Based on an
  Improved LPNN-LCA framework</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of sparse approximation is to estimate a sparse signal according to
the measurement matrix and an observation vector. It is widely used in data
analytics, image processing, and communication, etc. Up to now, a lot of
research has been done in this area, and many off-the-shelf algorithms have
been proposed. However, most of them cannot offer a real-time solution. To some
extent, this shortcoming limits its application prospects. To address this
issue, we devise a novel sparse approximation algorithm based on Lagrange
programming neural network (LPNN), locally competitive algorithm (LCA), and
projection theorem. LPNN and LCA are both analog neural network which can help
us get a real-time solution. The non-differentiable objective function can be
solved by the concept of LCA. Utilizing the projection theorem, we further
modify the dynamics and proposed a new system with global asymptotic stability.
Simulation results show that the proposed sparse approximation method has the
real-time solutions with satisfactory MSEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11972</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11972</id><created>2018-05-30</created><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Leung</keyname><forenames>Shu-Hung</forenames></author><author><keyname>Kim</keyname><forenames>Taejoon</forenames></author></authors><title>Two-stage Method for Millimeter Wave Channel Estimation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The millimeter wave is a promising technique for the next generation of
mobile communication. The large antenna array is able to provide sufficient
precoding gain to overcome the high pathloss at millimeter wave band. However,
the accurate channel state information is the key for the precoding design.
Unfortunately, the channel use overhead and complexity are two major challenges
when estimating the channel with high-dimensional array. In this paper, we
propose a two-stage approach which reduces the channel use overhead and the
computational complexity. Specifically, in the first stage, we estimate the
column subspace of the channel matrix. Based on the estimated column subspace,
we design the training sounders to acquire the remaining coefficient matrix of
the column subspace. By dividing the estimation task into two stages, the
training sounders for the second stages are only targeted for the column
subspace, which will save the channel uses and the computational complexity as
well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.11999</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.11999</id><created>2018-05-30</created><authors><author><keyname>Rajan</keyname><forenames>Raj Thilak</forenames></author><author><keyname>Schaijk</keyname><forenames>Rob-van</forenames></author><author><keyname>Das</keyname><forenames>Anup</forenames></author><author><keyname>Romme</keyname><forenames>Jac</forenames></author><author><keyname>Pasveer</keyname><forenames>Frank</forenames></author></authors><title>Reference-free Calibration in Sensor Networks</title><categories>stat.AP cs.LG eess.SP</categories><comments>Submitted to IEEE Sensor Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor calibration is one of the fundamental challenges in large-scale IoT
networks. In this article, we address the challenge of reference-free
calibration of a densely deployed sensor network. Conventionally, to calibrate
an in-place sensor network (or sensor array), a reference is arbitrarily chosen
with or without prior information on sensor performance. However, an arbitrary
selection of a reference could prove fatal, if an erroneous sensor is
inadvertently chosen. To avert single point of dependence, and to improve
estimator performance, we propose unbiased reference-free algorithms. Although,
our focus is on reference-free solutions, the proposed framework, allows the
incorporation of additional references, if available. We show with the help of
simulations that the proposed solutions achieve the derived statistical lower
bounds asymptotically. In addition, the proposed algorithms show improvements
on real-life datasets, as compared to prevalent algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12015</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12015</id><created>2018-05-30</created><authors><author><keyname>Temesgene</keyname><forenames>Dagnachew A.</forenames></author><author><keyname>Piovesan</keyname><forenames>Nicola</forenames></author><author><keyname>Miozzo</keyname><forenames>Marco</forenames></author><author><keyname>Dini</keyname><forenames>Paolo</forenames></author></authors><title>Optimal Placement of Baseband Functions for Energy Harvesting Virtual
  Small Cells</title><categories>cs.NI eess.SP</categories><comments>submitted to IEEEVTC2018 Fall</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flexible functional split in Cloud Radio Access Network (CRAN) greatly
overcomes fronthaul capacity and latency challenges. In such architecture, part
of the baseband processing is done locally and the remaining is done remotely
in the central cloud. On the other hand, Energy Harvesting (EH) technologies
are increasingly adopted due to sustainability and economic advantages. Power
consumption due to baseband processing has a huge share in the total power
consumption breakdown of smaller base stations. Given that such base stations
are powered by EH, in addition to QoS constraints, energy availability also
conditions the decision on where to place each baseband function in the system.
This work focuses on determining the performance bounds of an optimal placement
of baseband functional split option in virtualized small cells that are solely
powered by EH. The work applies Dynamic Programming (DP), in particular,
Shortest Path search is used to determine the optimal functional split option
considering traffic QoS requirements and available energy budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12209</identifier>
 <datestamp>2018-06-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12209</id><created>2018-05-28</created><authors><author><keyname>Feng</keyname><forenames>Yi</forenames></author><author><keyname>Zhang</keyname><forenames>Hong-fei</forenames></author><author><keyname>Xu</keyname><forenames>Yi-ling</forenames></author><author><keyname>Chen</keyname><forenames>Jin-ting</forenames></author><author><keyname>Yang</keyname><forenames>Dong-xu</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author><author><keyname>Chen</keyname><forenames>Cheng</forenames></author><author><keyname>Zhang</keyname><forenames>Guang-yu</forenames></author><author><keyname>Wang</keyname><forenames>Jian-min</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author></authors><title>Design of a Non-vacuum-cooling Compact Scientific CCD Camera</title><categories>physics.ins-det eess.IV</categories><comments>2 pages, 5 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CCD was born in Bell Laboratories in 1969 and has been widely used in various
fields. Its ultra-low noise and high quantum efficiency make it work well in
particle physics, high energy physics, nuclear physics and astrophysics.
Nowadays, more and more CCD cameras have been developed for medical diagnosis,
scientific experiments, aerospace, military exploration and other fields. For
the wide range of CCD cameras, a Non-vacuum-cooling compact (NVCC) scientific
CCD camera has been developed, including FPGA-based low noise clock and bias
driver circuit, data acquisition circuit, STM32-based temperature control
design. At the same time, the readout noise of the imaging system is studied
emphatically. The scheme to generate the CCD clock and the bias driving circuit
through ultralow noise LDOs is proposed. The camera was tested in a variety of
environments, and the test results show that the system can run at a maximum
rate of 5M pixels/s and readout noise is as low as 9.29e^- when the CCD readout
speed is 500K pixels/s. Finally, a series of stability tests were carried out
on the camera system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12278</identifier>
 <datestamp>2018-06-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12278</id><created>2018-05-30</created><authors><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author><author><keyname>Lin</keyname><forenames>Zhipeng</forenames></author><author><keyname>Huang</keyname><forenames>Pingmu</forenames></author><author><keyname>Zeng</keyname><forenames>Jie</forenames></author></authors><title>Optimization of the Energy-Efficient Relay-Based massive IoT Network</title><categories>eess.SP</categories><comments>Accepted by IEEE Internet of Things Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To meet the requirements of high energy efficiency (EE) and large system
capacity for the fifth-generation (5G) Internet of Things (IoT), the use of
massive multiple-input multipleoutput (MIMO) technology has been launched in
the massive IoT (mIoT) network, where a large number of devices are connected
and scheduled simultaneously. This paper considers the energyefficient design
of a multi-pair decode-and-forward relay-based IoT network, in which multiple
sources simultaneously transmit their information to the corresponding
destinations via a relay equipped with a large array. In order to obtain an
accurate yet tractable expression of the EE, firstly, a closed-form expression
of the EE is derived under an idealized simplifying assumption, in which the
location of each device is known by the network. Then, an exact integral-based
expression of the EE is derived under the assumption that the devices are
randomly scattered following a uniform distribution and transmit power of the
relay is equally shared among the destination devices. Furthermore, a simple
yet efficient lower bound of the EE is obtained. Based on this, finally, a
low-complexity energy-efficient resource allocation strategy of the mIoT
network is proposed under the specific qualityof- service (QoS) constraint. The
proposed strategy determines the near-optimal number of relay antennas, the
near-optimal transmit power at the relay and near-optimal density of active
mIoT device pairs in a given coverage area. Numerical results demonstrate the
accuracy of the performance analysis and the efficiency of the proposed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12281</identifier>
 <datestamp>2018-06-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12281</id><created>2018-05-30</created><authors><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author><author><keyname>Ma</keyname><forenames>Yuyu</forenames></author><author><keyname>Zeng</keyname><forenames>Jie</forenames></author><author><keyname>Mathiopoulos</keyname><forenames>P. Takis</forenames></author></authors><title>Millimeter-Wave NOMA Transmission in Cellular M2M Communications for
  Internet of Things</title><categories>eess.SP</categories><comments>Accepted by IEEE Internet of Things Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive connectivity and low latency are two important challenges for the
Internet of Things (IoT) to achieve the Quality of Service (QoS) provisions
required by the numerous devices it is designed to service. Motivated by these
challenges, in the paper we introduce a new millimeter-wave non-orthogonal
multiple access (mmWave-NOMA) transmission scheme designed for cellular
machine-to-machine (M2M) communication systems for IoT applications. It
consists of one base station (BS) and numerous multiple machine type
communication (MTC) devices operating in a cellular communication environment.
We consider its down-link performance and assume that multiple MTC devices
share the same communication resources offered by the proposed mmWave-NOMA
transmission scheme, which can support massive connectivity. For this system, a
novel MTC pairing scheme is introduced the design of which is based upon the
distance between the BS and the MTC devices aiming at reducing the system
overall overhead for massive connectivity and latency. In particular, we
consider three different MTC device pairing schemes, namely i) the random near
and the random far MTC devices (RNRF); ii) the nearest near and the nearest far
MTC devices (NNNF); and iii) the nearest near and the farthest far MTC device
(NNFF). For all three pairing schemes, their performance is analyzed by
deriving closed-form expressions of the outage probability and the sum rate.
Furthermore, performance comparison studies of the three MTC device pairing
schemes have been carried out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12300</identifier>
 <datestamp>2018-06-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12300</id><created>2018-05-30</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Leung</keyname><forenames>Chi-Sing</forenames></author><author><keyname>So</keyname><forenames>Hing Cheung</forenames></author><author><keyname>Liang</keyname><forenames>Junli</forenames></author><author><keyname>Feng</keyname><forenames>Ruibin</forenames></author><author><keyname>Han</keyname><forenames>Zifa</forenames></author></authors><title>Robust MIMO Radar Target Localization based on Lagrange Programming
  Neural Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on target localization in a widely distributed
multiple-input-multiple-output (MIMO) radar system. In this system, range
measurements, which include the sum of distances between transmitter and target
and the distances from the target to receivers, are used. We can obtain an
accurate estimated position of the target by minimizing the measurement errors.
In order to make our model come closer to reality, we introduce two kinds of
noises, namely, Gaussian noise and outliers. When we evaluate a target
localization algorithm, its localization accuracy and computational complexity
are two main criteria. To improve the positioning accuracy, the original
problem is formulated as solving a non-smooth constrained optimization problem
in which the objective function is either l1-norm or l0-norm term. To achieve a
real-time solution, the Lagrange programming neural network (LPNN) is utilized
to solve this problem. However, it is well known that LPNN requires
twice-differentiable objective function and constraints. Obviously, the l1-norm
or l0-norm term in the objective function does not satisfy this requirement. To
address this non-smooth optimization problem, this paper proposes two
modifications based on the LPNN framework. In the first method, a
differentiable proximate l1-norm function is introduced. While in the second
method, locally competitive algorithm is utilized. Simulation and experimental
results demonstrate that the performance of the proposed algorithms outperforms
several existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12315</identifier>
 <datestamp>2018-06-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12315</id><created>2018-05-31</created><authors><author><keyname>Jing</keyname><forenames>Haiyue</forenames></author><author><keyname>Cheng</keyname><forenames>Wenchi</forenames></author></authors><title>Radio Vortex Wireless Communications With Non-Coaxial UCA Transceiver</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past decade, more and more researchers have concentrated on
orbital-angular-momentum (OAM) based radio vortex wireless communications,
which is expected to provide orthogonality among different OAM-modes. The
uniform circular array (UCA) is considered as one promising antenna structure
for OAM based radio vortex wireless communications. However, most studies
regarding UCA focus on the scenario where the transmit and receive UCAs are
aligned with each other. In this paper, we investigate the radio vortex
wireless communications with non-coaxial UCA, i.e., the UCA transceivers are
parallel but non-coaxial. We study the channel model and develop the
mode-decomposition scheme to decompose the OAM-modes. Then, we discuss the
impact of included angles on the channel model under non-coaxial scenario.
Numerical results are presented to evaluate our developed scheme and show that
the spectrum efficiency of the non-coaxial UCA transceiver in some cases is
larger than that of the aligned UCA transceiver based radio vortex wireless
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12338</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12338</id><created>2018-05-31</created><updated>2018-07-29</updated><authors><author><keyname>Lundell</keyname><forenames>Jens</forenames></author><author><keyname>Verdoja</keyname><forenames>Francesco</forenames></author><author><keyname>Kyrki</keyname><forenames>Ville</forenames></author></authors><title>Hallucinating robots: Inferring Obstacle Distances from Partial Laser
  Measurements</title><categories>cs.RO eess.SP stat.ML</categories><comments>In 2018 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)</comments><journal-ref>2018 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), Madrid, Spain, 2018, pp. 4781-4787</journal-ref><doi>10.1109/IROS.2018.8594399</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many mobile robots rely on 2D laser scanners for localization, mapping, and
navigation. However, those sensors are unable to correctly provide distance to
obstacles such as glass panels and tables whose actual occupancy is invisible
at the height the sensor is measuring. In this work, instead of estimating the
distance to obstacles from richer sensor readings such as 3D lasers or RGBD
sensors, we present a method to estimate the distance directly from raw 2D
laser data. To learn a mapping from raw 2D laser distances to obstacle
distances we frame the problem as a learning task and train a neural network
formed as an autoencoder. A novel configuration of network hyperparameters is
proposed for the task at hand and is quantitatively validated on a test set.
Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the
trained network can successfully infer obstacle distances from partial 2D laser
readings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12472</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12472</id><created>2018-05-31</created><updated>2018-06-25</updated><authors><author><keyname>Hadar</keyname><forenames>Uri</forenames></author><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author></authors><title>Distributed Estimation of Gaussian Correlations</title><categories>math.ST cs.IT cs.LG eess.SP math.IT stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a distributed estimation problem in which two remotely located
parties, Alice and Bob, observe an unlimited number of i.i.d. samples
corresponding to two different parts of a random vector. Alice can send $k$
bits on average to Bob, who in turn wants to estimate the cross-correlation
matrix between the two parts of the vector. In the case where the parties
observe jointly Gaussian scalar random variables with an unknown correlation
$\rho$, we obtain two constructive and simple unbiased estimators attaining a
variance of $(1-\rho^2)/(2k\ln 2)$, which coincides with a known but
non-constructive random coding result of Zhang and Berger. We extend our
approach to the vector Gaussian case, which has not been treated before, and
construct an estimator that is uniformly better than the scalar estimator
applied separately to each of the correlations. We then show that the Gaussian
performance can essentially be attained even when the distribution is
completely unknown. This in particular implies that in the general problem of
distributed correlation estimation, the variance can decay at least as $O(1/k)$
with the number of transmitted bits. This behavior, however, is not tight: we
give an example of a rich family of distributions for which local samples
reveal essentially nothing about the correlations, and where a slightly
modified estimator attains a variance of $2^{-\Omega(k)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12586</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1805.12586</id><created>2018-05-31</created><updated>2018-11-13</updated><authors><author><keyname>Soysal</keyname><forenames>Alkan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Age of Information in G/G/1/1 Systems</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a single server communication setting where the interarrival
times of data updates at the source node and the service times to the
destination node are arbitrarily distributed. We consider two service
discipline models. If a new update arrives when the service is busy, it is
dropped in the first model; and it preempts the current update in the second
model. For both models, we derive exact expressions for the age of information
metric with no restriction on the distributions of interarrival and service
times. In addition, we derive upper bounds that are easier to calculate than
the exact expressions. In the case with dropping, we also derive a second upper
bound by utilizing stochastic ordering if the interarrival times have
decreasing mean residual life (DMRL) and service times have new better than use
in expectation (NBUE) property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00004</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00004</id><created>2018-05-30</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Leung</keyname><forenames>Chi-Sing</forenames></author><author><keyname>So</keyname><forenames>Hing Cheung</forenames></author><author><keyname>Liang</keyname><forenames>Junli</forenames></author><author><keyname>Feng</keyname><forenames>Ruibin</forenames></author><author><keyname>Han</keyname><forenames>Zifa</forenames></author></authors><title>Robust Real-time Ellipse Fitting Based on Lagrange Programming Neural
  Network and Locally Competitive Algorithm</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of 2-dimensional (2-D) scattering points, which are usually
obtained from the edge detection process, the aim of ellipse fitting is to
construct an elliptic equation that best fits the collected observations.
However, some of the scattering points may contain outliers due to imperfect
edge detection. To address this issue, we devise a robust real-time ellipse
fitting approach based on two kinds of analog neural network, Lagrange
programming neural network (LPNN) and locally competitive algorithm (LCA).
First, to alleviate the influence of these outliers, the fitting task is
formulated as a nonsmooth constrained optimization problem in which the
objective function is either an l1-norm or l0-norm term. It is because compared
with the l2-norm in some traditional ellipse fitting models, the lp-norm with
p&lt;2 is less sensitive to outliers. Then, to calculate a real-time solution of
this optimization problem, LPNN is applied. As the LPNN model cannot handle the
non-differentiable term in its objective, the concept of LCA is introduced and
combined with the LPNN framework. Simulation and experimental results show that
the proposed ellipse fitting approach is superior to several state-of-the-art
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00058</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00058</id><created>2018-05-31</created><authors><author><keyname>Barkley</keyname><forenames>Solomon</forenames></author><author><keyname>Dimiduk</keyname><forenames>Thomas G.</forenames></author><author><keyname>Fung</keyname><forenames>Jerome</forenames></author><author><keyname>Kaz</keyname><forenames>David M.</forenames></author><author><keyname>Manoharan</keyname><forenames>Vinothan N.</forenames></author><author><keyname>McGorty</keyname><forenames>Ryan</forenames></author><author><keyname>Perry</keyname><forenames>Rebecca W.</forenames></author><author><keyname>Wang</keyname><forenames>Anna</forenames></author></authors><title>Holographic Microscopy with Python and HoloPy</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A holographic microscope captures interference patterns, or holograms, that
encode three-dimensional (3D) information about the object being viewed.
Computation is essential to extracting that 3D information. By wrapping
low-level scattering codes and taking advantage of Python's data analysis
ecosystem, HoloPy makes it easy for experimentalists to use modern,
sophisticated inference methods to analyze holograms. The resulting data can be
used to understand how small particles or microorganisms move and interact. The
project illustrates how computational tools can enable experimental methods and
new experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00083</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00083</id><created>2018-05-23</created><authors><author><keyname>Lagadec</keyname><forenames>Marie Francine</forenames></author><author><keyname>Zahn</keyname><forenames>Raphael</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Simon</forenames></author><author><keyname>Wood</keyname><forenames>Vanessa</forenames></author></authors><title>Topological and Network Analysis of Lithium Ion Battery Components: The
  Importance of Pore Space Connectivity for Cell Operation</title><categories>physics.app-ph cond-mat.mtrl-sci eess.IV</categories><comments>Main article on pages on pages 1-8, supporting information on pages
  9-15</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The structure of lithium ion battery components, such as electrodes and
separators, are commonly characterised in terms of their porosity and
tortuosity. The ratio of these values gives the effective transport of lithium
ions in the electrolyte-filled pore spaces, which can be used to determine the
ionic resistivity and corresponding voltage losses. Here, we show that these
microstructural characteristics are not sufficient. Analysis of tomographic
data of commercial separators reveals that different polyolefin separators have
similar porosity and through-plane tortuosity, which, in the homogenised
picture of lithium ion cell operation, would imply that these different
separators exhibit similar performance. However, numerical diffusion
simulations indicate that this is not the case. We demonstrate that the extent
to which lithium ion concentration gradients are induced or smoothed by the
separator structure is linked to pore space connectivity, a parameter that can
be determined by topological or network based analysis of separators. These
findings enable us to propose how to design separator microstructures that are
safer and accommodate fast charge and discharge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00138</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00138</id><created>2018-05-31</created><authors><author><keyname>Amalladinne</keyname><forenames>Vamsi K.</forenames></author><author><keyname>Vem</keyname><forenames>Avinash</forenames></author><author><keyname>Soma</keyname><forenames>Dileep Kumar</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author><author><keyname>Chamberland</keyname><forenames>Jean-Francois</forenames></author></authors><title>A Coupled Compressive Sensing Scheme for Unsourced Multiple Access</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a novel paradigm for the unsourced multiple-access
communication problem. This divide-and-conquer approach leverages recent
advances in compressive sensing and forward error correction to produce a
computationally efficient algorithm. Within the proposed framework, every
active device first partitions its data into several sub-blocks, and
subsequently adds redundancy using a systematic linear block code. Compressive
sensing techniques are then employed to recover sub-blocks, and the original
messages are obtained by connecting pieces together using a low-complexity
tree-based algorithm. Numerical results suggest that the proposed scheme
outperforms other existing practical coding schemes. Measured performance lies
approximately $4.3$~dB away from the Polyanskiy achievability limit, which is
obtained in the absence of complexity constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00153</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00153</id><created>2018-05-31</created><updated>2019-06-17</updated><authors><author><keyname>Lee</keyname><forenames>Juyoung</forenames></author><author><keyname>Han</keyname><forenames>Yoseob</forenames></author><author><keyname>Ryu</keyname><forenames>Jae-Kyun</forenames></author><author><keyname>Park</keyname><forenames>Jang-Yeon</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>k-Space Deep Learning for Reference-free EPI Ghost Correction</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>To appear in Magnetic Resonance in Medicine</comments><report-no>https://doi.org/10.1002/mrm.27896</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nyquist ghost artifacts in EPI are originated from phase mismatch between the
even and odd echoes. However, conventional correction methods using reference
scans often produce erroneous results especially in high-field MRI due to the
non-linear and time-varying local magnetic field changes. Recently, it was
shown that the problem of ghost correction can be reformulated as k-space
interpolation problem that can be solved using structured low-rank Hankel
matrix approaches. Another recent work showed that data driven Hankel matrix
decomposition can be reformulated to exhibit similar structures as deep
convolutional neural network. By synergistically combining these findings, we
propose a k-space deep learning approach that immediately corrects the phase
mismatch without a reference scan in both accelerated and non-accelerated EPI
acquisitions. To take advantage of the even and odd-phase directional
redundancy, the k-space data is divided into two channels configured with even
and odd phase encodings. The redundancies between coils are also exploited by
stacking the multi-coil k-space data into additional input channels. Then, our
k-space ghost correction network is trained to learn the interpolation kernel
to estimate the missing virtual k-space data. For the accelerated EPI data, the
same neural network is trained to directly estimate the interpolation kernels
for missing k-space data from both ghost and subsampling. Reconstruction
results using 3T and 7T in-vivo data showed that the proposed method
outperformed the image quality compared to the existing methods, and the
computing time is much faster.The proposed k-space deep learning for EPI ghost
correction is highly robust and fast, and can be combined with acceleration, so
that it can be used as a promising correction tool for high-field MRI without
changing the current acquisition protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00160</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00160</id><created>2018-05-31</created><authors><author><keyname>Zhao</keyname><forenames>Yijiu</forenames></author><author><keyname>Xiao</keyname><forenames>Shuangman</forenames></author></authors><title>Sparse Multiband Signal Acquisition Receiver with Co-prime Sampling</title><categories>eess.SP cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Cognitive radio (CR) requires spectrum sensing over a broad frequency band.
One of the crucial tasks in CR is to sample wideband signal at high sampling
rate. In this paper, we propose an acquisition receiver with co-prime sampling
technique for wideband sparse signals, which occupy a small part of band range.
In this proposed acquisition receiver, we use two low speed analog-to-digital
converters (ADCs) to capture a common sparse multiband signal, whose band
locations are unknown. The two ADCs are synchronously clocked at co-prime
sampling rates. The obtained samples are re-sequenced into a group of uniform
sequences with low rate. We derive the mathematical model for the receiver in
the frequency domain and present its signal reconstruction algorithm. Compared
to the existing sub-Nyquist sampling techniques, such as multi-coset sampling
and modulated wideband converter, the proposed approach has a simple system
architecture and can be implemented with only two samplers. Experimental
results are reported to demonstrate the feasibility and advantage of the
proposed model. For sparse multiband signal with unknown spectral support, the
proposed system requires a sampling rate much lower than Nyquist rate, while
produces satisfactory reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00161</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00161</id><created>2018-05-31</created><updated>2019-09-25</updated><authors><author><keyname>Shaham</keyname><forenames>Sina</forenames></author><author><keyname>Ding</keyname><forenames>Ming</forenames></author><author><keyname>Kokshoorn</keyname><forenames>Matthew</forenames></author><author><keyname>Lin</keyname><forenames>Zihuai</forenames></author><author><keyname>Dang</keyname><forenames>Shuping</forenames></author><author><keyname>Abbas</keyname><forenames>Rana</forenames></author></authors><title>Fast Channel Estimation and Beam Tracking for Millimeter Wave Vehicular
  Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) has been claimed to be the only viable solution for
high-bandwidth vehicular communications. However, frequent channel estimation
and beamforming required to provide a satisfactory quality of service limits
mmWave for vehicular communications. In this paper, we propose a novel channel
estimation and beam tracking framework for mmWave communications in a vehicular
network setting. For channel estimation, we propose an algorithm termed robust
adaptive multi-feedback (RAF) that achieves comparable estimation performance
as existing channel estimation algorithms, with a significantly smaller number
of feedback bits. We derive upper and lower bounds on the probability of
estimation error (PEE) of the RAF algorithm, given a number of channel
estimations, whose accuracy is verified through Monte Carlo simulations. For
beam tracking, we propose a new practical model for mmWave vehicular
communications. In contrast to the prior works, the model is based on position,
velocity, and channel coefficient, which allows a significant improvement of
the tracking performance. Focused on the new beam tracking model, we re-derive
the equations for Jacobian matrices, reducing the complexity for vehicular
communications. An extensive number of simulations is conducted to show the
superiority of our proposed channel estimation method and beam tracking
algorithm in comparison with the existing algorithms and models. Our
simulations suggest that the RAF algorithm can achieve the desired PEE, while
on average, reducing the feedback overhead by 75.5% and the total channel
estimation time by 14%. The beam tracking algorithm is also shown to
significantly improve beam tracking performance, allowing more room for data
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00195</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00195</id><created>2018-06-01</created><authors><author><keyname>Simon</keyname><forenames>Ian</forenames></author><author><keyname>Roberts</keyname><forenames>Adam</forenames></author><author><keyname>Raffel</keyname><forenames>Colin</forenames></author><author><keyname>Engel</keyname><forenames>Jesse</forenames></author><author><keyname>Hawthorne</keyname><forenames>Curtis</forenames></author><author><keyname>Eck</keyname><forenames>Douglas</forenames></author></authors><title>Learning a Latent Space of Multitrack Measures</title><categories>stat.ML cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discovering and exploring the underlying structure of multi-instrumental
music using learning-based approaches remains an open problem. We extend the
recent MusicVAE model to represent multitrack polyphonic measures as vectors in
a latent space. Our approach enables several useful operations such as
generating plausible measures from scratch, interpolating between measures in a
musically meaningful way, and manipulating specific musical attributes. We also
introduce chord conditioning, which allows all of these operations to be
performed while keeping harmony fixed, and allows chords to be changed while
maintaining musical &quot;style&quot;. By generating a sequence of measures over a
predefined chord progression, our model can produce music with convincing
long-term structure. We demonstrate that our latent space model makes it
possible to intuitively control and generate musical sequences with rich
instrumentation (see https://goo.gl/s2N7dV for generated audio).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00273</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00273</id><created>2018-06-01</created><updated>2019-10-16</updated><authors><author><keyname>Schulze</keyname><forenames>S&#xf6;ren</forenames></author><author><keyname>King</keyname><forenames>Emily J.</forenames></author></authors><title>Sparse Pursuit and Dictionary Learning for Blind Source Separation in
  Polyphonic Music Recordings</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method for the blind separation of single-channel audio
signals produced by the mixed sounds of musical instruments. While the approach
of applying non-negative matrix factorization (NMF) has been studied in many
papers, it does not make use of the pitch-invariance that the sounds of many
instruments exhibit. This limitation can be overcome by using tensor
factorization, in which context the use of log-frequency spectrograms was
initiated, but this still requires the specific tuning of the instruments to be
hard-coded into the algorithm. We develop a general-purpose sparse pursuit
method that matches a discrete spectrum with given shifted continuous patterns.
We first use it in order to transform our audio signal into a log-frequency
spectrogram that shares properties with the mel spectrogram but is applicable
to a wider frequency range. Then, we use the same algorithm to identify
patterns from instrument sounds in the spectrogram. The relative amplitudes of
the harmonics are saved in a dictionary, which is trained via a modified
version of Adam. For a realistic monaural piece with acoustic recorder and
violin, we achieve qualitatively good separation with a signal-to-distortion
ratio (SDR) of 13.7 dB, a signal-to-interference ratio (SIR) of 28.1 dB, and a
signal-to-artifacts ratio (SAR) of 13.9 dB, averaged over the instruments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00318</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00318</id><created>2018-06-01</created><authors><author><keyname>Wang</keyname><forenames>Zhi-yue</forenames></author><author><keyname>Liu</keyname><forenames>Tian-kuan</forenames></author><author><keyname>Tang</keyname><forenames>Qi-jie</forenames></author><author><keyname>Feng</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author></authors><title>A programmable clock generator for automatic Quality Assurance of LOCx2</title><categories>eess.SP cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The upgrade of ATLAS Liquid Argon Calorimeter (LAr) Phase-1 trigger requires
high-speed, low-latency data transmission to read out the Lar Trigger Digitizer
Board (LTDB). A dual-channel transmitter ASIC LOCx2 have been designed and
produced. In order to ensure all the LOCx2 chips behave properly, a Quality
Assurance needs to be conducted before assembly. The problem I was trying to
solve in this project is to yield a clock signal with continuously adjustable
frequency and phase offset to generate and control an eye diagram for the QA.
By configuring the registers of an any-frequency generator IC, Si5338, the
clock signal whose frequency range from 5MHz to 200 MHz have been properly
produced. For the purpose of further development, a C-language based DLL which
packs up the function of adjusting frequency and setting phase offset was
designed and built, and several evaluation was performed to ensure the
robustness of DLL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00333</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00333</id><created>2018-06-01</created><authors><author><keyname>K&#x131;rmemi&#x15f;</keyname><forenames>Og&#xfc;n</forenames></author><author><keyname>Bakar</keyname><forenames>Gonca</forenames></author><author><keyname>Tekalp</keyname><forenames>A. Murat</forenames></author></authors><title>Learned Compression Artifact Removal by Deep Residual Networks</title><categories>eess.IV</categories><comments>Accepted for publication in the CVPR 2018, Challenge on Learned Image
  Compression (CLIC), Salt Lake City, Utah, USA, 18 June 2018 and appears in
  compression.cc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for learned compression artifact removal by
post-processing of BPG compressed images. We trained three networks of
different sizes. We encoded input images using BPG with different QP values. We
submitted the best combination of test images, encoded with different QP and
post-processed by one of three networks, which satisfy the file size and decode
time constraints imposed by the Challenge. The selection of the best
combination is posed as an integer programming problem. Although the visual
improvements in image quality is impressive, the average PSNR improvement for
the results is about 0.5 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00338</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00338</id><created>2018-06-01</created><updated>2019-07-21</updated><authors><author><keyname>Zhang</keyname><forenames>Yuqian</forenames></author><author><keyname>Kuo</keyname><forenames>Han-Wen</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Structured Local Optima in Sparse Blind Deconvolution</title><categories>eess.SP cs.IT math.IT math.OC stat.ML</categories><comments>63 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind deconvolution is a ubiquitous problem of recovering two unknown signals
from their convolution. Unfortunately, this is an ill-posed problem in general.
This paper focuses on the {\em short and sparse} blind deconvolution problem,
where the one unknown signal is short and the other one is sparsely and
randomly supported. This variant captures the structure of the unknown signals
in several important applications. We assume the short signal to have unit
$\ell^2$ norm and cast the blind deconvolution problem as a nonconvex
optimization problem over the sphere. We demonstrate that (i) in a certain
region of the sphere, every local optimum is close to some shift truncation of
the ground truth, and (ii) for a generic short signal of length $k$, when the
sparsity of activation signal $\theta\lesssim k^{-2/3}$ and number of
measurements $m\gtrsim poly(k)$, a simple initialization method together with a
descent algorithm which escapes strict saddle points recovers a near shift
truncation of the ground truth kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00360</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00360</id><created>2018-05-31</created><authors><author><keyname>Dkhil</keyname><forenames>M. Ben</forenames></author><author><keyname>Wali</keyname><forenames>A.</forenames></author><author><keyname>Alimi</keyname><forenames>Adel M.</forenames></author></authors><title>Towards a new system for drowsiness detection based on eye blinking and
  head posture estimation</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driver drowsiness problem is considered as one of the most important reasons
that increases road accidents number. We propose in this paper a new approach
for realtime driver drowsiness in order to prevent road accidents. The system
uses a smart video camera that takes drivers faces images and supervises the
eye blink (open and close) state and head posture to detect the different
drowsiness states. Face and eye detection are done by Viola and Jones
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00415</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00415</id><created>2018-06-01</created><updated>2018-06-21</updated><authors><author><keyname>Zhou</keyname><forenames>Boran</forenames></author><author><keyname>Trost</keyname><forenames>Landon W.</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoming</forenames></author></authors><title>A Numerical Study of the Relationship Between Erectile Pressure and
  Shear Wave Speed of Corpus Cavernosa in Ultrasound Vibro-elastography</title><categories>q-bio.TO eess.SP physics.med-ph</categories><comments>18 pages, 5 figures. 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this study was to investigate the relationship between
erectile pressure (EP) and shear wave speed of the corpus cavernosa obtained
via a specific ultrasound vibro-elastography (UVE) technique. This study builds
upon our prior investigation, in which UVE was used to evaluate the
viscoelastic properties of the corpus cavernosa in the flaccid and erect
states. A two-dimensional poroviscoelastic finite element model (FEM) was
developed to simulate wave propagation in the penile tissue according to our
experimental setup. Various levels of EP were applied to the corpus cavernosa,
and the relationship between shear wave speed in the corpus cavernosa and EP
was investigated. Results demonstrated non-linear, positive correlations
between shear wave speeds in the corpus cavernosa and increasing EP at
different vibration frequencies (100-200 Hz). These findings represent the
first report of the impact of EP on shear wave speed and validates the use of
UVE in the evaluation of men with erectile dysfunction. Further evaluations are
warranted to determine the clinical utility of this instrument in the diagnosis
and treatment of men with erectile dysfunction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00434</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00434</id><created>2018-06-01</created><authors><author><keyname>Zhou</keyname><forenames>Boran</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoming</forenames></author></authors><title>Will pleural fluid affect surface wave speed measurements of the lung
  using lung ultrasound surface wave elastography: experimental and numerical
  studies on sponge phantom?</title><categories>eess.SP physics.med-ph</categories><comments>20 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pleural effusion manifested as compression of pleural fluid on the lung
parenchyma, contributing to hypoxemia. Medical procedure such as drainage of
plural fluid releases this compression and increase the oxygenation. However,
the effect of pleural effusion on the elasticity of lung parenchyma is unknown.
By using the lung ultrasound surface wave elastography (LUSWE) and finite
element method (FEM), the effect of pleural effusion on the elasticity of
superficial lung parenchyma in terms of surface wave speed measurement was
evaluated in a sponge phantom study. Different thickness of ultrasound
transmission gel simulated as pleural fluid was inserted into a condom which
was placed between the sponge and standoff pad. A mechanical shaker was used to
generate vibration on the sponge phantom at different frequencies ranging from
100 to 300 Hz while ultrasound transducer was used to capture the motion for
measurement of surface wave speed of the sponge. FEM was conducted based on the
experimental setup and numerically assess the influence of pleural effusion on
the surface wave speed of the sponge. We found the influence of thickness of
ultrasound transmission gel was statistically insignificant on the surface wave
speed of the sponge at 100 and 150 Hz both from experiments the FEM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00511</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00511</id><created>2018-06-01</created><authors><author><keyname>Venkataramani</keyname><forenames>Shrikant</forenames></author><author><keyname>Higa</keyname><forenames>Ryley</forenames></author><author><keyname>Smaragdis</keyname><forenames>Paris</forenames></author></authors><title>Performance Based Cost Functions for End-to-End Speech Separation</title><categories>eess.AS cs.SD eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent neural network strategies for source separation attempt to model audio
signals by processing their waveforms directly. Mean squared error (MSE) that
measures the Euclidean distance between waveforms of denoised speech and the
ground-truth speech, has been a natural cost-function for these approaches.
However, MSE is not a perceptually motivated measure and may result in large
perceptual discrepancies. In this paper, we propose and experiment with new
loss functions for end-to-end source separation. These loss functions are
motivated by BSS\_Eval and perceptual metrics like source to distortion ratio
(SDR), source to interference ratio (SIR), source to artifact ratio (SAR) and
short-time objective intelligibility ratio (STOI). This enables the flexibility
to mix and match these loss functions depending upon the requirements of the
task. Subjective listening tests reveal that combinations of the proposed cost
functions help achieve superior separation performance as compared to
stand-alone MSE and SDR costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00516</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00516</id><created>2018-06-01</created><authors><author><keyname>M</keyname><forenames>Nazreen P</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>A G</forenames></author></authors><title>DNN Based Speech Enhancement for Unseen Noises Using Monte Carlo Dropout</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose the use of dropouts as a Bayesian estimator for
increasing the generalizability of a deep neural network (DNN) for speech
enhancement. By using Monte Carlo (MC) dropout, we show that the DNN performs
better enhancement in unseen noise and SNR conditions. The DNN is trained on
speech corrupted with Factory2, M109, Babble, Leopard and Volvo noises at SNRs
of 0, 5 and 10 dB and tested on speech with white, pink and factory1 noises.
Speech samples are obtained from the TIMIT database and noises from NOISEX-92.
In another experiment, we train five DNN models separately on speech corrupted
with Factory2, M109, Babble, Leopard and Volvo noises, at 0, 5 and 10 dB SNRs.
The model precision (estimated using MC dropout) is used as a proxy for squared
error to dynamically select the best of the DNN models based on their
performance on each frame of test data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00556</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00556</id><created>2018-06-01</created><updated>2018-07-04</updated><authors><author><keyname>Schwartz</keyname><forenames>Ariel</forenames></author><author><keyname>Talmon</keyname><forenames>Ronen</forenames></author></authors><title>Intrinsic Isometric Manifold Learning with Application to Localization</title><categories>stat.ML cs.LG eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data living on manifolds commonly appear in many applications. Often this
results from an inherently latent low-dimensional system being observed through
higher dimensional measurements. We show that under certain conditions, it is
possible to construct an intrinsic and isometric data representation, which
respects an underlying latent intrinsic geometry. Namely, we view the observed
data only as a proxy and learn the structure of a latent unobserved intrinsic
manifold, whereas common practice is to learn the manifold of the observed
data. For this purpose, we build a new metric and propose a method for its
robust estimation by assuming mild statistical priors and by using artificial
neural networks as a mechanism for metric regularization and parametrization.
We show successful application to unsupervised indoor localization in ad-hoc
sensor networks. Specifically, we show that our proposed method facilitates
accurate localization of a moving agent from imaging data it collects.
Importantly, our method is applied in the same way to two different imaging
modalities, thereby demonstrating its intrinsic and modality-invariant
capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00672</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00672</id><created>2018-06-02</created><authors><author><keyname>Dalton</keyname><forenames>Lori A.</forenames></author><author><keyname>Benalc&#xe1;zar</keyname><forenames>Marco E.</forenames></author><author><keyname>Dougherty</keyname><forenames>Edward R.</forenames></author></authors><title>Optimal Clustering under Uncertainty</title><categories>stat.ML cs.CV cs.LG eess.IV</categories><comments>19 pages, 5 eps figures, 1 table</comments><msc-class>62H30, 62F35</msc-class><acm-class>I.5.3; G.1.6; I.4.9; I.2.6</acm-class><doi>10.1371/journal.pone.0204627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical clustering algorithms typically either lack an underlying
probability framework to make them predictive or focus on parameter estimation
rather than defining and minimizing a notion of error. Recent work addresses
these issues by developing a probabilistic framework based on the theory of
random labeled point processes and characterizing a Bayes clusterer that
minimizes the number of misclustered points. The Bayes clusterer is analogous
to the Bayes classifier. Whereas determining a Bayes classifier requires full
knowledge of the feature-label distribution, deriving a Bayes clusterer
requires full knowledge of the point process. When uncertain of the point
process, one would like to find a robust clusterer that is optimal over the
uncertainty, just as one may find optimal robust classifiers with uncertain
feature-label distributions. Herein, we derive an optimal robust clusterer by
first finding an effective random point process that incorporates all
randomness within its own probabilistic structure and from which a Bayes
clusterer can be derived that provides an optimal robust clusterer relative to
the uncertainty. This is analogous to the use of effective class-conditional
distributions in robust classification. After evaluating the performance of
robust clusterers in synthetic mixtures of Gaussians models, we apply the
framework to granular imaging, where we make use of the asymptotic
granulometric moment theory for granular images to relate robust clustering
theory to the application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00704</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00704</id><created>2018-06-02</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author></authors><title>An Enhancement of Decimation Process using Fast Cascaded Integrator Comb
  (CIC) Filter</title><categories>eess.SP</categories><comments>International Conference on Semiconductor Electronics. Malaysia, pp.
  811-815</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The oversampling technique has been shown to increase the SNR and is used in
many high-performance systems such as in the ADC for audio and DAT systems.
This paper presents the design of the decimation and it's VLSI implementation
which is the sub-component in the oversampling technique. The design of three
main units in the decimation stage that is the Cascaded Integrator Comb (CIC)
filter, the associated half-band filters and the droop correction are also
described. The Verilog HDL code in Xilinx ISE environment has been derived to
describe the CIC filter properties and downloaded into Virtex II FPGA board. In
the design of these units, we focus on the trade-off between the speed
improvement and the power consumption as well as the silicon area for the chip
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00728</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00728</id><created>2018-06-02</created><updated>2018-07-21</updated><authors><author><keyname>Ahmed</keyname><forenames>Nisar</forenames></author></authors><title>Data-Free/Data-Sparse Softmax Parameter Estimation with Structured Class
  Geometries</title><categories>stat.ML cs.CV cs.LG cs.SY eess.SP</categories><comments>Final version accepted to IEEE Signal Processing Letters (double
  column), submitted July 21, 2018</comments><doi>10.1109/LSP.2018.2860238</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note considers softmax parameter estimation when little/no labeled
training data is available, but a priori information about the relative
geometry of class label log-odds boundaries is available. It is shown that
`data-free' softmax model synthesis corresponds to solving a linear system of
parameter equations, wherein desired dominant class log-odds boundaries are
encoded via convex polytopes that decompose the input feature space. When
solvable, the linear equations yield closed-form softmax parameter solution
families using class boundary polytope specifications only. This allows softmax
parameter learning to be implemented without expensive brute force data
sampling and numerical optimization. The linear equations can also be adapted
to constrained maximum likelihood estimation in data-sparse settings. Since
solutions may also fail to exist for the linear parameter equations derived
from certain polytope specifications, it is thus also shown that there exist
probabilistic classification problems over m convexly separable classes for
which the log-odds boundaries cannot be learned using an m-class softmax model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00768</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00768</id><created>2018-06-03</created><authors><author><keyname>Zhai</keyname><forenames>Xiaojun</forenames></author><author><keyname>Ali</keyname><forenames>Amine Ait Si</forenames></author><author><keyname>Amira</keyname><forenames>Abbes</forenames></author><author><keyname>Bensaali</keyname><forenames>Faycal</forenames></author></authors><title>ECG encryption and identification based security solution on the Zynq
  SoC for connected health systems</title><categories>eess.SP</categories><doi>10.1016/j.jpdc.2016.12.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connected health is a technology that associates medical devices, security
devices and communication technologies. It enables patients to be monitored and
treated remotely from their home. Patients' data and medical records within a
connected health system should be securely stored and transmitted for further
analysis and diagnosis. This paper presents a set of security solutions that
can be deployed in a connected health environment, which includes the advanced
encryption standard (AES) algorithm and electrocardiogram (ECG) identification
system. Efficient System-on-Chip (SoC) implementations for the proposed
algorithms have been carried out on the Xilinx ZC702 prototyping board. The
Achieved hardware implementation results have shown that the proposed AES and
ECG identification based system met the real-time requirements and outperformed
existing field programmable gate array (FPGA)-based systems in different key
performance metrics such as processing time, hardware resources and power
consumption. The proposed systems can process an ECG sample in 10.71 ms and
uses only 30% of the available hardware resources with a power consumption of
107 mW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00836</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00836</id><created>2018-06-03</created><authors><author><keyname>Chan</keyname><forenames>Raymond H.</forenames></author><author><keyname>Kan</keyname><forenames>Kelvin K.</forenames></author><author><keyname>Nikolova</keyname><forenames>Mila</forenames></author><author><keyname>Plemmons</keyname><forenames>Robert J.</forenames></author></authors><title>A two-stage method for spectral-spatial classification of hyperspectral
  images</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel two-stage method for the classification of
hyperspectral images. Pixel-wise classifiers, such as the classical support
vector machine (SVM), consider spectral information only; therefore they would
generate noisy classification results as spatial information is not utilized.
Many existing methods, such as morphological profiles, superpixel segmentation,
and composite kernels, exploit the spatial information too. In this paper, we
propose a two-stage approach to incorporate the spatial information. In the
first stage, an SVM is used to estimate the class probability for each pixel.
The resulting probability map for each class will be noisy. In the second
stage, a variational denoising method is used to restore these noisy
probability maps to get a good classification map. Our proposed method
effectively utilizes both spectral and spatial information of the hyperspectral
data sets. Experimental results on three widely used real hyperspectral data
sets indicate that our method is very competitive when compared with current
state-of-the-art methods, especially when the inter-class spectra are similar
or the percentage of the training pixels is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00864</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00864</id><created>2018-06-03</created><authors><author><keyname>Das</keyname><forenames>Samiran</forenames></author><author><keyname>Routray</keyname><forenames>Aurobinda</forenames></author><author><keyname>Deb</keyname><forenames>Alok Kanti</forenames></author></authors><title>Hyperspectral Unmixing by Nuclear Norm Difference Maximization based
  Dictionary Pruning</title><categories>eess.IV</categories><comments>Conference Paper, 5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dictionary pruning methods perform unmixing by identifying a smaller subset
of active spectral library elements that can represent the image efficiently as
a linear combination. This paper presents a new nuclear norm difference based
approach for dictionary pruning utilizing the low rank property of
hyperspectral data. The proposed workflow calculates the nuclear norm of
abundance of the original data assuming the whole spectral library as
endmembers. In the next step, the algorithm calculates nuclear norm of
abundance after appending a spectral library element with the data. The
spectral library elements having the maximum difference in the nuclear norm of
the obtained abundance matrices are suitable candidates for being image
endmember. The proposed workflow is verified with a large number of synthetic
data generated by varying condition as well as some real images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00927</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00927</id><created>2018-06-03</created><authors><author><keyname>Lee</keyname><forenames>Younggun</forenames></author><author><keyname>Kim</keyname><forenames>Taesu</forenames></author><author><keyname>Lee</keyname><forenames>Soo-Young</forenames></author></authors><title>Voice Imitating Text-to-Speech Neural Networks</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a neural text-to-speech (TTS) model that can imitate a new
speaker's voice using only a small amount of speech sample. We demonstrate
voice imitation using only a 6-seconds long speech sample without any other
information such as transcripts. Our model also enables voice imitation
instantly without additional training of the model. We implemented the voice
imitating TTS model by combining a speaker embedder network with a
state-of-the-art TTS model, Tacotron. The speaker embedder network takes a new
speaker's speech sample and returns a speaker embedding. The speaker embedding
with a target sentence are fed to Tacotron, and speech is generated with the
new speaker's voice. We show that the speaker embeddings extracted by the
speaker embedder network can represent the latent structure in different
voices. The generated speech samples from our model have comparable voice
quality to the ones from existing multi-speaker TTS models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.00984</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.00984</id><created>2018-06-04</created><authors><author><keyname>Fahad</keyname><forenames>Md. Shah</forenames></author><author><keyname>Yadav</keyname><forenames>Jainath</forenames></author><author><keyname>Pradhan</keyname><forenames>Gyadhar</forenames></author><author><keyname>Deepak</keyname><forenames>Akshay</forenames></author></authors><title>DNN-HMM based Speaker Adaptive Emotion Recognition using Proposed Epoch
  and MFCC Features</title><categories>cs.SD cs.AI eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech is produced when time varying vocal tract system is excited with time
varying excitation source. Therefore, the information present in a speech such
as message, emotion, language, speaker is due to the combined effect of both
excitation source and vocal tract system. However, there is very less
utilization of excitation source features to recognize emotion. In our earlier
work, we have proposed a novel method to extract glottal closure instants
(GCIs) known as epochs. In this paper, we have explored epoch features namely
instantaneous pitch, phase and strength of epochs for discriminating emotions.
We have combined the excitation source features and the well known
Male-frequency cepstral coefficient (MFCC) features to develop an emotion
recognition system with improved performance. DNN-HMM speaker adaptive models
have been developed using MFCC, epoch and combined features. IEMOCAP emotional
database has been used to evaluate the models. The average accuracy for emotion
recognition system when using MFCC and epoch features separately is 59.25% and
54.52% respectively. The recognition performance improves to 64.2% when MFCC
and epoch features are combined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01118</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01118</id><created>2018-05-30</created><authors><author><keyname>Westling</keyname><forenames>Fredrik</forenames></author><author><keyname>Underwood</keyname><forenames>James</forenames></author><author><keyname>&#xd6;rn</keyname><forenames>Samuel</forenames></author></authors><title>Light interception modelling using unstructured LiDAR data in avocado
  orchards</title><categories>eess.IV</categories><comments>14 pages, 16 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In commercial fruit farming, managing the light distribution through canopies
is important because the amount and distribution of solar energy that is
harvested by each tree impacts the production of fruit quantity and quality. It
is therefore an important characteristic to measure and ultimately to control
with pruning. We present a solar-geometric model to estimate light interception
in individual avocado (Persea americana) trees, that is designed to scale to
whole-orchard scanning, ultimately to inform pruning decisions. The geometry of
individual trees was measured using LiDAR and represented by point clouds. A
discrete energy distribution model of the hemispherical sky was synthesised
using public weather records. The light from each sky node was then ray traced,
applying a radiation absorption model where rays pass the point cloud
representation of the tree. The model was validated using ceptometer energy
measurements at the canopy floor, and model parameters were optimised by
analysing the error between modelled and measured energies. The model was shown
to perform well qualitatively well through visual comparison with tree shadows
in photographs, and quantitatively well with R^2 = 0.854, suggesting it is
suitable to use in the context of agricultural decision support systems, in
future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01145</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01145</id><created>2018-06-01</created><updated>2018-06-05</updated><authors><author><keyname>Baby</keyname><forenames>Deepak</forenames></author><author><keyname>Verhulst</keyname><forenames>Sarah</forenames></author></authors><title>Machines hear better when they have ears</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep-neural-network (DNN) based noise suppression systems yield significant
improvements over conventional approaches such as spectral subtraction and
non-negative matrix factorization, but do not generalize well to noise
conditions they were not trained for. In comparison to DNNs, humans show
remarkable noise suppression capabilities that yield successful speech
intelligibility under various adverse listening conditions and negative
signal-to-noise ratios (SNRs). Motivated by the excellent human performance,
this paper explores whether numerical models that simulate human cochlear
signal processing can be combined with DNNs to improve the robustness of DNN
based noise suppression systems. Five cochlear models were coupled to
fully-connected and recurrent NN-based noise suppression systems and were
trained and evaluated for a variety of noise conditions using objective
metrics: perceptual speech quality (PESQ), segmental SNR and cepstral distance.
The simulations show that biophysically-inspired cochlear models improve the
generalizability of DNN-based noise suppression systems for unseen noise and
negative SNRs. This approach thus leads to robust noise suppression systems
that are less sensitive to the noise type and noise level. Because cochlear
models capture the intrinsic nonlinearities and dynamics of peripheral auditory
processing, it is shown here that accounting for their deterministic signal
processing improves machine hearing and avoids overtraining of multi-layer
DNNs. We hence conclude that machines hear better when realistic cochlear
models are used at the input of DNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01180</identifier>
 <datestamp>2018-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01180</id><created>2018-06-04</created><authors><author><keyname>Lee</keyname><forenames>Kyungyun</forenames></author><author><keyname>Choi</keyname><forenames>Keunwoo</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Revisiting Singing Voice Detection: a Quantitative Review and the Future
  Outlook</title><categories>cs.SD cs.IR cs.MM eess.AS</categories><comments>Accepted to the 19th International Society of Music Information
  Retrieval (ISMIR) Conference, Paris, France, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the vocal component plays a crucial role in popular music, singing
voice detection has been an active research topic in music information
retrieval. Although several proposed algorithms have shown high performances,
we argue that there still is a room to improve to build a more robust singing
voice detection system. In order to identify the area of improvement, we first
perform an error analysis on three recent singing voice detection systems.
Based on the analysis, we design novel methods to test the systems on multiple
sets of internally curated and generated data to further examine the pitfalls,
which are not clearly revealed with the current datasets. From the experiment
results, we also propose several directions towards building a more robust
singing voice detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01321</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01321</id><created>2018-06-04</created><authors><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author></authors><title>A dedicated codec for compression of Gravitational Waves Sound</title><categories>eess.SP astro-ph.IM</categories><comments>All the results in this paper can be reproduced using the MATLAB
  software which has been made available on
  http://www.nonlinear-approx.info/examples/node010.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dedicated codec for compression of gravitational waves sound with high
quality recovery is proposed. The performance is tested on the available set of
gravitational sound signals that has been theoretically generated at the
Massachusetts Institute of Technology (MIT). The approach is based on a model
for data reduction rendering high quality approximation of the signals. The
reduction of dimensionality is achieved by selecting elementary components from
a redundant set called a dictionary. Comparisons with the compression standard
MP3 demonstrate the merit of the dedicated technique for compressing this type
of sound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01340</identifier>
 <datestamp>2020-01-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01340</id><created>2018-06-04</created><updated>2020-01-17</updated><authors><author><keyname>Feng</keyname><forenames>Jun</forenames></author><author><keyname>Jiao</keyname><forenames>Shuming</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Lei</keyname><forenames>Ting</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaocong</forenames></author></authors><title>Design of optimal illumination patterns in single-pixel imaging using
  image dictionaries</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-pixel imaging (SPI) has a major drawback that many sequential
illuminations are required for capturing one single image with long acquisition
time. Basis illumination patterns such as Fourier patterns and Hadamard
patterns can achieve much better imaging efficiency than random patterns. But
the performance is still sub-optimal since the basis patterns are fixed and
non-adaptive for varying object images. This Letter proposes a novel scheme for
designing and optimizing the illumination patterns adaptively from an image
dictionary by extracting the common image features using principal component
analysis (PCA). Simulation and experimental results reveal that our proposed
scheme outperforms conventional Fourier SPI in terms of imaging efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01443</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01443</id><created>2018-06-04</created><authors><author><keyname>Wang</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Feng</keyname><forenames>Yukang</forenames></author></authors><title>Analysis and Design of 8-Bit CMOS Priority Encoders</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comprehensive review and fair comparison of previous priority encoder (PE)
designs over the past one and a half decades are presented using a 45 nm
technology. Further, potential limitations of existed PEs are identified, based
on which we propose a robust PE design. The new PE is able to eliminate race
condition and charge sharing problem which are suffered by almost all the
previous designs. Besides, the proposed PE can also be used in comprising
higher order PEs by incorporating a carefully designed look-ahead structure.
Simulation results demonstrate that our design can achieve one of the best
power and delay performance among previous PEs and are free from potential
risks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01478</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01478</id><created>2018-06-04</created><authors><author><keyname>Bhandari</keyname><forenames>Ayush</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Sampling and Super-resolution of Sparse Signals Beyond the Fourier
  Domain</title><categories>cs.IT eess.SP math.IT</categories><comments>42 pages, 3 figures, manuscript under review</comments><doi>10.1109/TSP.2018.2890064</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering a sparse signal from its low-pass projections in the Fourier
domain is a problem of broad interest in science and engineering and is
commonly referred to as super-resolution. In many cases, however, Fourier
domain may not be the natural choice. For example, in holography, low-pass
projections of sparse signals are obtained in the Fresnel domain. Similarly,
time-varying system identification relies on low-pass projections on the space
of linear frequency modulated signals. In this paper, we study the recovery of
sparse signals from low-pass projections in the Special Affine Fourier
Transform domain (SAFT). The SAFT parametrically generalizes a number of well
known unitary transformations that are used in signal processing and optics. In
analogy to the Shannon's sampling framework, we specify sampling theorems for
recovery of sparse signals considering three specific cases: (1) sampling with
arbitrary, bandlimited kernels, (2) sampling with smooth, time-limited kernels
and, (3) recovery from Gabor transform measurements linked with the SAFT
domain. Our work offers a unifying perspective on the sparse sampling problem
which is compatible with the Fourier, Fresnel and Fractional Fourier domain
based results. In deriving our results, we introduce the SAFT series (analogous
to the Fourier series) and the short time SAFT, and study convolution theorems
that establish a convolution--multiplication property in the SAFT domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01490</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01490</id><created>2018-06-05</created><authors><author><keyname>Deng</keyname><forenames>Fanshui</forenames></author><author><keyname>Liang</keyname><forenames>Hao</forenames></author><author><keyname>Ye</keyname><forenames>Bangjiao</forenames></author><author><keyname>Tang</keyname><forenames>Jingyu</forenames></author></authors><title>Design of 32-channel TDC Based on Single FPGA for {\mu}SR Spectrometer
  at CSNS</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Muon Spin Rotation, Relaxation and Resonance ({\mu}SR) technology has an
irreplaceable role in studying the microstructure and properties of materials,
especially micro-magnetic properties. An experimental muon source is being
built in China Spallation Neutron Source (CSNS) now. At the same time, a
128-channel {\mu}SR spectrometer as China's first {\mu}SR spectrometer is being
developed. The time spectrum of {\mu}SR can be obtained by fitting the curve of
positron count rate with time. This paper presents a 32-channel Time-to-Digital
Converter (TDC) implemented in a Xilinx Virtex-6 Field Programmable Gate Array
(FPGA) for measuring the positron's flight time of {\mu}SR Spectrometer. Signal
of each channel is sampled by 16 equidistant shifted-phase 200 MHz sampling
clocks, so the TDC bin size is 312.5ps. The measuring range is up to 327us.
This TDC has the ability to store multiple hit signals in a short time with a
deep hit-buffer up to 512. Time tag is added to each data to record the moment
when the data was detected. Programmable time window and channel shielding give
the flexibility to choose the time range and channels of interest. The delay of
each channel can be calibrated. The data is transmitted to data acquisition
system (DAQ) through Gigabit Ethernet. TDC and control logic are configured in
real time by DAQ. The results of test show that the Full Width at Half Maximum
(FWHM) precision of single channel is better than 273 ps with a low sensitivity
to temperature and the linearity is pretty well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01496</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01496</id><created>2018-06-05</created><authors><author><keyname>Liu</keyname><forenames>Haojie</forenames></author><author><keyname>Chen</keyname><forenames>Tong</forenames></author><author><keyname>Shen</keyname><forenames>Qiu</forenames></author><author><keyname>Yue</keyname><forenames>Tao</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author></authors><title>Deep Image Compression via End-to-End Learning</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a lossy image compression method based on deep convolutional
neural networks (CNNs), which outperforms the existing BPG, WebP, JPEG2000 and
JPEG as measured via multi-scale structural similarity (MS-SSIM), at the same
bit rate. Currently, most of the CNNs based approaches train the network using
a L2 loss between the reconstructions and the ground-truths in the pixel
domain, which leads to over-smoothing results and visual quality degradation
especially at a very low bit rate. Therefore, we improve the subjective quality
with the combination of a perception loss and an adversarial loss additionally.
To achieve better rate-distortion optimization (RDO), we also introduce an
easy-to-hard transfer learning when adding quantization error and rate
constraint. Finally, we evaluate our method on public Kodak and the Test
Dataset P/M released by the Computer Vision Lab of ETH Zurich, resulting in
averaged 7.81% and 19.1% BD-rate reduction over BPG, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01506</identifier>
 <datestamp>2019-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01506</id><created>2018-06-05</created><updated>2019-05-02</updated><authors><author><keyname>Zhang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Du</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Zirui</forenames></author><author><keyname>Zhang</keyname><forenames>Jianshu</forenames></author></authors><title>Attention Based Fully Convolutional Network for Speech Emotion
  Recognition</title><categories>cs.SD cs.LG eess.AS</categories><journal-ref>2018 Asia-Pacific Signal and Information Processing Association
  Annual Summit and Conference (APSIPA ASC)</journal-ref><doi>10.23919/APSIPA.2018.8659587</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Speech emotion recognition is a challenging task for three main reasons: 1)
human emotion is abstract, which means it is hard to distinguish; 2) in
general, human emotion can only be detected in some specific moments during a
long utterance; 3) speech data with emotional labeling is usually limited. In
this paper, we present a novel attention based fully convolutional network for
speech emotion recognition. We employ fully convolutional network as it is able
to handle variable-length speech, free of the demand of segmentation to keep
critical information not lost. The proposed attention mechanism can make our
model be aware of which time-frequency region of speech spectrogram is more
emotion-relevant. Considering limited data, the transfer learning is also
adapted to improve the accuracy. Especially, it's interesting to observe
obvious improvement obtained with natural scene image based pre-trained model.
Validated on the publicly available IEMOCAP corpus, the proposed model
outperformed the state-of-the-art methods with a weighted accuracy of 70.4% and
an unweighted accuracy of 63.9% respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01512</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01512</id><created>2018-06-05</created><authors><author><keyname>Tong</keyname><forenames>Zhe</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Bo</forenames></author><author><keyname>Zhang</keyname><forenames>Meng</forenames></author></authors><title>Bearing fault diagnosis based on domain adaptation using transferable
  features under different working conditions</title><categories>eess.SP</categories><comments>Fault diagnosis; Vibration signal; Domain adaptation; Transferable
  features</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bearing failure is the most common failure mode in rotating machinery and can
result in large financial losses or even casualties. However, complex
structures around bearing and actual variable working conditions can lead to
large distribution difference of vibration signal between a training set and a
test set, which causes the accuracy-dropping problem of fault diagnosis. Thus,
how to improve efficiently the performance of bearing fault diagnosis under
different working conditions is always a primary challenge. In this paper, a
novel bearing fault diagnosis under different working conditions method is
proposed based on domain adaptation using transferable features(DATF). The
dataset of normal bearing and faulty bearings are obtained through the fast
Fourier transformation(FFT) of raw vibration signals under different motor
speeds and load conditions. Then we reduce marginal and conditional
distributions simultaneously across domains based on maximum mean
discrepancy(MMD) in feature space by refining pseudo test labels, which can be
obtained by the Nearest-Neighbor(NN) classifier built on training data, and
then a robust transferable feature representation for training and test domains
is achieved after several iterations. With the help of the NN classifier
trained on transferable features, bearing fault categories are identified
accurately in final. Extensive experiment results show that the proposed method
under different working conditions can identify the bearing faults accurately
and outperforms obviously competitive approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01665</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01665</id><created>2018-06-05</created><authors><author><keyname>Gong</keyname><forenames>Rong</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Singing voice phoneme segmentation by hierarchically inferring syllable
  and phoneme onset positions</title><categories>cs.SD cs.IR eess.AS</categories><comments>Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we tackle the singing voice phoneme segmentation problem in
the singing training scenario by using language-independent information --
onset and prior coarse duration. We propose a two-step method. In the first
step, we jointly calculate the syllable and phoneme onset detection functions
(ODFs) using a convolutional neural network (CNN). In the second step, the
syllable and phoneme boundaries and labels are inferred hierarchically by using
a duration-informed hidden Markov model (HMM). To achieve the inference, we
incorporate the a priori duration model as the transition probabilities and the
ODFs as the emission probabilities into the HMM. The proposed method is
designed in a language-independent way such that no phoneme class labels are
used. For the model training and algorithm evaluation, we collect a new jingju
(also known as Beijing or Peking opera) solo singing voice dataset and manually
annotate the boundaries and labels at phrase, syllable and phoneme levels. The
dataset is publicly available. The proposed method is compared with a baseline
method based on hidden semi-Markov model (HSMM) forced alignment. The
evaluation results show that the proposed method outperforms the baseline by a
large margin regarding both segmentation and onset detection tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01701</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01701</id><created>2018-06-05</created><authors><author><keyname>Sardellitti</keyname><forenames>Stefania</forenames></author><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author><author><keyname>Di Lorenzo</keyname><forenames>Paolo</forenames></author></authors><title>Graph topology inference based on sparsifying transform learning</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Signal Processing, March 2018</comments><doi>10.1109/TSP.2019.2896229</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph-based representations play a key role in machine learning. The
fundamental step in these representations is the association of a graph
structure to a dataset. In this paper, we propose a method that aims at finding
a block sparse representation of the graph signal leading to a modular graph
whose Laplacian matrix admits the found dictionary as its eigenvectors. The
role of sparsity here is to induce a band-limited representation or,
equivalently, a modular structure of the graph. The proposed strategy is
composed of two optimization steps: i) learning an orthonormal sparsifying
transform from the data; ii) recovering the Laplacian, and then topology, from
the transform. The first step is achieved through an iterative algorithm whose
alternating intermediate solutions are expressed in closed form. The second
step recovers the Laplacian matrix from the sparsifying transform through a
convex optimization method. Numerical results corroborate the effectiveness of
the proposed methods over both synthetic data and real brain data, used for
inferring the brain functionality network through experiments conducted over
patients affected by epilepsy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01735</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01735</id><created>2018-06-05</created><updated>2019-03-01</updated><authors><author><keyname>Wang</keyname><forenames>Zhi-yue</forenames></author><author><keyname>Chen</keyname><forenames>Ya-qi</forenames></author><author><keyname>Jia</keyname><forenames>Ming-hao</forenames></author><author><keyname>Zhang</keyname><forenames>Guang-yu</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-hao</forenames></author><author><keyname>Chen</keyname><forenames>Jin-ting</forenames></author><author><keyname>Zhang</keyname><forenames>Hong-fei</forenames></author><author><keyname>Jiang</keyname><forenames>Peng</forenames></author><author><keyname>Ji</keyname><forenames>Tuo</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author></authors><title>Design of remote control software of near infrared Sky Brightness
  Monitor in Antarctica</title><categories>astro-ph.IM eess.SP</categories><comments>Many revision were done after the submission, and the result in this
  paper may need more correction</comments><doi>10.1109/TNS.2019.2924474</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Near-infrared Sky Brightness Monitor (NIRBM) aims to measure the middle
infrared sky background in Antarctica. The NIRBM mainly consists of an InGaAs
detector, a chopper, a reflector, a cooler and a black body. The reflector can
rotate to scan the sky with a field of view ranging from 0{\deg} to 180{\deg}.
Electromechanical control and weak signal readout functions are accomplished by
the same circuit, whose core chip is a STM32F407VG microcontroller. Considering
the environment is harsh for humans in Antarctica, a multi-level remote control
software system is designed and implemented. A set of EPICS IOCs are developed
to control each hardware module independently via serial port communication
with the STM32 microcontroller. The tornado web framework and PyEpics are
introduced as a combination where PyEpics is used to monitor or change the
EPICS Process Variables, functioning as a client for the EPICS framework.
Tornado is responsible for the specific operation process of inter-device
collaboration, and expose a set of interfaces to users to make calls.
Considering the high delay and low bandwidth of the network environment, the
tornado back-end is designed as a master-and-agent architecture to improve
domestic user experience. The master node is deployed in Antarctic while
multiple agent nodes can be deployed domestic. The master and agent nodes
communicate with each other through the WebSocket protocol to exchange latest
information so that bandwidth is saved. The GUI is implemented in the form of
single-page application based on the Vue framework which communicates with
tornado through WebSocket and AJAX requests. The web page integrates device
control, data curve drawing, alarm display, auto observation and other
functions together.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01776</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01776</id><created>2018-05-07</created><authors><author><keyname>Zhang</keyname><forenames>Bo</forenames></author><author><keyname>Uhlmann</keyname><forenames>Jeffrey</forenames></author></authors><title>A Generalized Matrix Inverse with Applications to Robotic Systems</title><categories>eess.SP cs.RO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-understood that the robustness of mechanical and robotic control
systems depends critically on minimizing sensitivity to arbitrary
application-specific details whenever possible. For example, if a system is
defined and performs well in one particular Euclidean coordinate frame then it
should be expected to perform identically if that coordinate frame is
arbitrarily rotated or scaled. Similarly, the performance of the system should
not be affected if its key parameters are all consistently defined in metric
units or in imperial units. In this paper we show that a recently introduced
generalized matrix inverse permits performance consistency to be rigorously
guaranteed in control systems that require solutions to underdetermined and/or
overdetermined systems of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01777</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01777</id><created>2018-05-26</created><authors><author><keyname>Wang</keyname><forenames>Yuan-Ying</forenames></author><author><keyname>Wei</keyname><forenames>Hung-Yu</forenames></author></authors><title>Safe Driving Capacity of Autonomous Vehicles</title><categories>eess.SP cs.RO cs.SY</categories><comments>5 pages, VTC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An excellent self-driving car is expected to take its passengers safely and
efficiently from one place to another. However, different ways of defining
safety and efficiency may significantly affect the conclusion we make. In this
paper, we give formal definitions to the safe state of a road and safe state of
a vehicle using the syntax of linear temporal logic (LTL). We then propose the
concept of safe driving throughput (SDT) and safe driving capacity (SDC) which
measure the amount of vehicles in the safe state on a road. We analyze how SDT
is affected by different factors. We show the analytic difference of SDC
between the road with perception-based vehicles (PBV) and the road with
cooperative-based vehicles (CBV). We claim that through proper design, the SDC
of the road filled with PBVs will be upper-bounded by the SDC of the road
filled with CBVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01779</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01779</id><created>2018-05-30</created><authors><author><keyname>Polania</keyname><forenames>Luisa</forenames></author><author><keyname>Plaza</keyname><forenames>Rafael</forenames></author></authors><title>Compressed Sensing ECG using Restricted Boltzmann Machines</title><categories>eess.SP</categories><comments>Accepted for publication at Biomedical Signal Processing and Control
  (Elsevier)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that compressed sensing (CS) has the potential to
lower energy consumption in wireless electrocardiogram (ECG) systems. By
reducing the number of acquired measurements, the communication burden is
decreased and energy is saved. In this paper, we aim at further reducing the
number of necessary measurements to achieve faithful reconstruction by
exploiting the representational power of restricted Boltzmann machines (RBMs)
to model the probability distribution of the sparsity pattern of ECG signals.
The motivation for using this approach is to capture the higher-order
statistical dependencies between the coefficients of the ECG sparse
representation, which in turn, leads to superior reconstruction accuracy and
reduction in the number of measurements, as it is shown via experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01781</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01781</id><created>2018-05-30</created><authors><author><keyname>Abhishta</keyname></author><author><keyname>Joosten</keyname><forenames>Reinoud</forenames></author><author><keyname>Nieuwenhuis</keyname><forenames>Lambert J. M.</forenames></author></authors><title>Comparing Alternatives to Measure the Impact of DDoS Attack
  Announcements on Target Stock Prices</title><categories>q-fin.ST eess.SP</categories><comments>The final version of this paper has been published in Journal of
  Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications
  (JoWUA), Volume 8, Number 4</comments><journal-ref>2017, Volume 8, Number 4, Journal of Wireless Mobile Networks,
  Ubiquitous Computing, and Dependable Applications (JoWUA)</journal-ref><doi>10.22667/JOWUA.2017.12.31.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The attack intensity of distributed denial of service (DDoS) attacks is
increasing every year. Botnets based on internet of things (IOT) devices are
now being used to conduct DDoS attacks. The estimation of direct and indirect
economic damages caused by these attacks is a complex problem. One of the
indirect damage of a DDoS attack can be on the market value of the victim firm.
In this article we analyze the impact of 45 different DDoS attack announcements
on victim's stock prices. We find that previous studies have a mixed conclusion
on the impact of DDoS attack announcements on the victim's stock price. Hence,
in this article we evaluate this impact using three different approaches and
compare the results. In the first approach, we use the assume the cumulative
abnormal returns to be normally distributed and test the hypothesis that a DDoS
attack announcement has no impact on the victim's stock price. In the latter
two methods, we do not assume a distribution and use the empirical distribution
of cumulative abnormal returns to test the hypothesis. We find that the
assumption of cumulative abnormal returns being normally distributed leads to
overestimation/underestimation of the impact. Finally, we analyze the impact of
DDoS attack announcement on victim's stock price in each of the 45 cases and
present our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01782</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01782</id><created>2018-05-30</created><updated>2018-07-17</updated><authors><author><keyname>Ibraheem</keyname><forenames>Ibraheem Kasim</forenames></author></authors><title>Adaptive System Identification Using LMS Algorithm Integrated with
  Evolutionary Computation</title><categories>eess.SP cs.LG cs.NE stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System identification is an exceptionally expansive topic and of remarkable
significance in the discipline of signal processing and communication. Our goal
in this paper is to show how simple adaptive FIR and IIR filters can be used in
system modeling and demonstrating the application of adaptive system
identification. The main objective of our research is to study the LMS
algorithm and its improvement by the genetic search approach, namely, LMS-GA,
to search the multi-modal error surface of the IIR filter to avoid local minima
and finding the optimal weight vector when only measured or estimated data are
available. Convergence analysis of the LMS algorithm in the case of coloured
input signal, i.e., correlated input signal is demonstrated on adaptive FIR
filter via power spectral density of the input signals and Fourier transform of
the autocorrelation matrix of the input signal. Simulations have been carried
out on adaptive filtering of FIR and IIR filters and tested on white and
coloured input signals to validate the powerfulness of the genetic-based LMS
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01783</identifier>
 <datestamp>2019-03-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01783</id><created>2018-06-04</created><updated>2019-03-23</updated><authors><author><keyname>Ebied</keyname><forenames>Ahmed</forenames></author><author><keyname>Kinney-lang</keyname><forenames>Eli</forenames></author><author><keyname>Spyrou</keyname><forenames>Loukianos</forenames></author><author><keyname>Escudero</keyname><forenames>Javier</forenames></author></authors><title>Muscle Activity Analysis using Higher-Order Tensor Models: Application
  to Muscle Synergy Identification</title><categories>eess.SP q-bio.QM</categories><comments>Accepted February 5, 2019</comments><journal-ref>in IEEE Access, vol. 7, pp. 27257-27271, 2019</journal-ref><doi>10.1109/ACCESS.2019.2902122</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order tensor decompositions have hardly been used in muscle activity
analysis despite multichannel electromyography (EMG) datasets naturally
occurring as multi-way structures. Here, we seek to demonstrate and discuss the
potential of tensor decompositions as a framework to estimate muscle synergies
from $3^{rd}$-order EMG tensors built by stacking repetitions of multi-channel
EMG for several tasks. We compare the two most widespread tensor decomposition
models -- Parallel Factor Analysis (PARAFAC) and Tucker -- in muscle synergy
analysis of the wrist's three main Degree of Freedoms (DoFs) using the public
first Ninapro database. Furthermore, we proposed a constrained Tucker
decomposition (consTD) method for efficient synergy extraction building on the
power of tensor decompositions. This method is proposed as a direct novel
approach for shared and task-specific synergy estimation from two
biomechanically related tasks. Our approach is compared with the current
standard approach of repetitively applying non-negative matrix factorisation
(NMF) to a series of movements. The results show that the consTD method is
suitable for synergy extraction compared to PARAFAC and Tucker. Moreover,
exploiting the multi-way structure of muscle activity, the proposed methods
successfully identified shared and task-specific synergies for all three DoFs
tensors. These were found to be robust to disarrangement with regard to
task-repetition information, unlike the commonly used NMF. In summary, we
demonstrate how to use tensors to characterise muscle activity and develop a
new consTD method for muscle synergy extraction that could be used for shared
and task-specific synergies identification. We expect that this study will pave
the way for the development of novel muscle activity analysis methods based on
higher-order techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01785</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01785</id><created>2018-06-04</created><authors><author><keyname>Ebied</keyname><forenames>Ahmed</forenames></author><author><keyname>Kinney-Lang</keyname><forenames>Eli</forenames></author><author><keyname>Spyrou</keyname><forenames>Loukianos</forenames></author><author><keyname>Escudero</keyname><forenames>Javier</forenames></author></authors><title>Evaluation of matrix factorisation approaches for muscle synergy
  extraction</title><categories>eess.SP q-bio.QM</categories><comments>Keywords: Muscle synergy; Matrix factorisation; Surface
  electromyogram; Non-negative matrix factorisation; Second-order blind
  identification; Principal component analysis; Independent component analysis</comments><journal-ref>Medical Engineering &amp; Physics, Volume 57, 2018, Pages 51-60, ISSN
  1350-4533</journal-ref><doi>10.1016/J.MEDENGPHY.2018.04.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The muscle synergy concept provides a widely-accepted paradigm to break down
the complexity of motor control. In order to identify the synergies, different
matrix factorisation techniques have been used in a repertoire of fields such
as prosthesis control and biomechanical and clinical studies. However, the
relevance of these matrix factorisation techniques is still open for discussion
since there is no ground truth for the underlying synergies. Here, we evaluate
factorisation techniques and investigate the factors that affect the quality of
estimated synergies. We compared commonly used matrix factorisation methods:
Principal component analysis (PCA), Independent component analysis (ICA),
Non-negative matrix factorization (NMF) and second-order blind identification
(SOBI). Publicly available real data were used to assess the synergies
extracted by each factorisation method in the classification of wrist
movements. Synthetic datasets were utilised to explore the effect of muscle
synergy sparsity, level of noise and number of channels on the extracted
synergies. Results suggest that the sparse synergy model and a higher number of
channels would result in better-estimated synergies. Without dimensionality
reduction, SOBI showed better results than other factorisation methods. This
suggests that SOBI would be an alternative when a limited number of electrodes
is available but its performance was still poor in that case. Otherwise, NMF
had the best performance when the number of channels was higher than the number
of synergies. Therefore, NMF would be the best method for muscle synergy
extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01788</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01788</id><created>2018-05-31</created><authors><author><keyname>Eini</keyname><forenames>R.</forenames></author><author><keyname>Abdelwahed</keyname><forenames>S.</forenames></author></authors><title>Time-varying Rotational Inverted Pendulum Control using Fuzzy Approach</title><categories>eess.SP</categories><msc-class>39E99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a nonlinear rotational inverted pendulum with time-varying
parameters is controlled using the indirect adaptive fuzzy controller design.
This type of controller is chosen because this particular system performance is
highly sensitive to unavoidable unknown model changes. So, a conventional
controller is firstly designed through feedback linearization method, and
applied to the system. Feedback linearization method here is used for two
purposes; to attain an approximation of necessary system dynamics and to assess
the performance of the proposed adaptive fuzzy controller by comparing the
results of both adaptive fuzzy and feedback linearization controllers. An
indirect adaptive fuzzy controller, resistant to parameter variations is then
proposed. The general structure of the adaptive controller is specified in the
first stage. In the second stage, its parameters are regulated with the aid of
two fuzzy systems. Lyapunov stability theorem is used to regulate the system
parameters such that the closed loop system is stabilized and zero tracking
error is attained. Finally, the results of the proposed and the conventional
approaches are compared. Results showed that the adaptive fuzzy controller
performed more efficiently than the classical controller, with existing
parameters variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01789</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01789</id><created>2018-05-31</created><authors><author><keyname>Alwan</keyname><forenames>Hayder O.</forenames></author><author><keyname>Farhan</keyname><forenames>Noor M.</forenames></author></authors><title>Load Restoration Methodology Considering Renewable Energies and Combined
  Heat and Power Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outages and faults cause problems in interconnected power system with huge
economic consequences in modern societies. In the power system blackouts, black
start resources such as micro combined heat and power (CHP) systems and
renewable energies, due to their self-start ability, are one of the solutions
to restore power system as quickly as possible. In this paper, we propose a
model for power system restoration considering CHP systems and renewable energy
sources as being available in blackout states. We define a control variable
representing a level of balance between the distance and importance of loads
according to the importance and urgency of the affected customer. Dynamic power
flow is considered in order to find feasible sequence and combination of loads
for load restoration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01790</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01790</id><created>2018-06-01</created><authors><author><keyname>Hoelz</keyname><forenames>Peter</forenames></author><author><keyname>Boehlke</keyname><forenames>Thomas</forenames></author><author><keyname>Kraemer</keyname><forenames>Thomas</forenames></author></authors><title>Transient temperature calculation method for complex fluid-solid heat
  transfer problems with scattering boundary conditions</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A calculation method for engine temperatures is presented. Special focus is
placed on the transient and scattering boundary conditions within the
combustion chamber, including fired and coasting conditions, as well as the
dynamic heat transfer of the water jacket. Model reduction is achieved with
dimensional analysis and the application of probability density functions,
which allows for a timescale separation. Stationary in-cylinder pressure
measurements are used as input values and, according to the transient behavior,
modified with an own part-load model. A turbocharged SI race engine is equipped
with 70 thermocouples at various positions in proximity to the combustion
chamber. Differentiating from already published works, the method deals with
the transient engine behavior during a race lap, which undergoes a frequency
range of 0.1-1 Hz. This includes engine speed build-ups under gear changes,
torque variations, or the transition from fired to coasting conditions.
Different thermal behaviors of various measuring positions can be simulated
successfully. Additionally, cylinder individual temperature effects resulting
from an unsymmetrical ignition sequence and different volumetric efficiencies
with unequal residual gas can be predicted. Up to a few percent, the energy
balance of the water jacket is fulfilled and variations of water inlet
temperatures can be simulated accurately enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01791</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01791</id><created>2018-06-02</created><authors><author><keyname>Amanor</keyname><forenames>David</forenames></author><author><keyname>Edmonson</keyname><forenames>William</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author></authors><title>Inter-Satellite Communication System based on Visible Light</title><categories>eess.SP</categories><comments>26 pages, 9 figures, accepted in IEEE Transactions on Aerospace and
  Electronic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future space missions will be driven by factors such as the need for reduced
cost of spacecraft without diminished performance, new services and
capabilities including reconfigurability, autonomous operations, target
observation with improved resolution and servicing (or proximity) operations.
Small satellites, deployed as a sensor network in space, can through
inter-satellite communication (ISC) enable the realization of these future
goals. Developing the communication subsystem that can facilitate ISC within
this distributed network of small satellites require a complex range of design
trade-offs. For small satellites, the general design parameters that are to be
optimized for ISC are size, mass, and power, as well as cost (SMaP-C). Novel
and efficient design techniques for implementing the communication subsystem
are crucial for building multiple small satellite networks with capability for
achieving significant data-rates along the inter-satellite links (ISLs). In
this paper, we propose an alternative approach to RF and laser ISLs for ISC
among small satellites deployed as a sensor network in low Earth orbit (LEO).
For short to medium range ISLs, we present an LED-based visible light
communication (VLC) system that addresses the SMaP constraints, including
capability for achieving significant data rates. Our research is focused on the
development of the physical layer for pico-/nano class of satellites with prime
consideration for the impact of solar background illumination on link
performance. We develop an analytical model of the inter-satellite link (ISL)
in MATLAB and evaluate its feasibility and performance for different intensity
modulation and direct detection (IM/DD) schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01792</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01792</id><created>2018-06-04</created><authors><author><keyname>Liaskos</keyname><forenames>Christos</forenames></author><author><keyname>Nie</keyname><forenames>Shuai</forenames></author><author><keyname>Tsioliaridou</keyname><forenames>Ageliki</forenames></author><author><keyname>Pitsillides</keyname><forenames>Andreas</forenames></author><author><keyname>Ioannidis</keyname><forenames>Sotiris</forenames></author><author><keyname>Akyildiz</keyname><forenames>Ian</forenames></author></authors><title>A New Wireless Communication Paradigm through Software-controlled
  Metasurfaces</title><categories>eess.SP cs.ET cs.NI cs.SY</categories><comments>Paper accepted for publication at the IEEE Communications Magazine.
  This work was funded by the European Union via the Horizon 2020: Future
  Emerging Topics call (FETOPEN-RIA), grant EU736876, project VISORSURF:
  HyperSurfaces-A Hardware Platform for Software-driven Functional Metasurfaces
  (http://www.visorsurf.eu/)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electromagnetic waves undergo multiple uncontrollable alterations as they
propagate within a wireless environment. Free space path loss, signal
absorption, as well as reflections, refractions and diffractions caused by
physical objects within the environment highly affect the performance of
wireless communications. Currently, such effects are intractable to account for
and are treated as probabilistic factors. The paper proposes a radically
different approach, enabling deterministic, programmable control over the
behavior of the wireless environments. The key-enabler is the so-called
HyperSurface tile, a novel class of planar meta-materials which can interact
with impinging electromagnetic waves in a controlled manner. The HyperSurface
tiles can effectively re-engineer electromagnetic waves, including steering
towards any desired direction, full absorption, polarization manipulation and
more. Multiple tiles are employed to coat objects such as walls, furniture,
overall, any objects in the indoor and outdoor environments. An external
software service calculates and deploys the optimal interaction types per tile,
to best fit the needs of communicating devices. Evaluation via simulations
highlights the potential of the new concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01793</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01793</id><created>2018-06-04</created><authors><author><keyname>Recoskie</keyname><forenames>Daniel</forenames></author><author><keyname>Mann</keyname><forenames>Richard</forenames></author></authors><title>Gradient-based Filter Design for the Dual-tree Wavelet Transform</title><categories>eess.SP cs.LG stat.ML</categories><comments>19 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The wavelet transform has seen success when incorporated into neural network
architectures, such as in wavelet scattering networks. More recently, it has
been shown that the dual-tree complex wavelet transform can provide better
representations than the standard transform. With this in mind, we extend our
previous method for learning filters for the 1D and 2D wavelet transforms into
the dual-tree domain. We show that with few modifications to our original
model, we can learn directional filters that leverage the properties of the
dual-tree wavelet transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01875</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01875</id><created>2018-06-05</created><authors><author><keyname>Hartmann</keyname><forenames>Kay Gregor</forenames></author><author><keyname>Schirrmeister</keyname><forenames>Robin Tibor</forenames></author><author><keyname>Ball</keyname><forenames>Tonio</forenames></author></authors><title>EEG-GAN: Generative adversarial networks for electroencephalograhic
  (EEG) brain signals</title><categories>eess.SP cs.LG q-bio.NC stat.ML</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks (GANs) are recently highly successful in
generative applications involving images and start being applied to time series
data. Here we describe EEG-GAN as a framework to generate
electroencephalographic (EEG) brain signals. We introduce a modification to the
improved training of Wasserstein GANs to stabilize training and investigate a
range of architectural choices critical for time series generation (most
notably up- and down-sampling). For evaluation we consider and compare
different metrics such as Inception score, Frechet inception distance and
sliced Wasserstein distance, together showing that our EEG-GAN framework
generated naturalistic EEG examples. It thus opens up a range of new generative
application scenarios in the neuroscientific and neurological context, such as
data augmentation in brain-computer interfacing tasks, EEG super-sampling, or
restoration of corrupted data segments. The possibility to generate signals of
a certain class and/or with specific properties may also open a new avenue for
research into the underlying structure of brain signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01945</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01945</id><created>2018-06-05</created><authors><author><keyname>Perin</keyname><forenames>Jose Krause</forenames></author></authors><title>Spectrally and Power Efficient Optical Communication Systems</title><categories>eess.SP physics.app-ph</categories><comments>PhD thesis, Stanford (2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increased traffic demands globally and in particular in short-reach links in
data centers will require optical communication systems to continue scaling at
an accelerated pace. Nevertheless, energy constraints start to limit the bit
rate that can be practically transmitted over optical systems both at the
shortest distances in data centers and at the longest distances in ultra-long
submarine links. Short-reach links in data centers face strict constraints on
power consumption, size, and cost, which will demand low-power solutions that
scale to bit rates beyond 100 Gbit/s per wavelength, while accommodating
increased losses due to longer fiber plant, multiplexing of more wavelengths,
and possibly optical switching. At the longest distances, submarine optical
cables longer than about 5,000 km face energy constraints due to power feed
limits at the shores, which restricts the electrical power available to the
undersea optical amplifiers, ultimately limiting the optical power and
throughput per fiber. This dissertation presents strategies to mitigate these
limitations. For short-reach links in data centers, we propose low-power
coherent receiver architectures that completely avoid high-speed
analog-to-digital converters and digital signal processors. For long-haul
submarine links, we demonstrate how optimizing the channel power allocation
under a constraint on the amplifier power maximizes the information-theoretic
capacity per fiber.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01979</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01979</id><created>2018-06-05</created><authors><author><keyname>Song</keyname><forenames>Andrew H.</forenames></author><author><keyname>Flores</keyname><forenames>Francisco</forenames></author><author><keyname>Ba</keyname><forenames>Demba</forenames></author></authors><title>Spike Sorting by Convolutional Dictionary Learning</title><categories>stat.ME eess.SP q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spike sorting refers to the problem of assigning action potentials observed
in extra-cellular recordings of neural activity to the neuron(s) from which
they originate. We cast this problem as one of learning a convolutional
dictionary from raw multi-electrode waveform data, subject to sparsity
constraints. In this context, sparsity refers to the number of neurons that are
allowed to spike simultaneously. The convolutional dictionary setting, along
with its assumptions (e.g. refractoriness) that are motivated by the
spike-sorting problem, let us give theoretical bounds on the sample complexity
of spike sorting as a function of the number of underlying neurons, the rate of
occurrence of simultaneous spiking, and the firing rate of the neurons. We
derive memory/computation-efficient convolutional versions of OMP (cOMP) and
KSVD (cKSVD), popular algorithms for sparse coding and dictionary learning
respectively. We demonstrate via simulations that an algorithm that alternates
between cOMP and cKSVD can recover the underlying spike waveforms successfully,
assuming few neurons spike simultaneously, and is stable in the presence of
noise. We also apply the algorithm to extra-cellular recordings from a tetrode
in the rat Hippocampus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01989</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.01989</id><created>2018-06-05</created><updated>2018-06-20</updated><authors><author><keyname>Zhang</keyname><forenames>Sijie</forenames></author><author><keyname>Zhou</keyname><forenames>Nan</forenames></author><author><keyname>Deng</keyname><forenames>Fanshui</forenames></author><author><keyname>Liang</keyname><forenames>Hao</forenames></author></authors><title>Design of Voltage Pulse Control Module for Free Space
  Measurement-Device-Independent Quantum Key Distribution</title><categories>eess.SP cs.ET physics.app-ph</categories><doi>10.1109/TNS.2019.2916973</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measurement-Device-Independent Quantum Key Distribution (MDIQKD) protocol has
been proved that it is unaffected by all hacking attacks, and ensures the
security of information theory even when the performance of single-photon
detectors is not ideal. Fiber channel has been used by the previous MDIQKD
experimental device. However, the signal attenuation increases exponentially as
the transmission distance increases. In order to overcome this, we regard free
space as the channel of signal transmission, and the signal attenuation
increases square as the transmission distance increases (regardless of the
atmospheric scattering), which can effectively reduce the signal attenuation
trend. In order to implement the free space MDIQKD experiments, a modulation
module is needed to modulate the wide pulse chopping, decoy-state,
normalization, phase encoding and time encoding. In this paper, we present the
design of the Voltage Pulse Control Module for the free space MDIQKD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02002</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02002</id><created>2018-06-06</created><authors><author><keyname>Wang</keyname><forenames>Meng</forenames></author></authors><title>Pavement Crack Detection Based on Mobile Laser Scanning Data</title><categories>eess.IV</categories><comments>in Chinese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pavement cracks is one of the most important reasons that affects the road
capacity. Nowadays, China has the longest highway mileage in the world, thus
using traditional manual methods to detect pavement cracks is both time and
labor consuming, besides, the detection results are prone to be affected by
detectors, which is often subjective. Meanwhile, using digital image to detect
pavement cracks may be affected by illumination and shadows, which could
dramatically reduce the detection precision. Therefore, designing a new
detection method has important significance. This paper proposes a new method
of detecting pavement cracks using high density laser point cloud. High density
laser point cloud can be gathered through Vehicle-borne laser scanning system,
which integrates a variety types of sensors which include GNSS/INS,laser
scanner and cameras. It can automatically collect 3-D spatial information
around it in a high speed,it's one of the most advanced 3-D spatial information
acquisition technologies. The system is not affected by illumination while
gathering laser point cloud, besides, it gathers laser point cloud very fast,
which greatly improves the detection efficiency. The method proposed consists
of four parts, which are data preparation, image preprocessing, binarization
and crack enhancement. This method combines the advantages of digital image and
laser point cloud to solve the problem. High density laser point cloud are
first interpolated into georeferenced feature (GRF) image, then median filter,
morphology, local adaptive threshold and multi scale iterative tensor voting
method are used to detect pavement cracks from GRF image. At last, Hausdorff
distance is used to evaluate detection precision. The SM value reached around
95, indicates that pavement cracks are well detected and the method proposed
can serve the municipal departments well to detect pavement cracks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02013</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02013</id><created>2018-06-06</created><authors><author><keyname>Forouzesh</keyname><forenames>Moslem</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Wong</keyname><forenames>Kai Kit</forenames></author></authors><title>Robust Physical Layer Security for Power Domain Non-orthogonal Multiple
  Access-Based HetNets and HUDNs, SIC Avoidance at Eavesdroppers</title><categories>cs.CR cs.IT eess.SP math.IT</categories><comments>14 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the physical layer security in downlink of
Power Domain Non Orthogonal Multiple Access based heterogeneous cellular
network in presence of multiple eavesdroppers. Our aim is to maximize the sum
secrecy rate of the network. To this end, we formulate joint subcarrier and
power allocation optimization problems to increase sum secrecy rate. Moreover,
we propose a novel scheme at which the eavesdroppers are prevented from doing
Successive Interference Cancellation, while legitimate users are able to do it.
In practical systems, availability of eavesdroppers Channel State Information
is impractical, hence we consider two scenarios: 1 Perfect CSI of the
eavesdroppers, 2 imperfect CSI of the eavesdroppers. Since the proposed
optimization problems are nonconvex, we adopt the well known iterative
algorithm called Alternative Search Method. In this algorithm, the optimization
problems are converted to two subproblems, power allocation and subcarrier
allocation. We solve the power allocation problem by the Successive Convex
Approximation approach and solve the subcarrier allocation subproblem, by
exploiting the Mesh Adaptive Direct Search algorithm. Moreover, in order to
study the optimality gap of the proposed solution method, we apply the
monotonic optimization method. Moreover, we evaluate the proposed scheme for
secure massive connectivity in 5G networks. Numerical results highlight that
the proposed scheme significantly improves the sum secrecy rate compared with
the conventional case at which the eavesdroppers are able to apply SIC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02130</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02130</id><created>2018-06-06</created><updated>2018-10-30</updated><authors><author><keyname>Panta</keyname><forenames>Bhola R.</forenames></author><author><keyname>Kido</keyname><forenames>Kohta</forenames></author><author><keyname>Yasuda</keyname><forenames>Satoshi</forenames></author><author><keyname>Hanado</keyname><forenames>Yuko</forenames></author><author><keyname>Kawamura</keyname><forenames>Seiji</forenames></author><author><keyname>Hanado</keyname><forenames>Hiroshi</forenames></author><author><keyname>Takizawa</keyname><forenames>Kenichi</forenames></author><author><keyname>Inoue</keyname><forenames>Masugi</forenames></author><author><keyname>Shiga</keyname><forenames>Nobuyasu</forenames></author></authors><title>Range Variation Monitoring with Wireless Two-Way Interferometry (Wi-Wi)</title><categories>eess.SP</categories><comments>4 pages, 4 figures, related paper:
  https://doi.org/10.1587/comex.2016XBL0181</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrated a simple technique for monitoring range variation with
millimeter-precision between two remote sites using off-the-shelf wireless
communication modules. The need for the flexible positioning of wireless
devices is significantly increasing as more devices are being connected and new
services are being developed that require devices to collaborate with one
another. We showed that one can monitor the distance variation by analyzing the
propagation delay of the wireless communication signal between devices. We
previously reported a technique for synchronizing clocks with picosecond
precision by monitoring the time variation of two rubidium clocks located at
remote sites. Precise measurement of the propagation time variation was
necessary for precise synchronization of the clocks, and we used this
information to estimate the distance with high precision. In a localized
situation, our technique makes it easy to implement a millimeter-precision
measurement system. Furthermore, it is less complex in terms of system design
and can be a low-cost alternative to existing systems that require precise
position measurement. We envision that this demonstrated protocol will be
implemented in wireless communication chips and microprocessing units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02169</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02169</id><created>2018-06-06</created><updated>2018-06-29</updated><authors><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author><author><keyname>Kaneko</keyname><forenames>Takuhiro</forenames></author><author><keyname>Tanaka</keyname><forenames>Kou</forenames></author><author><keyname>Hojo</keyname><forenames>Nobukatsu</forenames></author></authors><title>StarGAN-VC: Non-parallel many-to-many voice conversion with star
  generative adversarial networks</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method that allows non-parallel many-to-many voice
conversion (VC) by using a variant of a generative adversarial network (GAN)
called StarGAN. Our method, which we call StarGAN-VC, is noteworthy in that it
(1) requires no parallel utterances, transcriptions, or time alignment
procedures for speech generator training, (2) simultaneously learns
many-to-many mappings across different attribute domains using a single
generator network, (3) is able to generate converted speech signals quickly
enough to allow real-time implementations and (4) requires only several minutes
of training examples to generate reasonably realistic-sounding speech.
Subjective evaluation experiments on a non-parallel many-to-many speaker
identity conversion task revealed that the proposed method obtained higher
sound quality and speaker similarity than a state-of-the-art method based on
variational autoencoding GANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02173</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02173</id><created>2018-06-03</created><authors><author><keyname>Zhang</keyname><forenames>Guangyu</forenames></author><author><keyname>Sun</keyname><forenames>Quan</forenames></author><author><keyname>Liu</keyname><forenames>Tiankuan</forenames></author><author><keyname>Gong</keyname><forenames>Datao</forenames></author><author><keyname>Yang</keyname><forenames>Dongxu</forenames></author><author><keyname>Feng</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author></authors><title>Study of Full Parallel RS(31,27) Encoder for a 3.2 Gbps Serial
  Transmitter in 0.18 um CMOS Technology</title><categories>eess.SP</categories><doi>10.1088/1748-0221/14/02/P02028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents the design of an RS(31,27) Reed Solomon encoder for a 3.2
Gbps serial transmitter in 0.18 um CMOS technology. The proposed encoder is
designed with a novel full parallel structure optimized for high speed and high
stability. One data frame contains 2 interleaved RS(31,27) codes and thus it
can correct at most 20 bits of consecutive errors. A corresponding decoder is
implemented on Xilinx Kintex-7 FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02192</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02192</id><created>2018-06-05</created><authors><author><keyname>Liu</keyname><forenames>Xuesong</forenames></author><author><keyname>Wu</keyname><forenames>Jie</forenames></author><author><keyname>Zhou</keyname><forenames>Meng</forenames></author></authors><title>Using Adjacent Data Retransmission to Improve the Transmission
  Efficiency of Multi-hop Relay Networks</title><categories>eess.SP physics.ins-det</categories><comments>2pages,5figures.21st IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data transmission systems are widely used in various aspects of life,
industry, research and other fields. Transmission systems have different
characteristics for different application scenarios. Many of them require
multi-hop transmission to extend the transmission range, such as Wireless Mesh
Network (WMN), Mobile Ad-hoc Network (MANET), Wireless Sensor Networks (WSN)
and so on. The biggest problem of multi-hop transmission lies in that packet
loss caused by bit error ratio (BER) in multiple transmission processes
increases greatly, which makes end-to-end transmission reliability and
bandwidth utilization decrease. This paper analyzes the impact of BER on
bandwidth utilization in multi-hop relay transmission and proposes a simple and
flexible transmission mechanism that is generally applicable to multi-hop
transmission scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02269</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02269</id><created>2018-05-22</created><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>New expression on the performance of a novel multi-hop relay-assisted
  hybrid FSO / RF communication system</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel multi-hop relay-assisted hybrid FSO / RF system is
presented. It is assumed that direct RF connection between mobile users and
source Base Station is impossible, therefore a relay connects RF users to the
source Base Station via a FSO link. Source and destination Base Stations are
connected via a multi-hop relay-assisted hybrid FSO / RF link. FSO link is
investigated over moderate to saturate regimes of atmospheric turbulence. Also
RF link is assumed to have Rayleigh fading. For the first time, new exact and
asymptotic expressions are derived in closed-form for Bit Error Rate (BER) and
the Outage Probability (P_out), of the proposed system. MATLAB simulations are
performed to validate obtained analytical results. Results indicate that the
proposed structure has low dependence on the number of users, therefore, the
proposed structure is suitable for cells which encounter different populations
during a day, because there is little performance difference between systems
with different number of users. Also the proposed structure, at Negative
exponential atmospheric turbulence has small dependence on the number of
relays, but this dependence is a bit more for Gamma-Gamma atmospheric
turbulence. Therefore, the proposed structure increases capacity whereas
maintaining performance of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02272</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02272</id><created>2018-05-27</created><authors><author><keyname>Shu</keyname><forenames>F.</forenames></author><author><keyname>Wang</keyname><forenames>Z.</forenames></author><author><keyname>Yan</keyname><forenames>S.</forenames></author><author><keyname>Zhou</keyname><forenames>X.</forenames></author><author><keyname>Li</keyname><forenames>J.</forenames></author><author><keyname>Zhou</keyname><forenames>X.</forenames></author></authors><title>Low-Complexity Linear Precoding for Secure Spatial Modulation</title><categories>eess.SP</categories><comments>11pages, 8figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this work, we investigate linear precoding for secure spatial modulation.
With secure spatial modulation, the achievable secrecy rate does not have an
easy-to-compute mathematical expression, and hence, has to be evaluated
numerically, which leads to high complexity in the optimal precoder design. To
address this issue, an accurate and analytical approximation of the secrecy
rate is derived in this work. Using this approximation as the objective
function, two low-complexity linear precoding methods based on gradient descend
(GD) and successive convex approximation (SCA) are proposed. The GD-based
method has much lower complexity but usually converges to a local optimum. On
the other hand, the SCA-based method uses semi-definite relaxation to deal with
the non-convexity in the precoder optimization problem and achieves
near-optimal solution. Compared with the existing GD-based precoder design in
the literature that directly uses the exact and numerically evaluated secrecy
capacity as the objective function, the two proposed designs have significantly
lower complexity. Our SCA-based design even achieves a higher secrecy rate than
the existing GD-based design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02317</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02317</id><created>2018-06-06</created><authors><author><keyname>Konda</keyname><forenames>Pavan Chandra</forenames></author><author><keyname>Taylor</keyname><forenames>Jonathan M.</forenames></author><author><keyname>Harvey</keyname><forenames>Andrew R.</forenames></author></authors><title>Parallelized aperture synthesis using multi-aperture Fourier
  ptychographic microscopy</title><categories>physics.optics eess.IV physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a novel microscopy platform, termed Multi-Aperture Fourier
ptychographic microscopy (MA-FPM), capable of realizing gigapixel complex field
images with large data acquisition bandwidths - in gigapixels per second.
MA-FPM is a synthetic aperture technique- an array of objectives together with
tilt-shift illumination are used to synthesize high-resolution, wide
field-of-view images. Here, the phase is recovered using Fourier ptychography
(FP) algorithms, unlike conventional optical synthetic aperture techniques
where holographic measurements are used. The parallel data-acquisition
capability due to multiple objectives provides unprecedented bandwidth enabling
imaging of high-speed in vitro processes over extended depth-of-field. Here, we
present a proof-of-concept experiment demonstrating high-quality imaging
performance despite using nine-fold fewer illumination angles compared to an
equivalent FP setup. Calibration procedures and reconstruction algorithm were
developed to address the challenges of multiple imaging systems. Our technique
provides a new imaging tool to study cell cultures, offering new insights into
these processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02388</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02388</id><created>2018-06-06</created><authors><author><keyname>Lin</keyname><forenames>Lei</forenames></author></authors><title>Efficient Collection of Connected Vehicle Data based on Compressive
  Sensing</title><categories>stat.AP eess.SP</categories><comments>Submitted to The 21st IEEE International Conference on Intelligent
  Transportation Systems</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Connected vehicles (CVs) can capture and transmit detailed data like vehicle
position, speed and so on through vehicle-to-vehicle and
vehicle-to-infrastructure communications. The wealth of CV data provides new
opportunities to improve the safety, mobility, and sustainability of
transportation systems. However, the potential data explosion likely will
overburden storage and communication systems. To solve this issue, we design a
real-time compressive sensing (CS) approach which allows CVs to collect and
compress data in real-time and can recover the original data accurately and
efficiently when it is necessary. The CS approach is applied to recapture 10
million CV Basic Safety Message speed samples from the Safety Pilot Model
Deployment program. With a compression ratio of 0.2, it is found that the CS
approach can recover the original speed data with the root mean squared error
as low as 0.05. The recovery performances of the CS approach are further
explored by time-of-day and acceleration. The results show that the CS approach
performs better in data recovery when CV speeds are steady or changing
smoothly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02412</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02412</id><created>2018-05-29</created><authors><author><keyname>Wang</keyname><forenames>Haichao</forenames></author><author><keyname>Wang</keyname><forenames>Jinlong</forenames></author><author><keyname>Ding</keyname><forenames>Guoru</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>D2D Communications Underlaying Wireless Powered Communication Networks</title><categories>cs.IT eess.SP math.IT math.OC</categories><journal-ref>IEEE Transactions on Vehicular Technology, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the resource allocation problem for D2D
communications underlaying wireless powered communication networks, where
multiple D2D pairs harvest energy from a power station equipped with multiple
antennas and then transmit information signals simultaneously over the same
spectrum resource. The aim is to maximize the sum throughput via joint time
scheduling and power control, while satisfying the energy causality
constraints. The formulated non-convex problem is first transformed into a
nonlinear fractional programming problem with a tactful reformulation. Then, by
leveraging D.C. (difference of two convex functions) programming, a suboptimal
solution to the non-convex problem is obtained by iteratively solving a
sequence of convex problems. Simulation results demonstrate that the proposed
scheme works well in different scenarios and can significantly improve the
system throughput compared with the-state-of-the-art schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02449</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02449</id><created>2018-06-06</created><updated>2018-12-23</updated><authors><author><keyname>Amiri</keyname><forenames>Roohollah</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author></authors><title>Joint Power Allocation in Interference-Limited Networks via Distributed
  Coordinated Learning</title><categories>eess.SP</categories><comments>VTC-Fall-2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deployment of ultra-dense networks is one of the main methods to meet the
5G data rate requirements. However, high density of independent small base
stations (SBSs) will increase the interference within the network. To
circumvent this interference, there is a need to develop self-organizing
methods to manage the resources of the network. In this paper, we present a
distributed power allocation algorithm based on multi-agent Q-learning in an
interference-limited network. The proposed method leverages coordination
through simple message passing between SBSs to achieve an optimal joint power
allocation. Simulation results show the optimality of the proposed method for a
two-user case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02530</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02530</id><created>2018-06-07</created><updated>2018-12-21</updated><authors><author><keyname>Santos</keyname><forenames>Irene</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>Djuri&#x107;</keyname><forenames>Petar M.</forenames></author></authors><title>Recursive Estimation of Dynamic RSS Fields Based on Crowdsourcing and
  Gaussian Processes</title><categories>eess.SP</categories><comments>This manuscript has been submitted to IEEE Transactions on Signal
  Processing on May 11, 2018; revised on August 9, 2018 and November 15, 2018;
  accepted on December 10, 2018</comments><doi>10.1109/TSP.2018.2889987</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the estimation of a time-varying spatial field of
received signal strength (RSS) by relying on measurements from randomly placed
and not very accurate sensors. We employ a radio propagation model where the
path loss exponent and the transmitted power are unknown with Gaussian priors
whose hyper-parameters are estimated by applying the empirical Bayes method. We
consider the locations of the sensors to be imperfectly known, which entails
that they represent another source of error in the model. The propagation model
includes shadowing which is considered to be a zero-mean Gaussian process where
the correlation of attenuation between two spatial points is quantified by an
exponential function of the distance between the points. The location of the
transmitter is also unknown and estimated from the data with a weighted
centroid approach. We propose to estimate time-varying RSS fields by a
recursive Bayesian method and crowdsourcing. The method is based on Gaussian
processes (GP), and it produces the joint distribution of the spatial field.
Further, it summarizes all the acquired information by keeping the size of the
needed memory bounded. We also present the Bayesian Cram\'er-Rao bound (BCRB)
of the estimated parameters. Finally, we illustrate the performance of our
method with experimental results on synthetic data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02597</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02597</id><created>2018-06-07</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Performance evaluation of a novel relay assisted hybrid FSO / RF
  communication system with receive diversity</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main problems in mobile communication systems is the degradation
of Radio Frequency (RF) connection when mobile user is far from base station.
One way to solve this problem is to increase the transmitter power, but the
mobile transmitter is not able to supply much power. Another way is to use a
relay; among relay schemes, amplify and forward is better for long range
communications. Amplify and forward relay is not affordable in terms of power
consumption and performance, because it consumes a lot of power inefficiently
and enhances the noise. Therefore, in other cases, except in the case of long
range links, other relay protocols, such as decode and forward, as well as
demodulate and forward, are preferable. In this paper, a novel multi-hop hybrid
Free Space Optical (FSO) / RF link is presented; it is made up of two main
parts. The first part establishes the connection between the mobile user and
source base station, and the second part establishes the connection between the
source and the destination base stations. In the first part, a mobile user
wants to connect to the source base station via a long range link; therefore, a
fixed gain amplify and forward relay with multiple receive antennas is used for
communication establishment. In the second part, the source and the destination
base stations are connected via a multi-hop hybrid parallel FSO / RF link with
demodulate and forward relaying. Considering the FSO link in Gamma-Gamma
atmospheric turbulence with the effect of pointing error in moderate to strong
regime and the Negative Exponential atmospheric turbulence in saturate regime,
and the RF link in Rayleigh fading, new closed form exact and asymptotic
expressions are derived for the Outage Probability and Bit Error Rate of the
proposed structure. Derived expressions are verified with MATLAB simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02628</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02628</id><created>2018-06-07</created><updated>2019-01-02</updated><authors><author><keyname>Diamant</keyname><forenames>Roee</forenames></author><author><keyname>Casari</keyname><forenames>Paolo</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author></authors><title>Cooperative Authentication in Underwater Acoustic Sensor Networks</title><categories>eess.SP cs.NI</categories><comments>Author version of paper accepted for publication in the IEEE
  Transactions on Wireless Communications</comments><doi>10.1109/TWC.2018.2886896</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing use of underwater acoustic communications (UWAC) for both
industrial and military operations, there is a need to ensure communication
security. A particular challenge is represented by underwater acoustic networks
(UWANs), which are often left unattended over long periods of time. Currently,
due to physical and performance limitations, UWAC packets rarely include
encryption, leaving the UWAN exposed to external attacks faking legitimate
messages. In this paper, we propose a new algorithm for message authentication
in a UWAN setting. We begin by observing that, due to the strong spatial
dependency of the underwater acoustic channel, an attacker can attempt to mimic
the channel associated with the legitimate transmitter only for a small set of
receivers, typically just for a single one. Taking this into account, our
scheme relies on trusted nodes that independently help a sink node in the
authentication process. For each incoming packet, the sink fuses beliefs
evaluated by the trusted nodes to reach an authentication decision. These
beliefs are based on estimated statistical channel parameters, chosen to be the
most sensitive to the transmitter-receiver displacement. Our simulation results
show accurate identification of an attacker's packet. We also report results
from a sea experiment demonstrating the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02674</identifier>
 <datestamp>2018-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02674</id><created>2018-06-05</created><updated>2018-10-23</updated><authors><author><keyname>Fannjiang</keyname><forenames>A.</forenames></author><author><keyname>Chen</keyname><forenames>P.</forenames></author></authors><title>Blind Ptychography: Uniqueness and Ambiguities</title><categories>eess.IV</categories><comments>Figure 2 added; Example 5.7 expanded</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ptychography with an unknown mask and object is analyzed for general
ptychographic schemes that allow the object parts to be strongly connected and
admits an anchoring object part.
  Under a mild mask phase constraint, it is proved that the masked object
estimate must be the product of a block phase factor and the true masked
object. Hence blind ptychographic ambiguities in general manifest in the
undetermined block phase that can vary from block to block arbitrarily. This is
the local uniqueness.
  The global uniqueness is proved for the mixing schemes that the block phase
has an affine profile and that the object and mask can be simultaneously
recovered up to a constant scaling factor and an affine phase factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02727</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02727</id><created>2018-06-07</created><authors><author><keyname>Zhang</keyname><forenames>Zihe</forenames></author><author><keyname>Li</keyname><forenames>Lixin</forenames></author><author><keyname>Liang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Xu</forenames></author><author><keyname>Gao</keyname><forenames>Ang</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Downlink Interference Management in Dense Interference-Aware Drone Small
  Cells Networks Using Mean-Field Game Theory</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of drone small cells (DSCs) has recently drawn significant attentions
as one key enabler for providing air-to-ground communication services in
various situations. This paper investigates the co-channel deployment of dense
DSCs, which are mounted on captive unmanned aerial vehicles (UAVs). As the
altitude of a DSC has a huge impact on the performance of downlink, the
downlink interference control problem is mapped to an altitude control problem
in this paper. All DSCs adjust their altitude to improve the available
signal-to-interference-plus-noise ratio (SINR). The control problem is modeled
as a mean-field game (MFG), where the cost function is designed to combine the
available SINR with the cost of altitude controling. The interference
introduced from a big amount of DSCs is derived through a mean-field
approximation approach. Within the proposed MFG framework, the related
Hamilton-Jacobi-Bellman and Fokker-Planck-Kolmogorov equations are deduced to
describe and explain the control policy. The optimal altitude control policy is
obtained by solving the partial differential equations with a proposed finite
difference algorithm based on the upwind scheme. The simulations illustrate the
optimal power controls and corresponding mean field distribution of DSCs. The
numerical results also validate that the proposed control policy achieves
better SINR performance of DSCs compared to the uniform control scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.02782</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.02782</id><created>2018-06-07</created><updated>2018-06-17</updated><authors><author><keyname>Sun</keyname><forenames>Sining</forenames></author><author><keyname>Yeh</keyname><forenames>Ching-Feng</forenames></author><author><keyname>Ostendorf</keyname><forenames>Mari</forenames></author><author><keyname>Hwang</keyname><forenames>Mei-Yuh</forenames></author><author><keyname>Xie</keyname><forenames>Lei</forenames></author></authors><title>Training Augmentation with Adversarial Examples for Robust Speech
  Recognition</title><categories>cs.CL cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the use of adversarial examples in training speech
recognition systems to increase robustness of deep neural network acoustic
models. During training, the fast gradient sign method is used to generate
adversarial examples augmenting the original training data. Different from
conventional data augmentation based on data transformations, the examples are
dynamically generated based on current acoustic model parameters. We assess the
impact of adversarial data augmentation in experiments on the Aurora-4 and
CHiME-4 single-channel tasks, showing improved robustness against noise and
channel variation. Further improvement is obtained when combining adversarial
examples with teacher/student training, leading to a 23% relative word error
rate reduction on Aurora-4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03047</identifier>
 <datestamp>2018-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03047</id><created>2018-06-08</created><authors><author><keyname>Gomez</keyname><forenames>Sergi</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Mark</forenames></author><author><keyname>Popovici</keyname><forenames>Emanuel</forenames></author><author><keyname>Mathieson</keyname><forenames>Sean</forenames></author><author><keyname>Boylan</keyname><forenames>Geraldine</forenames></author><author><keyname>Temko</keyname><forenames>Andriy</forenames></author></authors><title>On sound-based interpretation of neonatal EEG</title><categories>q-bio.NC cs.SD eess.AS stat.AP</categories><comments>ISSC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Significant training is required to visually interpret neonatal EEG signals.
This study explores alternative sound-based methods for EEG interpretation
which are designed to allow for intuitive and quick differentiation between
healthy background activity and abnormal activity such as seizures. A novel
method based on frequency and amplitude modulation (FM/AM) is presented. The
algorithm is tuned to facilitate the audio domain perception of rhythmic
activity which is specific to neonatal seizures. The method is compared with
the previously developed phase vocoder algorithm for different time compressing
factors. A survey is conducted amongst a cohort of non-EEG experts to
quantitatively and qualitatively examine the performance of sound-based methods
in comparison with the visual interpretation. It is shown that both
sonification methods perform similarly well, with a smaller inter-observer
variability in comparison with visual. A post-survey analysis of results is
performed by examining the sensitivity of the ear to frequency evolution in
audio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03174</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03174</id><created>2018-06-07</created><updated>2020-01-28</updated><authors><author><keyname>Heimowitz</keyname><forenames>Ayelet</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>A Markov Variation Approach to Smooth Graph Signal Interpolation</title><categories>eess.SP cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the Markov variation, a smoothness measure which
offers a probabilistic interpretation of graph signal smoothness. This measure
is then used to develop an optimization framework for graph signal
interpolation. Our approach is based on diffusion embedding vectors and the
connection between diffusion maps and signal processing on graphs. As diffusion
embedding vectors may be expensive to compute for large graphs, we present a
computationally efficient method, based on the Nystr\&quot;{o}m extension, for
interpolation of signals over a graph. We demonstrate our approach on the MNIST
dataset and a dataset of daily average temperatures around the US. We show that
our method outperforms state of the art graph signal interpolation techniques
on both datasets, and that our computationally efficient reconstruction
achieves slightly reduced accuracy with a large computational speedup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03175</identifier>
 <datestamp>2018-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03175</id><created>2018-06-06</created><authors><author><keyname>Uslu</keyname><forenames>Fatmatulzehra</forenames></author><author><keyname>Bharath</keyname><forenames>Anil Anthony</forenames></author></authors><title>A Multi-task Network to Detect Junctions in Retinal Vasculature</title><categories>eess.IV</categories><comments>MICCAI 2018 Camera Ready Version</comments><doi>10.1007/978-3-030-00934-2_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Junctions in the retinal vasculature are key points to be able to extract its
topology, but they vary in appearance, depending on vessel density, width and
branching/crossing angles. The complexity of junction patterns is usually
accompanied by a scarcity of labels, which discourages the usage of very deep
networks for their detection. We propose a multi-task network, generating
labels for vessel interior, centerline, edges and junction patterns, to provide
additional information to facilitate junction detection. After the initial
detection of potential junctions in junction-selective probability maps,
candidate locations are re-examined in centerline probability maps to verify if
they connect at least 3 branches. The experiments on the DRIVE and IOSTAR
showed that our method outperformed a recent study in which a popular deep
network was trained as a classifier to find junctions. Moreover, the proposed
approach is applicable to unseen datasets with the same degree of success,
after training it only once.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03182</identifier>
 <datestamp>2018-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03182</id><created>2018-06-06</created><authors><author><keyname>Zhang</keyname><forenames>Yujie</forenames></author><author><keyname>Ye</keyname><forenames>Wenjing</forenames></author></authors><title>Deep learning based inverse method for layout design</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Layout design with complex constraints is a challenging problem to solve due
to the non-uniqueness of the solution and the difficulties in incorporating the
constraints into the conventional optimization-based methods. In this paper, we
propose a design method based on the recently developed machine learning
technique, Variational Autoencoder (VAE). We utilize the learning capability of
the VAE to learn the constraints and the generative capability of the VAE to
generate design candidates that automatically satisfy all the constraints. As
such, no constraints need to be imposed during the design stage. In addition,
we show that the VAE network is also capable of learning the underlying physics
of the design problem, leading to an efficient design tool that does not need
any physical simulation once the network is constructed. We demonstrated the
performance of the method on two cases: inverse design of surface diffusion
induced morphology change and mask design for optical microlithography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03185</identifier>
 <datestamp>2018-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03185</id><created>2018-06-08</created><authors><author><keyname>Stoller</keyname><forenames>Daniel</forenames></author><author><keyname>Ewert</keyname><forenames>Sebastian</forenames></author><author><keyname>Dixon</keyname><forenames>Simon</forenames></author></authors><title>Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source
  Separation</title><categories>cs.SD eess.AS stat.ML</categories><comments>7 pages (1 for references), 4 figures, 3 tables. Appearing in the
  proceedings of the 19th International Society for Music Information Retrieval
  Conference (ISMIR 2018) (camera-ready version). Implementation available at
  https://github.com/f90/Wave-U-Net</comments><journal-ref>19th International Society for Music Information Retrieval
  Conference (ISMIR 2018)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models for audio source separation usually operate on the magnitude spectrum,
which ignores phase information and makes separation performance dependant on
hyper-parameters for the spectral front-end. Therefore, we investigate
end-to-end source separation in the time-domain, which allows modelling phase
information and avoids fixed spectral transformations. Due to high sampling
rates for audio, employing a long temporal input context on the sample level is
difficult, but required for high quality separation results because of
long-range temporal correlations. In this context, we propose the Wave-U-Net,
an adaptation of the U-Net to the one-dimensional time domain, which repeatedly
resamples feature maps to compute and combine features at different time
scales. We introduce further architectural improvements, including an output
layer that enforces source additivity, an upsampling technique and a
context-aware prediction framework to reduce output artifacts. Experiments for
singing voice separation indicate that our architecture yields a performance
comparable to a state-of-the-art spectrogram-based U-Net architecture, given
the same data. Finally, we reveal a problem with outliers in the currently used
SDR evaluation metrics and suggest reporting rank-based statistics to alleviate
this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03209</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03209</id><created>2018-06-08</created><updated>2018-06-11</updated><authors><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Chen</keyname><forenames>Jinkun</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>Analysis of Length Normalization in End-to-End Speaker Verification
  System</title><categories>eess.AS cs.SD</categories><comments>Accepted for Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical i-vectors and the latest end-to-end deep speaker embeddings are
the two representative categories of utterance-level representations in
automatic speaker verification systems. Traditionally, once i-vectors or deep
speaker embeddings are extracted, we rely on an extra length normalization step
to normalize the representations into unit-length hyperspace before back-end
modeling. In this paper, we explore how the neural network learns
length-normalized deep speaker embeddings in an end-to-end manner. To this end,
we add a length normalization layer followed by a scale layer before the output
layer of the common classification network. We conducted experiments on the
verification task of the Voxceleb1 dataset. The results show that integrating
this simple step in the end-to-end training pipeline significantly boosts the
performance of speaker verification. In the testing stage of our L2-normalized
end-to-end system, a simple inner-product can achieve the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03239</identifier>
 <datestamp>2018-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03239</id><created>2018-06-07</created><authors><author><keyname>Furat</keyname><forenames>Orkun</forenames></author><author><keyname>Lei&#xdf;ner</keyname><forenames>Thomas</forenames></author><author><keyname>Ditscherlein</keyname><forenames>Ralf</forenames></author><author><keyname>&#x160;ediv&#xfd;</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>Weber</keyname><forenames>Matthias</forenames></author><author><keyname>Bachmann</keyname><forenames>Kai</forenames></author><author><keyname>Gutzmer</keyname><forenames>Jens</forenames></author><author><keyname>Peuker</keyname><forenames>Urs</forenames></author><author><keyname>Schmidt</keyname><forenames>Volker</forenames></author></authors><title>Description of ore particles from XMT images, supported by SEM-based
  image analysis</title><categories>eess.IV cond-mat.mtrl-sci</categories><comments>19 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, 3D image data of ore particle systems is investigated. By
combining X-ray micro tomography (XMT) with scanning electron microscope (SEM)
based image analysis additional information about the mineralogical composition
from certain planar sections can be gained. For the analysis of tomographic
images of particle systems the extraction of single particles is essential.
This is performed with a marker-based watershed algorithm and a post-processing
step utilizing a neural network to reduce oversegmentation. The results are
validated by comparing the 3D particle-wise segmentation empirically with 2D
SEM images which have been obtained with a different imaging process and
segmentation algorithm. Finally, a stereological application is shown, in which
planar SEM images are embedded into the tomographic 3D image. This allows the
estimation of local X-ray attenuation coefficients, which are material-specific
quantities, in the entire tomographic image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03329</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03329</id><created>2018-06-08</created><updated>2018-12-29</updated><authors><author><keyname>Saavedra</keyname><forenames>Raphael</forenames></author><author><keyname>Tovar</keyname><forenames>Pedro</forenames></author><author><keyname>Amaral</keyname><forenames>Gustavo C.</forenames></author><author><keyname>Fanzeres</keyname><forenames>Bruno</forenames></author></authors><title>Full Optical Fiber Link Characterization with the BSS-Lasso</title><categories>eess.SP physics.ins-det</categories><comments>IEEE Transactions on Instrumentation and Measurement, 21 Dec. 2018</comments><doi>10.1109/TIM.2018.2884555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manipulation of the detected backscattered Rayleigh signal inside the
bandwidth of a frequency-swept optical sub-carrier propagating into an optical
fiber permits an efficient localization of faults through a Fourier operator.
When the bandwidth is restricted, analysis in the frequency domain can overcome
the spatial resolution limitation while also inducing a high-dimensional
problem. Introducing the Lasso as a signal processing technique paired with the
Baseband Subcarrier Sweep (BSS) framework allows for a methodology to
consistently evaluate fiber defects. In this work, a novel technique for
optical fiber monitoring within the BSS framework, hereinafter called the
BSS-Lasso, is proposed and tested in simulated and real-world environments,
taking into account both reflective and non-reflective events. The results show
that, for fiber links ranging from 2 to 15 km with up to 3 faults, over 80% of
faults are detected within a 50 m range, and indicate that the proposed
methodology significantly outperforms current state-of-the-art BSS-based
supervision techniques. Finally, the BSS-Lasso allows for precise, low-cost,
transmitter-embedded full characterization of optical fiber links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03400</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03400</id><created>2018-06-08</created><authors><author><keyname>Xie</keyname><forenames>Hong-Bo</forenames></author><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Shen</keyname><forenames>Qi</forenames></author><author><keyname>Liao</keyname><forenames>Sheng-Kai</forenames></author><author><keyname>Peng</keyname><forenames>Cheng-Zhi</forenames></author></authors><title>A 3.8 ps RMS time synchronization implemented in a 20 nm FPGA</title><categories>eess.SP</categories><comments>4 pages,5 figures.21st IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 3.8ps root mean square (RMS) time synchronization implemented in a 20nm
fabrication process ultrascale kintex Field Programmable Gate Array (FPGA) is
presented. The multichannel high-speed serial transceivers (e.g. GTH) play a
key role in a wide range of applications, such as the optical source for
quantum key distribution systems. However, owing to the independent clock
dividers existed in each transceiver, the random skew would appear among the
multiple channels every time the system powers up or resets. A self-phase
alignment method provided by Xilinx Corporation could reach a precision with 22
ps RMS and 100 ps maximum variation, which is far from meeting the demand of
applications with rate up to 2.5 Gbps. To implement a high-precision
intrachannel time synchronization, a protocol combined of a high-precision
time-to-digital converter (TDC) and a tunable phase interpolator (PI) is
presented. The TDC based on the carry8 primitive is applied to measure the
intrachannel skew with 40.7ps bin size. The embedded tunable PI in each GTH
channel has a theoretical step size of 3.125 ps. By tuning the PI in the
minimal step size, the final intrachannel time synchronization reaches a 3.8 ps
RMS precision and maximal variation 20 ps, much better than the self-phase
alignment method. Besides, a desirable time offset of every channel can be
implemented with a closed-loop control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03409</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03409</id><created>2018-06-09</created><updated>2018-12-07</updated><authors><author><keyname>Chen</keyname><forenames>Peng</forenames></author><author><keyname>Chen</keyname><forenames>Zhimin</forenames></author><author><keyname>Zhang</keyname><forenames>Xuan</forenames></author><author><keyname>Liu</keyname><forenames>Linxi</forenames></author></authors><title>Sparse Bayesian Learning-Based Direction Finding Method With Unknown
  Mutual Coupling Effect</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The imperfect array degrades the direction finding performance. In this
paper, we investigate the direction finding problem in uniform linear array
(ULA) system with unknown mutual coupling effect between antennas. By
exploiting the target sparsity in the spatial domain, sparse Bayesian learning
(SBL)-based model is proposed and converts the direction finding problem into a
sparse reconstruction problem. In the sparse-based model, the \emph{off-grid}
errors are introduced by discretizing the direction area into grids. Therefore,
an off-grid SBL model with mutual coupling vector is proposed to overcome both
the mutual coupling and the off-grid effect. With the distribution assumptions
of unknown parameters including the noise variance, the off-grid vector, the
received signals and the mutual coupling vector, a novel direction finding
method based on SBL with unknown mutual coupling effect named DFSMC is
proposed, where an expectation-maximum (EM)-based step is adopted by deriving
the estimation expressions for all the unknown parameters theoretically.
Simulation results show that the proposed DFSMC method can outperform
state-of-the-art direction finding methods significantly in the array system
with unknown mutual coupling effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03464</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03464</id><created>2018-06-09</created><updated>2018-12-11</updated><authors><author><keyname>Li</keyname><forenames>Yutian</forenames></author><author><keyname>Gao</keyname><forenames>Feng</forenames></author><author><keyname>Ou</keyname><forenames>Zhijian</forenames></author><author><keyname>Sun</keyname><forenames>Jiasong</forenames></author></authors><title>Angular Softmax Loss for End-to-end Speaker Verification</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end speaker verification systems have received increasing interests.
The traditional i-vector approach trains a generative model (basically a
factor-analysis model) to extract i-vectors as speaker embeddings. In contrast,
the end-to-end approach directly trains a discriminative model (often a neural
network) to learn discriminative speaker embeddings; a crucial component is the
training criterion. In this paper, we use angular softmax (A-softmax), which is
originally proposed for face verification, as the loss function for feature
learning in end-to-end speaker verification. By introducing margins between
classes into softmax loss, A-softmax can learn more discriminative features
than softmax loss and triplet loss, and at the same time, is easy and stable
for usage. We make two contributions in this work. 1) We introduce A-softmax
loss into end-to-end speaker verification and achieve significant EER
reductions. 2) We find that the combination of using A-softmax in training the
front-end and using PLDA in the back-end scoring further boosts the performance
of end-to-end systems under short utterance condition (short in both enrollment
and test). Experiments are conducted on part of $Fisher$ dataset and
demonstrate the improvements of using A-softmax.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03500</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03500</id><created>2018-06-09</created><authors><author><keyname>Zhang</keyname><forenames>Xiaoming</forenames></author><author><keyname>Zhou</keyname><forenames>Boran</forenames></author><author><keyname>Osborn</keyname><forenames>Thomas</forenames></author><author><keyname>Bartholmai</keyname><forenames>Brian</forenames></author><author><keyname>Kalra</keyname><forenames>Sanjay</forenames></author></authors><title>Lung ultrasound surface wave elastography for assessing instititial lung
  disease</title><categories>q-bio.TO eess.SP physics.med-ph</categories><comments>11 pages, 5 figures</comments><doi>10.1121/1.5101138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung ultrasound surface wave elastography (LUSWE) is a novel noninvasive
technique for measuring superficial lung tissue stiffness.The purpose of this
study was to translate LUSWE for assessing patients with interstitial lung
disease (ILD) and various connective diseases including systemic sclerosis
(SSc).In this study, LUSWE was used to measure the surface wave speed of lung
at 100 Hz, 150 Hz and 200 Hz through six intercostal lung spaces for 91
patients with ILD and 30 healthy control subjects. In addition, skin
viscoelasticity was measured at both forearms and upper arms for patients and
controls. The surface wave speeds of patients' lungs were significantly higher
than those of control subjects for the six intercostal spaces and the three
excitation frequencies. Patient skin elasticity and viscosity were
significantly higher than those of control subjects for the four locations on
the arm. In dividing ILD patients into two groups, ILD patients with SSc and
ILD patients without SSc, significant differences between each patient group
with the control group were found for both the lung and skin.No significant
differences were found between the two patients group, although there were some
differences at a few locations and at 100 Hz. LUSWE may be useful for assessing
ILD and SSc and screening early stage patients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03547</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03547</id><created>2018-06-09</created><authors><author><keyname>Ghods</keyname><forenames>Ramina</forenames></author><author><keyname>Lan</keyname><forenames>Andrew S.</forenames></author><author><keyname>Goldstein</keyname><forenames>Tom</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Linear Spectral Estimators and an Application to Phase Retrieval</title><categories>cs.IT eess.SP math.IT stat.ML</categories><comments>To appear at ICML 2018, extended version with supplementary material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase retrieval refers to the problem of recovering real- or complex-valued
vectors from magnitude measurements. The best-known algorithms for this problem
are iterative in nature and rely on so-called spectral initializers that
provide accurate initialization vectors. We propose a novel class of estimators
suitable for general nonlinear measurement systems, called linear spectral
estimators (LSPEs), which can be used to compute accurate initialization
vectors for phase retrieval problems. The proposed LSPEs not only provide
accurate initialization vectors for noisy phase retrieval systems with
structured or random measurement matrices, but also enable the derivation of
sharp and nonasymptotic mean-squared error bounds. We demonstrate the efficacy
of LSPEs on synthetic and real-world phase retrieval problems, and show that
our estimators significantly outperform existing methods for structured
measurement systems that arise in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03551</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03551</id><created>2018-06-09</created><authors><author><keyname>Lan</keyname><forenames>Andrew S.</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>An Estimation and Analysis Framework for the Rasch Model</title><categories>stat.ML cs.LG eess.SP</categories><comments>To be presented at ICML 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Rasch model is widely used for item response analysis in applications
ranging from recommender systems to psychology, education, and finance. While a
number of estimators have been proposed for the Rasch model over the last
decades, the available analytical performance guarantees are mostly asymptotic.
This paper provides a framework that relies on a novel linear minimum
mean-squared error (L-MMSE) estimator which enables an exact, nonasymptotic,
and closed-form analysis of the parameter estimation error under the Rasch
model. The proposed framework provides guidelines on the number of items and
responses required to attain low estimation errors in tests or surveys. We
furthermore demonstrate its efficacy on a number of real-world collaborative
filtering datasets, which reveals that the proposed L-MMSE estimator performs
on par with state-of-the-art nonlinear estimators in terms of predictive
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03564</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03564</id><created>2018-06-09</created><authors><author><keyname>Wang</keyname><forenames>Xinxin</forenames></author><author><keyname>Li</keyname><forenames>Feng</forenames></author><author><keyname>Liu</keyname><forenames>Shengquan</forenames></author><author><keyname>Miao</keyname><forenames>Peng</forenames></author><author><keyname>Zhang</keyname><forenames>Zhilei</forenames></author><author><keyname>Geng</keyname><forenames>Tianru</forenames></author><author><keyname>Zhou</keyname><forenames>Shuang</forenames></author><author><keyname>Jin</keyname><forenames>Ge</forenames></author></authors><title>Scanning Test System Prototype of p/sFEB for the ATLAS Phase-I sTGC
  Trigger Upgrade</title><categories>eess.SP physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Pad Front End Board (pFEB) and the Strip Front End Board (sFEB) are
developed for the ATLAS Phase-I sTGC Trigger Upgrade. The pFEB is used to to
gather and analyze pads trigger, and the sFEB is developed to accept the pad
trigger to define the regions-of-interest for strips readout. The performance
of p/sFEBs must be confirmed before they are mounted on the sTGC detector. We
will present the scanning test system prototype which is designed according to
the test requirements of the p/sFEB. In this test system prototype, a
simulation signal board is developed to generate different types of signal to
the p/sFEB. PC software and FPGA XADC cooperate to achieve the scan test of
analog parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03580</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03580</id><created>2018-06-10</created><authors><author><keyname>Li</keyname><forenames>Yuying</forenames></author><author><keyname>Faraji</keyname><forenames>Mehdi</forenames></author></authors><title>EREL Selection using Morphological Relation</title><categories>cs.CV eess.IV</categories><comments>6 pages, 8 figures, accepted to be published in International
  Conference on SMART MULTIMEDIA, 2018. The final authenticated publication is
  available online at https://doi.org/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work concentrates on Extremal Regions of Extremum Level (EREL)
selection. EREL is a recently proposed feature detector aiming at detecting
regions from a set of extremal regions. This is a branching problem derived
from segmentation of arterial wall boundaries from Intravascular Ultrasound
(IVUS) images. For each IVUS frame, a set of EREL regions is generated to
describe the luminal area of human coronary. Each EREL is then fitted by an
ellipse to represent the luminal border. The goal is to assign the most
appropriate EREL as the lumen. In this work, EREL selection carries out in two
rounds. In the first round, the pattern in a set of EREL regions is analyzed
and used to generate an approximate luminal region. Then, the two-dimensional
(2D) correlation coefficients are computed between this approximate region and
each EREL to keep the ones with tightest relevance. In the second round, a
compactness measure is calculated for each EREL and its fitted ellipse to
guarantee that the resulting EREL has not affected by the common artifacts such
as bifurcations, shadows, and side branches. We evaluated the selected ERELs in
terms of Hausdorff Distance (HD) and Jaccard Measure (JM) on the train and test
set of a publicly available dataset. The results show that our selection
strategy outperforms the current state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03583</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03583</id><created>2018-06-10</created><updated>2018-06-14</updated><authors><author><keyname>Yang</keyname><forenames>Ji</forenames></author><author><keyname>Tong</keyname><forenames>Lin</forenames></author><author><keyname>Faraji</keyname><forenames>Mehdi</forenames></author><author><keyname>Basu</keyname><forenames>Anup</forenames></author></authors><title>IVUS-Net: An Intravascular Ultrasound Segmentation Network</title><categories>stat.ML cs.LG cs.NE eess.IV</categories><comments>7 pages, 3 figures, accepted to be published in International
  Conference of Smart Multimedia. The final authenticated publication is
  available online at https://doi.org/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IntraVascular UltraSound (IVUS) is one of the most effective imaging
modalities that provides assistance to experts in order to diagnose and treat
cardiovascular diseases. We address a central problem in IVUS image analysis
with Fully Convolutional Network (FCN): automatically delineate the lumen and
media-adventitia borders in IVUS images, which is crucial to shorten the
diagnosis process or benefits a faster and more accurate 3D reconstruction of
the artery. Particularly, we propose an FCN architecture, called IVUS-Net,
followed by a post-processing contour extraction step, in order to
automatically segments the interior (lumen) and exterior (media-adventitia)
regions of the human arteries. We evaluated our IVUS-Net on the test set of a
standard publicly available dataset containing 326 IVUS B-mode images with two
measurements, namely Jaccard Measure (JM) and Hausdorff Distances (HD). The
evaluation result shows that IVUS-Net outperforms the state-of-the-art lumen
and media segmentation methods by 4% to 20% in terms of HD distance. IVUS-Net
performs well on images in the test set that contain a significant amount of
major artifacts such as bifurcations, shadows, and side branches that are not
common in the training set. Furthermore, using a modern GPU, IVUS-Net segments
each IVUS frame only in 0.15 seconds. The proposed work, to the best of our
knowledge, is the first deep learning based method for segmentation of both the
lumen and the media vessel walls in 20 MHz IVUS B-mode images that achieves the
best results without any manual intervention. Code is available at
https://github.com/Kulbear/ivus-segmentation-icsm2018
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03660</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03660</id><created>2018-06-10</created><authors><author><keyname>Lin</keyname><forenames>Jin</forenames></author><author><keyname>Liang</keyname><forenames>Fu-Tian</forenames></author><author><keyname>Xu</keyname><forenames>Yu</forenames></author><author><keyname>Sun</keyname><forenames>Li-Hua</forenames></author><author><keyname>Guo</keyname><forenames>Cheng</forenames></author><author><keyname>Liao</keyname><forenames>Sheng-Kai</forenames></author><author><keyname>Peng</keyname><forenames>Cheng-Zhi</forenames></author></authors><title>High Performance and Scalable AWG for Superconducting Quantum Computing</title><categories>eess.SP quant-ph</categories><comments>5 pages,9 figures.21st IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superconducting quantum computer is manufactured based on semiconductor
process which makes qubits integration possible. At the same time, this kind of
qubit exhibits high performance fidelity, de-coherence time, scalability and
requires a programmable arbitrary waveform generator (AWG). This paper presents
implementation of an AWG which composed of two gigabit samples per second
(GSPS) sampling rate, 16 bit vertical resolution digital to analog converters
(DACs). The AWG integrated with separate microwave devices onto a metal plate
for the scale-up consideration. A special waveform sequence output controller
is designed to realize seamless waveform switching and arbitrary waveform
generator. The jitter in multiple AWG channels is around 10ps, Integral
nonlinearity (INL) as well as differential nonlinearity (DNL) is about 2 LSB,
and the qubit performance of the de-coherence time (T2*) achieved 33% promotion
over that of a commercial 1 GSPS, 14 bit AWG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03678</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03678</id><created>2018-06-10</created><authors><author><keyname>Xu</keyname><forenames>Yu</forenames></author><author><keyname>Lin</keyname><forenames>Jin</forenames></author><author><keyname>Li</keyname><forenames>Yu-Huai</forenames></author><author><keyname>Dai</keyname><forenames>Hui</forenames></author><author><keyname>Liao</keyname><forenames>Sheng-Kai</forenames></author><author><keyname>Peng</keyname><forenames>Cheng-Zhi</forenames></author></authors><title>Technique of active phase stabilization for the interferometer with 128
  actively selectable paths</title><categories>eess.SP quant-ph</categories><comments>4 pages, 4 figures, 21st IEEE Real Time Conference</comments><doi>10.1109/TNS.2019.2921982</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variable-delay optical interferometer with 128 actively selectable delays
and a technique of active phase stabilization are innovatively designed and
applied for the first time in the experiment of round-robin differential phase
shift quantum key distribution (RRDPS-QKD). According to the RRDPS protocol,
larger number of delay channels in interferometer can ensure higher tolerance
of bit errors, eliminating the fundamental threshold of bit error rate of 11%
of traditional BB84 protocol. Considering that the implementation of RRDPS
protocol relys on the realizaiton of the interferometer, therefore, an
interferometer with 128 selectable delay paths is constructed and demands the
ability of fast switching at the rate of 10 kHz, which requires dynamic
stability of multiple paths. Thus, a specific designed phase stabilization
technique with closed real time feedback loop is introduced to guarantee the
high visibility of interferometer selections dynamically. The active phase
stabilization technique employs a phase modulator (PM) driven by a DAC to
adjust the relative phase between the two arms of the interferometer. By
monitoring photon counting rates of two Up-Conversion Detectors (UCD) at two
output ports of the interferometer, a Field Programmable Gate Array (FPGA)
calculates and finds the optimal code value for the DAC, maintaining a high
visibility of the interferometer every time a new light path is selected. The
visibility of most of the 128 interferometer selections can simultaneously be
maintained over 96% during the QKD, which lays the foundation for the RRDPS
experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03695</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03695</id><created>2018-06-10</created><authors><author><keyname>Faraji</keyname><forenames>Mehdi</forenames></author><author><keyname>Cheng</keyname><forenames>Irene</forenames></author><author><keyname>Naudin</keyname><forenames>Iris</forenames></author><author><keyname>Basu</keyname><forenames>Anup</forenames></author></authors><title>Segmentation of Arterial Walls in Intravascular Ultrasound
  Cross-Sectional Images Using Extremal Region Selection</title><categories>cs.CV eess.IV</categories><comments>15 pages, 5 figures, published in Elsevier Ultrasonics</comments><doi>10.1016/j.ultras.2017.11.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intravascular Ultrasound (IVUS) is an intra-operative imaging modality that
facilitates observing and appraising the vessel wall structure of the human
coronary arteries. Segmentation of arterial wall boundaries from the IVUS
images is not only crucial for quantitative analysis of the vessel walls and
plaque characteristics, but is also necessary for generating 3D reconstructed
models of the artery. The aim of this study is twofold. Firstly, we investigate
the feasibility of using a recently proposed region detector, namely Extremal
Region of Extremum Level (EREL) to delineate the luminal and media-adventitia
borders in IVUS frames acquired by 20 MHz probes. Secondly, we propose a region
selection strategy to label two ERELs as lumen and media based on the stability
of their textural information. We extensively evaluated our selection strategy
on the test set of a standard publicly available dataset containing 326 IVUS
B-mode images. We showed that in the best case, the average Hausdorff Distances
(HD) between the extracted ERELs and the actual lumen and media were $0.22$ mm
and $0.45$ mm, respectively. The results of our experiments revealed that our
selection strategy was able to segment the lumen with $\le 0.3$ mm HD to the
gold standard even though the images contained major artifacts such as
bifurcations, shadows, and side branches. Moreover, when there was no artifact,
our proposed method was able to delineate media-adventitia boundaries with
$0.31$ mm HD to the gold standard. Furthermore, our proposed segmentation
method runs in time that is linear in the number of pixels in each frame. Based
on the results of this work, by using a 20 MHz IVUS probe with controlled
pullback, not only can we now analyze the internal structure of human arteries
more accurately, but also segment each frame during the pullback procedure
because of the low run time of our proposed segmentation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03715</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03715</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Ahmed</keyname><forenames>Salah Addin</forenames></author><author><keyname>Chan</keyname><forenames>Kok Wai</forenames></author><author><keyname>Hoong</keyname><forenames>Mok Vee</forenames></author></authors><title>Smart GSM Based Home Automation System</title><categories>eess.SP</categories><comments>Conference on Systems Process and Control (ICSPC 2013) Page 306 _ 309</comments><doi>10.1109/SPC.2013.6735152</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This research work investigates the potential of Full Home Control, which is
the aim of the Home Automation Systems in near future. The analysis and
implementation of the home automation technology using Global System for Mobile
Communication (GSM) modem to control home appliances such as light, conditional
system, and security system via Short Message Service (SMS) text messages is
presented in this paper. The proposed research work is focused on the
functionality of the GSM protocol, which allows the user to control the target
system away from residential using the frequency bandwidths. The concept of
serial communication and AT-commands has been applied towards the development
of the smart GSM-based home automation system. Homeowners will be able to
receive feedback status of any home appliances under control whether switched
on or off remotely from their mobile phones. PIC16F887 microcontroller with the
integration of GSM provides the smart automated house system with the desired
baud rate of 9600 bps. The proposed prototype of GSM based home automation
system was implemented and tested with a maximum of four loads and shows the
accuracy of greater or equal 98%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03716</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03716</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Abigo</keyname><forenames>Mometo Jim</forenames></author><author><keyname>Hoong</keyname><forenames>Mok Vee</forenames></author></authors><title>Static Quantized Radix-2 FFT/IFFT Processor for Constraints Analysis</title><categories>eess.SP cs.AR</categories><journal-ref>International Journal of Electronics Taylor and Francis 2013, pp
  1-10</journal-ref><doi>10.1080/00207217.2013.780264</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This research work focuses on the design of a high-resolution fast Fourier
transform (FFT) /inverse fast Fourier transform (IFFT) processors for
constraints analysis purpose. Amongst the major setbacks associated with such
high resolution, FFT processors are the high power consumption resulting from
the structural complexity and computational inefficiency of floating-point
calculations. As such, a parallel pipelined architecture was proposed to
statically scale the resolution of the processor to suite adequate trade-off
constraints. The quantization was applied to provide an approximation to
address the finite word-length constraints of digital signal processing (DSP).
An optimum operating mode was proposed, based on the
signal-to-quantization-noise ratio (SQNR) as well as the statistical theory of
quantization, to minimize the tradeoff issues associated with selecting the
most application-efficient floating-point processing capability in contrast to
their resolution quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03721</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03721</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author></authors><title>VLSI Design Of Advanced Digital Filters</title><categories>eess.SP cs.AR</categories><comments>Academic Publishing 2013</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Cascaded Integrator Comb filters (CIC) find many applications in recent
electronic devices such as frequency selection functions in a digital radio or
modem and any filter structure that is required to efficiently process large
sample rate factor. These filters are normally located after the sigma-delta
modulator and have a regular structure. These types of filters do not require
multipliers and the coefficient storage unlike in the normal digital FIR and
IIR filters because of all filter coefficients are unity. Hence, it can be
efficiently implemented to operate at high speed. Hence, this book describes
the Very Large Scale Integration (VLSI) implementation of the CIC filters that
are suitable for high-performance audio applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03767</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03767</id><created>2018-06-10</created><authors><author><keyname>Sun</keyname><forenames>Li-Hua</forenames></author><author><keyname>Liang</keyname><forenames>Fu-Tian</forenames></author><author><keyname>Lin</keyname><forenames>Jin</forenames></author><author><keyname>Guo</keyname><forenames>Cheng</forenames></author><author><keyname>Xu</keyname><forenames>Yu</forenames></author><author><keyname>Liao</keyname><forenames>Sheng-Kai</forenames></author><author><keyname>Peng</keyname><forenames>Cheng-Zhi</forenames></author></authors><title>Scalable Self-Adaptive Synchronous Triggering System in Superconducting
  Quantum Computing</title><categories>eess.SP quant-ph</categories><comments>5 pages, 12 figures, IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superconducting quantum computers (SQC) can solve some specific problems
which are deeply believed to be intractable for classical computers. The
control and measurement of qubits can't go on without the synchronous operation
of digital-to-analog converters (DAC) array and the controlled sampling of
analog-to-digital converters (ADC). In this paper, a scalable self-adaptive
synchronous triggering system is proposed to ensure the synchronized operation
of multiple qubits. The skew of the control signal between different qubits is
less than 25 ps. After upgrading the clock design, the 250 MHz single-tone
phase noise of DAC has been increased about 15 dB. The phase noise of the 6.25
GHz qubit control signal has an improvement of about 6 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03811</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03811</id><created>2018-06-11</created><authors><author><keyname>Jiao</keyname><forenames>Shuming</forenames></author><author><keyname>Jin</keyname><forenames>Zhi</forenames></author><author><keyname>Chang</keyname><forenames>Chenliang</forenames></author><author><keyname>Zhou</keyname><forenames>Changyuan</forenames></author><author><keyname>Zou</keyname><forenames>Wenbin</forenames></author><author><keyname>Li</keyname><forenames>Xia</forenames></author></authors><title>Compression of phase-only holograms with JPEG standard and deep learning</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a critical issue to reduce the enormous amount of data in the
processing, storage and transmission of a hologram in digital format. In
photograph compression, the JPEG standard is commonly supported by almost every
system and device. It will be favorable if JPEG standard is applicable to
hologram compression, with advantages of universal compatibility. However, the
reconstructed image from a JPEG compressed hologram suffers from severe quality
degradation since some high frequency features in the hologram will be lost
during the compression process. In this work, we employ a deep convolutional
neural network to reduce the artifacts in a JPEG compressed hologram.
Simulation and experimental results reveal that our proposed &quot;JPEG + deep
learning&quot; hologram compression scheme can achieve satisfactory reconstruction
results for a computer-generated phase-only hologram after compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03828</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03828</id><created>2018-06-11</created><authors><author><keyname>Ep&#xe7;a&#xe7;an</keyname><forenames>Erdal</forenames></author><author><keyname>&#xc7;ilo&#x11f;lu</keyname><forenames>Tolga</forenames></author></authors><title>SVA Based Beamforming</title><categories>eess.SP</categories><comments>4 pages 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A frequency domain method is proposed to reduce the sidelobe level of a
uniformly weighted uniform linear array in direction-of-arrival estimation. The
development is based on the nonlinear method of spatially variant apodization
originally proposed for spectral analysis and synthetic aperture radar imagery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03929</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03929</id><created>2018-06-11</created><authors><author><keyname>Pratschner</keyname><forenames>Stefan</forenames></author><author><keyname>Tahir</keyname><forenames>Bashar</forenames></author><author><keyname>Marijanovic</keyname><forenames>Ljiljana</forenames></author><author><keyname>Mussbah</keyname><forenames>Mariam</forenames></author><author><keyname>Kirev</keyname><forenames>Kiril</forenames></author><author><keyname>Nissel</keyname><forenames>Ronald</forenames></author><author><keyname>Schwarz</keyname><forenames>Stefan</forenames></author><author><keyname>Rupp</keyname><forenames>Markus</forenames></author></authors><title>Versatile Mobile Communications Simulation: The Vienna 5G Link Level
  Simulator</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research and development of mobile communications systems require a detailed
analysis and evaluation of novel technologies to further enhance spectral
efficiency, connectivity and reliability. Due to the exponentially increasing
demand of mobile broadband data rates and challenging requirements for latency
and reliability, mobile communications specifications become increasingly
complex to support ever more sophisticated techniques. For this reason,
analytic analysis as well as measurement based investigations of link level
methods soon encounter feasibility limitations. Therefore, computer aided
numeric simulation is an important tool for investigation of wireless
communications standards and is indispensable for analysis and developing
future technologies. In this contribution, we introduce the Vienna 5G Link
Level Simulator, a Matlab-based link level simulation tool to facilitate
research and development of 5G and beyond mobile communications. Our simulator
enables standard compliant setups according to 4G Long Term Evolution, 5G new
radio and even beyond, making it a very flexible simulation tool. Offered under
an academic use license to fellow researchers it considerably enhances
reproducibility in wireless communications research. We give a brief overview
of our simulation platform and introduce unique features of our link level
simulator in more detail to outline its versatile functionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03958</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03958</id><created>2018-06-11</created><authors><author><keyname>Kulhandjian</keyname><forenames>Michel</forenames></author><author><keyname>D'Amours</keyname><forenames>Claude</forenames></author><author><keyname>Kulhandjian</keyname><forenames>Hovannes</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author><author><keyname>Pados</keyname><forenames>Dimitris A.</forenames></author><author><keyname>Khachatrian</keyname><forenames>Gurgen</forenames></author></authors><title>Fast Decoder for Overloaded Uniquely Decodable Synchronous CDMA</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing a fast decoder for antipodal uniquely
decodable (errorless) code sets for overloaded synchronous code-division
multiple access (CDMA) systems where the number of signals K_{max}^a is the
largest known for the given code length L. The proposed decoder is designed in
a such a way that the users can uniquely recover the information bits with a
very simple decoder, which uses only a few comparisons. Compared to
maximum-likelihood (ML) decoder, which has a high computational complexity for
even moderate code length, the proposed decoder has a much lower computational
complexity. Simulation results in terms of bit error rate (BER) demonstrate
that the performance of the proposed decoder only has a 1-2 dB degradation at
BER of 10^{-3} when compared to ML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03992</identifier>
 <datestamp>2018-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03992</id><created>2018-06-07</created><authors><author><keyname>Cherukara</keyname><forenames>Mathew J.</forenames></author><author><keyname>Nashed</keyname><forenames>Youssef S. G.</forenames></author><author><keyname>Harder</keyname><forenames>Ross J.</forenames></author></authors><title>Real-time coherent diffraction inversion using deep generative networks</title><categories>cs.CV cs.LG eess.IV</categories><journal-ref>Scientific Reports (2018) 8:16520</journal-ref><doi>10.1038/s41598-018-34525-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase retrieval, or the process of recovering phase information in reciprocal
space to reconstruct images from measured intensity alone, is the underlying
basis to a variety of imaging applications including coherent diffraction
imaging (CDI). Typical phase retrieval algorithms are iterative in nature, and
hence, are time-consuming and computationally expensive, precluding real-time
imaging. Furthermore, iterative phase retrieval algorithms struggle to converge
to the correct solution especially in the presence of strong phase structures.
In this work, we demonstrate the training and testing of CDI NN, a pair of deep
deconvolutional networks trained to predict structure and phase in real space
of a 2D object from its corresponding far-field diffraction intensities alone.
Once trained, CDI NN can invert a diffraction pattern to an image within a few
milliseconds of compute time on a standard desktop machine, opening the door to
real-time imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.03997</identifier>
 <datestamp>2019-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.03997</id><created>2018-06-07</created><authors><author><keyname>Sinha</keyname><forenames>Ayushi</forenames></author><author><keyname>Liu</keyname><forenames>Xingtong</forenames></author><author><keyname>Reiter</keyname><forenames>Austin</forenames></author><author><keyname>Ishii</keyname><forenames>Masaru</forenames></author><author><keyname>Hager</keyname><forenames>Gregory D.</forenames></author><author><keyname>Taylor</keyname><forenames>Russell H.</forenames></author></authors><title>Endoscopic navigation in the absence of CT imaging</title><categories>eess.IV cs.CV</categories><comments>8 pages, 3 figures, MICCAI 2018</comments><acm-class>G.3; I.4.m; J.3</acm-class><doi>10.1007/978-3-030-00937-3_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clinical examinations that involve endoscopic exploration of the nasal cavity
and sinuses often do not have a reference image to provide structural context
to the clinician. In this paper, we present a system for navigation during
clinical endoscopic exploration in the absence of computed tomography (CT)
scans by making use of shape statistics from past CT scans. Using a deformable
registration algorithm along with dense reconstructions from video, we show
that we are able to achieve submillimeter registrations in in-vivo clinical
data and are able to assign confidence to these registrations using confidence
criteria established using simulated data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04003</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04003</id><created>2018-06-11</created><updated>2019-02-19</updated><authors><author><keyname>Ripp</keyname><forenames>Christopher</forenames></author><author><keyname>Steinke</keyname><forenames>Florian</forenames></author></authors><title>Modeling Time-dependent CO$_2$ Intensities in Multi-modal Energy Systems
  with Storage</title><categories>eess.SP</categories><comments>This work has been submitted to the Elsevier Applied Energy for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CO$_2$ emission reduction and increasing volatile renewable energy generation
mandate stronger energy sector coupling and the use of energy storage. In such
multi-modal energy systems, it is challenging to determine the effect of an
individual player's consumption pattern onto overall CO$_2$ emissions. This,
however, is often important to evaluate the suitability of local CO$_2$
reduction measures. Due to renewables' volatility, the traditional approach of
using annual average CO$_2$ intensities per energy form is no longer accurate,
but the time of consumption should be considered. Moreover, CO$_2$ intensities
are highly coupled over time and different energy forms due to sector coupling
and energy storage. We introduce and compare two novel methods for computing
time-dependent CO$_2$ intensities, that address different objectives: the first
method determines CO$_2$ intensities of the energy system as is. The second
method analyzes how overall CO$_2$ emissions would change in response to
infinitesimal demand changes. Given a digital twin of the energy system in form
of a linear program, we show how to compute these sensitivities very
efficiently. We present the results of both methods for two simulated test
energy systems and discuss their different implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04021</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04021</id><created>2018-06-11</created><authors><author><keyname>Guo</keyname><forenames>Cheng</forenames></author><author><keyname>Liang</keyname><forenames>FuTian</forenames></author><author><keyname>Lin</keyname><forenames>Jin</forenames></author><author><keyname>Xu</keyname><forenames>Yu</forenames></author><author><keyname>Sun</keyname><forenames>LiHua</forenames></author><author><keyname>Liao</keyname><forenames>ShengKai</forenames></author><author><keyname>Peng</keyname><forenames>ChengZhi</forenames></author><author><keyname>Liu</keyname><forenames>WeiYue</forenames></author></authors><title>Control and Readout Software in Superconducting Quantum Computing</title><categories>eess.SP quant-ph</categories><comments>4 pages, 7 figures, 1 table</comments><doi>10.1109/TNS.2019.2920337</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital-to-analog converter (DAC) and analog-to-digital converter (ADC) as an
important part of the superconducting quantum computer are used to control and
readout the qubit states. The complexity of instrument manipulation increases
rapidly as the number of qubits grows. Low-speed data transmission,
imperfections of realistic instruments and coherent control of qubits are
gradually highlighted which have become the bottlenecks in scaling up the
number of qubits. To deal with the challenges, we present a solution in this
study. Based on client-server (C/S) model, we develop two servers called
Readout Server and Control Server for managing self-innovation digitizer,
arbitrary waveform generator (AWG) and ultra-precision DC source which enable
to implement physical experiments rapidly. Both Control Server and Readout
Server consist three parts: resource manager, waveform engine and communication
interface. The resource manager maps the resources of separate instruments to a
unified virtual instrument and automatically aligns the timing of waveform
channels. The waveform engine generates and processes the waveform for AWGs or
captures and analyzes the data from digitizers. The communication interface is
responsible for sending and receiving data in an efficient manner. We design a
simple data link protocol for digitizers and a multi-threaded communication
mechanism for AWGs. By using different network optimization strategies, both
data transmission speed of digitizers and AWGs reach hundreds of Mbps through a
single Gigabit-NIC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04053</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04053</id><created>2018-06-11</created><authors><author><keyname>Rodriguez</keyname><forenames>R.</forenames></author><author><keyname>Finger</keyname><forenames>R.</forenames></author><author><keyname>Mena</keyname><forenames>F. P.</forenames></author><author><keyname>Alvear</keyname><forenames>A.</forenames></author><author><keyname>Fuentes</keyname><forenames>R.</forenames></author><author><keyname>Khudchenko</keyname><forenames>A.</forenames></author><author><keyname>Hesper</keyname><forenames>R.</forenames></author><author><keyname>Baryshev</keyname><forenames>A. M.</forenames></author><author><keyname>Reyes</keyname><forenames>N.</forenames></author><author><keyname>Bronfman</keyname><forenames>L.</forenames></author></authors><title>Digital compensation of the side-band-rejection ratio in a fully analog
  2SB sub-millimeter receiver</title><categories>eess.SP</categories><journal-ref>A&amp;A 619, A153 (2018)</journal-ref><doi>10.1051/0004-6361/201732316</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In observational radio astronomy, sideband-separating receivers are
preferred, particularly under high atmospheric noise, which is usually the case
in the sub-millimeter range. However, obtaining a good rejection ratio between
the two sidebands is difficult since, unavoidably, imbalances in the different
analog components appear. We describe a method to correct these imbalances
without making any change in the analog part of the sideband-separating
receiver, specifically, keeping the intermediate-frequency hybrid in place.
This opens the possibility of implementing the method in any existing receiver.
We have built hardware to demonstrate the validity of the method and tested it
on a fully analog receiver operating between 600 and 720GHz. We have tested the
stability of calibration and performance vs time and after full resets of the
receiver. We have performed an error analysis to compare the digital
compensation in two configurations of analog receivers, with and without
intermediate frequency (IF) hybrid. An average compensated sideband rejection
ratio of 46dB is obtained. Degradation of the compensated sideband rejection
ratio on time and after several resets of the receiver is minimal. A receiver
with an IF hybrid is more robust to systematic errors. Moreover, we have shown
that the intrinsic random errors in calibration have the same impact for
configuration without IF hybrid and for a configuration with IF hybrid with
analog rejection ratio better than 10dB. Compensated rejection ratios above
40dB are obtained even in the presence of high analog rejection. The method is
robust allowing its use under normal operational conditions at any telescope.
We also demonstrate that a full analog receiver is more robust against
systematic errors. Finally, the error bars associated to the compensated
rejection ratio are almost independent of whether IF hybrid is present or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04070</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04070</id><created>2018-06-11</created><authors><author><keyname>Jian-min</keyname><forenames>Liu</forenames></author></authors><title>The Research of the Real-time Detection and Recognition of Targets in
  Streetscape Videos</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This study proposes a method for the real-time detection and recognition of
targets in streetscape videos. The proposed method is based on separation
confidence computation and scale synthesis optimization. We use the proposed
method to detect and recognize targets in streetscape videos with high frame
rates and high definition. Furthermore, we experimentally demonstrate that the
accuracy and robustness of our proposed method are superior to those of
conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04072</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04072</id><created>2018-06-11</created><updated>2019-06-13</updated><authors><author><keyname>Yazar</keyname><forenames>Ahmet</forenames></author><author><keyname>Arslan</keyname><forenames>H&#xfc;seyin</forenames></author></authors><title>Fairness-Aware Scheduling in Multi-Numerology Based 5G New Radio</title><categories>eess.SP</categories><comments>The extended and updated version of this work was published in
  EURASIP Journal on Wireless Communications and Networking (DOI:
  10.1186/s13638-019-1435-z)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-numerology waveform based 5G New Radio (NR) systems offer great
flexibility for different requirements of users and services. Providing
fairness between users is not an easy task due to inter-numerology interference
(INI) between multiple numerologies. This paper proposes two novel scheduling
algorithms to provide fairness for all users, especially at the edges of
numerologies. Signal-to-noise ratio (SIR) results for multi-numerology systems
are obtained through computer simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04096</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04096</id><created>2018-06-11</created><updated>2019-05-24</updated><authors><author><keyname>Roche</keyname><forenames>Fanny</forenames><affiliation>Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Grenoble, France</affiliation><affiliation>Arturia, Meylan, France</affiliation></author><author><keyname>Hueber</keyname><forenames>Thomas</forenames><affiliation>Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Grenoble, France</affiliation></author><author><keyname>Limier</keyname><forenames>Samuel</forenames><affiliation>Arturia, Meylan, France</affiliation></author><author><keyname>Girin</keyname><forenames>Laurent</forenames><affiliation>Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Grenoble, France</affiliation><affiliation>INRIA, Perception Team, Montbonnot, France</affiliation></author></authors><title>Autoencoders for music sound modeling: a comparison of linear, shallow,
  deep, recurrent and variational models</title><categories>eess.AS cs.SD</categories><comments>SMC 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This study investigates the use of non-linear unsupervised dimensionality
reduction techniques to compress a music dataset into a low-dimensional
representation which can be used in turn for the synthesis of new sounds. We
systematically compare (shallow) autoencoders (AEs), deep autoencoders (DAEs),
recurrent autoencoders (with Long Short-Term Memory cells -- LSTM-AEs) and
variational autoencoders (VAEs) with principal component analysis (PCA) for
representing the high-resolution short-term magnitude spectrum of a large and
dense dataset of music notes into a lower-dimensional vector (and then convert
it back to a magnitude spectrum used for sound resynthesis). Our experiments
were conducted on the publicly available multi-instrument and multi-pitch
database NSynth. Interestingly and contrary to the recent literature on image
processing, we can show that PCA systematically outperforms shallow AE. Only
deep and recurrent architectures (DAEs and LSTM-AEs) lead to a lower
reconstruction error. The optimization criterion in VAEs being the sum of the
reconstruction error and a regularization term, it naturally leads to a lower
reconstruction accuracy than DAEs but we show that VAEs are still able to
outperform PCA while providing a low-dimensional latent space with nice
&quot;usability&quot; properties. We also provide corresponding objective measures of
perceptual audio quality (PEMO-Q scores), which generally correlate well with
the reconstruction error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04139</identifier>
 <datestamp>2018-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04139</id><created>2018-06-11</created><updated>2018-09-26</updated><authors><author><keyname>Li</keyname><forenames>Yunzhe</forenames></author><author><keyname>Xue</keyname><forenames>Yujia</forenames></author><author><keyname>Tian</keyname><forenames>Lei</forenames></author></authors><title>Deep speckle correlation: a deep learning approach towards scalable
  imaging through scattering media</title><categories>eess.IV physics.optics</categories><journal-ref>Yunzhe Li, Yujia Xue, and Lei Tian, &quot;Deep speckle correlation: a
  deep learning approach toward scalable imaging through scattering media,&quot;
  Optica 5, 1181-1190 (2018)</journal-ref><doi>10.1364/OPTICA.5.001181</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging through scattering is an important, yet challenging problem.
Tremendous progress has been made by exploiting the deterministic input-output
&quot;transmission matrix&quot; for a fixed medium. However, this &quot;one-to-one&quot; mapping is
highly susceptible to speckle decorrelations - small perturbations to the
scattering medium lead to model errors and severe degradation of the imaging
performance. Our goal here is to develop a new framework that is highly
scalable to both medium perturbations and measurement requirement. To do so, we
propose a statistical &quot;one-to-all&quot; deep learning technique that encapsulates a
wide range of statistical variations for the model to be resilient to speckle
decorrelations. Specifically, we develop a convolutional neural network (CNN)
that is able to learn the statistical information contained in the speckle
intensity patterns captured on a set of diffusers having the same macroscopic
parameter. We then show for the first time, to the best of our knowledge, that
the trained CNN is able to generalize and make high-quality object predictions
through an entirely different set of diffusers of the same class. Our work
paves the way to a highly scalable deep learning approach for imaging through
scattering media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04183</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04183</id><created>2018-06-11</created><authors><author><keyname>Alaraifi</keyname><forenames>Surour</forenames></author><author><keyname>Djouadi</keyname><forenames>Seddik</forenames></author><author><keyname>El-Moursi</keyname><forenames>Mohamed</forenames></author></authors><title>Regions of Attraction Approximation Using Individual Invariance</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximating regions of attraction in nonlinear systems require extensive
computational and analytical efforts. In this paper, nonlinear vector fields
are recasted as sum of vectors where each individual vector is used to
construct an artificial system. The theoretical foundation is provided for a
theorem in individual invariance to relate regions of attraction of artificial
systems to the original vector field's region of attraction which leads to
significant simplification in approximating regions of attraction. Several
second order examples are used to demonstrate the effectiveness of this
theorem. It is also proposed to use this theorem for the transient stability
problem in power systems where an algorithm is presented to identify the
critical clearing time through sequences of function evaluations. The algorithm
is successfully applied on the 3-machine 9-bus system as well as the IEEE
39-bus New England system giving accurate and realistic estimations of the
critical clearing time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04219</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04219</id><created>2018-06-11</created><authors><author><keyname>Khorshid</keyname><forenames>Ahmed E.</forenames></author><author><keyname>Alquaydheb</keyname><forenames>Ibrahim N.</forenames></author><author><keyname>Eltawil</keyname><forenames>Ahmed M.</forenames></author><author><keyname>Kurdahi</keyname><forenames>Fadi J.</forenames></author></authors><title>Physical Multi-Layer Phantoms for Intra-Body Communications</title><categories>eess.SP</categories><msc-class>94A40, 94C99, 92C42</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents approaches to creating tissue mimicking materials that
can be used as phantoms for evaluating the performance of Body Area Networks
(BAN). The main goal of the paper is to describe a methodology to create a
repeatable experimental BAN platform that can be customized depending on the
BAN scenario under test. Comparisons between different material compositions
and percentages are shown, along with the resulting electrical properties of
each mixture over the frequency range of interest for intra-body
communications; 100 KHz to 100 MHz. Test results on a composite multi-layer
sample are presented confirming the efficacy of the proposed methodology. To
date, this is the first paper that provides guidance on how to decide on
concentration levels of ingredients, depending on the exact frequency range of
operation, and the desired matched electrical characteristics (conductivity vs.
permittivity), to create multi-layer phantoms for intra-body communication
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04223</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04223</id><created>2018-06-11</created><authors><author><keyname>Siljak</keyname><forenames>Harun</forenames></author></authors><title>Reversibility in space, time, and computation: the case of underwater
  acoustic communications</title><categories>nlin.CG cs.ET eess.SP</categories><comments>7 pages, RC 2018 Work in Progress paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time reversal of waves has been successfully used in communications, sensing
and imaging for decades. The application in underwater acoustic communications
is of our special interest, as it puts together a reversible process (allowing
a reversible software or hardware realisation) and a reversible medium
(allowing a reversible model of the environment). This work in progress report
addresses the issues of modelling, analysis and implementation of acoustic time
reversal from the reversible computation perspective. We show the potential of
using reversible cellular automata for modelling and quantification of
reversibility in the time reversal communication process. Then we present an
implementation of time reversal hardware based on reversible circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04278</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04278</id><created>2018-06-11</created><authors><author><keyname>Donahue</keyname><forenames>Chris</forenames></author><author><keyname>Mao</keyname><forenames>Huanru Henry</forenames></author><author><keyname>McAuley</keyname><forenames>Julian</forenames></author></authors><title>The NES Music Database: A multi-instrumental dataset with expressive
  performance attributes</title><categories>cs.SD cs.LG cs.NE eess.AS</categories><comments>Published as a conference paper at ISMIR 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing research on music generation focuses on composition, but often
ignores the expressive performance characteristics required for plausible
renditions of resultant pieces. In this paper, we introduce the Nintendo
Entertainment System Music Database (NES-MDB), a large corpus allowing for
separate examination of the tasks of composition and performance. NES-MDB
contains thousands of multi-instrumental songs composed for playback by the
compositionally-constrained NES audio synthesizer. For each song, the dataset
contains a musical score for four instrument voices as well as expressive
attributes for the dynamics and timbre of each voice. Unlike datasets comprised
of General MIDI files, NES-MDB includes all of the information needed to render
exact acoustic performances of the original compositions. Alongside the
dataset, we provide a tool that renders generated compositions as NES-style
audio by emulating the device's audio processor. Additionally, we establish
baselines for the tasks of composition, which consists of learning the
semantics of composing for the NES synthesizer, and performance, which involves
finding a mapping between a composition and realistic expressive attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04368</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04368</id><created>2018-06-12</created><authors><author><keyname>Rackerseder</keyname><forenames>Julia</forenames></author><author><keyname>Baust</keyname><forenames>Maximilian</forenames></author><author><keyname>G&#xf6;bl</keyname><forenames>R&#xfc;diger</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Hennersperger</keyname><forenames>Christoph</forenames></author></authors><title>Initialize globally before acting locally: Enabling Landmark-free 3D US
  to MRI Registration</title><categories>eess.IV cs.CV</categories><comments>This is a pre-print of an article published in the Proceedings of the
  21st International Conference on Medical Image Computing and Computer
  Assisted Interventions (MICCAI), Granada, Spain, September 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Registration of partial-view 3D US volumes with MRI data is influenced by
initialization. The standard of practice is using extrinsic or intrinsic
landmarks, which can be very tedious to obtain. To overcome the limitations of
registration initialization, we present a novel approach that is based on
Euclidean distance maps derived from easily obtainable coarse segmentations. We
evaluate our approach quantitatively on the publicly available RESECT dataset
and show that it is robust regarding overlap of target area and initial
position. Furthermore, our method provides initializations that are suitable
for state-of-the-art nonlinear, deformable image registration algorithm's
capture ranges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04374</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04374</id><created>2018-06-12</created><updated>2020-01-29</updated><authors><author><keyname>McCann</keyname><forenames>Michael T.</forenames></author><author><keyname>Andrearczyk</keyname><forenames>Vincent</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author><author><keyname>Depeursinge</keyname><forenames>Adrien</forenames></author></authors><title>Fast Rotational Sparse Coding</title><categories>eess.IV cs.CV</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm for rotational sparse coding along with an efficient
implementation using steerability. Sparse coding (also called dictionary
learning) is an important technique in image processing, useful in inverse
problems, compression, and analysis; however, the usual formulation fails to
capture an important aspect of the structure of images: images are formed from
building blocks, e.g., edges, lines, or points, that appear at different
locations, orientations, and scales. The sparse coding problem can be
reformulated to explicitly account for these transforms, at the cost of
increased computation. In this work, we propose an algorithm for a rotational
version of sparse coding that is based on K-SVD with additional rotation
operations. We then propose a method to accelerate these rotations by learning
the dictionary in a steerable basis. Our experiments on patch coding and
texture classification demonstrate that the proposed algorithm is fast enough
for practical use and compares favorably to standard sparse coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04558</identifier>
 <datestamp>2019-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04558</id><created>2018-06-12</created><updated>2019-01-02</updated><authors><author><keyname>Jia</keyname><forenames>Ye</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Shen</keyname><forenames>Jonathan</forenames></author><author><keyname>Ren</keyname><forenames>Fei</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Pang</keyname><forenames>Ruoming</forenames></author><author><keyname>Moreno</keyname><forenames>Ignacio Lopez</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author></authors><title>Transfer Learning from Speaker Verification to Multispeaker
  Text-To-Speech Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>NeurIPS 2018</comments><journal-ref>Advances in Neural Information Processing Systems 31 (2018),
  4485-4495</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a neural network-based system for text-to-speech (TTS) synthesis
that is able to generate speech audio in the voice of many different speakers,
including those unseen during training. Our system consists of three
independently trained components: (1) a speaker encoder network, trained on a
speaker verification task using an independent dataset of noisy speech from
thousands of speakers without transcripts, to generate a fixed-dimensional
embedding vector from seconds of reference speech from a target speaker; (2) a
sequence-to-sequence synthesis network based on Tacotron 2, which generates a
mel spectrogram from text, conditioned on the speaker embedding; (3) an
auto-regressive WaveNet-based vocoder that converts the mel spectrogram into a
sequence of time domain waveform samples. We demonstrate that the proposed
model is able to transfer the knowledge of speaker variability learned by the
discriminatively-trained speaker encoder to the new task, and is able to
synthesize natural speech from speakers that were not seen during training. We
quantify the importance of training the speaker encoder on a large and diverse
speaker set in order to obtain the best generalization performance. Finally, we
show that randomly sampled speaker embeddings can be used to synthesize speech
in the voice of novel speakers dissimilar from those used in training,
indicating that the model has learned a high quality speaker representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04561</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04561</id><created>2018-06-12</created><authors><author><keyname>Sim&#xf5;es</keyname><forenames>Miguel</forenames></author><author><keyname>Bioucas-Dias</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Almeida</keyname><forenames>Luis B.</forenames></author></authors><title>An Extension of Averaged-Operator-Based Algorithms</title><categories>math.OC cs.CV eess.SP stat.ML</categories><comments>26th Eur. Signal Process. Conf. (EUSIPCO 2018), accepted. 5 pages, 1
  figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many of the algorithms used to solve minimization problems with
sparsity-inducing regularizers are generic in the sense that they do not take
into account the sparsity of the solution in any particular way. However,
algorithms known as semismooth Newton are able to take advantage of this
sparsity to accelerate their convergence. We show how to extend these
algorithms in different directions, and study the convergence of the resulting
algorithms by showing that they are a particular case of an extension of the
well-known Krasnosel'ski\u{\i}--Mann scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04568</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04568</id><created>2018-06-09</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author></authors><title>On-Chip Implementation of Cascaded Integrator Comb filters (CIC) for DSP
  applications</title><categories>eess.SP</categories><journal-ref>Research Student Seminar SPS05. Faculty of Engineering, National
  University of Malaysia, pp. 97-102, 2005</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents the design of CIC filters based on a low-pass filter for
reducing the sampling rate, also known as decimation process. The targeted
application for the filter is in the analog to digital conversion (ADC).The CIC
is chosen because of its attractive property of both low power and complexity
since it does not require multipliers. Simulink toolbox available in Matlab
software is used to design and simulate the functionality of the CIC filter.
This paper also shows how sample frequency is decreased by CIC filter and it
can be used to give enough stop-band attenuation to prevent aliasing after
decimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04570</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04570</id><created>2018-06-09</created><authors><author><keyname>Algnabi</keyname><forenames>Yazan Samir</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author><author><keyname>Islam</keyname><forenames>Md Shabiul</forenames></author></authors><title>FPGA Implementation of pipeline Digit-Slicing Multiplier-Less Radix 2
  power of 2 DIF SDF Butterfly for Fourier Transform Structure</title><categories>eess.SP cs.AR</categories><comments>European Conference on Antennas and Propagation (EUCAP2011). Pp 4168-
  4172</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The need for wireless communication has driven the communication systems to
high performance. However, the main bottleneck that affects the communication
capability is the Fast Fourier Transform (FFT), which is the core of most
modulators. This paper presents FPGA implementation of pipeline digit-slicing
multiplier-less radix 22 DIF (Decimation In Frequency) SDF (single path delay
feedback) butterfly for FFT structure. The approach is taken, in order to
reduce computation complexity in butterfly multiplier, the digit-slicing
multiplier-less technique was utilized in the critical path of pipeline
Radix-22 DIF SDF FFT structure. The proposed design focused on the trade-off
between the speed and active silicon area for the chip implementation. The
multiplier input data was sliced into four blocks each one with four bits to
process at the same time in parallel. The new architecture was investigated and
simulated with MATLAB software. The Verilog HDL code in Xilinx ISE environment
was derived to describe the FFT Butterfly functionality and was downloaded to
Virtex II FPGA board. Consequently, the Virtex-II FG456 Proto board was used to
implement and test the design on the real hardware. As a result, from the
findings, the synthesis report indicates the maximum clock frequency of 555.75
MHz with the total equivalent gate count of 32,146 is a marked and significant
improvement over Radix 22 DIF SDF FFT butterfly. In comparison with the
conventional butterfly architecture design which can only run at a maximum
clock frequency of 200.102 MHz and the conventional multiplier can only run at
a maximum clock frequency of 221.140 MHz, the proposed system exhibits better
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04572</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04572</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Jim</keyname><forenames>Memtode</forenames></author><author><keyname>hong</keyname><forenames>Mok Vee</forenames></author></authors><title>Characteristic Analysis of 1024-Point Quantized Radix-2 FFT/IFFT
  Processor</title><categories>eess.SP cs.AR</categories><comments>ICSE2012 Proc.International Conference on Semiconductor Electronics
  (ICSE-2012). Pp 664-668.ISBN: 978-1-4673-2395-6</comments><doi>10.1109/SMElec.2012.6417231</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The precise analysis and accurate measurement of harmonic provides a reliable
scientific industrial application. However, the high-performance DSP processor
is the important method of electrical harmonic analysis. Hence, in this
research work, the effort was taken to design a novel high-resolution single
1024-point fast Fourier transform (FFT) and inverse fast Fourier transform
(IFFT) processors for improvement of the harmonic measurement techniques.
Meanwhile, the project is started with design and simulation to demonstrate the
benefit that is achieved by the proposed 1024-point FFT/IFFT processor. The
pipelined structure is incorporated in order to enhance the system efficiency.
As such, a pipelined architecture was proposed to statically scale the
resolution of the processor to suite adequate trade-off constraints. The
proposed FFT makes use of programmable fixed-point/floating-point to realize
higher precision FFT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04573</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04573</id><created>2018-06-10</created><authors><author><keyname>Algnabi</keyname><forenames>Yazan Samir</forenames></author><author><keyname>Aldaamee</keyname><forenames>Furat A.</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author></authors><title>Novel Architecture of Pipeline Radix 2 power of 2 SDF FFT Based on
  Digit-Slicing Technique</title><categories>eess.SP cs.AR</categories><comments>ICSE2012 Proc.International Conference on Semiconductor Electronics
  (ICSE-2012). Pp 470-474. ISBN: 978-1-4673-2395-6. arXiv admin note: text
  overlap with arXiv:1806.04570</comments><doi>10.1109/SMElec.2012.6417188</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The prevalent need for very high-speed digital signals processing in wireless
communications has driven the communications system to high-performance levels.
The objective of this paper is to propose a novel structure for efficient
implementation for the Fast Fourier Transform (FFT) processor to meet the
requirement for high-speed wireless communication system standards. Based on
the algorithm, architecture analysis, the design of pipeline Radix 2power of 2
SDF FFT processor based on digit-slicing Multiplier-Less is proposed.
Furthermore, this paper proposed an optimal constant multiplication arithmetic
design to multiply a fixed point input selectively by one of the several
present twiddle factor constants. The proposed architecture was simulated using
MATLAB software and the Field Programmable Gate Array (FPGA) Virtex 4 was
targeted to synthesis the proposed architecture. The design was tested in real
hardware of TLA5201 logic analyzer and the ISE synthesis report results the
high speed of 669.277 MHz with the total equivalent gate count of 14,854.
Meanwhile, It can be found as significant improvement over Radix 22 DIF SDF FFT
processor and can be concluded that the proposed pipeline Radix 22 DIF SDF FFT
processor based on digit-slicing multiplier-less is an enable in solving
problems that affect the most high-speed wireless communication systems
capability in FFT and possesses huge potentials for future related works and
research areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04574</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04574</id><created>2018-06-10</created><authors><author><keyname>Garidi</keyname><forenames>Waleed Ahmed Al</forenames></author><author><keyname>Sahar</keyname><forenames>Norsuzlin Bt Mohd</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author></authors><title>Planar Dipole Antenna Design At 1800MHz Band Using Different Feeding
  Methods For GSM Application</title><categories>eess.SP</categories><comments>Proc.International Conference on Semiconductor Electronics
  (ICSE-2012). Pp 560-564. ISBN: 978-1-4673-2395-6</comments><doi>10.1109/SMElec.2012.6417208</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This research work focuses on the design and simulation of a planar dipole
antenna for 1800MHZ Band for Global System Mobile GSM application using
Computer Software Technology CST studio software. The antenna is structured on
a fire resistance FR4 substrate with a relative constant of 4.3 S/m. Two types
of feeding configuration are designed to feed the antenna in order to match 50
ohm transmission lines which are via-hole integrated balun and quarter
wavelength open stub. The via-hole is capable to provide maximum return loss of
25dB, bandwidth of 18.4 percent and the voltage standing wave ratio (VSWR) of
1.116 V at optimum dimension of length 59mm and width 4mm, the bandwidth is
improved 25 percent to 30 percent by extending the width of the antenna 8 mm to
10 mm followed by deterioration of return loss value to 15dB. While the open
stub at length of 67 mm, the width of 6 mm and height 1.6mm will provide max
return loss of 47.88dB and bandwidth of 17 percent with VSWR 1.008 less than 2.
The way that the antenna substrate has influenced the performance of the
antenna. The lower relative constant will result in the higher return lows,
narrower bandwidth and better radiation pattern in trade-off the resonant
length Via-hole and then the quarter wave open stub are most convenient for
practical implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04576</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04576</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Alpha</keyname><forenames>Amirrize</forenames></author><author><keyname>Mok</keyname><forenames>VH</forenames></author></authors><title>Smart Novel Computer-based Analytical Tool for Image Forgery
  Authentication</title><categories>eess.IV cs.CV</categories><comments>Circuit and Systems (CAS) Conference. Pp.120-125. ISBN:
  978-1-4673-3117</comments><doi>10.1109/ICCircuitsAndSystems.2012.6408276</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents an integration of image forgery detection with image
facial recognition using black propagation neural network (BPNN). We observed
that facial image recognition by itself will always give a matching output or
closest possible output image for every input image irrespective of the
authenticity or otherwise not of the testing input image. Based on this, we are
proposing the combination of the blind but powerful automation image forgery
detection for entire input images for the BPNN recognition program. Hence, an
input image must first be authenticated before being fed into the recognition
program. Thus, an image security identification and authentication requirement,
any image that fails the authentication/verification stage are not to be used
as an input/test image. In addition, the universal smart GUI tool is proposed
and designed to perform image forgery detection with the high accuracy of 2%
error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04583</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04583</id><created>2018-05-29</created><authors><author><keyname>Wang</keyname><forenames>Haichao</forenames></author><author><keyname>Wang</keyname><forenames>Jinlong</forenames></author><author><keyname>Chen</keyname><forenames>Jin</forenames></author><author><keyname>Gong</keyname><forenames>Yuping</forenames></author><author><keyname>Ding</keyname><forenames>Guoru</forenames></author></authors><title>Network-Connected UAV Communications: Potentials and Challenges</title><categories>cs.NI eess.SP</categories><journal-ref>China Communications, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article explores the use of network-connected unmanned aerial vehicle
(UAV) communications as a compelling solution to achieve high-rate information
transmission and support ultra-reliable UAV remote command and control. We
first discuss the use cases of UAVs and the resulting communication
requirements, accompanied with a flexible architecture for network-connected
UAV communications. Then, the signal transmission and interference
characteristics are theoretically analyzed, and subsequently we highlight the
design and optimization considerations, including antenna design,
non-orthogonal multiple access communications, as well as network selection and
association optimization. Finally, case studies are provided to show the
feasibility of network-connected UAV communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04588</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04588</id><created>2018-06-10</created><authors><author><keyname>Esswie</keyname><forenames>Ali A.</forenames></author><author><keyname>Pedersen</keyname><forenames>Klaus I.</forenames></author></authors><title>Multi-User Preemptive Scheduling for Critical Low Latency Communications
  in 5G Networks</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G new radio is envisioned to support three major service classes: enhanced
mobile broadband (eMBB), ultra-reliable low-latency communications (URLLC), and
massive machine type communications. Emerging URLLC services require up to one
millisecond of communication latency with 99.999% success probability. Though,
there is a fundamental trade-off between system spectral efficiency (SE) and
achievable latency. This calls for novel scheduling protocols which
cross-optimize system performance on user-centric; instead of network-centric
basis. In this paper, we develop a joint multi-user preemptive scheduling
strategy to simultaneously cross-optimize system SE and URLLC latency. At each
scheduling opportunity, available URLLC traffic is always given higher
priority. When sporadic URLLC traffic appears during a transmission time
interval (TTI), proposed scheduler seeks for fitting the URLLC-eMBB traffic in
a multi-user transmission. If the available spatial degrees of freedom are
limited within a TTI, the URLLC traffic instantly overwrites part of the
ongoing eMBB transmissions to satisfy the URLLC latency requirements, at the
expense of minimal eMBB throughput loss. Extensive dynamic system level
simulations show that proposed scheduler provides significant performance gain
in terms of eMBB SE and URLLC latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04589</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04589</id><created>2018-06-08</created><updated>2018-07-17</updated><authors><author><keyname>Zhou</keyname><forenames>Fuhui</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Hu</keyname><forenames>Rose Qingyang</forenames></author><author><keyname>Qian</keyname><forenames>Yi</forenames></author></authors><title>Computation Rate Maximization in UAV-Enabled Wireless Powered
  Mobile-Edge Computing Systems</title><categories>eess.SP cs.CE cs.IT cs.NI math.IT</categories><comments>This paper has been accepted by IEEE JSAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile edge computing (MEC) and wireless power transfer (WPT) are two
promising techniques to enhance the computation capability and to prolong the
operational time of low-power wireless devices that are ubiquitous in Internet
of Things. However, the computation performance and the harvested energy are
significantly impacted by the severe propagation loss. In order to address this
issue, an unmanned aerial vehicle (UAV)-enabled MEC wireless powered system is
studied in this paper. The computation rate maximization problems in a
UAV-enabled MEC wireless powered system are investigated under both partial and
binary computation offloading modes, subject to the energy harvesting causal
constraint and the UAV's speed constraint. These problems are non-convex and
challenging to solve. A two-stage algorithm and a three-stage alternative
algorithm are respectively proposed for solving the formulated problems. The
closed-form expressions for the optimal central processing unit frequencies,
user offloading time, and user transmit power are derived. The optimal
selection scheme on whether users choose to locally compute or offload
computation tasks is proposed for the binary computation offloading mode.
Simulation results show that our proposed resource allocation schemes
outperforms other benchmark schemes. The results also demonstrate that the
proposed schemes converge fast and have low computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04596</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04596</id><created>2018-06-12</created><updated>2019-08-14</updated><authors><author><keyname>Abdulaziz</keyname><forenames>Abdullah</forenames></author><author><keyname>Dabbech</keyname><forenames>Arwa</forenames></author><author><keyname>Wiaux</keyname><forenames>Yves</forenames></author></authors><title>Wideband Super-resolution Imaging in Radio Interferometry via Low
  Rankness and Joint Average Sparsity Models (HyperSARA)</title><categories>eess.IV astro-ph.IM eess.SP</categories><journal-ref>MNRAS, 08/2019</journal-ref><doi>10.1093/mnras/stz2117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach within the versatile framework of convex
optimization to solve the radio-interferometric wideband imaging problem. Our
approach, dubbed HyperSARA, solves a sequence of weighted nuclear norm and l21
minimization problems promoting low rankness and joint average sparsity of the
wideband model cube. On the one hand, enforcing low rankness enhances the
overall resolution of the reconstructed model cube by exploiting the
correlation between the different channels. On the other hand, promoting joint
average sparsity improves the overall sensitivity by rejecting artefacts
present on the different channels. An adaptive Preconditioned Primal-Dual
algorithm is adopted to solve the minimization problem. The algorithmic
structure is highly scalable to large data sets and allows for imaging in the
presence of unknown noise levels and calibration errors. We showcase the
superior performance of the proposed approach, reflected in high-resolution
images on simulations and real VLA observations with respect to single channel
imaging and the CLEAN-based wideband imaging algorithm in the WSCLEAN software.
Our MATLAB code is available online on GITHUB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04597</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04597</id><created>2018-06-12</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Gao</keyname><forenames>Zhifan</forenames></author><author><keyname>Ni</keyname><forenames>Hao</forenames></author><author><keyname>Angelini</keyname><forenames>Elsa</forenames></author><author><keyname>Mohiaddin</keyname><forenames>Raad</forenames></author><author><keyname>Wong</keyname><forenames>Tom</forenames></author><author><keyname>Zhang</keyname><forenames>Yanping</forenames></author><author><keyname>Du</keyname><forenames>Xiuquan</forenames></author><author><keyname>Zhang</keyname><forenames>Heye</forenames></author><author><keyname>Keegan</keyname><forenames>Jennifer</forenames></author><author><keyname>Firmin</keyname><forenames>David</forenames></author></authors><title>Multiview Two-Task Recursive Attention Model for Left Atrium and Atrial
  Scars Segmentation</title><categories>cs.CV eess.IV</categories><comments>8 pages, 4 figures, accepted by MICCAI 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Late Gadolinium Enhanced Cardiac MRI (LGE-CMRI) for detecting atrial scars in
atrial fibrillation (AF) patients has recently emerged as a promising technique
to stratify patients, guide ablation therapy and predict treatment success.
Visualisation and quantification of scar tissues require a segmentation of both
the left atrium (LA) and the high intensity scar regions from LGE-CMRI images.
These two segmentation tasks are challenging due to the cancelling of healthy
tissue signal, low signal-to-noise ratio and often limited image quality in
these patients. Most approaches require manual supervision and/or a second
bright-blood MRI acquisition for anatomical segmentation. Segmenting both the
LA anatomy and the scar tissues automatically from a single LGE-CMRI
acquisition is highly in demand. In this study, we proposed a novel fully
automated multiview two-task (MVTT) recursive attention model working directly
on LGE-CMRI images that combines a sequential learning and a dilated residual
learning to segment the LA (including attached pulmonary veins) and delineate
the atrial scars simultaneously via an innovative attention model. Compared to
other state-of-the-art methods, the proposed MVTT achieves compelling
improvement, enabling to generate a patient-specific anatomical and atrial scar
assessment model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04627</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04627</id><created>2018-05-22</created><authors><author><keyname>Esmaeilzadeh</keyname><forenames>Soheil</forenames></author><author><keyname>Khebzegga</keyname><forenames>Ouassim</forenames></author><author><keyname>Moradshahi</keyname><forenames>Mehrad</forenames></author></authors><title>Clinical Parameters Prediction for Gait Disorder Recognition</title><categories>eess.IV cs.CV</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being able to predict clinical parameters in order to diagnose gait disorders
in a patient is of great value in planning treatments. It is known that
\textit{decision parameters} such as cadence, step length, and walking speed
are critical in the diagnosis of gait disorders in patients. This project aims
to predict the decision parameters using two ways and afterwards giving advice
on whether a patient needs treatment or not. In one way, we use clinically
measured parameters such as Ankle Dorsiflexion, age, walking speed, step
length, stride length, weight over height squared (BMI) and etc. to predict the
decision parameters. In a second way, we use videos recorded from patient's
walking tests in a clinic in order to extract the coordinates of the joints of
the patient over time and predict the decision parameters. Finally, having the
decision parameters we pre-classify gait disorder intensity of a patient and as
the result make decisions on whether a patient needs treatment or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04674</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04674</id><created>2018-06-12</created><updated>2019-08-20</updated><authors><author><keyname>Bertrand</keyname><forenames>Nicholas P.</forenames></author><author><keyname>Charles</keyname><forenames>Adam S.</forenames></author><author><keyname>Lee</keyname><forenames>John</forenames></author><author><keyname>Dunn</keyname><forenames>Pavel B.</forenames></author><author><keyname>Rozell</keyname><forenames>Christopher J.</forenames></author></authors><title>Efficient Tracking of Sparse Signals via an Earth Mover's Distance
  Dynamics Regularizer</title><categories>eess.SP</categories><comments>5 pages, 4 figures, submitted manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tracking algorithms such as the Kalman filter aim to improve inference
performance by leveraging the temporal dynamics in streaming observations.
However, the tracking regularizers are often based on the $\ell_p$-norm which
cannot account for important geometrical relationships between neighboring
signal elements. We propose a practical approach to using the earth mover's
distance (EMD) via the earth mover's distance dynamic filtering (EMD-DF)
algorithm for causally tracking time-varying sparse signals when there is a
natural geometry to the coefficient space that should be respected (e.g.,
meaningful ordering). Specifically, this paper presents a new Beckmann
formulation that dramatically reduces computational complexity, as well as an
evaluation of the performance and complexity of the proposed approach in
imaging and frequency tracking applications with real and simulated
neurophysiology data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04699</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04699</id><created>2018-06-12</created><authors><author><keyname>Iqbal</keyname><forenames>Turab</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author></authors><title>Capsule Routing for Sound Event Detection</title><categories>cs.SD eess.AS</categories><comments>Paper accepted for 26th European Signal Processing Conference
  (EUSIPCO 2018)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The detection of acoustic scenes is a challenging problem in which
environmental sound events must be detected from a given audio signal. This
includes classifying the events as well as estimating their onset and offset
times. We approach this problem with a neural network architecture that uses
the recently-proposed capsule routing mechanism. A capsule is a group of
activation units representing a set of properties for an entity of interest,
and the purpose of routing is to identify part-whole relationships between
capsules. That is, a capsule in one layer is assumed to belong to a capsule in
the layer above in terms of the entity being represented. Using capsule
routing, we wish to train a network that can learn global coherence implicitly,
thereby improving generalization performance. Our proposed method is evaluated
on Task 4 of the DCASE 2017 challenge. Results show that classification
performance is state-of-the-art, achieving an F-score of 58.6%. In addition,
overfitting is reduced considerably compared to other architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04702</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04702</id><created>2018-05-24</created><authors><author><keyname>Soeffker</keyname><forenames>Philip</forenames></author><author><keyname>Block</keyname><forenames>Dimitri</forenames></author><author><keyname>Wiebusch</keyname><forenames>Nico</forenames></author><author><keyname>Meier</keyname><forenames>Uwe</forenames></author></authors><title>Resource Allocation for a Wireless Coexistence Management System Based
  on Reinforcement Learning</title><categories>eess.SP cs.LG cs.NI stat.ML</categories><comments>Submitted to the 23rd IEEE International Conference on Emerging
  Technologies and Factory Automation (ETFA 2018)</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In industrial environments, an increasing amount of wireless devices are
used, which utilize license-free bands. As a consequence of these mutual
interferences of wireless systems might decrease the state of coexistence.
Therefore, a central coexistence management system is needed, which allocates
conflict-free resources to wireless systems. To ensure a conflict-free resource
utilization, it is useful to predict the prospective medium utilization before
resources are allocated. This paper presents a self-learning concept, which is
based on reinforcement learning. A simulative evaluation of reinforcement
learning agents based on neural networks, called deep Q-networks and double
deep Q-networks, was realized for exemplary and practically relevant
coexistence scenarios. The evaluation of the double deep Q-network showed that
a prediction accuracy of at least 98 % can be reached in all investigated
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04711</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04711</id><created>2018-06-05</created><authors><author><keyname>Farias</keyname><forenames>Antonio Diego S.</forenames></author><author><keyname>Costa</keyname><forenames>Valdigleis S.</forenames></author><author><keyname>Lopes</keyname><forenames>Luiz Ranyer de Ara&#xfa;jo</forenames></author><author><keyname>Bedregal</keyname><forenames>Benjam&#xed;n</forenames></author><author><keyname>Santiago</keyname><forenames>Regivan H. N.</forenames></author></authors><title>Bounded Generalized Mixture Functions</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In literature, it is common to find problems which require a way to encode a
finite set of information into a single data; usually means are used for that.
An important generalization of means are the so called Aggregation Functions,
with a noteworthy subclass called OWA functions. There are, however, further
functions which are able to provide such codification which do not satisfy the
definition of aggregation functions; this is the case of pre-aggregation and
mixture functions.
  In this paper we investigate two special types of functions: Generalized
Mixture and Bounded Generalized Mixture functions. They generalize both: OWA
and Mixture functions. Both Generalized and Bounded Generalized Mixture
functions are developed in such way that the weight vectors are variables
depending on the input vector. A special generalized mixture operator, H, is
provided and applied in a simple toy example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04716</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04716</id><created>2018-06-09</created><authors><author><keyname>Yuan</keyname><forenames>Guangyuan</forenames></author><author><keyname>cao</keyname><forenames>Zhe</forenames></author><author><keyname>Wang</keyname><forenames>Shuwen</forenames></author><author><keyname>Liu</keyname><forenames>Shubin</forenames></author><author><keyname>An</keyname><forenames>Qi</forenames></author></authors><title>Application of FPGA Acceleration in ADC Performance Calibration</title><categories>eess.SP physics.ins-det</categories><comments>2 pages, 4 figures, 21st IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, high speed and high resolution analog-to-digital converter
(ADC) is widely employed in many physical experiments, especially in high
precision time and charge measurement. The rapid increasing amount of digitized
data demands faster computing. FPGA acceleration has an attracting prospect in
data process for its stream process and parallel process feature. In this
paper, an ADC performance calibration application based on FPGA acceleration is
described. FPGA reads the ADC digitized data stream from PC memory, processes
and then writes processed result back to the PC memory. PCIE bus is applied to
increase the data transfer speed, and floating point algorithm is applied to
improve the accuracy. The test result shows that FPGA acceleration can reduce
the processing time of the ADC performance calibration compared with
traditional method of C-based CPU processing. This frame of PCIE-based FPGA
acceleration method can be applied in analysis and simulation in the future
physical experiment for large ADC array, such as CCD camera and waveform
digitization readout electronics calibration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04727</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04727</id><created>2018-06-10</created><authors><author><keyname>Esswie</keyname><forenames>Ali A.</forenames></author><author><keyname>Pedersen</keyname><forenames>Klaus I.</forenames></author></authors><title>Null Space Based Preemptive Scheduling For Joint URLLC and eMBB Traffic
  in 5G Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a null-space-based preemptive scheduling framework
for cross-objective optimization to always guarantee robust URLLC performance,
while extracting the maximum possible eMBB capacity. The proposed scheduler
perpetually grants incoming URLLC traffic a higher priority for instant
scheduling. In case that radio resources are not immediately schedulable,
proposed scheduler forcibly enforces an artificial spatial user separation, for
the URLLC traffic to get instantly scheduled over shared resources with ongoing
eMBB transmissions. A pre-defined reference spatial subspace is constructed for
which scheduler instantly picks the active eMBB user whose precoder is the
closest possible. Then, it projects the eMBB precoder on-the-go onto the
reference subspace, in order for its paired URLLC user to orient its decoder
matrix into one possible null space of the reference subspace. Hence, a robust
decoding ability is always preserved at the URLLC user, while cross-maximizing
the ergodic capacity. Compared to the state-of-the-art proposals from industry
and academia, proposed scheduler shows extreme URLLC latency robustness with
significantly improved overall spectral efficiency. Analytical analysis and
extensive system level simulations are presented to support paper conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04841</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04841</id><created>2018-06-13</created><authors><author><keyname>Tang</keyname><forenames>Hao</forenames></author><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Grondin</keyname><forenames>Francois</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>A Study of Enhancement, Augmentation, and Autoencoder Methods for Domain
  Adaptation in Distant Speech Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Interspeech, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech recognizers trained on close-talking speech do not generalize to
distant speech and the word error rate degradation can be as large as 40%
absolute. Most studies focus on tackling distant speech recognition as a
separate problem, leaving little effort to adapting close-talking speech
recognizers to distant speech. In this work, we review several approaches from
a domain adaptation perspective. These approaches, including speech
enhancement, multi-condition training, data augmentation, and autoencoders, all
involve a transformation of the data between domains. We conduct experiments on
the AMI data set, where these approaches can be realized under the same
controlled setting. These approaches lead to different amounts of improvement
under their respective assumptions. The purpose of this paper is to quantify
and characterize the performance gap between the two domains, setting up the
basis for studying adaptation of speech recognizers from close-talking speech
to distant speech. Our results also have implications for improving distant
speech recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04872</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04872</id><created>2018-06-13</created><authors><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Tang</keyname><forenames>Hao</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Unsupervised Adaptation with Interpretable Disentangled Representations
  for Distant Conversational Speech Recognition</title><categories>cs.CL cs.LG cs.NE cs.SD eess.AS</categories><comments>to appear in Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current trend in automatic speech recognition is to leverage large
amounts of labeled data to train supervised neural network models.
Unfortunately, obtaining data for a wide range of domains to train robust
models can be costly. However, it is relatively inexpensive to collect large
amounts of unlabeled data from domains that we want the models to generalize
to. In this paper, we propose a novel unsupervised adaptation method that
learns to synthesize labeled data for the target domain from unlabeled
in-domain data and labeled out-of-domain data. We first learn without
supervision an interpretable latent representation of speech that encodes
linguistic and nuisance factors (e.g., speaker and channel) using different
latent variables. To transform a labeled out-of-domain utterance without
altering its transcript, we transform the latent nuisance variables while
maintaining the linguistic variables. To demonstrate our approach, we focus on
a channel mismatch setting, where the domain of interest is distant
conversational speech, and labels are only available for close-talking speech.
Our proposed method is evaluated on the AMI dataset, outperforming all
baselines and bridging the gap between unadapted and in-domain models by over
77% without using any parallel data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04874</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04874</id><created>2018-06-13</created><authors><author><keyname>M</keyname><forenames>Amarlingam</forenames></author><author><keyname>Mishra</keyname><forenames>Pradeep Kumar</forenames></author><author><keyname>Rajalakshmi</keyname><forenames>P</forenames></author><author><keyname>Channappayya</keyname><forenames>Sumohana S.</forenames></author><author><keyname>Sastry</keyname><forenames>C. S.</forenames></author></authors><title>Novel Light Weight Compressed Data Aggregation Using Sparse Measurements
  for IoT Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal data aggregation aimed at maximizing IoT network lifetime by
minimizing constrained on-board resource utilization continues to be a
challenging task. The existing data aggregation methods have proven that
compressed sensing is promising for data aggregation. However, they compromise
either on energy efficiency or recovery fidelity and require complex on-node
computations. In this paper, we propose a novel Light Weight Compressed Data
Aggregation (LWCDA) algorithm that randomly divides the entire network into
non-overlapping clusters for data aggregation. The random non-overlapping
clustering offers two important advantages: 1) energy efficiency, as each node
has to send its measurement only to its cluster head, 2) highly sparse
measurement matrix, which leads to a practically implementable framework with
low complexity. We analyze the properties of our measurement matrix using
restricted isometry property, the associated coherence and phase transition.
Through extensive simulations on practical data, we show that the measurement
matrix can reconstruct data with high fidelity. Further, we demonstrate that
the LWCDA algorithm reduces transmission cost significantly against baseline
approaches, implying thereby the enhancement of the network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04885</identifier>
 <datestamp>2018-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04885</id><created>2018-06-13</created><updated>2018-10-01</updated><authors><author><keyname>Kavalekalam</keyname><forenames>Mathew Shaji</forenames></author><author><keyname>Nielsen</keyname><forenames>Jesper K.</forenames></author><author><keyname>Boldt</keyname><forenames>Jesper B.</forenames></author><author><keyname>Christensen</keyname><forenames>Mads G.</forenames></author></authors><title>Model-based Speech Enhancement for Intelligibility Improvement in
  Binaural Hearing Aids</title><categories>eess.AS cs.SD</categories><comments>after revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech intelligibility is often severely degraded among hearing impaired
individuals in situations such as the cocktail party scenario. The performance
of the current hearing aid technology has been observed to be limited in these
scenarios. In this paper, we propose a binaural speech enhancement framework
that takes into consideration the speech production model. The enhancement
framework proposed here is based on the Kalman filter that allows us to take
the speech production dynamics into account during the enhancement process. The
usage of a Kalman filter requires the estimation of clean speech and noise
short term predictor (STP) parameters, and the clean speech pitch parameters.
In this work, a binaural codebook-based method is proposed for estimating the
STP parameters, and a directional pitch estimator based on the harmonic model
and maximum likelihood principle is used to estimate the pitch parameters. The
proposed method for estimating the STP and pitch parameters jointly uses the
information from left and right ears, leading to a more robust estimation of
the filter parameters. Objective measures such as PESQ and STOI have been used
to evaluate the enhancement framework in different acoustic scenarios
representative of the cocktail party scenario. We have also conducted
subjective listening tests on a set of nine normal hearing subjects, to
evaluate the performance in terms of intelligibility and quality improvement.
The listening tests show that the proposed algorithm, even with access to only
a single channel noisy observation, significantly improves the overall speech
quality, and the speech intelligibility by up to 15%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04903</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04903</id><created>2018-06-13</created><authors><author><keyname>Aljanaki</keyname><forenames>Anna</forenames></author><author><keyname>Soleymani</keyname><forenames>Mohammad</forenames></author></authors><title>A data-driven approach to mid-level perceptual musical feature modeling</title><categories>cs.SD eess.AS</categories><comments>7 pages, ISMIR conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musical features and descriptors could be coarsely divided into three levels
of complexity. The bottom level contains the basic building blocks of music,
e.g., chords, beats and timbre. The middle level contains concepts that emerge
from combining the basic blocks: tonal and rhythmic stability, harmonic and
rhythmic complexity, etc. High-level descriptors (genre, mood, expressive
style) are usually modeled using the lower level ones. The features belonging
to the middle level can both improve automatic recognition of high-level
descriptors, and provide new music retrieval possibilities. Mid-level features
are subjective and usually lack clear definitions. However, they are very
important for human perception of music, and on some of them people can reach
high agreement, even though defining them and therefore, designing a
hand-crafted feature extractor for them can be difficult. In this paper, we
derive the mid-level descriptors from data. We collect and release a
dataset\footnote{https://osf.io/5aupt/} of 5000 songs annotated by musicians
with seven mid-level descriptors, namely, melodiousness, tonal and rhythmic
stability, modality, rhythmic complexity, dissonance and articulation. We then
compare several approaches to predicting these descriptors from spectrograms
using deep-learning. We also demonstrate the usefulness of these mid-level
features using music emotion recognition as an application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04935</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04935</id><created>2018-06-13</created><authors><author><keyname>Serrano</keyname><forenames>Ana</forenames></author><author><keyname>Garces</keyname><forenames>Elena</forenames></author><author><keyname>Gutierrez</keyname><forenames>Diego</forenames></author><author><keyname>Masia</keyname><forenames>Belen</forenames></author></authors><title>Convolutional sparse coding for capturing high speed video content</title><categories>cs.GR cs.CV eess.IV</categories><journal-ref>Computer Graphics Forum 36, 8, Pages 380-389 (February 2017)</journal-ref><doi>10.1111/cgf.13086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video capture is limited by the trade-off between spatial and temporal
resolution: when capturing videos of high temporal resolution, the spatial
resolution decreases due to bandwidth limitations in the capture system.
Achieving both high spatial and temporal resolution is only possible with
highly specialized and very expensive hardware, and even then the same basic
trade-off remains. The recent introduction of compressive sensing and sparse
reconstruction techniques allows for the capture of single-shot high-speed
video, by coding the temporal information in a single frame, and then
reconstructing the full video sequence from this single coded image and a
trained dictionary of image patches. In this paper, we first analyze this
approach, and find insights that help improve the quality of the reconstructed
videos. We then introduce a novel technique, based on convolutional sparse
coding (CSC), and show how it outperforms the state-of-the-art, patch-based
approach in terms of flexibility and efficiency, due to the convolutional
nature of its filter banks. The key idea for CSC high-speed video acquisition
is extending the basic formulation by imposing an additional constraint in the
temporal dimension, which enforces sparsity of the first-order derivatives over
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.04942</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.04942</id><created>2018-06-13</created><authors><author><keyname>Serrano</keyname><forenames>Ana</forenames></author><author><keyname>Heide</keyname><forenames>Felix</forenames></author><author><keyname>Gutierrez</keyname><forenames>Diego</forenames></author><author><keyname>Wetzstein</keyname><forenames>Gordon</forenames></author><author><keyname>Masia</keyname><forenames>Belen</forenames></author></authors><title>Convolutional Sparse Coding for High Dynamic Range Imaging</title><categories>cs.CV cs.GR eess.IV</categories><journal-ref>Computer Graphics Forum 35, 2, Pages 153-163 (May 2016)</journal-ref><doi>10.1111/cgf.12819</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current HDR acquisition techniques are based on either (i) fusing
multibracketed, low dynamic range (LDR) images, (ii) modifying existing
hardware and capturing different exposures simultaneously with multiple
sensors, or (iii) reconstructing a single image with spatially-varying pixel
exposures. In this paper, we propose a novel algorithm to recover high-quality
HDRI images from a single, coded exposure. The proposed reconstruction method
builds on recently-introduced ideas of convolutional sparse coding (CSC); this
paper demonstrates how to make CSC practical for HDR imaging. We demonstrate
that the proposed algorithm achieves higher-quality reconstructions than
alternative methods, we evaluate optical coding schemes, analyze algorithmic
parameters, and build a prototype coded HDR camera that demonstrates the
utility of convolutional sparse HDRI coding with a custom hardware platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05017</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05017</id><created>2018-06-13</created><updated>2018-07-26</updated><authors><author><keyname>Sole-Casals</keyname><forenames>Jordi</forenames></author><author><keyname>Caiafa</keyname><forenames>Cesar F.</forenames></author><author><keyname>Zhao</keyname><forenames>Qibin</forenames></author><author><keyname>Cichocki</keyname><forenames>Adrzej</forenames></author></authors><title>Brain-Computer Interface with Corrupted EEG Data: A Tensor Completion
  Approach</title><categories>q-bio.QM eess.SP stat.ML</categories><comments>21 pages, 3 tables, 4 figures</comments><journal-ref>Sole-Casals, J., Caiafa, C.F., Zhao, Q. et al. Cogn Comput (2018).
  https://doi.org/10.1007/s12559-018-9574-9</journal-ref><doi>10.1007/s12559-018-9574-9</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One of the current issues in Brain-Computer Interface is how to deal with
noisy Electroencephalography measurements organized as multidimensional
datasets. On the other hand, recently, significant advances have been made in
multidimensional signal completion algorithms that exploit tensor decomposition
models to capture the intricate relationship among entries in a
multidimensional signal. We propose to use tensor completion applied to EEG
data for improving the classification performance in a motor imagery BCI system
with corrupted measurements. Noisy measurements are considered as unknowns that
are inferred from a tensor decomposition model. We evaluate the performance of
four recently proposed tensor completion algorithms plus a simple interpolation
strategy, first with random missing entries and then with missing samples
constrained to have a specific structure (random missing channels), which is a
more realistic assumption in BCI Applications. We measured the ability of these
algorithms to reconstruct the tensor from observed data. Then, we tested the
classification accuracy of imagined movement in a BCI experiment with missing
samples. We show that for random missing entries, all tensor completion
algorithms can recover missing samples increasing the classification
performance compared to a simple interpolation approach. For the random missing
channels case, we show that tensor completion algorithms help to reconstruct
missing channels, significantly improving the accuracy in the classification of
motor imagery, however, not at the same level as clean data. Tensor completion
algorithms are useful in real BCI applications. The proposed strategy could
allow using motor imagery BCI systems even when EEG data is highly affected by
missing channels and/or samples, avoiding the need of new acquisitions in the
calibration stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05059</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05059</id><created>2018-06-12</created><updated>2018-06-13</updated><authors><author><keyname>Zhou</keyname><forenames>Shiyu</forenames></author><author><keyname>Xu</keyname><forenames>Shuang</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>Multilingual End-to-End Speech Recognition with A Single Transformer on
  Low-Resource Languages</title><categories>eess.AS cs.CL cs.SD</categories><comments>arXiv admin note: text overlap with arXiv:1805.06239</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence attention-based models integrate an acoustic,
pronunciation and language model into a single neural network, which make them
very suitable for multilingual automatic speech recognition (ASR). In this
paper, we are concerned with multilingual speech recognition on low-resource
languages by a single Transformer, one of sequence-to-sequence attention-based
models. Sub-words are employed as the multilingual modeling unit without using
any pronunciation lexicon. First, we show that a single multilingual ASR
Transformer performs well on low-resource languages despite of some language
confusion. We then look at incorporating language information into the model by
inserting the language symbol at the beginning or at the end of the original
sub-words sequence under the condition of language information being known
during training. Experiments on CALLHOME datasets demonstrate that the
multilingual ASR Transformer with the language symbol at the end performs
better and can obtain relatively 10.5\% average word error rate (WER) reduction
compared to SHL-MLSTM with residual learning. We go on to show that, assuming
the language information being known during training and testing, about
relatively 12.4\% average WER reduction can be observed compared to SHL-MLSTM
with residual learning through giving the language symbol as the sentence start
token.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05143</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05143</id><created>2018-06-13</created><updated>2018-06-30</updated><authors><author><keyname>Jamal</keyname><forenames>Hosseinali</forenames></author><author><keyname>Matolak</keyname><forenames>David W.</forenames></author></authors><title>Dual-Polarization OFDM-OQAM Wireless Communication System</title><categories>eess.SP</categories><comments>1.This paper is accepted to be published in IEEE Vehicular Technology
  Conference (VTC) FALL 2018. 2.In this new submitted version authors have
  revised the paper based on the VTC FALL reviewers comments. Therefore some
  typos have fixed and some results have changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe the overall idea and results of a recently proposed
radio access technique based on filter bank multicarrier (FBMC) communication
system using two orthogonal polarizations: dual-polarization FBMC (DP-FBMC).
Using this system we can alleviate the intrinsic interference problem in FBMC
systems. This enables use of all the multicarrier techniques used in
cyclic-prefix orthogonal frequency-division multiplexing (CP-OFDM) systems for
channel equalization, multiple-input/multiple-output (MIMO) processing, etc.,
without using the extra processing required for conventional FBMC. DP-FBMC also
provides other interesting advantages over CP-OFDM and FBMC such as more
robustness in multipath fading channels, and more robustness to receiver
carrier frequency offset (CFO) and timing offset (TO). For DP-FBMC we propose
three different structures based on different multiplexing techniques in time,
frequency, and polarization. We will show that one of these structures has
exactly the same system complexity and equipment as conventional FBMC. In our
simulation results DP-FBMC has better bit error ratio (BER) performance in
dispersive channels. Based on these results, DP-FBMC has potential as a
promising candidate for future wireless communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05176</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05176</id><created>2018-06-13</created><authors><author><keyname>Nagaraj</keyname><forenames>Pavithra</forenames></author></authors><title>Impact of atmospheric impairments on mmWave based outdoor communication</title><categories>eess.SP</categories><comments>5 Pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Substantial growth of demand for mobile data and rapidly increasing spread of
personal communication devices such as smart phones and tablets is the major
challenge faced by the mobile service providers in recent years. The allotted
spectrum for the currently operating mobile communication systems have been
saturated in the last few years by such a considerable rate that the future
fifth generation network would not be able to operate without applying new
frequencies. In accordance with the concept of 5G, millimeter wave frequency
band will also be used along with the currently used frequency bands. In this
particular spectrum however, a new and most significant attenuation factor due
to precipitation and atmospheric absorption is introduced. In this paper the
effects of precipitation, fog and atmospheric absorption on millimeter wave
propagation are investigated using MATLAB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05211</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05211</id><created>2018-06-07</created><authors><author><keyname>Ta&#x15f;cikarao&#x11f;lu</keyname><forenames>Ak&#x131;n</forenames></author><author><keyname>Erdin&#xe7;</keyname><forenames>Ozan</forenames></author></authors><title>A Profit Optimization Approach Based on the Use of Pumped-Hydro Energy
  Storage Unit and Dynamic Pricing</title><categories>econ.EM eess.SP</categories><comments>in Turkish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, an optimization problem is proposed in order to obtain the
maximum economic benefit from wind farms with variable and intermittent energy
generation in the day ahead and balancing electricity markets. This method,
which is based on the use of pumped-hydro energy storage unit and wind farm
together, increases the profit from the power plant by taking advantage of the
price changes in the markets and at the same time supports the power system by
supplying a portion of the peak load demand in the system to which the plant is
connected. With the objective of examining the effectiveness of the proposed
method, detailed simulation studies are carried out by making use of actual
wind and price data, and the results are compared to those obtained for the
various cases in which the storage unit is not available and/or the proposed
price-based energy management method is not applied. As a consequence, it is
demonstrated that the pumped-hydro energy storage units are the storage systems
capable of being used effectively for high-power levels and that the proposed
optimization problem is quite successful in the cost-effective implementation
of these systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05233</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05233</id><created>2018-06-13</created><authors><author><keyname>Esmaeilzadeh</keyname><forenames>Soheil</forenames></author><author><keyname>Yang</keyname><forenames>Yao</forenames></author><author><keyname>Adeli</keyname><forenames>Ehsan</forenames></author></authors><title>End-to-End Parkinson Disease Diagnosis using Brain MR-Images by 3D-CNN</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we use a deep learning framework for simultaneous
classification and regression of Parkinson disease diagnosis based on MR-Images
and personal information (i.e. age, gender). We intend to facilitate and
increase the confidence in Parkinson disease diagnosis through our deep
learning framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05296</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05296</id><created>2018-06-13</created><updated>2018-07-23</updated><authors><author><keyname>Casebeer</keyname><forenames>Jonah</forenames></author><author><keyname>Luc</keyname><forenames>Brian</forenames></author><author><keyname>Smaragdis</keyname><forenames>Paris</forenames></author></authors><title>Multi-View Networks for Denoising of Arbitrary Numbers of Channels</title><categories>eess.AS cs.SD</categories><comments>5 pages, 6 figures, IWAENC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a set of denoising neural networks capable of operating on an
arbitrary number of channels at runtime, irrespective of how many channels they
were trained on. We coin the proposed models multi-view networks since they
operate using multiple views of the same data. We explore two such
architectures and show how they outperform traditional denoising models in
multi-channel scenarios. Additionally, we demonstrate how multi-view networks
can leverage information provided by additional recordings to make better
predictions, and how they are able to generalize to a number of recordings not
seen in training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05352</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05352</id><created>2018-06-13</created><authors><author><keyname>Shen</keyname><forenames>Yiru</forenames></author><author><keyname>Salley</keyname><forenames>James</forenames></author><author><keyname>Muth</keyname><forenames>Eric</forenames></author><author><keyname>Hoover</keyname><forenames>Adam</forenames></author></authors><title>Assessing the Accuracy of a Wrist Motion Tracking Method for Counting
  Bites across Demographic and Food Variables</title><categories>eess.SP</categories><journal-ref>IEEE Journal of Biomedical and Health Informatics, 2017</journal-ref><doi>10.1109/JBHI.2016.2612580</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a study to test the accuracy of a method that tracks
wrist motion during eating to detect and count bites. The purpose was to assess
its accuracy across demographic (age, gender, ethnicity) and bite (utensil,
container, hand used, food type) variables. Data were collected in a cafeteria
under normal eating conditions. A total of 271 participants ate a single meal
while wearing a watch-like device to track their wrist motion. Video was
simultaneously recorded of each participant and subsequently reviewed to
determine the ground truth times of bites. Bite times were operationally
defined as the moment when food or beverage was placed into the mouth. Food and
beverage choices were not scripted or restricted. Participants were seated in
groups of 2-4 and were encouraged to eat naturally. A total of 24,088 bites of
374 different food and beverage items were consumed. Overall the method for
automatically detecting bites had a sensitivity of 75% with a positive
predictive value of 89%. A range of 62-86% sensitivity was found across
demographic variables, with slower eating rates trending towards higher
sensitivity. Variations in sensitivity due to food type showed a modest
correlation with the total wrist motion during the bite, possibly due to an
increase in head-towards-plate motion and decrease in hand-towards-mouth motion
for some food types. Overall, the findings provide the largest evidence to date
that the method produces a reliable automated measure of intake during
unrestricted eating.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05408</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05408</id><created>2018-06-14</created><updated>2018-06-15</updated><authors><author><keyname>Feuillen</keyname><forenames>Thomas</forenames></author><author><keyname>Xu</keyname><forenames>Chunlei</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author></authors><title>1-bit Localization Scheme for Radar using Dithered Quantized Compressed
  Sensing</title><categories>eess.SP</categories><comments>10 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel scheme allowing for 2D target localization using highly
quantized 1-bit measurements from a Frequency Modulated Continuous Wave (FMCW)
radar with two receiving antennas. Quantization of radar signals introduces
localization artifacts, we remove this limitation by inserting a dithering on
the unquantized observations. We then adapt the projected back projection
algorithm to estimate both the range and angle of targets from the dithered
quantized radar observations, with provably decaying reconstruction error when
the number of observations increases. Simulations are performed to highlight
the accuracy of the dithered scheme in noiseless conditions when compared to
the non-dithered and full 32-bit resolution under severe bit-rate reduction.
Finally, measurements are performed using a radar sensor to demonstrate the
effectiveness and performances of the proposed quantized dithered scheme in
real conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05546</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05546</id><created>2018-06-13</created><authors><author><keyname>Xu</keyname><forenames>Rui</forenames></author><author><keyname>Soltanolkotabi</keyname><forenames>Mahdi</forenames></author><author><keyname>Haldar</keyname><forenames>Justin P.</forenames></author><author><keyname>Unglaub</keyname><forenames>Walter</forenames></author><author><keyname>Zusman</keyname><forenames>Joshua</forenames></author><author><keyname>Levi</keyname><forenames>Anthony F. J.</forenames></author><author><keyname>Leahy</keyname><forenames>Richard M.</forenames></author></authors><title>Accelerated Wirtinger Flow: A fast algorithm for ptychography</title><categories>eess.IV math.NA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new algorithm, Accelerated Wirtinger Flow (AWF), for
ptychographic image reconstruction from phaseless diffraction pattern
measurements. AWF is based on combining Nesterov's acceleration approach with
Wirtinger gradient descent. Theoretical results enable prespecification of all
AWF algorithm parameters, with no need for computationally-expensive line
searches and no need for manual parameter tuning. AWF is evaluated in the
context of simulated X-ray ptychography, where we demonstrate fast convergence
and low per-iteration computational complexity. We also show examples where AWF
reaches higher image quality with less computation than classical algorithms.
AWF is also shown to have robustness to noise and probe misalignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05621</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05621</id><created>2018-06-14</created><authors><author><keyname>Ren</keyname><forenames>Chenglin</forenames></author><author><keyname>Ma</keyname><forenames>Zhaohui</forenames></author><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Pi</keyname><forenames>Weichao</forenames></author><author><keyname>Zhou</keyname><forenames>Jianming</forenames></author></authors><title>A Convex Hull Based Approach for MIMO Radar Waveform Design with
  Quantized Phases</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we focus on designing constant-modulus waveform with discrete
phases for the multi-input multi-output (MIMO) radar, where the
signal-to-interference-plus-noise ratio (SINR) is maximized in the presence of
both the signal-dependent clutter and the noise. Given the NP-hardness of the
formulated problem, we propose to relax the original optimization as a sequence
of continuous quadratic programming (QP) subproblems by use of the convex hull
of the discrete feasible region, which yields approximated solutions with much
lower computational costs. Finally, we assess the effectiveness of the proposed
waveform design approach by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05622</identifier>
 <datestamp>2018-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05622</id><created>2018-06-14</created><updated>2018-06-26</updated><authors><author><keyname>Chung</keyname><forenames>Joon Son</forenames></author><author><keyname>Nagrani</keyname><forenames>Arsha</forenames></author><author><keyname>Zisserman</keyname><forenames>Andrew</forenames></author></authors><title>VoxCeleb2: Deep Speaker Recognition</title><categories>cs.SD cs.CV eess.AS</categories><comments>To appear in Interspeech 2018. The audio-visual dataset can be
  downloaded from http://www.robots.ox.ac.uk/~vgg/data/voxceleb2 .
  1806.05622v2: minor fixes; 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is speaker recognition under noisy and
unconstrained conditions.
  We make two key contributions. First, we introduce a very large-scale
audio-visual speaker recognition dataset collected from open-source media.
Using a fully automated pipeline, we curate VoxCeleb2 which contains over a
million utterances from over 6,000 speakers. This is several times larger than
any publicly available speaker recognition dataset.
  Second, we develop and compare Convolutional Neural Network (CNN) models and
training strategies that can effectively recognise identities from voice under
various conditions. The models trained on the VoxCeleb2 dataset surpass the
performance of previous works on a benchmark dataset by a significant margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05698</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05698</id><created>2018-06-14</created><authors><author><keyname>Boehm</keyname><forenames>James A</forenames><suffix>III</suffix></author><author><keyname>Dawood</keyname><forenames>Muhammad</forenames></author></authors><title>Applications of Various Space-time Transformations to Determine Radar
  Signal Distortion Caused by a Moving Target Having Constant Velocity and
  Acceleration</title><categories>eess.SP</categories><comments>17 pages, 4 appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of target motion on the distortion of radar signals are
investigated using five transformations, namely, Hsu, Lorentz, Galilean,
Reference, and Classical transformation equations. Hsu transformation is used
as a primary transformation since it expresses the temporal and spatial
transformations between an inertial reference frame and accelerating frame
where the origin of the accelerating frame has an initial velocity and
acceleration with respect to the inertial frame. Additionally, as the
acceleration approach zero and infinity, respectively, the Lorentz and Galilean
transformations are obtained. These transformations are used to express the
transmitted waveforms in the radar reference frame variables to that of the
target reference frame variables, and the reflected waveform from the target in
its reference frame variable to that of the radar reference frame variables,
leading to the distorted waveform received at the radar receiver due to the
motion of the target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05752</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05752</id><created>2018-06-14</created><updated>2019-05-08</updated><authors><author><keyname>Kim</keyname><forenames>Daeun</forenames></author><author><keyname>Wisnowski</keyname><forenames>Jessica L.</forenames></author><author><keyname>Nguyen</keyname><forenames>Christopher T.</forenames></author><author><keyname>Haldar</keyname><forenames>Justin P.</forenames></author></authors><title>Multidimensional Correlation Spectroscopic Imaging of Exponential
  Decays: From Theoretical Principles to In Vivo Human Applications</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiexponential modeling of relaxation or diffusion MR signal decays is a
popular approach for estimating and spatially mapping different microstructural
tissue compartments. While this approach can be quite powerful, it is also
limited by the fact that one-dimensional multiexponential modeling is an
ill-posed inverse problem with substantial ambiguities. In this paper, we
present an overview of a recent multidimensional correlation spectroscopic
imaging approach to this problem. This approach helps to alleviate
ill-posedness by leveraging multidimensional contrast encoding (e.g., 2D
diffusion-relaxation encoding or 2D relaxation-relaxation encoding) combined
with a regularized spatial-spectral estimation procedure. Theoretical
calculations, simulations, and experimental results are used to illustrate the
benefits of this approach relative to classical methods. In addition, we
demonstrate an initial proof-of-principle application of this kind of approach
to in vivo human MRI experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05765</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05765</id><created>2018-06-14</created><authors><author><keyname>AlHajri</keyname><forenames>Mohamed</forenames></author><author><keyname>Goian</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Darweesh</keyname><forenames>Muna</forenames></author><author><keyname>AlMemari</keyname><forenames>Rashid</forenames></author><author><keyname>Shubair</keyname><forenames>Raed</forenames></author><author><keyname>Weruaga</keyname><forenames>Luis</forenames></author><author><keyname>AlTunaiji</keyname><forenames>Ahmed</forenames></author></authors><title>Accurate and Robust Localization Techniques for Wireless Sensor Networks</title><categories>eess.SP</categories><comments>149 pages, Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The report focuses on three areas in particular: the first is the Received
Signal Strength indicator technique, Direction of Arrival technique, and the
integration of two algorithms, RSS and DOA, in order to build a hybrid, more
robust algorithms.
  In the Received Signal Strength (RSS), the unknown node location is estimated
using trilateration. This report examines the performance of different
estimators such as Least Square, Weighted Least Square, and Huber robustness in
order to obtain the most robust performance.
  In the direction of arrival (DOA) method, the estimation is carried out using
Multiple Signal Classification (MUSIC), Root-MUSIC, and Estimation of Signal
Parameters Via Rotational Invariance Technique (ESPRIT) algorithms. We
investigate multiple signal scenarios utilizing various antenna geometries,
which includes uniform linear array (ULA) and uniform circular array (UCA).
Specific attention is given for multipath scenarios in which signals become
spatially correlated (or coherent). This required the use of pre-processing
techniques, which include phase mode excitation (PME), spatial smoothing (SS),
and Toeplitz.
  Further improvements of existing localization techniques are demonstrated
through the use of a hybrid approach in which various combinations of RSS and
DOA are explored, simulated, and analyzed. This has led to two major
contributions: the first contribution is a combined RSS/DOA method, based on
UCA, which has the tolerance of detecting both uncorrelated and coherent
signals simultaneously. The second major contribution is a combined
Root-MUSIC/Toepltiz method, based on UCA, which is outperforms other techniques
in terms of increased number of detected signals and reduced computationally
load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05791</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05791</id><created>2018-06-14</created><authors><author><keyname>Nakajima</keyname><forenames>Hiroaki</forenames></author><author><keyname>Takahashi</keyname><forenames>Yu</forenames></author><author><keyname>Kondo</keyname><forenames>Kazunobu</forenames></author><author><keyname>Hisaminato</keyname><forenames>Yuji</forenames></author></authors><title>Monaural source enhancement maximizing source-to-distortion ratio via
  automatic differentiation</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>This paper is submitted to 16th International Workshop on Acoustic
  Signal Enhancement (IWAENC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep neural network (DNN) has made a breakthrough in monaural
source enhancement. Through a training step by using a large amount of data,
DNN estimates a mapping between mixed signals and clean signals. At this time,
we use an objective function that numerically expresses the quality of a
mapping by DNN. In the conventional methods, L1 norm, L2 norm, and
Itakura-Saito divergence are often used as objective functions. Recently, an
objective function based on short-time objective intelligibility (STOI) has
also been proposed. However, these functions only indicate similarity between
the clean signal and the estimated signal by DNN. In other words, they do not
show the quality of noise reduction or source enhancement. Motivated by the
fact, this paper adopts signal-to-distortion ratio (SDR) as the objective
function. Since SDR virtually shows signal-to-noise ratio (SNR), maximizing SDR
solves the above problem. The experimental results revealed that the proposed
method achieved better performance than the conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05825</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05825</id><created>2018-06-15</created><authors><author><keyname>Zuo</keyname><forenames>Yihui</forenames></author><author><keyname>Sossan</keyname><forenames>Fabrizio</forenames></author><author><keyname>Bozorg</keyname><forenames>Mokhtar</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Dispatch and Primary Frequency Control with Electrochemical Storage: a
  System-wise Verification</title><categories>eess.SP</categories><comments>7 pages, 20 figures, accepted by ISGT Europe 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty levels in forecasting of renewable generation and demand are
known to affect the amount of reserve required to operate the power grid with a
given level of reliability. In this paper, we quantify the effects on the
system reserve and reliability, due to the local dispatch of stochastic demand
and renewable generation. The analysis is performed considering the model of
the IEEE 39-bus system, with detailed dynamic models of conventional
generation, wind generation, demand and an under-frequency load shedding
mechanism. The analysis compares to cases: the base case, where renewable
generation and demand power are stochastic and the power reserve is provided by
conventional generation, against the case where the operation of traditionally
stochastic resources is dispatched according to pre-established dispatch plans
thanks to controlling local flexibility. Simulations reproduce the
post-contingency dynamic behavior of the grid due to outages of generators. The
contingencies are selected to trigger under frequency load shedding mechanisms,
hence to demonstrate the different levels of system operation reliability for
the two case studies. Simulation results show that dispatching traditionally
stochastic generation scores better regarding to expected energy not served,
producing an increase of the system reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05882</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05882</id><created>2018-06-15</created><updated>2018-08-27</updated><authors><author><keyname>Yue</keyname><forenames>Yang</forenames></author><author><keyname>He</keyname><forenames>Liuyuan</forenames></author><author><keyname>He</keyname><forenames>Gan</forenames></author><author><keyname>Liu</keyname><forenames>Jian. K.</forenames></author><author><keyname>Du</keyname><forenames>Kai</forenames></author><author><keyname>Tian</keyname><forenames>Yonghong</forenames></author><author><keyname>Huang</keyname><forenames>Tiejun</forenames></author></authors><title>A simple blind-denoising filter inspired by electrically coupled
  photoreceptors in the retina</title><categories>cs.CV eess.IV q-bio.NC</categories><comments>16 pages, 8 figures, 9 tables, Submitted to NIPS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoreceptors in the retina are coupled by electrical synapses called &quot;gap
junctions&quot;. It has long been established that gap junctions increase the
signal-to-noise ratio of photoreceptors. Inspired by electrically coupled
photoreceptors, we introduced a simple filter, the PR-filter, with only one
variable. On BSD68 dataset, PR-filter showed outstanding performance in SSIM
during blind denoising tasks. It also significantly improved the performance of
state-of-the-art convolutional neural network blind denosing on non-Gaussian
noise. The performance of keeping more details might be attributed to small
receptive field of the photoreceptors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05892</identifier>
 <datestamp>2019-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05892</id><created>2018-06-15</created><authors><author><keyname>Humayun</keyname><forenames>Ahmed Imtiaz</forenames></author><author><keyname>Ghaffarzadegan</keyname><forenames>Shabnam</forenames></author><author><keyname>Feng</keyname><forenames>Zhe</forenames></author><author><keyname>Hasan</keyname><forenames>Taufiq</forenames></author></authors><title>Learning Front-end Filter-bank Parameters using Convolutional Neural
  Networks for Abnormal Heart Sound Detection</title><categories>cs.CV cs.LG eess.SP stat.ML</categories><comments>4 pages, 6 figures, IEEE International Engineering in Medicine and
  Biology Conference (EMBC)</comments><doi>10.1109/EMBC.2018.8512578</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Automatic heart sound abnormality detection can play a vital role in the
early diagnosis of heart diseases, particularly in low-resource settings. The
state-of-the-art algorithms for this task utilize a set of Finite Impulse
Response (FIR) band-pass filters as a front-end followed by a Convolutional
Neural Network (CNN) model. In this work, we propound a novel CNN architecture
that integrates the front-end bandpass filters within the network using
time-convolution (tConv) layers, which enables the FIR filter-bank parameters
to become learnable. Different initialization strategies for the learnable
filters, including random parameters and a set of predefined FIR filter-bank
coefficients, are examined. Using the proposed tConv layers, we add constraints
to the learnable FIR filters to ensure linear and zero phase responses.
Experimental evaluations are performed on a balanced 4-fold cross-validation
task prepared using the PhysioNet/CinC 2016 dataset. Results demonstrate that
the proposed models yield superior performance compared to the state-of-the-art
system, while the linear phase FIR filterbank method provides an absolute
improvement of 9.54% over the baseline in terms of an overall accuracy metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.05932</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.05932</id><created>2018-06-15</created><authors><author><keyname>Lindmark</keyname><forenames>Gustav</forenames></author><author><keyname>Altafini</keyname><forenames>Claudio</forenames></author></authors><title>The role of non-normality for control energy reduction in network
  controllability problems</title><categories>cs.SY eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of controlling a complex network with
reduced control energy. Two centrality measures are defined, one related to the
energy that a control, placed on a node, can exert on the entire network, the
other related to the energy that all other nodes exert on a node. We show that
by combining these two centrality measures, conflicting control energy
requirements, like minimizing the average energy needed to steer the state in
any direction and the energy needed for the worst direction, can be
simultaneously taken into account. From an algebraic point of view, the node
ranking that we obtain from the combination of our centrality measures is
related to the non-normality of the adjacency matrix of the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06062</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06062</id><created>2018-05-25</created><authors><author><keyname>Yazdandoost</keyname><forenames>Mina</forenames></author><author><keyname>Khazaei</keyname><forenames>Peyman</forenames></author><author><keyname>Saadatian</keyname><forenames>Salar</forenames></author><author><keyname>Kamali</keyname><forenames>Rahim</forenames></author></authors><title>Distributed Optimization Strategy for Multi Area Economic Dispatch Based
  on Electro Search Optimization Algorithm</title><categories>cs.OH cs.NE eess.SP</categories><comments>This paper is accepted for WAC 2018 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new adopted evolutionary algorithm is presented in this paper to solve the
non-smooth, non-convex and non-linear multi-area economic dispatch (MAED). MAED
includes some areas which contains its own power generation and loads. By
transmitting the power from the area with lower cost to the area with higher
cost, the total cost function can be minimized greatly. The tie line capacity,
multi-fuel generator and the prohibited operating zones are satisfied in this
study. In addition, a new algorithm based on electro search optimization
algorithm (ESOA) is proposed to solve the MAED optimization problem with
considering all the constraints. In ESOA algorithm all probable moving states
for individuals to get away from or move towards the worst or best solution
needs to be considered. To evaluate the performance of the ESOA algorithm, the
algorithm is applied to both the original economic dispatch with 40 generator
systems and the multi-area economic dispatch with 3 different systems such as:
6 generators in 2 areas; and 40 generators in 4 areas. It can be concluded
that, ESOA algorithm is more accurate and robust in comparison with other
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06171</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06171</id><created>2018-06-15</created><authors><author><keyname>Kovacs</keyname><forenames>Laszlo</forenames></author><author><keyname>Kovacs</keyname><forenames>Roland</forenames></author><author><keyname>Hajdu</keyname><forenames>Andras</forenames></author></authors><title>High Performance Computing in Medical Image Analysis HuSSaR</title><categories>eess.IV</categories><comments>4 pages 6 images</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our former works we have made serious efforts to improve the performance
of medical image analysis methods with using ensemble-based systems. In this
paper, we present a novel hardware-based solution for the efficient adoption of
our complex, fusion-based approaches for real-time applications. Even though
most of the image processing problems and the increasing amount of data have
high-performance computing(HPC) demand, there is still a lack of corresponding
dedicated HPC solutions for several medical tasks. To widen this bottleneck we
have developed a Hybrid Small Size high performance computing Resource
(abbreviated by HuSSaR) which efficiently alloys CPU and GPU technologies,
mobile and has an own cooling system to support easy mobility and wide
applicability. Besides a proper technical description, we include several
practical examples from the clinical data processing domain in this work. For
more details see also:
https://arato.inf.unideb.hu/kovacs.laszlo/research_hybridmicrohpc.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06261</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06261</id><created>2018-06-16</created><authors><author><keyname>Kidane</keyname><forenames>Hiliwi Leake</forenames></author></authors><title>Comparative survey: People detection, tracking and multi-sensor Fusion
  in a video sequence</title><categories>eess.IV</categories><comments>7 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tracking people in a video sequence is one of the fields of interest in
computer vision. It has broad applications in motion capture and surveillance.
However, due to the complexity of human dynamic structure, detecting and
tracking are not straightforward. Consequently, different detection and
tracking techniques with different applications and performance have been
developed. To minimize the noise between the prediction and measurement during
tracking, Kalman filter has been used as a filtering technique. At the same
time, in most cases, detection and tracking results from a single sensor is not
enough to detect and track a person. To avoid this problem, using a
multi-sensor fusion technique is indispensable. In this paper, a comparative
survey of detection, tracking and multi-sensor fusion methods are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06273</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06273</id><created>2018-06-16</created><authors><author><keyname>Moser</keyname><forenames>Bernhard A.</forenames></author></authors><title>On the Discrepancy Normed Space of Event Sequences for Threshold-based
  Sampling</title><categories>math.MG eess.SP</categories><msc-class>46Exx, 54C35, 26B39, 26A45, 46B20, 94Axx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recalling recent results on the characterization of threshold-based sampling
as quasi-isometric mapping, mathematical implications on the metric and
topological structure of the space of event sequences are derived. In this
context, the space of event sequences is extended to a normed space equipped
with Hermann Weyl's discrepancy measure. Sequences of finite discrepancy norm
are characterized by a Jordan decomposition property. Its dual norm turns out
to be the norm of total variation. As a by-product a measure for the lack of
monotonicity of sequences is obtained. A further result refers to an inequality
between the discrepancy norm and total variation which resembles Heisenberg's
uncertainty relation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06295</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06295</id><created>2018-06-16</created><authors><author><keyname>Gribkova</keyname><forenames>Nadezhda</forenames></author><author><keyname>Zitikis</keyname><forenames>Ri&#x10d;ardas</forenames></author></authors><title>Detecting intrusions in control systems: a rule of thumb, its
  justification and illustrations</title><categories>stat.ME eess.SP</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control systems are exposed to unintentional errors, deliberate intrusions,
false data injection attacks, and various other disruptions. In this paper we
propose, justify, and illustrate a rule of thumb for detecting, or confirming
the absence of, such disruptions. To facilitate the use of the rule, we
rigorously discuss background results that delineate the boundaries of the
rule's applicability. We also discuss ways to further widen the applicability
of the proposed intrusion-detection methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06321</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06321</id><created>2018-06-16</created><authors><author><keyname>Kidane</keyname><forenames>Hiliwi Leake</forenames></author></authors><title>Comparative survey of visual object classifiers</title><categories>eess.IV cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification of Visual Object Classes represents one of the most elaborated
areas of interest in Computer Vision. It is always challenging to get one
specific detector, descriptor or classifier that provides the expected object
classification result. Consequently, it critical to compare the different
detection, descriptor and classifier methods available and chose a single or
combination of two or three to get an optimal result. In this paper, we have
presented a comparative survey of different feature descriptors and
classifiers. From feature descriptors, SIFT (Sparse &amp; Dense) and HeuSIFT
combination colour descriptors; From classification techniques, Support Vector
Classifier, K-Nearest Neighbor, ADABOOST, and fisher are covered in comparative
practical implementation survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06342</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06342</id><created>2018-06-17</created><updated>2019-02-25</updated><authors><author><keyname>Dong</keyname><forenames>Linhao</forenames></author><author><keyname>Zhou</keyname><forenames>Shiyu</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>Extending Recurrent Neural Aligner for Streaming End-to-End Speech
  Recognition in Mandarin</title><categories>cs.SD cs.CL eess.AS</categories><comments>To appear in Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end models have been showing superiority in Automatic Speech
Recognition (ASR). At the same time, the capacity of streaming recognition has
become a growing requirement for end-to-end models. Following these trends, an
encoder-decoder recurrent neural network called Recurrent Neural Aligner (RNA)
has been freshly proposed and shown its competitiveness on two English ASR
tasks. However, it is not clear if RNA can be further improved and applied to
other spoken language. In this work, we explore the applicability of RNA in
Mandarin Chinese and present four effective extensions: In the encoder, we
redesign the temporal down-sampling and introduce a powerful convolutional
structure. In the decoder, we utilize a regularizer to smooth the output
distribution and conduct joint training with a language model. On two Mandarin
Chinese conversational telephone speech recognition (MTS) datasets, our
Extended-RNA obtains promising performance. Particularly, it achieves 27.7%
character error rate (CER), which is superior to current state-of-the-art
result on the popular HKUST task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06347</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06347</id><created>2018-06-17</created><updated>2018-06-29</updated><authors><author><keyname>Tralie</keyname><forenames>Christopher J.</forenames></author></authors><title>Cover Song Synthesis by Analogy</title><categories>cs.SD eess.AS</categories><comments>11 pages, 5 figures</comments><acm-class>H.5.5; H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we pose and address the following &quot;cover song analogies&quot;
problem: given a song A by artist 1 and a cover song A' of this song by artist
2, and given a different song B by artist 1, synthesize a song B' which is a
cover of B in the style of artist 2. Normally, such a polyphonic style transfer
problem would be quite challenging, but we show how the cover songs example
constrains the problem, making it easier to solve. First, we extract the
longest common beat-synchronous subsequence between A and A', and we time
stretch the corresponding beat intervals in A' so that they align with A. We
then derive a version of joint 2D convolutional NMF, which we apply to the
constant-Q spectrograms of the synchronized segments to learn a translation
dictionary of sound templates from A to A'. Finally, we apply the learned
templates as filters to the song B, and we mash up the translated filtered
components into the synthesized song B' using audio mosaicing. We showcase our
algorithm on several examples, including a synthesized cover version of Michael
Jackson's &quot;Bad&quot; by Alien Ant Farm, learned from the latter's &quot;Smooth Criminal&quot;
cover.'
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06469</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06469</id><created>2018-06-17</created><authors><author><keyname>Kidane</keyname><forenames>Hiliwi Leake</forenames></author><author><keyname>Bricq</keyname><forenames>Stephanie</forenames></author><author><keyname>Lalande</keyname><forenames>Alain</forenames></author></authors><title>Sigmoid function based intensity transformation for parameter
  initialization in MRI-PET Registration Tool for Preclinical Studies</title><categories>eess.IV</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images from Positron Emission Tomography (PET) deliver functional data such
as perfusion and metabolism. On the other hand, images from Magnetic Resonance
Imaging (MRI) provide information describing anatomical structures. Fusing the
complementary information from the two modalities is helpful in oncology. In
this project, we implemented a complete tool allowing semi-automatic MRI-PET
registration for small animal imaging in the preclinical studies. A two-stage
hierarchical registration approach is proposed. First, a global affine
registration is applied. For robust and fast registration, principal component
analysis (PCA) is used to compute the initial parameters for the global affine
registration. Since, only the low intensities in the PET volume reveal the
anatomic information on the MRI scan, we proposed a non-uniform intensity
transformation to the PET volume to enhance the contrast of the low intensity.
This helps to improve the computation of the centroid and principal axis by
increasing the contribution of the low intensities. Then, the globally
registered image is given as input to the second stage which is a local
deformable registration (B-spline registration). Mutual information is used as
metric function for the optimization. A multi-resolution approach is used in
both stages. The registration algorithm is supported by graphical user
interface (GUI) and visualization methods so that the user can interact easily
with the process. The performance of the registration algorithm is validated by
two medical experts on seven different datasets on abdominal and brain areas
including noisy and difficult image volumes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06513</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06513</id><created>2018-06-18</created><authors><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Woodland</keyname><forenames>Philip</forenames></author></authors><title>Semi-tied Units for Efficient Gating in LSTM and Highway Networks</title><categories>cs.CL cs.LG eess.AS stat.ML</categories><comments>To appear in Proc. INTERSPEECH 2018, September 2-6, 2018, Hyderabad,
  India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gating is a key technique used for integrating information from multiple
sources by long short-term memory (LSTM) models and has recently also been
applied to other models such as the highway network. Although gating is
powerful, it is rather expensive in terms of both computation and storage as
each gating unit uses a separate full weight matrix. This issue can be severe
since several gates can be used together in e.g. an LSTM cell. This paper
proposes a semi-tied unit (STU) approach to solve this efficiency issue, which
uses one shared weight matrix to replace those in all the units in the same
layer. The approach is termed &quot;semi-tied&quot; since extra parameters are used to
separately scale each of the shared output values. These extra scaling factors
are associated with the network activation functions and result in the use of
parameterised sigmoid, hyperbolic tangent, and rectified linear unit functions.
Speech recognition experiments using British English multi-genre broadcast data
showed that using STUs can reduce the calculation and storage cost by a factor
of three for highway networks and four for LSTMs, while giving similar word
error rates to the original models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06629</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06629</id><created>2018-06-18</created><authors><author><keyname>Yang</keyname><forenames>Xiuzhu</forenames></author><author><keyname>Yin</keyname><forenames>Wenfeng</forenames></author><author><keyname>Li</keyname><forenames>Lei</forenames></author><author><keyname>Zhang</keyname><forenames>Lin</forenames></author></authors><title>Dense People Counting Using IR-UWB Radar with a Hybrid Feature
  Extraction Method</title><categories>eess.SP</categories><doi>10.1109/LGRS.2018.2869287</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People counting is one of the hottest issues in sensing applications. The
impulse radio ultra-wideband (IR-UWB) radar has been extensively applied to
count people, providing a device-free solution without illumination and privacy
concerns. However, performance of current solutions is limited in congested
environments due to the superposition and obstruction of signals. In this
letter, a hybrid feature extraction method based on curvelet transform and
distance bin is proposed. 2-D radar matrix features are extracted in multiple
scales and multiple angles by applying the curvelet transform. Furthermore, the
distance bin is introduced by dividing each row of the matrix into several bins
along the propagating distance to select features. The radar signal dataset in
three dense scenarios is constructed, including people randomly walking in the
constrained area with densities of 3 and 4 persons per square meter, and
queueing with an average distance of 10 centimeters. The number of people is up
to 20 in the dataset. Four classifiers including decision tree, AdaBoost,
random forest and neural network are compared to validate the hybrid features,
and random forest performs the highest accuracies of all above 97% in three
dense scenarios. Moreover, to ensure the reliability of the hybrid features,
three other features including cluster features, activity features and CNN
features are compared. The experimental results reveal that the proposed hybrid
feature extraction method exhibits stable performance with significantly
superior effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06641</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06641</id><created>2018-06-18</created><updated>2018-08-14</updated><authors><author><keyname>Greiff</keyname><forenames>Christian</forenames></author><author><keyname>Mateos-N&#xfa;&#xf1;ez</keyname><forenames>David</forenames></author><author><keyname>Gonz&#xe1;lez-Huici</keyname><forenames>Mar&#xed;a A.</forenames></author><author><keyname>Br&#xfc;ggenwirth</keyname><forenames>Stefan</forenames></author></authors><title>Adaptive transmission for radar arrays using Weiss-Weinstein bounds</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for adaptive selection of pulse repetition frequency
or antenna activations for Doppler and DoA estimation. The adaptation is
performed sequentially using a Bayesian filter, responsible for updating the
belief on parameters, and a controller, responsible for selecting transmission
variables for the next measurement by optimizing a prediction of the estimation
error. This selection optimizes the Weiss-Weinstein bound for a
multi-dimensional frequency estimation model based on array measurements of a
narrow-band far-field source. A particle filter implements the update of the
posterior distribution after each new measurement is taken, and this posterior
is further approximated by a Gaussian or a uniform distribution for which
computationally fast expressions of the Weiss-Weinstein bound are analytically
derived. We characterize the controller's optimal choices in terms of SNR and
variance of the current belief, discussing their properties in terms of the
ambiguity function and comparing them with optimal choices of other
Weiss-Weinstein bound constructions in the literature. The resulting algorithms
are analyzed in simulations where we showcase a practically feasible real-time
evaluation based on look-up tables or small neural networks trained off-line.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06676</identifier>
 <datestamp>2018-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06676</id><created>2018-06-18</created><updated>2018-10-03</updated><authors><author><keyname>Vogl</keyname><forenames>Richard</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author><author><keyname>Knees</keyname><forenames>Peter</forenames></author></authors><title>Towards multi-instrument drum transcription</title><categories>cs.SD cs.IR cs.NE eess.AS</categories><comments>Published in Proceedings of the 21th International Conference on
  Digital Audio Effects (DAFx18), 4 - 8 September, 2018, Aveiro, Portugal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic drum transcription, a subtask of the more general automatic music
transcription, deals with extracting drum instrument note onsets from an audio
source. Recently, progress in transcription performance has been made using
non-negative matrix factorization as well as deep learning methods. However,
these works primarily focus on transcribing three drum instruments only: snare
drum, bass drum, and hi-hat. Yet, for many applications, the ability to
transcribe more drum instruments which make up standard drum kits used in
western popular music would be desirable. In this work, convolutional and
convolutional recurrent neural networks are trained to transcribe a wider range
of drum instruments. First, the shortcomings of publicly available datasets in
this context are discussed. To overcome these limitations, a larger synthetic
dataset is introduced. Then, methods to train models using the new dataset
focusing on generalization to real world data are investigated. Finally, the
trained models are evaluated on publicly available datasets and results are
discussed. The contributions of this work comprise: (i.) a large-scale
synthetic dataset for drum transcription, (ii.) first steps towards an
automatic drum transcription system that supports a larger range of instruments
by evaluating and discussing training setups and the impact of datasets in this
context, and (iii.) a publicly available set of trained models for drum
transcription. Additional materials are available at
http://ifs.tuwien.ac.at/~vogl/dafx2018
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06703</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06703</id><created>2018-06-15</created><authors><author><keyname>Mohanty</keyname><forenames>Vaibhav</forenames></author></authors><title>A 5-Dimensional Tonnetz for Nearly Symmetric Hexachords</title><categories>math.HO cs.SD eess.AS</categories><msc-class>00A65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard 2-dimensional Tonnetz describes parsimonious voice-leading
connections between major and minor triads as the 3-dimensional Tonnetz does
for dominant seventh and half-diminished seventh chords. In this paper, I
present a geometric model for a 5-dimensional Tonnetz for parsimonious
voice-leading between nearly symmetric hexachords of the mystic-Wozzeck genus.
Cartesian coordinates for points on this discretized grid, generalized
coordinate collections for 5-simplices corresponding to mystic and Wozzeck
chords, and the geometric nearest-neighbors of a selected chord are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06773</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06773</id><created>2018-06-18</created><updated>2018-06-19</updated><authors><author><keyname>Gong</keyname><forenames>Rong</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Towards an efficient deep learning model for musical onset detection</title><categories>cs.SD cs.IR eess.AS</categories><comments>Paper rejected by the 19th International Society for Music
  Information Retrieval Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient and reproducible deep learning model
for musical onset detection (MOD). We first review the state-of-the-art deep
learning models for MOD, and identify their shortcomings and challenges: (i)
the lack of hyper-parameter tuning details, (ii) the non-availability of code
for training models on other datasets, and (iii) ignoring the network
capability when comparing different architectures. Taking the above issues into
account, we experiment with seven deep learning architectures. The most
efficient one achieves equivalent performance to our implementation of the
state-of-the-art architecture. However, it has only 28.3% of the total number
of trainable parameters compared to the state-of-the-art. Our experiments are
conducted using two different datasets: one mainly consists of instrumental
music excerpts, and another developed by ourselves includes only solo singing
voice excerpts. Further, inter-dataset transfer learning experiments are
conducted. The results show that the model pre-trained on one dataset fails to
detect onsets on another dataset, which denotes the importance of providing the
implementation code to enable re-training the model for a different dataset.
Datasets, code and a Jupyter notebook running on Google Colab are publicly
available to make this research understandable and easy to reproduce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06779</identifier>
 <datestamp>2018-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06779</id><created>2018-06-18</created><authors><author><keyname>Gerazov</keyname><forenames>Branislav</forenames></author><author><keyname>Bailly</keyname><forenames>G&#xe9;rard</forenames></author><author><keyname>Xu</keyname><forenames>Yi</forenames></author></authors><title>A Weighted Superposition of Functional Contours Model for Modelling
  Contextual Prominence of Elementary Prosodic Contours</title><categories>eess.AS cs.SD</categories><comments>Accepted for publication at INTERSPEECH 2018</comments><journal-ref>Proceedings of Interspeech 2018</journal-ref><doi>10.21437/Interspeech.2018</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The way speech prosody encodes linguistic, paralinguistic and non-linguistic
information via multiparametric representations of the speech signals is still
an open issue. The Superposition of Functional Contours (SFC) model proposes to
decompose prosody into elementary multiparametric functional contours through
the iterative training of neural network contour generators using
analysis-by-synthesis. Each generator is responsible for computing
multiparametric contours that encode one given linguistic, paralinguistic and
non-linguistic information on a variable scope of rhythmic units. The
contributions of all generators' outputs are then overlapped and added to
produce the prosody of the utterance. We propose an extension of the contour
generators that allows them to model the prominence of the elementary contours
based on contextual information. WSFC jointly learns the patterns of the
elementary multiparametric functional contours and their weights dependent on
the contours' contexts. The experimental results show that the proposed
weighted SFC (WSFC) model can successfully capture contour prominence and thus
improve SFC modelling performance. The WSFC is also shown to be effective at
modelling the impact of attitudes on the prominence of functional contours
cuing syntactic relations in French, and that of emphasis on the prominence of
tone contours in Chinese.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06812</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06812</id><created>2018-06-18</created><authors><author><keyname>Kawahara</keyname><forenames>Hideki</forenames></author><author><keyname>Sakakibara</keyname><forenames>Ken-Ichi</forenames></author><author><keyname>Morise</keyname><forenames>Masanori</forenames></author><author><keyname>Banno</keyname><forenames>Hideki</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author><author><keyname>Irino</keyname><forenames>Toshio</forenames></author></authors><title>Frequency domain variants of velvet noise and their application to
  speech processing and synthesis: with appendices</title><categories>cs.SD eess.AS eess.SP</categories><comments>11 pages, 20 figures, and 1 table, Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new excitation source signal for VOCODERs and an all-pass
impulse response for post-processing of synthetic sounds and pre-processing of
natural sounds for data-augmentation. The proposed signals are variants of
velvet noise, which is a sparse discrete signal consisting of a few non-zero (1
or -1) elements and sounds smoother than Gaussian white noise. One of the
proposed variants, FVN (Frequency domain Velvet Noise) applies the procedure to
generate a velvet noise on the cyclic frequency domain of DFT (Discrete Fourier
Transform). Then, by smoothing the generated signal to design the phase of an
all-pass filter followed by inverse Fourier transform yields the proposed FVN.
Temporally variable frequency weighted mixing of FVN generated by frozen and
shuffled random number provides a unified excitation signal which can span from
random noise to a repetitive pulse train. The other variant, which is an
all-pass impulse response, significantly reduces &quot;buzzy&quot; impression of VOCODER
output by filtering. Finally, we will discuss applications of the proposed
signal for watermarking and psychoacoustic research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06823</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06823</id><created>2018-06-18</created><updated>2018-12-12</updated><authors><author><keyname>Hersche</keyname><forenames>Michael</forenames></author><author><keyname>Rellstab</keyname><forenames>Tino</forenames></author><author><keyname>Schiavone</keyname><forenames>Pasquale Davide</forenames></author><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author><author><keyname>Rahimi</keyname><forenames>Abbas</forenames></author></authors><title>Fast and Accurate Multiclass Inference for MI-BCIs Using Large
  Multiscale Temporal and Spectral Features</title><categories>eess.SP q-bio.NC</categories><comments>Published as a conference paper at the IEEE European Signal
  Processing Conference (EUSIPCO), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate, fast, and reliable multiclass classification of
electroencephalography (EEG) signals is a challenging task towards the
development of motor imagery brain-computer interface (MI-BCI) systems. We
propose enhancements to different feature extractors, along with a support
vector machine (SVM) classifier, to simultaneously improve classification
accuracy and execution time during training and testing. We focus on the
well-known common spatial pattern (CSP) and Riemannian covariance methods, and
significantly extend these two feature extractors to multiscale temporal and
spectral cases. The multiscale CSP features achieve 73.70$\pm$15.90% (mean$\pm$
standard deviation across 9 subjects) classification accuracy that surpasses
the state-of-the-art method [1], 70.6$\pm$14.70%, on the 4-class BCI
competition IV-2a dataset. The Riemannian covariance features outperform the
CSP by achieving 74.27$\pm$15.5% accuracy and executing 9x faster in training
and 4x faster in testing. Using more temporal windows for Riemannian features
results in 75.47$\pm$12.8% accuracy with 1.6x faster testing than CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.06994</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.06994</id><created>2018-06-18</created><authors><author><keyname>Qiu</keyname><forenames>Yu</forenames></author><author><keyname>Qu</keyname><forenames>Daiming</forenames></author><author><keyname>Chen</keyname><forenames>Da</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author></authors><title>Smoothed SVD-based Beamforming for FBMC/OQAM Systems Based on Frequency
  Spreading</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combination of singular value decomposition (SVD)-based beamforming and
filter bank multicarrier with offset quadrature amplitude modulation
(FBMC/OQAM) has not been successful to date. The difficulty of this combination
is that, the beamformers may experience significant changes between adjacent
subchannels, therefore destroy the orthogonality among FBMC/OQAM real-valued
symbols, even under channels with moderate frequency selectivity. In this
paper, we address this problem from two aspects: i) an SVD-FS-FBMC architecture
is adopted to support beamforming with finer granularity in frequency domain,
based on the frequency spreading FBMC (FS-FBMC) structure, i.e., beamforming on
FS-FBMC tones rather than on subchannels; ii) criterion and methods are
proposed to smooth the beamformers from tone to tone. The proposed finer
beamforming and smoothing greatly improve the smoothness of beamformers,
therefore effectively suppress the leaked ICI/ISI. Simulations are conducted
under the scenario of IEEE 802.11n wireless LAN. Results show that the proposed
SVD-FS-FBMC system shares close BER performance with its orthogonal frequency
division multiplexing (OFDM) counterpart under the frequency selective
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07050</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07050</id><created>2018-06-19</created><authors><author><keyname>Liu</keyname><forenames>Y.</forenames></author><author><keyname>Zhang</keyname><forenames>Y.</forenames></author><author><keyname>Huang</keyname><forenames>Q.</forenames></author><author><keyname>Kundu</keyname><forenames>S.</forenames></author><author><keyname>Tang</keyname><forenames>Y.</forenames></author><author><keyname>James</keyname><forenames>D.</forenames></author><author><keyname>Etingov</keyname><forenames>P.</forenames></author><author><keyname>Mitra</keyname><forenames>B.</forenames></author><author><keyname>Chassin</keyname><forenames>D.</forenames></author></authors><title>Impact of Building-Level Motor Protection on Power System Transient
  Behaviors</title><categories>eess.SP</categories><comments>6 figures, 2 tables, 5 pages, IEEE PES General Meeting 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protection strategies for transmission and distribution systems have been
extensively investigated to facilitate better coordination of physical
protection devices. A diverse range of functional motors with dedicated
protection schemes are being used more and more in commercial, residential, and
industrial buildings. This paper focuses on simulating several of the most
popular protection schemes using the ElectroMagnetic Transient Program (EMTP)
model for three-phase and single-phase induction motors in existing commercial
buildings connected to typical distribution feeders. To investigate the
behaviors of single-phase motors stalling, the actions of motor protection and
reconnections, and the impacts of device-level protection on system-level
dynamics, we imposed voltage depressions at the head of a feeder fully loaded
with functional induction motors. Several distribution feeders are represented
in a standard IEEE 39-bus transmission system to simulate fault-induced delayed
voltage recovery (FIDVR) and explore mitigation strategies by optimally
configuring the building-level motor protection settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07098</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07098</id><created>2018-06-19</created><updated>2018-06-21</updated><authors><author><keyname>Zeghidour</keyname><forenames>Neil</forenames></author><author><keyname>Usunier</keyname><forenames>Nicolas</forenames></author><author><keyname>Synnaeve</keyname><forenames>Gabriel</forenames></author><author><keyname>Collobert</keyname><forenames>Ronan</forenames></author><author><keyname>Dupoux</keyname><forenames>Emmanuel</forenames></author></authors><title>End-to-End Speech Recognition From the Raw Waveform</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for presentation at Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art speech recognition systems rely on fixed, hand-crafted
features such as mel-filterbanks to preprocess the waveform before the training
pipeline. In this paper, we study end-to-end systems trained directly from the
raw waveform, building on two alternatives for trainable replacements of
mel-filterbanks that use a convolutional architecture. The first one is
inspired by gammatone filterbanks (Hoshen et al., 2015; Sainath et al, 2015),
and the second one by the scattering transform (Zeghidour et al., 2017). We
propose two modifications to these architectures and systematically compare
them to mel-filterbanks, on the Wall Street Journal dataset. The first
modification is the addition of an instance normalization layer, which greatly
improves on the gammatone-based trainable filterbanks and speeds up the
training of the scattering-based filterbanks. The second one relates to the
low-pass filter used in these approaches. These modifications consistently
improve performances for both approaches, and remove the need for a careful
initialization in scattering-based trainable filterbanks. In particular, we
show a consistent improvement in word error rate of the trainable filterbanks
relatively to comparable mel-filterbanks. It is the first time end-to-end
models trained from the raw signal significantly outperform mel-filterbanks on
a large vocabulary task under clean recording conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07220</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07220</id><created>2018-06-19</created><authors><author><keyname>Pizzo</keyname><forenames>Andrea</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author></authors><title>Solving Fractional Polynomial Problems by Polynomial Optimization Theory</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 2 figures, 1 table, submitted to Signal Processing Letters</comments><doi>10.1109/LSP.2018.2864620</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work aims to introduce the framework of polynomial optimization theory
to solve fractional polynomial problems (FPPs). Unlike other widely used
optimization frameworks, the proposed one applies to a larger class of FPPs,
not necessarily defined by concave and convex functions. An iterative algorithm
that is provably convergent and enjoys asymptotic optimality properties is
proposed. Numerical results are used to validate its accuracy in the
non-asymptotic regime when applied to the energy efficiency maximization in
multiuser multiple-input multiple-output communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07271</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07271</id><created>2018-06-18</created><updated>2019-05-09</updated><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Age-Minimal Transmission for Energy Harvesting Sensors with Finite
  Batteries: Online Policies</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, June 2018.
  arXiv admin note: text overlap with arXiv:1802.02129, arXiv:1802.01563</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An energy-harvesting sensor node that is sending status updates to a
destination is considered. The sensor is equipped with a battery of finite size
to save its incoming energy, and consumes one unit of energy per status update
transmission, which is delivered to the destination instantly over an
error-free channel. The setting is online in which the harvested energy is
revealed to the sensor causally over time, and the goal is to design status
update transmission policy such that the long term average age of information
(AoI) is minimized. AoI is defined as the time elapsed since the latest update
has reached at the destination. Two energy arrival models are considered: a
random battery recharge (RBR) model, and an incremental battery recharge (IBR)
model. In both models, energy arrives according to a Poisson process with unit
rate, with values that completely fill up the battery in the RBR model, and
with values that fill up the battery incrementally, unit-by-unit, in the IBR
model. The key approach to characterizing the optimal status update policy for
both models is showing the optimality of renewal policies, in which the
inter-update times follow a specific renewal process that depends on the energy
arrival model and the battery size. It is then shown that the optimal renewal
policy has an energy-dependent threshold structure, in which the sensor sends a
status update only if the AoI grows above a certain threshold that depends on
the energy available. For both the RBR and the IBR models, the optimal
energy-dependent thresholds are characterized explicitly, i.e., in closed-form,
in terms of the optimal long term average AoI. It is also shown that the
optimal thresholds are monotonically decreasing in the energy available in the
battery, and that the smallest threshold, which comes in effect when the
battery is full, is equal to the optimal long term average AoI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07284</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07284</id><created>2018-06-02</created><authors><author><keyname>Dkhil</keyname><forenames>Mejdi Ben</forenames></author><author><keyname>Neji</keyname><forenames>Mohamed</forenames></author><author><keyname>Wali</keyname><forenames>Ali</forenames></author><author><keyname>Alimi</keyname><forenames>Adel M.</forenames></author></authors><title>A new approach for a safe car assistance system</title><categories>eess.SP cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drowsiness, which is the state when drivers do not have scheduled breaks
while traveling long distances, is the main reason behind serious motorway
accidents. Accordingly, experts claim that drowsy state is hard to be
recognized early enough to prevent serious accidents that may lead even to road
deaths. In this work, we propose a new drowsiness state detection system based
on physiological signals and eye blinking. An experiment has been directed to
justify the utility of the proposed approach. This system uses a smart video
camera that takes drivers faces images and supervises the eye blink (open and
close); also, it uses the Emotiv EPOC headset to acquire the
electroencephalogram (EEG) signals. Eye detection is done by Viola and Jones
technique, EEG. Finally, we have chosen the fuzzy logic techniques to classify
the EEG signals and eye blinking detection to analyze the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07286</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07286</id><created>2018-06-06</created><authors><author><keyname>Dkhil</keyname><forenames>Mejdi Ben</forenames></author><author><keyname>Wali</keyname><forenames>Ali</forenames></author><author><keyname>Alimi</keyname><forenames>Adel M.</forenames></author></authors><title>Drowsy Driver Detection by EEG Analysis Using Fast Fourier Transform</title><categories>eess.SP cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we try to analyze drowsiness which is a major factor in many
traffic accidents due to the clear decline in the attention and recognition of
danger drivers. The object of this work is to develop an automatic method to
evaluate the drowsiness stage by analysis of EEG signals records. The absolute
band power of the EEG signal was computed by taking the Fast Fourier Transform
(FFT) of the time series signal. Finally, the algorithm developed in this work
has been improved on eight samples from the Physionet sleep-EDF database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07407</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07407</id><created>2018-06-19</created><authors><author><keyname>Menne</keyname><forenames>Tobias</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Ralf</forenames></author><author><keyname>Ney</keyname><forenames>Hermann</forenames></author></authors><title>Speaker Adapted Beamforming for Multi-Channel Automatic Speech
  Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>submitted to IEEE SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents, in the context of multi-channel ASR, a method to adapt a
mask based, statistically optimal beamforming approach to a speaker of
interest. The beamforming vector of the statistically optimal beamformer is
computed by utilizing speech and noise masks, which are estimated by a neural
network. The proposed adaptation approach is based on the integration of the
beamformer, which includes the mask estimation network, and the acoustic model
of the ASR system. This allows for the propagation of the training error, from
the acoustic modeling cost function, all the way through the beamforming
operation and through the mask estimation network. By using the results of a
first pass recognition and by keeping all other parameters fixed, the mask
estimation network can therefore be fine tuned by retraining. Utterances of a
speaker of interest can thus be used in a two pass approach, to optimize the
beamforming for the speech characteristics of that specific speaker. It is
shown that this approach improves the ASR performance of a state-of-the-art
multi-channel ASR system on the CHiME-4 data. Furthermore the effect of the
adaptation on the estimated speech masks is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07440</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07440</id><created>2018-06-19</created><authors><author><keyname>Massaroppe</keyname><forenames>Lucas</forenames></author><author><keyname>Baccal&#xe1;</keyname><forenames>Luiz A.</forenames></author></authors><title>Kernel Methods for Nonlinear Connectivity Detection</title><categories>eess.SP math.DS stat.AP stat.OT</categories><comments>14 pages, 14 figures, preliminary version being prepared for
  submission to a refereed journal</comments><doi>10.3390/e21060610</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the presence of nonlinear coupling between time
series may be detected employing kernel feature space representations alone
dispensing with the need to go back to solve the pre-image problem to gauge
model adequacy. As a consequence, the canonical methodology for model
construction, diagnostics, and Granger connectivity inference applies with no
change other than computation using kernels in lieu of second-order moments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07456</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07456</id><created>2018-06-19</created><authors><author><keyname>Lohani</keyname><forenames>Sanjaya</forenames></author><author><keyname>Glasser</keyname><forenames>Ryan T.</forenames></author></authors><title>Turbulence correction with artificial neural networks</title><categories>eess.SP physics.optics quant-ph</categories><comments>4 pages, 4 figures, 1 table</comments><journal-ref>Optics Letters Vol. 43, Issue 11, pp. 2611-2614 (2018)</journal-ref><doi>10.1364/OL.43.002611</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design an optical feedback network making use of machine learning
techniques and demonstrate via simulations its ability to correct for the
effects of turbulent propagation on optical modes. This artificial neural
network scheme only relies on measuring the intensity profile of the distorted
modes, making the approach simple and robust. The network results in the
generation of various mode profiles at the transmitter that, after propagation
through turbulence, closely resemble the desired target mode. The corrected
optical mode profiles at the receiver are found to be nearly identical to the
desired profiles, with near-zero mean square error indices. We are hopeful that
the present results combining the fields of machine learning and optical
communications will greatly enhance the robustness of free-space optical links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07506</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07506</id><created>2018-06-19</created><updated>2018-06-27</updated><authors><author><keyname>Fonseca</keyname><forenames>Eduardo</forenames></author><author><keyname>Gong</keyname><forenames>Rong</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>A Simple Fusion of Deep and Shallow Learning for Acoustic Scene
  Classification</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>accepted to SMC 2018; updated Figure 7, results unchanged</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the past, Acoustic Scene Classification systems have been based on hand
crafting audio features that are input to a classifier. Nowadays, the common
trend is to adopt data driven techniques, e.g., deep learning, where audio
representations are learned from data. In this paper, we propose a system that
consists of a simple fusion of two methods of the aforementioned types: a deep
learning approach where log-scaled mel-spectrograms are input to a
convolutional neural network, and a feature engineering approach, where a
collection of hand-crafted features is input to a gradient boosting machine. We
first show that both methods provide complementary information to some extent.
Then, we use a simple late fusion strategy to combine both methods. We report
classification accuracy of each method individually and the combined system on
the TUT Acoustic Scenes 2017 dataset. The proposed fused system outperforms
each of the individual methods and attains a classification accuracy of 72.8%
on the evaluation set, improving the baseline system by 11.8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07546</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07546</id><created>2018-06-20</created><authors><author><keyname>Mitra</keyname><forenames>Bhaskar</forenames></author><author><keyname>Chowdhury</keyname><forenames>Badrul</forenames></author></authors><title>Comparative Analysis of Hybrid DC Breaker and Assembly HVDC Breaker</title><categories>eess.SP</categories><comments>6 pagess, 14 figures, 2 tables, 49th North American Power Symposium
  (NAPS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voltage Source Converters (VSC) are becoming more common in modern High
Voltage DC (HVDC) transmission systems. One of the major challenges in a
multi-terminal VSCHVDC is protection against DC side faults. Two major designs,
namely, the hybrid DC breaker and the assembly HVDC breaker, are compared for
operational behavior, speed of operation and current carrying capability. The
Dual Modular Redundancy (DMR) technique is utilized for decision making of a
fault scenario. This uses a dual voting system when one result contradicts the
other. This helps in the design of a fail-safe mechanism for the operation of
both types of breakers. Current threshold combined with directional change is
considered for the breaker operation. A three-terminal bipolar VSC HVDC system
is designed in PSCAD/EMTDC and simulation results are utilized to draw a
comparison of the two different designs of DC breakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07566</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07566</id><created>2018-06-20</created><authors><author><keyname>Reddy</keyname><forenames>K. Pavan Kumar</forenames></author><author><keyname>Shiva</keyname><forenames>K. Lakhan</forenames></author><author><keyname>Abhilash</keyname><forenames>K.</forenames></author><author><keyname>Yoganandam</keyname><forenames>Y.</forenames></author></authors><title>Database Assisted Automatic Modulation Classification Using Sequential
  Minimal Optimization</title><categories>eess.SP</categories><comments>5 pages, 2 figures, 18th International Symposium on Wireless Personal
  Multimedia Communications, Hyderabad, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have proposed a novel algorithm for identifying the
modulation scheme of an unknown incoming signal in order to mitigate the
interference with primary user in Cognitive Radio systems, which is facilitated
by using Automatic Modulation Classification (AMC) at the front end of Software
Defined Radio (SDR). In this study, we used computer simulations of analog and
digital modulations belonging to eleven classes. Spectral based features have
been used as input features for Sequential Minimal Optimization (SMO). These
features of primary users are stored in the database, then it matches the
unknown signal's features with those in the database. Built upon recently
proposed AMC, our new database approach inherits the benefits of SMO based
approach and makes it much more time efficient in classifying an unknown
signal, especially in the case of multiple modulation schemes to overcome the
issue of intense computations in constructing features. In various
applications, primary users own frequent wireless transmissions having limited
their feature size and save few computations. The SMO based classification
methodology proves to be over 99 \% accurate for SNR of 15 dB and accuracy of
classification is over 95 \% for low SNRs around 5dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07618</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07618</id><created>2018-06-20</created><authors><author><keyname>Calvet</keyname><forenames>Denis</forenames></author></authors><title>Back-end Electronics for Low Background and Medium Scale Physics
  Experiments Based on an Asymmetric Network</title><categories>eess.SP physics.ins-det</categories><comments>21st IEEE Real Time Conference, 9-15 June 2018, Colonial
  Williamsburg, Virginia, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detector readout architecture introduced in this paper is intended for
small to medium size physics experiments that have moderate bandwidth needs,
and applications that require an ultimately low background radioactivity for
the parts close to the detector. The first idea to simplify the readout system
and minimize material budget is to use a common fanout structure to transport
from the off-detector back-end electronics all the traffic required for the
synchronization, configuration and readout of the front-end electronics. The
second idea is to use between each front-end card and the back-end electronics
a point-to-point link that runs at the relatively low speed that suffices for
the target application. This broadens the possible choices for the physical
media of the communication links, e.g. glass fiber, plastic optical fiber, or
copper. This paper presents a communication protocol adequate for the proposed
asymmetric network and shows the design of a back-end unit capable of
controlling 32 front-end units at up to 12.8 Gbps of aggregate bandwidth using
an inexpensive commercial FPGA module where the large number of regular I/O
pins interface to the front-end links, while the few available multi-gigabit
per second capable transceivers are affected to the communication with the
upper stage of the DAQ system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07715</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07715</id><created>2018-06-08</created><authors><author><keyname>Lu</keyname><forenames>Weijia</forenames></author><author><keyname>Shuai</keyname><forenames>Jie</forenames></author><author><keyname>Gu</keyname><forenames>Shuyan</forenames></author><author><keyname>Xue</keyname><forenames>Joel</forenames></author></authors><title>Method to Annotate Arrhythmias by Deep Network</title><categories>eess.SP cs.CV cs.IR cs.LG</categories><doi>10.1109/Cybermatics_2018.2018.00307</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This study targets to automatically annotate on arrhythmia by deep network.
The investigated types include sinus rhythm, asystole (Asys), supraventricular
tachycardia (Tachy), ventricular flutter or fibrillation (VF/VFL), ventricular
tachycardia (VT). Methods: 13s limb lead ECG chunks from MIT malignant
ventricular arrhythmia database (VFDB) and MIT normal sinus rhythm database
were partitioned into subsets for 5-fold cross validation. These signals were
resampled to 200Hz, filtered to remove baseline wandering, projected to 2D gray
spectrum and then fed into a deep network with brand-new structure. In this
network, a feature vector for a single time point was retrieved by residual
layers, from which latent representation was extracted by variational
autoencoder (VAE). These front portions were trained to meet a certain
threshold in loss function, then fixed while training procedure switched to
remaining bidirectional recurrent neural network (RNN), the very portions to
predict an arrhythmia category. Attention windows were polynomial lumped on RNN
outputs for learning from details to outlines. And over sampling was employed
for imbalanced data. The trained model was wrapped into docker image for
deployment in edge or cloud. Conclusion: Promising sensitivities were achieved
in four arrhythmias and good precision rates in two ventricular arrhythmias
were also observed. Moreover, it was proven that latent representation by VAE,
can significantly boost the speed of convergence and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07741</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07741</id><created>2018-06-18</created><updated>2018-07-25</updated><authors><author><keyname>Heilmeyer</keyname><forenames>Felix A.</forenames></author><author><keyname>Schirrmeister</keyname><forenames>Robin T.</forenames></author><author><keyname>Fiederer</keyname><forenames>Lukas D. J.</forenames></author><author><keyname>V&#xf6;lker</keyname><forenames>Martin</forenames></author><author><keyname>Behncke</keyname><forenames>Joos</forenames></author><author><keyname>Ball</keyname><forenames>Tonio</forenames></author></authors><title>A large-scale evaluation framework for EEG deep learning architectures</title><categories>eess.SP cs.LG cs.NE q-bio.NC stat.ML</categories><comments>7 pages, 3 figures, final version accepted for presentation at IEEE
  SMC 2018 conference</comments><doi>10.1109/SMC.2018.00185</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  EEG is the most common signal source for noninvasive BCI applications. For
such applications, the EEG signal needs to be decoded and translated into
appropriate actions. A recently emerging EEG decoding approach is deep learning
with Convolutional or Recurrent Neural Networks (CNNs, RNNs) with many
different architectures already published. Here we present a novel framework
for the large-scale evaluation of different deep-learning architectures on
different EEG datasets. This framework comprises (i) a collection of EEG
datasets currently including 100 examples (recording sessions) from six
different classification problems, (ii) a collection of different EEG decoding
algorithms, and (iii) a wrapper linking the decoders to the data as well as
handling structured documentation of all settings and (hyper-) parameters and
statistics, designed to ensure transparency and reproducibility. As an
applications example we used our framework by comparing three publicly
available CNN architectures: the Braindecode Deep4 ConvNet, Braindecode Shallow
ConvNet, and two versions of EEGNet. We also show how our framework can be used
to study similarities and differences in the performance of different decoding
methods across tasks. We argue that the deep learning EEG framework as
described here could help to tap the full potential of deep learning for BCI
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07745</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07745</id><created>2018-06-18</created><updated>2018-12-04</updated><authors><author><keyname>Lees</keyname><forenames>W. Max</forenames></author><author><keyname>Wunderlich</keyname><forenames>Adam</forenames></author><author><keyname>Jeavons</keyname><forenames>Peter</forenames></author><author><keyname>Hale</keyname><forenames>Paul D.</forenames></author><author><keyname>Souryal</keyname><forenames>Michael R.</forenames></author></authors><title>Deep Learning Classification of 3.5 GHz Band Spectrograms with
  Applications to Spectrum Sensing</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the United States, the Federal Communications Commission has adopted rules
permitting commercial wireless networks to share spectrum with federal
incumbents in the 3.5~GHz Citizens Broadband Radio Service band. These rules
require commercial systems to vacate the band when sensors detect radars
operated by the U.S. military; a key example being the SPN-43 air traffic
control radar. Such sensors require highly-accurate detection algorithms to
meet their operating requirements. In this paper, using a library of over
14,000 3.5~GHz band spectrograms collected by a recent measurement campaign, we
investigate the performance of thirteen methods for SPN-43 radar detection.
Namely, we compare classical methods from signal detection theory and machine
learning to several deep learning architectures. We demonstrate that machine
learning algorithms appreciably outperform classical signal detection methods.
Specifically, we find that a three-layer convolutional neural network offers a
superior tradeoff between accuracy and computational complexity. Last, we apply
this three-layer network to generate descriptive statistics for the full
3.5~GHz spectrogram library. Our findings highlight potential weaknesses of
classical methods and strengths of modern machine learning algorithms for radar
detection in the 3.5~GHz band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07751</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07751</id><created>2018-06-19</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Corcoran</keyname><forenames>Peter</forenames></author></authors><title>Versatile Auxiliary Classifier with Generative Adversarial Network
  (VAC+GAN), Multi Class Scenarios</title><categories>cs.LG eess.IV stat.ML</categories><comments>arXiv admin note: substantial text overlap with arXiv:1805.00316</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional generators learn the data distribution for each class in a
multi-class scenario and generate samples for a specific class given the right
input from the latent space. In this work, a method known as &quot;Versatile
Auxiliary Classifier with Generative Adversarial Network&quot; for multi-class
scenarios is presented. In this technique, the Generative Adversarial Networks
(GAN)'s generator is turned into a conditional generator by placing a
multi-class classifier in parallel with the discriminator network and
backpropagate the classification error through the generator. This technique is
versatile enough to be applied to any GAN implementation. The results on two
databases and comparisons with other method are provided as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07778</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07778</id><created>2018-06-20</created><authors><author><keyname>Khan</keyname><forenames>Irfan</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Vikram</forenames></author></authors><title>Effect of the Approximation of Voltage Angle Difference on the OPF
  algorithms in the Power Network</title><categories>eess.SP</categories><comments>27 Pages, 8 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In real-time applications involving power flow equations, measuring of
voltage phase angle difference of the connected buses is essential. However, it
needs special techniques to measure voltage angle difference, which may enlarge
the computational burden of the working controller and hence, may make the
control process slow. In this paper, authors investigate the approximation of
angle difference to zero and its effects on the convergence speed and optimal
solutions of a distributed algorithm. To test this approximation, a distributed
nonlinear algorithm is proposed to optimize the multi-objective function which
includes power loss, voltage deviation and cost of reactive power generation,
by controlling the reactive power generations from distributed generators.
Authors investigate the reasons which may outlaw making this approximation and
finally, propose a condition to make such approximation. Importance of making
this approximation in terms of fast convergence of the algorithms is also
illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07789</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07789</id><created>2018-06-20</created><authors><author><keyname>Parcollet</keyname><forenames>Titouan</forenames></author><author><keyname>Zhang</keyname><forenames>Ying</forenames></author><author><keyname>Morchid</keyname><forenames>Mohamed</forenames></author><author><keyname>Trabelsi</keyname><forenames>Chiheb</forenames></author><author><keyname>Linar&#xe8;s</keyname><forenames>Georges</forenames></author><author><keyname>De Mori</keyname><forenames>Renato</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Quaternion Convolutional Neural Networks for End-to-End Automatic Speech
  Recognition</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Accepted at INTERSPEECH 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the connectionist temporal classification (CTC) model coupled with
recurrent (RNN) or convolutional neural networks (CNN), made it easier to train
speech recognition systems in an end-to-end fashion. However in real-valued
models, time frame components such as mel-filter-bank energies and the cepstral
coefficients obtained from them, together with their first and second order
derivatives, are processed as individual elements, while a natural alternative
is to process such components as composed entities. We propose to group such
elements in the form of quaternions and to process these quaternions using the
established quaternion algebra. Quaternion numbers and quaternion neural
networks have shown their efficiency to process multidimensional inputs as
entities, to encode internal dependencies, and to solve many tasks with less
learning parameters than real-valued models. This paper proposes to integrate
multiple feature views in quaternion-valued convolutional neural network
(QCNN), to be used for sequence-to-sequence mapping with the CTC model.
Promising results are reported using simple QCNNs in phoneme recognition
experiments with the TIMIT corpus. More precisely, QCNNs obtain a lower phoneme
error rate (PER) with less learning parameters than a competing model based on
real-valued CNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07913</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07913</id><created>2018-06-20</created><authors><author><keyname>Santos</keyname><forenames>Eonassis O.</forenames></author><author><keyname>Martins</keyname><forenames>Joberto S. B.</forenames></author></authors><title>Distribution Power Network Reconfiguration in the Smart Grid</title><categories>eess.SP cs.NI</categories><comments>13 pages</comments><journal-ref>International Seminar on Politics, Incentives, Technology and
  Regulation of Smart Grids, Rio de Janeiro, 2017</journal-ref><doi>10.5281/zenodo.1066442</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The power network reconfiguration algorithm with an &quot;R&quot; modeling approach
evaluates its behavior in computing new reconfiguration topologies for the
power grid in the context of the Smart Grid. The power distribution network
modelling with the R language is used to represent the network and support
computation of different algorithm configurations for the evaluation of new
reconfiguration topologies. This work presents a reconfiguration solution of
distribution networks, with a construction of an algorithm that receiving the
network configuration data and the nodal measurements and from these data build
a radial network, after this and using a branch exchange algorithm And
verifying the best configuration of the network through artificial
intelligence, so that there are no unnecessary changes during the operation,
and applied an algorithm that analyses the load levels, to suggest changes in
the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.07924</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.07924</id><created>2018-06-20</created><authors><author><keyname>Nimr</keyname><forenames>Ahmad</forenames></author><author><keyname>Matthe</keyname><forenames>Maximilian</forenames></author><author><keyname>Zhang</keyname><forenames>Dan</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Optimal Radix-2 FFT Compatible Filters for GFDM</title><categories>eess.SP</categories><doi>10.1109/LCOMM.2017.2687926</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a linear waveform, a finite condition number of the corresponding
modulation matrix is necessary for the waveform to convey the message without
ambiguity. Based on the Zak transform, this letter presents an analytical
approach to compute the condition number of the modulation matrix for the
multi-carrier waveform generalized frequency division multiplexing (GFDM). On
top, we further propose a filter design that yields non-singular modulation
matrices for an even number of subcarriers and subsymbols, which is not
achievable for any previous work. Such new design has significant impact on
implementation complexity, as the radix-2 FFT operations for conventional
multicarrier waveforms can readily be employed for GFDM. Additionally, we
analytically derive the optimal filter that minimizes the condition number.We
further numerically evaluate the signal-to-interference ratio (SIR) and
noise-enhancement factor (NEF) for matched filter (MF) and zero-forcing (ZF)
GFDM receivers for such design, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08002</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08002</id><created>2018-06-20</created><authors><author><keyname>Antognini</keyname><forenames>Joseph</forenames></author><author><keyname>Hoffman</keyname><forenames>Matt</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author></authors><title>Synthesizing Diverse, High-Quality Audio Textures</title><categories>cs.SD eess.AS</categories><comments>10 pages, submitted to TASLP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Texture synthesis techniques based on matching the Gram matrix of feature
activations in neural networks have achieved spectacular success in the image
domain. In this paper we extend these techniques to the audio domain. We
demonstrate that synthesizing diverse audio textures is challenging, and argue
that this is because audio data is relatively low-dimensional. We therefore
introduce two new terms to the original Grammian loss: an autocorrelation term
that preserves rhythm, and a diversity term that encourages the optimization
procedure to synthesize unique textures. We quantitatively study the impact of
our design choices on the quality of the synthesized audio by introducing an
audio analogue to the Inception loss which we term the VGGish loss. We show
that there is a trade-off between the diversity and quality of the synthesized
audio using this technique. We additionally perform a number of experiments to
qualitatively study how these design choices impact the quality of the
synthesized audio. Finally we describe the implications of these results for
the problem of audio style transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08086</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08086</id><created>2018-06-21</created><authors><author><keyname>Gang</keyname><forenames>Arpita</forenames></author><author><keyname>Biyani</keyname><forenames>Pravesh</forenames></author><author><keyname>Soni</keyname><forenames>Akshay</forenames></author></authors><title>Towards Automated Single Channel Source Separation using Neural Networks</title><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Many applications of single channel source separation (SCSS) including
automatic speech recognition (ASR), hearing aids etc. require an estimation of
only one source from a mixture of many sources. Treating this special case as a
regular SCSS problem where in all constituent sources are given equal priority
in terms of reconstruction may result in a suboptimal separation performance.
In this paper, we tackle the one source separation problem by suitably
modifying the orthodox SCSS framework and focus only on one source at a time.
The proposed approach is a generic framework that can be applied to any
existing SCSS algorithm, improves performance, and scales well when there are
more than two sources in the mixture unlike most existing SCSS methods.
Additionally, existing SCSS algorithms rely on fine hyper-parameter tuning
hence making them difficult to use in practice. Our framework takes a step
towards automatic tuning of the hyper-parameters thereby making our method
better suited for the mixture to be separated and thus practically more useful.
We test our framework on a neural network based algorithm and the results show
an improved performance in terms of SDR and SAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08101</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08101</id><created>2018-06-21</created><authors><author><keyname>Chan</keyname><forenames>Kelvin C. K.</forenames></author><author><keyname>Chan</keyname><forenames>Raymond H.</forenames></author><author><keyname>Nikolova</keyname><forenames>Mila</forenames></author></authors><title>A Convex Model for Edge-Histogram Specification with Applications to
  Edge-preserving Smoothing</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of edge-histogram specification is to find an image whose edge image
has a histogram that matches a given edge-histogram as much as possible.
Mignotte has proposed a non-convex model for the problem [M. Mignotte. An
energy-based model for the image edge-histogram specification problem. IEEE
Transactions on Image Processing, 21(1):379--386, 2012]. In his work, edge
magnitudes of an input image are first modified by histogram specification to
match the given edge-histogram. Then, a non-convex model is minimized to find
an output image whose edge-histogram matches the modified edge-histogram. The
non-convexity of the model hinders the computations and the inclusion of useful
constraints such as the dynamic range constraint. In this paper, instead of
considering edge magnitudes, we directly consider the image gradients and
propose a convex model based on them. Furthermore, we include additional
constraints in our model based on different applications. The convexity of our
model allows us to compute the output image efficiently using either
Alternating Direction Method of Multipliers or Fast Iterative
Shrinkage-Thresholding Algorithm. We consider several applications in
edge-preserving smoothing including image abstraction, edge extraction, details
exaggeration, and documents scan-through removal. Numerical results are given
to illustrate that our method successfully produces decent results efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08216</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08216</id><created>2018-06-09</created><updated>2018-06-26</updated><authors><author><keyname>de Gelder</keyname><forenames>Ard</forenames></author><author><keyname>Huisman</keyname><forenames>Henkjan</forenames></author></authors><title>Autoencoders for Multi-Label Prostate MR Segmentation</title><categories>eess.IV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Organ image segmentation can be improved by implementing prior knowledge
about the anatomy. One way of doing this is by training an autoencoder to learn
a lowdimensional representation of the segmentation. In this paper, this is
applied in multi-label prostate MR segmentation, with some positive results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08218</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08218</id><created>2018-06-13</created><authors><author><keyname>Hu</keyname><forenames>Peng</forenames></author></authors><title>Towards Energy Harvesting Powered Sensor Networks for Cyber-Physical
  Systems</title><categories>eess.SP</categories><comments>This paper was first submitted to CASCON-2014 in August 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of sensor networks (WSNs) has become an important component of
the recently proposed cyber-physical systems (CPSs) and Internet of Things
which can connect the physical world with embedded software systems. Energy-
harvesting (EH) as an enabling technology applied in SNs can heavily reduce the
installation and maintenance cost as well as increase system life, flexibility,
and scalability as the EH is subject to the important &quot;energy interruption&quot;
problem where system tasks can be significantly disrupted by the EH outputs.
This problem not only affects the system modeling but also relates to the
cross-layer network design and schedulability. This paper discusses the
EH-powered CPS architecture and some theoretical problems. In particular, we
propose a framework for fully EH-powered CPS, within which essential topics are
discussed, such as EH software architecture, EH models, and real-time
communication. Different EH models for CPSs (e.g., fully EH-powered and
partially EH-powered) are addressed. Future research directions are briefly
discussed in the end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08223</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08223</id><created>2018-06-18</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>New expressions on the performance of a novel multi-hop relay-assisted
  hybrid FSO / RF communication system with receive diversity</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1806.02597,
  arXiv:1806.02269</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel multi-hop relay-assisted hybrid Free Space Optical /
Radio Frequency (FSO / RF) communication system is presented, in which a mobile
user is connected to the Base Station via a multi-hop relay-assisted hybrid FSO
/ RF link with receive diversity. In this structure, received signal at each
relay is demodulated and forwarded. This is the first time that in a multi-hop
hybrid FSO / RF system, receive diversity is used. Bit Error Rate (BER) and
Outage Probability (P_out) are investigated as system performance criteria. New
exact and asymptotic expressions are derived for these criteria, and MATLAB
simulations are provided to verify the obtained results. For the first time
impact of number of receive antennas and number of relays on the performance of
such a structure is investigated. Results indicate that proposed structure has
low dependence on number of receive antennas; therefore, in the proposed
structure use of single receive antenna has the same performance as the
multi-antenna, while low complexity and power consumption. The proposed
structure shows independent performance at moderate and strong atmospheric
turbulence regimes. Hence, it does not require adaptive processing to match
itself according to atmospheric turbulence condition, therefore is cost
effective and particularly suitable for urban areas that encounter frequent
changes in atmospheric turbulence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08236</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08236</id><created>2018-06-21</created><updated>2019-02-04</updated><authors><author><keyname>Lattner</keyname><forenames>Stefan</forenames></author><author><keyname>Grachten</keyname><forenames>Maarten</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Learning Transposition-Invariant Interval Features from Symbolic Music
  and Audio</title><categories>cs.SD cs.LG eess.AS</categories><comments>Paper accepted at the 19th International Society for Music
  Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27;
  8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many music theoretical constructs (such as scale types, modes, cadences, and
chord types) are defined in terms of pitch intervals---relative distances
between pitches. Therefore, when computer models are employed in music tasks,
it can be useful to operate on interval representations rather than on the raw
musical surface. Moreover, interval representations are
transposition-invariant, valuable for tasks like audio alignment, cover song
detection and music structure analysis. We employ a gated autoencoder to learn
fixed-length, invertible and transposition-invariant interval representations
from polyphonic music in the symbolic domain and in audio. An unsupervised
training method is proposed yielding an organization of intervals in the
representation space which is musically plausible. Based on the
representations, a transposition-invariant self-similarity matrix is
constructed and used to determine repeated sections in symbolic music and in
audio, yielding competitive results in the MIREX task &quot;Discovery of Repeated
Themes and Sections&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08242</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08242</id><created>2018-06-20</created><authors><author><keyname>Hassanien</keyname><forenames>Aboul Ella</forenames></author><author><keyname>Kilany</keyname><forenames>Moataz</forenames></author><author><keyname>Houssein</keyname><forenames>Essam H.</forenames></author></authors><title>Combining Support Vector Machine and Elephant Herding Optimization for
  Cardiac Arrhythmias</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many people are currently suffering from heart diseases that can lead to
untimely death. The most common heart abnormality is arrhythmia, which is
simply irregular beating of the heart. A prediction system for the early
intervention and prevention of heart diseases, including cardiovascular
diseases (CDVs) and arrhythmia, is important. This paper introduces the
classification of electrocardiogram (ECG) heartbeats into normal or abnormal.
The approach is based on the combination of swarm optimization algorithms with
a modified PannTompkins algorithm (MPTA) and support vector machines (SVMs).
The MPTA was implemented to remove ECG noise, followed by the application of
the extended features extraction algorithm (EFEA) for ECG feature extraction.
Then, elephant herding optimization (EHO) was used to find a subset of ECG
features from a larger feature pool that provided better classification
performance than that achieved using the whole set. Finally, SVMs were used for
classification. The results show that the EHOSVM approach achieved good
classification results in terms of five statistical indices: accuracy, 93.31%;
sensitivity, 45.49%; precision, 46.45%; F-measure, 45.48%; and specificity,
45.48%. Furthermore, the results demonstrate a clear improvement in accuracy
compared to that of other methods when applied to the MITBIH arrhythmia
database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08302</identifier>
 <datestamp>2018-06-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08302</id><created>2018-06-21</created><authors><author><keyname>Haigh</keyname><forenames>Paul Anthony</forenames></author><author><keyname>Chvojka</keyname><forenames>Petr</forenames></author><author><keyname>Ghassemlooy</keyname><forenames>Zabih</forenames></author><author><keyname>Zvanovec</keyname><forenames>Stanislav</forenames></author><author><keyname>Darwazeh</keyname><forenames>Izzat</forenames></author></authors><title>Non-Orthogonal Multi-band CAP for Highly Spectrally Efficient VLC
  Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose and experimentally demonstrate a novel non-orthogonal
multi-band carrier-less amplitude and phase (NM-CAP) scheme for bandlimited
visible light communication systems in order to increase the spectral
efficiency. We show that a bandwidth saving up to 30% can be achieved thus
resulting in 44% improvement in the measured spectral efficiency with no
further bit error rate performance degradation compared to the traditional
m-CAP scheme. We also show that higher order systems can provide higher
bandwidth compression than low order systems. Furthermore, with no additional
functional blocks at the transmitter or the receiver the proposed scheme
introduces no extra computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08404</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08404</id><created>2018-06-21</created><updated>2018-12-04</updated><authors><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>On the Relationship Between Short-Time Objective Intelligibility and
  Short-Time Spectral-Amplitude Mean-Square Error for Speech Enhancement</title><categories>cs.SD eess.AS</categories><journal-ref>Published in IEEE/ACM Trans. Audio, Speech, Lang. Process., vol.
  27, no. 2, pp. 283-295, 2018</journal-ref><doi>10.1109/TASLP.2018.2877909</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The majority of deep neural network (DNN) based speech enhancement algorithms
rely on the mean-square error (MSE) criterion of short-time spectral amplitudes
(STSA), which has no apparent link to human perception, e.g. speech
intelligibility. Short-Time Objective Intelligibility (STOI), a popular
state-of-the-art speech intelligibility estimator, on the other hand, relies on
linear correlation of speech temporal envelopes. This raises the question if a
DNN training criterion based on envelope linear correlation (ELC) can lead to
improved speech intelligibility performance of DNN based speech enhancement
algorithms compared to algorithms based on the STSA-MSE criterion. In this
paper we derive that, under certain general conditions, the STSA-MSE and ELC
criteria are practically equivalent, and we provide empirical data to support
our theoretical results. Furthermore, our experimental findings suggest that
the standard STSA minimum-MSE estimator is near optimal, if the objective is to
enhance noisy speech in a manner which is optimal with respect to the STOI
speech intelligibility estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08409</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08409</id><created>2018-06-21</created><updated>2018-06-29</updated><authors><author><keyname>Hori</keyname><forenames>Chiori</forenames></author><author><keyname>Alamri</keyname><forenames>Huda</forenames></author><author><keyname>Wang</keyname><forenames>Jue</forenames></author><author><keyname>Wichern</keyname><forenames>Gordon</forenames></author><author><keyname>Hori</keyname><forenames>Takaaki</forenames></author><author><keyname>Cherian</keyname><forenames>Anoop</forenames></author><author><keyname>Marks</keyname><forenames>Tim K.</forenames></author><author><keyname>Cartillier</keyname><forenames>Vincent</forenames></author><author><keyname>Lopes</keyname><forenames>Raphael Gontijo</forenames></author><author><keyname>Das</keyname><forenames>Abhishek</forenames></author><author><keyname>Essa</keyname><forenames>Irfan</forenames></author><author><keyname>Batra</keyname><forenames>Dhruv</forenames></author><author><keyname>Parikh</keyname><forenames>Devi</forenames></author></authors><title>End-to-End Audio Visual Scene-Aware Dialog using Multimodal
  Attention-Based Video Features</title><categories>cs.CL cs.CV cs.SD eess.AS</categories><comments>A prototype system for the Audio Visual Scene-aware Dialog (AVSD) at
  DSTC7</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dialog systems need to understand dynamic visual scenes in order to have
conversations with users about the objects and events around them. Scene-aware
dialog systems for real-world applications could be developed by integrating
state-of-the-art technologies from multiple research areas, including:
end-to-end dialog technologies, which generate system responses using models
trained from dialog data; visual question answering (VQA) technologies, which
answer questions about images using learned image features; and video
description technologies, in which descriptions/captions are generated from
videos using multimodal information. We introduce a new dataset of dialogs
about videos of human behaviors. Each dialog is a typed conversation that
consists of a sequence of 10 question-and-answer(QA) pairs between two Amazon
Mechanical Turk (AMT) workers. In total, we collected dialogs on roughly 9,000
videos. Using this new dataset for Audio Visual Scene-aware dialog (AVSD), we
trained an end-to-end conversation model that generates responses in a dialog
about a video. Our experiments demonstrate that using multimodal features that
were developed for multimodal attention-based video description enhances the
quality of generated dialog about dynamic scenes (videos). Our dataset, model
code and pretrained models will be publicly available for a new Video
Scene-Aware Dialog challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08419</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08419</id><created>2018-06-21</created><authors><author><keyname>Adhikari</keyname><forenames>Kaushallya</forenames></author></authors><title>Sparse Sensing with Semi-Coprime Arrays</title><categories>eess.SP</categories><doi>10.1121/1.5100281</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A semi-coprime array (SCA) interleaves two undersampled uniform linear arrays
(ULAs) and a $Q$ element standard ULA. The undersampling factors of the first
two arrays are $QM$ and $QN$ respectively where $M$ and $N$ are coprime. The
resulting non-uniform linear array is highly sparse. Taking the minimum of the
absolute values of the conventional beampatterns of the three arrays results in
a beampattern free of grating lobes. The SCA offers more savings in the number
of sensors than other popular sparse arrays like coprime arrays, nested arrays,
and minimum redundant arrays. Also, the SCA exhibits better side lobe patterns
than other sparse arrays. An example of direction of arrival estimation with
the SCA illustrates SCA's promising potential in reducing number of sensors,
decreasing system cost and complexity in various signal sensing and processing
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08514</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08514</id><created>2018-06-22</created><updated>2018-07-09</updated><authors><author><keyname>Zhao</keyname><forenames>Lijun</forenames></author><author><keyname>Bai</keyname><forenames>Huihui</forenames></author><author><keyname>Wang</keyname><forenames>Anhong</forenames></author><author><keyname>Zhao</keyname><forenames>Yao</forenames></author></authors><title>Virtual Codec Supervised Re-Sampling Network for Image Compression</title><categories>eess.IV cs.CV</categories><comments>13 pages, 11 figures Our project can be found in the website:
  https://github.com/VirtualCodecNetwork</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an image re-sampling compression method by learning
virtual codec network (VCN) to resolve the non-differentiable problem of
quantization function for image compression. Here, the image re-sampling not
only refers to image full-resolution re-sampling but also low-resolution
re-sampling. We generalize this method for standard-compliant image compression
(SCIC) framework and deep neural networks based compression (DNNC) framework.
Specifically, an input image is measured by re-sampling network (RSN) network
to get re-sampled vectors. Then, these vectors are directly quantized in the
feature space in SCIC, or discrete cosine transform coefficients of these
vectors are quantized to further improve coding efficiency in DNNC. At the
encoder, the quantized vectors or coefficients are losslessly compressed by
arithmetic coding. At the receiver, the decoded vectors are utilized to restore
input image by image decoder network (IDN). In order to train RSN network and
IDN network together in an end-to-end fashion, our VCN network intimates
projection from the re-sampled vectors to the IDN-decoded image. As a result,
gradients from IDN network to RSN network can be approximated by VCN network's
gradient. Because dimension reduction can be further achieved by quantization
in some dimensional space after image re-sampling within auto-encoder
architecture, we can well initialize our networks from pre-trained auto-encoder
networks. Through extensive experiments and analysis, it is verified that the
proposed method has more effectiveness and versatility than many
state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08530</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08530</id><created>2018-06-22</created><authors><author><keyname>Wang</keyname><forenames>Y.</forenames></author><author><keyname>Ji</keyname><forenames>Z. S.</forenames></author><author><keyname>Zhang</keyname><forenames>Z. C.</forenames></author><author><keyname>Li</keyname><forenames>S.</forenames></author><author><keyname>Wang</keyname><forenames>F.</forenames></author><author><keyname>Sun</keyname><forenames>X. Y.</forenames></author></authors><title>Upgrade of the Analog Integrator for EAST Device</title><categories>eess.SP</categories><report-no>564</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrators are fundamental instruments to recover differential signals from
magnetic probes in Experimental Advanced Superconducting Tokamak (EAST)
experiments. A kind of difference integrator is introduced which has the same
structure as the standard difference amplifier. The linear fitting method is
used for determining the effective drift slope, then the plasma control system
(PCS) use the drift slope to rectify the integration signal in real time. A new
integrator controller was developed, which uses an ARM micro-controller and the
lightweight IP protocol stack to realize the network control. The tests show
that the upgraded integrator works well, its CMRR is high up to 125 dB when the
common voltage is 1.5 V, and the processed integration drift is about 200 uVs
/1000 s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08535</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08535</id><created>2018-06-22</created><authors><author><keyname>Rikos</keyname><forenames>Apostolos I.</forenames></author><author><keyname>Hadjicostis</keyname><forenames>Christoforos N.</forenames></author></authors><title>Distributed Average Consensus under Quantized Communication via
  Event-Triggered Mass Summation</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study distributed average consensus problems in multi-agent systems with
directed communication links that are subject to quantized information flow.
The goal of distributed average consensus is for the nodes, each associated
with some initial value, to obtain the average (or some value close to the
average) of these initial values. In this paper, we present and analyze a
distributed averaging algorithm which operates exclusively with quantized
values (specifically, the information stored, processed and exchanged between
neighboring agents is subject to deterministic uniform quantization) and relies
on event-driven updates (e.g., to reduce energy consumption, communication
bandwidth, network congestion, and/or processor usage). We characterize the
properties of the proposed distributed averaging protocol on quantized values
and show that its execution, on any time-invariant and strongly connected
digraph, will allow all agents to reach, in finite time, a common consensus
value represented as the ratio of two integer that is equal to the exact
average. We conclude with examples that illustrate the operation, performance,
and potential advantages of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08619</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08619</id><created>2018-06-22</created><authors><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Kang</keyname><forenames>Yongguo</forenames></author></authors><title>Multi-task WaveNet: A Multi-task Generative Model for Statistical
  Parametric Speech Synthesis without Fundamental Frequency Conditions</title><categories>eess.AS cs.SD eess.SP</categories><comments>Accepted by Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an improved generative model for statistical parametric
speech synthesis (SPSS) based on WaveNet under a multi-task learning framework.
Different from the original WaveNet model, the proposed Multi-task WaveNet
employs the frame-level acoustic feature prediction as the secondary task and
the external fundamental frequency prediction model for the original WaveNet
can be removed. Therefore the improved WaveNet can generate high-quality speech
waveforms only conditioned on linguistic features. Multi-task WaveNet can
produce more natural and expressive speech by addressing the pitch prediction
error accumulation issue and possesses more succinct inference procedures than
the original WaveNet. Experimental results prove that the SPSS method proposed
in this paper can achieve better performance than the state-of-the-art approach
utilizing the original WaveNet in both objective and subjective preference
tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08621</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08621</id><created>2018-06-22</created><authors><author><keyname>Karu</keyname><forenames>Martin</forenames></author><author><keyname>Alum&#xe4;e</keyname><forenames>Tanel</forenames></author></authors><title>Weakly Supervised Training of Speaker Identification Models</title><categories>cs.SD cs.CL cs.HC eess.AS</categories><comments>Odyssey 2018 The Speaker and Language Recognition Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach for training speaker identification models in a weakly
supervised manner. We concentrate on the setting where the training data
consists of a set of audio recordings and the speaker annotation is provided
only at the recording level. The method uses speaker diarization to find unique
speakers in each recording, and i-vectors to project the speech of each speaker
to a fixed-dimensional vector. A neural network is then trained to map
i-vectors to speakers, using a special objective function that allows to
optimize the model using recording-level speaker labels. We report experiments
on two different real-world datasets. On the VoxCeleb dataset, the method
provides 94.6% accuracy on a closed set speaker identification task, surpassing
the baseline performance by a large margin. On an Estonian broadcast news
dataset, the method provides 66% time-weighted speaker identification recall at
93% precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08624</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08624</id><created>2018-06-22</created><authors><author><keyname>Callebaut</keyname><forenames>Gilles</forenames></author><author><keyname>Ottoy</keyname><forenames>Geoffrey</forenames></author><author><keyname>Van der Perre</keyname><forenames>Liesbet</forenames></author></authors><title>Cross-layer framework and optimization for efficient use of the energy
  budget of IoT Nodes</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both physical and MAC-layer need to be jointly optimized to maximize the
autonomy of IoT devices. Therefore, a cross-layer design is imperative to
effectively realize Low Power Wide Area networks (LPWANs). In the present
paper, a cross-layer assessment framework including power modeling is proposed.
Through this simulation framework, the energy consumption of IoT devices,
currently deployed in LoRaWAN networks, is evaluated. We demonstrate that a
cross-layer approach significantly improves energy efficiency and overall
throughput. Two major contributions are made. First, an open-source LPWAN
assessment framework has been conceived. It allows testing and evaluating
hypotheses and schemes. Secondly, as a representative case, the LoRaWAN
protocol is assessed. The findings indicate how a cross-layer approach can
optimize LPWANs in terms of energy efficiency and throughput. For instance, it
is shown that the use of larger payloads can reduce up to three times the
energy consumption on quasi-static channels yet may bring an energy penalty
under adverse dynamic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08675</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08675</id><created>2018-06-20</created><updated>2019-01-28</updated><authors><author><keyname>Schwabedal</keyname><forenames>Justus T. C.</forenames></author><author><keyname>Snyder</keyname><forenames>John C.</forenames></author><author><keyname>Cakmak</keyname><forenames>Ayse</forenames></author><author><keyname>Nemati</keyname><forenames>Shamim</forenames></author><author><keyname>Clifford</keyname><forenames>Gari D.</forenames></author></authors><title>Addressing Class Imbalance in Classification Problems of Noisy Signals
  by using Fourier Transform Surrogates</title><categories>eess.SP nlin.CD q-bio.QM stat.ML</categories><comments>7 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomizing the Fourier-transform (FT) phases of temporal-spatial data
generates surrogates that approximate examples from the data-generating
distribution. We propose such FT surrogates as a novel tool to augment and
analyze training of neural networks and explore the approach in the example of
sleep-stage classification. By computing FT surrogates of raw EEG, EOG, and EMG
signals of under-represented sleep stages, we balanced the CAPSLPDB sleep
database. We then trained and tested a convolutional neural network for sleep
stage classification, and found that our surrogate-based augmentation improved
the mean F1-score by 7%. As another application of FT surrogates, we formulated
an approach to compute saliency maps for individual sleep epochs. The
visualization is based on the response of inferred class probabilities under
replacement of short data segments by partial surrogates. To quantify how well
the distributions of the surrogates and the original data match, we evaluated a
trained classifier on surrogates of correctly classified examples, and
summarized these conditional predictions in a confusion matrix. We show how
such conditional confusion matrices can qualitatively explain the performance
of surrogates in class balancing. The FT-surrogate augmentation approach may
improve classification on noisy signals if carefully adapted to the data
distribution under analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08685</identifier>
 <datestamp>2019-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08685</id><created>2018-06-22</created><updated>2019-03-18</updated><authors><author><keyname>Gerazov</keyname><forenames>Branislav</forenames></author><author><keyname>Bailly</keyname><forenames>G&#xe9;rard</forenames></author><author><keyname>Mohammed</keyname><forenames>Omar</forenames></author><author><keyname>Xu</keyname><forenames>Yi</forenames></author><author><keyname>Garner</keyname><forenames>Philip N.</forenames></author></authors><title>A Variational Prosody Model for Mapping the Context-Sensitive Variation
  of Functional Prosodic Prototypes</title><categories>eess.AS cs.SD</categories><comments>Updated with recurrent version of contour generators, unified
  prosodic latent space, and performance evaluation with baseline</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The quest for comprehensive generative models of intonation that link
linguistic and paralinguistic functions to prosodic forms has been a
longstanding challenge of speech communication research. Traditional intonation
models have given way to the overwhelming performance of deep learning (DL)
techniques for training general purpose end-to-end mappings using millions of
tunable parameters. The shift towards black box machine learning models has
nonetheless posed the reverse problem -- a compelling need to discover
knowledge, to explain, visualise and interpret. Our work bridges between a
comprehensive generative model of intonation and state-of-the-art DL
techniques. We build upon the modelling paradigm of the Superposition of
Functional Contours (SFC) model and propose a Variational Prosody Model (VPM)
that uses a network of variational contour generators to capture the
context-sensitive variation of the constituent elementary prosodic contours. We
show that the VPM can give insight into the intrinsic variability of these
prosodic prototypes through learning a meaningful prosodic latent space
representation structure. We also show that the VPM is able to capture prosodic
phenomena that have multiple dimensions of context based variability. Since it
is based on the principle of superposition, the VPM does not necessitate the
use of specially crafted corpora for the analysis, opening up the possibilities
of using big data for prosody analysis. In a speech synthesis scenario, the
model can be used to generate a dynamic and natural prosody contour that is
devoid of averaging effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08686</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08686</id><created>2018-06-22</created><authors><author><keyname>Lattner</keyname><forenames>Stefan</forenames></author><author><keyname>Grachten</keyname><forenames>Maarten</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>A Predictive Model for Music Based on Learned Interval Representations</title><categories>cs.SD cs.AI eess.AS</categories><comments>Paper accepted at the 19th International Society for Music
  Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27;
  8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectionist sequence models (e.g., RNNs) applied to musical sequences
suffer from two known problems: First, they have strictly &quot;absolute pitch
perception&quot;. Therefore, they fail to generalize over musical concepts which are
commonly perceived in terms of relative distances between pitches (e.g.,
melodies, scale types, modes, cadences, or chord types). Second, they fall
short of capturing the concepts of repetition and musical form. In this paper
we introduce the recurrent gated autoencoder (RGAE), a recurrent neural network
which learns and operates on interval representations of musical sequences. The
relative pitch modeling increases generalization and reduces sparsity in the
input data. Furthermore, it can learn sequences of copy-and-shift operations
(i.e. chromatically transposed copies of musical fragments)---a promising
capability for learning musical repetition structure. We show that the RGAE
improves the state of the art for general connectionist sequence models in
learning to predict monophonic melodies, and that ensembles of relative and
absolute music processing models improve the results appreciably. Furthermore,
we show that the relative pitch processing of the RGAE naturally facilitates
the learning and the generation of sequences of copy-and-shift operations,
wherefore the RGAE greatly outperforms a common absolute pitch recurrent neural
network on this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08689</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08689</id><created>2018-06-21</created><authors><author><keyname>Lehmann</keyname><forenames>Matthias</forenames></author><author><keyname>Wittpahl</keyname><forenames>Christian</forenames></author><author><keyname>Zakour</keyname><forenames>Hatem Ben</forenames></author><author><keyname>Braun</keyname><forenames>Alexander</forenames></author></authors><title>Resolution and accuracy of non-linear regression of PSF with artificial
  neural networks</title><categories>eess.IV astro-ph.IM</categories><comments>12 pages, 9 figures, submitted and accepted for SPIE Optical Systems
  Design, 2018, Frankfurt, Germany. arXiv admin note: text overlap with
  arXiv:1801.02197</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous work we have demonstrated a novel numerical model for the point
spread function (PSF) of an optical system that can efficiently model both
experimental measurements and lens design simulations of the PSF. The novelty
lies in the portability and the parameterization of this model, which allows
for completely new ways to validate optical systems, which is especially
interesting for mass production optics like in the automotive industry, but
also for ophtalmology. The numerical basis for this model is a non-linear
regression of the PSF with an artificial neural network (ANN). In this work we
examine two important aspects of this model: the spatial resolution and the
accuracy of the model. Measurement and simulation of a PSF can have a much
higher resolution then the typical pixel size used in current camera sensors,
especially those for the automotive industry. We discuss the influence this has
on on the topology of the ANN and the final application where the modeled PSF
is actually used. Another important influence on the accuracy of the trained
ANN is the error metric which is used during training. The PSF is a distinctly
non-linear function, which varies strongly over field and defocus, but
nonetheless exhibits strong symmetries and spatial relations. Therefore we
examine different distance and similarity measures and discuss its influence on
the modeling performance of the ANN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08711</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08711</id><created>2018-06-21</created><authors><author><keyname>Hoelz</keyname><forenames>Peter</forenames></author><author><keyname>Boehlke</keyname><forenames>Thomas</forenames></author><author><keyname>Kraemer</keyname><forenames>Thomas</forenames></author></authors><title>Determining water mass flow control strategies for a turbocharged SI
  engine using a two-stage calculation method</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reduction of heat and friction losses is a proven approach to increase the
engine efficiency. Therefore, and due to a stabilized, robust combustion, a
specific adjustment of component temperatures is desirable in highly transient
conditions. In this paper, a turbocharged SI engine is investigated numerically
concerning the potential regulation of temperatures, including heat fluxes,
only by controlling the water mass flow rate. Using two independent models, a
simplified lumped capacity model and a detailed three-dimensional CFD-CHT
simulation, an efficient, two-stage calculation method is suggested for an
optimized determination of control strategies and their parameters. This
complements existing published works which usually control more than one
parameter, but use one model. Different control strategies, like feed forward
or feedback controllers, are proposed and compared. In addition, a more
holistic approach is presented performing a Monte Carlo simulation which
evaluates temperatures, as well as hydraulic pumping losses. Using expedient
control strategies and parameters, it could be shown that the engine
temperatures can be effectively regulated within a wide range. The two
different models show partly similar results, and the efficient, two-stage
optimization method has proven its worth. However, there are some significant
differences between simplified and detailed modelling which are worth
mentioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08724</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08724</id><created>2018-06-22</created><authors><author><keyname>Sears</keyname><forenames>David R. W.</forenames></author><author><keyname>Korzeniowski</keyname><forenames>Filip</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Evaluating language models of tonal harmony</title><categories>cs.SD eess.AS</categories><comments>7 pages, 4 figures, 3 tables. To appear in Proceedings of the 19th
  International Society for Music Information Retrieval Conference (ISMIR),
  Paris, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study borrows and extends probabilistic language models from natural
language processing to discover the syntactic properties of tonal harmony.
Language models come in many shapes and sizes, but their central purpose is
always the same: to predict the next event in a sequence of letters, words,
notes, or chords. However, few studies employing such models have evaluated the
most state-of-the-art architectures using a large-scale corpus of Western tonal
music, instead preferring to use relatively small datasets containing chord
annotations from contemporary genres like jazz, pop, and rock.
  Using symbolic representations of prominent instrumental genres from the
common-practice period, this study applies a flexible, data-driven encoding
scheme to (1) evaluate Finite Context (or n-gram) models and Recurrent Neural
Networks (RNNs) in a chord prediction task; (2) compare predictive accuracy
from the best-performing models for chord onsets from each of the selected
datasets; and (3) explain differences between the two model architectures in a
regression analysis. We find that Finite Context models using the Prediction by
Partial Match (PPM) algorithm outperform RNNs, particularly for the piano
datasets, with the regression model suggesting that RNNs struggle with
particularly rare chord types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08739</identifier>
 <datestamp>2018-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08739</id><created>2018-06-22</created><authors><author><keyname>Hirsh</keyname><forenames>Seth M.</forenames></author><author><keyname>Brunton</keyname><forenames>Bingni W.</forenames></author><author><keyname>Kutz</keyname><forenames>J. Nathan</forenames></author></authors><title>Data-driven Spatiotemporal Modal Decomposition for Time Frequency
  Analysis</title><categories>math.NA eess.SP</categories><comments>23 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new solution to the blind source separation problem that factors
mixed time-series signals into a sum of spatiotemporal modes, with the
constraint that the temporal components are intrinsic mode functions (IMF's).
The key motivation is that IMF's allow the computation of meaningful Hilbert
transforms of non-stationary data, from which instantaneous time-frequency
representations may be derived. Our spatiotemporal intrinsic mode decomposition
(STIMD) method leverages spatial correlations to generalize the extraction of
IMF's from one-dimensional signals, commonly performed using the empirical mode
decomposition (EMD), to multi-dimensional signals. Further, this data-driven
method enables future-state prediction. We demonstrate STIMD on several
synthetic examples, comparing it to common matrix factorization techniques,
namely singular value decomposition (SVD), independent component analysis
(ICA), and dynamic mode decomposition (DMD). We show that STIMD outperforms
these methods at reconstruction and extracting interpretable modes. Next, we
apply STIMD to analyze two real-world datasets, gravitational wave data and
neural recordings from the rodent hippocampus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08887</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08887</id><created>2018-06-22</created><updated>2018-12-01</updated><authors><author><keyname>Chen</keyname><forenames>Yubei</forenames></author><author><keyname>Paiton</keyname><forenames>Dylan M.</forenames></author><author><keyname>Olshausen</keyname><forenames>Bruno A.</forenames></author></authors><title>The Sparse Manifold Transform</title><categories>stat.ML cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a signal representation framework called the sparse manifold
transform that combines key ideas from sparse coding, manifold learning, and
slow feature analysis. It turns non-linear transformations in the primary
sensory signal space into linear interpolations in a representational embedding
space while maintaining approximate invertibility. The sparse manifold
transform is an unsupervised and generative framework that explicitly and
simultaneously models the sparse discreteness and low-dimensional manifold
structure found in natural scenes. When stacked, it also models hierarchical
composition. We provide a theoretical description of the transform and
demonstrate properties of the learned representation on both synthetic data and
natural videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08898</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08898</id><created>2018-06-22</created><authors><author><keyname>He</keyname><forenames>Lin</forenames></author><author><keyname>Rao</keyname><forenames>Yizhou</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Plaza</keyname><forenames>Antonio</forenames></author><author><keyname>Zhu</keyname><forenames>Jiawei</forenames></author></authors><title>Pansharpening via Detail Injection Based Convolutional Neural Networks</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pansharpening aims to fuse a multispectral (MS) image with an associated
panchromatic (PAN) image, producing a composite image with the spectral
resolution of the former and the spatial resolution of the latter. Traditional
pansharpening methods can be ascribed to a unified detail injection context,
which views the injected MS details as the integration of PAN details and
band-wise injection gains. In this work, we design a detail injection based CNN
(DiCNN) framework for pansharpening, with the MS details being directly
formulated in end-to-end manners, where the first detail injection based CNN
(DiCNN1) mines MS details through the PAN image and the MS image, and the
second one (DiCNN2) utilizes only the PAN image. The main advantage of the
proposed DiCNNs is that they provide explicit physical interpretations and can
achieve fast convergence while achieving high pansharpening quality.
Furthermore, the effectiveness of the proposed approaches is also analyzed from
a relatively theoretical point of view. Our methods are evaluated via
experiments on real-world MS image datasets, achieving excellent performance
when compared to other state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.08946</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.08946</id><created>2018-06-23</created><authors><author><keyname>Wang</keyname><forenames>Jingyuan</forenames></author><author><keyname>Wang</keyname><forenames>Ze</forenames></author><author><keyname>Li</keyname><forenames>Jianfeng</forenames></author><author><keyname>Wu</keyname><forenames>Junjie</forenames></author></authors><title>Multilevel Wavelet Decomposition Network for Interpretable Time Series
  Analysis</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed the unprecedented rising of time series from
almost all kindes of academic and industrial fields. Various types of deep
neural network models have been introduced to time series analysis, but the
important frequency information is yet lack of effective modeling. In light of
this, in this paper we propose a wavelet-based neural network structure called
multilevel Wavelet Decomposition Network (mWDN) for building frequency-aware
deep learning models for time series analysis. mWDN preserves the advantage of
multilevel discrete wavelet decomposition in frequency learning while enables
the fine-tuning of all parameters under a deep neural network framework. Based
on mWDN, we further propose two deep learning models called Residual
Classification Flow (RCF) and multi-frequecy Long Short-Term Memory (mLSTM) for
time series classification and forecasting, respectively. The two models take
all or partial mWDN decomposed sub-series in different frequencies as input,
and resort to the back propagation algorithm to learn all the parameters
globally, which enables seamless embedding of wavelet-based frequency analysis
into deep learning frameworks. Extensive experiments on 40 UCR datasets and a
real-world user volume dataset demonstrate the excellent performance of our
time series models based on mWDN. In particular, we propose an importance
analysis method to mWDN based models, which successfully identifies those
time-series elements and mWDN layers that are crucially important to time
series analysis. This indeed indicates the interpretability advantage of mWDN,
and can be viewed as an indepth exploration to interpretable deep learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09009</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09009</id><created>2018-06-23</created><authors><author><keyname>Karthik</keyname><forenames>Anantha K.</forenames></author><author><keyname>Blum</keyname><forenames>Rick S.</forenames></author></authors><title>Minimax Optimum Clock Skew and Offset Estimators for IEEE 1588</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of clock skew and offset estimation for the
IEEE 1588 precision time protocol. Built on the classical two-way message
exchange scheme, IEEE 1588 is a prominent synchronization protocol for packet
switched networks. It is employed in various applications including cellular
base station synchronization in 4G long-term evaluation backhaul networks,
substation synchronization in electrical grid networks and industrial control.
Due to the presence of random queuing delays in a packet switched network, the
recovery of clock skew and offset from the received packet timestamps can be
viewed as a statistical estimation problem. Recently, assuming perfect clock
skew information, minimax optimum clock offset estimators were developed for
IEEE 1588. Building on this work, we develop minimax optimum clock skew and
offset estimators for IEEE 1588 in this paper. Simulation results indicate the
proposed minimax estimators exhibit a lower mean square estimation error than
the estimators available in the literature for various network scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09010</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09010</id><created>2018-06-23</created><authors><author><keyname>Liu</keyname><forenames>Gabrielle K.</forenames></author></authors><title>Evaluating Gammatone Frequency Cepstral Coefficients with Neural
  Networks for Emotion Recognition from Speech</title><categories>cs.SD cs.CL eess.AS</categories><comments>5 pages, 1 figure, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current approaches to speech emotion recognition focus on speech features
that can capture the emotional content of a speech signal. Mel Frequency
Cepstral Coefficients (MFCCs) are one of the most commonly used representations
for audio speech recognition and classification. This paper proposes Gammatone
Frequency Cepstral Coefficients (GFCCs) as a potentially better representation
of speech signals for emotion recognition. The effectiveness of MFCC and GFCC
representations are compared and evaluated over emotion and intensity
classification tasks with fully connected and recurrent neural network
architectures. The results provide evidence that GFCCs outperform MFCCs in
speech emotion recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09064</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09064</id><created>2018-06-23</created><authors><author><keyname>Yu</keyname><forenames>Hongwei</forenames></author><author><keyname>Song</keyname><forenames>Kezhu</forenames></author><author><keyname>Yang</keyname><forenames>Junfeng</forenames></author><author><keyname>Li</keyname><forenames>Kehan</forenames></author><author><keyname>Chen</keyname><forenames>Tengfei</forenames></author><author><keyname>Luo</keyname><forenames>Shiyu</forenames></author><author><keyname>Tang</keyname><forenames>Cheng</forenames></author><author><keyname>Yu</keyname><forenames>Han</forenames></author></authors><title>A multi-channel DAQ system based on FPGA for long-distance transmission
  in nuclear physics experiments</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the development of electronic science and technology, electronic data
acquisition (DAQ) system is more and more widely applied to nuclear physics
experiments. Workstations are often utilized for data storage, data display,
data processing and data analysis by researchers. Nevertheless, the
workstations are ordinarily separated from detectors in nuclear physics
experiments by several kilometers or even tens of kilometers. Thus a DAQ system
that can transmit data for long distance is in demand. In this paper, we
designed a DAQ system suitable for high-speed and high-precision sampling for
remote data transfer. An 8-channel, 24-bit simultaneous sampling
analog-to-digital converter(ADC) named AD7779 was utilized for high-speed and
high-precision sampling, the maximum operating speed of which runs up to 16
kilo samples per second(KSPS). ADC is responsible for collecting signals from
detectors, which is sent to Field Programmable Gate Array(FPGA) for processing
and long-distance transmission to the workstation through optical fiber. As the
central processing unit of DAQ system, FPGA provides powerful computing
capability and has enough flexibility. The most prominent feature of the system
is real-time mass data transfer based on streaming transmission mode, highly
reliable data transmission based on error detection and correction and
high-speed high-precision data acquisition. The results of our tests show that
the system is able to transmit data stably at the bandwidth of 1Gbps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09068</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09068</id><created>2018-06-23</created><authors><author><keyname>Wang</keyname><forenames>Shuwen</forenames></author><author><keyname>Shen</keyname><forenames>Zhongtao</forenames></author><author><keyname>Zhao</keyname><forenames>Keqing</forenames></author><author><keyname>Feng</keyname><forenames>Changqing</forenames></author><author><keyname>Liu</keyname><forenames>Shubin</forenames></author></authors><title>Prototype of Front-end Electronics for PandaX-4ton Experiment</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the China Jinping Underground Laboratory, the Particle AND Astrophysical
Xenon phase IV (PandaX-4ton) in planning is a dark matter direct detection
experiment with dual-phase xenon detector as an upgrade of the second phase of
the experiment, PandaX-II. In this paper, the prototype of the front-end
electronics of PandaX-4ton is presented. The front-end electronics consist of
the high-gain preamplifier cards and the eight-channel digitizers with 14-bit
resolution and 1 GSps sampling rate for waveform digitization. The clock
synchronization circuit within the digitizer is well-designed to align all the
PMT channels. The digitizer also contains gigabit fiber to exchange data with
trigger and data acquisition system. The specification of effective number of
bits f the digitizer is about 9.7 b at 148 MHz, and the integral nonlinearity
of the digitizer ranges from -4 least significant bit (LSB) to +4 LSB, and the
differential nonlinearity ranges from -0.6 LSB to +0.6 LSB. The performance of
the front-end electronics can meet the requirements for the PandaX-4ton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09080</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09080</id><created>2018-06-24</created><authors><author><keyname>Chen</keyname><forenames>Haolei</forenames></author><author><keyname>Feng</keyname><forenames>Changqing</forenames></author><author><keyname>Hu</keyname><forenames>Jiadong</forenames></author><author><keyname>Luo</keyname><forenames>Laifu</forenames></author><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Tan</keyname><forenames>Zhixin</forenames></author><author><keyname>Liu</keyname><forenames>Shubin</forenames></author></authors><title>Development of a 256-channel Time-of-flight Electronics System For
  Neutron Beam Profiling</title><categories>physics.ins-det eess.SP</categories><doi>10.1109/TNS.2019.2924640</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 256-channel time-of-flight (TOF) electronics system has been developed for
a beam line facility called &quot;Back-n WNS&quot; in China Spallation Neutron Source
(CSNS). This paper shows the structure and performance of electronics system
and the test results in CSNS. A 256-channel photomultiplier tube (PMT) is
chosen as the detector in this system. In order to acquire the time information
from the PMT, an electronics system has been designed. The electronics system
mainly includes one front-end board (FEB), four time-to-digital converter (TDC)
boards and one clock distribution module (CDM). There are 256 channels on FEB
and 64 channels on each TDC board. The FEB is connected to the PMT with
high-density connectors and the TDC boards are connected to the FEB through 2m
cables. The TDC boards are 6U size so that they can be PCI extensions for
Instrumentation (PXI) cards. Data from TDC boards can be transferred to the PXI
control card through the backboard. In order to make four TDC boards work
synchronously, a CDM outputs four clock signals to TDC boards which are
distributed from one clock source. The TDC boards achieve a timing resolution
of 3.5ns by test with a signal generator. The TOF measurement system has been
used in CSNS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09106</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09106</id><created>2018-06-24</created><authors><author><keyname>Xu</keyname><forenames>Tianbo</forenames></author><author><keyname>Song</keyname><forenames>Kezhu</forenames></author><author><keyname>Yang</keyname><forenames>Junfeng</forenames></author></authors><title>The Electronics Design of Error Field Feedback Control System in KTX</title><categories>eess.SP physics.ins-det</categories><comments>3 pages , 6 figures, 21st IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  KTX (Keda Tours eXperiment) is a new RFP (reversed field pinch) device at the
University of Science and Technology of China. The unique double-C design of
the KTX makes modifications and investigations of power and particle control
easy, but the error field of slit zone in the new design should not be
neglected. The objective of this paper is to introduce a new active feedback
control system which can change the voltage between the unique double-C
structures to make the toroidal field better. FPGA is the central part of the
whole system to control all the process, because it can manipulate and transmit
the data from coils in real time. There are 2 high-speed 8-channels ADCs in the
system to convert the analog signal from 16 Rogowski coils which can detect
dynamic eddy current of copper shells near the vertical gap. FPGA also control
the external power amplifier to change the voltage between the unique double-C
structures by commanding 16 high-speed DACs to give the RFP device a feedback.
Result indicated that the error field in KTX device was reduced, and the system
could successfully achieve fast matrix calculation with lower delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09117</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09117</id><created>2018-06-24</created><authors><author><keyname>Lu</keyname><forenames>Jiaming</forenames></author><author><keyname>Zhao</keyname><forenames>Lei</forenames></author><author><keyname>Deng</keyname><forenames>Peipei</forenames></author><author><keyname>Li</keyname><forenames>Bowen</forenames></author><author><keyname>Chen</keyname><forenames>Kairen</forenames></author><author><keyname>Liu</keyname><forenames>Shubin</forenames></author><author><keyname>An</keyname><forenames>Qi</forenames></author></authors><title>A Design of FPGA Based Small Animal PET Real Time Digital Signal
  Processing and Correction Logic</title><categories>eess.SP physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Small animal Positron Emission Tomography (PET) is dedicated to small animal
imaging. Animals used in experiments, such as rats and monkeys, are often much
smaller than human bodies, which requires higher position and energy precision
of the PET imaging system. Besides, Flexibility, high efficiency are also the
major demands of a practical PET system. These requires a high-quality analog
front-end and a digital signal processing logic with high efficiency and
compatibility of multiple data processing modes. The digital signal processing
logic of the small animal PET system presented in this paper implements
32-channel signal processing in a single Xilinx Artix-7 family of
Field-Programmable Gate Array (FPGA). The logic is designed to support three
online modes which are regular package mode, flood map and energy spectrum
histogram. Several functions are integrated, including two-dimensional (2D) raw
position calculation, crystal identification, events filtering, etc. Besides, a
series of online corrections are also integrated, such as photon peak
correction to 511 keV and timing offset correction with crystal granularity. A
Gigabit Ethernet interface is utilized for data transfer, Look-Up Tables (LUTs)
configuration and commands issuing. The pipe-line logic processes the signals
at 125 MHz with a rate of 1,000,000 events/s. A series of initial tests are
conducted. The results indicate that the digital processing logic achieves the
expectations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09120</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09120</id><created>2018-06-24</created><authors><author><keyname>Hu</keyname><forenames>Jiadong</forenames></author><author><keyname>Cao</keyname><forenames>Zhe</forenames></author><author><keyname>An</keyname><forenames>Qi</forenames></author><author><keyname>Zhao</keyname><forenames>Lei</forenames></author><author><keyname>Liu</keyname><forenames>Shubin</forenames></author></authors><title>A New All-Digital Background Calibration Technique for Time-Interleaved
  ADC Using First Order Approximation FIR Filters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new all-digital technique for calibration of the
mismatches in time-interleaved analog-to-digital converters (TIADCs) to reduce
the circuit area. The proposed technique gives the first order approximation of
the gain mismatches and sample-time mismatches, and employs first order
approximation FIR filter banks to calibrate the sampled signal, which do not
need large number of FIR taps. In the case of a two-channel 12-bit TIADC, the
proposed technique improves SINAD of simulated data from 45dB to 69dB, and
improves SINAD of measured data from 47dB to 53dB, while the number of FIR taps
is only 30. In the case of slight mismatches, 24-bit FIR coefficient is
sufficient to correct 12-bit signals, which makes it easy to implement this
technique in hardware. In addition, this technique is not limited by the number
of sub-ADC channels and can be calculated in parallel in hardware, these
features enable this technique to be versatile and capable of real-time
calibration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09126</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09126</id><created>2018-06-24</created><authors><author><keyname>Mohades</keyname><forenames>Zohreh</forenames></author><author><keyname>TabaTabaVakili</keyname><forenames>Vahid</forenames></author></authors><title>Channel Estimation for Massive MIMO Communication System Using Deep
  Neural Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of sparse signal recovery in Multiple
Measurement Vectors (MMVs) case. Recently, ample researches have been conducted
to solve this problem and diverse methods are proposed, one of which is deep
neural network approach. Here, employing deep neural networks we have provided
two new greedy algorithms in order to solve MMV problems. In the first
algorithm, we create a stacked vector of measurement matrix columns and a new
measurement matrix, which can be assumed as the Kronecker product of the
primary compressive sampling matrix and a unitary matrix. Afterwards, in order
to reconstruct sparse vectors corresponding to this new set of equations, a
four-layer feed-forward neural network is applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09169</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09169</id><created>2018-06-24</created><authors><author><keyname>Itturriet</keyname><forenames>F&#xe1;bio P.</forenames></author><author><keyname>Costa</keyname><forenames>M&#xe1;rcio H.</forenames></author></authors><title>Perceptually Relevant Preservation of Interaural Time Differences in
  Binaural Hearing Aids</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a noise reduction method with perceptually relevant
preservation of the interaural time difference (ITD) of the residual noise in
binaural hearing aids. The interaural coherence (IC) concept, previously
applied to the Multichannel Wiener Filter (MWF) for preservation of the spatial
subjective sensation of diffuse noise fields, is proposed here to both preserve
and emphasize the ITD binaural cues of a directional acoustic noise source. It
is demonstrated that the previously developed MWF-ITD technique may decrease
the original IC magnitude of the processed noise, consequently increasing the
variance of the interaural phase difference (IPD) of the output signals. It is
shown that the MWF-IC technique concomitantly minimizes a nonlinear function of
the difference between input and output IPD, which is strictly related to ITD,
and preserves the natural coherence of the directional noise captured by the
reference microphones. Objective measures and psychoacoustic experiments
corroborate the theoretical findings, showing the MWF-IC technique provides
relevant noise reduction, while preserving the original ITD subjective
perception and original lateralization for a directional noise source. These
results are especially relevant for hearing aid designers, since they indicate
the MWF-IC as a noise reduction technique that provides resid-ual noise spatial
preservation for both diffuse and directional noise sources in frequencies
below 1.5 kHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09247</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09247</id><created>2018-06-24</created><authors><author><keyname>Rutkowski</keyname><forenames>Igor</forenames></author><author><keyname>Czuba</keyname><forenames>Krzysztof</forenames></author></authors><title>Additive phase-noise in frequency conversion in LLRF systems</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution focuses on phase-noise added during frequency conversion in
low-level radio frequency (LLRF) control systems. The stability of beams'
parameters in linear accelerators depends on the stability of amplitude and
phase of the accelerating field. A LLRF control system regulates the
electromagnetic field inside accelerating modules based on the input RF
signals. Typically active mixers down-convert those signals, which are later
sampled and digitized by ADCs. This field detection scheme necessitates
synthesis of a heterodyne/local oscillator (LO) signal which is often generated
using a passive mixer and a frequency divider. Additive close-to-carrier phase
noise can be observed in the aforementioned circuits. The phase noise of a
passive mixer's output signal is typically calculated using a small-signal
model based on modulation theory. Experimental results indicate that the power
level of the input signals has a nonlinear effect on phase noise beyond the
noise floor. The frequency dividers' output phase noise was measured as a
function of input power, input frequency, and division ratio. The influence of
the LO signal power level on the active mixers' output signal phase noise was
measured and two hypotheses were made. Further measurements of the AM-PM and
PM-AM conversion were made to verify one of the hypotheses. The fidelity of the
LO signal is partially determined by the phase noise of the IF signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09249</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09249</id><created>2018-06-24</created><authors><author><keyname>Ji</keyname><forenames>X. Y.</forenames></author><author><keyname>Cao</keyname><forenames>P.</forenames></author><author><keyname>Yu</keyname><forenames>T.</forenames></author><author><keyname>Xie</keyname><forenames>L. K.</forenames></author><author><keyname>Huang</keyname><forenames>X. R.</forenames></author><author><keyname>An</keyname><forenames>Q.</forenames></author><author><keyname>Bai</keyname><forenames>H. Y.</forenames></author><author><keyname>Bao</keyname><forenames>J.</forenames></author><author><keyname>Chen</keyname><forenames>Y. H.</forenames></author><author><keyname>Cheng</keyname><forenames>P. J.</forenames></author><author><keyname>Cui</keyname><forenames>Z. Q.</forenames></author><author><keyname>Fan</keyname><forenames>R. R.</forenames></author><author><keyname>Feng</keyname><forenames>C. Q.</forenames></author><author><keyname>Gu</keyname><forenames>M. H.</forenames></author><author><keyname>Han</keyname><forenames>Z. J.</forenames></author><author><keyname>He</keyname><forenames>G. Z.</forenames></author><author><keyname>He</keyname><forenames>Y. C.</forenames></author><author><keyname>He</keyname><forenames>Y. F.</forenames></author><author><keyname>Huang</keyname><forenames>H. X.</forenames></author><author><keyname>Huang</keyname><forenames>W. L.</forenames></author><author><keyname>Ji</keyname><forenames>X. L.</forenames></author><author><keyname>Jiang</keyname><forenames>H. Y.</forenames></author><author><keyname>Jiang</keyname><forenames>W.</forenames></author><author><keyname>Jing</keyname><forenames>H. Y.</forenames></author><author><keyname>Kang</keyname><forenames>L.</forenames></author><author><keyname>Li</keyname><forenames>B.</forenames></author><author><keyname>Li</keyname><forenames>L.</forenames></author><author><keyname>Li</keyname><forenames>Q.</forenames></author><author><keyname>Li</keyname><forenames>X.</forenames></author><author><keyname>Li</keyname><forenames>Y.</forenames></author><author><keyname>Liu</keyname><forenames>R.</forenames></author><author><keyname>Liu</keyname><forenames>S. B.</forenames></author><author><keyname>Liu</keyname><forenames>X. Y.</forenames></author><author><keyname>Luan</keyname><forenames>G. Y.</forenames></author><author><keyname>Ma</keyname><forenames>Y. L.</forenames></author><author><keyname>Ning</keyname><forenames>C. J.</forenames></author><author><keyname>Ren</keyname><forenames>J.</forenames></author><author><keyname>Ruan</keyname><forenames>X. C.</forenames></author><author><keyname>Song</keyname><forenames>Z. H.</forenames></author><author><keyname>Sun</keyname><forenames>H.</forenames></author><author><keyname>Sun</keyname><forenames>X. Y.</forenames></author><author><keyname>Sun</keyname><forenames>Z. J.</forenames></author><author><keyname>Tan</keyname><forenames>Z. X.</forenames></author><author><keyname>Tang</keyname><forenames>J. Y.</forenames></author><author><keyname>Tang</keyname><forenames>H. Q.</forenames></author><author><keyname>Wang</keyname><forenames>P. C.</forenames></author><author><keyname>Wang</keyname><forenames>Q.</forenames></author><author><keyname>Wang</keyname><forenames>T. F.</forenames></author><author><keyname>Wang</keyname><forenames>Y. F.</forenames></author><author><keyname>Wang</keyname><forenames>Z. H.</forenames></author><author><keyname>Wang</keyname><forenames>Z.</forenames></author><author><keyname>Wen</keyname><forenames>J.</forenames></author><author><keyname>Wen</keyname><forenames>Z. W.</forenames></author><author><keyname>Wu</keyname><forenames>Q. B.</forenames></author><author><keyname>Wu</keyname><forenames>X. G.</forenames></author><author><keyname>Wu</keyname><forenames>X.</forenames></author><author><keyname>Yang</keyname><forenames>Y. W.</forenames></author><author><keyname>Yi</keyname><forenames>H.</forenames></author><author><keyname>Yu</keyname><forenames>L.</forenames></author><author><keyname>Yu</keyname><forenames>Y. J.</forenames></author><author><keyname>Zhang</keyname><forenames>G. H.</forenames></author><author><keyname>Zhang</keyname><forenames>L. Y.</forenames></author><author><keyname>Zhang</keyname><forenames>J.</forenames></author><author><keyname>Zhang</keyname><forenames>Q. M.</forenames></author><author><keyname>Zhang</keyname><forenames>Q. W.</forenames></author><author><keyname>Zhang</keyname><forenames>X. P.</forenames></author><author><keyname>Zhao</keyname><forenames>Y. T.</forenames></author><author><keyname>Zhong</keyname><forenames>Q. P.</forenames></author><author><keyname>Zhou</keyname><forenames>L.</forenames></author><author><keyname>Zhou</keyname><forenames>Z. Y.</forenames></author><author><keyname>Zhu</keyname><forenames>K. J.</forenames></author></authors><title>T0 Fan-out for Back-n White Neutron Facility at CSNS</title><categories>physics.ins-det eess.SP</categories><comments>3 pages, 6 figures, the 21st IEEE Real Time Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  the main physics goal for Back-n white neutron facility at China Spallation
Neutron Source (CSNS) is to measure nuclear data. The energy of neutrons is one
of the most important parameters for measuring nuclear data. Method of time of
flight (TOF) is used to obtain the energy of neutrons. The time when proton
bunches hit the thick tungsten target is considered as the start point of TOF.
T0 signal, generated from the CSNS accelerator, represents this start time.
Besides, the T0 signal is also used as the gate control signal that triggers
the readout electronics. Obviously, the timing precision of T0 directly affects
the measurement precision of TOF and controls the running or readout
electronics. In this paper, the T0 fan-out for Back-n white neutron facility at
CSNS is proposed. The T0 signal travelling from the CSNS accelerator is fanned
out to the two underground experiment stations respectively over long cables.
To guarantee the timing precision, T0 signal is conditioned with good signal
edge. Furthermore, techniques of signal pre-emphasizing and equalizing are used
to improve signal quality after T0 being transmitted over long cables with
about 100 m length. Experiments show that the T0 fan-out works well, the T0
signal transmitted over 100 m remains a good time resolution with a standard
deviation of 25 ps. It absolutely meets the required accuracy of the
measurement of TOF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09250</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09250</id><created>2018-06-24</created><authors><author><keyname>Yu</keyname><forenames>T.</forenames></author><author><keyname>Cao</keyname><forenames>P.</forenames></author><author><keyname>Ji</keyname><forenames>X. Y.</forenames></author><author><keyname>Xie</keyname><forenames>L. K.</forenames></author><author><keyname>Huang</keyname><forenames>X. R.</forenames></author><author><keyname>An</keyname><forenames>Q.</forenames></author><author><keyname>Bai</keyname><forenames>H. Y.</forenames></author><author><keyname>Bao</keyname><forenames>J.</forenames></author><author><keyname>Chen</keyname><forenames>Y. H.</forenames></author><author><keyname>Cheng</keyname><forenames>P. J.</forenames></author><author><keyname>Cui</keyname><forenames>Z. Q.</forenames></author><author><keyname>Fan</keyname><forenames>R. R.</forenames></author><author><keyname>Feng</keyname><forenames>C. Q.</forenames></author><author><keyname>Gu</keyname><forenames>M. H.</forenames></author><author><keyname>Han</keyname><forenames>Z. J.</forenames></author><author><keyname>He</keyname><forenames>G. Z.</forenames></author><author><keyname>He</keyname><forenames>Y. C.</forenames></author><author><keyname>He</keyname><forenames>Y. F.</forenames></author><author><keyname>Huang</keyname><forenames>H. X.</forenames></author><author><keyname>Huang</keyname><forenames>W. L.</forenames></author><author><keyname>Ji</keyname><forenames>X. L.</forenames></author><author><keyname>Jiang</keyname><forenames>H. Y.</forenames></author><author><keyname>Jiang</keyname><forenames>W.</forenames></author><author><keyname>Jing</keyname><forenames>H. Y.</forenames></author><author><keyname>Kang</keyname><forenames>L.</forenames></author><author><keyname>Li</keyname><forenames>B.</forenames></author><author><keyname>Li</keyname><forenames>L.</forenames></author><author><keyname>Li</keyname><forenames>Q.</forenames></author><author><keyname>Li</keyname><forenames>X.</forenames></author><author><keyname>Li</keyname><forenames>Y.</forenames></author><author><keyname>Liu</keyname><forenames>R.</forenames></author><author><keyname>Liu</keyname><forenames>S. B.</forenames></author><author><keyname>Liu</keyname><forenames>X. Y.</forenames></author><author><keyname>Luan</keyname><forenames>G. Y.</forenames></author><author><keyname>Ma</keyname><forenames>Y. L.</forenames></author><author><keyname>Ning</keyname><forenames>C. J.</forenames></author><author><keyname>Ren</keyname><forenames>J.</forenames></author><author><keyname>Ruan</keyname><forenames>X. C.</forenames></author><author><keyname>Song</keyname><forenames>Z. H.</forenames></author><author><keyname>Sun</keyname><forenames>H.</forenames></author><author><keyname>Sun</keyname><forenames>X. Y.</forenames></author><author><keyname>Sun</keyname><forenames>Z. J.</forenames></author><author><keyname>Tan</keyname><forenames>Z. X.</forenames></author><author><keyname>Tang</keyname><forenames>J. Y.</forenames></author><author><keyname>Tang</keyname><forenames>H. Q.</forenames></author><author><keyname>Wang</keyname><forenames>P. C.</forenames></author><author><keyname>Wang</keyname><forenames>Q.</forenames></author><author><keyname>Wang</keyname><forenames>T. F.</forenames></author><author><keyname>Wang</keyname><forenames>Y. F.</forenames></author><author><keyname>Wang</keyname><forenames>Z. H.</forenames></author><author><keyname>Wang</keyname><forenames>Z.</forenames></author><author><keyname>Wen</keyname><forenames>J.</forenames></author><author><keyname>Wen</keyname><forenames>Z. W.</forenames></author><author><keyname>Wu</keyname><forenames>Q. B.</forenames></author><author><keyname>Wu</keyname><forenames>X. G.</forenames></author><author><keyname>Wu</keyname><forenames>X.</forenames></author><author><keyname>Yang</keyname><forenames>Y. W.</forenames></author><author><keyname>Yi</keyname><forenames>H.</forenames></author><author><keyname>Yu</keyname><forenames>L.</forenames></author><author><keyname>Yu</keyname><forenames>Y. J.</forenames></author><author><keyname>Zhang</keyname><forenames>G. H.</forenames></author><author><keyname>Zhang</keyname><forenames>L. Y.</forenames></author><author><keyname>Zhang</keyname><forenames>J.</forenames></author><author><keyname>Zhang</keyname><forenames>Q. M.</forenames></author><author><keyname>Zhang</keyname><forenames>Q. W.</forenames></author><author><keyname>Zhang</keyname><forenames>X. P.</forenames></author><author><keyname>Zhao</keyname><forenames>Y. T.</forenames></author><author><keyname>Zhong</keyname><forenames>Q. P.</forenames></author><author><keyname>Zhou</keyname><forenames>L.</forenames></author><author><keyname>Zhou</keyname><forenames>Z. Y.</forenames></author><author><keyname>Zhu</keyname><forenames>K. J.</forenames></author></authors><title>Electronics of Time-of-flight Measurement for Back-n at CSNS</title><categories>physics.ins-det eess.SP</categories><comments>4 pages, 13 figures, 21st IEEE Real Time Conference</comments><doi>10.1109/TNS.2019.2900480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Back-n is a white neutron experimental facility at China Spallation Neutron
Source (CSNS). The time structure of the primary proton beam make it fully
applicable to use TOF (time-of-flight) method for neutron energy measuring. We
implement the electronics of TOF measurement on the general-purpose readout
electronics designed for all of the seven detectors in Back-n. The electronics
is based on PXIe (Peripheral Component Interconnect Express eXtensions for
Instrumentation) platform, which is composed of FDM (Field Digitizer Modules),
TCM (Trigger and Clock Module), and SCM (Signal Conditioning Module). T0 signal
synchronous to the CSNS accelerator represents the neutron emission from the
target. It is the start of time stamp. The trigger and clock module (TCM)
receives, synchronizes and distributes the T0 signal to each FDM based on the
PXIe backplane bus. Meantime, detector signals after being conditioned are fed
into FDMs for waveform digitizing. First sample point of the signal is the stop
of time stamp. According to the start, stop time stamp and the time of signal
over threshold, the total TOF can be obtained. FPGA-based (Field Programmable
Gate Array) TDC is implemented on TCM to accurately acquire the time interval
between the asynchronous T0 signal and the global synchronous clock phase.
There is also an FPGA-based TDC on FDM to accurately acquire the time interval
between T0 arriving at FDM and the first sample point of the detector signal,
the over threshold time of signal is obtained offline. This method for TOF
measurement is efficient and not needed for additional modules. Test result
shows the accuracy of TOF is sub-nanosecond and can meet the requirement for
Back-n at CSNS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09257</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09257</id><created>2018-06-24</created><authors><author><keyname>Zhu</keyname><forenames>Danyang</forenames></author><author><keyname>Liu</keyname><forenames>Shubin</forenames></author><author><keyname>Feng</keyname><forenames>Changqing</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Chen</keyname><forenames>Haolei</forenames></author></authors><title>Development of the Front-End Electronics for PandaX-III Prototype TPC</title><categories>physics.ins-det eess.SP</categories><doi>10.1109/TNS.2019.2907125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Particle And Astrophysical Xenon Experiment III (PandaX-III) is an
experiment to search for the Neutrinoless Double Beta Decay (NLDBD) using 200
kg radio-pure high-pressure gaseous xenon TPC with Micromegas detectors at both
ends and cathode in the middle. A small-scale TPC equipped with 7 Microbulk
Micromegas detectors is developed as the prototype detector. 128 channels are
readout following an X-Y design with strips of 3 mm pitch (64 channels each
direction) from one Micromegas module. Highly integrated front-end electronics
composed of 4 front-end cards with 1024 readout channels is designed to readout
the charge of Micromegas anode signals, digitize the waveform after shaping and
send compressed data to the DCM board. The cornerstone of the front-end
electronics is a 64-channel application specific integrated circuit which is
based on a switched capacitor array. The integral nonlinearity of the front-end
electronics is less than 1% with 1 pC. The noise (RMS) of each readout channel
is less than 0.9 fC with 1 microsecond peaking time and 1 pC range. Using the
radioactive sources 56 Fe and 137 Cs, joint-tests of front-end electronics with
the prototype TPC were carried out and the hit map of 7 Micromegas has been
reconstructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09258</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09258</id><created>2018-06-24</created><authors><author><keyname>Jiang</keyname><forenames>Wei</forenames></author><author><keyname>Huang</keyname><forenames>Xiru</forenames></author><author><keyname>Cao</keyname><forenames>Ping</forenames></author><author><keyname>Li</keyname><forenames>Chao</forenames></author><author><keyname>Wang</keyname><forenames>Junru</forenames></author><author><keyname>Li</keyname><forenames>Jiawen</forenames></author><author><keyname>Yuan</keyname><forenames>Jianhui</forenames></author><author><keyname>An</keyname><forenames>Qi</forenames></author></authors><title>Real-time Data Flow Control for CBM-TOF Super Module Quality Evaluation</title><categories>physics.ins-det eess.SP</categories><doi>10.1109/TNS.2019.2900657</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Super module assembled with MRPC detectors is the component unit of TOF (Time
of Flight) system for the Compressed Baryonic Matter (CBM) experiment. Quality
of super modules needs to be evaluated before it is applied in CBM-TOF. Time
signals exported from super module are digitalized at TDC (Time to Digital
Converter) station. Data rate is up to 6 Gbps at each TDC station, which brings
a tremendous pressure for data transmission in real time. In this paper, a
real-time data flow control method is designed. In this control method, data
flow is divided into 3 types: scientific data flow, status data flow and
control data flow. In scientific data flow, data of each TDC station is divided
into 4 sub-flows, and then is read out by a parallel and hierarchical network,
which consists of multiple readout mother boards and daughter boards groups. In
status data flow, status data is aggregated into a specific readout mother
board. Then it is uploaded to DAQ via readout daughter board. In control data
flow, control data is downloaded to all circuit modules in the opposite
direction of status data flow. Preliminary test result indicated data of STS
was correctly transmitted to DAQ with no error and three type data flows were
control orderly in real time. This data flow control method can meet the
quality evaluation requirement of supper module in CBM-TOF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09268</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09268</id><created>2018-06-24</created><authors><author><keyname>Grzegrz&#xf3;&#x142;ka</keyname><forenames>Maciej</forenames></author><author><keyname>Czuba</keyname><forenames>Krzysztof</forenames></author><author><keyname>Lipi&#x144;ski</keyname><forenames>Mateusz</forenames></author><author><keyname>Rutkowski</keyname><forenames>Igor</forenames></author></authors><title>Cavity Simulator for European Spallation Source</title><categories>physics.acc-ph eess.SP physics.ins-det</categories><comments>21st IEEE Real Time Conference</comments><doi>10.1109/TNS.2019.2890994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  European Spallation Source will be the brightest neutron source in the world.
It is being built in Lund, Sweden. Over 120 superconducting cavities will be
installed in the facility, each regulated by an individual LLRF control system.
To reduce the risk associated with testing the systems on real cavities a
Cavity Simulator was designed. It reproduces the behaviour of superconducting
cavities used in the medium and high beta sections of ESS's Linac. The high
power RF amplifier and piezo actuators parameters are also simulated. Based on
the RF drive and piezo control signals the Cavity Simulator generates the RF
signals acquired by the inputs of the LLRF control system. This is used to
close the LLRF feedback loop in real time. The RF front end of the Cavity
Simulator consists of vector modulators, down-converting circuits, and a set of
fast data converters. The cavity response simulation is performed in a high
speed FPGA logic by a dedicated firmware, that was optimized to minimize the
processing time. The device also generates clock, LO, and the 704.42 MHz
reference signals to allow for system tests outside of the accelerator
environment. In this paper the design of the Cavity Simulator, description of
the algorithms used in its firmware, and measurement results of the device are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09270</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09270</id><created>2018-06-24</created><authors><author><keyname>Brown</keyname><forenames>E. R.</forenames></author><author><keyname>Zhang</keyname><forenames>W-D.</forenames></author><author><keyname>Growden</keyname><forenames>T. A.</forenames></author><author><keyname>Berger</keyname><forenames>P. R.</forenames></author><author><keyname>Droopad</keyname><forenames>R.</forenames></author><author><keyname>Storm</keyname><forenames>D. F.</forenames></author><author><keyname>Meyer</keyname><forenames>D. J.</forenames></author></authors><title>Noise Measurements of High-Speed, Light-Emitting GaN Resonant-Tunneling
  Diodes</title><categories>cond-mat.mes-hall eess.SP</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report here the first RF noise measurements on two designs of n-doped
GaN/AlN double-barrier resonant tunneling diodes (RTDs), each having a
room-temperature negative differential resistance (NDR) and also strong near-UV
light emission. The measurements are made with a standard, un-isolated RF
receiver and calibration is made using a substitution-resistor/hot-cold
radiometric technique which works in the positive differential resistance (PDR)
region but not the NDR region. A high-quality InGaAs/AlAs double-barrier RTD is
used as a control sample and displays shot noise suppression down to
$\Gamma\approx$0.5 in the PDR region, as expected. The GaN/AlN RTDs display
both shot-noise enhancement and suppression in the PDR regions, but no obvious
sign of sudden shot-noise enhancement in the threshold bias region of light
emission. This supports the hypothesis that the holes required for light
emission are created by electronic (Zener) interband tunneling, not impact
ionization. Further the minimum shot-noise factor of $\Gamma\sim$ 0.34 suggests
that the GaN/AlN RTDs are acting like triple-barrier devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09276</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09276</id><created>2018-06-24</created><updated>2018-06-25</updated><authors><author><keyname>Li</keyname><forenames>Hao</forenames></author><author><keyname>Kang</keyname><forenames>Yongguo</forenames></author><author><keyname>Wang</keyname><forenames>Zhenyu</forenames></author></authors><title>EMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis
  System</title><categories>eess.AS cs.SD</categories><comments>Accepted by Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present EMPHASIS, an emotional phoneme-based acoustic model for speech
synthesis system. EMPHASIS includes a phoneme duration prediction model and an
acoustic parameter prediction model. It uses a CBHG-based regression network to
model the dependencies between linguistic features and acoustic features. We
modify the input and output layer structures of the network to improve the
performance. For the linguistic features, we apply a feature grouping strategy
to enhance emotional and prosodic features. The acoustic parameters are
designed to be suitable for the regression task and waveform reconstruction.
EMPHASIS can synthesize speech in real-time and generate expressive
interrogative and exclamatory speech with high audio quality. EMPHASIS is
designed to be a multi-lingual model and can synthesize Mandarin-English speech
for now. In the experiment of emotional speech synthesis, it achieves better
subjective results than other real-time speech synthesis systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09281</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09281</id><created>2018-06-25</created><authors><author><keyname>G&#x105;sowski</keyname><forenames>Bartosz</forenames></author><author><keyname>Owczarek</keyname><forenames>Tomasz</forenames></author><author><keyname>Czuba</keyname><forenames>Krzysztof</forenames></author><author><keyname>Zembala</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Schlarb</keyname><forenames>Holger</forenames></author></authors><title>Real-Time Redundancy for the 1.3 GHz Master Oscillator of the
  European-XFEL</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many modern large-scale facilities, like European X-ray Free Electron Laser
(E-XFEL), require precise synchronisation, often down to femtosecond level.
Even a very short interruption or an excessive glitch in the reference signal
might break the precise time relations between subsystems. In such event, a
time-consuming resynchronization process is required that renders the facility
not available for the users until it is completed. Therefore, such events are
highly undesirable.
  In this paper, we present an autonomous redundancy solution for the
European-XFEL's master oscillator that will guarantee a continuous delivery of
the high-quality reference signal even in case of most of the potential
failures. The concept and implementation are presented, as well as results from
testing in the laboratory environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09301</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09301</id><created>2018-06-25</created><authors><author><keyname>Dubey</keyname><forenames>Harishchandra</forenames></author><author><keyname>Sangwan</keyname><forenames>Abhijeet</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Robust Feature Clustering for Unsupervised Speech Activity Detection</title><categories>cs.SD eess.AS</categories><comments>5 Pages, 4 Tables, 1 Figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In certain applications such as zero-resource speech processing or very-low
resource speech-language systems, it might not be feasible to collect speech
activity detection (SAD) annotations. However, the state-of-the-art supervised
SAD techniques based on neural networks or other machine learning methods
require annotated training data matched to the target domain. This paper
establish a clustering approach for fully unsupervised SAD useful for cases
where SAD annotations are not available. The proposed approach leverages
Hartigan dip test in a recursive strategy for segmenting the feature space into
prominent modes. Statistical dip is invariant to distortions that lends
robustness to the proposed method. We evaluate the method on NIST OpenSAD 2015
and NIST OpenSAT 2017 public safety communications data. The results showed the
superiority of proposed approach over the two-component GMM baseline. Index
Terms: Clustering, Hartigan dip test, NIST OpenSAD, NIST OpenSAT, speech
activity detection, zero-resource speech processing, unsupervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09325</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09325</id><created>2018-06-25</created><authors><author><keyname>Li</keyname><forenames>Chenxing</forenames></author><author><keyname>Wang</keyname><forenames>Tieqiang</forenames></author><author><keyname>Xu</keyname><forenames>Shuang</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>Single-channel Speech Dereverberation via Generative Adversarial
  Training</title><categories>cs.SD cs.CL eess.AS</categories><comments>5 pages. Accepted by Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a single-channel speech dereverberation system
(DeReGAT) based on convolutional, bidirectional long short-term memory and deep
feed-forward neural network (CBLDNN) with generative adversarial training
(GAT). In order to obtain better speech quality instead of only minimizing a
mean square error (MSE), GAT is employed to make the dereverberated speech
indistinguishable form the clean samples. Besides, our system can deal with
wide range reverberation and be well adapted to variant environments. The
experimental results show that the proposed model outperforms weighted
prediction error (WPE) and deep neural network-based systems. In addition,
DeReGAT is extended to an online speech dereverberation scenario, which reports
comparable performance with the offline case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09380</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09380</id><created>2018-06-25</created><authors><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Wireless Power Transfer in Cooperative DF Relaying Networks with
  Log-Normal Fading</title><categories>eess.SP</categories><doi>10.1109/GLOCOM.2016.7842388</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-harvesting and wireless power transfer in cooperative relaying
networks have recently attracted a considerable amount of research attention.
Most of the existing work on this topic however focuses on Rayleigh fading
channels which represents outdoor environments. Unlike these studies, in this
paper we analyze the performance of wireless power transfer in two-hop
decode-and-forward (DF) cooperative relaying systems in indoor channels
characterized by log-normal fading. Three well-known energy-harvesting
protocols are considered in our evaluations: a) time-switching relaying (TSR),
b) power-splitting relaying (PSR) and c) ideal relaying receiver (IRR). The
performance is evaluated in terms of the ergodic outage probability for which
we derive accurate analytical expressions for the three systems under
consideration. Results reveal that careful selection of the energy-harvesting
time and power-splitting factors in the TSR- and PSR-based system are important
to optimize performance. It is also presented that the optimized PSR system has
near-ideal performance and that increasing the source transmit power and/or the
energy-harvester efficiency can further improve performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09382</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09382</id><created>2018-06-25</created><authors><author><keyname>Saffarpour</keyname><forenames>Mahya</forenames></author><author><keyname>Ghiasi</keyname><forenames>Soheil</forenames></author></authors><title>A Design Space Exploration (DSE) on Non-Invasive Sensing of Bladder
  Filling Using Near Infrared Spectroscopy (NIRS)</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urinary Incontinence (UI) is a widespread medical condition that affects one
person from every three or four Americans. Near-Infrared Spectroscopy (NIRS) is
a non-invasive under-study method for bladder filling sensation that can
enhance the life quality of UI patients by finding the optimal voiding time.
However, the application of NIRS to bladder volume sensing can be quite
challenging due to three major obstacles: non-adequate traversal depth of NIR
wavelengths, robustness and power efficiency requirements of the application,
and low power transmission rate of NIR wavelengths. This work provides a Design
Space Exploration (DSE) through the effect of various design parameters on NIRS
applicability for bladder volume sensing. We investigate the impact of 7
different wavelengths from 650-950 nm, 16 possible detector-source distances,
and 6 different sensation depths. The results of our work can be used as a
guideline through optimal design and implementation of NIRS for bladder filling
sensation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09411</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09411</id><created>2018-06-25</created><updated>2019-01-24</updated><authors><author><keyname>Zhao</keyname><forenames>Ziyue</forenames></author><author><keyname>Liu</keyname><forenames>Huijun</forenames></author><author><keyname>Fingscheidt</keyname><forenames>Tim</forenames></author></authors><title>Convolutional Neural Networks to Enhance Coded Speech</title><categories>eess.AS cs.SD</categories><comments>More analysis are added for version 4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enhancing coded speech suffering from far-end acoustic background noise,
quantization noise, and potentially transmission errors, is a challenging task.
In this work we propose two postprocessing approaches applying convolutional
neural networks (CNNs) either in the time domain or the cepstral domain to
enhance the coded speech without any modification of the codecs. The time
domain approach follows an end-to-end fashion, while the cepstral domain
approach uses analysis-synthesis with cepstral domain features. The proposed
postprocessors in both domains are evaluated for various narrowband and
wideband speech codecs in a wide range of conditions. The proposed
postprocessor improves speech quality (PESQ) by up to 0.25 MOS-LQO points for
G.711, 0.30 points for G.726, 0.82 points for G.722, and 0.26 points for
adaptive multirate wideband codec (AMR-WB). In a subjective CCR listening test,
the proposed postprocessor on G.711-coded speech exceeds the speech quality of
an ITU-T-standardized postfilter by 0.36 CMOS points, and obtains a clear
preference of 1.77 CMOS points compared to legacy G.711, even better than
uncoded speech with statistical significance. The source code for the cepstral
domain approach to enhance G.711-coded speech is made available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09465</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09465</id><created>2018-06-21</created><authors><author><keyname>Pavlov</keyname><forenames>Konstantin M.</forenames></author><author><keyname>Morgan</keyname><forenames>Kaye S.</forenames></author><author><keyname>Punegov</keyname><forenames>Vasily I.</forenames></author><author><keyname>Paganin</keyname><forenames>David M.</forenames></author></authors><title>Deterministic X-ray Bragg coherent diffraction imaging as a seed for
  subsequent iterative reconstruction</title><categories>eess.IV</categories><comments>12 pages, 4 figures</comments><journal-ref>Journal of Physics Communications 2, 085027 (2018)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coherent diffractive imaging (CDI), using both X-rays and electrons, has made
extremely rapid progress over the past two decades. The associated
reconstruction algorithms are typically iterative, and seeded with a crude
first estimate. A deterministic method for Bragg Coherent Diffraction Imaging
(Pavlov et al., Sci. Rep. 7, 1132 (2017)) is used as a more refined starting
point for a shrink-wrap iterative reconstruction procedure. The appropriate
comparison with the autocorrelation function as a starting point is performed.
Real-space and Fourier-space error metrics are used to analyse the convergence
of the reconstruction procedure for noisy and noise-free simulated data. Our
results suggest that the use of deterministic-CDI reconstructions, as a seed
for subsequent iterative-CDI refinement, may boost the speed and degree of
convergence compared to the cruder seeds that are currently commonly used. We
also highlight the utility of monitoring multiple error metrics in the context
of iterative refinement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09514</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09514</id><created>2018-06-25</created><authors><author><keyname>Adigwe</keyname><forenames>Adaeze</forenames></author><author><keyname>Tits</keyname><forenames>No&#xe9;</forenames></author><author><keyname>Haddad</keyname><forenames>Kevin El</forenames></author><author><keyname>Ostadabbas</keyname><forenames>Sarah</forenames></author><author><keyname>Dutoit</keyname><forenames>Thierry</forenames></author></authors><title>The Emotional Voices Database: Towards Controlling the Emotion Dimension
  in Voice Generation Systems</title><categories>cs.CL cs.AI eess.AS</categories><comments>Submitted to SLSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a database of emotional speech intended to be
open-sourced and used for synthesis and generation purpose. It contains data
for male and female actors in English and a male actor in French. The database
covers 5 emotion classes so it could be suitable to build synthesis and voice
transformation systems with the potential to control the emotional dimension in
a continuous way. We show the data's efficiency by building a simple MLP system
converting neutral to angry speech style and evaluate it via a CMOS perception
test. Even though the system is a very simple one, the test show the efficiency
of the data which is promising for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09548</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09548</id><created>2018-06-25</created><updated>2019-12-10</updated><authors><author><keyname>Lindholm</keyname><forenames>Andreas</forenames></author><author><keyname>Lindsten</keyname><forenames>Fredrik</forenames></author></authors><title>Learning dynamical systems with particle stochastic approximation EM</title><categories>stat.CO cs.CE eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the particle stochastic approximation EM (PSAEM) algorithm for
learning of dynamical systems. The method builds on the EM algorithm, an
iterative procedure for maximum likelihood inference in latent variable models.
By combining stochastic approximation EM and particle Gibbs with ancestor
sampling (PGAS), PSAEM obtains superior computational performance and
convergence properties compared to plain particle-smoothing-based
approximations of the EM algorithm. PSAEM can be used for plain maximum
likelihood inference as well as for empirical Bayes learning of
hyperparameters. Specifically, the latter point means that existing PGAS
implementations easily can be extended with PSAEM to estimate hyperparameters
at almost no extra computational cost. We discuss the convergence properties of
the algorithm, and demonstrate it on several signal processing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09587</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09587</id><created>2018-06-25</created><authors><author><keyname>Hung</keyname><forenames>Yun-Ning</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Frame-level Instrument Recognition by Timbre and Pitch</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Instrument recognition is a fundamental task in music information retrieval,
yet little has been done to predict the presence of instruments in
multi-instrument music for each time frame. This task is important for not only
automatic transcription but also many retrieval problems. In this paper, we use
the newly released MusicNet dataset to study this front, by building and
evaluating a convolutional neural network for making frame-level instrument
prediction. We consider it as a multi-label classification problem for each
frame and use frame-level annotations as the supervisory signal in training the
network. Moreover, we experiment with different ways to incorporate pitch
information to our model, with the premise that doing so informs the model the
notes that are active per frame, and also encourages the model to learn
relative rates of energy buildup in the harmonic partials of different
instruments. Experiments show salient performance improvement over baseline
methods. We also report an analysis probing how pitch information helps the
instrument prediction task. Code and experiment details can be found at
\url{https://biboamy.github.io/instrument-recognition/}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09617</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09617</id><created>2018-06-25</created><authors><author><keyname>Sinclair</keyname><forenames>Stephen</forenames></author></authors><title>Sounderfeit: Cloning a Physical Model using a Conditional Adversarial
  Autoencoder</title><categories>cs.SD cs.LG cs.NE eess.AS</categories><comments>Extended conference paper published as article in Brazilian
  open-access journal Musica Hodie. 17 pages, 10 figures. ISSN 1676-3939.
  Dispon\'ivel em: https://www.revistas.ufg.br/musica/article/view/53570. arXiv
  admin note: substantial text overlap with arXiv:1802.08008</comments><journal-ref>Revista M\'usica Hodie, [S.l.], v. 18, n. 1, p. 44 - 60, jun. 2018</journal-ref><doi>10.5216/mh.v18i1.53570</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  An adversarial autoencoder conditioned on known parameters of a physical
modeling bowed string synthesizer is evaluated for use in parameter estimation
and resynthesis tasks. Latent dimensions are provided to capture variance not
explained by the conditional parameters. Results are compared with and without
the adversarial training, and a system capable of &quot;copying&quot; a given
parameter-signal bidirectional relationship is examined. A real-time synthesis
system built on a generative, conditioned and regularized neural network is
presented, allowing to construct engaging sound synthesizers based purely on
recorded data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09727</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09727</id><created>2018-06-25</created><updated>2018-09-25</updated><authors><author><keyname>Paschoal</keyname><forenames>A. J. A.</forenames></author><author><keyname>de Souza</keyname><forenames>R. M. Campello</forenames></author><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author></authors><title>The Hamming and Golay Number-Theoretic Transforms</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 2 figures</comments><report-no>XXXVI Simp\'osio Brasileiro de Telecomunica\c{c}\~oes SBrT 2018</report-no><msc-class>11Txx, 11Yxx, 11H71, 11D04, 15Bxx</msc-class><doi>10.14209/SBRT.2018.179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New number-theoretic transforms are derived from known linear block codes
over finite fields. In particular, two new such transforms are built from
perfect codes, namely the \textit {Hamming number-theoretic transform} and the
\textit {Golay number-theoretic transform}. A few properties of these new
transforms are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09843</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09843</id><created>2018-06-26</created><updated>2018-09-03</updated><authors><author><keyname>Kim</keyname><forenames>Minsu</forenames></author><author><keyname>Lee</keyname><forenames>Jemin</forenames></author></authors><title>Outage Probability of UAV Communications in the Presence of Interference</title><categories>eess.SP</categories><comments>6 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike terrestrial communications, unmanned aerial vehicle (UAV)
communications have some advantages such as line-of-sight (LoS) environment and
flexible mobility, but the interference will be still inevitable. In this
paper, we analyze the effect of interference on the UAV communications by
considering the LoS probability and different channel fadings for LoS and
non-line-of-sight (NLoS) links, affected by the elevation angle of
communication link. We then derive a closed-form outage probability in the
presence of interfering node for all the possible scenarios and environments of
main and interference links. After discussing the impacts of transmitting and
interfering node parameters on the outage probability, we show the existence of
the optimal height of UAV that minimizes the outage probability. We also show
NLoS environment can be better than LoS environment if the average received
power of interference is more dominant than that of transmitting signal in UAV
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09844</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09844</id><created>2018-06-26</created><updated>2018-07-17</updated><authors><author><keyname>Kim</keyname><forenames>Dongsun</forenames></author><author><keyname>Lee</keyname><forenames>Jemin</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author></authors><title>Performance Analysis for Multi-layer Unmanned Aerial Vehicle Networks</title><categories>eess.SP</categories><comments>6 pages, 4 figures, Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide the model of the multilayer aerial network (MAN),
composed unmanned aerial vehicles (UAVs) that distributed in Poisson point
process (PPP) with different densities, heights, and transmission power. In our
model, we consider the line of sight (LoS) and non-line of sight (NLoS)
channels which is probabilistically formed. We firstly derive the probability
distribution function (PDF) of the main link distance and the Laplace transform
of interference of MAN considering strongest average received power-based
association. We then analyze the successful transmission probability (STP) of
the MAN and provide the upper bound of the optimal density that maximizes the
STP of the MAN. Through the numerical results, we show the existence of the
optimal height of UAV due to a performance tradeoff caused by the height of the
aerial network (AN), and also show the upper bounds of the optimal densities in
terms of the STP, which decrease with the height of the ANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09905</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09905</id><created>2018-06-26</created><authors><author><keyname>Manzelli</keyname><forenames>Rachel</forenames></author><author><keyname>Thakkar</keyname><forenames>Vijay</forenames></author><author><keyname>Siahkamari</keyname><forenames>Ali</forenames></author><author><keyname>Kulis</keyname><forenames>Brian</forenames></author></authors><title>Conditioning Deep Generative Raw Audio Models for Structured Automatic
  Music</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Presented at the ISMIR 2018 Conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Existing automatic music generation approaches that feature deep learning can
be broadly classified into two types: raw audio models and symbolic models.
Symbolic models, which train and generate at the note level, are currently the
more prevalent approach; these models can capture long-range dependencies of
melodic structure, but fail to grasp the nuances and richness of raw audio
generations. Raw audio models, such as DeepMind's WaveNet, train directly on
sampled audio waveforms, allowing them to produce realistic-sounding, albeit
unstructured music. In this paper, we propose an automatic music generation
methodology combining both of these approaches to create structured,
realistic-sounding compositions. We consider a Long Short Term Memory network
to learn the melodic structure of different styles of music, and then use the
unique symbolic generations from this model as a conditioning input to a
WaveNet-based raw audio generator, creating a model for automatic, novel music.
We then evaluate this approach by showcasing results of this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09932</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09932</id><created>2018-06-26</created><authors><author><keyname>Adel</keyname><forenames>Mohamed</forenames></author><author><keyname>Afify</keyname><forenames>Mohamed</forenames></author><author><keyname>Gaballah</keyname><forenames>Akram</forenames></author></authors><title>Text-Independent Speaker Verification Based on Deep Neural Networks and
  Segmental Dynamic Time Warping</title><categories>cs.SD cs.CL eess.AS</categories><comments>Submitted to SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new method for text-independent speaker
verification that combines segmental dynamic time warping (SDTW) and the
d-vector approach. The d-vectors, generated from a feed forward deep neural
network trained to distinguish between speakers, are used as features to
perform alignment and hence calculate the overall distance between the
enrolment and test utterances.We present results on the NIST 2008 data set for
speaker verification where the proposed method outperforms the conventional
i-vector baseline with PLDA scores and outperforms d-vector approach with local
distances based on cosine and PLDA scores. Also score combination with the
i-vector/PLDA baseline leads to significant gains over both methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09968</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09968</id><created>2018-06-19</created><authors><author><keyname>Yuan</keyname><forenames>Ziyang</forenames></author><author><keyname>Wang</keyname><forenames>Hongxia</forenames></author></authors><title>Multiple Scattering Media Imaging via End-to-End Neural Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering the image of an object from its phaseless speckle pattern is
difficult. Let alone the transmission matrix is unknown in multiple scattering
media imaging. Double phase retrieval is a recently proposed efficient method
which recovers the unknown object from its phaseless measurements by two steps
with phase retrieval.
  In this paper, we combine the two steps in double phase retrieval and
construct an end-to-end neural network called TCNN(Transforming Convolutional
Neural Network) which directly learns the relationship between the phaseless
measurements and the object. TCNN contains a special layer called transform
layer which aims to be a bridge between different transform domains. Tested by
the empirical data provided in\cite{Metzler2017Coherent}, images can be
recovered by TCNN with comparable quality compared with state-of-the-art
methods. Not only the transmission matrix needn't to be calculated but also the
time to recover the object can be hugely reduced once the parameters of TCNN
are stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09980</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09980</id><created>2018-06-23</created><authors><author><keyname>Behzad</keyname><forenames>Muzammil</forenames></author><author><keyname>Abdullah</keyname><forenames>Manal</forenames></author><author><keyname>Hassan</keyname><forenames>Muhammad Talal</forenames></author><author><keyname>Ge</keyname><forenames>Yao</forenames></author><author><keyname>Khan</keyname><forenames>Mahmood Ashraf</forenames></author></authors><title>Toward Performance Optimization in IoT-based Next-Gen Wireless Sensor
  Networks</title><categories>eess.SP cs.CV cs.NI eess.IV</categories><comments>45 pages, 22 figures, pending article. arXiv admin note: substantial
  text overlap with arXiv:1712.04259</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel framework for performance optimization in
Internet of Things (IoT)-based next-generation wireless sensor networks. In
particular, a computationally-convenient system is presented to combat two
major research problems in sensor networks. First is the conventionally-tackled
resource optimization problem which triggers the drainage of battery at a
faster rate within a network. Such drainage promotes inefficient resource usage
thereby causing sudden death of the network. The second main bottleneck for
such networks is that of data degradation. This is because the nodes in such
networks communicate via a wireless channel, where the inevitable presence of
noise corrupts the data making it unsuitable for practical applications.
Therefore, we present a layer-adaptive method via 3-tier communication
mechanism to ensure the efficient use of resources. This is supported with a
mathematical coverage model that deals with the formation of coverage holes. We
also present a transform-domain based robust algorithm to effectively remove
the unwanted components from the data. Our proposed framework offers a handy
algorithm that enjoys desirable complexity for real-time applications as shown
by the extensive simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09981</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09981</id><created>2018-06-23</created><authors><author><keyname>Liu</keyname><forenames>Jinchao</forenames></author><author><keyname>Gibson</keyname><forenames>Stuart J.</forenames></author><author><keyname>Mills</keyname><forenames>James</forenames></author><author><keyname>Osadchy</keyname><forenames>Margarita</forenames></author></authors><title>Dynamic Spectrum Matching with One-shot Learning</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) have been shown to provide a good
solution for classification problems that utilize data obtained from
vibrational spectroscopy. Moreover, CNNs are capable of identification from
noisy spectra without the need for additional preprocessing. However, their
application in practical spectroscopy is limited due to two shortcomings. The
effectiveness of the classification using CNNs drops rapidly when only a small
number of spectra per substance are available for training (which is a typical
situation in real applications). Additionally, to accommodate new, previously
unseen substance classes, the network must be retrained which is
computationally intensive. Here we address these issues by reformulating a
multi-class classification problem with a large number of classes, but a small
number of samples per class, to a binary classification problem with sufficient
data available for representation learning. Namely, we define the learning task
as identifying pairs of inputs as belonging to the same or different classes.
We achieve this using a Siamese convolutional neural network. A novel sampling
strategy is proposed to address the imbalance problem in training the Siamese
Network. The trained network can effectively classify samples of unseen
substance classes using just a single reference sample (termed as one-shot
learning in the machine learning community). Our results demonstrate better
accuracy than other practical systems to date, while allowing effortless
updates of the system's database with novel substance classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09994</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09994</id><created>2018-06-24</created><authors><author><keyname>Wadehn</keyname><forenames>Federico</forenames></author><author><keyname>Fanelli</keyname><forenames>Andrea</forenames></author><author><keyname>Heldt</keyname><forenames>Thomas</forenames></author></authors><title>Segmentation of TCD Cerebral Blood Flow Velocity Recordings</title><categories>eess.SP physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binary beat-by-beat classification algorithm for cerebral blood flow
velocity (CBFV) recordings based on amplitude, spectral and morphological
features is presented. The classification difference between 15 manually and
algorithmically annotated CBFV records is around 5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.09998</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.09998</id><created>2018-06-24</created><authors><author><keyname>Liu</keyname><forenames>S. Q.</forenames></author><author><keyname>Ji</keyname><forenames>Z. S.</forenames></author><author><keyname>Wang</keyname><forenames>Y</forenames></author><author><keyname>Zhang</keyname><forenames>Z. C.</forenames></author></authors><title>Real time state monitoring and fault diagnosis system for motor based on
  LabVIEW</title><categories>eess.SP cs.SE cs.SY</categories><comments>4 pages,the IEEE NPSS Real Time Conference</comments><report-no>547,poster session 1</report-no><journal-ref>2018 IEEE-NPSS Real Time Conference (RT)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motor is the most widely used production equipment in industrial field. In
order to realize the real-time state monitoring and multi-fault pre-diagnosis
of three-phase motor, this paper presents a design of three-phase motor state
monitoring and fault diagnosis system based on LabVIEW.
  The multi-dimensional vibration acceleration, rotational speed, temperature,
current and voltage signals of the motor are collected with NI cDAQ acquisition
equipment in real time and high speed. At the same time, the model of motor
health state and fault state is established. The order analysis algorithm is
used to analyze the data at an advanced level, and the diagnosis and
classification of different fault types are realized. The system is equipped
with multi-channel acquisition, display, analysis and storage. Combined with
the current cloud transmission technology, we will back up the data to the
cloud to be used by other terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10013</identifier>
 <datestamp>2018-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10013</id><created>2018-06-26</created><authors><author><keyname>Gheth</keyname><forenames>Waled</forenames></author><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Ijaz</keyname><forenames>Muhammad</forenames></author><author><keyname>Harris</keyname><forenames>Georgina</forenames></author><author><keyname>Alfitouri</keyname><forenames>A.</forenames></author></authors><title>Hybrid Power-Line/Wireless Communication Systems For Indoor Applications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high attenuation which increases as frequency increases in power line
communication systems (PLC) makes achieving and sustaining high data rates over
such channels a challenging task. In most communication systems, relays are
normally deployed to overcome the effect of signal attenuation and to achieve
reliable transmissions between users. Amplifyand- forward (AF) and
decode-and-forward (DF) relays are often used. In contrast to the existing work
on this topic which advocate utilizing relays either between PLC links or
between wireless links, the authors of this paper focus on using AF relaying
for in-home PLC and wireless systems where one PLC user wants to share data
with one wireless user which has no access to the PLC network. We refer to this
system as the Hybrid approach. A mathematical method is developed for this
network to formulate the capacity of the system by exploiting the statistical
properties of both PLC and wireless channels. Monte Carlo simulations are used
throughout this paper to validate the analytical results. The impact of several
system parameters is investigated in this paper. For the sake of comparison, we
also provide the performance analysis and results for a PLC only network. The
results showed that the performance of the hybrid system enhances as we
increase the relay gain and deteriorates as the end-to-end distance increases.
It is also found that the PLC only scheme may outperform the hybrid one if the
relay gain is relatively small; however, the user mobility offered by the
hybrid system remains the main advantage over the PLC only system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10029</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10029</id><created>2018-06-25</created><authors><author><keyname>Goy</keyname><forenames>Alexandre</forenames></author><author><keyname>Arthur</keyname><forenames>Kwabena</forenames></author><author><keyname>Li</keyname><forenames>Shuai</forenames></author><author><keyname>Barbastathis</keyname><forenames>George</forenames></author></authors><title>Low Photon Count Phase Retrieval Using Deep Learning</title><categories>eess.IV physics.optics</categories><comments>8 pages, 5 figures</comments><journal-ref>Phys. Rev. Lett. 121, 243902 (2018)</journal-ref><doi>10.1103/PhysRevLett.121.243902</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging systems' performance at low light intensity is affected by shot
noise, which becomes increasingly strong as the power of the light source
decreases. In this paper we experimentally demonstrate the use of deep neural
networks to recover objects illuminated with weak light and demonstrate better
performance than with the classical Gerchberg-Saxton phase retrieval algorithm
for equivalent signal over noise ratio. Prior knowledge about the object is
implicitly contained in the training data set and feature detection is possible
for a signal over noise ratio close to one. We apply this principle to a phase
retrieval problem and show successful recovery of the object's most salient
features with as little as one photon per detector pixel on average in the
illumination beam. We also show that the phase reconstruction is significantly
improved by training the neural network with an initial estimate of the object,
as opposed as training it with the raw intensity measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10171</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10171</id><created>2018-06-26</created><updated>2019-04-11</updated><authors><author><keyname>Simon</keyname><forenames>Dror</forenames></author><author><keyname>Sulam</keyname><forenames>Jeremias</forenames></author><author><keyname>Romano</keyname><forenames>Yaniv</forenames></author><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>MMSE Approximation For Sparse Coding Algorithms Using Stochastic
  Resonance</title><categories>eess.SP cs.CV</categories><doi>10.1109/TSP.2019.2929464</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse coding refers to the pursuit of the sparsest representation of a
signal in a typically overcomplete dictionary. From a Bayesian perspective,
sparse coding provides a Maximum a Posteriori (MAP) estimate of the unknown
vector under a sparse prior. In this work, we suggest enhancing the performance
of sparse coding algorithms by a deliberate and controlled contamination of the
input with random noise, a phenomenon known as stochastic resonance. The
proposed method adds controlled noise to the input and estimates a sparse
representation from the perturbed signal. A set of such solutions is then
obtained by projecting the original input signal onto the recovered set of
supports. We present two variants of the described method, which differ in
their final step. The first is a provably convergent approximation to the
Minimum Mean Square Error (MMSE) estimator, relying on the generative model and
applying a weighted average over the recovered solutions. The second is a
relaxed variant of the former that simply applies an empirical mean. We show
that both methods provide a computationally efficient approximation to the MMSE
estimator, which is typically intractable to compute. We demonstrate our
findings empirically and provide a theoretical analysis of our method under
several different cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10192</identifier>
 <datestamp>2018-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10192</id><created>2018-06-23</created><authors><author><keyname>Zhang</keyname><forenames>Zhilei</forenames></author><author><keyname>Miao</keyname><forenames>Peng</forenames></author><author><keyname>Liu</keyname><forenames>Houbing</forenames></author><author><keyname>Hu</keyname><forenames>Kun</forenames></author><author><keyname>Li</keyname><forenames>Feng</forenames></author><author><keyname>Jin</keyname><forenames>Ge</forenames></author></authors><title>A low power DAQ system with high-speed storage for submersible buoy</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submersible Buoy (SB) is an important apparatus capable of long-term,
fixed-point, continuous and multi-directional measurement of acoustic signals
and hydrological environment monitoring in the harsh marine environment,
providing important information for hydrological environment research, marine
organism research and protection. We will describe a real-time data acquisition
(DAQ) system with multiple designs to meet low-power consumption and high-speed
data transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10240</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10240</id><created>2018-06-26</created><authors><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author><author><keyname>Ikpehai</keyname><forenames>Augustine</forenames></author><author><keyname>Soltanpur</keyname><forenames>Cinna</forenames></author><author><keyname>Wells</keyname><forenames>Andrew</forenames></author></authors><title>Vector OFDM Transmission over Non-Gaussian Power Line Communication
  Channels</title><categories>eess.SP</categories><doi>10.1109/JSYST.2017.2669086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the recent power line communication (PLC) systems and standards, both
narrow-band and broadband, are based on orthogonal frequency-division
multiplexing (OFDM). This multiplexing scheme however suffers from the high
peak-to-average power ratio (PAPR) which can considerably impact the energy
efficiency, size and cost of PLC modems as well as cause electromagnetic
compatibility (EMC) issues. This paper investigates the performance of vector
OFDM (VOFDM), which has inherently better PAPR properties, over non-Gaussian
broadband PLC channels equipped with two nonlinear preprocessors at the
receiver. In addition, the low PAPR property of the VOFDM system is exploited
to further enhance the efficiency of the nonlinear preprocessors. The
achievable gains are studied in terms of the complementary cumulative
distribution function of the PAPR, probability of noise detection error and the
signal-to-noise ratio at the output of the nonlinear preprocessors. For
comparison's sake, the performance of conventional OFDM systems is also
presented throughout the paper. Results reveal that the proposed system is able
to provide up to 2 dB saving in the transmit power relative to the conventional
OFDM under same system conditions, which eventually also translates into a
system that is more resilient to EMC limits, reduced cost and size of PLC
modems. It is also shown that the achievable gains become more significant as
the vector block (VB) size of the VOFDM system is increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10273</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10273</id><created>2018-06-26</created><authors><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>Chaves</keyname><forenames>F.</forenames></author></authors><title>von Mises Tapering: A Circular Data Windowing</title><categories>eess.SP cs.NA math.ST stat.AP stat.TH</categories><comments>5 pages, 5 figures</comments><msc-class>94A12, 62P30, 62P35</msc-class><journal-ref>XXXVI SIMPOSIO BRASILEIRO DE TELECOMUNICACOES E PROCESSAMENTO DE
  SINAIS-SBrT2018</journal-ref><doi>10.14209/SBRT.2018.179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous standard windowing is revisited and a new taper shape is
introduced, which is based on the normal circular distribution by von Mises.
Continuous-time windows are considered and their spectra obtained. A brief
comparison with classical window families is performed in terms of their
spectral properties. These windows can be used as an alternative in spectral
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10307</identifier>
 <datestamp>2018-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10307</id><created>2018-06-27</created><authors><author><keyname>Mogami</keyname><forenames>Shinichi</forenames></author><author><keyname>Sumino</keyname><forenames>Hayato</forenames></author><author><keyname>Kitamura</keyname><forenames>Daichi</forenames></author><author><keyname>Takamune</keyname><forenames>Norihiro</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author><author><keyname>Ono</keyname><forenames>Nobutaka</forenames></author></authors><title>Independent Deeply Learned Matrix Analysis for Multichannel Audio Source
  Separation</title><categories>eess.AS cs.SD</categories><comments>5 pages, 4 figures, To appear in the Proceedings of the 26th European
  Signal Processing Conference (EUSIPCO 2018)</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In this paper, we address a multichannel audio source separation task and
propose a new efficient method called independent deeply learned matrix
analysis (IDLMA). IDLMA estimates the demixing matrix in a blind manner and
updates the time-frequency structures of each source using a pretrained deep
neural network (DNN). Also, we introduce a complex Student's t-distribution as
a generalized source generative model including both complex Gaussian and
Cauchy distributions. Experiments are conducted using music signals with a
training dataset, and the results show the validity of the proposed method in
terms of separation accuracy and computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10367</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10367</id><created>2018-06-27</created><authors><author><keyname>Yangzhang</keyname><forenames>Xianhe</forenames></author><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Le</keyname><forenames>Son T.</forenames></author><author><keyname>Buelow</keyname><forenames>Henning</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>400 Gbps Dual-polarisation Non-linear Frequency-division Multiplexed
  Transmission with b-Modulation</title><categories>eess.SP</categories><comments>Accepted by ECOC 2018</comments><doi>10.1109/JLT.2019.2902961</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate, for the first time, a b-modulated dual-polarisation NFDM
transmission in simulation, achieving a record net data rate of 400 Gbps (SE of
7.2 bit/s/Hz) over 960 km. The proposed scheme shows 1 dB Q-factor improvement
over qc-modulation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10450</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10450</id><created>2018-06-27</created><authors><author><keyname>Deshmukh</keyname><forenames>Madhukar</forenames></author><author><keyname>Zafaruddin</keyname><forenames>S. M.</forenames></author><author><keyname>Mihovska</keyname><forenames>Albena</forenames></author><author><keyname>Prasad</keyname><forenames>Ramjee</forenames></author></authors><title>Stochastic-Geometry Based Characterization of Aggregate Interference in
  TVWS Cognitive Radio Networks</title><categories>eess.SP</categories><doi>10.1109/JSYST.2019.2904584</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we characterize the worst-case interference for a finite-area
TV white space heterogeneous network using the tools of stochastic geometry. We
derive closed-form expressions on the probability distribution function (PDF)
and an average value of the aggregate interference for various values of path
loss exponent. The proposed characterization of the interference is simple and
can be used in improving the spectrum access techniques. Using the derived PDF,
we demonstrate the performance gain in the spectrum detection of an
eigenvalue-based detector for cognitive radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10474</identifier>
 <datestamp>2018-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10474</id><created>2018-06-26</created><authors><author><keyname>Dieleman</keyname><forenames>Sander</forenames></author><author><keyname>Oord</keyname><forenames>A&#xe4;ron van den</forenames></author><author><keyname>Simonyan</keyname><forenames>Karen</forenames></author></authors><title>The challenge of realistic music generation: modelling raw audio at
  scale</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>13 pages, 2 figures, submitted to NIPS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Realistic music generation is a challenging task. When building generative
models of music that are learnt from data, typically high-level representations
such as scores or MIDI are used that abstract away the idiosyncrasies of a
particular performance. But these nuances are very important for our perception
of musicality and realism, so in this work we embark on modelling music in the
raw audio domain. It has been shown that autoregressive models excel at
generating raw audio waveforms of speech, but when applied to music, we find
them biased towards capturing local signal structure at the expense of
modelling long-range correlations. This is problematic because music exhibits
structure at many different timescales. In this work, we explore autoregressive
discrete autoencoders (ADAs) as a means to enable autoregressive models to
capture long-range correlations in waveforms. We find that they allow us to
unconditionally generate piano music directly in the raw audio domain, which
shows stylistic consistency across tens of seconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10522</identifier>
 <datestamp>2018-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10522</id><created>2018-06-27</created><updated>2018-09-14</updated><authors><author><keyname>Germain</keyname><forenames>Francois G.</forenames></author><author><keyname>Chen</keyname><forenames>Qifeng</forenames></author><author><keyname>Koltun</keyname><forenames>Vladlen</forenames></author></authors><title>Speech Denoising with Deep Feature Losses</title><categories>eess.AS cs.SD</categories><comments>Code can be found at
  https://github.com/francoisgermain/SpeechDenoisingWithDeepFeatureLosses .
  Sound examples can be found at
  https://ccrma.stanford.edu/~francois/SpeechDenoisingWithDeepFeatureLosses/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an end-to-end deep learning approach to denoising speech signals
by processing the raw waveform directly. Given input audio containing speech
corrupted by an additive background signal, the system aims to produce a
processed signal that contains only the speech content. Recent approaches have
shown promising results using various deep network architectures. In this
paper, we propose to train a fully-convolutional context aggregation network
using a deep feature loss. That loss is based on comparing the internal feature
activations in a different network, trained for acoustic environment detection
and domestic audio tagging. Our approach outperforms the state-of-the-art in
objective speech quality metrics and in large-scale perceptual experiments with
human listeners. It also outperforms an identical network trained using
traditional regression losses. The advantage of the new approach is
particularly pronounced for the hardest data with the most intrusive background
noise, for which denoising is most needed and most challenging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10570</identifier>
 <datestamp>2018-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10570</id><created>2018-06-27</created><authors><author><keyname>Aljanaki</keyname><forenames>Anna</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Modeling Majorness as a Perceptual Property in Music from Listener
  Ratings</title><categories>cs.SD eess.AS</categories><comments>short paper for ICMPC proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the tasks of automatic music emotion recognition, genre recognition,
music recommendation it is helpful to be able to extract mode from any section
of a musical piece as a perceived amount of major or minor mode (majorness)
inside that section, perceived as a whole (one or several melodies and any
harmony present). In this paper we take a data-driven approach (modeling
directly from data without giving an explicit definition or explicitly
programming an algorithm) towards modeling this property. We collect
annotations from musicians and show that majorness can be understood by
musicians in an intuitive way. We model this property from the data using deep
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10662</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10662</id><created>2018-06-26</created><authors><author><keyname>Luo</keyname><forenames>Shiyu</forenames></author><author><keyname>Yang</keyname><forenames>Junfeng</forenames></author><author><keyname>Song</keyname><forenames>Kezhu</forenames></author><author><keyname>Yu</keyname><forenames>Hongwei</forenames></author><author><keyname>Chen</keyname><forenames>Tengfei</forenames></author><author><keyname>Xu</keyname><forenames>Tianbo</forenames></author><author><keyname>Tang</keyname><forenames>Cheng</forenames></author></authors><title>I2C Management Based on IPbus</title><categories>physics.ins-det eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CBM (Compressed Baryonic Matter) is mainly used to study QCD phase diagram of
strong interactions in high and moderate temperature region. Before the next
generation GBTx based CBM DAQ system is built up, the DPB (Data Processing
Board) layer is used in data readout and data pre-processing, where a general
FPGA FMC carrier board named AFCK is used. This paper mainly describes the
management of the Inter-integrated Circuit (I2C) devices on AFCK and the FMCs
it carries via IPBus, an FPGA-based slow control bus used in CBM DAQ system. On
AFCK, the connection of IPBus depends on the correct initialization of a set of
I2C devices, including the I2C-bus multiplexer (choosing correct I2C bus), the
clock crosspoint switch (providing the 125MHz needed by 1000BASE-X/SGMII), the
serial EEPROM with a EUI-48 address (providing the AFCK MAC address). An
independent initial module can execute an I2C command sequence stored in a ROM,
through which the FPGA can write to/read from the I2C devices without IPBus, so
that the related I2C devices are correctly initialized and the necessary
preparation for the IPBus start-up is fulfilled. After the initialization, a
Wishbone I2C master core is used as an IPbus slave and all other I2C devices
can be configured directly via IPBus. All the design has been fully tested in
the CBM DPB design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10684</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10684</id><created>2018-06-27</created><authors><author><keyname>Jamalzadeh</keyname><forenames>Reza</forenames></author><author><keyname>Abedi</keyname><forenames>Sajjad</forenames></author><author><keyname>Rashidinejad</keyname><forenames>Masoud</forenames></author><author><keyname>Hong</keyname><forenames>Mingguo</forenames></author></authors><title>Price-Based Market Clearing with V2G Integration Using Generalized
  Benders Decomposition</title><categories>math.OC cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, most ISOs adopt offer cost minimization (OCM) auction mechanism
which minimizes the total offer cost, and then, a settlement rule based on
either locational marginal prices (LMPs) or market clearing price (MCP) is used
to determine the payments to the committed units, which is not compatible with
the auction mechanism because the minimized cost is different from the payment
cost calculated by the settlement rule. This inconsistency can drastically
increase the payment cost. On the other hand, payment cost minimization (PCM)
auction mechanism eliminates this inconsistency; however, PCM problem is a
nonlinear self-referring NP-hard problem which poses grand computational
burden. In this paper, a mixed-integer nonlinear programing (MINLP) formulation
of PCM problem are presented to address additional complexity of fast-growing
penetration of Vehicle-to-Grid (V2G) in the price-based market clearing
problem, and a solution method based on the generalized benders decomposition
(GBD) is then proposed to solve the V2G-integrated PCM problem, and its
favorable performance in terms of convergence and computational efficiency is
demonstrated using case studies. The proposed GBD-based method can handle
scaled-up models with the increased number of decision variables and
constraints which facilitates the use of PCM mechanism in the market clearing
of large-scale power systems. The impact of using V2G technologies on the OCM
and PCM mechanisms in terms of MCPs and payments is also investigated, and by
using numerical results, the performances of these two mechanisms are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10730</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10730</id><created>2018-06-27</created><authors><author><keyname>Baba</keyname><forenames>Hidetada</forenames><affiliation>for the RIBFDAQ Collaboration</affiliation></author></authors><title>Prototype of a multi-host type DAQ front-end system for RI-beam
  experiments</title><categories>eess.SP physics.ins-det</categories><comments>Conference Record of IEEE 21th RealTime Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multi-host type DAQ front-end system is proposed and a prototype system
is developed. In general, CAMAC/VME type ADC modules have a single
trigger-input (or gate-input) port. In contrast, a prototype of a new system
has multiple trigger-input ports. In addition, the Wilkinson-type and
successive approximation ADCs have the dead time, whereas, this prototype
system utilizes the combination of Flash-ADC and FPGA that enabling the
dead-time free system. Corresponding to the trigger-input ports, data are sent
to different back-end systems. So, a legacy ADC module is a 1-to-1 system, but,
this proposing system is a 1-to-X system without loss. This system will be
applied for nuclear physics experiments at RIKEN RIBF which produces intense
RI-beams. This multi-host type DAQ front-end system enables us to perform
different experiments simultaneously at the same beam line. In this
contribution, the concept and the performance-test results of the front-end
system is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10749</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10749</id><created>2018-06-27</created><updated>2019-06-30</updated><authors><author><keyname>Faradonbeh</keyname><forenames>Mohamad Kazem Shirani</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author><author><keyname>Michailidis</keyname><forenames>George</forenames></author></authors><title>On Optimality of Adaptive Linear-Quadratic Regulators</title><categories>cs.SY eess.SP math.PR stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance of adaptive control policies is assessed through the regret with
respect to the optimal regulator, which reflects the increase in the operating
cost due to uncertainty about the dynamics parameters. However, available
results in the literature do not provide a quantitative characterization of the
effect of the unknown parameters on the regret. Further, there are problems
regarding the efficient implementation of some of the existing adaptive
policies. Finally, results regarding the accuracy with which the system's
parameters are identified are scarce and rather incomplete.
  This study aims to comprehensively address these three issues. First, by
introducing a novel decomposition of adaptive policies, we establish a sharp
expression for the regret of an arbitrary policy in terms of the deviations
from the optimal regulator. Second, we show that adaptive policies based on a
slight modification of the widely used Certainty Equivalence scheme are
efficient. Specifically, we establish a regret of (nearly) square-root rate for
two families of randomized adaptive policies. The presented regret bounds are
obtained by using anti-concentration results on the random matrices employed
for randomizing the estimates of the unknown parameters. Moreover, we study the
minimal additional information needed on dynamics matrices for which the regret
will become of logarithmic order. Finally, the rate at which the unknown
parameters of the system are being identified is specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10781</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10781</id><created>2018-06-28</created><authors><author><keyname>Du</keyname><forenames>Chen</forenames></author><author><keyname>Kang</keyname><forenames>Byeongkeun</forenames></author><author><keyname>Xu</keyname><forenames>Zheng</forenames></author><author><keyname>Dai</keyname><forenames>Ji</forenames></author><author><keyname>Nguyen</keyname><forenames>Truong</forenames></author></authors><title>Accurate and efficient video de-fencing using convolutional neural
  networks and temporal information</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  De-fencing is to eliminate the captured fence on an image or a video,
providing a clear view of the scene. It has been applied for many purposes
including assisting photographers and improving the performance of computer
vision algorithms such as object detection and recognition. However, the
state-of-the-art de-fencing methods have limited performance caused by the
difficulty of fence segmentation and also suffer from the motion of the camera
or objects. To overcome these problems, we propose a novel method consisting of
segmentation using convolutional neural networks and a fast/robust recovery
algorithm. The segmentation algorithm using convolutional neural network
achieves significant improvement in the accuracy of fence segmentation. The
recovery algorithm using optical flow produces plausible de-fenced images and
videos. The proposed method is experimented on both our diverse and complex
dataset and publicly available datasets. The experimental results demonstrate
that the proposed method achieves the state-of-the-art performance for both
segmentation and content recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10923</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10923</id><created>2018-06-28</created><authors><author><keyname>Benoit</keyname><forenames>A</forenames><affiliation>LISTIC</affiliation></author><author><keyname>Cuevas</keyname><forenames>Leonel</forenames><affiliation>Le2i</affiliation></author><author><keyname>Thomas</keyname><forenames>Jean-Baptiste</forenames><affiliation>Le2i</affiliation></author></authors><title>Deep learning for dehazing: Comparison and analysis</title><categories>cs.CV cs.MM eess.IV</categories><proxy>ccsd</proxy><journal-ref>Colour and Visual Computing Symposium (CVCS), Sep 2018,
  Gj{{\o}}vik, Norway</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare a recent dehazing method based on deep learning, Dehazenet, with
traditional state-of-the-art approaches , on benchmark data with reference.
Dehazenet estimates the depth map from transmission factor on a single color
image, which is used to inverse the Koschmieder model of imaging in the
presence of haze. In this sense, the solution is still attached to the
Koschmieder model. We demonstrate that the transmission is very well estimated
by the network, but also that this method exhibits the same limitation than
others due to the use of the same imaging model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10976</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10976</id><created>2018-06-28</created><authors><author><keyname>Ortiz-Jim&#xe9;nez</keyname><forenames>Guillermo</forenames></author><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Sparse Sampling for Inverse Problems with Tensors</title><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, 7 figures</comments><doi>10.1109/TSP.2019.2914879</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing sparse sampling strategies for
multidomain signals, which can be represented using tensors that admit a known
multilinear decomposition. We leverage the multidomain structure of tensor
signals and propose to acquire samples using a Kronecker-structured sensing
function, thereby circumventing the curse of dimensionality. For designing such
sensing functions, we develop low-complexity greedy algorithms based on
submodular optimization methods to compute near-optimal sampling sets. We
present several numerical examples, ranging from multi-antenna communications
to graph signal processing, to validate the developed theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10988</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10988</id><created>2018-06-19</created><authors><author><keyname>Bartos</keyname><forenames>Matthew</forenames></author><author><keyname>Park</keyname><forenames>Hyongju</forenames></author><author><keyname>Zhou</keyname><forenames>Tian</forenames></author><author><keyname>Kerkez</keyname><forenames>Branko</forenames></author><author><keyname>Vasudevan</keyname><forenames>Ramanarayan</forenames></author></authors><title>Vehicles as sensors: high-accuracy rainfall maps from windshield wiper
  measurements</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connected vehicles are poised to transform the field of environmental sensing
by enabling acquisition of scientific data at unprecedented scales. Drawing on
a real-world dataset collected from almost 70 connected vehicles, this study
generates improved rainfall estimates by combining weather radar with
windshield wiper observations. Existing methods for measuring precipitation are
subject to spatial and temporal uncertainties that compromise high-precision
applications like flash flood forecasting. Windshield wiper measurements from
connected vehicles correct these uncertainties by providing precise information
about the timing and location of rainfall. Using co-located vehicle dashboard
camera footage, we find that wiper measurements are a stronger predictor of
binary rainfall state than traditional stationary gages or radar-based
measurements. We introduce a Bayesian filtering framework that generates
improved rainfall estimates by updating radar rainfall fields with windshield
wiper observations. We find that the resulting rainfall field estimate captures
rainfall events that would otherwise be missed by conventional measurements. We
discuss how these enhanced rainfall maps can be used to improve flood warnings
and facilitate real-time operation of stormwater infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10989</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10989</id><created>2018-06-25</created><authors><author><keyname>Liu</keyname><forenames>Feiyang</forenames></author><author><keyname>Zhang</keyname><forenames>Yulong</forenames></author><author><keyname>Dahlsten</keyname><forenames>Oscar</forenames></author><author><keyname>Wang</keyname><forenames>Fei</forenames></author></authors><title>On intelligent energy harvesting</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We probe the potential for intelligent intervention to enhance the power
output of energy harvesters. We investigate general principles and a case
study: a bi-resonant piezo electric harvester. We consider intelligent
interventions via pre-programmed reversible energy-conserving operations. We
find that in important parameter regimes these can outperform diode-based
intervention, which in contrast has a fundamental minimum power dissipation
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10990</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10990</id><created>2018-06-23</created><authors><author><keyname>Tipireddy</keyname><forenames>Ramakrishna</forenames></author><author><keyname>Tartakovsky</keyname><forenames>Alexandre</forenames></author></authors><title>Physics-informed Machine Learning Method for Forecasting and Uncertainty
  Quantification of Partially Observed and Unobserved States in Power Grids</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a physics-informed Gaussian Process Regression (GPR) model to
predict the phase angle, angular speed, and wind mechanical power from a
limited number of measurements. In the traditional data-driven GPR method, the
form of the Gaussian Process covariance matrix is assumed and its parameters
are found from measurements. In the physics-informed GPR, we treat unknown
variables (including wind speed and mechanical power) as a random process and
compute the covariance matrix from the resulting stochastic power grid
equations. We demonstrate that the physics-informed GPR method is significantly
more accurate than the standard data-driven one for immediate forecasting of
generators' angular velocity and phase angle. We also show that the
physics-informed GPR provides accurate predictions of the unobserved wind
mechanical power, phase angle, or angular velocity when measurements from only
one of these variables are available. The immediate forecast of observed
variables and predictions of unobserved variables can be used for effectively
managing power grids (electricity market clearing, regulation actions) and
early detection of abnormal behavior and faults. The physics-based GPR forecast
time horizon depends on the combination of input (wind power, load, etc.)
correlation time and characteristic (relaxation) time of the power grid and can
be extended to short and medium-range times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10991</identifier>
 <datestamp>2019-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10991</id><created>2018-06-26</created><updated>2019-01-21</updated><authors><author><keyname>Passerini</keyname><forenames>Federico</forenames></author><author><keyname>Tonello</keyname><forenames>Andrea M.</forenames></author></authors><title>Smart Grid Monitoring Using Power Line Modems: Effect of Anomalies on
  Signal Propagation</title><categories>eess.SP</categories><comments>A version of this paper has been submitted to an IEEE Journal</comments><journal-ref>IEEE Access, 2019</journal-ref><doi>10.1109/ACCESS.2019.2901861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the present work is to provide the theoretical fundamentals needed
to monitor power grids using high frequency sensors. In our context, network
monitoring refers to the harvesting of different kinds of information: topology
of the grid, load changes, presence of faults and cable degradation. We rely on
transmission line theory to carry out a thorough analysis of how high frequency
signals, such those produced by power line modems, propagate through
multi-conductor power networks. We also consider the presence of electrical
anomalies on the network and analyze how they affect the signal propagation. In
this context, we propose two models that rely on reflectometric and end-to-end
measurements to extrapolate information about possible anomalies. A thorough
discussion is carried out to explain the properties of each model and
measurement method, in order to enable the development of appropriate anomaly
detection and location algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.10993</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.10993</id><created>2018-06-27</created><authors><author><keyname>Mielczarek</keyname><forenames>Aleksander</forenames><affiliation>Lodz University of Technology</affiliation></author><author><keyname>Makowski</keyname><forenames>Dariusz</forenames><affiliation>Lodz University of Technology</affiliation></author><author><keyname>Perek</keyname><forenames>Piotr</forenames><affiliation>Lodz University of Technology</affiliation></author><author><keyname>Napieralski</keyname><forenames>Andrzej</forenames><affiliation>Lodz University of Technology</affiliation></author></authors><title>Framework for High-performance Video Acquisition and Processing in
  MTCA.4 Form Factor</title><categories>eess.IV eess.SP</categories><comments>2 pages, 2 figures, short form article for Real-Time 2018 Conference</comments><doi>10.1109/TNS.2019.2910878</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The video acquisition and processing systems are commonly used in industrial
and scientific applications. Many of them utilize Camera Link interface for the
transmission of a video stream from the camera to the host system. The
framework presented in the paper enables capturing such data, processing it and
transmitting to the host CPU. It consist of MTCA.4-compliant frame grabber and
a set of software libraries supporting several different cameras. It is
designed for use in large scale physics experiments such as ITER tokamak or
European X-Ray Free-Electron Laser (E-XFEL), as well as in the Centre for
Free-Electron Laser Science (CFEL). The proposed video acquisition solution
features the worlds first Camera Link frame grabber for the MTCA.4
architecture. Thanks to the modern FPGA circuit architecture, the
deserialization is done using only the built-in ISERDES primitives, which
reduces the costs and complexity of the required hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11019</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11019</id><created>2018-06-28</created><updated>2019-05-30</updated><authors><author><keyname>Torres</keyname><forenames>Yolanda</forenames></author><author><keyname>Arranz</keyname><forenames>Jose Juan</forenames></author><author><keyname>Gaspar-Escribano</keyname><forenames>Jorge M.</forenames></author><author><keyname>Haghi</keyname><forenames>Azadeh</forenames></author><author><keyname>Martinez-Cuevas</keyname><forenames>Sandra</forenames></author><author><keyname>Benito</keyname><forenames>Belen</forenames></author><author><keyname>Ojeda</keyname><forenames>Juan Carlos</forenames></author></authors><title>Integration of LiDAR and multispectral images for exposure and
  earthquake vulnerability estimation. Application in Lorca, Spain</title><categories>physics.geo-ph eess.IV</categories><journal-ref>I.J. of Applied Earth Observation and Geoinformation, 81, 161-175
  (2019)</journal-ref><doi>10.1016/j.jag.2019.05.015</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We present a procedure for assessing the urban exposure and seismic
vulnerability that integrates LiDAR data with aerial and satellite images. It
comprises three phases: first, we segment the satellite image to divide the
study area into different urban patterns. Second, we extract building
footprints and attributes that represent the type of building of each urban
pattern. Finally, we assign the seismic vulnerability to each building using
different machine-learning techniques: Decision trees, SVM, logistic regression
and Bayesian networks. We apply the procedure to 826 buildings in the city of
Lorca (SE Spain), where we count on a vulnerability database that we use as
ground truth for the validation of results. The outcomes show that the machine
learning techniques have similar performance, yielding vulnerability
classification results with an accuracy of 77% - 80% (F1-Score). The procedure
is scalable and can be replicated in different areas. It is especially
interesting as a complement to conventional data gathering approaches for
disaster risk applications in areas where field surveys need to be restricted
to certain areas, dates or budget. Keywords LiDAR, satellite image, orthophoto,
image segmentation, machine learning, earthquake vulnerability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11038</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11038</id><created>2018-06-28</created><updated>2020-02-10</updated><authors><author><keyname>Shah-Mohammadi</keyname><forenames>Fatemeh</forenames></author><author><keyname>Kwasinski</keyname><forenames>Andres</forenames></author></authors><title>Neural Network Cognitive Engine for Autonomous and Distributed Underlay
  Dynamic Spectrum Access</title><categories>cs.NI cs.LG eess.SP stat.ML</categories><comments>Submitted to IEEE Access Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two key challenges in underlay dynamic spectrum access (DSA) are how to
establish an interference limit from the primary network (PN) and how cognitive
radios (CRs) in the secondary network (SN) become aware of the interference
they create on the PN, especially when there is no exchange of information
between the two networks. These challenges are addressed in this paper by
presenting a fully autonomous and distributed underlay DSA scheme where each CR
operates based on predicting its transmission effect on the PN. The scheme is
based on a cognitive engine with an artificial neural network that predicts,
without exchanging information between the networks, the adaptive modulation
and coding configuration for the primary link nearest to a transmitting CR. By
managing the effect of the SN on the PN, the presented technique maintains the
relative average throughput change in the PN within a prescribed maximum value,
while also finding transmit settings for the CRs that result in throughput as
large as allowed by the PN interference limit. It is shown through simulation
results that the ability of the cognitive engine to estimate the effect of a CR
transmission on the full adaptive modulation and coding (AMC) mode that is used
at a PN link translates into a much more fine underlay transmit power control
and increase of the CR transmission opportunities, compared to a scheme that
can only estimate the modulation scheme used at the PN link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11077</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11077</id><created>2018-06-27</created><authors><author><keyname>Lubashevsky</keyname><forenames>Ihor</forenames></author></authors><title>Psychophysical laws as reflection of mental space properties</title><categories>q-bio.NC eess.IV</categories><doi>10.1016/j.plrev.2018.10.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to the relationship between psychophysics and physics of
mind. The basic trends in psychophysics development are briefly discussed with
special attention focused on Teghtsoonian's hypotheses. These hypotheses pose
the concept of the universality of inner psychophysics and enable to speak
about psychological space as an individual object with its own properties.
Turning to the two-component description of human behavior (I. Lubashevsky,
Physics of the Human Mind, Springer, 2017) the notion of mental space is
formulated and human perception of external stimuli is treated as the emergence
of the corresponding images in the mental space. On one hand, these images are
caused by external stimuli and their magnitude bears the information about the
intensity of the corresponding stimuli. On the other hand, the individual
structure of such images as well as their subsistence after emergence is
determined only by the properties of mental space on its own. Finally, the
mental operations of image comparison and their scaling are defined in a way
allowing for the bounded capacity of human cognition. As demonstrated, the
developed theory of stimulus perception is able to explain the basic
regularities of psychophysics, e.g., (i) the regression and range effects
leading to the overestimation of weak stimuli and the underestimation of strong
stimuli, (ii) scalar variability (Weber's and Ekman' laws), and (\textit{iii})
the sequential (memory) effects. As the final result, a solution to the
Fechner-Stevens dilemma is proposed. This solution posits that Fechner's
logarithmic law is not a consequences of Weber's law but stems from the
interplay of uncertainty in evaluating stimulus intensities and the multi-step
scaling required to overcome the stimulus incommensurability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11170</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11170</id><created>2018-06-28</created><updated>2019-08-12</updated><authors><author><keyname>Lin</keyname><forenames>Zhiyu</forenames></author><author><keyname>Xiao</keyname><forenames>Kyle</forenames></author><author><keyname>Riedl</keyname><forenames>Mark</forenames></author></authors><title>GenerationMania: Learning to Semantically Choreograph</title><categories>cs.SD eess.AS</categories><comments>To appear in AIIDE 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beatmania is a rhythm action game where players must reproduce some of the
sounds of a song by pressing specific controller buttons at the correct time.
In this paper we investigate the use of deep neural networks to automatically
create game stages - called charts - for arbitrary pieces of music. Our
technique uses a multi-layer feed-forward network trained on sound sequence
summary statistics to predict which sounds in the music are to be played by the
player and which will play automatically. We use another neural network along
with rules to determine which controls should be mapped to which sounds. We
evaluated our system on the ability to reconstruct charts in a held-out test
set, achieving an $F_1$-score that significantly beats LSTM baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11175</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11175</id><created>2018-06-28</created><authors><author><keyname>Capdeboscq</keyname><forenames>Yves</forenames></author><author><keyname>Mamigonians</keyname><forenames>Hrand</forenames></author><author><keyname>Sulaimalebbe</keyname><forenames>Aslam</forenames></author><author><keyname>Tshitoyan</keyname><forenames>Vahe</forenames></author></authors><title>Combining Radon transform and Electrical Capacitance Tomography for a
  $2d+1$ imaging device</title><categories>eess.IV</categories><journal-ref>Inverse Problems 2018</journal-ref><doi>10.1088/1361-6420/aad344</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a coplanar non invasive non destructive capacitive
imaging device. We first introduce a mathematical model for its output, and
discuss some of its theoretical capabilities. We show that the data obtained
from this device can be interpreted as a weighted Radon transform of the
electrical permittivity of the measured object near its surface. Image
reconstructions from experimental data provide good surface resolution as well
as short depth imaging, making the apparatus a $2d+1$ imager. The quality of
the images leads us to expect that excellent results can be delivered by
\emph{ad-hoc} optimized inversion formulas. There are also interesting, yet
unexplored, theoretical questions on imaging that this sensor will allow to
test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11214</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11214</id><created>2018-06-28</created><updated>2018-07-19</updated><authors><author><keyname>Elayan</keyname><forenames>Hadeel</forenames></author><author><keyname>Shubair</keyname><forenames>Raed</forenames></author></authors><title>Robust Algorithms for Localizing Moving Nodes in Wireless Sensor
  Networks</title><categories>eess.SP</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vivid success of the emerging wireless sensor technology (WSN) gave rise
to the notion of localization in the communications field. Indeed, the interest
in localization grew further with the proliferation of the wireless sensor
network applications including medicine, military as well as transport. By
utilizing a subset of sensor terminals, gathered data in a WSN can be both
identified and correlated which helps in managing the nodes distributed
throughout the network. In most scenarios presented in the literature, the
nodes to be localized are often considered static. However, as we are heading
towards the 5th generation mobile communication, the aspect of mobility should
be regarded. Thus, the novelty of this research relies in its ability to merge
the robotics as well as WSN fields creating a state of art for the localization
of moving nodes. The challenging aspect relies in the capability of merging
these two platforms in a way where the limitations of each is minimized as much
as possible. A hybrid technique which combines both the Particle Filter (PF)
method and the Time Difference of Arrival Technique (TDOA) is presented.
Simulation results indicate that the proposed approach outperforms other
techniques in terms of accuracy and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11224</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11224</id><created>2018-06-28</created><updated>2018-07-20</updated><authors><author><keyname>Elayan</keyname><forenames>Hadeel</forenames></author><author><keyname>Shubair</keyname><forenames>Raed</forenames></author><author><keyname>Almoosa</keyname><forenames>Nawaf</forenames></author></authors><title>In Vivo WBAN Communication: Design and Implementation</title><categories>eess.SP</categories><comments>15 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emerging in vivo communication and networking system is a prospective
component in advancing healthcare delivery and empowering the development of
new applications and services. In vivo communications is based on networked
cyber-physical systems of embedded devices to allow rapid, correct and cost-
effective responses under various conditions. This chapter presents the
existing research which investigates the state of art of the in vivo
communication. It focuses on characterizing and modeling the in vivo wireless
channel and contrasting it with the other familiar channels. MIMO in vivo is
also of cencern in this chapter since it significantly enhances the performance
gain and data rates. Furthermore, this chapter addresses in vivo
nano-communication which is presented for medical applications to provide fast
and accurate disease diagnosis and treatment. Such communication paradigm is
capable of operating inside the human body in real time and will be of great
benefit for medical monitoring and medical implant communications.
Consequently, propagation at the Terahertz (THz) frequency must be well
understood as it is considered the most promising band for electromagnetic
nano-communication models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11267</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11267</id><created>2018-06-29</created><updated>2019-05-12</updated><authors><author><keyname>Hu</keyname><forenames>Song</forenames></author><author><keyname>Wang</keyname><forenames>Fei</forenames></author><author><keyname>Wang</keyname><forenames>Hua</forenames></author></authors><title>A 28/37/39GHz Multiband Linear Doherty Power Amplifier in Silicon for 5G
  Applications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the first multiband mm-wave linear Doherty PA in silicon
for broadband 5G applications. We introduce a new transformer-based on-chip
Doherty power combiner, which can reduce the impedance transformation ratio in
power back-off (PBO) and thus improve the bandwidth and power-combining
efficiency. We also devise a &quot;driver-PA co-design&quot; method, which creates
power-dependent uneven feeding in the Doherty PA and enhances the Doherty
operation without any hardware overhead or bandwidth compromise. For the proof
of concept, we implement a 28/37/39-GHz PA fully integrated in a standard
130-nm SiGe BiCMOS process, which occupies 1.8mm2. The PA achieves a 52% -3-dB
small-signal S21 bandwidth and a 40% -1-dB large-signal saturated output power
(Psat) bandwidth. At 28/37/39GHz, the PA achieves +16.8/+17.1/+17-dBm Psat,
+15.2/+15.5/+15.4-dBm P1dB, and superior 1.72/1.92/1.62 times efficiency
enhancement over class-B operation at 5.9/6/6.7-dB PBO. Moreover, the PA
demonstrates multi-Gb/s data rates with excellent efficiency and linearity for
64QAM in all the three 5G bands. This PA advances the state of the art for
Doherty, wideband, and 5G silicon PAs in mm-wave bands. It supports drop-in
upgrade for current PAs in existing mm-wave systems and opens doors to compact
system solutions for future multiband 5G massive MIMO and phased-array
platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11285</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11285</id><created>2018-06-29</created><authors><author><keyname>Emara</keyname><forenames>Mustafa</forenames></author><author><keyname>Filippou</keyname><forenames>Miltiades C.</forenames></author><author><keyname>Karls</keyname><forenames>Ingolf</forenames></author></authors><title>Availability and Reliability of Wireless Links in 5G Systems: A
  Space-Time Approach</title><categories>eess.SP cs.NI</categories><comments>Submitted to Globecom18, 5th International Workshop on Ultra-Reliable
  Low-Latency Communications in Wireless Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless links are characterized by fluctuating quality leading to variable
packet error rates which are orders of magnitude higher than the ones of wired
links. Therefore, it is of paramount importance to investigate the limitations
of using 5G wireless links for internet of things (IoT) applications. 5G
wireless links in IoT need to assure determinism of process flows via realtime
communication anytime and anywhere, which is an utmost requirement for multiple
verticals like automotive, industrial automation and aerospace. Based on a
space-time approach, in this work, we provide novel definitions of wireless
link availability and reliability, assuming a number of access points (APs) and
end points (EPs) deployed over a fixed area. Our objective is to analyze the
availability of a service in both domains. In the space domain, we characterize
spatially available areas consisting of all locations that meet a performance
requirement with confidence. In the time domain, we propose a channel
allocation scheme accounting for the spatial availability of a cell. To
emphasize the incurred space-time performance trade-offs, numerical results are
presented, also highlighting the effect of different system parameters on the
achievable link availability and reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11301</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11301</id><created>2018-06-29</created><authors><author><keyname>Fan</keyname><forenames>YouZhe</forenames></author><author><keyname>Xia</keyname><forenames>ChenYang</forenames></author><author><keyname>Chen</keyname><forenames>Ji</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-Ying</forenames></author><author><keyname>Jin</keyname><forenames>Jie</forenames></author><author><keyname>Shen</keyname><forenames>Hui</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author></authors><title>A Low-Latency List Successive-Cancellation Decoding Implementation for
  Polar Codes</title><categories>cs.IT cs.AR eess.SP math.IT</categories><comments>15 pages, 13 figures, 5 tables</comments><journal-ref>IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 34, NO. 2,
  FEBRUARY 2016</journal-ref><doi>10.1109/JSAC.2015.2504318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to their provably capacity-achieving performance, polar codes have
attracted a lot of research interest recently. For a good error-correcting
performance, list successive-cancellation decoding (LSCD) with large list size
is used to decode polar codes. However, as the complexity and delay of the list
management operation rapidly increase with the list size, the overall latency
of LSCD becomes large and limits the applicability of polar codes in
high-throughput and latency-sensitive applications. Therefore, in this work,
the low-latency implementation for LSCD with large list size is studied.
Specifically, at the system level, a selective expansion method is proposed
such that some of the reliable bits are not expanded to reduce the computation
and latency. At the algorithmic level, a double thresholding scheme is proposed
as a fast approximate-sorting method for the list management operation to
reduce the LSCD latency for large list size. A VLSI architecture of the LSCD
implementing the selective expansion and double thresholding scheme is then
developed, and implemented using a UMC 90 nm CMOS technology. Experimental
results show that, even for a large list size of 16, the proposed LSCD achieves
a decoding throughput of 460 Mbps at a clock frequency of 658 MHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11320</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11320</id><created>2018-06-29</created><updated>2019-01-25</updated><authors><author><keyname>P&#xf6;hlmann</keyname><forenames>Robert</forenames></author><author><keyname>Almasri</keyname><forenames>Sami Alkubti</forenames></author><author><keyname>Zhang</keyname><forenames>Siwei</forenames></author><author><keyname>Jost</keyname><forenames>Thomas</forenames></author><author><keyname>Dammann</keyname><forenames>Armin</forenames></author><author><keyname>Hoeher</keyname><forenames>Peter A.</forenames></author></authors><title>On the Potential of Multi-Mode Antennas for Direction-of-Arrival
  Estimation</title><categories>eess.SP</categories><doi>10.1109/TAP.2019.2899010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that a multi-mode antenna (MMA) is an interesting
alternative to a conventional phased antenna array for direction-of-arrival
(DoA) estimation. By MMA we mean a single physical radiator with multiple
ports, which excite different characteristic modes. In contrast to phased
arrays, a closed-form mathematical model of the antenna response, like a
steering vector, is not straightforward to define for MMAs. Instead one has to
rely on calibration measurement or electromagnetic field (EMF) simulation data,
which is discrete. To perform DoA estimation, array interpolation technique
(AIT) and wavefield modeling (WM) are suggested as methods with inherent
interpolation capabilities, fully taking antenna nonidealities like mutual
coupling into account. We present a non-coherent DoA estimator for low-cost
receivers and show how coherent DoA estimation and joint DoA and polarization
estimation can be performed with MMAs. Utilizing these methods, we assess the
DoA estimation performance of an MMA prototype in simulations for both 2D and
3D cases. The results show that WM outperforms AIT for high SNR. Coherent
estimation is superior to non-coherent, especially in 3D, because non-coherent
suffers from estimation ambiguities. In conclusion, DoA estimation with a
single MMA is feasible and accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11408</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11408</id><created>2018-06-29</created><updated>2020-02-17</updated><authors><author><keyname>van Diepen</keyname><forenames>Anouk</forenames></author><author><keyname>Cox</keyname><forenames>Marco</forenames></author><author><keyname>de Vries</keyname><forenames>Bert</forenames></author></authors><title>A Probabilistic Modeling Approach to One-Shot Gesture Recognition</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gesture recognition enables a natural extension of the way we currently
interact with devices. Commercially available gesture recognition systems are
usually pre-trained and offer no option for customization by the user. In order
to improve the user experience, it is desirable to allow end users to define
their own gestures. This scenario requires learning from just a few training
examples if we want to impose only a light training load on the user. To this
end, we propose a gesture classifier based on a hierarchical probabilistic
modeling approach. In this framework, high-level features that are shared among
different gestures can be extracted from a large labeled data set, yielding a
prior distribution for gestures. When learning new types of gestures, the
learned shared prior reduces the number of required training examples for
individual gestures. We implemented the proposed gesture classifier for a Myo
sensor bracelet and show favorable results for the tested system on a database
of 17 different gesture types. Furthermore, we propose and implement two
methods to incorporate the gesture classifier in a real-time gesture
recognition system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11496</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11496</id><created>2018-06-29</created><authors><author><keyname>Iswardani</keyname><forenames>Ardymulya</forenames></author><author><keyname>Hidayat</keyname><forenames>Wahyu</forenames></author></authors><title>Mammographic Image Enhancement using Digital Image Processing Technique</title><categories>eess.IV cs.CV</categories><comments>3 tables, 5 pages, 7 figures</comments><report-no>Vol. 16 No. 5</report-no><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Abstract PURPOSES this study aims to perform microcalsification detection by
performing image enhancement in mammography image by using transformation of
negative image and histogram equalization. image mammography with .pgm format
changed to. jpg format then processed into negative image result then processed
again using histogram equalization. the results of the image enhancement
process using negative image techniques and equalization histograms are
compared and validated with MSE and PSNR on each mammographic image.
CONCLUSION: Image enhancement process on mammography image can be done, however
there are only some image that have improved quality, this affected by
threshold usage, which have important role to get better visualization on
mammographic image. Keywords-component; Image enhancement, image negative,
histogram equalization, mammographic, breast cancer
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.11555</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1806.11555</id><created>2018-06-20</created><authors><author><keyname>Torquato</keyname><forenames>Matheus F.</forenames></author><author><keyname>Fernandes</keyname><forenames>Marcelo A. C.</forenames></author></authors><title>High-Performance Parallel Implementation of Genetic Algorithm on FPGA</title><categories>cs.DC cs.AI cs.AR eess.SP</categories><comments>27 pages, 16 figures</comments><doi>10.1007/s00034-019-01037-w</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic Algorithms (GAs) are used to solve search and optimization problems
in which an optimal solution can be found using an iterative process with
probabilistic and non-deterministic transitions. However, depending on the
problem's nature, the time required to find a solution can be high in
sequential machines due to the computational complexity of genetic algorithms.
This work proposes a parallel implementation of a genetic algorithm on
field-programmable gate array (FPGA). Optimization of the system's processing
time is the main goal of this project. Results associated with the processing
time and area occupancy (on FPGA) for various population sizes are analyzed.
Studies concerning the accuracy of the GA response for the optimization of two
variables functions were also evaluated for the hardware implementation.
However, the high-performance implementation proposes in this paper is able to
work with more variable from some adjustments on hardware architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00064</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00064</id><created>2018-06-29</created><authors><author><keyname>Jagtap</keyname><forenames>Pushpak</forenames></author><author><keyname>Soudjani</keyname><forenames>Sadegh</forenames></author><author><keyname>Zamani</keyname><forenames>Majid</forenames></author></authors><title>Temporal Logic Verification of Stochastic Systems Using Barrier
  Certificates</title><categories>cs.SY eess.SY</categories><comments>15 pages, 5 figures, accepted in ATVA 2018 conference</comments><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a methodology for temporal logic verification of
discrete-time stochastic systems. Our goal is to find a lower bound on the
probability that a complex temporal property is satisfied by finite traces of
the system. Desired temporal properties of the system are expressed using a
fragment of linear temporal logic, called safe LTL over finite traces. We
propose to use barrier certificates for computations of such lower bounds,
which is computationally much more efficient than the existing
discretization-based approaches. The new approach is discretization-free and
does not suffer from the curse of dimensionality caused by discretizing state
sets. The proposed approach relies on decomposing the negation of the
specification into a union of sequential reachabilities and then using barrier
certificates to compute upper bounds for these reachability probabilities. We
demonstrate the effectiveness of the proposed approach on case studies with
linear and polynomial dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00069</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00069</id><created>2018-06-29</created><authors><author><keyname>Kroher</keyname><forenames>Nadine</forenames></author><author><keyname>Pikrakis</keyname><forenames>Aggelos</forenames></author></authors><title>Exploratory Analysis of a Large Flamenco Corpus using an Ensemble of
  Convolutional Neural Networks as a Structural Annotation Backend</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present computational tools that we developed for the analysis of a large
corpus of flamenco music recordings, along with the related exploratory
findings. The proposed computational backend is based on a set of Convolutional
Neural Networks that provide the structural annotation of each music recording
with respect to the presence of vocals, guitar and hand-clapping (&quot;palmas&quot;).
The resulting, automatically extracted annotations, allowed for the
visualization of music recordings in structurally meaningful ways, the
extraction of global statistics related to the instrumentation of flamenco
music, the detection of a cappella and instrumental recordings for which no
such information existed, the investigation of differences in structure and
instrumentation across styles and the study of tonality across instrumentation
and styles. The reported findings show that it is feasible to perform a large
scale analysis of flamenco music with state-of-the-art classification
technology and produce automatically extracted descriptors that are both
musicologically valid and useful, in the sense that they can enhance
conventional metadata schemes and assist bridging the semantic gap between
audio recordings and high-level musicological concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00078</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00078</id><created>2018-06-29</created><authors><author><keyname>Mahmood</keyname><forenames>Aamir</forenames></author><author><keyname>Ashraf</keyname><forenames>Muhammad Ikram</forenames></author><author><keyname>Gidlund</keyname><forenames>Mikael</forenames></author><author><keyname>Torsner</keyname><forenames>Johan</forenames></author></authors><title>Over-the-Air Time Synchronization for URLLC: Requirements, Challenges
  and Possible Enablers</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultra-reliable and low-latency communications (URLLC) is an emerging feature
in 5G and beyond wireless systems, which is introduced to support stringent
latency and reliability requirements of mission-critical industrial
applications. In many potential applications, multiple sensors/actuators
collaborate and require isochronous operation with strict and bounded jitter,
e.g., \SI{1}{\micro\second}. To this end, network time synchronization becomes
crucial for real-time and isochronous communication between a controller and
the sensors/actuators. In this paper, we look at different applications in
factory automation and smart grids to reveal the requirements of device-level
time synchronization and the challenges in extending the high-granularity
timing information to the devices. Also, we identify the potential over-the-air
synchronization mechanisms in 5G radio interface, and discuss the needed
enhancements to meet the jitter constraints of time-sensitive URLLC
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00129</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00129</id><created>2018-06-30</created><updated>2018-12-17</updated><authors><author><keyname>Adavanne</keyname><forenames>Sharath</forenames></author><author><keyname>Politis</keyname><forenames>Archontis</forenames></author><author><keyname>Nikunen</keyname><forenames>Joonas</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Sound Event Localization and Detection of Overlapping Sources Using
  Convolutional Recurrent Neural Networks</title><categories>cs.SD eess.AS</categories><comments>Published in Journal of Selected Topics in Signal Processing 2018</comments><doi>10.1109/JSTSP.2018.2885636</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we propose a convolutional recurrent neural network for joint
sound event localization and detection (SELD) of multiple overlapping sound
events in three-dimensional (3D) space. The proposed network takes a sequence
of consecutive spectrogram time-frames as input and maps it to two outputs in
parallel. As the first output, the sound event detection (SED) is performed as
a multi-label classification task on each time-frame producing temporal
activity for all the sound event classes. As the second output, localization is
performed by estimating the 3D Cartesian coordinates of the
direction-of-arrival (DOA) for each sound event class using multi-output
regression. The proposed method is able to associate multiple DOAs with
respective sound event labels and further track this association with respect
to time. The proposed method uses separately the phase and magnitude component
of the spectrogram calculated on each audio channel as the feature, thereby
avoiding any method- and array-specific feature extraction. The method is
evaluated on five Ambisonic and two circular array format datasets with
different overlapping sound events in anechoic, reverberant and real-life
scenarios. The proposed method is compared with two SED, three DOA estimation,
and one SELD baselines. The results show that the proposed method is generic
and applicable to any array structures, robust to unseen DOA values,
reverberation, and low SNR scenarios. The proposed method achieved a
consistently higher recall of the estimated number of DOAs across datasets in
comparison to the best baseline. Additionally, this recall was observed to be
significantly better than the best baseline method for a higher number of
overlapping sound events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00145</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00145</id><created>2018-06-30</created><authors><author><keyname>Ortiz-Jim&#xe9;nez</keyname><forenames>Guillermo</forenames></author><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Sampling and Reconstruction of Signals on Product Graphs</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of subsampling and reconstruction of
signals that reside on the vertices of a product graph, such as sensor network
time series, genomic signals, or product ratings in a social network.
Specifically, we leverage the product structure of the underlying domain and
sample nodes from the graph factors. The proposed scheme is particularly useful
for processing signals on large-scale product graphs. The sampling sets are
designed using a low-complexity greedy algorithm and can be proven to be
near-optimal. To illustrate the developed theory, numerical experiments based
on real datasets are provided for sampling 3D dynamic point clouds and for
active learning in recommender systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00244</identifier>
 <datestamp>2018-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00244</id><created>2018-06-30</created><updated>2018-10-26</updated><authors><author><keyname>Gritsenko</keyname><forenames>Andrey</forenames></author><author><keyname>Lindquist</keyname><forenames>Martin A.</forenames></author><author><keyname>Kirk</keyname><forenames>Gregory R.</forenames></author><author><keyname>Chung</keyname><forenames>Moo K.</forenames></author></authors><title>Automatic Identification of Twin Zygosity in Resting-State Functional
  MRI</title><categories>eess.IV cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key strength of twin studies arises from the fact that there are two types
of twins, monozygotic and dizygotic, that share differing amounts of genetic
information. Accurate differentiation of twin types allows efficient inference
on genetic influences in a population. However, identification of zygosity is
often prone to errors without genotying. In this study, we propose a novel
pairwise feature representation to classify the zygosity of twin pairs of
resting state functional magnetic resonance images (rs-fMRI). For this, we
project an fMRI signal to a set of basis functions and use the projection
coefficients as the compact and discriminative feature representation of noisy
fMRI. We encode the relationship between twins as the correlation between the
new feature representations across brain regions. We employ hill climbing
variable selection to identify brain regions that are the most genetically
affected. The proposed framework was applied to 208 twin pairs and achieved
94.19% classification accuracy in automatically identifying the zygosity of
paired images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00270</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00270</id><created>2018-07-01</created><authors><author><keyname>Cheng</keyname><forenames>Zhengxue</forenames></author><author><keyname>Sun</keyname><forenames>Heming</forenames></author><author><keyname>Takeuchi</keyname><forenames>Masaru</forenames></author><author><keyname>Katto</keyname><forenames>Jiro</forenames></author></authors><title>Performance Comparison of Convolutional AutoEncoders, Generative
  Adversarial Networks and Super-Resolution for Image Compression</title><categories>eess.IV</categories><comments>Submitted to CVPR Workshop and Challenge On Learned Image Compression
  (CLIC) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image compression has been investigated for many decades. Recently, deep
learning approaches have achieved a great success in many computer vision
tasks, and are gradually used in image compression. In this paper, we develop
three overall compression architectures based on convolutional autoencoders
(CAEs), generative adversarial networks (GANs) as well as super-resolution
(SR), and present a comprehensive performance comparison. According to
experimental results, CAEs achieve better coding efficiency than JPEG by
extracting compact features. GANs show potential advantages on large
compression ratio and high subjective quality reconstruction. Super-resolution
achieves the best rate-distortion (RD) performance among them, which is
comparable to BPG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00464</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00464</id><created>2018-07-02</created><authors><author><keyname>Sliwa</keyname><forenames>Benjamin</forenames></author><author><keyname>Piatkowski</keyname><forenames>Nico</forenames></author><author><keyname>Haferkamp</keyname><forenames>Marcus</forenames></author><author><keyname>Dorn</keyname><forenames>Dennis</forenames></author><author><keyname>Wietfeld</keyname><forenames>Christian</forenames></author></authors><title>Leveraging the Channel as a Sensor: Real-time Vehicle Classification
  Using Multidimensional Radio-fingerprinting</title><categories>eess.SP cs.NI</categories><journal-ref>2018 21st International Conference on Intelligent Transportation
  Systems (ITSC)</journal-ref><doi>10.1109/ITSC.2018.8569391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upcoming Intelligent Transportation Systems (ITSs) will transform roads from
static resources to dynamic Cyber Physical Systems (CPSs) in order to satisfy
the requirements of future vehicular traffic in smart city environments.
Up-to-date information serves as the basis for changing street directions as
well as guiding individual vehicles to a fitting parking slot. In this context,
not only abstract indicators like traffic flow and density are required, but
also data about mobility parameters and class information of individual
vehicles. Consequently, accurate and reliable systems that are capable of
providing these kinds of information in real-time are highly demanded. In this
paper, we present a system for classifying vehicles based on their
radio-fingerprints which applies cutting-edge machine learning models and can
be non-intrusively installed into the existing road infrastructure in an ad-hoc
manner. In contrast to other approaches, it is able to provide accurate
classification results without causing privacy-violations or being vulnerable
to challenging weather conditions. Moreover, it is a promising candidate for
large-scale city deployments due to its cost-efficient installation and
maintenance properties. The proposed system is evaluated in a comprehensive
field evaluation campaign within an experimental live deployment on a German
highway, where it is able to achieve a binary classification success ratio of
more than 99% and an overall accuracy of 89.15% for a fine-grained
classification task with nine different classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00619</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00619</id><created>2018-07-02</created><updated>2018-08-12</updated><authors><author><keyname>Kumar</keyname><forenames>Yaman</forenames></author><author><keyname>Aggarwal</keyname><forenames>Mayank</forenames></author><author><keyname>Nawal</keyname><forenames>Pratham</forenames></author><author><keyname>Satoh</keyname><forenames>Shin'ichi</forenames></author><author><keyname>Shah</keyname><forenames>Rajiv Ratn</forenames></author><author><keyname>Zimmerman</keyname><forenames>Roger</forenames></author></authors><title>Harnessing AI for Speech Reconstruction using Multi-view Silent Video
  Feed</title><categories>cs.SD eess.AS</categories><comments>2018 ACM Multimedia Conference (MM '18), October 22--26, 2018, Seoul,
  Republic of Korea</comments><doi>10.1145/3240508.3241911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speechreading or lipreading is the technique of understanding and getting
phonetic features from a speaker's visual features such as movement of lips,
face, teeth and tongue. It has a wide range of multimedia applications such as
in surveillance, Internet telephony, and as an aid to a person with hearing
impairments. However, most of the work in speechreading has been limited to
text generation from silent videos. Recently, research has started venturing
into generating (audio) speech from silent video sequences but there have been
no developments thus far in dealing with divergent views and poses of a
speaker. Thus although, we have multiple camera feeds for the speech of a user,
but we have failed in using these multiple video feeds for dealing with the
different poses. To this end, this paper presents the world's first ever
multi-view speech reading and reconstruction system. This work encompasses the
boundaries of multimedia research by putting forth a model which leverages
silent video feeds from multiple cameras recording the same subject to generate
intelligent speech for a speaker. Initial results confirm the usefulness of
exploiting multiple camera views in building an efficient speech reading and
reconstruction system. It further shows the optimal placement of cameras which
would lead to the maximum intelligibility of speech. Next, it lays out various
innovative applications for the proposed system focusing on its potential
prodigious impact in not just security arena but in many other multimedia
analytics problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00655</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00655</id><created>2018-07-02</created><updated>2018-12-11</updated><authors><author><keyname>Giard</keyname><forenames>Pascal</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author><author><keyname>Burg</keyname><forenames>Andreas</forenames></author></authors><title>On the Tradeoff Between Accuracy and Complexity in Blind Detection of
  Polar Codes</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 4 figures, fixes typo in Sect. IV-D; presented at the
  International Symposium on Turbo Codes &amp; Iterative Information Processing
  (ISTC) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes are a recent family of error-correcting codes with a number of
desirable characteristics. Their disruptive nature is illustrated by their
rapid adoption in the $5^{th}$-generation mobile-communication standard, where
they are used to protect control messages. In this work, we describe a
two-stage system tasked with identifying the location of control messages that
consists of a detection and selection stage followed by a decoding one. The
first stage spurs the need for polar-code detection algorithms with variable
effort to balance complexity between the two stages. We illustrate this idea of
variable effort for multiple detection algorithms aimed at the first stage. We
propose three novel blind detection methods based on belief-propagation
decoding inspired by early-stopping criteria. Then we show how their
reliability improves with the number of decoding iterations to highlight the
possible tradeoffs between accuracy and complexity. Additionally, we show
similar tradeoffs for a detection method from previous work. In a setup where
only one block encoded with the polar code of interest is present among many
other blocks, our results notably show that, depending on the complexity
budget, a variable number of undesirable blocks can be dismissed while
achieving a missed-detection rate in line with the block-error rate of a
complex decoding algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00670</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00670</id><created>2018-06-26</created><updated>2018-07-03</updated><authors><author><keyname>Me&#x161;trovi&#x107;</keyname><forenames>Romeo</forenames></author></authors><title>A generalization of some random variables involving in certain
  compressive sensing problems</title><categories>eess.SP</categories><comments>12 pages, no figures; literature is extended and minor corrections in
  its citations have been made</comments><msc-class>60C05, 94A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give a generalization of the discrete complex-valued random
variable defined and investigated in \cite{ssa} and \cite{m8}. We prove the
statements concerning the expressions for the excepted value and the variance
of this random variable.
  In partucular, such a random variable here is defined for each of $m$ rows of
any $m\times N$ complex or real matrix ${\rm{\bf A}}$ with $1\le m\le N$. We
consider the arithmetic mean $\bar{X}(m)$ of these $m$ random variables and we
deduce the expressions for the expected value $\Bbb E[\bar{X}(m)]$ and the
variance ${\rm{ Var}}[\bar{X}(m)]$ of $\bar{X}(m)$. Using the expression for
${\rm{ Var}}[\bar{X}(m)]$, we establish some equalities and inequalities
involving ${\rm{Var}}[\bar{X}(m)]$, the Frobenius norm, the largest eigenvalue,
the largest singular value and the coherence of a matrix ${\rm{\bf A}}$. It is
showed that some of these estimates are closely related to the Welch bound of
the coherence of a $m\times N$ complex or real matrix ${\rm{\bf A}}$ with $1\le
m\le N$. Taking into account that the value of coherence of the measurement
matrix in the theory of compressive sensing has a significant role, we believe
that our results should be useful for some topics of this theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00682</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00682</id><created>2018-06-28</created><authors><author><keyname>Choi</keyname><forenames>Minseok</forenames></author><author><keyname>Kim</keyname><forenames>Joongheon</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>Dynamic Power Allocation and User Scheduling for Power-Efficient and
  Low-Latency Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>30 pages, 10 figures, Submission to IEEE Journal on Selected Areas in
  Communication</comments><journal-ref>IEEE Transactions on Wireless Communications, 26 July, 2019</journal-ref><doi>10.1109/TWC.2019.2929809</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a joint dynamic power control and user pairing
algorithm for power-efficient and low-latency hybrid multiple access systems.
In a hybrid multiple access system, user pairing determines whether the
transmitter should serve a certain user by orthogonal multiple access (OMA) or
non-orthogonal multiple access (NOMA). The proposed optimization framework
minimizes the long-term time-average transmit power expenditure while reducing
the queueing delay and satisfying time-average data rate requirements. The
proposed technique observes channel and queue state information and adjusts
queue backlogs to avoid an excessive queueing delay by appropriate user pairing
and power allocation. Further, user scheduling for determining the activation
of a given user link as well as flexible use of resources are captured in the
proposed algorithm. Data-intensive simulation results show that the proposed
scheme guarantees an end-to-end delay smaller than 1 ms with high
power-efficiency and high reliability, based on the short frame structure
designed for ultra-reliable low-latency communications (URLLC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00747</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00747</id><created>2018-07-02</created><authors><author><keyname>Schibisch</keyname><forenames>Stefan</forenames></author><author><keyname>Cammerer</keyname><forenames>Sebastian</forenames></author><author><keyname>D&#xf6;rner</keyname><forenames>Sebastian</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>Online Label Recovery for Deep Learning-based Communication through
  Error Correcting Codes</title><categories>cs.IT eess.SP math.IT</categories><comments>accepted for ISWCS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that error correcting codes (ECCs) can be used to construct a
labeled data set for finetuning of &quot;trainable&quot; communication systems without
sacrificing resources for the transmission of known symbols. This enables
adaptive systems, which can be trained on-the-fly to compensate for slow
fluctuations in channel conditions or varying hardware impairments. We examine
the influence of corrupted training data and show that it is crucial to train
based on correct labels. The proposed method can be applied to fully end-to-end
trained communication systems (autoencoders) as well as systems with only some
trainable components. This is exemplified by extending a conventional OFDM
system with a trainable pre-equalizer neural network (NN) that can be optimized
at run time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00752</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00752</id><created>2018-07-02</created><authors><author><keyname>Kato</keyname><forenames>Akihiro</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author></authors><title>Waveform to Single Sinusoid Regression to Estimate the F0 Contour from
  Noisy Speech Using Recurrent Deep Neural Networks</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>Accepted by peer reviewing for Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental frequency (F0) represents pitch in speech that determines
prosodic characteristics of speech and is needed in various tasks for speech
analysis and synthesis. Despite decades of research on this topic, F0
estimation at low signal-to-noise ratios (SNRs) in unexpected noise conditions
remains difficult. This work proposes a new approach to noise robust F0
estimation using a recurrent neural network (RNN) trained in a supervised
manner. Recent studies employ deep neural networks (DNNs) for F0 tracking as a
frame-by-frame classification task into quantised frequency states but we
propose waveform-to-sinusoid regression instead to achieve both noise
robustness and accurate estimation with increased frequency resolution.
  Experimental results with PTDB-TUG corpus contaminated by additive noise
(NOISEX-92) demonstrate that the proposed method improves gross pitch error
(GPE) rate and fine pitch error (FPE) by more than 35 % at SNRs between -10 dB
and +10 dB compared with well-known noise robust F0 tracker, PEFAC.
Furthermore, the proposed method also outperforms state-of-the-art DNN-based
approaches by more than 15 % in terms of both FPE and GPE rate over the
preceding SNR range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00790</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00790</id><created>2018-07-02</created><authors><author><keyname>Harrison</keyname><forenames>Peter M. C.</forenames></author><author><keyname>Pearce</keyname><forenames>Marcus T.</forenames></author></authors><title>An energy-based generative sequence model for testing sensory theories
  of Western harmony</title><categories>cs.SD eess.AS</categories><comments>8 pages, 2 figures. To appear in Proceedings of the 19th
  International Society for Music Information Retrieval Conference (ISMIR),
  Paris, France, 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The relationship between sensory consonance and Western harmony is an
important topic in music theory and psychology. We introduce new methods for
analysing this relationship, and apply them to large corpora representing three
prominent genres of Western music: classical, popular, and jazz music. These
methods centre on a generative sequence model with an exponential-family
energy-based form that predicts chord sequences from continuous features. We
use this model to investigate one aspect of instantaneous consonance
(harmonicity) and two aspects of sequential consonance (spectral distance and
voice-leading distance). Applied to our three musical genres, the results
generally support the relationship between sensory consonance and harmony, but
lead us to question the high importance attributed to spectral distance in the
psychological literature. We anticipate that our methods will provide a useful
platform for future work linking music psychology to music theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00862</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00862</id><created>2018-07-02</created><authors><author><keyname>Hassan</keyname><forenames>Shah</forenames></author><author><keyname>Sajjad</keyname><forenames>Hadia</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Mahboob Ur</forenames></author></authors><title>Power Imbalance Detection in Smart Grid via Grid Frequency Deviations: A
  Hidden Markov Model based Approach</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 6 figures, accepted by IEEE VTC conference, Fall 2018
  edition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We detect the deviation of the grid frequency from the nominal value (i.e.,
50 Hz), which itself is an indicator of the power imbalance (i.e., mismatch
between power generation and load demand). We first pass the noisy estimates of
grid frequency through a hypothesis test which decides whether there is no
deviation, positive deviation, or negative deviation from the nominal value.
The hypothesis testing incurs miss-classification errors---false alarms (i.e.,
there is no deviation but we declare a positive/negative deviation), and missed
detections (i.e., there is a positive/negative deviation but we declare no
deviation). Therefore, to improve further upon the performance of the
hypothesis test, we represent the grid frequency's fluctuations over time as a
discrete-time hidden Markov model (HMM). We note that the outcomes of the
hypothesis test are actually the emitted symbols, which are related to the true
states via emission probability matrix. We then estimate the hidden Markov
sequence (the true values of the grid frequency) via maximum likelihood method
by passing the observed/emitted symbols through the Viterbi decoder.
Simulations results show that the mean accuracy of Viterbi algorithm is at
least $5$\% greater than that of hypothesis test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00868</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00868</id><created>2018-07-02</created><authors><author><keyname>Bataev</keyname><forenames>Vladimir</forenames></author><author><keyname>Korenevsky</keyname><forenames>Maxim</forenames></author><author><keyname>Medennikov</keyname><forenames>Ivan</forenames></author><author><keyname>Zatvornitskiy</keyname><forenames>Alexander</forenames></author></authors><title>Exploring End-to-End Techniques for Low-Resource Speech Recognition</title><categories>cs.SD cs.CL eess.AS</categories><comments>Accepted for Specom 2018, 20th International Conference on Speech and
  Computer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present simple grapheme-based system for low-resource speech
recognition using Babel data for Turkish spontaneous speech (80 hours). We have
investigated different neural network architectures performance, including
fully-convolutional, recurrent and ResNet with GRU. Different features and
normalization techniques are compared as well. We also proposed CTC-loss
modification using segmentation during training, which leads to improvement
while decoding with small beam size. Our best model achieved word error rate of
45.8%, which is the best reported result for end-to-end systems using in-domain
data for this task, according to our knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00893</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00893</id><created>2018-07-02</created><updated>2019-07-26</updated><authors><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames></author><author><keyname>Dewaskar</keyname><forenames>Miheer</forenames></author><author><keyname>Genest</keyname><forenames>Blaise</forenames></author><author><keyname>Gimbert</keyname><forenames>Hugo</forenames></author><author><keyname>Godbole</keyname><forenames>Adwait Amit</forenames></author></authors><title>Controlling a population</title><categories>cs.FL cs.SY eess.SY</categories><comments>This is a journal version of the extended abstract arXiv:1707.02058
  which appeared in Concur 2017, together with proofs</comments><proxy>Logical Methods In Computer Science</proxy><journal-ref>Logical Methods in Computer Science, Volume 15, Issue 3 (July 29,
  2019) lmcs:5647</journal-ref><doi>10.23638/LMCS-15(3:6)2019</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a new setting where a population of agents, each modelled by a
finite-state system, are controlled uniformly: the controller applies the same
action to every agent. The framework is largely inspired by the control of a
biological system, namely a population of yeasts, where the controller may only
change the environment common to all cells. We study a synchronisation problem
for such populations: no matter how individual agents react to the actions of
the controller, the controller aims at driving all agents synchronously to a
target state. The agents are naturally represented by a non-deterministic
finite state automaton (NFA), the same for every agent, and the whole system is
encoded as a 2-player game. The first player (Controller) chooses actions, and
the second player (Agents) resolves non-determinism for each agent. The game
with m agents is called the m -population game. This gives rise to a
parameterized control problem (where control refers to 2 player games), namely
the population control problem: can Controller control the m-population game
for all m in N whatever Agents does?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00951</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00951</id><created>2018-07-02</created><authors><author><keyname>Sadek</keyname><forenames>Ibrahim</forenames></author></authors><title>Ballistocardiogram Signal Processing: A Literature Review</title><categories>eess.SP cs.CV</categories><comments>Review Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-domain algorithms are focused on detecting local maxima or local minima
using a moving window, and therefore finding the interval between the dominant
J-peaks of ballistocardiogram (BCG) signal. However, this approach has many
limitations due to the nonlinear and nonstationary behavior of the BCG signal.
This is because the BCG signal does not display consistent J-peaks, which can
usually be the case for overnight, in-home monitoring, particularly with frail
elderly. Additionally, its accuracy will be undoubtedly affected by motion
artifacts. Second, frequency-domain algorithms do not provide information about
interbeat intervals. Nevertheless, they can provide information about heart
rate variability. This is usually done by taking the fast Fourier transform or
the inverse Fourier transform of the logarithm of the estimated spectrum, i.e.,
cepstrum of the signal using a sliding window. Thereafter, the dominant
frequency is obtained in a particular frequency range. The limit of these
algorithms is that the peak in the spectrum may get wider and multiple peaks
may appear, which might cause a problem in measuring the vital signs. At last,
the objective of wavelet-domain algorithms is to decompose the signal into
different components, hence the component which shows an agreement with the
vital signs can be selected i.e., the selected component contains only
information about the heart cycles or respiratory cycles, respectively. An
empirical mode decomposition is an alternative approach to wavelet
decomposition, and it is also a very suitable approach to cope with nonlinear
and nonstationary signals such as cardiorespiratory signals. Apart from the
above-mentioned algorithms, machine learning approaches have been implemented
for measuring heartbeats. However, manual labeling of training data is a
restricting property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.00967</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.00967</id><created>2018-07-02</created><authors><author><keyname>Bai</keyname><forenames>Yanna</forenames></author><author><keyname>Ai</keyname><forenames>Bo</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>Deep Learning Based Fast Multiuser Detection for Massive Machine-Type
  Communication</title><categories>eess.SP</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive machine-type communication (MTC) with sporadically transmitted small
packets and low data rate requires new designs on the PHY and MAC layer with
light transmission overhead. Compressive sensing based multiuser detection
(CS-MUD) is designed to detect active users through random access with low
overhead by exploiting sparsity, i.e., the nature of sporadic transmissions in
MTC. However, the high computational complexity of conventional sparse
reconstruction algorithms prohibits the implementation of CS-MUD in real
communication systems. To overcome this drawback, in this paper, we propose a
fast Deep learning based approach for CS-MUD in massive MTC systems. In
particular, a novel block restrictive activation nonlinear unit, is proposed to
capture the block sparse structure in wide-band wireless communication systems
(or multi-antenna systems). Our simulation results show that the proposed
approach outperforms various existing algorithms for CS-MUD and allows for
ten-fold decrease of the computing time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01071</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01071</id><created>2018-07-03</created><authors><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Tataria</keyname><forenames>Harsh</forenames></author></authors><title>Does Massive MIMO Fail in Ricean Channels?</title><categories>eess.SP</categories><comments>IEEE Wireless Communications Letters, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (MIMO) is now making its way to the
standardization exercise of future 5G networks. Yet, there are still
fundamental questions pertaining to the robustness of massive MIMO against
physically detrimental propagation conditions. On these grounds, we identify
scenarios under which massive MIMO can potentially fail in Ricean channels, and
characterize them physically, as well as, mathematically. Our analysis extends
and generalizes a stream of recent papers on this topic and articulates
emphatically that such harmful scenarios in Ricean fading conditions are
unlikely and can be compensated using any standard scheduling scheme. This
implies that massive MIMO is intrinsically effective at combating interuser
interference and, if needed, can avail of the base-station scheduler for
further robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01080</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01080</id><created>2018-07-03</created><authors><author><keyname>Cancino-Chac&#xf3;n</keyname><forenames>Carlos</forenames></author><author><keyname>Grachten</keyname><forenames>Maarten</forenames></author></authors><title>A Computational Study of the Role of Tonal Tension in Expressive Piano
  Performance</title><categories>cs.SD eess.AS</categories><comments>6 pages, 2 figures, accepted as poster at the ICMPC15/ESCOM10 in
  Graz, Austria</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Expressive variations of tempo and dynamics are an important aspect of music
performances, involving a variety of underlying factors. Previous work has
showed a relation between such expressive variations (in particular expressive
tempo) and perceptual characteristics derived from the musical score, such as
musical expectations, and perceived tension. In this work we use a
computational approach to study the role of three measures of tonal tension
proposed by Herremans and Chew (2016) in the prediction of expressive
performances of classical piano music. These features capture tonal
relationships of the music represented in Chew's spiral array model, a three
dimensional representation of pitch classes, chords and keys constructed in
such a way that spatial proximity represents close tonal relationships. We use
non-linear sequential models (recurrent neural networks) to assess the
contribution of these features to the prediction of expressive dynamics and
expressive tempo using a dataset of Mozart piano sonatas performed by a
professional concert pianist. Experiments of models trained with and without
tonal tension features show that tonal tension helps predict change of tempo
and dynamics more than absolute tempo and dynamics values. Furthermore, the
improvement is stronger for dynamics than for tempo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01106</identifier>
 <datestamp>2018-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01106</id><created>2018-07-03</created><updated>2018-09-26</updated><authors><author><keyname>Mart&#xed;n</keyname><forenames>Rodrigo</forenames></author><author><keyname>Weinmann</keyname><forenames>Michael</forenames></author><author><keyname>Hullin</keyname><forenames>Matthias B.</forenames></author></authors><title>A Study of Material Sonification in Touchscreen Devices</title><categories>cs.HC cs.MM cs.SD eess.AS</categories><comments>9 pages</comments><acm-class>H.5.2</acm-class><journal-ref>Proc. ACM ISS 2018, 305-310</journal-ref><doi>10.1145/3279778.3281455</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even in the digital age, designers largely rely on physical material samples
to illustrate their products, as existing visual representations fail to
sufficiently reproduce the look and feel of real world materials. Here, we
investigate the use of interactive material sonification as an additional
sensory modality for communicating well-established material qualities like
softness, pleasantness or value. We developed a custom application for
touchscreen devices that receives tactile input and translate it into material
rubbing sound using granular synthesis. We used this system to perform a
psychophysical study, in which the ability of the user to rate subjective
material qualities is evaluated, with the actual material samples serving as
reference stimulus. Our experimental results indicate that the considered audio
cues do not significantly contribute to the perception of material qualities
but are able to increase the level of immersion when interacting with digital
samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01126</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01126</id><created>2018-07-03</created><updated>2019-06-20</updated><authors><author><keyname>Yalta</keyname><forenames>Nelson</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Nakadai</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Ogata</keyname><forenames>Tetsuya</forenames></author></authors><title>Weakly Supervised Deep Recurrent Neural Networks for Basic Dance Step
  Generation</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>8 pages, 7 figures. Proc. IJCNN 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Synthesizing human's movements such as dancing is a flourishing research
field which has several applications in computer graphics. Recent studies have
demonstrated the advantages of deep neural networks (DNNs) for achieving
remarkable performance in motion and music tasks with little effort for feature
pre-processing. However, applying DNNs for generating dance to a piece of music
is nevertheless challenging, because of 1) DNNs need to generate large
sequences while mapping the music input, 2) the DNN needs to constraint the
motion beat to the music, and 3) DNNs require a considerable amount of
hand-crafted data. In this study, we propose a weakly supervised deep recurrent
method for real-time basic dance generation with audio power spectrum as input.
The proposed model employs convolutional layers and a multilayered Long
Short-Term memory (LSTM) to process the audio input. Then, another deep LSTM
layer decodes the target dance sequence. Notably, this end-to-end approach has
1) an auto-conditioned decode configuration that reduces accumulation of
feedback error of large dance sequence, 2) uses a contrastive cost function to
regulate the mapping between the music and motion beat, and 3) trains with weak
labels generated from the motion beat, reducing the amount of hand-crafted
data. We evaluate the proposed network based on i) the similarities between
generated and the baseline dancer motion with a cross entropy measure for large
dance sequences, and ii) accurate timing between the music and motion beat with
an F-measure. Experimental results revealed that, after training using a small
dataset, the model generates basic dance steps with low cross entropy and
maintains an F-measure score similar to that of a baseline dancer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01138</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01138</id><created>2018-07-03</created><authors><author><keyname>Nandi</keyname><forenames>Swagata</forenames></author><author><keyname>Kundu</keyname><forenames>Debasis</forenames></author></authors><title>Estimation of Parameters of Multiple Chirp Signal in presence of Heavy
  Tailed Errors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the estimation of the unknown parameters of the
multiple chirp signal model in presence of additive error. The chirp signals
are quite common in many areas of science and engineering, specially sonar,
radar, audio signals etc. The observed signals are usually corrupted by noise.
In different signal processing applications it is observed that the errors may
be heavy tailed. In this paper it is assumed that the additive errors have mean
zero but may not have finite variance and are independent and identically
distributed. We consider the least squares estimators and the approximate least
squares estimators which maximize a periodogram like function. It has been
observed that both the estimators are strongly consistent. The asymptotic
distribution of the least squares estimators is obtained under the assumption
that the additive errors are from a symmetric stable distribution. The
approximate least squares estimators have the same asymptotic distribution as
the least squares estimators. We perform some numerical simulations to see how
the proposed estimators work. It is observed that the least squares estimators
perform slightly better than the approximately least squares estimators in
terms of the biases and mean absolute deviation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01224</identifier>
 <datestamp>2018-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01224</id><created>2018-07-03</created><updated>2018-09-28</updated><authors><author><keyname>Almansouri</keyname><forenames>Hani</forenames></author><author><keyname>Venkatakrishnan</keyname><forenames>S. V.</forenames></author><author><keyname>Buzzard</keyname><forenames>Gregery T.</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author><author><keyname>Santos-Villalobos</keyname><forenames>Hector</forenames></author></authors><title>Deep neural networks for non-linear model-based ultrasound
  reconstruction</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound reflection tomography is widely used to image large complex
specimens that are only accessible from a single side, such as well systems and
nuclear power plant containment walls. Typical methods for inverting the
measurement rely on delay-and-sum algorithms that rapidly produce
reconstructions but with significant artifacts. Recently, model-based
reconstruction approaches using a linear forward model have been shown to
significantly improve image quality compared to the conventional approach.
However, even these techniques result in artifacts for complex objects because
of the inherent non-linearity of the ultrasound forward model.
  In this paper, we propose a non-iterative model-based reconstruction method
for inverting measurements that are based on non-linear forward models for
ultrasound imaging. Our approach involves obtaining an approximate estimate of
the reconstruction using a simple linear back-projection and training a deep
neural network to refine this to the actual reconstruction. We apply our method
to simulated ultrasound data and demonstrate dramatic improvements in image
quality compared to the delay-and-sum approach and the linear model-based
reconstruction approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01237</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01237</id><created>2018-06-30</created><authors><author><keyname>Tuladhar</keyname><forenames>Saurav R</forenames></author><author><keyname>Buck</keyname><forenames>John R</forenames></author></authors><title>Unit circle rectification of the MVDR beamformer</title><categories>eess.SP cs.SY</categories><comments>Submitted to IEEE Journal of Oceanic Engineering</comments><doi>10.1109/JOE.2018.2876584</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The sample matrix inversion (SMI) beamformer implements Capon's minimum
variance distortionless (MVDR) beamforming using the sample covariance matrix
(SCM). In a snapshot limited environment, the SCM is poorly conditioned
resulting in a suboptimal performance from the SMI beamformer. Imposing
structural constraints on the SCM estimate to satisfy known theoretical
properties of the ensemble MVDR beamformer mitigates the impact of limited
snapshots on the SMI beamformer performance. Toeplitz rectification and
bounding the norm of weight vector are common approaches for such constrains.
This paper proposes the unit circle rectification technique which constraints
the SMI beamformer to satisfy a property of the ensemble MVDR beamformer: for
narrowband planewave beamforming on a uniform linear array, the zeros of the
MVDR weight array polynomial must fall on the unit circle. Numerical
simulations show that the resulting unit circle MVDR (UC MVDR) beamformer
frequently improves the suppression of both discrete interferers and white
background noise compared to the classic SMI beamformer. Moreover, the UC MVDR
beamformer is shown to suppress discrete interferers better than the MVDR
beamformer diagonally loaded to maximize the SINR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01238</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01238</id><created>2018-07-01</created><authors><author><keyname>Jajimi</keyname><forenames>Sai Charan</forenames></author></authors><title>Fast Fourier-Based Generation of the Compression Matrix for
  Deterministic Compressed Sensing</title><categories>eess.SP cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primary goal of this work is to review the importance of data compression
and present a fast Fourier-based method for generating the deterministic
compression matrix in the area of deterministic compressed sensing. The
principle concepts of data compression such as general process of data
compression, sparse signals, coherence matrix and Restricted Isometry Property
(RIP) have been defined. We have introduced two methods of sparse data
compression. The first method is formed by utilizing a stochastic matrix which
is a common approach, and the second method is created by utilizing a
deterministic matrix which is proposed more recently. The main goal of this
work is to improve the execution time of the deterministic matrix generation.
The execution time is related to the generation method of the deterministic
matrix. Furthermore, we have implemented a software which makes it possible to
compare different methods of reconstructing data compression. To make this
comparison, it is necessary to draw and compare certain graphs, e.g. phase
transition, the ratio of output signal to noise and input signal to noise,
signal to noise output and also the ratio of percentage of accurate
reconstructing and order of sparse signals for various reconstructing methods.
To facilitate this process, the user would be able to draw his/her favorite
graphs in GUI environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01242</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01242</id><created>2018-06-26</created><authors><author><keyname>Lekidis</keyname><forenames>Alexios</forenames><affiliation>Aristotle University of Thessaloniki</affiliation></author><author><keyname>Katsaros</keyname><forenames>Panagiotis</forenames><affiliation>Aristotle University of Thessaloniki</affiliation></author></authors><title>Model-Based Design of Energy-Efficient Applications for IoT Systems</title><categories>eess.SP cs.NI</categories><comments>In Proceedings MeTRiD 2018, arXiv:1806.09330</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 272, 2018, pp. 24-38</journal-ref><doi>10.4204/EPTCS.272.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major challenge that is currently faced in the design of applications for
the Internet of Things (IoT) concerns with the optimal use of available energy
resources given the battery lifetime of the IoT devices. The challenge is
derived from the heterogeneity of the devices, in terms of their hardware and
the provided functionalities (e.g data processing/communication). In this
paper, we propose a novel method for (i) characterizing the parameters that
influence energy consumption and (ii) validating the energy consumption of IoT
devices against the system's energy-efficiency requirements (e.g. lifetime).
Our approach is based on energy-aware models of the IoT application's design in
the BIP (Behavior, Interaction, Priority) component framework. This allows for
a detailed formal representation of the system's behavior and its subsequent
validation, thus providing feedback for enhancements in the pre-deployment or
pre-production stages. We illustrate our approach through a Building Management
System, using well-known IoT devices running the Contiki OS that communicate by
diverse IoT protocols (e.g. CoAP, MQTT). The results allow to derive tight
bounds for the energy consumption in various device functionalities, as well as
to validate lifetime requirements through Statistical Model Checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01276</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01276</id><created>2018-07-01</created><updated>2019-05-11</updated><authors><author><keyname>Cui</keyname><forenames>Angang</forenames></author><author><keyname>Wen</keyname><forenames>Meng</forenames></author><author><keyname>Li</keyname><forenames>Haiyang</forenames></author><author><keyname>Peng</keyname><forenames>Jigen</forenames></author></authors><title>A non-convex approach to low-rank and sparse matrix decomposition</title><categories>math.OC cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a nonconvex approach to the problem of low-rank and
sparse matrix decomposition. In our nonconvex method, we replace the rank
function and the $l_{0}$-norm of a given matrix with a non-convex fraction
function on the singular values and the elements of the matrix respectively. An
alternative direction method of multipliers algorithm is utilized to solve our
proposed nonconvex problem with the nonconvex fraction function penalty.
Numerical experiments on some low-rank and sparse matrix decomposition problems
show that our method performs very well in recovering low-rank matrices which
are heavily corrupted by large sparse errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01385</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01385</id><created>2018-07-03</created><authors><author><keyname>Shinoda</keyname><forenames>Kazuma</forenames></author><author><keyname>Kawase</keyname><forenames>Maru</forenames></author><author><keyname>Hasegawa</keyname><forenames>Madoka</forenames></author><author><keyname>Ishikawa</keyname><forenames>Masahiro</forenames></author><author><keyname>Komagata</keyname><forenames>Hideki</forenames></author><author><keyname>Kobayashi</keyname><forenames>Naoki</forenames></author></authors><title>Joint optimization of multispectral filter arrays and demosaicking for
  pathological images</title><categories>eess.IV</categories><journal-ref>IIEEJ Transactions on Image Electronics and Visual Computing, Vol.
  6, No. 1, pp. 13-21, Jun. 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A capturing system with multispectral filter array (MSFA) technology is
proposed for shortening the capture time and reducing costs. Therein, a
mosaicked image captured using an MSFA is demosaicked to reconstruct
multispectral images (MSIs). Joint optimization of the spectral sensitivity of
the MSFAs and demosaicking is considered, and pathology-specific multispectral
imaging is proposed. This optimizes the MSFA and the demosaicking matrix by
minimizing the reconstruction error between the training data of a hematoxylin
and eosin-stained pathological tissue and a demosaicked MSI using a cost
function. Initially, the spectral sensitivity of the filter array is set
randomly and the mosaicked image is obtained from the training data.
Subsequently, a reconstructed image is obtained using Wiener estimation. To
minimize the reconstruction error, the spectral sensitivity of the filter array
and the Wiener estimation matrix are optimized iteratively through an
interior-point approach. The effectiveness of the proposed MSFA and
demosaicking is demonstrated by comparing the recovered spectrum and RGB image
with those obtained using a conventional method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01386</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01386</id><created>2018-07-03</created><authors><author><keyname>Shinoda</keyname><forenames>Kazuma</forenames></author><author><keyname>Kawase</keyname><forenames>Maru</forenames></author><author><keyname>Hasegawa</keyname><forenames>Madoka</forenames></author><author><keyname>Ishikawa</keyname><forenames>Masahiro</forenames></author><author><keyname>Komagata</keyname><forenames>Hideki</forenames></author><author><keyname>Kobayashi</keyname><forenames>Naoki</forenames></author></authors><title>Optimal Spectral Sensitivity of Multispectral Filter Array for
  Pathological Images</title><categories>eess.IV</categories><journal-ref>Image Electronics and Visual Computing Workshop (IEVC), 1P-10,
  Mar. 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A capturing system with multispectral filter array (MSFA) technology has been
researched to shorten the capturing time and reduce the cost. In this system,
the mosaicked image captured by the MSFA is demosaicked to reconstruct
multispectral images (MSIs). We focus on the spectral sensitivity design of a
MSFA in this paper and propose a pathology-specific MSFA. The proposed method
optimizes the MSFA by minimizing the reconstruction error between training data
of a pathological tissue and a demosaicked MSI under a cost function. Firstly,
the spectral sensitivities of the filter array are set randomly, and the
mosaicked image is obtained from the training data and the filter array. Then,
a reconstructed image is obtained by Wiener estimation. The spectral
sensitivities of the filter array are optimized iteratively by an
interior-point approach to minimize the reconstruction error. We show the
effectiveness of the proposed MSFA by comparing the recovered spectrum and RGB
image with a conventional method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01401</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01401</id><created>2018-07-03</created><authors><author><keyname>Farnell</keyname><forenames>Elin</forenames></author><author><keyname>Kvinge</keyname><forenames>Henry</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author></authors><title>Endmember Extraction on the Grassmannian</title><categories>cs.CV cs.LG eess.IV eess.SP</categories><comments>To appear in Proceedings of the 2018 IEEE Data Science Workshop,
  Lausanne, Switzerland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Endmember extraction plays a prominent role in a variety of data analysis
problems as endmembers often correspond to data representing the purest or best
representative of some feature. Identifying endmembers then can be useful for
further identification and classification tasks. In settings with
high-dimensional data, such as hyperspectral imagery, it can be useful to
consider endmembers that are subspaces as they are capable of capturing a wider
range of variations of a signature. The endmember extraction problem in this
setting thus translates to finding the vertices of the convex hull of a set of
points on a Grassmannian. In the presence of noise, it can be less clear
whether a point should be considered a vertex. In this paper, we propose an
algorithm to extract endmembers on a Grassmannian, identify subspaces of
interest that lie near the boundary of a convex hull, and demonstrate the use
of the algorithm on a synthetic example and on the 220 spectral band AVIRIS
Indian Pines hyperspectral image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01462</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01462</id><created>2018-07-04</created><authors><author><keyname>Nguyen</keyname><forenames>Anh-Duc</forenames></author><author><keyname>Kim</keyname><forenames>Woojae</forenames></author><author><keyname>Kim</keyname><forenames>Jongyoo</forenames></author><author><keyname>Lee</keyname><forenames>Sanghoon</forenames></author></authors><title>Video Frame Interpolation by Plug-and-Play Deep Locally Linear Embedding</title><categories>cs.CV eess.IV</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generative framework which takes on the video frame
interpolation problem. Our framework, which we call Deep Locally Linear
Embedding (DeepLLE), is powered by a deep convolutional neural network (CNN)
while it can be used instantly like conventional models. DeepLLE fits an
auto-encoding CNN to a set of several consecutive frames and embeds a linearity
constraint on the latent codes so that new frames can be generated by
interpolating new latent codes. Different from the current deep learning
paradigm which requires training on large datasets, DeepLLE works in a
plug-and-play and unsupervised manner, and is able to generate an arbitrary
number of frames. Thorough experiments demonstrate that without bells and
whistles, our method is highly competitive among current state-of-the-art
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01497</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01497</id><created>2018-07-04</created><updated>2018-10-05</updated><authors><author><keyname>Aydogdu</keyname><forenames>Canan</forenames></author><author><keyname>Garcia</keyname><forenames>Nil</forenames></author><author><keyname>Hammarstrand</keyname><forenames>Lars</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author></authors><title>Radar Communication for Combating Mutual Interference of FMCW Radars</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 8 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commercial automotive radars used today are based on frequency modulated
continuous wave signals due to the simple and robust detection method and good
accuracy. However, the increase in both the number of radars deployed per
vehicle and the number of such vehicles leads to mutual interference among
automotive radars, and cutting short future plans for autonomous driving and
safety. We propose and analyze a radar communication (RadCom) approach to
reduce or eliminate this mutual interference while simultaneously offering
communication functionality. Our RadCom approach frequency division multiplexes
radar and communication, where communication is built on a decentralized
carrier sense multiple access protocol and is used to adjust the timing of
radar transmissions. Our simulation results indicate that radar interference
can be significantly reduced, at no cost in radar accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01533</identifier>
 <datestamp>2018-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01533</id><created>2018-07-04</created><authors><author><keyname>Balthazar</keyname><forenames>Lucas</forenames></author><author><keyname>Xavier</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author></authors><title>Distributed Estimation Via a Roaming Token</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for the problem of linear distributed estimation of a
parameter in a network where a set of agents are successively taking
measurements. The approach considers a roaming token in a network that carries
the estimate, and jumps from one agent to another in its vicinity according to
the probabilities of a Markov chain. When the token is at an agent it records
the agent's local information. We analyze the proposed algorithm and show that
it is consistent and asymptotically optimal, in the sense that its
mean-square-error (MSE) rate of decay approaches the centralized one as the
number of iterations increases. We show these results for a scenario where the
network changes over time, and we consider two different set of assumptions on
the network instantiations: they are i.i.d. and connected on the average, or
they are deterministic and strongly connected for every finite time window of a
fixed size. Simulations show our algorithm is competitive with
consensus+innovations type algorithms, achieving a smaller MSE at each
iteration in all considered scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01541</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01541</id><created>2018-07-04</created><updated>2019-06-29</updated><authors><author><keyname>Cao</keyname><forenames>Zehong</forenames></author><author><keyname>Prasad</keyname><forenames>Mukesh</forenames></author><author><keyname>Tanveer</keyname><forenames>M.</forenames></author><author><keyname>Lin</keyname><forenames>Chin-Teng</forenames></author></authors><title>Tensor Decomposition for EEG Signal Retrieval</title><categories>eess.SP</categories><journal-ref>2019 IEEE International Conference on Systems, Man and Cybernetics
  (SMC)</journal-ref><doi>10.1109/SMC.2019.8914076</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prior studies have proposed methods to recover multi-channel
electroencephalography (EEG) signal ensembles from their partially sampled
entries. These methods depend on spatial scenarios, yet few approaches aiming
to a temporal reconstruction with lower loss. The goal of this study is to
retrieve the temporal EEG signals independently which was overlooked in data
pre-processing. We considered EEG signals are impinging on tensor-based
approach, named nonlinear Canonical Polyadic Decomposition (CPD). In this
study, we collected EEG signals during a resting-state task. Then, we defined
that the source signals are original EEG signals and the generated tensor is
perturbed by Gaussian noise with a signal-to-noise ratio of 0 dB. The sources
are separated using a basic non-negative CPD and the relative errors on the
estimates of the factor matrices. Comparing the similarities between the source
signals and their recovered versions, the results showed significantly high
correlation over 95%. Our findings reveal the possibility of recoverable
temporal signals in EEG applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01671</identifier>
 <datestamp>2019-03-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01671</id><created>2018-07-04</created><updated>2019-03-22</updated><authors><author><keyname>Zamzam</keyname><forenames>Ahmed S.</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author></authors><title>Data-Driven Learning-Based Optimization for Distribution System State
  Estimation</title><categories>eess.SP</categories><comments>13 pages, 6 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution system state estimation (DSSE) is a core task for monitoring and
control of distribution networks. Widely used algorithms such as Gauss-Netwon
perform poorly with the limited number of measurements typically available for
DSSE, often require many iterations to obtain reasonable results, and sometimes
fail to converge. DSSE is a non-convex problem, and working with a limited
number of measurements further aggravate the situation, as indeterminacy
induces multiple global (in addition to local) minima. Gauss-Newton is also
known to be sensitive to initialization. Hence, the situation is far from
ideal. It is therefore natural to ask if there is a smart way of initializing
Gauss-Newton that will avoid these DSSE-specific pitfalls. This paper proposes
using historical or simulation-derived data to train a shallow neural network
to `learn to initialize' -- that is, map the available measurements to a point
in the neighborhood of the true latent states (network voltages), which is used
to initialize Gauss-Newton. It is shown that this hybrid machine learning /
optimization approach yields superior performance in terms of stability,
accuracy, and runtime efficiency, compared to conventional optimization-only
approaches. It is also shown that judicious design of the neural network
training cost function helps to improve the overall DSSE performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01738</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01738</id><created>2018-07-04</created><authors><author><keyname>Tu</keyname><forenames>Ming</forenames></author><author><keyname>Grabek</keyname><forenames>Anna</forenames></author><author><keyname>Liss</keyname><forenames>Julie</forenames></author><author><keyname>Berisha</keyname><forenames>Visar</forenames></author></authors><title>Investigating the role of L1 in automatic pronunciation evaluation of L2
  speech</title><categories>eess.AS cs.SD</categories><comments>To appear in Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic pronunciation evaluation plays an important role in pronunciation
training and second language education. This field draws heavily on concepts
from automatic speech recognition (ASR) to quantify how close the pronunciation
of non-native speech is to native-like pronunciation. However, it is known that
the formation of accent is related to pronunciation patterns of both the target
language (L2) and the speaker's first language (L1). In this paper, we propose
to use two native speech acoustic models, one trained on L2 speech and the
other trained on L1 speech. We develop two sets of measurements that can be
extracted from two acoustic models given accented speech. A new utterance-level
feature extraction scheme is used to convert these measurements into a
fixed-dimension vector which is used as an input to a statistical model to
predict the accentedness of a speaker. On a data set consisting of speakers
from 4 different L1 backgrounds, we show that the proposed system yields
improved correlation with human evaluators compared to systems only using the
L2 acoustic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01898</identifier>
 <datestamp>2018-07-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01898</id><created>2018-07-05</created><authors><author><keyname>Liu</keyname><forenames>Jen-Yu</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Denoising Auto-encoder with Recurrent Skip Connections and Residual
  Regression for Music Source Separation</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks with skip connections have shown good
performance in music source separation. In this work, we propose a denoising
Auto-encoder with Recurrent skip Connections (ARC). We use 1D convolution along
the temporal axis of the time-frequency feature map in all layers of the
fully-convolutional network. The use of 1D convolution makes it possible to
apply recurrent layers to the intermediate outputs of the convolution layers.
In addition, we also propose an enhancement network and a residual regression
method to further improve the separation result. The recurrent skip
connections, the enhancement module, and the residual regression all improve
the separation quality. The ARC model with residual regression achieves 5.74
siganl-to-distoration ratio (SDR) in vocals with MUSDB in SiSEC 2018. We also
evaluate the ARC model alone on the older dataset DSD100 (used in SiSEC 2016)
and it achieves 5.91 SDR in vocals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01956</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01956</id><created>2018-07-05</created><authors><author><keyname>M&#xfc;ller</keyname><forenames>Markus</forenames></author><author><keyname>St&#xfc;ker</keyname><forenames>Sebastian</forenames></author><author><keyname>Waibel</keyname><forenames>Alex</forenames></author></authors><title>Neural Language Codes for Multilingual Acoustic Models</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>5 pages, 3 figures, accepted at Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilingual Speech Recognition is one of the most costly AI problems,
because each language (7,000+) and even different accents require their own
acoustic models to obtain best recognition performance. Even though they all
use the same phoneme symbols, each language and accent imposes its own coloring
or &quot;twang&quot;. Many adaptive approaches have been proposed, but they require
further training, additional data and generally are inferior to monolingually
trained models. In this paper, we propose a different approach that uses a
large multilingual model that is \emph{modulated} by the codes generated by an
ancillary network that learns to code useful differences between the &quot;twangs&quot;
or human language.
  We use Meta-Pi networks to have one network (the language code net) gate the
activity of neurons in another (the acoustic model nets). Our results show that
during recognition multilingual Meta-Pi networks quickly adapt to the proper
language coloring without retraining or new data, and perform better than
monolingually trained networks. The model was evaluated by training acoustic
modeling nets and modulating language code nets jointly and optimize them for
best recognition performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01957</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01957</id><created>2018-07-05</created><updated>2018-08-15</updated><authors><author><keyname>Anis</keyname><forenames>Abdelrahman A. H.</forenames></author><author><keyname>Abdelhamid</keyname><forenames>Bassant</forenames></author><author><keyname>Elramly</keyname><forenames>Salwa</forenames></author></authors><title>Low Overhead Weighted-Graph-Coloring-Based Two-Layer Precoding for FDD
  Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 3 figures, accepted at the 9th International Conference on
  Computing, Communication and Networking Technologies, ICCCNT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A massive multiple-input multiple-output (MIMO) system, operating in
Frequency Division Duplexing (FDD) mode of operation, suffers from
prohibitively high overhead associated with downlink channel state information
(CSI) acquisition and downlink precoding, due to the lack of uplink/downlink
channel reciprocity. In this paper, a heuristic edge-weighted vertex-coloring
based pattern division (EWVC-PD) scheme is proposed to alleviate the overhead
of a two-layer precoding approach, in a practical scenario where the user
clusters undergo serious angular-spreading-range (ASR) overlapping.
Specifically, under a constraint of limited number of subchannels, an
undirected edge-weighted graph (EWG) is firstly constructed, to depict the
potential ASR overlapping relationship among clusters. Then, inspired by
classical graph coloring algorithms, we develop the EWVC-PD scheme which
mitigate the ASR by subchannel orthogonalization between clusters possessing
serious ASR overlapping, and multiplexing the ones having slight ASR
overlapping. Simulation results reveal that our scheme efficiently outperforms
the existing pattern division schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.01958</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.01958</id><created>2018-07-05</created><updated>2019-07-24</updated><authors><author><keyname>Ba</keyname><forenames>Demba</forenames></author></authors><title>Deeply-Sparse Signal rePresentations ($\text{D}\text{S}^2\text{P}$)</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent line of work has sought to build a parallel between deep neural
network architectures and sparse coding/recovery and estimation. Said line of
work suggests, as pointed out by Papyan et al., that a deep neural network
architecture with ReLu nonlinearities arises from a finite sequence of cascaded
sparse coding models, the outputs of which, except for the last element in the
cascade, are sparse and unobservable. That is, intermediate outputs deep in the
cascade are sparse, hence the title of this manuscript. We show here, using
techniques from the dictionary learning/sparse coding literature, that if the
measurement matrices in the cascaded sparse coding model (a) satisfy RIP and
(b) all have sparse columns except for the last, they can be recovered with
high probability in the absence of noise using an optimization algorithm that,
beginning with the last element of the cascade, alternates between estimating
the dictionary and the sparse code and then, at convergence, proceeds to the
preceding element in the cascade. The method of choice in deep learning to
solve this problem is by training an auto-encoder whose architecture we
specify. Our algorithm provides a sound alternative, derived from the
perspective of sparse coding, and with theoretical guarantees, as well as
sample complexity assessments. In particular, the learning complexity depends
on the maximum, across layers, of the product of the number of active neurons
and the embedding dimension. Our proof relies on a certain type of sparse
random matrix satisfying the RIP property. We use non-asymptotic random matrix
theory to prove this. We demonstrate the deep dictionary learning algorithm via
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02010</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02010</id><created>2018-07-05</created><authors><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Ge</keyname><forenames>Lulu</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhuang</keyname><forenames>Yuchen</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Shen</keyname><forenames>Ziyuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhong</keyname><forenames>Zhiwei</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory</affiliation></author></authors><title>DNA Computing for Combinational Logic</title><categories>cs.ET eess.SP q-bio.MN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the progressive scale-down of semiconductor's feature size, people are
looking forward to More Moore and More than Moore. In order to offer a possible
alternative implementation process, people are trying to figure out a feasible
transfer from silicon to molecular computing. Such transfer lies on bio-based
modules programming with computer-like logic, aiming at realizing the Turing
machine. To accomplish this, the DNA-based combinational logic is inevitably
the first step we have taken care of. This timely overview paper introduces
combinational logic synthesized in DNA computing from both analog and digital
perspectives separately. State-of-the-art research progress is summarized for
interested readers to quick understand DNA computing, initiate discussion on
existing techniques and inspire innovation solutions. We hope this paper can
pave the way for the future DNA computing synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02013</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02013</id><created>2018-07-05</created><authors><author><keyname>Lopez-Ramos</keyname><forenames>Luis M.</forenames></author><author><keyname>Romero</keyname><forenames>Daniel</forenames></author><author><keyname>Zaman</keyname><forenames>Bakht</forenames></author><author><keyname>Beferull-Lozano</keyname><forenames>Baltasar</forenames></author></authors><title>Dynamic network identification from non-stationary vector autoregressive
  time series</title><categories>eess.SP</categories><comments>5 pages, 2 figures, conference paper submitted to GlobalSIP2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning the dynamics of complex systems features a large number of
applications in data science. Graph-based modeling and inference underpins the
most prominent family of approaches to learn complex dynamics due to their
ability to capture the intrinsic sparsity of direct interactions in such
systems. They also provide the user with interpretable graphs that unveil
behavioral patterns and changes. To cope with the time-varying nature of
interactions, this paper develops an estimation criterion and a solver to learn
the parameters of a time-varying vector autoregressive model supported on a
network of time series. The notion of local breakpoint is proposed to
accommodate changes at individual edges. It contrasts with existing works,
which assume that changes at all nodes are aligned in time. Numerical
experiments validate the proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02040</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02040</id><created>2018-07-05</created><authors><author><keyname>Xu</keyname><forenames>Weihong</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhong</keyname><forenames>Zhiwei</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Be'ery</keyname><forenames>Yair</forenames><affiliation>School of Electrical Engineering, Tel-Aviv University, Israel</affiliation></author><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>Lab of Efficient Architectures for Digital-communication and Signal-processing</affiliation><affiliation>National Mobile Communications Research Laboratory</affiliation><affiliation>Quantum Information Center, Southeast University, China</affiliation></author></authors><title>Joint Neural Network Equalizer and Decoder</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep learning methods have shown significant improvements in
communication systems. In this paper, we study the equalization problem over
the nonlinear channel using neural networks. The joint equalizer and decoder
based on neural networks are proposed to realize blind equalization and
decoding process without the knowledge of channel state information (CSI).
Different from previous methods, we use two neural networks instead of one.
First, convolutional neural network (CNN) is used to adaptively recover the
transmitted signal from channel impairment and nonlinear distortions. Then the
deep neural network decoder (NND) decodes the detected signal from CNN
equalizer. Under various channel conditions, the experiment results demonstrate
that the proposed CNN equalizer achieves better performance than other
solutions based on machine learning methods. The proposed model reduces about
$2/3$ of the parameters compared to state-of-the-art counterparts. Besides, our
model can be easily applied to long sequence with $\mathcal{O}(n)$ complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02077</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02077</id><created>2018-07-05</created><updated>2019-05-29</updated><authors><author><keyname>Almasri</keyname><forenames>Sami Alkubti</forenames></author><author><keyname>P&#xf6;hlmann</keyname><forenames>Robert</forenames></author><author><keyname>Doose</keyname><forenames>Niklas</forenames></author><author><keyname>Hoeher</keyname><forenames>Peter A.</forenames></author><author><keyname>Dammann</keyname><forenames>Armin</forenames></author></authors><title>Modelling Aspects of Planar Multi-Mode Antennas for Direction-of-Arrival
  Estimation</title><categories>eess.SP</categories><doi>10.1109/JSEN.2019.2902674</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-mode antennas are an alternative to classical antenna arrays, and hence
a promising emerging sensor technology for a vast variety of applications in
the areas of array signal processing and digital communications. An unsolved
problem is to describe the radiation pattern of multi-mode antennas in closed
analytic form based on calibration measurements or on electromagnetic field
(EMF) simulation data. As a solution, we investigate two modeling methods: One
is based on the array interpolation technique (AIT), the other one on wavefield
modeling (WM). Both methods are able to accurately interpolate quantized EMF
data of a given multi-mode antenna, in our case a planar four-port antenna
developed for the 6-8.5 GHz range. Since the modeling methods inherently depend
on parameter sets, we investigate the influence of the parameter choice on the
accuracy of both models. Furthermore, we evaluate the impact of modeling errors
for coherent maximum-likelihood direction-of-arrival (DoA) estimation given
different model parameters. Numerical results are presented for a single
polarization component. Simulations reveal that the estimation bias introduced
by model errors is subject to the chosen model parameters. Finally, we provide
optimized sets of AIT and WM parameters for the multi-mode antenna under
investigation. With these parameter sets, EMF data samples can be reproduced in
interpolated form with high angular resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02175</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02175</id><created>2018-07-05</created><authors><author><keyname>Storrs</keyname><forenames>Katherine</forenames></author><author><keyname>Van Leuven</keyname><forenames>Sebastiaan</forenames></author><author><keyname>Kojder</keyname><forenames>Steve</forenames></author><author><keyname>Theis</keyname><forenames>Lucas</forenames></author><author><keyname>Husz&#xe1;r</keyname><forenames>Ferenc</forenames></author></authors><title>Adaptive Paired-Comparison Method for Subjective Video Quality
  Assessment on Mobile Devices</title><categories>stat.AP eess.IV</categories><journal-ref>Picture Coding Symposium, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To effectively evaluate subjective visual quality in weakly-controlled
environments, we propose an Adaptive Paired Comparison method based on particle
filtering. As our approach requires each sample to be rated only once, the test
time compared to regular paired comparison can be reduced. The method works
with non-experts and improves reliability compared to MOS and DS-MOS methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02233</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02233</id><created>2018-07-05</created><authors><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Huang</keyname><forenames>Xiang</forenames></author><author><keyname>Ferrier</keyname><forenames>Nicola</forenames></author><author><keyname>Gulsoy</keyname><forenames>Emine B.</forenames></author><author><keyname>Phatak</keyname><forenames>Charudatta</forenames></author></authors><title>U-SLADS: Unsupervised Learning Approach for Dynamic Dendrite Sampling</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Novel data acquisition schemes have been an emerging need for scanning
microscopy based imaging techniques to reduce the time in data acquisition and
to minimize probing radiation in sample exposure. Varies sparse sampling
schemes have been studied and are ideally suited for such applications where
the images can be reconstructed from a sparse set of measurements. Dynamic
sparse sampling methods, particularly supervised learning based iterative
sampling algorithms, have shown promising results for sampling pixel locations
on the edges or boundaries during imaging. However, dynamic sampling for
imaging skeleton-like objects such as metal dendrites remains difficult. Here,
we address a new unsupervised learning approach using Hierarchical Gaussian
Mixture Mod- els (HGMM) to dynamically sample metal dendrites. This technique
is very useful if the users are interested in fast imaging the primary and
secondary arms of metal dendrites in solidification process in materials
science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02254</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02254</id><created>2018-07-06</created><authors><author><keyname>Wu</keyname><forenames>Cheng-Wei</forenames></author><author><keyname>Liu</keyname><forenames>Jen-Yu</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author><author><keyname>Jang</keyname><forenames>Jyh-Shing R.</forenames></author></authors><title>Singing Style Transfer Using Cycle-Consistent Boundary Equilibrium
  Generative Adversarial Networks</title><categories>cs.SD cs.AI eess.AS</categories><comments>3 pages, 3 figures, demo website:
  http://mirlab.org/users/haley.wu/cybegan</comments><journal-ref>ICML Workshop 2018 (Joint Music Workshop)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can we make a famous rap singer like Eminem sing whatever our favorite song?
Singing style transfer attempts to make this possible, by replacing the vocal
of a song from the source singer to the target singer. This paper presents a
method that learns from unpaired data for singing style transfer using
generative adversarial networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02267</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02267</id><created>2018-07-06</created><authors><author><keyname>Li</keyname><forenames>Minzhe</forenames></author><author><keyname>Jing</keyname><forenames>Zhongliang</forenames></author></authors><title>Multi-target Joint Detection, Tracking and Classification Based on
  Generalized Bayesian Risk using Radar and ESM sensors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel approach is proposed for multi-target joint detection,
tracking and classification based on the labeled random finite set and
generalized Bayesian risk using Radar and ESM sensors. A new Bayesian risk is
defined for the labeled random finite set variables involving the costs of
multi-target cardinality estimation (detection), state estimation (tracking)
and classification. The inter-dependence of detection, tracking and
classification is then utilized with the minimum Bayesian risk. Furthermore,
the conditional labeled multi-Bernoulli filter is developed to calculate the
estimates and costs for different hypotheses and decisions of target classes
using attribute and dynamical measurements. Moreover, the performance is
analyzed. The effectiveness and superiority of the proposed approach are
verified using numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02370</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02370</id><created>2018-07-06</created><authors><author><keyname>Ye</keyname><forenames>Dong Hye</forenames></author><author><keyname>Buzzard</keyname><forenames>Gregery T.</forenames></author><author><keyname>Ruby</keyname><forenames>Max</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author></authors><title>Deep Back Projection for Sparse-View CT Reconstruction</title><categories>eess.IV cs.CV</categories><comments>GlobalSIP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filtered back projection (FBP) is a classical method for image reconstruction
from sinogram CT data. FBP is computationally efficient but produces lower
quality reconstructions than more sophisticated iterative methods, particularly
when the number of views is lower than the number required by the Nyquist rate.
In this paper, we use a deep convolutional neural network (CNN) to produce
high-quality reconstructions directly from sinogram data. A primary novelty of
our approach is that we first back project each view separately to form a stack
of back projections and then feed this stack as input into the convolutional
neural network. These single-view back projections convert the encoding of
sinogram data into the appropriate spatial location, which can then be
leveraged by the spatial invariance of the CNN to learn the reconstruction
effectively. We demonstrate the benefit of our CNN based back projection on
simulated sparse-view CT data over classical FBP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02424</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02424</id><created>2018-07-06</created><authors><author><keyname>Tutika</keyname><forenames>Chetan Sai</forenames></author><author><keyname>Vallapaneni</keyname><forenames>Charan</forenames></author><author><keyname>B</keyname><forenames>Karthikeyan</forenames></author></authors><title>Image Handling and Processing for Efficient Parking Space Detection and
  Navigation Aid</title><categories>eess.IV</categories><comments>International Conference on Recent Trends in Computer Science and
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to develop a robust and flexible algorithm for vacant parking
space detections using the image processing capabilities of OpenCV. It removes
the need for independent sensors to detect a car and instead, uses real-time
images derived from various sources and servers to consider a group of slots
together. This greatly decreases the expenses required to design an efficient
parking system and increases the flexibility of the operation. This method
includes the use of a portable processing system with recognition algorithm and
has the option of extracting and importing images to the specified servers. The
results can be viewed on a custom website with the option to reserve the
particular empty slots and GPS navigations to the selected slots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02465</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02465</id><created>2018-07-06</created><authors><author><keyname>Lugosch</keyname><forenames>Loren</forenames></author><author><keyname>Tomar</keyname><forenames>Vikrant Singh</forenames></author></authors><title>Tone Recognition Using Lifters and CTC</title><categories>eess.AS cs.SD</categories><comments>Accepted to Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new method for recognizing tones in continuous
speech for tonal languages. The method works by converting the speech signal to
a cepstrogram, extracting a sequence of cepstral features using a convolutional
neural network, and predicting the underlying sequence of tones using a
connectionist temporal classification (CTC) network. The performance of the
proposed method is evaluated on a freely available Mandarin Chinese speech
corpus, AISHELL-1, and is shown to outperform the existing techniques in the
literature in terms of tone error rate (TER).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02485</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02485</id><created>2018-07-06</created><authors><author><keyname>Sun</keyname><forenames>Jingcong</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author></authors><title>Deployment Strategies of Multiple Aerial BSs for User Coverage and Power
  Efficiency Maximization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicle (UAV) based aerial base stations (BSs) can provide
rapid communication services to ground users and are thus promising for future
communication systems. In this paper, we consider a scenario where no
functional terrestrial BSs are available and the aim is deploying multiple
aerial BSs to cover a maximum number of users within a certain target area. To
this end, we first propose a naive successive deployment method, which converts
the non-convex constraints in the involved optimization into a combination of
linear constraints through geometrical relaxation. Then we investigate a
deployment method based on K-means clustering. The method divides the target
area into K convex subareas, where within each subarea, a mixed integer
non-linear problem (MINLP) is solved. An iterative power efficient technique is
further proposed to improve coverage probability with reduced power. Finally,
we propose a robust technique for compensating the loss of coverage probability
in the existence of inaccurate user location information (ULI). Our simulation
results show that, the proposed techniques achieve an up to 30% higher coverage
probability when users are not distributed uniformly. In addition, the proposed
simultaneous deployment techniques, especially the one using iterative
algorithm improve power-efficiency by up to 15% compared to the benchmark
circle packing theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02545</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02545</id><created>2018-07-06</created><authors><author><keyname>Shen</keyname><forenames>Yiru</forenames></author><author><keyname>Muth</keyname><forenames>Eric</forenames></author><author><keyname>Hoover</keyname><forenames>Adam</forenames></author></authors><title>A Study of the Lexicography of Hand Gestures During Eating</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the lexicographical challenge of defining actions a
person takes while eating. The goal is to establish objective and repeatable
gesture definitions based on discernible intent. Such a standard would support
the sharing of data and results between researchers working on the problem of
automatic monitoring of dietary intake. We define five gestures: taking a bite
of food (bite), sipping a drink of liquid (drink), manipulating food for
preparation of intake (utensiling), not moving (rest) and a non-eating category
(other). To test this lexicography, we used our definitions to label a large
data set and tested for inter-rater reliability. The data set consists of a
total of 276 participants eating a single meal while wearing a watch-like
device to track wrist motion. Video was simultaneously recorded and
subsequently reviewed to label gestures. A total of 18 raters manually labeled
51,614 gestures. Every meal was labeled by at least 1 rater, with 95 meals
labeled by 2 raters. Inter-rater reliability was calculated in terms of
agreement, boundary ambiguity, and mistakes. Results were 92.5% agreement (75%
exact agreement, 17.5% boundary ambiguity). Mistakes of intake gestures (0.6%
bite and 1.9% drink) occur much less frequently than non-intake gestures (16.5%
utensiling and 8.7% rest). Similar rates were found across all 18 raters.
Finally, a comparison of gesture segments against single index labels of bites
and drinks from a previous effort showed an agreement of 95.8% with 0.6%
ambiguity and 3.6% mistakes. Overall, these findings take a step towards
developing a consensus lexicography of eating gestures for the research
community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02548</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02548</id><created>2018-07-06</created><authors><author><keyname>Ozfatura</keyname><forenames>Emre</forenames></author><author><keyname>Rarris</keyname><forenames>Thomas</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>Delay-Aware Coded Caching for Mobile Users</title><categories>cs.IT cs.MM eess.IV math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the trade-off between the cache capacity and the user
delay for a cooperative Small Base Station (SBS) coded caching system with
mobile users. First, a delay-aware coded caching policy, which takes into
account the popularity of the files and the maximum re-buffering delay to
minimize the average rebuffering delay of a mobile user under a given cache
capacity constraint is introduced. Subsequently, we address a scenario where
some files are served by the macro-cell base station (MBS) when the cache
capacity of the SBSs is not sufficient to store all the files in the library.
For this scenario, we develop a coded caching policy that minimizes the average
amount of data served by the MBS under an average re-buffering delay
constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02647</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02647</id><created>2018-07-07</created><authors><author><keyname>Alkishriwo</keyname><forenames>Osama A. S.</forenames></author></authors><title>An Image Encryption Algorithm Based on Chaotic Maps and Discrete Linear
  Chirp Transform</title><categories>eess.IV cs.CR</categories><journal-ref>Almadar Journal for Communications, Information Technology, and
  Applications, Vol. 05, No. 01, June 2018</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this paper, a novel image encryption algorithm, which involves a chaotic
block image scrambling followed by a two-dimensional (2-D) discrete linear
chirp transform, is proposed. The definition of the 2-D discrete linear chirp
transform is introduced and then it is used to construct the basis of the novel
encryption algorithm. Finally, security analysis are performed to show the
quality of the encryption process using different metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02651</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02651</id><created>2018-07-07</created><authors><author><keyname>Bahlke</keyname><forenames>Florian</forenames></author><author><keyname>Pesavento</keyname><forenames>Marius</forenames></author></authors><title>Energy Consumption Optimization in Mobile Communication Networks</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses the challenge of minimizing the energy consumption of a
wireless communication network by joint optimization of the base station
transmit power and the cell activity. A mixed-integer nonlinear optimization
problem is formulated, for which a computationally tractable linear inner
approximation algorithm is provided. The proposed method offers great
flexibility in optimizing the network operation by considering multiple system
parameters jointly, which mitigates a major drawback of existing
state-of-the-art schemes that are mostly based on heuristics. Simulation
results show that the proposed method exhibits high performance in decreasing
the energy consumption, and provides implicit load balancing in difficult high
demand scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02684</identifier>
 <datestamp>2019-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02684</id><created>2018-07-07</created><updated>2018-11-15</updated><authors><author><keyname>Ibtehaz</keyname><forenames>Nabil</forenames></author><author><keyname>Rahman</keyname><forenames>M. Saifur</forenames></author><author><keyname>Rahman</keyname><forenames>M. Sohel</forenames></author></authors><title>VFPred: A Fusion of Signal Processing and Machine Learning techniques in
  Detecting Ventricular Fibrillation from ECG Signals</title><categories>cs.LG eess.SP stat.ML</categories><doi>10.1016/j.bspc.2018.12.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ventricular Fibrillation (VF), one of the most dangerous arrhythmias, is
responsible for sudden cardiac arrests. Thus, various algorithms have been
developed to predict VF from Electrocardiogram (ECG), which is a binary
classification problem. In the literature, we find a number of algorithms based
on signal processing, where, after some robust mathematical operations the
decision is given based on a predefined threshold over a single value. On the
other hand, some machine learning based algorithms are also reported in the
literature; however, these algorithms merely combine some parameters and make a
prediction using those as features. Both the approaches have their perks and
pitfalls; thus our motivation was to coalesce them to get the best out of the
both worlds. Hence we have developed, VFPred that, in addition to employing a
signal processing pipeline, namely, Empirical Mode Decomposition and Discrete
Time Fourier Transform for useful feature extraction, uses a Support Vector
Machine for efficient classification. VFPred turns out to be a robust algorithm
as it is able to successfully segregate the two classes with equal confidence
(Sensitivity = 99.99%, Specificity = 98.40%) even from a short signal of 5
seconds long, whereas existing works though requires longer signals, flourishes
in one but fails in the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02710</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02710</id><created>2018-07-07</created><updated>2018-07-16</updated><authors><author><keyname>Muth</keyname><forenames>Joachim</forenames></author><author><keyname>Uhlich</keyname><forenames>Stefan</forenames></author><author><keyname>Perraudin</keyname><forenames>Nathanael</forenames></author><author><keyname>Kemp</keyname><forenames>Thomas</forenames></author><author><keyname>Cardinaux</keyname><forenames>Fabien</forenames></author><author><keyname>Mitsufuji</keyname><forenames>Yuki</forenames></author></authors><title>Improving DNN-based Music Source Separation using Phase Features</title><categories>cs.SD cs.LG eess.AS</categories><comments>7 pages, 9 figures, Joint Workshop on Machine Learning for Music at
  ICML, IJCAI/ECAI and AAMAS, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music source separation with deep neural networks typically relies only on
amplitude features. In this paper we show that additional phase features can
improve the separation performance. Using the theoretical relationship between
STFT phase and amplitude, we conjecture that derivatives of the phase are a
good feature representation opposed to the raw phase. We verify this conjecture
experimentally and propose a new DNN architecture which combines amplitude and
phase. This joint approach achieves a better signal-to distortion ratio on the
DSD100 dataset for all instruments compared to a network that uses only
amplitude features. Especially, the bass instrument benefits from the phase
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02723</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02723</id><created>2018-07-07</created><authors><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author><author><keyname>Beltagy</keyname><forenames>Iz</forenames></author></authors><title>Machine Learning for Reliable mmWave Systems: Blockage Prediction and
  Proactive Handoff</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted to IEEE GlobalSIP 2018 (Invited paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sensitivity of millimeter wave (mmWave) signals to blockages is a
fundamental challenge for mobile mmWave communication systems. The sudden
blockage of the line-of-sight (LOS) link between the base station and the
mobile user normally leads to disconnecting the communication session, which
highly impacts the system reliability. Further, reconnecting the user to
another LOS base station incurs high beam training overhead and critical
latency problems. In this paper, we leverage machine learning tools and propose
a novel solution for these reliability and latency challenges in mmWave MIMO
systems. In the developed solution, the base stations learn how to predict that
a certain link will experience blockage in the next few time frames using their
past observations of adopted beamforming vectors. This allows the serving base
station to proactively hand-over the user to another base station with a highly
probable LOS link. Simulation results show that the developed deep learning
based strategy successfully predicts blockage/hand-off in close to 95% of the
times. This reduces the probability of communication session disconnection,
which ensures high reliability and low latency in mobile mmWave systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02757</identifier>
 <datestamp>2019-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02757</id><created>2018-07-08</created><authors><author><keyname>Feng</keyname><forenames>Shijie</forenames></author><author><keyname>Chen</keyname><forenames>Qian</forenames></author><author><keyname>Gu</keyname><forenames>Guohua</forenames></author><author><keyname>Tao</keyname><forenames>Tianyang</forenames></author><author><keyname>Zhang</keyname><forenames>Liang</forenames></author><author><keyname>Hu</keyname><forenames>Yan</forenames></author><author><keyname>Yin</keyname><forenames>Wei</forenames></author><author><keyname>Zuo</keyname><forenames>Chao</forenames></author></authors><title>Fringe pattern analysis using deep learning</title><categories>eess.IV</categories><journal-ref>Advanced Photonics, 1(2), 025001 (2019)</journal-ref><doi>10.1117/1.AP.1.2.025001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many optical metrology techniques, fringe pattern analysis is the central
algorithm for recovering the underlying phase distribution from the recorded
fringe patterns. Despite extensive research efforts for decades, how to extract
the desired phase information, with the highest possible accuracy, from the
minimum number of fringe patterns remains one of the most challenging open
problems. Inspired by recent successes of deep learning techniques for computer
vision and other applications, here, we demonstrate for the first time, to our
knowledge, that the deep neural networks can be trained to perform fringe
analysis, which substantially enhances the accuracy of phase demodulation from
a single fringe pattern. The effectiveness of the proposed method is
experimentally verified using carrier fringe patterns under the scenario of
fringe projection profilometry. Experimental results demonstrate its superior
performance in terms of high accuracy and edge-preserving over two
representative single-frame techniques: Fourier transform profilometry and
Windowed Fourier profilometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02776</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02776</id><created>2018-07-08</created><authors><author><keyname>Pellegrini</keyname><forenames>Thomas</forenames></author></authors><title>Densely Connected CNNs for Bird Audio Detection</title><categories>cs.SD eess.AS</categories><comments>Challenge solution source code available at
  https://github.com/topel/bird_audio_detection_challenge, Proc. EUSIPCO 2017</comments><doi>10.23919/EUSIPCO.2017.8081506</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Detecting bird sounds in audio recordings automatically, if accurate enough,
is expected to be of great help to the research community working in bio- and
ecoacoustics, interested in monitoring biodiversity based on audio field
recordings. To estimate how accurate the state-of-the-art machine learning
approaches are, the Bird Audio Detection challenge involving large audio
datasets was recently organized. In this paper, experiments using several types
of convolutional neural networks (i.e. standard CNNs, residual nets and densely
connected nets) are reported in the framework of this challenge. DenseNets were
the preferred solution since they were the best performing and most compact
models, leading to a 88.22% area under the receiver operator curve score on the
test set of the challenge. Performance gains were obtained thank to data
augmentation through time and frequency shifting, model parameter averaging
during training and ensemble methods using the geometric mean. On the contrary,
the attempts to enlarge the training dataset with samples of the test set with
automatic predictions used as pseudo-groundtruth labels consistently degraded
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.02896</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.02896</id><created>2018-07-08</created><authors><author><keyname>Giasemidis</keyname><forenames>Georgios</forenames></author><author><keyname>Greetham</keyname><forenames>Danica Vukadinovic</forenames></author></authors><title>Optimising Parameters in Recurrence Quantification Analysis of Smart
  Energy Systems</title><categories>eess.SP</categories><comments>14 pages, 11 figures</comments><journal-ref>2018 9th International Conference on Information, Intelligence,
  Systems and Applications (IISA) IEEE</journal-ref><doi>10.1109/IISA.2018.8633648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrence Quantification Analysis (RQA) can help to detect significant
events and phase transitions of a dynamical system, but choosing a suitable set
of parameters is crucial for the success. From recurrence plots different RQA
variables can be obtained and analysed. Currently, most of the methods for RQA
radius optimisation are focusing on a single RQA variable. In this work we are
proposing two new methods for radius optimisation that look for an optimum in
the higher dimensional space of the RQA variables, therefore synchronously
optimising across several variables. We illustrate our approach using two case
studies: a well known Lorenz dynamical system, and a time-series obtained from
monitoring energy consumption of a small enterprise. Our case studies show that
both methods result in plausible values and can be used to analyse energy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03046</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03046</id><created>2018-07-09</created><authors><author><keyname>G&#xf3;mez</keyname><forenames>Emilia</forenames></author><author><keyname>Blaauw</keyname><forenames>Merlijn</forenames></author><author><keyname>Bonada</keyname><forenames>Jordi</forenames></author><author><keyname>Chandna</keyname><forenames>Pritish</forenames></author><author><keyname>Cuesta</keyname><forenames>Helena</forenames></author></authors><title>Deep Learning for Singing Processing: Achievements, Challenges and
  Impact on Singers and Listeners</title><categories>cs.SD cs.IR cs.LG cs.MM eess.AS stat.ML</categories><comments>Keynote speech, 2018 Joint Workshop on Machine Learning for Music.
  The Federated Artificial Intelligence Meeting (FAIM), a joint workshop
  program of ICML, IJCAI/ECAI, and AAMAS</comments><msc-class>97M80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper summarizes some recent advances on a set of tasks related to the
processing of singing using state-of-the-art deep learning techniques. We
discuss their achievements in terms of accuracy and sound quality, and the
current challenges, such as availability of data and computing resources. We
also discuss the impact that these advances do and will have on listeners and
singers when they are integrated in commercial applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03094</identifier>
 <datestamp>2019-04-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03094</id><created>2018-07-09</created><updated>2019-04-19</updated><authors><author><keyname>Hu</keyname><forenames>Di</forenames></author><author><keyname>Nie</keyname><forenames>Feiping</forenames></author><author><keyname>Li</keyname><forenames>Xuelong</forenames></author></authors><title>Deep Multimodal Clustering for Unsupervised Audiovisual Learning</title><categories>cs.CV cs.MM cs.SD eess.AS</categories><comments>Accepted by CVPR2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The seen birds twitter, the running cars accompany with noise, etc. These
naturally audiovisual correspondences provide the possibilities to explore and
understand the outside world. However, the mixed multiple objects and sounds
make it intractable to perform efficient matching in the unconstrained
environment. To settle this problem, we propose to adequately excavate audio
and visual components and perform elaborate correspondence learning among them.
Concretely, a novel unsupervised audiovisual learning model is proposed, named
as \Deep Multimodal Clustering (DMC), that synchronously performs sets of
clustering with multimodal vectors of convolutional maps in different shared
spaces for capturing multiple audiovisual correspondences. And such integrated
multimodal clustering network can be effectively trained with max-margin loss
in the end-to-end fashion. Amounts of experiments in feature evaluation and
audiovisual tasks are performed. The results demonstrate that DMC can learn
effective unimodal representation, with which the classifier can even
outperform human performance. Further, DMC shows noticeable performance in
sound localization, multisource detection, and audiovisual understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03131</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03131</id><created>2018-06-28</created><authors><author><keyname>Chronopoulos</keyname><forenames>Spyridon K.</forenames></author><author><keyname>Christofilakis</keyname><forenames>Vasilis</forenames></author><author><keyname>Tatsis</keyname><forenames>Giorgos</forenames></author><author><keyname>Kostarakis</keyname><forenames>Panos</forenames></author></authors><title>Performance of Turbo Coded OFDM Under the Presence of Various Noise
  Types</title><categories>eess.SP cs.IT math.IT</categories><comments>21 pages, 11 figures</comments><journal-ref>Chronopoulos, S.K., Christofilakis, V., Tatsis, G. et al. Wireless
  Pers Commun (2016) 87: 1319. https://doi.org/10.1007/s11277-015-3055-1</journal-ref><doi>10.1007/s11277-015-3055-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A telecommunication system uses carriers in order to transmit information
through a cable or wirelessly. If each time only one carrier is transmitted,
then the system s signal will not be immune to frequency selective fading. If
frequency selective fading includes the working frequency of the system, then
the wireless link will not be established. Orthogonal frequency division
multiplexing OFDM is the primary solution for coping with inter signal
interference and frequency selective fading. Many carriers can be produced by
splitting a fast information stream to slower data series. Different orthogonal
frequencies carry slower data series. System s performance can be further
enhanced with the utilization of turbo codes. Turbo codes make the system more
immune to noise effects with excellent BER results. This paper presents the
thorough analysis of a turbo coded OFDM scheme using a PCCC technique in the
presence of a channel which includes AWGN, phase noise, Rayleigh fading, Rician
fading and Doppler shift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03145</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03145</id><created>2018-07-05</created><authors><author><keyname>Gupta</keyname><forenames>Prashant</forenames></author></authors><title>NIRS Based Bladder Volume Sensing for Patients Suffering with Neurogenic
  Bladder Dysfunction</title><categories>eess.SP physics.med-ph</categories><comments>Master's Thesis, University of California, Davis; 58 pages, 24
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neurogenic Bladder Dysfunction has detrimental effects on day-to-day life of
millions of people. Some of the most common symptoms faced by these patients
include urinary incontinence, urgency and retention. Since elevated bladder
pressure due to prolonged urine storage inside bladder may have adverse impacts
on patient's renal health, urologists recommend clean-intermittent
catheterization (CIC) every 2 to 4 hours throughout the day to relieve bladder
pressure. However, since urine production by kidneys is an intermittent process
and most of these patients have limited mobility, such frequent trips to
washroom can prove to be challenging. Sometimes, bladder fills to capacity
before the recommended CIC time is reached causing embarrassing situation due
to leakage. Hence, time-based CIC strategy is difficult to implement and has
high chances of failure. As such, continence is the primary concern for most of
these patients but sadly there are no practical solutions available in the
market that address this concern. A real-time notification system that could
give feedback to patients on when &quot;bladder is almost-full&quot; could help these
patients to better plan their bathroom trips. This work explores the
feasibility of using a near infrared-light based wearable, non-invasive
spectroscopy technique that can sense amount of urine present inside the
bladder and give details on developing a bladder state estimation device.
  We present preliminary results by testing our device on optical phantoms and
performing ex vivo measurements on porcine bladder and intestines. We later
explored the possibility of using the device on human subjects, after study was
approved by the UC Davis Institution Review Board (IRB).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03147</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03147</id><created>2018-07-05</created><updated>2019-04-29</updated><authors><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author><author><keyname>Ditthapron</keyname><forenames>Apiwat</forenames></author><author><keyname>Matchaparn</keyname><forenames>Karis</forenames></author><author><keyname>Tongbuasirilai</keyname><forenames>Tanaboon</forenames></author><author><keyname>Banluesombatkul</keyname><forenames>Nannapas</forenames></author><author><keyname>Chuangsuwanich</keyname><forenames>Ekapol</forenames></author></authors><title>Affective EEG-Based Person Identification Using the Deep Learning
  Approach</title><categories>eess.SP cs.CV</categories><comments>10 pages</comments><journal-ref>IEEE Transactions on Cognitive and Developmental System (2019)</journal-ref><doi>10.1109/TCDS.2019.2924648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG) is another mode for performing Person
Identification (PI). Due to the nature of the EEG signals, EEG-based PI is
typically done while the person is performing some kind of mental task, such as
motor control. However, few works have considered EEG-based PI while the person
is in different mental states (affective EEG). The aim of this paper is to
improve the performance of affective EEG-based PI using a deep learning
approach. \textcolor{red}{We proposed a cascade of deep learning using a
combination of Convolutional Neural Networks (CNNs) and Recurrent Neural
Networks (RNNs)}. CNNs are used to handle the spatial information from the EEG
while RNNs extract the temporal information. \textcolor{red}{We evaluated two
types of RNNs, namely, Long Short-Term Memory (CNN-LSTM) and Gated Recurrent
Unit (CNN-GRU). } The proposed method is evaluated on the state-of-the-art
affective dataset DEAP. The results indicate that CNN-GRU and CNN-LSTM can
perform PI from different affective states and reach up to 99.90--100\% mean
Correct Recognition Rate (CRR), significantly outperforming a support vector
machine (SVM) baseline system that uses power spectral density (PSD) features.
Notably, the 100\% mean \emph{CRR} comes from only 40 subjects in DEAP dataset.
To reduce the number of EEG electrodes from thirty-two to five for more
practical applications, the frontal region gives the best results reaching up
to 99.17\% CRR (from CNN-GRU). Amongst the two deep learning models, we find
CNN-GRU to slightly outperform CNN-LSTM, while having faster training time.
\textcolor{red}{Furthermore, CNN-GRU overcomes the influence of affective
states in EEG-Based PI reported in the previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03162</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03162</id><created>2018-07-05</created><authors><author><keyname>Mohammadkarimi</keyname><forenames>Mostafa</forenames></author><author><keyname>Mehrabi</keyname><forenames>Mehrtash</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author></authors><title>Deep Learning Based Sphere Decoding</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a deep learning (DL)-based sphere decoding algorithm is
proposed, where the radius of the decoding hypersphere is learnt by a deep
neural network (DNN). The performance achieved by the proposed algorithm is
very close to the optimal maximum likelihood decoding (MLD) over a wide range
of signal-to-noise ratios (SNRs), while the computational complexity, compared
to existing sphere decoding variants, is significantly reduced. This
improvement is attributed to DNN's ability of intelligently learning the radius
of the hypersphere used in decoding. The expected complexity of the proposed
DL-based algorithm is analytically derived and compared with existing ones. It
is shown that the number of lattice points inside the decoding hypersphere
drastically reduces in the DL- based algorithm in both the average and
worst-case senses. The effectiveness of the proposed algorithm is shown through
simulation for high-dimensional multiple-input multiple-output (MIMO) systems,
using high-order modulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03182</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03182</id><created>2018-07-09</created><authors><author><keyname>Musa</keyname><forenames>Osman</forenames></author><author><keyname>Jung</keyname><forenames>Peter</forenames></author><author><keyname>Goertz</keyname><forenames>Norbert</forenames></author></authors><title>Generalized Approximate Message Passing for Unlimited Sampling of Sparse
  Signals</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the generalized approximate message passing (GAMP)
algorithm for recovering a sparse signal from modulo samples of randomized
projections of the unknown signal. The modulo samples are obtained by a
self-reset (SR) analog to digital converter (ADC). Additionally, in contrast to
previous work on SR ADC, we consider a scenario where the compressed sensing
(CS) measurements (i.e., randomized projections) are sent through a
communication channel, namely an additive white Gaussian noise (AWGN) channel
before being quantized by a SR ADC. To show the effectiveness of the proposed
approach, we conduct Monte-Carlo (MC) simulations for both noiseless and noisy
case. The results show strong ability of the proposed algorithm to fight the
nonlinearity of the SR ADC, as well as the possible additional distortion
introduced by the AWGN channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03191</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03191</id><created>2018-07-09</created><authors><author><keyname>Hauptmann</keyname><forenames>Andreas</forenames></author><author><keyname>Cox</keyname><forenames>Ben</forenames></author><author><keyname>Lucka</keyname><forenames>Felix</forenames></author><author><keyname>Huynh</keyname><forenames>Nam</forenames></author><author><keyname>Betcke</keyname><forenames>Marta</forenames></author><author><keyname>Beard</keyname><forenames>Paul</forenames></author><author><keyname>Arridge</keyname><forenames>Simon</forenames></author></authors><title>Approximate k-space models and Deep Learning for fast photoacoustic
  reconstruction</title><categories>cs.CV cs.LG cs.SD eess.AS math.OC</categories><msc-class>49N45, 65T50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework for accelerated iterative reconstructions using a fast
and approximate forward model that is based on k-space methods for
photoacoustic tomography. The approximate model introduces aliasing artefacts
in the gradient information for the iterative reconstruction, but these
artefacts are highly structured and we can train a CNN that can use the
approximate information to perform an iterative reconstruction. We show
feasibility of the method for human in-vivo measurements in a limited-view
geometry. The proposed method is able to produce superior results to total
variation reconstructions with a speed-up of 32 times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03216</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03216</id><created>2018-06-28</created><authors><author><keyname>Hebert</keyname><forenames>Joshua</forenames></author><author><keyname>Lewis</keyname><forenames>Brittany</forenames></author><author><keyname>Cai</keyname><forenames>Hang</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Krishna K.</forenames></author><author><keyname>Provost</keyname><forenames>Matthew</forenames></author><author><keyname>Charlebois</keyname><forenames>Kelly</forenames></author></authors><title>Ballistocardiogram-based Authentication using Convolutional Neural
  Networks</title><categories>eess.SP cs.CV q-bio.QM</categories><comments>8 pages, 6 figures</comments><msc-class>68U35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this work is to demonstrate the use of the ballistocardiogram
(BCG) signal, derived using head-mounted wearable devices, as a viable
biometric for authentication. The BCG signal is the measure of an person's body
acceleration as a result of the heart's ejection of blood. It is a
characterization of the cardiac cycle and can be derived non-invasively from
the measurement of subtle movements of a person's extremities. In this paper,
we use several versions of the BCG signal, derived from accelerometer and
gyroscope sensors on a Smart Eyewear (SEW) device, for authentication. The
derived BCG signals are used to train a convolutional neural network (CNN) as
an authentication model, which is personalized for each subject. We evaluate
our authentication models using data from 12 subjects and show that our
approach has an equal error rate (EER) of 3.5% immediately after training and
13\% after about 2 months, in the worst case. We also explore the use of our
authentication approach for people with motor disabilities. Our analysis using
a separate dataset of 6 subjects with non-spastic cerebral palsy shows an EER
of 11.2% immediately after training and 21.6% after about 2 months, in the
worst-case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03232</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03232</id><created>2018-06-29</created><authors><author><keyname>Chandra</keyname><forenames>B S</forenames></author><author><keyname>Sastry</keyname><forenames>C S</forenames></author><author><keyname>Jana</keyname><forenames>S</forenames></author></authors><title>Robust Heartbeat Detection from Multimodal Data via CNN-based
  Generalizable Information Fusion</title><categories>eess.SP cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Heartbeat detection remains central to cardiac disease diagnosis
and management, and is traditionally performed based on electrocardiogram
(ECG). To improve robustness and accuracy of detection, especially, in certain
critical-care scenarios, the use of additional physiological signals such as
arterial blood pressure (BP) has recently been suggested. There, estimation of
heartbeat location requires information fusion from multiple signals. However,
reported efforts in this direction often obtain multimodal estimates somewhat
indirectly, by voting among separately obtained signal-specific intermediate
estimates. In contrast, we propose to directly fuse information from multiple
signals without requiring intermediate estimates, and thence estimate heartbeat
location in a robust manner. Method: We propose as a heartbeat detector, a
convolutional neural network (CNN) that learns fused features from multiple
physiological signals. This method eliminates the need for hand-picked
signal-specific features and ad hoc fusion schemes. Further, being data-driven,
the same algorithm learns suitable features from arbitrary set of signals.
Results: Using ECG and BP signals of PhysioNet 2014 Challenge database, we
obtained a score of 94%. Further, using two ECG channels of MIT-BIH arrhythmia
database, we scored 99.92\%. Both those scores compare favourably with
previously reported database-specific results. Also, our detector achieved high
accuracy in a variety of clinical conditions. Conclusion: The proposed
CNN-based information fusion (CIF) algorithm is generalizable, robust and
efficient in detecting heartbeat location from multiple signals. Significance:
In medical signal monitoring systems, our technique would accurately estimate
heartbeat locations even when only a subset of channels are reliable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03234</identifier>
 <datestamp>2019-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03234</id><created>2018-07-09</created><updated>2019-04-18</updated><authors><author><keyname>Reinhard</keyname><forenames>Dominik</forenames></author><author><keyname>Fauss</keyname><forenames>Michael</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author></authors><title>Bayesian Sequential Joint Detection and Estimation</title><categories>eess.SP cs.IT math.IT math.ST stat.TH</categories><comments>35 pages, 2 figures, accepted for publication in Sequential Analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint detection and estimation refers to deciding between two or more
hypotheses and, depending on the test outcome, simultaneously estimating the
unknown parameters of the underlying distribution. This problem is investigated
in a sequential framework under mild assumptions on the underlying random
process. We formulate an unconstrained sequential decision problem, whose cost
function is the weighted sum of the expected run-length and the
detection/estimation errors. Then, a strong connection between the derivatives
of the cost function with respect to the weights, which can be interpreted as
Lagrange multipliers, and the detection/estimation errors of the underlying
scheme is shown. This property is used to characterize the solution of a
closely related sequential decision problem, whose objective function is the
expected run-length under constraints on the average detection/estimation
errors. We show that the solution of the constrained problem coincides with the
solution of the unconstrained problem with suitably chosen weights. These
weights are characterized as the solution of a linear program, which can be
solved using efficient off-the-shelf solvers. The theoretical results are
illustrated with two example problems, for which optimal sequential schemes are
designed numerically and whose performance is validated via Monte Carlo
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03343</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03343</id><created>2018-07-09</created><authors><author><keyname>Dedmari</keyname><forenames>Muneer Ahmad</forenames></author><author><keyname>Conjeti</keyname><forenames>Sailesh</forenames></author><author><keyname>Estrada</keyname><forenames>Santiago</forenames></author><author><keyname>Ehses</keyname><forenames>Phillip</forenames></author><author><keyname>St&#xf6;cker</keyname><forenames>Tony</forenames></author><author><keyname>Reuter</keyname><forenames>Martin</forenames></author></authors><title>Complex Fully Convolutional Neural Networks for MR Image Reconstruction</title><categories>cs.CV eess.IV</categories><comments>9 pages, accepted in MICCAI-MLMIR 2018 Worshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undersampling the k-space data is widely adopted for acceleration of Magnetic
Resonance Imaging (MRI). Current deep learning based approaches for supervised
learning of MRI image reconstruction employ real-valued operations and
representations by treating complex valued k-space/spatial-space as real
values. In this paper, we propose complex dense fully convolutional neural
network ($\mathbb{C}$DFNet) for learning to de-alias the reconstruction
artifacts within undersampled MRI images. We fashioned a densely-connected
fully convolutional block tailored for complex-valued inputs by introducing
dedicated layers such as complex convolution, batch normalization,
non-linearities etc. $\mathbb{C}$DFNet leverages the inherently complex-valued
nature of input k-space and learns richer representations. We demonstrate
improved perceptual quality and recovery of anatomical structures through
$\mathbb{C}$DFNet in contrast to its real-valued counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03348</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03348</id><created>2018-07-09</created><updated>2019-08-14</updated><authors><author><keyname>Gao</keyname><forenames>Mingjun</forenames></author><author><keyname>Li</keyname><forenames>Yongzhao</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>Blind Identification of SFBC-OFDM Signals Based on the Central Limit
  Theorem</title><categories>eess.SP</categories><journal-ref>IEEE Trans. Wireless Commun. 18 (2019) 3500-3514</journal-ref><doi>10.1109/TWC.2019.2914687</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous approaches for blind identification of space-frequency block codes
(SFBC) do not perform well for short observation periods due to their
inefficient utilization of frequency-domain redundancy. This paper proposes a
hypothesis test (HT)-based algorithm and a support vector machine (SVM)-based
algorithm for SFBC signals identification over frequency-selective fading
channels to exploit two-dimensional space-frequency domain redundancy. Based on
the central limit theorem, space-domain redundancy is exploited to construct
the cross-correlation function of the estimator and frequency-domain redundancy
is incorporated in the construction of the statistics. The difference between
the two proposed algorithms is that the HT-based algorithm constructs a
chi-square statistic and employs an HT to make the decision, while the
SVM-based algorithm constructs a non-central chi-square statistic with unknown
mean as a strongly-distinguishable statistical feature and uses an SVM to make
the decision. Both algorithms do not require knowledge of the channel
coefficients, modulation type or noise power, and the SVM-based algorithm does
not require timing synchronization. Simulation results verify the superior
performance of the proposed algorithms for short observation periods with
comparable computational complexity to conventional algorithms, as well as
their acceptable identification performance in the presence of transmission
impairments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03368</identifier>
 <datestamp>2018-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03368</id><created>2018-07-09</created><updated>2018-10-08</updated><authors><author><keyname>Safavi</keyname><forenames>Sam</forenames></author><author><keyname>Bento</keyname><forenames>Jose</forenames></author></authors><title>How should we (correctly) compare multiple graphs?</title><categories>cs.DM cs.LG eess.SP math.CO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs are used in almost every scientific discipline to express relations
among a set of objects. Algorithms that compare graphs, and output a closeness
score, or a correspondence among their nodes, are thus extremely important.
Despite the large amount of work done, many of the scalable algorithms to
compare graphs do not produce closeness scores that satisfy the intuitive
properties of metrics. This is problematic since non-metrics are known to
degrade the performance of algorithms such as distance-based clustering of
graphs (Stratis et al. 2018). On the other hand, the use of metrics increases
the performance of several machine learning tasks (Indyk et al. 1999, Clarkson
et al. 1999, Angiulli et al. 2002 and Ackermann et al, 2010). In this paper, we
introduce a new family of multi-distances (a distance between more than two
elements) that satisfies a generalization of the properties of metrics to
multiple elements. In the context of comparing graphs, we are the first to show
the existence of multi-distances that simultaneously incorporate the useful
property of alignment consistency (Nguyen et al. 2011), and a generalized
metric property, and that can be computed via convex optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03396</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03396</id><created>2018-07-09</created><updated>2018-10-31</updated><authors><author><keyname>Tang</keyname><forenames>Hao</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>On Training Recurrent Networks with Truncated Backpropagation Through
  Time in Speech Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks have been the dominant models for many speech and
language processing tasks. However, we understand little about the behavior and
the class of functions recurrent networks can realize. Moreover, the heuristics
used during training complicate the analyses. In this paper, we study recurrent
networks' ability to learn long-term dependency in the context of speech
recognition. We consider two decoding approaches, online and batch decoding,
and show the classes of functions to which the decoding approaches correspond.
We then draw a connection between batch decoding and a popular training
approach for recurrent networks, truncated backpropagation through time.
Changing the decoding approach restricts the amount of past history recurrent
networks can use for prediction, allowing us to analyze their ability to
remember. Empirically, we utilize long-term dependency in subphonetic states,
phonemes, and words, and show how the design decisions, such as the decoding
approach, lookahead, context frames, and consecutive prediction, characterize
the behavior of recurrent networks. Finally, we draw a connection between
Markov processes and vanishing gradients. These results have implications for
studying the long-term dependency in speech data and how these properties are
learned by recurrent networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03418</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03418</id><created>2018-07-09</created><updated>2019-10-22</updated><authors><author><keyname>Becker</keyname><forenames>S&#xf6;ren</forenames></author><author><keyname>Ackermann</keyname><forenames>Marcel</forenames></author><author><keyname>Lapuschkin</keyname><forenames>Sebastian</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Klaus-Robert</forenames></author><author><keyname>Samek</keyname><forenames>Wojciech</forenames></author></authors><title>Interpreting and Explaining Deep Neural Networks for Classification of
  Audio Signals</title><categories>cs.SD cs.AI cs.LG eess.AS</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpretability of deep neural networks is a recently emerging area of
machine learning research targeting a better understanding of how models
perform feature selection and derive their classification decisions. This paper
explores the interpretability of neural networks in the audio domain by using
the previously proposed technique of layer-wise relevance propagation (LRP). We
present a novel audio dataset of English spoken digits which we use for
classification tasks on spoken digits and speaker's gender. We use LRP to
identify relevant features for two neural network architectures that process
either waveform or spectrogram representations of the data. Based on the
relevance scores obtained from LRP, hypotheses about the neural networks'
feature selection are derived and subsequently tested through systematic
manipulations of the input data. The results confirm that the networks are
highly reliant on features marked as relevant by LRP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03425</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03425</id><created>2018-07-09</created><authors><author><keyname>Kvinge</keyname><forenames>Henry</forenames></author><author><keyname>Farnell</keyname><forenames>Elin</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author></authors><title>A GPU-Oriented Algorithm Design for Secant-Based Dimensionality
  Reduction</title><categories>cs.CV cs.LG eess.IV eess.SP</categories><comments>To appear in the 17th IEEE International Symposium on Parallel and
  Distributed Computing, Geneva, Switzerland 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dimensionality-reduction techniques are a fundamental tool for extracting
useful information from high-dimensional data sets. Because secant sets encode
manifold geometry, they are a useful tool for designing meaningful
data-reduction algorithms. In one such approach, the goal is to construct a
projection that maximally avoids secant directions and hence ensures that
distinct data points are not mapped too close together in the reduced space.
This type of algorithm is based on a mathematical framework inspired by the
constructive proof of Whitney's embedding theorem from differential topology.
Computing all (unit) secants for a set of points is by nature computationally
expensive, thus opening the door for exploitation of GPU architecture for
achieving fast versions of these algorithms. We present a polynomial-time
data-reduction algorithm that produces a meaningful low-dimensional
representation of a data set by iteratively constructing improved projections
within the framework described above. Key to our algorithm design and
implementation is the use of GPUs which, among other things, minimizes the
computational time required for the calculation of all secant lines. One goal
of this report is to share ideas with GPU experts and to discuss a class of
mathematical algorithms that may be of interest to the broader GPU community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03440</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03440</id><created>2018-07-09</created><updated>2019-06-07</updated><authors><author><keyname>Iqbal</keyname><forenames>Asim</forenames></author><author><keyname>Khan</keyname><forenames>Romesa</forenames></author><author><keyname>Karayannis</keyname><forenames>Theofanis</forenames></author></authors><title>Developing Brain Atlas through Deep Learning</title><categories>cs.CV cs.LG eess.IV</categories><comments>31 pages, 17 figures, 1 Table</comments><doi>10.1038/s42256-019-0058-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuroscientists have devoted significant effort into the creation of standard
brain reference atlases for high-throughput registration of anatomical regions
of interest. However, variability in brain size and form across individuals
poses a significant challenge for such reference atlases. To overcome these
limitations, we introduce a fully automated deep neural network-based method
(SeBRe) for registration through Segmenting Brain Regions of interest with
minimal human supervision. We demonstrate the validity of our method on brain
images from different mouse developmental time points, across a range of
neuronal markers and imaging modalities. We further assess the performance of
our method on images from MR-scanned human brains. Our registration method can
accelerate brain-wide exploration of region-specific changes in brain
development and, by simply segmenting brain regions of interest for
high-throughput brain-wide analysis, provides an alternative to existing
complex brain registration techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03442</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03442</id><created>2018-07-09</created><authors><author><keyname>Guan</keyname><forenames>Birmingham Hang</forenames></author><author><keyname>Rangarajan</keyname><forenames>Anand</forenames></author></authors><title>Signals as Parametric Curves: Application to Independent Component
  Analysis and Blind Source Separation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images Stacks as Parametric Surfaces (ISPS) is a powerful model that was
originally proposed for image registration. Being closely related to mutual
information (MI) - the most classic similarity measure for image registration,
ISPS works well across different categories of registration problems. The
Signals as Parametric Curves (SPC) model is derived from ISPS extended to
1-dimensional signals. Blind Source Separation (BSS) is a classic problem in
signal processing, where Independent Component Analysis (ICA) based approaches
are popular and effective. Since MI plays an important role in ICA, based on
the close relationship with MI, we apply SPC model to BSS in this paper, and
propose a group of geometrical objective functions that are simple yet
powerful, and serve as replacements of original MI-based objective functions.
Motivated by the geometrical objective functions, we also propose a
second-order-statistics approach, FT-PCA. Both geometrical objective functions
and FT-PCA consider signals as functions instead of stochastic processes, make
use of derivative information of signals, and do not rely on the independence
assumption. In this paper, we discuss the reasonability of the assumptions of
geometrical objective functions and FT-PCA, and show their effectiveness by
synthetic experiments, comparing with other previous classic approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03463</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03463</id><created>2018-07-09</created><updated>2018-12-24</updated><authors><author><keyname>Amor</keyname><forenames>Nesrine</forenames></author><author><keyname>Rasool</keyname><forenames>Ghulam</forenames></author><author><keyname>Bouaynaya</keyname><forenames>Nidhal C.</forenames></author></authors><title>Constrained State Estimation - A Review</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasingly for many real-world applications in signal processing,
nonlinearity, non-Gaussianity, and additional constraints are considered while
handling dynamic state estimation problems. This paper provides a critical
review of the state of the art in constrained Bayesian state estimation for
linear and nonlinear state-space systems. Specifically, we provide a review of
unconstrained estimation using Kalman filters for the linear system, and their
extensions for the nonlinear state-space system including extended Kalman
filters, unscented Kalman filters, and ensemble Kalman filters. In addition, we
present the particle filters for nonlinear state space systems and discuss
recent advances. Next, we review constrained state estimation using all these
filters where we highlighted the advantages and disadvantages of the different
recent approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03474</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03474</id><created>2018-07-10</created><authors><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Takamune</keyname><forenames>Norihiro</forenames></author><author><keyname>Kitamura</keyname><forenames>Daichi</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>Phase reconstruction from amplitude spectrograms based on
  von-Mises-distribution deep neural network</title><categories>cs.SD eess.AS</categories><comments>To appear in the Proc. of IWAENC2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a deep neural network (DNN)-based phase reconstruction
from amplitude spectrograms. In audio signal and speech processing, the
amplitude spectrogram is often used for processing, and the corresponding phase
spectrogram is reconstructed from the amplitude spectrogram on the basis of the
Griffin-Lim method. However, the Griffin-Lim method causes unnatural artifacts
in synthetic speech. Addressing this problem, we introduce the
von-Mises-distribution DNN for phase reconstruction. The DNN is a generative
model having the von Mises distribution that can model distributions of a
periodic variable such as a phase, and the model parameters of the DNN are
estimated on the basis of the maximum likelihood criterion. Furthermore, we
propose a group-delay loss for DNN training to make the predicted group delay
close to a natural group delay. The experimental results demonstrate that 1)
the trained DNN can predict group delay accurately more than phases themselves,
and 2) our phase reconstruction methods achieve better speech quality than the
conventional Griffin-Lim method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03526</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03526</id><created>2018-07-10</created><updated>2018-07-17</updated><authors><author><keyname>Shakeel</keyname><forenames>Ismail</forenames></author><author><keyname>Ahmad</keyname><forenames>Ishtiaq</forenames></author><author><keyname>Suzuki</keyname><forenames>Hajime</forenames></author></authors><title>Construction of Adaptive Short LDPC Codes for Distributed Transmit
  Beamforming</title><categories>eess.SP</categories><comments>Submitted to 12th International Conference on Signal Processing and
  Communication Systems (ICSPCS'2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenges often faced with wireless communication systems is its
limited range and data-rate. Distributed Transmit Beamforming (DTB) techniques
are being developed to address these two issues to provide reliable
connectivity from power-limited distributed users. This paper proposes an
adaptive Low Density Parity Check (LDPC) coding scheme for the DTB system. The
proposed scheme constructs powerful LDPC codes with varying code-rates and
block-lengths. This feature of the proposed scheme allows the DTB system to
optimise its system resources, improve throughput and communicate reliably
under large variation of different channel environments. The performance of
some of the codes constructed using the proposed scheme is evaluated and
compared with the uncoded and other coded-DTB systems. The results obtained
show large gains over the compared systems. The results also show that coding
applied to the DTB system drastically reduces the minimum number of distributed
transmit nodes required to achieve a target error-rate with the same energy per
information bit to noise power spectral density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03530</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03530</id><created>2018-07-10</created><authors><author><keyname>Hu</keyname><forenames>Yongchang</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Robust Differential Received Signal Strength-Based Localization</title><categories>eess.SP</categories><journal-ref>IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 65, NO. 12, JUNE 15,
  2017</journal-ref><doi>10.1109/TSP.2017.2684741</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source localization based on signal strength measurements has become very
popular due to its practical simplicity. However, the severe nonlinearity and
non-convexity make the related optimization problem mathematically difficult to
solve, especially when the transmit power or the path-loss exponent (PLE) is
unknown. Moreover, even if the PLE is known but not perfectly estimated or the
anchor location information is not accurate, the constructed data model will
become uncertain, making the problem again hard to solve. This paper
particularly focuses on differential received signal strength (DRSS)-based
localization with model uncertainties in case of unknown transmit power and
PLE. A new whitened model for DRSS-based localization with unknown transmit
powers is first presented and investigated. When assuming the PLE is known, we
introduce two estimators based on an exact data model, an advanced best linear
unbiased estimator (A-BLUE) and a Lagrangian estimator (LE), and then we
present a robust semidefinite programming (SDP)-based estimator (RSDPE), which
can cope with model uncertainties (imperfect PLE and inaccurate anchor location
information). The three proposed estimators have their own advantages from
different perspectives: the A-BLUE has the lowest complexity; the LE holds the
best accuracy for a small measurement noise; and the RSDPE yields the best
performance under a large measurement noise and possesses a very good
robustness against model uncertainties. Finally, we propose a robust SDP-based
block coordinate descent estimator (RSDP-BCDE) to deal with a completely
unknown PLE and its performance converges to that of the RSDPE using a
perfectly known PLE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03534</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03534</id><created>2018-07-10</created><updated>2018-07-24</updated><authors><author><keyname>Zhang</keyname><forenames>Bingbing</forenames></author><author><keyname>Hu</keyname><forenames>Yongchang</forenames></author><author><keyname>Wang</keyname><forenames>Hongyi</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhaowen</forenames></author></authors><title>Underwater Source Localization Using TDOA and FDOA Measurements with
  Unknown Propagation Speed and Sensor Parameter Errors</title><categories>eess.SP</categories><journal-ref>IEEE Access 6(1):36645-36661, 2018</journal-ref><doi>10.1109/ACCESS.2018.2852636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underwater source localization problems are complicated and challenging: a)
the sound propagation speed is often unknown and the unpredictable ocean
current might lead to the uncertainties of sensor parameters (i.e. position and
velocity); b) the underwater acoustic signal travels much slower than the radio
one in terrestrial environments, thus resulting in a significantly severe
Doppler effect; c) energy-efficient techniques are urgently required and hence
in favour of the design with a low computational complexity. Considering these
issues, we propose a simple and efficient underwater source localization
approach based on time difference of arrival (TDOA) and frequency difference of
arrival (FDOA) measurements, which copes with unknown propagation speed and
sensor parameter errors. The proposed method mitigates the impact of the
Doppler effect for accurately inferring the source parameters (i.e. position
and velocity). The Cramer-Rao lower bounds (CRLBs) for this kind of
localization are derived and, moreover, the analytical study shows that our
method can yield the performance that is very close to the CRLB, particularly
under small noise. The numerical results not only confirm the above conclusions
but also show that our method outperforms other competing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03548</identifier>
 <datestamp>2018-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03548</id><created>2018-07-10</created><updated>2018-09-24</updated><authors><author><keyname>Shao</keyname><forenames>Mingjie</forenames></author><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Liu</keyname><forenames>Yatao</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>Multiuser One-Bit Massive MIMO Precoding Under MPSK Signaling</title><categories>cs.IT eess.SP math.IT</categories><comments>IEEE GlobalSIP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most recently, there has been a flurry of research activities on studying how
massive MIMO precoding should be designed when the digital-to-analog conversion
at the transmitter side is operated by cheap one-bit digital-to-analog
converters (DACs). Such research is motivated by the desire to substantially
cut down the hardware cost and power consumption of the radio-frequency chain,
which is unaffordable in massive MIMO if high-resolution DACs are still used.
One-bit MIMO precoding design problems are much harder to solve than their
high-resolution DAC counterparts. In our previous work, we developed a minimum
symbol-error probability (SEP) design for one-bit precoding under the multiuser
MISO downlink scenario and under quadrature amplitude modulation signaling.
Leveraging on the previous work, this work shows how the minimum SEP design is
applied to M-ary phase shift keying (MPSK) signaling. Simulation results show
that our minimum SEP design delivers significantly better bit-error rate (BER)
performance than the other designs for higher-order PSK such as 8-PSK and
16-PSK. As a minor, but useful, side contribution, we also tackle an MPSK SEP
characterization problem which was only intuitively treated in the prior arts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03612</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03612</id><created>2018-07-10</created><updated>2018-07-11</updated><authors><author><keyname>Z&#xe1;vi&#x161;ka</keyname><forenames>Pavel</forenames></author><author><keyname>Rajmic</keyname><forenames>Pavel</forenames></author><author><keyname>Pr&#x16f;&#x161;a</keyname><forenames>Zden&#x11b;k</forenames></author><author><keyname>Vesel&#xfd;</keyname><forenames>V&#xed;t&#x11b;zslav</forenames></author></authors><title>Revisiting Synthesis Model of Sparse Audio Declipper</title><categories>eess.AS eess.SP</categories><journal-ref>LVA ICA 2018. The 14th International Conference on Latent Variable
  Analysis and Signal Separation, Guildford, United Kingdom, July 2018</journal-ref><doi>10.1007/978-3-319-93764-9_40</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The state of the art in audio declipping has currently been achieved by SPADE
(SParse Audio DEclipper) algorithm by Kiti\'c et al. Until now, the
synthesis/sparse variant, S-SPADE, has been considered significantly slower
than its analysis/cosparse counterpart, A-SPADE. It turns out that the opposite
is true: by exploiting a recent projection lemma, individual iterations of both
algorithms can be made equally computationally expensive, while S-SPADE tends
to require considerably fewer iterations to converge. In this paper, the two
algorithms are compared across a range of parameters such as the window length,
window overlap and redundancy of the transform. The experiments show that
although S-SPADE typically converges faster, the average performance in terms
of restoration quality is not superior to A-SPADE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03625</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03625</id><created>2018-07-09</created><authors><author><keyname>Kitashov</keyname><forenames>Fedor</forenames></author><author><keyname>Svitanko</keyname><forenames>Elizaveta</forenames></author><author><keyname>Dutta</keyname><forenames>Debojyoti</forenames></author></authors><title>Foreign English Accent Adjustment by Learning Phonetic Patterns</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art automatic speech recognition (ASR) systems struggle with the
lack of data for rare accents. For sufficiently large datasets, neural engines
tend to outshine statistical models in most natural language processing
problems. However, a speech accent remains a challenge for both approaches.
Phonologists manually create general rules describing a speaker's accent, but
their results remain underutilized. In this paper, we propose a model that
automatically retrieves phonological generalizations from a small dataset. This
method leverages the difference in pronunciation between a particular dialect
and General American English (GAE) and creates new accented samples of words.
The proposed model is able to learn all generalizations that previously were
manually obtained by phonologists. We use this statistical method to generate a
million phonological variations of words from the CMU Pronouncing Dictionary
and train a sequence-to-sequence RNN to recognize accented words with 59%
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03644</identifier>
 <datestamp>2018-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03644</id><created>2018-07-10</created><authors><author><keyname>Shah</keyname><forenames>Syed Waqas Haider</forenames></author></authors><title>A Technique for Multi-User MIMO using Spatial Channel Model for out-door
  environments</title><categories>eess.SP</categories><comments>masters thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Any wireless communication system needs to specify a propagation channel
model which acts as basis for performance evaluation and comparison. Spatial
channel models can be divided into deterministic i.e ray tracing, measurement
based which is based on channel information and geometry based stochastic
channel models which are based on assumption that directional structure of
channel can be modelled by last interaction between physical objects and
electromagnetic waves, before waves reach the base or mobile station. Multi
user double directional channel model (MDDCM) is a geometry based channel model
which is used to calculate the double directional channel information in
cellular system with MIMO mobile station and MIMO base station.
  In this research phase firstly, Multi User Multiple Input Multiple Output
(MU-MIMO) spatial channel model has been implemented for different outdoor
environments Urban Micro and Urban Macro using MATLAB for finding various
parameters like angle of arrival of the user, user direction and the distance
between user and access point (AP). Secondly coded (Multiple Input Multiple
Output-Orthogonal Frequency Division Multiplexing) MIMO-OFDM system has been
implemented using multipath Rayleigh faded channel and realistic Spatial
Channel Model. Different BER improvement techniques are used such as,
Viterbi-decoder, Time and Frequency inter-leaving. Multi-channel diversity is
also observed by using multiple antennas at transmitting and receiving end
[(2x2) and (2x4)] on both the channels. Effect of different modulation
techniques on BER performance is also observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03710</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03710</id><created>2018-07-10</created><authors><author><keyname>Wong</keyname><forenames>Timothy</forenames></author><author><keyname>Luo</keyname><forenames>Zhiyuan</forenames></author></authors><title>Recurrent Auto-Encoder Model for Large-Scale Industrial Sensor Signal
  Analysis</title><categories>cs.LG cs.AI cs.NE eess.SP stat.ML</categories><comments>Accepted paper at the 19th International Conference on Engineering
  Applications of Neural Networks (EANN 2018)</comments><journal-ref>E. Pimenidis and C. Jayne (Eds.): EANN 2018, CCIS 893</journal-ref><doi>10.1007/978-3-319-98204-5_17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent auto-encoder model summarises sequential data through an encoder
structure into a fixed-length vector and then reconstructs the original
sequence through the decoder structure. The summarised vector can be used to
represent time series features. In this paper, we propose relaxing the
dimensionality of the decoder output so that it performs partial
reconstruction. The fixed-length vector therefore represents features in the
selected dimensions only. In addition, we propose using rolling fixed window
approach to generate training samples from unbounded time series data. The
change of time series features over time can be summarised as a smooth
trajectory path. The fixed-length vectors are further analysed using additional
visualisation and unsupervised clustering techniques. The proposed method can
be applied in large-scale industrial processes for sensors signal analysis
purpose, where clusters of the vector representations can reflect the operating
states of the industrial system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03763</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03763</id><created>2018-07-10</created><updated>2019-10-14</updated><authors><author><keyname>Du</keyname><forenames>Jinfeng</forenames></author><author><keyname>Chizhik</keyname><forenames>Dmitry</forenames></author><author><keyname>Feick</keyname><forenames>Rodolfo</forenames></author><author><keyname>Rodriguez</keyname><forenames>Mauricio</forenames></author><author><keyname>Castro</keyname><forenames>Guillermo</forenames></author><author><keyname>Valenzuela</keyname><forenames>Reinaldo. A.</forenames></author></authors><title>Suburban Fixed Wireless Access Channel Measurements and Models at 28 GHz
  for 90% Outdoor Coverage</title><categories>cs.IT eess.SP math.IT</categories><comments>This work was presented in part at 2018 IEEE Symposium on Antennas
  and Propagation, Boston, MA, Jul. 2018</comments><journal-ref>IEEE Transactions on Antennas and Propagation. Date of IEEE online
  Publication: 19 August 2019</journal-ref><doi>10.1109/TAP.2019.2935110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving adequate coverage with high gain antennas is key to realizing the
full promise of the wide bandwidth available at cm/mm bands. We report
extensive outdoor measurements at 28 GHz in suburban residential areas in New
Jersey and Chile, with over 2000 links measured for same-street link types
(vegetation blocked LOS) from 13 streets and other-street link types (true
NLOS) from 7 streets, using a specialized narrowband channel sounder at ranges
reaching 200 m. The measurements, applicable to fixed wireless access, involved
a 55$^\circ$ transmit antenna placed on the exterior of a street-facing window
and a 10$^\circ$ receive horn antenna spinning on top of a van mast at 3 m
height, emulating a lamppost-mounted base station. Measured path gain-distance
dependence is well represented by power-law models, and azimuth gains at the
base are degraded through scattering by more than 4.3 dB for 10% of links. It
was found that, with 51 dBm EIRP at the base station and 11 dBi antenna at an
outdoor mounted terminal, 1 Gbps downlink rate can be delivered up to 100 m
from a base station deployed in the same street with 90% coverage guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03886</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03886</id><created>2018-07-10</created><authors><author><keyname>Ren</keyname><forenames>David</forenames></author><author><keyname>Chen</keyname><forenames>Michael</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author><author><keyname>Ophus</keyname><forenames>Colin</forenames></author></authors><title>A Practical Reconstruction Method for Three-Dimensional Phase Contrast
  Atomic Electron Tomography</title><categories>eess.SP physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electron tomography is a technique used in both materials science and
structural biology to image features well below optical resolution limit. In
this work, we present a new algorithm for reconstructing the
three-dimensional(3D) electrostatic potential of a sample at atomic resolution
from phase contrast imaging using high-resolution transmission electron
microscopy. Our method accounts for dynamical and strong phase scattering,
providing more accurate results with much lower electron doses than those
current atomic electron tomography experiments. We test our algorithm using
simulated images of a synthetic needle geometry dataset composed of an
amorphous silicon dioxide shell around a silicon core. Our results show that,
for a wide range of experimental parameters, we can accurately determine both
atomic positions and species, and also identify vacancies even for light
elements such as silicon and disordered materials such as amorphous silicon
dioxide and also identify vacancies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03919</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03919</id><created>2018-07-10</created><authors><author><keyname>Mahjoub</keyname><forenames>Hossein Nourkhiz</forenames></author><author><keyname>Toghi</keyname><forenames>Behrad</forenames></author><author><keyname>Fallah</keyname><forenames>Yaser P.</forenames></author></authors><title>A Driver Behavior Modeling Structure Based on Non-parametric Bayesian
  Stochastic Hybrid Architecture</title><categories>eess.SP cs.SY</categories><comments>This work has been accepted in 2018 IEEE Connected and Automated
  Vehicles Symposium (CAVS 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous nature of the vehicular networks, which results from the
co-existence of human-driven, semi-automated, and fully autonomous vehicles, is
a challenging phenomenon toward the realization of the intelligent
transportation systems with an acceptable level of safety, comfort, and
efficiency. Safety applications highly suffer from communication resource
limitations, specifically in dense and congested vehicular networks. The idea
of model-based communication (MBC) has been recently proposed to address this
issue. In this work, we propose Gaussian Process-based Stochastic Hybrid System
with Cumulative Relevant History (CRH-GP-SHS) framework, which is a
hierarchical stochastic hybrid modeling structure, built upon a non-parametric
Bayesian inference method, i.e. Gaussian processes. This framework is proposed
in order to be employed within the MBC context to jointly model driver/vehicle
behavior as a stochastic object. Non-parametric Bayesian methods relieve the
limitations imposed by non-evolutionary model structures and enable the
proposed framework to properly capture different stochastic behaviors. The
performance of the proposed CRH-GP-SHS framework at the inter-mode level has
been evaluated over a set of realistic lane change maneuvers from NGSIM-US101
dataset. The results show a noticeable performance improvement for GP in
comparison to the baseline constant speed model, specifically in critical
situations such as highly congested networks. Moreover, an augmented model has
also been proposed which is a composition of GP and constant speed models and
capable of capturing the driver behavior under various network reliability
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03930</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03930</id><created>2018-07-10</created><authors><author><keyname>Sun</keyname><forenames>Haijian</forenames></author><author><keyname>Zhou</keyname><forenames>Fuhui</forenames></author><author><keyname>Hu</keyname><forenames>Rose Qingyang</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Robust Beamforming Design in a NOMA Cognitive Radio Network Relying on
  SWIPT</title><categories>eess.SP cs.NI</categories><comments>This paper is submitted to IEEE Journal on Selected Areas in
  Communications for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a multiple-input single-output non-orthogonal multiple
access cognitive radio network relying on simultaneous wireless information and
power transfer. A realistic non-linear energy harvesting model is applied and a
power splitting architecture is adopted at each secondary user (SU). Since it
is difficult to obtain perfect channel state information (CSI) in practice,
instead either a bounded or gaussian CSI error model is considered. Our robust
beamforming and power splitting ratio are jointly designed for two problems
with different objectives, namely that of minimizing the transmission power of
the cognitive base station and that of maximizing the total harvested energy of
the SUs, respectively. The optimization problems are challenging to solve,
mainly because of the non-linear structure of the energy harvesting and CSI
errors models. We converted them into convex forms by using semi-definite
relaxation. For the minimum transmission power problem, we obtain the rank-2
solution under the bounded CSI error model, while for the maximum energy
harvesting problem, a two-loop procedure using a one-dimensional search is
proposed. Our simulation results show that the proposed scheme significantly
outperforms its traditional orthogonal multiple access counterpart.
Furthermore, the performance using the gaussian CSI error model is generally
better than that using the bounded CSI error model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03983</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03983</id><created>2018-07-11</created><authors><author><keyname>Curiac</keyname><forenames>Daniel-Ioan</forenames></author><author><keyname>Dragan</keyname><forenames>Florin</forenames></author><author><keyname>Banias</keyname><forenames>Ovidiu</forenames></author><author><keyname>Iercan</keyname><forenames>Daniel</forenames></author></authors><title>A knowledge based system approach in securing distributed wireless
  sensor networks</title><categories>eess.SP cs.NI cs.SE</categories><journal-ref>SCIENTIFIC BULLETIN of Politehnica University of Timisoara,
  ROMANIA,Transactions on AUTOMATIC CONTROL and COMPUTER SCIENCE, Vol. 51 (65),
  No. 4, 2006, ISSN 1224-600X</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor networks technologies had proved their great practicability in the
real world, being just a matter of time until this kind of networks will be
standardized and used in the field. This paper presents a new approach to
secure the transmission of information in sensor networks and is based on a
combined hardware-software architecture using three components: a) a mechanism
to provide sensor authentication and secret key distribution; b) AES
symmetrical encryption algorithm with predistributed keys; and c) an attack
detection stratagem using an expert system based on the prediction of the
values provided by the sensors, followed by reducing the sensor trust
coefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.03985</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.03985</id><created>2018-07-11</created><authors><author><keyname>Sahba</keyname><forenames>Farshid</forenames></author><author><keyname>Sahba</keyname><forenames>Ramin</forenames></author></authors><title>Prevention of Metro Rail Accidents and Incidents in Stations Using RFID
  Technology</title><categories>eess.SP</categories><comments>4 pages, 5 figures, 12th International Symposium on Intelligent
  Automation and Control, World Automation Congress 2018, Stevenson,
  Washington, USA, June 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, metro is one of the urban infrastructure and plays an important role
in urban transport. The safety and health of people in a city are always
important, and transport in the metro should also be safe. When subway trains
operate, it is possible to occur various accidents such as an exit from the
rails or collision with a possible obstacle on the rails (human or another
train). In this paper, a model is proposed based on RFID technology in which
the train is equipped with a RFID reader, and a control circuit with a
microcontroller as well as placing RFID active tags at specific points of the
path. When the train approaches the tagged points of the route, the train tag
reader scans the tag number, and then the microcontroller identifies the status
of the environment by retrieving the information from the internal database.
Then, the control circuit adjusts the rotational speed of the electric motor
and the train speed consequently based on that data. In this way, the speed of
the train is adapted automatically and promptly to the conditions and the
probability of an accident in unforeseen circumstances is reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04000</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04000</id><created>2018-07-11</created><updated>2018-07-18</updated><authors><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Garcia-Rodriguez</keyname><forenames>Adrian</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Geraci</keyname><forenames>Giovanni</forenames></author></authors><title>Interfering Channel Estimation in Radar-Cellular Coexistence: How Much
  Information Do We Need?</title><categories>eess.SP cs.IT math.IT</categories><comments>15 pages, 10 figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the coexistence between a MIMO radar and cellular
base stations. We study the interfering channel estimation, where the radar is
operated in the &quot;search and track&quot; mode, and the BS receives the interference
from the radar. Unlike the conventional methods where the radar and the
cellular systems fully cooperate with each other, in this work we consider that
they are uncoordinated and the BS needs to acquire the interfering channel
state information (ICSI) by exploiting the radar probing waveforms. For
completeness, both the line-of-sight (LoS) and Non-LoS (NLoS) channels are
considered in the coexistence scenario. By further assuming that the BS has
limited a priori knowledge about the radar waveforms, we propose several
hypothesis testing methods to identify the working mode of the radar, and then
obtain the ICSI through a variety of channel estimation schemes. Based on the
statistical theory, we analyze the theoretical performance of both the
hypothesis testing and the channel estimation methods. Finally, simulation
results verify the effectiveness of our theoretical analysis and demonstrate
that the BS can effectively estimate the interfering channel even with limited
information from the radar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04014</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04014</id><created>2018-07-11</created><updated>2020-02-21</updated><authors><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames><affiliation>PANAMA, DANTE</affiliation></author><author><keyname>Nikolova</keyname><forenames>Mila</forenames><affiliation>CMLA</affiliation></author></authors><title>A characterization of proximity operators</title><categories>math.CA eess.SP math.FA</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize proximity operators, that is to say functions that map a
vector to a solution of a penalized least squares optimization problem.
Proximity operators of convex penalties have been widely studied and fully
characterized by Moreau. They are also widely used in practice with nonconvex
penalties such as the {\ell} 0 pseudo-norm, yet the extension of Moreau's
characterization to this setting seemed to be a missing element of the
literature. We characterize proximity operators of (convex or nonconvex)
penalties as functions that are the subdifferential of some convex potential.
This is proved as a consequence of a more general characterization of so-called
Bregman proximity operators of possibly nonconvex penalties in terms of certain
convex potentials. As a side effect of our analysis, we obtain a test to verify
whether a given function is the proximity operator of some penalty, or not.
Many well-known shrinkage operators are indeed confirmed to be proximity
operators. However, we prove that windowed Group-LASSO and persistent empirical
Wiener shrinkage -- two forms of so-called social sparsity shrinkage-- are
generally not the proximity operator of any penalty; the exception is when they
are simply weighted versions of group-sparse shrinkage with non-overlapping
groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04051</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04051</id><created>2018-07-11</created><authors><author><keyname>Gebhard</keyname><forenames>Andreas</forenames></author><author><keyname>Lang</keyname><forenames>Oliver</forenames></author><author><keyname>Lunglmayr</keyname><forenames>Michael</forenames></author><author><keyname>Motz</keyname><forenames>Christian</forenames></author><author><keyname>Kanumalli</keyname><forenames>Ram Sunil</forenames></author><author><keyname>Auer</keyname><forenames>Christina</forenames></author><author><keyname>Paireder</keyname><forenames>Thomas</forenames></author><author><keyname>Wagner</keyname><forenames>Matthias</forenames></author><author><keyname>Pretl</keyname><forenames>Harald</forenames></author><author><keyname>Huemer</keyname><forenames>Mario</forenames></author></authors><title>A Robust Nonlinear RLS Type Adaptive Filter for
  Second-Order-Intermodulation Distortion Cancellation in FDD LTE and 5G Direct
  Conversion Transceivers</title><categories>eess.SP</categories><doi>10.1109/TMTT.2019.2896513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transceivers operating in frequency division duplex experience a transmitter
leakage (TxL) signal into the receiver due to the limited duplexer stop-band
isolation. This TxL signal in combination with the second-order nonlinearity of
the receive mixer may lead to a baseband (BB) second-order intermodulation
distortion (IMD2) with twice the transmit signal bandwidth. In direct
conversion receivers, this nonlinear IMD2 interference may cause a severe
signal-to-interference-plus-noise ratio degradation of the wanted receive
signal. This contribution presents a nonlinear Wiener model recursive
least-squares (RLS) type adaptive filter for the cancellation of the IMD2
interference in the digital BB. The included channel-select-, and DC-notch
filter at the output of the proposed adaptive filter ensure that the provided
IMD2 replica includes the receiver front-end filtering. A second, robust
version of the nonlinear RLS algorithm is derived which provides numerical
stability for highly correlated input signals which arise in e.g. LTE-A
intra-band multi-cluster transmission scenarios. The performance of the
proposed algorithms is evaluated by numerical simulations and by measurement
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04070</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04070</id><created>2018-07-11</created><authors><author><keyname>Hu</keyname><forenames>Yongchang</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Self-Estimation of Path-Loss Exponent in Wireless Networks and
  Applications</title><categories>eess.SP</categories><journal-ref>IEEE Transactions On Vehicular Technology, Vol. 64, No. 11,
  November 2015</journal-ref><doi>10.1109/TVT.2014.2380823</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The path-loss exponent (PLE) is one of the most crucial parameters in
wireless communications to characterize the propagation of fading channels. It
is currently adopted for many different kinds of wireless network problems such
as power consumption issues, modelling the communication environment, and
received signal strength (RSS)-based localization. PLE estimation is thus of
great use to assist in wireless networking. However, a majority of methods to
estimate the PLE require either some particular information of the wireless
network, which might be unknown or some external auxiliary devices, such as
anchor nodes or the Global Positioning System. Moreover, this external
information might sometimes be unreliable, spoofed, or difficult to obtain.
Therefore, a self-estimator for the PLE, which is able to work independently,
becomes an urgent demand to robustly and securely get a grip on the PLE for
various wireless network applications. This paper is the first to introduce two
methods that can solely and locally estimate the PLE. To start, a new linear
regression model for the PLE is presented. Based on this model, a closed-form
total least squares (TLS) method to estimate the PLE is first proposed, in
which, with no other assistance or external information, each node can estimate
the PLE merely by collecting RSSs. Second, to suppress the estimation errors, a
closed-form weighted TLS method is further developed, having a better
performance. Due to their simplicity and independence of any auxiliary system,
our two proposed methods can be easily incorporated into any kind of wireless
communication stack. Simulation results show that our estimators are reliable,
even in harsh environments, where the PLE is high. Many potential applications
are also explicitly illustrated in this paper, such as secure RSS-based
localization, kth nearest neighbour routing, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04077</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04077</id><created>2018-07-11</created><authors><author><keyname>Whiting</keyname><forenames>Stewart</forenames></author><author><keyname>Moreland</keyname><forenames>Samuel</forenames></author><author><keyname>Costello</keyname><forenames>Jason</forenames></author><author><keyname>Colopy</keyname><forenames>Glen</forenames></author><author><keyname>McCann</keyname><forenames>Christopher</forenames></author></authors><title>Recognising Cardiac Abnormalities in Wearable Device
  Photoplethysmography (PPG) with Deep Learning</title><categories>eess.SP</categories><comments>Appearing in the 2018 KDD Workshop on Machine Learning for Medicine
  and Healthcare</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiac abnormalities affecting heart rate and rhythm are commonly observed
in both healthy and acutely unwell people. Although many of these are benign,
they can sometimes indicate a serious health risk. ECG monitors are typically
used to detect these events in electrical heart activity, however they are
impractical for continuous long-term use. In contrast, current-generation
wearables with optical photoplethysmography (PPG) have gained popularity with
their low-cost, lack of wires and tiny size. Many cardiac abnormalities such as
ectopic beats and AF can manifest as both obvious and subtle anomalies in a PPG
waveform as they disrupt blood flow. We propose an automatic method for
recognising these anomalies in PPG signal alone, without the need for ECG. We
train an LSTM deep neural network on 400,000 clean PPG samples to learn typical
PPG morphology and rhythm, and flag PPG signal diverging from this as cardiac
abnormalities. We compare the cardiac abnormalities our approach recognises
with the ectopic beats recorded by a bedside ECG monitor for 29 patients over
47.6 hours of gold standard observations. Our proposed cardiac abnormality
recognition approach recognises 60%+ of ECG-detected PVCs in PPG signal, with a
false positive rate of 23% - demonstrating the compelling power and value of
this novel approach. Finally we examine how cardiac abnormalities manifest in
PPG signal for in- and out-of-hospital patient populations using a wearable
device during standard care.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04096</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04096</id><created>2018-07-11</created><updated>2018-07-12</updated><authors><author><keyname>G&#xf6;&#xdf;ling</keyname><forenames>N.</forenames></author><author><keyname>Doclo</keyname><forenames>S.</forenames></author></authors><title>RTF-Based Binaural MVDR Beamformer Exploiting an External Microphone in
  a Diffuse Noise Field</title><categories>eess.AS</categories><comments>Accepted at ITG Conference on Speech Communication 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Besides suppressing all undesired sound sources, an important objective of a
binaural noise reduction algorithm for hearing devices is the preservation of
the binaural cues, aiming at preserving the spatial perception of the acoustic
scene. A well-known binaural noise reduction algorithm is the binaural minimum
variance distortionless response beamformer, which can be steered using the
relative transfer function (RTF) vector of the desired source, relating the
acoustic transfer functions between the desired source and all microphones to a
reference microphone. In this paper, we propose a computationally efficient
method to estimate the RTF vector in a diffuse noise field, requiring an
additional microphone that is spatially separated from the head-mounted
microphones. Assuming that the spatial coherence between the noise components
in the head-mounted microphone signals and the additional microphone signal is
zero, we show that an unbiased estimate of the RTF vector can be obtained.
Based on real-world recordings, experimental results for several reverberation
times show that the proposed RTF estimator outperforms the widely used RTF
estimator based on covariance whitening and a simple biased RTF estimator in
terms of noise reduction and binaural cue preservation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04206</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04206</id><created>2018-07-11</created><authors><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Barazideh</keyname><forenames>Reza</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author></authors><title>Cross-layer Interference Modeling for 5G MmWave Networks in the Presence
  of Blockage</title><categories>eess.SP</categories><comments>Accepted for publication in VTC2018-Fall</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifth generation (5G) wireless technology is expected to utilize highly
directive antennas at millimeter wave (mmWave) spectrum to offer higher data
rates. However, given the high directivity of antennas and adverse propagation
characteristics at mmWave frequencies, these signals are very susceptible to
obstacles. One of the important factors that are highly impacted is
interference behavior. In fact, signals received from other terminals can be
easily blocked or attenuated at the receiver. In addition, higher number of
terminals can transmit signals without introducing much interference and hence
the traffic behavior, maintained by medium access control (MAC) layer, may
change. In this paper, we provide an interference model to evaluate the
interference power received at the physical layer of the receiving terminal,
considering antenna directivity, effect of obstacles and MAC layer constraints
that control the number of terminals transmitting simultaneously. We first
develop a blockage model and then derive the Laplace transform of the
interference power received at a typical receiving node. Subsequently, using
the derived Laplace transform, we evaluate the network error performance using
average bit-error-rate (BER). Analytical results are validated via Monte-Carlo
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04353</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04353</id><created>2018-07-11</created><updated>2018-08-28</updated><authors><author><keyname>Myer</keyname><forenames>Samuel</forenames></author><author><keyname>Tomar</keyname><forenames>Vikrant Singh</forenames></author></authors><title>Efficient keyword spotting using time delay neural networks</title><categories>eess.AS cs.SD</categories><comments>Will appear in Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel method of live keyword spotting using a
two-stage time delay neural network. The model is trained using transfer
learning: initial training with phone targets from a large speech corpus is
followed by training with keyword targets from a smaller data set. The accuracy
of the system is evaluated on two separate tasks. The first is the freely
available Google Speech Commands dataset. The second is an in-house task
specifically developed for keyword spotting. The results show significant
improvements in false accept and false reject rates in both clean and noisy
environments when compared with previously known techniques. Furthermore, we
investigate various techniques to reduce computation in terms of
multiplications per second of audio. Compared to recently published work, the
proposed system provides up to 89% savings on computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04387</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04387</id><created>2018-07-11</created><updated>2019-10-14</updated><authors><author><keyname>Yi</keyname><forenames>Jianxin</forenames></author><author><keyname>Wan</keyname><forenames>Xianrong</forenames></author><author><keyname>Li</keyname><forenames>Deshi</forenames></author></authors><title>Exactly Decoupled Kalman Filtering for Multitarget State Estimation with
  Sensor Bias</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Aerospace and Electronic Systems, 2019</journal-ref><doi>10.1109/TAES.2019.2945092</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of multisensor multitarget state estimation in the presence of
constant but unknown sensor biases is investigated. The classical approach to
this problem is to augment the state vector to include the states of all the
targets and the sensor biases, and then implement an augmented state Kalman
filter (ASKF). In this paper, we propose a novel decoupled Kalman filtering
algorithm. The decoupled Kalman filtering first processes each target in a
separate branch, namely the single-target Kalman filtering branch, where the
single-target states and the sensor biases are estimated. Then the bias
estimate is refined by fusing the former bias estimates across all the
single-target Kalman filtering branches. Finally, the refined bias estimate is
fed back to each single-target Kalman filtering branch to improve the target
state estimation. We prove that the proposed decoupled Kalman filtering is
exactly equivalent to the ASKF in terms of the estimation results under a usual
initial condition. The equivalence is also confirmed via the numerical example.
Moreover, we further validate the proposed algorithm using the field
experimental data of a multistatic passive radar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04388</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04388</id><created>2018-07-11</created><updated>2019-07-01</updated><authors><author><keyname>Jain</keyname><forenames>Ish Kumar</forenames></author><author><keyname>Kumar</keyname><forenames>Rajeev</forenames></author><author><keyname>Panwar</keyname><forenames>Shivendra</forenames></author></authors><title>The Impact of Mobile Blockers on Millimeter Wave Cellular Systems</title><categories>eess.SP</categories><comments>This paper earlier published on arxiv with a different name as: &quot;Can
  Millimeter Wave Cellular Systems provide High Reliability and Low Latency? An
  analysis of the impact of Mobile Blockers.&quot; The paper is published at IEEE
  Journal in Selected Area of Communication (JSAC 2019). This current arxiv
  version also corrects Figure 3 and Figure 11(b) of the published JSAC version</comments><doi>10.1109/JSAC.2019.2898756</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter Wave (mmWave) communication systems can provide high data rates,
but the system performance may degrade significantly due to interruptions by
mobile blockers such as humans or vehicles. A high frequency of interruptions
and lengthy blockage durations will degrade the quality of the user's
experience. A promising solution is to employ the macrodiversity of Base
Stations (BSs), where the User Equipment (UE) can handover to other available
BSs if the current serving BS gets blocked. However, an analytical model to
evaluate the system performance of dynamic blockage events in this setting is
unknown. In this paper, we develop a Line of Sight (LOS) dynamic blockage model
and evaluate the probability, duration, and frequency of blockage events
considering all the links to the UE which are not blocked by buildings or the
user's own body. For a dense urban area, we also analyze the impact of non-LOS
(NLOS) links on blockage events. Our results indicate that the minimum density
of BS required to satisfy the Quality of Service (QoS) requirements of Ultra
Reliable Low Latency Communication (URLLC) applications will be driven mainly
by blockage and latency constraints, rather than coverage or capacity
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04392</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04392</id><created>2018-07-11</created><updated>2018-09-03</updated><authors><author><keyname>Ju</keyname><forenames>Shihao</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Simulating Motion - Incorporating Spatial Consistency into the NYUSIM
  Channel Model</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an implementation of spatial consistency in the NYUSIM
channel simulation platform. NYUSIM is a millimeter wave (mmWave) channel
simulator that realizes measurement-based channel models based on a wide range
of multipath channel parameters, including realistic multipath time delays and
multipath components that arrive at different 3-D angles in space, and
generates life-like samples of channel impulse responses (CIRs) that
statistically match those measured in the real world. To properly simulate
channel impairments and variations for adaptive antenna algorithms or channel
state feedback, channel models should implement spatial consistency which
ensures correlated channel responses over short time and distance epochs. The
ability to incorporate spatial consistency into channel simulators will be
essential to explore the ability to train and deploy massive multiple-input and
multiple-output (MIMO) and multi-user beamforming in next-generation mobile
communication systems. This paper reviews existing modeling approaches to
spatial consistency, and describes an implementation of spatial consistency in
NYUSIM for when a user is moving in a square area having a side length of 15 m.
The spatial consistency extension will enable NYUSIM to generate realistic
evolutions of temporal and spatial characteristics of the wideband CIRs for
mobile users in motion, or for multiple users who are relatively close to one
another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04397</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04397</id><created>2018-07-11</created><authors><author><keyname>Jain</keyname><forenames>Ish Kumar</forenames></author></authors><title>Millimeter Wave Line-of-Sight Blockage Analysis</title><categories>eess.SP</categories><comments>MS thesis submitted at NYU Tandon School of Engineering, May 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) communication systems can provide high data rates
but the system performance may degrade significantly due to mobile blockers and
the user's own body. A high frequency of interruptions and long duration of
blockage may degrade the quality of experience. For example, delays of more
than about 10ms cause nausea to VR viewers. Macro-diversity of base stations
(BSs) has been considered a promising solution where the user equipment (UE)
can handover to other available BSs, if the current serving BS gets blocked.
However, an analytical model for the frequency and duration of dynamic blockage
events in this setting is largely unknown. In this thesis, we consider an open
park-like scenario and obtain closed-form expressions for the blockage
probability, expected frequency and duration of blockage events using
stochastic geometry. Our results indicate that the minimum density of BS that
is required to satisfy the Quality of Service (QoS) requirements of AR/VR and
other low latency applications is largely driven by blockage events rather than
capacity requirements. Placing the BS at a greater height reduces the
likelihood of blockage. We present a closed-form expression for the BS
density-height trade-off that can be used for network planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04435</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04435</id><created>2018-07-12</created><authors><author><keyname>Prasad</keyname><forenames>Shree M.</forenames></author><author><keyname>Panigrahi</keyname><forenames>Trilochan</forenames></author><author><keyname>Hassan</keyname><forenames>Mahbub</forenames></author></authors><title>Direction of Arrival Estimation for Nanoscale Sensor Networks</title><categories>cs.ET eess.SP</categories><comments>6 Pages, 9 figures, Camera Ready Version, NANOCOM '18: ACM The Fifth
  Annual International Conference on Nanoscale Computing and Communication,
  September 5--7, 2018, Reykjavik, Iceland</comments><doi>10.1145/3233188.3233210</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nanoscale wireless sensor networks (NWSNs) could be within reach soon using
graphene-based antennas, which resonate in 0.1-10 terahertz band. To conserve
the limited energy available at nanoscale, it is expected that NWSNs will
communicate using extremely short pulses on the order of femtoseconds. Accurate
estimation of direction of arrival (DOA) for such terahertz pulses will help
realize many useful applications for NWSNs. In this paper, using the well-known
MUltiple SIgnal Classification (MUSIC) algorithm, we study DOA estimation for
NWSNs for different energy levels, distances, pulse shapes, and frequencies.
Our analyses reveal that the best DOA estimation is achieved with the first
order Gaussian pulses, which emit their peak energy at 6 THz. Based on Monte
Carlo simulations, we demonstrate that MUSIC algorithm is capable of estimating
DOA with root mean square error less than one degree from a distance of around
6 meter for pulse energy as little as 1 atto Joule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04577</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04577</id><created>2018-07-12</created><authors><author><keyname>Kara</keyname><forenames>Ferdi</forenames></author><author><keyname>Kaya</keyname><forenames>Hakan</forenames></author></authors><title>Derivation of the closed-form BER expressions for DL-NOMA over
  Nakagami-m fading channels</title><categories>cs.IT eess.SP math.IT</categories><comments>26.IEEE Signal Processing and Communications Applications
  Conference,Izmir,Turkey</comments><doi>10.1109/SIU.2018.8404743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NOMA is as a strong candidate for the Future Radio Access Network (FRA) due
to its potential to support massive connectivity and high spectral efficiency.
However, the most important drawback of NOMA is the error during Successive
Interference Canceller (SIC) is implemented because of the inter-user
interferences. In this paper, we derive closed-form exact Bit-Error Rate
expressions for Downlink(DL) NOMA over Nakagami-m fading channels in the
presence of SIC errors. The derived expressions are validated by the computer
simulations. It is shown that the m parameter still represents the diversity
order like as OMA systems. Besides, the BER performances of users for NOMA have
substantially depended on the power allocation coefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04578</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04578</id><created>2018-07-12</created><authors><author><keyname>Sanli</keyname><forenames>Ezgi</forenames></author><author><keyname>Kara</keyname><forenames>Ferdi</forenames></author><author><keyname>Kaya</keyname><forenames>Hakan</forenames></author></authors><title>Effect of the Error Propagation on the Error Performance of Cooperative
  Communications with the Best Relay Selection Schemes</title><categories>cs.IT eess.SP math.IT</categories><comments>26.IEEE Signal Processing and Communications Applications
  Conference,Izmir,Turkey,2017</comments><msc-class>94-06</msc-class><doi>10.1109/SIU.2018.8404742</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, error performance of the cooperative communication systems
with the best relay selection scheme is investigated in the presence of error
propagation from role to destination. The error propagation expression is
derived firstly when the best relay is selected within M relays. The derived
end-to-end BER expression is verified with the computer simulations. It is
shown that the best relay selection does not ensure M+1 diversity order under
the error propagation unlike perfect decoding. In addition, the threshold
selection for the relays has dominant effect on the error performance of the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04629</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04629</id><created>2018-07-12</created><updated>2019-03-04</updated><authors><author><keyname>Wu</keyname><forenames>Hanwei</forenames></author><author><keyname>Flierl</keyname><forenames>Markus</forenames></author></authors><title>Learning Product Codebooks using Vector Quantized Autoencoders for Image
  Retrieval</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector-Quantized Variational Autoencoders (VQ-VAE)[1] provide an unsupervised
model for learning discrete representations by combining vector quantization
and autoencoders. In this paper, we study the use of VQ-VAE for representation
learning for downstream tasks, such as image retrieval. We first describe the
VQ-VAE in the context of an information-theoretic framework. We show that the
regularization term on the learned representation is determined by the size of
the embedded codebook before the training and it affects the generalization
ability of the model. As a result, we introduce a hyperparameter to balance the
strength of the vector quantizer and the reconstruction error. By tuning the
hyperparameter, the embedded bottleneck quantizer is used as a regularizer that
forces the output of the encoder to share a constrained coding space such that
learned latent features preserve the similarity relations of the data space. In
addition, we provide a search range for finding the best hyperparameter.
Finally, we incorporate the product quantization into the bottleneck stage of
VQ-VAE and propose an end-to-end unsupervised learning model for the image
retrieval task. The product quantizer has the advantage of generating
large-size codebooks. Fast retrieval can be achieved by using the lookup tables
that store the distance between any pair of sub-codewords. State-of-the-art
retrieval results are achieved by the learned codebooks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04636</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04636</id><created>2018-07-12</created><authors><author><keyname>G&#xf6;&#xdf;ling</keyname><forenames>N.</forenames></author><author><keyname>Marquardt</keyname><forenames>D.</forenames></author><author><keyname>Merks</keyname><forenames>I.</forenames></author><author><keyname>Zhang</keyname><forenames>T.</forenames></author><author><keyname>Doclo</keyname><forenames>S.</forenames></author></authors><title>Optimal Binaural LCMV Beamforming in Complex Acoustic Scenarios:
  Theoretical and Practical Insights</title><categories>eess.AS cs.SD</categories><comments>To appear in Proc. IWAENC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binaural beamforming algorithms for head-mounted assistive listening devices
are crucial to improve speech quality and speech intelligibility in noisy
environments, while maintaining the spatial impression of the acoustic scene.
While the well-known BMVDR beamformer is able to preserve the binaural cues of
one desired source, the BLCMV beamformer uses additional constraints to also
preserve the binaural cues of interfering sources. In this paper, we provide
theoretical and practical insights on how to optimally set the interference
scaling parameters in the BLCMV beamformer for an arbitrary number of
interfering sources. In addition, since in practice only a limited temporal
observation interval is available to estimate all required beamformer
quantities, we provide an experimental evaluation in a complex acoustic
scenario using measured impulse responses from hearing aids in a cafeteria for
different observation intervals. The results show that even rather short
observation intervals are sufficient to achieve a decent noise reduction
performance and that a proposed threshold on the optimal interference scaling
parameters leads to smaller binaural cue errors in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04813</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04813</id><created>2018-07-12</created><authors><author><keyname>Robey</keyname><forenames>Alexander</forenames></author><author><keyname>Ganapati</keyname><forenames>Vidya</forenames></author></authors><title>Optimal Physical Preprocessing for Example-Based Super-Resolution</title><categories>eess.IV</categories><doi>10.1364/OE.26.031333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In example-based super-resolution, the function relating low-resolution
images to their high-resolution counterparts is learned from a given dataset.
This data-driven approach to solving the inverse problem of increasing image
resolution has been implemented with deep learning algorithms. In this work, we
explore modifying the imaging hardware in order to collect more informative
low-resolution images for better ultimate high-resolution image reconstruction.
We show that this &quot;physical preprocessing&quot; allows for improved image
reconstruction with deep learning in Fourier ptychographic microscopy.
  Fourier ptychographic microscopy is a technique allowing for both high
resolution and high field-of-view at the cost of temporal resolution. In
Fourier ptychographic microscopy, variable illumination patterns are used to
collect multiple low-resolution images. These low-resolution images are then
computationally combined to create an image with resolution exceeding that of
any single image from the microscope. We use deep learning to jointly optimize
the illumination pattern with the post-processing reconstruction algorithm for
a given sample type, allowing for single-shot imaging with both high resolution
and high field-of-view. We demonstrate, with simulated data, that the joint
optimization yields improved image reconstruction as compared with sole
optimization of the post-processing reconstruction algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04819</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04819</id><created>2018-07-12</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Enhanced C-V2X Mode-4 Subchannel Selection</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In Release 14, the 3rd Generation Partnership Project (3GPP) introduced
Cellular Vehicle--to--Everything (C-V2X) \textit{mode-4} as a novel disruptive
technology to support sidelink vehicular communications in out--of--coverage
scenarios. C-V2X \textit{mode-4} has been engineered to operate in a
distributed manner, wherein vehicles autonomously monitor the received power
across sidelink subchannels before selecting one for utilization. By means of
such an strategy, vehicles attempt to $(i)$ discover and $(ii)$ reserve
subchannels with low interference that may have the potential to maximize the
reception likelihood of their own broadcasted safety messages. However, due to
dynamicity of the vehicular environment, the subchannels optimality may
fluctuate rapidly over time. As a consequence, vehicles are required to make a
new selection every few hundreds of milliseconds. In consonance with 3GPP, the
subchannel selection phase relies on the linear average of the perceived power
intensities on each of the subchannels during a monitoring window. However, in
this paper we propose a nonlinear power averaging phase, where the most
up--to--date measurements are assigned higher priority via exponential
weighting. We show through simulations that the overall system performance can
be leveraged in both urban and freeway scenarios. Furthermore, the linear
averaging can be considered as a special case of the exponentially-weighted
moving average, ensuring backward compatibility with the standardized method.
Finally, the 3GPP \textit{mode-4} scheduling approach is described in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04822</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04822</id><created>2018-07-12</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>Math</keyname><forenames>Chetan B.</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>System Level Simulation of Scheduling Schemes for C-V2X Mode-3</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The 3rd Generation Partnership Project (3GPP) introduced Cellular
Vehicle--to--Everything (C-V2X) as a novel technology to support sidelink
vehicular communications. While a distributed scheduling approach has been
proposed by 3GPP for the out--of--coverage scenario, i.e. C-V2X
\textit{mode-4}, there is no standardized scheme for centralized systems in
C-V2X \textit{mode-3}. In this paper, we propose two scheduling approaches for
C-V2X \textit{mode-3}. One of them is based on the minimization of the overall
power perceived by the vehicles. The second approach is based on the
maximization of the subchannels re-usage distance. The two centralized schemes
are compared against the distributed approach. Through simulations we show that
the proposed schemes outperform C-V2X \textit{mode-4} as the subchannels are
assigned in a more efficient manner with mitigated interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04824</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04824</id><created>2018-07-12</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>TDOA-based Localization via Stochastic Gradient Descent Variants</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Source localization is of pivotal importance in several areas such as
wireless sensor networks and Internet of Things (IoT), where the location
information can be used for a variety of purposes, e.g. surveillance,
monitoring, tracking, etc. Time Difference of Arrival (TDOA) is one of the
well-known localization approaches where the source broadcasts a signal and a
number of receivers record the arriving time of the transmitted signal. By
means of computing the time difference from various receivers, the source
location can be estimated. On the other hand, in the recent few years novel
optimization algorithms have appeared in the literature for $(i)$ processing
big data and for $(ii)$ training deep neural networks. Most of these techniques
are enhanced variants of the classical stochastic gradient descent (SGD) but
with additional features that promote faster convergence. In this paper, we
compare the performance of the classical SGD with the novel techniques
mentioned above. In addition, we propose an optimization procedure called
RMSProp+AF, which is based on RMSProp algorithm but with the advantage of
incorporating adaptation of the decaying factor. We show through simulations
that all of these techniques---which are commonly used in the machine learning
domain---can also be successfully applied to signal processing problems and are
capable of attaining improved convergence and stability. Finally, it is also
shown through simulations that the proposed method can outperform other
competing approaches as both its convergence and stability are superior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04829</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04829</id><created>2018-07-12</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Network-Assisted Resource Allocation with Quality and Conflict
  Constraints for V2V Communications</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The 3rd Generation Partnership Project (3GPP) has recently established in
Rel. 14 a network-assisted resource allocation scheme for vehicular broadcast
communications. Such novel paradigm is known as vehicle--to--vehicle (V2V)
\textit{mode-3} and consists in eNodeBs engaging only in the distribution of
sidelink subchannels among vehicles in coverage. Thereupon, without further
intervention of the former, vehicles will broadcast their respective signals
directly to their counterparts. Because the allotment of subchannels takes
place intermittently to reduce signaling, it must primarily be conflict-free in
order not to jeopardize the reception of signals. We have identified four
pivotal types of allocation requirements that must be guaranteed: one quality
of service (QoS) requirement and three conflict conditions which must be
precluded in order to preserve reception reliability. The underlying problem is
formulated as a maximization of the system sum-capacity with four types of
constraints that must be enforced. In addition, we propose a three-stage
suboptimal approach that is cast as multiple independent knapsack problems
(MIKPs). We compare the two approaches through simulations and show that the
latter formulation can attain acceptable performance at lesser complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04830</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04830</id><created>2018-07-12</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Impact of Quantized Side Information on Subchannel Scheduling for
  Cellular V2X</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In Release 14, 3GPP completed a first version of cellular
vehicle--to--everything (C-V2X) communications wherein two modalities were
introduced. One of these schemes, known as \textit{mode-3}, requires support
from eNodeBs in order to realize subchannel scheduling. This paper discusses a
graph theoretical approach for semi-persistent scheduling (SPS) in
\textit{mode-3} harnessing a sensing mechanism whereby vehicles can monitor
signal--to--interference--plus--noise ratio (SINR) levels across sidelink
subchannels. eNodeBs request such measurements from vehicles and utilize them
to accomplish suitable subchannel assignments. However, since SINR
values---herein also referred to as side information---span a wide range,
quantization is required. We conclude that 3 bits per vehicle every 100 ms can
provide sufficient granularity to maintain appropriate performance without
severe degradation. Furthermore, the proposed algorithm is compared against
pseudo-random and greedy SPS algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04854</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04854</id><created>2018-07-12</created><authors><author><keyname>Navazi</keyname><forenames>Hassan M.</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Jahangir</forenames></author></authors><title>Novel Method for Multi-Dimensional Mapping of Higher Order Modulations
  for BICM-ID Over Rayleigh Fading Channels</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-dimensional (MD) mapping offers more flexibility in mapping design for
bit-interleaved coded modulation with iterative decoding (BICM-ID) and
potentially improves the bandwidth efficiency. However, for higher order signal
constellations, finding suitable MD mappings is a very complicated task due to
the large number of possible mappings. In this paper, a novel mapping method is
introduced to construct efficient MD mappings to improve the error performance
of BICM-ID over Rayleigh fading
  channels. We propose to break the MD mapping design problem into four
distinct $2$-D mapping functions. The $2$-D mappings are designed such that the
resulting MD mapping improves the BICM-ID error performance at low signal to
noise ratios (SNRs). We also develop cost functions that can be optimized to
improve the error performance at high SNRs. The proposed mapping method is very
simple compared to well-known mapping methods, and it can achieve suitable MD
mappings for different modulations including higher order modulations for
BICM-ID. Simulation results show that our mappings significantly outperform the
previously known mappings at a target bit error rate (BER) of $10^{-6}$. Our
mappings also offer a lower error-floor compared to their well-known
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04970</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04970</id><created>2018-07-13</created><authors><author><keyname>Park</keyname><forenames>Sangwook</forenames></author><author><keyname>Mun</keyname><forenames>Seongkyu</forenames></author><author><keyname>Lee</keyname><forenames>Younglo</forenames></author><author><keyname>Han</keyname><forenames>David K.</forenames></author><author><keyname>Ko</keyname><forenames>Hanseok</forenames></author></authors><title>Analysis Acoustic Features for Acoustic Scene Classification and Score
  fusion of multi-classification systems applied to DCASE 2016 challenge</title><categories>cs.SD eess.AS</categories><comments>This article is related to a technical report for a challenge named
  Detection and Classification of Acoustic Scenes and Events 2016</comments><journal-ref>Park, S., Mun, S., Lee, Y., and Ko, H. (2016). Score fusion of
  classification systems for acoustic scene classification. IEEE AASP Challenge
  on Detection and Classification of Acoustic Scenes and Events (DCASE)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an acoustic scene classification method which achieved
the 4th ranking result in the IEEE AASP challenge of Detection and
Classification of Acoustic Scenes and Events 2016. In order to accomplish the
ensuing task, several methods are explored in three aspects: feature
extraction, feature transformation, and score fusion for final decision. In the
part of feature extraction, several features are investigated for effective
acoustic scene classification. For resolving the issue that the same sound can
be heard in different places, a feature transformation is applied for better
separation for classification. From these, several systems based on different
feature sets are devised for classification. The final result is determined by
fusing the individual systems. The method is demonstrated and validated by the
experiment conducted using the Challenge database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.04978</identifier>
 <datestamp>2018-09-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.04978</id><created>2018-07-13</created><updated>2018-09-05</updated><authors><author><keyname>Xiao</keyname><forenames>Zhangyu</forenames></author><author><keyname>Ou</keyname><forenames>Zhijian</forenames></author><author><keyname>Chu</keyname><forenames>Wei</forenames></author><author><keyname>Lin</keyname><forenames>Hui</forenames></author></authors><title>Hybrid CTC-Attention based End-to-End Speech Recognition using Subword
  Units</title><categories>eess.AS cs.CL cs.SD</categories><comments>accepted by ISCSLP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an end-to-end automatic speech recognition system,
which successfully employs subword units in a hybrid CTC-Attention based
system. The subword units are obtained by the byte-pair encoding (BPE)
compression algorithm. Compared to using words as modeling units, using
characters or subword units does not suffer from the out-of-vocabulary (OOV)
problem. Furthermore, using subword units further offers a capability in
modeling longer context than using characters. We evaluate different systems
over the LibriSpeech 1000h dataset. The subword-based hybrid CTC-Attention
system obtains 6.8% word error rate (WER) on the test_clean subset without any
dictionary or external language model. This represents a significant
improvement (a 12.8% WER relative reduction) over the character-based hybrid
CTC-Attention system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05072</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05072</id><created>2018-07-13</created><authors><author><keyname>Sigalov</keyname><forenames>Daniel</forenames></author><author><keyname>Gal</keyname><forenames>Aharon</forenames></author><author><keyname>Vigdor</keyname><forenames>Boaz</forenames></author></authors><title>On Universal Sensor Registration</title><categories>eess.SP cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple approach for sensor registration in target tracking
applications. The proposed method uses targets of opportunity and, without
making assumptions on their dynamical models, allows simultaneous calibration
of multiple three- and two-dimensional sensors. Whereas for two-sensor
scenarios only relative registration is possible, in practical cases with three
or more sensors unambiguous absolute calibration may be achieved. The derived
algorithms are straightforward to implement and do not require tuning of
parameters. The performance of the algorithms is tested in a numerical study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05108</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05108</id><created>2018-07-13</created><authors><author><keyname>Muhammad</keyname><forenames>Cahya Budi</forenames></author><author><keyname>Wijanto</keyname><forenames>Heroe</forenames></author><author><keyname>Setiawan</keyname><forenames>Antonius Darma</forenames></author></authors><title>Performance of Angle of Arrival Detection Using MUSIC Algorithm in
  Inter-Satellite Link</title><categories>eess.SP</categories><doi>10.1109/ICSIGSYS.2018.8372662</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An attitude of satellite is not always static, sometimes it moves randomly
and the antenna pointing of satellite is harder to achieve line of sight
communication to other satellite when it is outage by tumbling effect. In order
to determine an appropriate direction of satellite antenna in inter-satellite
link, this paper analyze estimation performance of the direction of arrival
(DoA) using MUSIC algorithm from connected satellite signal source. It differs
from optical measurement, magnetic field measurement, inertial measurement, and
global positioning system (GPS) attitude determination. The proposed method is
characterized by taking signal source from connected satellites, after that the
main satellite processed the information to obtain connected satellites antenna
direction. The simulation runs only on the direction of azimuth. The simulation
result shows that MUSIC algorithm processing time is faster than satellite
movement time in orbit on altitude of 830 km with the period of 101 minutes.
With the use of a 50 elements array antenna in spacing of 0.5 wavelength, the
total of 20 angle of arrival (AoA) can be detected in 0.98 seconds of
processing time when using MUSIC algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05133</identifier>
 <datestamp>2018-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05133</id><created>2018-07-13</created><authors><author><keyname>Marchi</keyname><forenames>Pablo</forenames></author><author><keyname>Messina</keyname><forenames>Francisco</forenames></author><author><keyname>Vega</keyname><forenames>Leonardo Rey</forenames></author><author><keyname>Galarza</keyname><forenames>Cecilia</forenames></author></authors><title>Augmented Generator Sub-transient Model Using Dynamic Phasor
  Measurements</title><categories>eess.SP</categories><comments>8 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we present a new model for a synchronous generator based on
phasor measurement units (PMUs) data. The proposed sub-transient model allows
to estimate the dynamic state variables as well as to calibrate model
parameters. The motivation for this new model is to use more efficiently the
PMU measurements which are becoming widely available in power grids. The
concept of phasor derivative is applied, which not only includes the signal
phase derivative but also its amplitude derivative. Applying known non-linear
estimation techniques, we study the merits of this new model. In particular, we
test robustness by considering a generator with different mechanical power
controls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05146</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05146</id><created>2018-07-13</created><updated>2019-01-14</updated><authors><author><keyname>Shang</keyname><forenames>Chao</forenames></author><author><keyname>You</keyname><forenames>Fengqi</forenames></author></authors><title>A data-driven robust optimization approach to scenario-based stochastic
  model predictive control</title><categories>math.OC cs.SY eess.SY</categories><journal-ref>Journal of Process Control, Volume 75, March 2019, Pages 24-39</journal-ref><doi>10.1016/j.jprocont.2018.12.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic model predictive control (SMPC) has been a promising solution to
complex control problems under uncertain disturbances. However, traditional
SMPC approaches either require exact knowledge of probabilistic distributions,
or rely on massive scenarios that are generated to represent uncertainties. In
this paper, a novel scenario-based SMPC approach is proposed by actively
learning a data-driven uncertainty set from available data with machine
learning techniques. A systematical procedure is then proposed to further
calibrate the uncertainty set, which gives appropriate probabilistic guarantee.
The resulting data-driven uncertainty set is more compact than traditional
norm-based sets, and can help reducing conservatism of control actions.
Meanwhile, the proposed method requires less data samples than traditional
scenario-based SMPC approaches, thereby enhancing the practicability of SMPC.
Finally the optimal control problem is cast as a single-stage robust
optimization problem, which can be solved efficiently by deriving the robust
counterpart problem. The feasibility and stability issue is also discussed in
detail. The efficacy of the proposed approach is demonstrated through a
two-mass-spring system and a building energy control problem under uncertain
disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05219</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05219</id><created>2018-07-13</created><authors><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Half-Duplex and Full-Duplex AF and DF Relaying with Energy-Harvesting in
  Log-Normal Fading</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1806.09380</comments><journal-ref>IEEE Transactions on Green Communications and Networking, vol. 1,
  no. 4, pp. 468-480, Dec. 2017</journal-ref><doi>10.1109/TGCN.2017.2740258</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-harvesting (EH) and wireless power transfer in cooperative relaying
networks have recently attracted a considerable amount of research attention.
Most of the existing work on this topic however focuses on Rayleigh fading
channels, which represent outdoor environments. In contrast, this paper is
dedicated to analyze the performance of dual-hop relaying systems with EH over
indoor channels characterized by log-normal fading. Both half-duplex (HD) and
full-duplex (FD) relaying mechanisms are studied in this work with
decode-and-forward (DF) and amplify-and-forward (AF) relaying protocols. In
addition, three EH schemes are investigated, namely, time switching relaying,
power splitting relaying and ideal relaying receiver which serves as a lower
bound. The system performance is evaluated in terms of the ergodic outage
probability for which we derive accurate analytical expressions. Monte Carlo
simulations are provided throughout to validate the accuracy of our analysis.
Results reveal that, in both HD and FD scenarios, AF relaying performs only
slightly worse than DF relaying which can make the former a more efficient
solution when the processing energy cost at the DF relay is taken into account.
It is also shown that FD relaying systems can generally outperform HD relaying
schemes as long as the loop-back interference in FD is relatively small.
Furthermore, increasing the variance of the log-normal channel has shown to
deteriorate the performance in all the relaying and EH protocols considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05247</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05247</id><created>2018-07-13</created><updated>2018-08-21</updated><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>Medjkouh</keyname><forenames>Sa&#xef;d</forenames></author><author><keyname>G&#xf6;n&#xfc;lta&#x15f;</keyname><forenames>Emre</forenames></author><author><keyname>Goldstein</keyname><forenames>Tom</forenames></author><author><keyname>Tirkkonen</keyname><forenames>Olav</forenames></author></authors><title>Channel Charting: Locating Users within the Radio Environment using
  Channel State Information</title><categories>cs.IT eess.SP math.IT stat.ML</categories><comments>To appear in IEEE Access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose channel charting (CC), a novel framework in which a multi-antenna
network element learns a chart of the radio geometry in its surrounding area.
The channel chart captures the local spatial geometry of the area so that
points that are close in space will also be close in the channel chart and vice
versa. CC works in a fully unsupervised manner, i.e., learning is only based on
channel state information (CSI) that is passively collected at a single point
in space, but from multiple transmit locations in the area over time. The
method then extracts channel features that characterize large-scale fading
properties of the wireless channel. Finally, the channel charts are generated
with tools from dimensionality reduction, manifold learning, and deep neural
networks. The network element performing CC may be, for example, a
multi-antenna base-station in a cellular system and the charted area in the
served cell. Logical relationships related to the position and movement of a
transmitter, e.g., a user equipment (UE), in the cell can then be directly
deduced from comparing measured radio channel characteristics to the channel
chart. The unsupervised nature of CC enables a range of new applications in UE
localization, network planning, user scheduling, multipoint connectivity,
hand-over, cell search, user grouping, and other cognitive tasks that rely on
CSI and UE movement relative to the base-station, without the need of
information from global navigation satellite systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05331</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05331</id><created>2018-07-14</created><authors><author><keyname>Roy</keyname><forenames>Monalisa Singha</forenames></author><author><keyname>Gupta</keyname><forenames>Rajarshi</forenames></author><author><keyname>Chandra</keyname><forenames>Jayanta K.</forenames></author><author><keyname>Sharma</keyname><forenames>Kaushik Das</forenames></author><author><keyname>Talukdar</keyname><forenames>Arunansu</forenames></author></authors><title>Improving Photoplethysmographic Measurements under Motion Artifacts
  using Artificial Neural Network for Personal Healthcare</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Instrumentation &amp; Measurement 2018</journal-ref><doi>10.1109/TIM.2018.2829488</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Photoplethysmographic (PPG) measurements are susceptible to motion artifacts
(MA) due to movement of the peripheral body parts. In this paper, we present a
new approach to identify the MA corrupted PPG beats and then rectify the beat
morphology using artificial neural network (ANN). Initially, beat quality
assessment was done to identify the clean PPG beats by a pre-trained feedback
ANN to generate a reference beat template for each person. The PPG data was
decomposed using principal component analysis (PCA) and reconstructed using
fixed energy retention. A weight coefficient was assigned for each PPG samples
in such a way that when they are multiplied , the modified beat morphology
matches the reference template. A particle swarm optimization (PSO) based
technique was utilized to select the best weight weight vector coefficients to
tune another feedback ANN, fed with a set of significant features generated by
an auto encoder from PCA reconstructed data. For real time implementation, this
pre-trained ANN was operated in feed-forward mode to directly generate the
weight vectors for any subsequent measurements of PPG. The method was validated
with PPG data collected from 55 human subjects. An average RMSE of 0.28 and SNR
improvement of 14.54 dB was obtained, with an average improvement of 36% and
47% measurement accuracy on crest time and systolic to diastolic peak height
ratio respectively. With IEEE Signal Processing Cup 2015 Challenge database,
Pearson's correlation coefficient between PPG estimated and ECG derived heart
rate was 0.990. The proposed method can be useful for personal health
monitoring applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05347</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05347</id><created>2018-07-14</created><updated>2019-02-06</updated><authors><author><keyname>Passerini</keyname><forenames>Federico</forenames></author><author><keyname>Tonello</keyname><forenames>Andrea M.</forenames></author></authors><title>Smart Grid Monitoring Using Power Line Modems: Anomaly Detection and
  Localization</title><categories>eess.SP</categories><comments>A version of this paper has been accepted for publication in IEEE
  Transactions on Smart Grids</comments><journal-ref>IEEE Transactions on Smart Grids, 2019</journal-ref><doi>10.1109/TSG.2019.2899264</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main subject of this paper is the sensing of network anomalies that span
from harmless impedance changes at some network termination to more or less
pronounced electrical faults, considering also cable degradation over time. In
this paper, we present how to harvest information about such anomalies in
distribution grids using high frequency signals spanning from few kHz to
several MHz. Given the wide bandwidth considered, we rely on power line modems
as network sensors. We firstly discuss the front-end architectures needed to
perform the measurement and then introduce two algorithms to detect, classify
and locate the different kinds of network anomalies listed above. Simulation
results are finally presented. They validate the concept of sensing in smart
grids using power line modems and show the efficiency of the proposed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05371</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05371</id><created>2018-07-14</created><authors><author><keyname>Sch&#xfc;tze</keyname><forenames>Henry</forenames></author><author><keyname>Barth</keyname><forenames>Erhardt</forenames></author><author><keyname>Martinetz</keyname><forenames>Thomas</forenames></author></authors><title>Adaptive Hierarchical Sensing for the Efficient Sampling of Sparse and
  Compressible Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the novel adaptive hierarchical sensing algorithm K-AHS, which
samples sparse or compressible signals with a measurement complexity equal to
that of Compressed Sensing (CS). In contrast to CS, K-AHS is adaptive as
sensing vectors are selected while sampling, depending on previous
measurements. Prior to sampling, the user chooses a transform domain in which
the signal of interest is sparse. The corresponding transform determines the
collection of sensing vectors. K-AHS gradually refines initial coarse
measurements to significant signal coefficients in the sparse transform domain
based on a sensing tree which provides a natural hierarchy of sensing vectors.
K-AHS directly provides significant signal coefficients in the sparse transform
domain and does not require a reconstruction stage based on inverse
optimization. Therefore, the K-AHS sensing vectors must not satisfy any
incoherence or restricted isometry property. A mathematical analysis proves the
sampling complexity of K-AHS as well as a general and sufficient condition for
sampling the optimal k-term approximation, which is applied to particular
signal models. The analytical findings are supported by simulations with
synthetic signals and real world images. On standard benchmark images, K-AHS
achieves lower reconstruction errors than CS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05372</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05372</id><created>2018-07-14</created><authors><author><keyname>Zheng</keyname><forenames>Yuan</forenames></author><author><keyname>Bi</keyname><forenames>Suzhi</forenames></author><author><keyname>Lin</keyname><forenames>Xiaohui</forenames></author></authors><title>Backscatter-assisted Relaying in Wireless Powered Communications Network</title><categories>cs.NI eess.SP</categories><comments>This paper has been accepted by the International Conference on
  Machine Learning and Intelligent Communications (MLICOM), Hangzhou, China,
  July 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a novel cooperation method in a two-user wireless powered
communication network (WPCN), in which one hybrid access point (HAP) broadcasts
wireless energy to two distributed wireless devices (WDs), while the WDs use
the harvested energy to transmit their independent information to the HAP. To
tackle the user unfairness problem caused by the near-far effect in WPCN, we
allow the WD with the stronger WD-to-HAP channel to use part of its harvested
energy to help relay the other weaker user's information to the HAP. In
particular, we exploit the use of backscatter communication during the wireless
energy transfer phase such that the helping relay user can harvest energy and
receive the information from the weaker user simultaneously. We derive the
maximum common throughput performance by jointly optimizing the time duration
and power allocations on wireless energy and information transmissions. Our
simulation results demonstrate that the backscatter-assisted cooperation scheme
can effectively improve the throughput fairness performance in WPCNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05408</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05408</id><created>2018-07-14</created><updated>2019-12-14</updated><authors><author><keyname>Abuella</keyname><forenames>Hisham</forenames></author><author><keyname>Ekin</keyname><forenames>Sabit</forenames></author></authors><title>Non-contact Vital Signs Monitoring through Visible Light Sensing</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a non-contact vital signs (respiration and heartbeat)
monitoring system that utilizes visible light sensing (VLS) technology. We have
for the first time demonstrated the ability to wirelessly (non-contact) sense
vital signs using only reflected incoherent light signals from a human subject.
The VLS-based system is implemented by using simple visible light source,
photodetector and data acquisition/processing unit, and is used with the
developed signal processing algorithms to turn slight variations in reflected
light power into accurate measurements of respiration and heart rate. To assess
the accuracy of our method, the results were compared with reliable
measurements using a contact-based monitoring device (ground truth). More than
94% of accuracy was observed in test results including both breathing and
heartbeat rates in different scenarios as compared to the state-of-the-art
baseline methods such as contact-based vitals monitoring devices. These
competitive results have demonstrated that VLS-based vitals monitoring
innovation is indeed a viable, powerful, attractive, low-cost and safe method.
This study represents a substantive departure from the traditional ways of
doing non-contact vitals monitoring methods (e.g., radio-frequency-based radars
and imaging-based cameras) and is poised to make big contributions to this
area. Since vital signs monitoring is a ubiquitous element of medicine, this
work would also impact the entire health care community, from patients in their
homes, to doctor's offices, to large medical institutions and industries. This
technology has potential to address numerous conditions and situations in which
vital signs are critical indicators such as sleep apnea and
human-computer-interaction applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05412</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05412</id><created>2018-07-14</created><authors><author><keyname>Abuella</keyname><forenames>Hisham</forenames></author><author><keyname>Miramirkhani</keyname><forenames>Farshad</forenames></author><author><keyname>Ekin</keyname><forenames>Sabit</forenames></author><author><keyname>Uysal</keyname><forenames>Murat</forenames></author><author><keyname>Ahmed</keyname><forenames>Samir</forenames></author></authors><title>ViLDAR - Visible Light Sensing Based Speed Estimation using Vehicle's
  Headlamps</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The introduction of light emitting diodes (LED) in automotive exterior
lighting systems provides opportunities to develop viable alternatives to
conventional communication and sensing technologies. Most of the advanced
driver-assist and autonomous vehicle technologies are based on Radio Detection
and Ranging (RADAR) or Light Detection and Ranging (LiDAR) systems that use
radio frequency or laser signals, respectively. While reliable and real-time
information on vehicle speeds is critical for traffic operations management and
autonomous vehicles safety, RADAR or LiDAR systems have some deficiencies
especially in curved road scenarios where the incidence angle is rapidly
varying. In this paper, we propose a novel speed estimation system so-called
the Visible Light Detection and Ranging (ViLDAR) that builds upon sensing
visible light variation of the vehicle's headlamp. We determine the accuracy of
the proposed speed estimator in straight and curved road scenarios. We further
present how the algorithm design parameters and the channel noise level affect
the speed estimation accuracy. For wide incidence angles, the simulation
results show that the ViLDAR outperforms RADAR/LiDAR systems in both straight
and curved road scenarios. A provisional patent (US#62/541,913) has been
obtained for this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05459</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05459</id><created>2018-07-14</created><authors><author><keyname>Mishra</keyname><forenames>Sakshi</forenames></author><author><keyname>Palanisamy</keyname><forenames>Praveen</forenames></author></authors><title>Multi-time-horizon Solar Forecasting Using Recurrent Neural Network</title><categories>cs.LG eess.SP stat.ML</categories><comments>Accepted at: IEEE Energy Conversion Congress and Exposition (ECCE
  2018), 7 pages, 5 figures, code available: sakshi-mishra.github.io</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The non-stationarity characteristic of the solar power renders traditional
point forecasting methods to be less useful due to large prediction errors.
This results in increased uncertainties in the grid operation, thereby
negatively affecting the reliability and increased cost of operation. This
research paper proposes a unified architecture for multi-time-horizon
predictions for short and long-term solar forecasting using Recurrent Neural
Networks (RNN). The paper describes an end-to-end pipeline to implement the
architecture along with the methods to test and validate the performance of the
prediction model. The results demonstrate that the proposed method based on the
unified architecture is effective for multi-horizon solar forecasting and
achieves a lower root-mean-squared prediction error compared to the previous
best-performing methods which use one model for each time-horizon. The proposed
method enables multi-horizon forecasts with real-time inputs, which have a high
potential for practical applications in the evolving smart grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05497</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05497</id><created>2018-07-15</created><authors><author><keyname>Nazari</keyname><forenames>Milad</forenames></author><author><keyname>Mehrpooya</keyname><forenames>Ali</forenames></author><author><keyname>Abbasi</keyname><forenames>Zahra</forenames></author><author><keyname>Nayebi</keyname><forenames>Mehdi</forenames></author><author><keyname>Bastani</keyname><forenames>M. Hassan</forenames></author></authors><title>Fast and Robust High-Dimensional Sparse Representation Recovery Using
  Generalized SL0</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representation can be described in high dimensions and used in many
applications, including MRI imaging and radar imaging. In some cases, methods
have been proposed to solve the high-dimensional sparse representation problem,
but main solution is converting high-dimensional problem into one-dimension.
Solving the equivalent problem had very high computational complexity. In this
paper, the problem of high-dimensional sparse representation is formulated
generally based on the theory of tensors, and a method for solving it based on
SL0 (Smoothed Least zero-nor) is presented. Also, the uniqueness conditions for
solution of the problem are considered in the high-dimensions. At the end of
the paper, some numerical experiments are performed to evaluate the efficiency
of the proposed algorithm and the results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05615</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05615</id><created>2018-07-15</created><authors><author><keyname>Sulieman</keyname><forenames>Nabeel I.</forenames></author><author><keyname>Gitlin</keyname><forenames>Richard D.</forenames></author></authors><title>Efficiently Secure Broadcasting in 5G Wireless Fog-Based-Fronthaul
  Networks</title><categories>eess.SP</categories><comments>12 pages, 8 figures</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  10, No. 3, June 2018</journal-ref><doi>10.5121/ijwmn.2018.10301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enhanced Diversity and Network Coding (eDC-NC), the synergistic combination
of Diversity and modified Triangular Network Coding, was introduced recently to
provide efficient and ultra-reliable networking with near-instantaneous fault
recovery. In this paper it is shown that eDC-NC technology can efficiently and
securely broadcast messages in 5G wireless fog-computing-based Radio Access
Networks (F-RAN). In particular, this work is directed towards demonstrating
the ability of eDC-NC technology to more efficiently provide secure messages
broadcasting than standardized methods such as Secure Multicasting using Secret
(Shared) Key Cryptography, such that the adversary has no ability to acquire
information even if they wiretap the entire F-RAN network (except of course the
source and destination nodes). Our results show that using secure eDC-NC
technology in F-RAN fronthaul network will enhance secure broadcasting and
provide ultra-reliability networking, near-instantaneous fault recovery, and
retain the throughput benefits of Network Coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05694</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05694</id><created>2018-07-16</created><authors><author><keyname>Wan</keyname><forenames>Shuo</forenames></author><author><keyname>Lu</keyname><forenames>Jiaxun</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Minor probability events detection in big data: An integrated approach
  with Bayesian testing and MIM</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minor probability events detection is a crucial problem in Big data. Such
events tend to include rarely occurring phenomenons which should be detected
and monitored carefully. Given the prior probabilities of separate events and
the conditional distributions of observations on the events, the Bayesian
detection can be applied to estimate events behind the observations. It has
been proved that Bayesian detection has the smallest overall testing error in
average sense. However, when detecting an event with very small prior
probability, the conditional Bayesian detection would result in high miss
testing rate. To overcome such a problem, a modified detection approach is
proposed based on Bayesian detection and message importance measure, which can
reduce miss testing rate in conditions of detecting events with minor
probability. The result can help to dig minor probability events in big data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05716</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05716</id><created>2018-07-16</created><authors><author><keyname>Ta</keyname><forenames>Viet-Cuong</forenames><affiliation>MICA</affiliation></author><author><keyname>Dao</keyname><forenames>Trung-Kien</forenames><affiliation>MICA</affiliation></author><author><keyname>Vaufreydaz</keyname><forenames>Dominique</forenames><affiliation>PERVASIVE</affiliation></author><author><keyname>Castelli</keyname><forenames>Eric</forenames><affiliation>PERVASIVE</affiliation></author></authors><title>Smartphone-based user positioning in a multiple-user context with Wi-Fi
  and Bluetooth</title><categories>eess.SP cs.NI</categories><comments>International Conference on Indoor Positioning and Indoor Navigation
  (IPIN), Sep 2018, Nantes, France</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multiuser context, the Bluetooth data from the smartphone could give an
approximation of the distance between users. Meanwhile, the Wi-Fi data can be
used to calculate the user's position directly. However, both the Wi-Fi-based
position outputs and Bluetooth-based distances are affected by some degree of
noise. In our work, we propose several approaches to combine the two types of
outputs for improving the tracking accuracy in the context of collaborative
positioning. The two proposed approaches attempt to build a model for measuring
the errors of the Bluetooth output and Wi-Fi output. In a non-temporal
approach, the model establishes the relationship in a specific interval of the
Bluetooth output and Wi-Fi output. In a temporal approach, the error
measurement model is expanded to include the time component between users'
movement. To evaluate the performance of the two approaches, we collected the
data from several multiuser scenarios in indoor environment. The results show
that the proposed approaches could reach a distance error around 3.0m for 75
percent of time, which outperforms the positioning results of the standard
Wi-Fi fingerprinting model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05721</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05721</id><created>2018-07-16</created><authors><author><keyname>Liu</keyname><forenames>Yanzhou</forenames></author><author><keyname>Barford</keyname><forenames>Lee</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Shuvra S.</forenames></author></authors><title>Generalized Graph Connections for Dataflow Modeling of DSP Applications</title><categories>eess.SP</categories><comments>This is a pre-publication version of a paper that has been accepted
  for publication in the 2018 IEEE International Workshop on Signal Processing
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In dataflow representations for signal processing systems, applications are
represented as directed graphs in which vertices represent computations and
edges correspond to buffers that store data as it passes between computations.
The buffers are single-input, single-output components that manage data in a
first-in, first-out (FIFO) fashion. In this paper, we generalize the concept of
dataflow buffers with a concept called &quot;passive blocks&quot;. Like dataflow buffers,
passive blocks are used to store data during the intervals between its
generation by producing actors, and its use by consuming actors. However,
passive blocks can have multiple inputs and multiple outputs, and can
incorporate operations on and rearrangements of the stored data subject to
certain constraints. We define a form of flowgraph representation that is based
on replacing dataflow edges with the proposed concept of passive blocks. We
present a structured design methodology for utilizing this new form of signal
processing flowgraph, and demonstrate its utility in improving memory
management efficiency, and execution time performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05750</identifier>
 <datestamp>2019-04-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05750</id><created>2018-07-16</created><updated>2019-03-29</updated><authors><author><keyname>Argyris</keyname><forenames>Apostolos</forenames></author><author><keyname>Bueno</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Fischer</keyname><forenames>Ingo</forenames></author></authors><title>PAM-4 Transmission at 1550nm using Photonic Reservoir Computing
  Post-processing</title><categories>eess.SP</categories><doi>10.1109/ACCESS.2019.2905422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficacy of data decoding in contemporary ultrafast fiber transmission
systems is greatly determined by the capabilities of the signal processing
tools that are used. The received signal must not exceed a certain level of
complexity, beyond which the applied signal processing solutions become
insufficient or slow. Moreover, the required signal-to-noise ratio of the
received signal can be challenging, especially when adopting modulation formats
with multi-level encoding. Lately, photonic reservoir computing (RC) - a
hardware machine learning technique with recurrent connectivity - has been
proposed as a post-processing tool that deals with deterministic distortions
from fiber transmission. Here we show that RC post-processing is remarkably
efficient for multilevel encoding and for the use of very high launched optical
peak power for fiber transmission up to 14dBm. Higher power levels provide the
desired high signal-to-noise ratio (SNR) values at the receiver end, at the
expense of a complex nonlinear transformation of the transmission signal. Our
demonstration evaluates a direct fiber communication link with 4-level pulse
amplitude modulation (PAM-4) encoding and direct detection, without including
optical amplification, dispersion compensation, pulse shaping or other digital
signal processing (DSP) techniques. By applying RC post-processing on the
distorted signal, we numerically estimate fiber transmission distances of 27km
at 56Gb/s and of 5.5 km at 112Gb/s data encoding rates, while fulfilling the
hard-decision forward error correction (HD-FEC) bit-error-rate (BER) limit for
data recovery. In an experimental equivalent demonstration of our photonic
reservoir, the achieved distances are 21km and 4.6km respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05764</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05764</id><created>2018-07-16</created><updated>2019-02-17</updated><authors><author><keyname>Van Beirendonck</keyname><forenames>Michiel</forenames></author><author><keyname>Trudeau</keyname><forenames>Louis-Charles</forenames></author><author><keyname>Giard</keyname><forenames>Pascal</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author></authors><title>A Lyra2 FPGA Core for Lyra2REv2-Based Cryptocurrencies</title><categories>cs.CR cs.AR eess.SP</categories><comments>5 pages, to be presented at the IEEE International Symposium on
  Circuits and Systems (ISCAS) 2019</comments><doi>10.1109/ISCAS.2019.8702498</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lyra2REv2 is a hashing algorithm that consists of a chain of individual
hashing algorithms and it is used as a proof-of-work function in several
cryptocurrencies that aim to be ASIC-resistant. The most crucial hashing
algorithm in the Lyra2REv2 chain is a specific instance of the general Lyra2
algorithm. In this work we present the first FPGA implementation of the
aforementioned instance of Lyra2 and we explain how several properties of the
algorithm can be exploited in order to optimize the design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05780</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05780</id><created>2018-07-16</created><authors><author><keyname>Lyu</keyname><forenames>Xue</forenames></author><author><keyname>Jia</keyname><forenames>Youwei</forenames></author><author><keyname>Xu</keyname><forenames>Zhao</forenames></author><author><keyname>&#xd8;stergaard</keyname><forenames>Jacob</forenames></author></authors><title>Mileage-responsive Wind Power Smoothing</title><categories>cs.SY eess.SP</categories><comments>Submitted to IEEE Power Engineering Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel wind power smoothing control paradigm in context
of performance-based regulation service. Conventional methods aim at adjusting
wind power output using hard-coded filtering algorithms that can result in
visually smoothed power output with unmeasurable impacts on system
generation-demand balance. Distinguished from conventional methods, the newly
proposed control method smooths wind power output from a power system
perspective by using the regulation mileage as a key performance indicator. To
simultaneously address the system needs and maximize wind energy harvesting, a
mileage-responsive framework is developed to enable wind farms to optimally
generate smoothing power. The effectiveness of the proposed method is well
demonstrated through case studies, of which the simulation results shows a
great potential for practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05812</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05812</id><created>2018-07-16</created><authors><author><keyname>Stowell</keyname><forenames>Dan</forenames></author><author><keyname>Stylianou</keyname><forenames>Yannis</forenames></author><author><keyname>Wood</keyname><forenames>Mike</forenames></author><author><keyname>Pamu&#x142;a</keyname><forenames>Hanna</forenames></author><author><keyname>Glotin</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Automatic acoustic detection of birds through deep learning: the first
  Bird Audio Detection challenge</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Assessing the presence and abundance of birds is important for monitoring
specific species as well as overall ecosystem health. Many birds are most
readily detected by their sounds, and thus passive acoustic monitoring is
highly appropriate. Yet acoustic monitoring is often held back by practical
limitations such as the need for manual configuration, reliance on example
sound libraries, low accuracy, low robustness, and limited ability to
generalise to novel acoustic conditions. Here we report outcomes from a
collaborative data challenge showing that with modern machine learning
including deep learning, general-purpose acoustic bird detection can achieve
very high retrieval rates in remote monitoring data --- with no manual
recalibration, and no pre-training of the detector for the target species or
the acoustic conditions in the target environment. Multiple methods were able
to attain performance of around 88% AUC (area under the ROC curve), much higher
performance than previous general-purpose methods. We present new acoustic
monitoring datasets, summarise the machine learning techniques proposed by
challenge teams, conduct detailed performance evaluation, and discuss how such
approaches to detection can be integrated into remote monitoring projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05813</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05813</id><created>2018-07-16</created><authors><author><keyname>Madhavaraj</keyname><forenames>A</forenames></author><author><keyname>Ananthapadmanabha</keyname><forenames>T V</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>A G</forenames></author></authors><title>Subjective and objective experiments on the influence of speaker's
  gender on the unvoiced segments</title><categories>cs.SD eess.AS</categories><comments>2 Figures, 5 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subjective and objective experiments are conducted to understand the extent
to which a speaker's gender influences the acoustics of unvoiced (U) sounds. U
segments of utterances are replaced by the corresponding segments of a speaker
of opposite gender to prepare modified utterances. Humans are asked to judge if
the modified utterance is spoken by one or two speakers. The experiments show
that human subjects are unable to distinguish the modified from the original.
Thus, listeners are able to identify the U segments irrespective of the gender,
which may be based on some speaker-independent invariant acoustic cues. To test
if this finding is purely a perceptual phenomenon, objective experiments are
also conducted. Gender specific HMM based phoneme recognition systems are
trained using the TIMIT training set and tested on (a) utterances spoken by the
same gender (b) utterances spoken by the opposite gender and (c) the modified
utterances of the test set. As expected, the performance is the highest for
case (a) and the lowest for case (b). The performance degrades only slightly
for case (c). This result shows that the speaker's gender does not as strongly
influence the acoustics of U sounds as they do the voiced sounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05854</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05854</id><created>2018-07-16</created><authors><author><keyname>Shermeyer</keyname><forenames>Jacob</forenames></author></authors><title>Assessment of electrical and infrastructure recovery in Puerto Rico
  following hurricane Maria using a multisource time series of satellite
  imagery</title><categories>cs.CV eess.IV</categories><comments>15 pages, 5 figures, 5 videos</comments><doi>10.1117/12.2325585</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Puerto Rico suffered severe damage from the category 5 hurricane (Maria) in
September 2017. Total monetary damages are estimated to be ~92 billion USD, the
third most costly tropical cyclone in US history. The response to this damage
has been tempered and slow moving, with recent estimates placing 45% of the
population without power three months after the storm. Consequently, we
developed a unique data-fusion mapping approach called the Urban Development
Index (UDI) and new open source tool, Comet Time Series (CometTS), to analyze
the recovery of electricity and infrastructure in Puerto Rico. Our approach
incorporates a combination of time series visualizations and change detection
mapping to create depictions of power or infrastructure loss. It also provides
a unique independent assessment of areas that are still struggling to recover.
For this workflow, our time series approach combines nighttime imagery from the
Suomi National Polar-orbiting Partnership Visible Infrared Imaging Radiometer
Suite (NPP VIIRS), multispectral imagery from two Landsat satellites, US Census
data, and crowd-sourced building footprint labels. Based upon our approach we
can identify and evaluate: 1) the recovery of electrical power compared to
pre-storm levels, 2) the location of potentially damaged infrastructure that
has yet to recover from the storm, and 3) the number of persons without power
over time. As of May 31, 2018, declined levels of observed brightness across
the island indicate that 13.9% +/- ~5.6% of persons still lack power and/or
that 13.2% +/- ~5.3% of infrastructure has been lost. In comparison, the Puerto
Rico Electric Power Authority states that less than 1% of their customers still
are without power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05855</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05855</id><created>2018-07-11</created><authors><author><keyname>Park</keyname><forenames>Hosung</forenames></author><author><keyname>Lee</keyname><forenames>Donghyun</forenames></author><author><keyname>Lim</keyname><forenames>Minkyu</forenames></author><author><keyname>Kang</keyname><forenames>Yoseb</forenames></author><author><keyname>Oh</keyname><forenames>Juneseok</forenames></author><author><keyname>Kim</keyname><forenames>Ji-Hwan</forenames></author></authors><title>A Fast-Converged Acoustic Modeling for Korean Speech Recognition: A
  Preliminary Study on Time Delay Neural Network</title><categories>cs.CL cs.SD eess.AS</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a time delay neural network (TDNN) based acoustic model is
proposed to implement a fast-converged acoustic modeling for Korean speech
recognition. The TDNN has an advantage in fast-convergence where the amount of
training data is limited, due to subsampling which excludes duplicated weights.
The TDNN showed an absolute improvement of 2.12% in terms of character error
rate compared to feed forward neural network (FFNN) based modelling for Korean
speech corpora. The proposed model converged 1.67 times faster than a
FFNN-based model did.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05920</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05920</id><created>2018-07-12</created><authors><author><keyname>Broumand</keyname><forenames>Ariana</forenames></author><author><keyname>Dadaneh</keyname><forenames>Siamak Zamani</forenames></author></authors><title>Sequential Sampling for Optimal Bayesian Classification of Sequencing
  Count Data</title><categories>stat.ME eess.SP</categories><comments>6 pages, 4 figures, accepted in Asilomar Conference on Signals,
  Systems, and Computers 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High throughput technologies have become the practice of choice for
comparative studies in biomedical applications. Limited number of sample points
due to sequencing cost or access to organisms of interest necessitates the
development of efficient sample collections to maximize the power of downstream
statistical analyses. We propose a method for sequentially choosing training
samples under the Optimal Bayesian Classification framework. Specifically
designed for RNA sequencing count data, the proposed method takes advantage of
efficient Gibbs sampling procedure with closed-form updates. Our results shows
enhanced classification accuracy, when compared to random sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05929</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05929</id><created>2018-07-12</created><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames></author><author><keyname>Koppelaar</keyname><forenames>Arie</forenames></author><author><keyname>de Groot</keyname><forenames>Sonia Heemstra</forenames></author></authors><title>Poster Abstract: Hierarchical Subchannel Allocation for Mode-3
  Vehicle-to-Vehicle Sidelink Communications</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In V2V Mode-3, eNodeBs assign subchannels to vehicles in order for them to
periodically broadcast CAM messages \cite{b2}. A crucial aspect is to ensure
that vehicles in the same cluster will broadcast in orthogonal time
subchannels\footnote{A subchannel is a time-frequency resource chunk capable of
sufficiently conveying a CAM message.} to avoid conflicts. In general,
resource/subchannel allocation problems can be represented as weighted
bipartite graphs. However, in this scenario there is an additional time
orthogonality constraint which cannot be straightforwardly handled by
conventional graph matching methods \cite{b3}. Thus, in our approach the
mentioned constraint has been taken into account. We also perform the
allocation task in a sequential manner based on the constrainedness of each
cluster. To illustrate the gist of the problem, in Fig. 1 we show two partially
overlapping clusters where a conflict between vehicles $V_8$ and $V_{10}$ is
generated as the allotted subchannels are in the same subframe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05931</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05931</id><created>2018-07-12</created><authors><author><keyname>Gelonch</keyname><forenames>Antoni</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Gomez</keyname><forenames>Ismael</forenames></author></authors><title>Teaching Telecommunication Standards - Bridging the Gap Between Theory
  and Practice</title><categories>eess.SP</categories><journal-ref>IEEE Communications Magazine, Vol. 55, Iss. 5, pp. 145-153, May
  2017</journal-ref><doi>10.1109/MCOM.2017.1601231</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Telecommunication standards have become a reliable mechanism to strengthen
collaboration between industry and research institutions to accelerate the
evolution of communications systems. Standards are needed to enable cooperation
while promoting competition. Within the framework of a standard, the companies
involved in the standardization process contribute and agree on appropriate
technical specifications to ensure diversity, compatibility and facilitate
worldwide commercial deployment and evolution. Those parts of the system that
can create competitive advantages are intentionally left open in the
specifications. Such specifications are extensive, complex and minimalistic.
This makes the telecommunication standards education a difficult endeavor, but
it is much demanded by industry and governments to spur economic growth. This
paper describes a methodology for teaching wireless communications standards.
We define our methodology around six learning stages that assimilate the
standardization process and identify key learning objectives for each. Enabled
by software-defined radio technology we describe a practical learning
environment that facilitates developing many of the needed technical and soft
skills without the inherent difficulty and cost associated with radio frequency
components and regulation. Using only open-source software and commercial
off-the-shelf computers, this environment is portable and can easily be
recreated at other educational institutions and adapted to their educational
needs and constraints. We discuss our and our students' experiences when
employing the proposed methodology to 4th generation (4G) long-term-evolution
(LTE) standard education at Barcelona Tech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05977</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05977</id><created>2018-07-12</created><authors><author><keyname>Dorostkar</keyname><forenames>Ali</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author></authors><title>Faster than Nyquist Transmission by Non-Orthogonal Time Division
  Multiplexing of Nyquist Sinc Sequences</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One possibility to break down the capacity limit in optical transmission
systems are higher spectral efficiencies, enabled by Faster-than-Nyquist
signaling. Here we present the utilization of non-orthogonal time division
multiplexing of sinc pulse sequences for this purpose. The mathematical
expression, with a representation of the Nyquist sinc sequence by a cosine
Fourier series and simulation results show that non-orthogonal time-division
multiplexing increases the transmittable symbol rate by up to 25%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05979</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05979</id><created>2018-07-10</created><updated>2018-07-17</updated><authors><author><keyname>Sorokin</keyname><forenames>Andrey</forenames></author></authors><title>Lesion Analysis and Diagnosis with Mask-RCNN</title><categories>eess.IV stat.ML</categories><comments>4 pages, 4 figures, ISIC 2018 challenge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This project applies Mask R-CNN method to ISIC 2018 challenge tasks: lesion
boundary segmentation (task1), lesion attributes detection (task 2), lesion
diagnosis (task 3), a solution to the latter is using a trained model for task
1 and a simple voting procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05980</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05980</id><created>2018-07-11</created><authors><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Qingqing</forenames></author><author><keyname>Lin</keyname><forenames>Hua</forenames></author><author><keyname>Liu</keyname><forenames>Mingqing</forenames></author><author><keyname>Liang</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Liu</keyname><forenames>Qingwen</forenames></author></authors><title>Wireless Energy Transmission Channel Modeling in Resonant Beam Charging
  for IoT Devices</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power supply for Internet of Things (IoT) devices is one of the bottlenecks
in IoT development. To provide perpetual power supply to IoT devices, resonant
beam charging (RBC) is a promising safe, long-range and high-power wireless
power transfer solution. How long distance can RBC reach and how much power can
RBC transfer? In this paper, we analyze the RBC's consistent and steady
operational conditions, which determine the maximum power transmission
distance. Moreover, we study the power transmission efficiency within the
operational distance, which determines the deliverable power through the RBC
energy transmission channel. Based on this energy transmission channel
modeling, we numerically evaluate its impacts on the RBC system performance in
terms of the transmission distance, the transmission efficiency, and the output
electrical power. The analysis leads to the guidelines for the RBC system
design and implementation, which can deliver multi-Watt power over multi-meter
distance wirelessly for IoT devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.05981</identifier>
 <datestamp>2018-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.05981</id><created>2018-07-11</created><authors><author><keyname>Chambon</keyname><forenames>Stanislas</forenames></author><author><keyname>Thorey</keyname><forenames>Valentin</forenames></author><author><keyname>Arnal</keyname><forenames>Pierrick J.</forenames></author><author><keyname>Mignot</keyname><forenames>Emmanuel</forenames></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames></author></authors><title>A deep learning architecture to detect events in EEG signals during
  sleep</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG) during sleep is used by clinicians to evaluate
various neurological disorders. In sleep medicine, it is relevant to detect
macro-events (&gt; 10s) such as sleep stages, and micro-events (&lt;2s) such as
spindles and K-complexes. Annotations of such events require a trained sleep
expert, a time consuming and tedious process with a large inter-scorer
variability. Automatic algorithms have been developed to detect various types
of events but these are event-specific. We propose a deep learning method that
jointly predicts locations, durations and types of events in EEG time series.
It relies on a convolutional neural network that builds a feature
representation from raw EEG signals. Numerical experiments demonstrate
efficiency of this new approach on various event detection tasks compared to
current state-of-the-art, event specific, algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06089</identifier>
 <datestamp>2018-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06089</id><created>2018-07-16</created><updated>2018-11-15</updated><authors><author><keyname>Schwier</keyname><forenames>Michael</forenames></author><author><keyname>van Griethuysen</keyname><forenames>Joost</forenames></author><author><keyname>Vangel</keyname><forenames>Mark G</forenames></author><author><keyname>Pieper</keyname><forenames>Steve</forenames></author><author><keyname>Peled</keyname><forenames>Sharon</forenames></author><author><keyname>Tempany</keyname><forenames>Clare M</forenames></author><author><keyname>Aerts</keyname><forenames>Hugo JWL</forenames></author><author><keyname>Kikinis</keyname><forenames>Ron</forenames></author><author><keyname>Fennessy</keyname><forenames>Fiona M</forenames></author><author><keyname>Fedorov</keyname><forenames>Andrey</forenames></author></authors><title>Repeatability of Multiparametric Prostate MRI Radiomics Features</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we assessed the repeatability of the values of radiomics
features for small prostate tumors using test-retest Multiparametric Magnetic
Resonance Imaging (mpMRI) images. The premise of radiomics is that quantitative
image features can serve as biomarkers characterizing disease. For such
biomarkers to be useful, repeatability is a basic requirement, meaning its
value must remain stable between two scans, if the conditions remain stable. We
investigated repeatability of radiomics features under various preprocessing
and extraction configurations including various image normalization schemes,
different image pre-filtering, 2D vs 3D texture computation, and different bin
widths for image discretization. Image registration as means to re-identify
regions of interest across time points was evaluated against human-expert
segmented regions in both time points. Even though we found many radiomics
features and preprocessing combinations with a high repeatability (Intraclass
Correlation Coefficient (ICC) &gt; 0.85), our results indicate that overall the
repeatability is highly sensitive to the processing parameters (under certain
configurations, it can be below 0.0). Image normalization, using a variety of
approaches considered, did not result in consistent improvements in
repeatability. There was also no consistent improvement of repeatability
through the use of pre-filtering options, or by using image registration
between timepoints to improve consistency of the region of interest
localization. Based on these results we urge caution when interpreting
radiomics features and advise paying close attention to the processing
configuration details of reported results. Furthermore, we advocate reporting
all processing details in radiomics studies and strongly recommend making the
implementation available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06112</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06112</id><created>2018-07-16</created><authors><author><keyname>Yoo</keyname><forenames>Seong Ki</forenames></author><author><keyname>Cotton</keyname><forenames>Simon L.</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author><author><keyname>Badarneh</keyname><forenames>Osamah S.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Entropy and Energy Detection-based Spectrum Sensing over F Composite
  Fading Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>30 pages, 11 figures, 1 table, Submitted to IEEE TCOM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the performance of energy detection-based
spectrum sensing over F composite fading channels. To this end, an analytical
expression for the average detection probability is firstly derived. This
expression is then extended to account for collaborative spectrum sensing,
square-law selection diversity reception and noise power uncertainty. The
corresponding receiver operating characteristics (ROC) are analyzed for
different conditions of the average signal-to-noise ratio (SNR), noise power
uncertainty, time-bandwidth product, multipath fading, shadowing, number of
diversity branches and number of collaborating users. It is shown that the
energy detection performance is sensitive to the severity of the multipath
fading and amount of shadowing, whereby even small variations in either of
these physical phenomena can significantly impact the detection probability. As
a figure of merit to evaluate the detection performance, the area under the ROC
curve (AUC) is derived and evaluated for different multipath fading and
shadowing conditions. Closed-form expressions for the Shannon entropy and cross
entropy are also formulated and assessed for different average SNR, multipath
fading and shadowing conditions. Then the relationship between the Shannon
entropy and ROC/AUC is examined where it is found that the average number of
bits required for encoding a signal becomes small (i.e., low Shannon entropy)
when the detection probability is high or when the AUC is large. The difference
between composite and traditional small-scale fading is emphasized by comparing
the cross entropy for Rayleigh and Nakagami-m fading. A validation of the
analytical results is provided through a careful comparison with the results of
some simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06143</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06143</id><created>2018-07-16</created><authors><author><keyname>Zou</keyname><forenames>Shaofeng</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Quickest Detection of Dynamic Events in Networks</title><categories>eess.SP cs.IT math.IT stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of quickest detection of dynamic events in networks is studied.
At some unknown time, an event occurs, and a number of nodes in the network are
affected by the event, in that they undergo a change in the statistics of their
observations. It is assumed that the event is dynamic, in that it can propagate
along the edges in the network, and affect more and more nodes with time. The
event propagation dynamics is assumed to be unknown. The goal is to design a
sequential algorithm that can detect a &quot;significant&quot; event, i.e., when the
event has affected no fewer than $\eta$ nodes, as quickly as possible, while
controlling the false alarm rate. Fully connected networks are studied first,
and the results are then extended to arbitrarily connected networks. The
designed algorithms are shown to be adaptive to the unknown propagation
dynamics, and their first-order asymptotic optimality is demonstrated as the
false alarm rate goes to zero. The algorithms can be implemented with linear
computational complexity in the network size at each time step, which is
critical for online implementation. Numerical simulations are provided to
validate the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06190</identifier>
 <datestamp>2018-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06190</id><created>2018-07-16</created><updated>2018-10-24</updated><authors><author><keyname>Manzanilla-Salazar</keyname><forenames>Orestes</forenames><affiliation>Polytechnique Montr&#xe9;al</affiliation></author><author><keyname>Sans&#xf2;</keyname><forenames>Brunilde</forenames><affiliation>Polytechnique Montr&#xe9;al</affiliation></author></authors><title>Privacy-preserving classifiers recognize shared mobility behaviours from
  WiFi network imperfect data</title><categories>eess.SP cs.CR cs.LG stat.AP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><msc-class>62P30</msc-class><acm-class>I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proves the concept that it is feasible to accurately recognize
specific human mobility shared patterns, based solely on the connection logs
between portable devices and WiFi Access Points (APs), while preserving user's
privacy. We gathered data from the Eduroam WiFi network of Polytechnique
Montreal, making omission of device tracking or physical layer data. The
behaviors we chose to detect were the movements associated to the end of an
academic class, and the patterns related to the small break periods between
classes. Stringent conditions were self-imposed in our experiments. The data is
known to have errors noise, and be susceptible to information loss. No
countermeasures were adopted to mitigate any of these issues. Data
pre-processing consists of basic statistics that were used in aggregating the
data in time intervals. We obtained accuracy values of 93.7 % and 83.3 % (via
Bagged Trees) when recognizing behaviour patterns of breaks between classes and
end-of-classes, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06244</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06244</id><created>2018-07-17</created><updated>2019-08-30</updated><authors><author><keyname>Dumas</keyname><forenames>Thierry</forenames><affiliation>Sirocco</affiliation></author><author><keyname>Roumy</keyname><forenames>Aline</forenames><affiliation>Sirocco</affiliation></author><author><keyname>Guillemot</keyname><forenames>Christine</forenames><affiliation>Sirocco</affiliation></author></authors><title>Context-adaptive neural network based prediction for image compression</title><categories>cs.NE eess.IV</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a set of neural network architectures, called Prediction
Neural Networks Set (PNNS), based on both fully-connected and convolutional
neural networks, for intra image prediction. The choice of neural network for
predicting a given image block depends on the block size, hence does not need
to be signalled to the decoder. It is shown that, while fully-connected neural
networks give good performance for small block sizes, convolutional neural
networks provide better predictions in large blocks with complex textures.
Thanks to the use of masks of random sizes during training, the neural networks
of PNNS well adapt to the available context that may vary, depending on the
position of the image block to be predicted. When integrating PNNS into a H.265
codec, PSNR-rate performance gains going from 1.46% to 5.20% are obtained.
These gains are on average 0.99% larger than those of prior neural network
based methods. Unlike the H.265 intra prediction modes, which are each
specialized in predicting a specific texture, the proposed PNNS can model a
large set of complex textures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06303</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06303</id><created>2018-07-17</created><authors><author><keyname>Wang</keyname><forenames>Ziqiang</forenames></author><author><keyname>Xu</keyname><forenames>Hegen</forenames></author><author><keyname>Wan</keyname><forenames>Youwen</forenames></author></authors><title>Wheeled Robots Path Planing and Tracking System Based on Monocular
  Visual SLAM</title><categories>cs.RO eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Warehouse logistics robots will work in different warehouse environments. In
order to enable robots to perceive environment and plan path faster without
modifying existing warehouses, we uses monocular camera to achieve an efficient
robot integrated system. Mapping and path planning the two main tasks presented
in this paper. The direct method visual odometry is applied to localize, and
the 3D position of major obstacles in the environment is calculated. We
describe the terrain with occupied grid map, the 3D points are projected onto
the robot motion plane, thus accessibility of each grid is determined. Based on
the terrain information, the optimized A* algorithm is used for path planning.
Finally, according to localization and planning, we control the robot to track
path. We also develop a path-tracking robot prototype. Simulation and
experimental results verify the effectiveness and reliability of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06324</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06324</id><created>2018-07-17</created><authors><author><keyname>Park</keyname><forenames>Junhyeong</forenames></author><author><keyname>Park</keyname><forenames>Seungwoon</forenames></author><author><keyname>Park</keyname><forenames>Seong-Ook</forenames></author></authors><title>Leakage Mitigation and Internal Delay Compensation in FMCW Radar for
  Small Drone Detection</title><categories>eess.SP</categories><comments>11 pages, 12 figures, 3 tables, This work has been presented in part
  at 2017 International Symposium on Antennas and Propagation (ISAP), Phuket,
  2017</comments><journal-ref>An upgraded version is arXiv:1809.06708, and the upgraded version
  has been published in IEEE Transactions on Microwave Theory and Techniques (
  Volume: 67 , Issue: 3 , March 2019 )</journal-ref><doi>10.1109/TMTT.2018.2889045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the notorious problems of frequency modulated continuous-wave (FMCW)
radar is leakage between the transmitter and the receiver. The phase noise of
the leakage is expressed as a skirt around the leakage signal on power
spectrum. It causes the deterioration of the dynamic range, especially, in the
near-distance region. Therefore, although FMCW radar has an advantage over
pulse radar in terms of near-distance target detection due to its way of
operation, the advantage of FMCW radar can be lost because of the leakage.
Another problem of FMCW radar is internal delay in the radar system. It leads
to the decrease of the maximum detectable range. In this paper, a novel
down-conversion technique which resolves these problems is proposed. Detailed
theory and procedures to implement the proposed technique are explained. Then,
performances of it are verified with the experiment results. The proposed
technique can be implemented through frequency planning and digital signal
processing without additional parts. The results show that the proposed
technique lowers the noise floor about 7.0 dB in the near-distance region and
2.1 dB even in the far-distance region. Also, the results demonstrate the
proposed technique recover the reduced maximum detectable range by compensating
the internal delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06391</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06391</id><created>2018-07-17</created><authors><author><keyname>Dorfer</keyname><forenames>Matthias</forenames></author><author><keyname>Henkel</keyname><forenames>Florian</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Learning to Listen, Read, and Follow: Score Following as a Reinforcement
  Learning Game</title><categories>cs.AI cs.LG cs.SD eess.AS</categories><comments>Published in the Proceedings of the 19th International Society for
  Music Information Retrieval Conference, Paris, France, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Score following is the process of tracking a musical performance (audio) with
respect to a known symbolic representation (a score). We start this paper by
formulating score following as a multimodal Markov Decision Process, the
mathematical foundation for sequential decision making. Given this formal
definition, we address the score following task with state-of-the-art deep
reinforcement learning (RL) algorithms such as synchronous advantage actor
critic (A2C). In particular, we design multimodal RL agents that simultaneously
learn to listen to music, read the scores from images of sheet music, and
follow the audio along in the sheet, in an end-to-end fashion. All this
behavior is learned entirely from scratch, based on a weak and potentially
delayed reward signal that indicates to the agent how close it is to the
correct position in the score. Besides discussing the theoretical advantages of
this learning paradigm, we show in experiments that it is in fact superior
compared to previously proposed methods for score following in raw sheet music
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06434</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06434</id><created>2018-07-13</created><authors><author><keyname>Abdelfattah</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Han</keyname><forenames>David</forenames></author><author><keyname>Bitar</keyname><forenames>Andrew</forenames></author><author><keyname>DiCecco</keyname><forenames>Roberto</forenames></author><author><keyname>OConnell</keyname><forenames>Shane</forenames></author><author><keyname>Shanker</keyname><forenames>Nitika</forenames></author><author><keyname>Chu</keyname><forenames>Joseph</forenames></author><author><keyname>Prins</keyname><forenames>Ian</forenames></author><author><keyname>Fender</keyname><forenames>Joshua</forenames></author><author><keyname>Ling</keyname><forenames>Andrew C.</forenames></author><author><keyname>Chiu</keyname><forenames>Gordon R.</forenames></author></authors><title>DLA: Compiler and FPGA Overlay for Neural Network Inference Acceleration</title><categories>cs.DC cs.AR eess.SP</categories><comments>Accepted in the International Conference on Field-Programmable Logic
  and Applications (FPL 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Overlays have shown significant promise for field-programmable gate-arrays
(FPGAs) as they allow for fast development cycles and remove many of the
challenges of the traditional FPGA hardware design flow. However, this often
comes with a significant performance burden resulting in very little adoption
of overlays for practical applications. In this paper, we tailor an overlay to
a specific application domain, and we show how we maintain its full
programmability without paying for the performance overhead traditionally
associated with overlays. Specifically, we introduce an overlay targeted for
deep neural network inference with only ~1% overhead to support the control and
reprogramming logic using a lightweight very-long instruction word (VLIW)
network. Additionally, we implement a sophisticated domain specific graph
compiler that compiles deep learning languages such as Caffe or Tensorflow to
easily target our overlay. We show how our graph compiler performs
architecture-driven software optimizations to significantly boost performance
of both convolutional and recurrent neural networks (CNNs/RNNs) - we
demonstrate a 3x improvement on ResNet-101 and a 12x improvement for long
short-term memory (LSTM) cells, compared to naive implementations. Finally, we
describe how we can tailor our hardware overlay, and use our graph compiler to
achieve ~900 fps on GoogLeNet on an Intel Arria 10 1150 - the fastest ever
reported on comparable FPGAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06441</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06441</id><created>2018-07-12</created><authors><author><keyname>Vanek</keyname><forenames>Jan</forenames></author><author><keyname>Michalek</keyname><forenames>Josef</forenames></author><author><keyname>Zelinka</keyname><forenames>Jan</forenames></author><author><keyname>Psutka</keyname><forenames>Josef</forenames></author></authors><title>A Comparison of Adaptation Techniques and Recurrent Neural Network
  Architectures</title><categories>eess.AS cs.CL cs.SD</categories><comments>submitted and accepted to SLSP 2018 conference. arXiv admin note:
  text overlap with arXiv:1806.07186, arXiv:1806.07974</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, recurrent neural networks have become state-of-the-art in acoustic
modeling for automatic speech recognition. The long short-term memory (LSTM)
units are the most popular ones. However, alternative units like gated
recurrent unit (GRU) and its modifications outperformed LSTM in some
publications. In this paper, we compared five neural network (NN) architectures
with various adaptation and feature normalization techniques. We have evaluated
feature-space maximum likelihood linear regression, five variants of i-vector
adaptation and two variants of cepstral mean normalization. The most adaptation
and normalization techniques were developed for feed-forward NNs and, according
to results in this paper, not all of them worked also with RNNs. For
experiments, we have chosen a well known and available TIMIT phone recognition
task. The phone recognition is much more sensitive to the quality of AM than
large vocabulary task with a complex language model. Also, we published the
open-source scripts to easily replicate the results and to help continue the
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06446</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06446</id><created>2018-07-13</created><authors><author><keyname>Yang</keyname><forenames>Haoyu</forenames></author><author><keyname>Li</keyname><forenames>Shuhe</forenames></author><author><keyname>Tabery</keyname><forenames>Cyrus</forenames></author><author><keyname>Lin</keyname><forenames>Bingqing</forenames></author><author><keyname>Yu</keyname><forenames>Bei</forenames></author></authors><title>Bridging the Gap Between Layout Pattern Sampling and Hotspot Detection
  via Batch Active Learning</title><categories>cs.LG eess.IV stat.ML</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Layout hotpot detection is one of the main steps in modern VLSI design. A
typical hotspot detection flow is extremely time consuming due to the
computationally expensive mask optimization and lithographic simulation. Recent
researches try to facilitate the procedure with a reduced flow including
feature extraction, training set generation and hotspot detection, where
feature extraction methods and hotspot detection engines are deeply studied.
However, the performance of hotspot detectors relies highly on the quality of
reference layout libraries which are costly to obtain and usually predetermined
or randomly sampled in previous works. In this paper, we propose an active
learning-based layout pattern sampling and hotspot detection flow, which
simultaneously optimizes the machine learning model and the training set that
aims to achieve similar or better hotspot detection performance with much
smaller number of training instances. Experimental results show that our
proposed method can significantly reduce lithography simulation overhead while
attaining satisfactory detection accuracy on designs under both DUV and EUV
lithography technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06458</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06458</id><created>2018-07-17</created><authors><author><keyname>Ayaz</keyname><forenames>Ferheen</forenames></author><author><keyname>Rabie</keyname><forenames>Khaled</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author></authors><title>Analysis of Optimized Threshold with SLM based Blanking Non-Linearity
  for Impulsive Noise Reduction in Power Line Communication Systems</title><categories>eess.SP cs.NI</categories><comments>Accepted in 11th IEEE/IET International Symposium on Communication
  Systems, Networks, and Digital Signal Processing. Consists of 6 pages and 5
  figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  High amplitude impulsive noise (IN) occurrence over power line channels
severely degrades the performance of Orthogonal Frequency Division Multiplexing
(OFDM)systems. One of the simplest methods to reduce IN is to precede the OFDM
demodulator with a blanking non-linearity processor. In this respect, Selective
Mapping (SLM) applied to an OFDM signal before the transmitter does not only
reduce Peak-to-Average Power Ratio (PAPR) but also increases the resulting
Signal-to-Noise Ratio (SNR) when blanking nonlinearity is applied at the
receiver. This paper highlights another advantage of SLM based IN reduction,
which is the reduced dependency on threshold used for blanking nonlinearity.
The simulation results show that the optimal threshold to achieve maximum SNR
is found to be constant for phase vectors greater than or equal to 64 in the
SLM scheme. If the optimized threshold calculation method is used, the output
SNR with SLM OFDM will result in SNR gains of up to 8.6dB compared to the
unmodified system, i.e. without implementing SLM. Moreover, by using SLM, we
not only get the advantage of low peak power, but also the need to calculate
optimized threshold is eliminated, thereby reducing the additional computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06461</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06461</id><created>2018-07-17</created><authors><author><keyname>Cerovi&#x107;</keyname><forenames>Stefan</forenames></author><author><keyname>Visoz</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Madier</keyname><forenames>Louis</forenames></author><author><keyname>Berthet</keyname><forenames>Antoine O.</forenames></author></authors><title>Centralized Scheduling Strategies for Cooperative HARQ Retransmissions
  in Multi-Source Multi-Relay Wireless Networks</title><categories>eess.SP</categories><doi>10.1109/ICC.2018.8422578</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate centralized scheduling strategies for
cooperative incremental redundancy retransmissions in the slow-fading
half-duplex multiple access multiple relay channel. Time Division Multiple
Access is assumed for the sources and the relays. Sources transmit successively
in time slots for the first phase. The second phase consists of a limited
number of time slots for retransmissions. In each time slot, the destination
schedules a node (being a relay or a source) to retransmit, conditional on the
knowledge of the correctly decoded source sets of each node (which is itself
for a source). A scheduled relay retransmission uses Joint Network and Channel
Coding on its correctly decoded source messages (cooperative retransmission).
Several node selection strategies are proposed based on the maximization of the
long-term aggregate throughput under a given constraint of fairness.
Monte-Carlo simulations show that these strategies outperform the state of the
art one based on the minimization of the probability of the common outage event
after each time-slot. Moreover, the long-term aggregate throughput reached with
these strategies is close to the upper-bound, calculated by the exhaustive
search approach. The same conclusion remains valid for both symmetric and
asymmetric source rate scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06480</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06480</id><created>2018-07-17</created><authors><author><keyname>Chen</keyname><forenames>Lingji</forenames></author></authors><title>Roos' Matrix Permanent Approximation Bounds for Data Association
  Probabilities</title><categories>eess.SP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix permanent plays a key role in data association probability
calculations. Exact algorithms (such as Ryser's) scale exponentially with
matrix size. Fully polynomial time randomized approximation schemes exist but
are quite complex. This letter introduces to the tracking community a simple
approximation algorithm with error bounds, recently developed by Bero Roos, and
illustrates its potential use for estimating probabilities of data association
hypotheses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06518</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06518</id><created>2018-07-17</created><authors><author><keyname>Lorenzini</keyname><forenames>Charles</forenames></author><author><keyname>Pereira</keyname><forenames>Lu&#xed;s Fernando Alves</forenames></author><author><keyname>Bazanella</keyname><forenames>Alexandre Sanfelice</forenames></author></authors><title>A Generalized Forced Oscillation Method for tuning Proportional Resonant
  Controllers</title><categories>eess.SP</categories><comments>12 pages, 12 figures, 15 tables, Preprint submitted to IEEE
  Transactions on Control Systems Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a tuning methodology for proportional resonant (PR)
controllers by using the design philosophy of the Ziegler-Nichols forced
oscillation method. Unlike such related methods that are usual for PID design,
and those that have been recently proposed for PR controllers, the method in
this paper is not restricted to plants whose Nyquist diagram crosses the
negative real axis. It involves a feedback experiment with a relay of
adjustable phase, which allows the identification of the most appropriate point
of the frequency response for each class of plants. The validation of the
proposed method, which includes the identification experiment and specific
tuning formulas that provide appropriate stability margins for each class of
plants, is performed by means of numerical examples in a large variety of
plants, showing its wide applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06610</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06610</id><created>2018-07-17</created><authors><author><keyname>Liang</keyname><forenames>Davis</forenames></author><author><keyname>Huang</keyname><forenames>Zhiheng</forenames></author><author><keyname>Lipton</keyname><forenames>Zachary C.</forenames></author></authors><title>Learning Noise-Invariant Representations for Robust Speech Recognition</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Under Review at IEEE SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite rapid advances in speech recognition, current models remain brittle
to superficial perturbations to their inputs. Small amounts of noise can
destroy the performance of an otherwise state-of-the-art model. To harden
models against background noise, practitioners often perform data augmentation,
adding artificially-noised examples to the training set, carrying over the
original label. In this paper, we hypothesize that a clean example and its
superficially perturbed counterparts shouldn't merely map to the same class ---
they should map to the same representation. We propose
invariant-representation-learning (IRL): At each training iteration, for each
training example,we sample a noisy counterpart. We then apply a penalty term to
coerce matched representations at each layer (above some chosen layer). Our key
results, demonstrated on the Librispeech dataset are the following: (i) IRL
significantly reduces character error rates (CER) on both 'clean' (3.3% vs
6.5%) and 'other' (11.0% vs 18.1%) test sets; (ii) on several out-of-domain
noise settings (different from those seen during training), IRL's benefits are
even more pronounced. Careful ablations confirm that our results are not simply
due to shrinking activations at the chosen layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06663</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06663</id><created>2018-07-17</created><authors><author><keyname>Shon</keyname><forenames>Suwon</forenames></author><author><keyname>Dehak</keyname><forenames>Najim</forenames></author><author><keyname>Reynolds</keyname><forenames>Douglas</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>MCE 2018: The 1st Multi-target Speaker Detection and Identification
  Challenge Evaluation (MCE) Plan, Dataset and Baseline System</title><categories>eess.AS cs.SD</categories><comments>MCE 2018 Plan (http://mce.csail.mit.edu)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Multitarget Challenge aims to assess how well current speech technology
is able to determine whether or not a recorded utterance was spoken by one of a
large number of 'blacklisted' speakers. It is a form of multi-target speaker
detection based on real-world telephone conversations. Data recordings are
generated from call center customer-agent conversations. Each conversation is
represented by a single i-vector. Given a pool of training and development data
from non-Blacklist and Blacklist speakers, the task is to measure how
accurately one can detect 1) whether a test recording is spoken by a Blacklist
speaker, and 2) which specific Blacklist speaker was talking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06700</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06700</id><created>2018-07-17</created><authors><author><keyname>Sears</keyname><forenames>David R. W.</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Psychological constraints on string-based methods for pattern discovery
  in polyphonic corpora</title><categories>cs.SD eess.AS</categories><comments>Extended abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers often divide symbolic music corpora into contiguous sequences of
n events (called n-grams) for the purposes of pattern discovery, key finding,
classification, and prediction. What is more, several studies have reported
improved task performance when using psychologically motivated weighting
functions, which adjust the count to privilege n-grams featuring more salient
or memorable events (e.g., Krumhansl, 1990). However, these functions have yet
to appear in harmonic pattern discovery algorithms, which attempt to discover
the most recurrent chord progressions in complex polyphonic corpora. This study
examines whether psychologically-motivated weighting functions can improve
harmonic pattern discovery algorithms. Models using various n-gram selection
methods, weighting functions, and ranking algorithms attempt to discover the
most conventional closing harmonic progression in the common-practice period,
ii6-&quot;I64&quot;-V7-I, with the progression's mean reciprocal rank serving as an
evaluation metric for model comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06706</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06706</id><created>2018-07-17</created><authors><author><keyname>Axon</keyname><forenames>Louise M.</forenames></author><author><keyname>Alahmadi</keyname><forenames>Bushra</forenames></author><author><keyname>Nurse</keyname><forenames>Jason R. C.</forenames></author><author><keyname>Goldsmith</keyname><forenames>Michael</forenames></author><author><keyname>Creese</keyname><forenames>Sadie</forenames></author></authors><title>Sonification in security operations centres: what do security
  practitioners think?</title><categories>cs.HC cs.CR cs.SD eess.AS</categories><acm-class>K.6.5; H.5.5</acm-class><journal-ref>Workshop on Usable Security (USEC) at the Network and Distributed
  System Security (NDSS) Symposium 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Security Operations Centres (SOCs) security practitioners work using a
range of tools to detect and mitigate malicious computer-network activity.
Sonification, in which data is represented as sound, is said to have potential
as an approach to addressing some of the unique challenges faced by SOCs. For
example, sonification has been shown to enable peripheral monitoring of
processes, which could aid practitioners multitasking in busy SOCs. The
perspectives of security practitioners on incorporating sonification into their
actual working environments have not yet been examined, however. The aim of
this paper therefore is to address this gap by exploring attitudes to using
sonification in SOCs. We report on the results of a study consisting of an
online survey (N=20) and interviews (N=21) with security practitioners working
in a range of different SOCs. Our contribution is a refined appreciation of the
contexts in which sonification could aid in SOC working practice, and an
understanding of the areas in which sonification may not be beneficial or may
even be problematic.We also analyse the critical requirements for the design of
sonification systems and their integration into the SOC setting. Our findings
clarify insights into the potential benefits and challenges of introducing
sonification to support work in this vital security-monitoring environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06716</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06716</id><created>2018-07-17</created><authors><author><keyname>Zhang</keyname><forenames>Xuejing</forenames></author><author><keyname>He</keyname><forenames>Zishu</forenames></author><author><keyname>Zhang</keyname><forenames>Xuepan</forenames></author></authors><title>Pattern Synthesis via Complex-Coefficient Weight Vector Orthogonal
  Decomposition--Part I: Fundamentals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new array response control scheme named
complex-coefficient weight vector orthogonal decomposition ($
\textrm{C}^2\textrm{-WORD} $) and its application to pattern synthesis. The
proposed $ \textrm{C}^2\textrm{-WORD} $ algorithm is a modified version of the
existing WORD approach. We extend WORD by allowing a complex-valued combining
coefficient in $ \textrm{C}^2\textrm{-WORD} $, and find the optimal combining
coefficient by maximizing white noise gain (WNG). Our algorithm offers a
closed-from expression to precisely control the array response level of a given
point starting from an arbitrarily-specified weight vector. In addition, it
results less pattern variations on the uncontrolled angles. Elaborate analysis
shows that the proposed $ \textrm{C}^2\textrm{-WORD} $ scheme performs at least
as good as the state-of-the-art $\textrm{A}^\textrm{2}\textrm{RC} $ or WORD
approach. By applying $ \textrm{C}^2\textrm{-WORD} $ successively, we present a
flexible and effective approach to pattern synthesis. Numerical examples are
provided to demonstrate the flexibility and effectiveness of $
\textrm{C}^2\textrm{-WORD} $ in array response control as well as pattern
synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06721</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06721</id><created>2018-07-17</created><authors><author><keyname>Zhang</keyname><forenames>Xuejing</forenames></author><author><keyname>He</keyname><forenames>Zishu</forenames></author><author><keyname>Zhang</keyname><forenames>Xuepan</forenames></author></authors><title>Pattern Synthesis via Complex-Coefficient Weight Vector Orthogonal
  Decomposition--Part II: Robust Sidelobe Synthesis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the complex-coefficient weight vector orthogonal decomposition
($ \textrm{C}^2\textrm{-WORD} $) algorithm proposed in Part I of this two paper
series is extended to robust sidelobe control and synthesis with steering
vector mismatch. Assuming that the steering vector uncertainty is norm-bounded,
we obtain the worst-case upper and lower boundaries of array response. Then, we
devise a robust $ \textrm{C}^2\textrm{-WORD} $ algorithm to control the
response of a sidelobe point by precisely adjusting its upper-boundary response
level as desired. To enhance the practicality of the proposed robust $
\textrm{C}^2\textrm{-WORD} $ algorithm, we also present detailed analyses on
how to determine the upper norm boundary of steering vector uncertainty under
various mismatch circumstances. By applying the robust $
\textrm{C}^2\textrm{-WORD} $ algorithm iteratively, a robust sidelobe synthesis
approach is developed. In this approach, the upper-boundary response is
adjusted in a point-by-point manner by successively updating the weight vector.
Contrary to the existing approaches, the devised robust $
\textrm{C}^2\textrm{-WORD} $ algorithm has an analytical expression and can
work starting from an arbitrarily-specified weight vector. Simulation results
are presented to validate the effectiveness and good performance of the robust
$ \textrm{C}^2\textrm{-WORD} $ algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06736</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06736</id><created>2018-07-17</created><authors><author><keyname>Zhang</keyname><forenames>Jing-Xuan</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author><author><keyname>Dai</keyname><forenames>Li-Rong</forenames></author></authors><title>Forward Attention in Sequence-to-sequence Acoustic Modelling for Speech
  Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>5 pages, 3 figures, 2 tables. Published in IEEE International
  Conference on Acoustics, Speech and Signal Processing 2018 (ICASSP2018)</comments><journal-ref>IEEE International Conference on Acoustics, Speech and Signal
  Processing (2018) 4789-4793</journal-ref><doi>10.1109/ICASSP.2018.8462020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a forward attention method for the sequenceto- sequence
acoustic modeling of speech synthesis. This method is motivated by the nature
of the monotonic alignment from phone sequences to acoustic sequences. Only the
alignment paths that satisfy the monotonic condition are taken into
consideration at each decoder timestep. The modified attention probabilities at
each timestep are computed recursively using a forward algorithm. A transition
agent for forward attention is further proposed, which helps the attention
mechanism to make decisions whether to move forward or stay at each decoder
timestep. Experimental results show that the proposed forward attention method
achieves faster convergence speed and higher stability than the baseline
attention method. Besides, the method of forward attention with transition
agent can also help improve the naturalness of synthetic speech and control the
speed of synthetic speech effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06767</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06767</id><created>2018-07-17</created><authors><author><keyname>Hillyard</keyname><forenames>Peter</forenames></author><author><keyname>Luong</keyname><forenames>Anh</forenames></author><author><keyname>Abrar</keyname><forenames>Alemayehu Solomon</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Sundar</keyname><forenames>Krishna</forenames></author><author><keyname>Farney</keyname><forenames>Robert</forenames></author><author><keyname>Burch</keyname><forenames>Jason</forenames></author><author><keyname>Porucznik</keyname><forenames>Christina A.</forenames></author><author><keyname>Pollard</keyname><forenames>Sarah Hatch</forenames></author></authors><title>Comparing Respiratory Monitoring Performance of Commercial Wireless
  Devices</title><categories>eess.SP physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the performance of systems which use commercial wireless
devices to make bistatic RF channel measurements for non-contact respiration
sensing. Published research has typically presented results from short
controlled experiments on one system. In this paper, we deploy an extensive
real-world comparative human subject study. We observe twenty patients during
their overnight sleep (a total of 160 hours), during which contact sensors
record ground-truth breathing data, patient position is recorded, and four
different RF breathing monitoring systems simultaneously record measurements.
We evaluate published methods and algorithms. We find that WiFi channel state
information measurements provide the most robust respiratory rate estimates of
the four RF systems tested. However, all four RF systems have periods during
which RF-based breathing estimates are not reliable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06785</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06785</id><created>2018-07-18</created><authors><author><keyname>Ibrahim</keyname><forenames>Ahmed</forenames></author><author><keyname>Eltawil</keyname><forenames>Ahmed</forenames></author><author><keyname>Na</keyname><forenames>Yunsu</forenames></author><author><keyname>El-Tawil</keyname><forenames>Sherif</forenames></author></authors><title>Effect of Sensor Error on the Assessment of Seismic Building Damage</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural disasters affect structural health of buildings, thus directly
impacting public safety. Continuous structural monitoring can be achieved by
deploying an internet of things (IoT) network of distributed sensors in
buildings to capture floor movement. These sensors can be used to compute the
displacements of each floor, which can then be employed to assess building
damage after a seismic event. The peak relative floor displacement is computed,
which is directly related to damage level according to government standards.
With this information, the building inventory can be classified into immediate
occupancy (IO), life safety (LS) or collapse prevention (CP) categories. In
this work, we propose a zero velocity update (ZUPT) technique to minimize
displacement estimation error. Theoretical derivation and experimental
validation are presented. In addition, we investigate modeling sensor error and
interstory drift ratio (IDR) distribution. Moreover, we discuss the impact of
sensor error on the achieved building classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06811</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06811</id><created>2018-07-18</created><authors><author><keyname>Atif</keyname><forenames>Syed Muhammad</forenames></author><author><keyname>Ahmed</keyname><forenames>Anees</forenames></author><author><keyname>Qazi</keyname><forenames>Sameer</forenames></author></authors><title>Tri-Compress: A Cascaded Data Compression Framework for Smart
  Electricity Distribution Systems</title><categories>eess.SP</categories><comments>6 pages, 9 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern smart distribution system requires storage, transmission and
processing of big data generated by sensors installed in electric meters. On
one hand, this data is essentially required for intelligent decision making by
smart grid but on the other hand storage, transmission and processing of that
huge amount of data is also a challenge. Present approaches to compress this
information have only relied on the traditional matrix decomposition techniques
benefitting from low number of principal components to represent the entire
data. This paper proposes a cascaded data compression technique that blends
three different methods in order to achieve high compression rate for efficient
storage and transmission. In the first and second stages, two lossy data
compression techniques are used, namely Singular Value Decomposition (SVD) and
Normalization; Third stage achieves further compression by using the technique
of Sparsity Encoding (SE) which is a lossless compression technique but only
having appreciable benefits for sparse data sets. Our simulation results show
that the combined use of the 3 techniques achieves data compression ratio to be
15% higher than state of the art SVD for small, sparse datasets and up to 28%
higher in large, non-sparse datasets with acceptable Mean Absolute Error (MAE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06826</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06826</id><created>2018-07-18</created><authors><author><keyname>Ge</keyname><forenames>Nan</forenames></author><author><keyname>Gonzalez</keyname><forenames>Fernando Rodriguez</forenames></author><author><keyname>Wang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Shi</keyname><forenames>Yilei</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Spaceborne Staring Spotlight SAR Tomography - A First Demonstration with
  TerraSAR-X</title><categories>eess.SP</categories><comments>Accepted publication in IEEE Journal of Selected Topics in Applied
  Earth Observations and Remote Sensing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the objective of exploiting hardware capabilities and preparing the
ground for the next-generation X-band synthetic aperture radar (SAR) missions,
TerraSAR-X and TanDEM-X are now able to operate in staring spotlight mode,
which is characterized by an increased azimuth resolution of approximately 0.24
m compared to 1.1 m of the conventional sliding spotlight mode. In this paper,
we demonstrate for the first time its potential for SAR tomography. To this
end, we tailored our interferometric and tomographic processors for the
distinctive features of the staring spotlight mode, which will be analyzed
accordingly. By means of its higher spatial resolution, the staring spotlight
mode will not only lead to a denser point cloud, but also to more accurate
height estimates due to the higher signal-to-clutter ratio. As a result of a
first comparison between sliding and staring spotlight TomoSAR, the following
were observed: 1) the density of the staring spotlight point cloud is
approximately 5.1--5.5 times as high; 2) the relative height accuracy of the
staring spotlight point cloud is approximately 1.7 times as high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06899</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06899</id><created>2018-07-18</created><authors><author><keyname>Naithani</keyname><forenames>Gaurav</forenames></author><author><keyname>Nikunen</keyname><forenames>Joonas</forenames></author><author><keyname>Bramsl&#xf8;w</keyname><forenames>Lars</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Deep neural network based speech separation optimizing an objective
  estimator of intelligibility for low latency applications</title><categories>cs.SD eess.AS</categories><comments>To appear at International Workshop on Acoustic Signal Enhancement
  (IWAENC) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean square error (MSE) has been the preferred choice as loss function in the
current deep neural network (DNN) based speech separation techniques. In this
paper, we propose a new cost function with the aim of optimizing the extended
short time objective intelligibility (ESTOI) measure. We focus on applications
where low algorithmic latency ($\leq 10$ ms) is important. We use long
short-term memory networks (LSTM) and evaluate our proposed approach on four
sets of two-speaker mixtures from extended Danish hearing in noise (HINT)
dataset. We show that the proposed loss function can offer improved or at par
objective intelligibility (in terms of ESTOI) compared to an MSE optimized
baseline while resulting in lower objective separation performance (in terms of
the source to distortion ratio (SDR)). We then proceed to propose an approach
where the network is first initialized with weights optimized for MSE criterion
and then trained with the proposed ESTOI loss criterion. This approach
mitigates some of the losses in objective separation performance while
preserving the gains in objective intelligibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06912</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06912</id><created>2018-07-18</created><updated>2018-11-28</updated><authors><author><keyname>Duarte</keyname><forenames>Roberto</forenames></author><author><keyname>Repetti</keyname><forenames>Audrey</forenames></author><author><keyname>G&#xf3;mez</keyname><forenames>Pedro A.</forenames></author><author><keyname>Davies</keyname><forenames>Mike</forenames></author><author><keyname>Wiaux</keyname><forenames>Yves</forenames></author></authors><title>Greedy Approximate Projection for Magnetic Resonance Fingerprinting with
  Partial Volumes</title><categories>eess.IV</categories><doi>10.1088/1361-6420/ab356d</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In quantitative Magnetic Resonance Imaging, traditional methods suffer from
the so-called Partial Volume Effect (PVE) due to spatial resolution
limitations. As a consequence of PVE, the parameters of the voxels containing
more than one tissue are not correctly estimated. Magnetic Resonance
Fingerprinting (MRF) is not an exception. The existing methods addressing PVE
are neither scalable nor accurate. We propose to formulate the recovery of
multiple tissues per voxel as a nonconvex constrained least-squares
minimisation problem. To solve this problem, we develop a memory efficient,
greedy approximate projected gradient descent algorithm, dubbed GAP-MRF. Our
method adaptively finds the regions of interest on the manifold of fingerprints
defined by the MRF sequence. We generalise our method to compensate for phase
errors appearing in the model, using an alternating minimisation approach. We
show, through simulations on synthetic data with PVE, that our algorithm
outperforms state-of-the-art methods. Our approach is validated on the EUROSPIN
phantom and on in vivo datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06920</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06920</id><created>2018-07-18</created><updated>2018-11-28</updated><authors><author><keyname>Wu</keyname><forenames>Fangfang</forenames></author><author><keyname>Dong</keyname><forenames>Weisheng</forenames></author><author><keyname>Shi</keyname><forenames>Guangming</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author></authors><title>Learning Hybrid Sparsity Prior for Image Restoration: Where Deep
  Learning Meets Sparse Coding</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art approaches toward image restoration can be classified into
model-based and learning-based. The former - best represented by sparse coding
techniques - strive to exploit intrinsic prior knowledge about the unknown
high-resolution images; while the latter - popularized by recently developed
deep learning techniques - leverage external image prior from some training
dataset. It is natural to explore their middle ground and pursue a hybrid image
prior capable of achieving the best in both worlds. In this paper, we propose a
systematic approach of achieving this goal called Structured Analysis Sparse
Coding (SASC). Specifically, a structured sparse prior is learned from
extrinsic training data via a deep convolutional neural network (in a similar
way to previous learning-based approaches); meantime another structured sparse
prior is internally estimated from the input observation image (similar to
previous model-based approaches). Two structured sparse priors will then be
combined to produce a hybrid prior incorporating the knowledge from both
domains. To manage the computational complexity, we have developed a novel
framework of implementing hybrid structured sparse coding processes by deep
convolutional neural networks. Experimental results show that the proposed
hybrid image restoration method performs comparably with and often better than
the current state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06928</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06928</id><created>2018-06-23</created><authors><author><keyname>Iida</keyname><forenames>Kenta</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Robust Image Identification for Double-Compressed JPEG Images</title><categories>eess.IV cs.IR</categories><comments>This paper was presented at International Conference on
  Communications 2018</comments><doi>10.1587/transinf.2018MUP0007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that JPEG images uploaded to social networks (SNs) are mostly
re-compressed by the social network providers. Because of such a situation, a
new image identification scheme for double-compressed JPEG images is proposed
in this paper. The aim is to detect single-compressed images that have the same
original image as that of a double-compressed one. In the proposed scheme, the
signs of only DC coefficients in DCT coefficients and one threshold value are
used for the identification. The use of them allows us to robustly avoid errors
caused by double-compression, which are not considered in conventional schemes.
The proposed scheme has applications not only to find uploaded images
corresponding to double-compressed ones, but also to detect some image
integrity. The simulation results demonstrate that the proposed one outperforms
conventional ones including state-of-art image hashing one in terms of the
querying performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06931</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06931</id><created>2018-06-24</created><authors><author><keyname>Hosseinianfar</keyname><forenames>Hamid</forenames></author><author><keyname>Chizari</keyname><forenames>Ata</forenames></author><author><keyname>Salehi</keyname><forenames>Jawad A.</forenames></author></authors><title>GOPA: Geometrical Optics Positioning Algorithm Using Spatial Color Coded
  LEDs (Extended Version)</title><categories>eess.SP</categories><comments>10 pages, 11 figures, and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an accurate visible light indoor localization
system for a smartphone using the existing commercial light-emitting diode
(LED) luminaries. The proposed technique, called geometrical optics positioning
algorithm (GOPA), uses spatial color code landmarks alongside angle of arrival
(AOA)-based geometrical algorithm on smartphones to locate the device, and
reserves LED's time-frequency domain modulation to increase the throughput of
the visible light network broadcast from the same luminaries infrastructure.
GOPA algorithm is developed with practical considerations such as flexible hand
gesture and handshake, and it enables both positioning robustness and on-device
processing. By introducing the idea of virtual plane, field of view (FOV) issue
of AOA-based positioning systems is addressed in GOPA. The embedded
accelerometer and front-facing camera of the smartphone are used at the
receiver side to measure the smartphone inclination and acquire the image.
Experimental results show robust two-dimensional ($2$-D) and three-dimensional
($3$-D) positioning. The experimental mean positioning error for $2$-D
positioning is $0.54$ cm, in case one ignoring the tilt. The experimental mean
positioning errors for $3$-D positioning are respectively $1.24$ cm, $1.85$ cm,
and $6.02$ cm for ideal non-tilted and non-oriented, non-tilted but orientated,
and both tilted and orientated scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06942</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06942</id><created>2018-07-18</created><authors><author><keyname>Voorhoeve</keyname><forenames>Robbert</forenames></author><author><keyname>de Rozario</keyname><forenames>Robin</forenames></author><author><keyname>Aangenent</keyname><forenames>Wouter</forenames></author><author><keyname>Oomen</keyname><forenames>Tom</forenames></author></authors><title>Identifying Position-Dependent Mechanical Systems: A Modal Approach with
  Applications to Wafer Stage Control</title><categories>cs.SY eess.SP math.DS math.OC</categories><comments>13 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasingly stringent performance requirements for motion control
necessitate the use of increasingly detailed models of the system behavior.
Motion systems inherently move, therefore, spatio-temporal models of the
flexible dynamics are essential. In this paper, a two-step approach for the
identification of the spatio-temporal behavior of mechanical systems is
developed and applied to a prototype industrial wafer stage with a lightweight
design for fast and highly accurate positioning. The proposed approach exploits
a modal modeling framework and combines recently developed powerful linear time
invariant (LTI) identification tools with a spline-based mode-shape
interpolation approach to estimate the spatial system behavior. The
experimental results for the wafer stage application confirm the suitability of
the proposed approach for the identification of complex position-dependent
mechanical systems, and show the pivotal role of the obtained models for
improved motion control performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06945</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06945</id><created>2018-07-02</created><authors><author><keyname>Banerjee</keyname><forenames>Taposh</forenames></author><author><keyname>Whipps</keyname><forenames>Gene</forenames></author><author><keyname>Gurram</keyname><forenames>Prudhvi</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Cyclostationary Statistical Models and Algorithms for Anomaly Detection
  Using Multi-Modal Data</title><categories>eess.SP cs.LG stat.ME stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A framework is proposed to detect anomalies in multi-modal data. A deep
neural network-based object detector is employed to extract counts of objects
and sub-events from the data. A cyclostationary model is proposed to model
regular patterns of behavior in the count sequences. The anomaly detection
problem is formulated as a problem of detecting deviations from learned
cyclostationary behavior. Sequential algorithms are proposed to detect
anomalies using the proposed model. The proposed algorithms are shown to be
asymptotically efficient in a well-defined sense. The developed algorithms are
applied to a multi-modal data consisting of CCTV imagery and social media posts
to detect a 5K run in New York City.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06966</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06966</id><created>2018-07-17</created><authors><author><keyname>Lunglmayr</keyname><forenames>Michael</forenames></author><author><keyname>Wiesinger</keyname><forenames>Daniel</forenames></author><author><keyname>Haselmayr</keyname><forenames>Werner</forenames></author></authors><title>Design and Analysis of Efficient Maximum/Minimum Circuits for Stochastic
  Computing</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In stochastic computing (SC), a real-valued number is represented by a
stochastic bit stream, encoding its value in the probability of obtaining a
one. This leads to a significantly lower hardware effort for various functions
and provides a higher tolerance to errors (e.g., bit flips) compared to binary
radix representation. The implementation of a stochastic max/min function is
important for many areas where SC has been successfully applied, such as image
processing or machine learning (e.g., max pooling in neural networks). In this
work, we propose a novel shift-register-based architecture for a stochastic
max/min function. We show that the proposed circuit has a significantly higher
accuracy than state-of-the-art architectures at comparable hardware cost.
Moreover, we analytically proof the correctness of the proposed circuit and
provide a new error analysis, based on the individual bits of the stochastic
streams. Interestingly, the analysis reveals that for a certain practical bit
stream length a finite optimal shift register length exists and it allows to
determine the optimal length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06972</identifier>
 <datestamp>2018-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06972</id><created>2018-07-17</created><updated>2018-10-26</updated><authors><author><keyname>Morfi</keyname><forenames>Veronica</forenames></author><author><keyname>Stowell</keyname><forenames>Dan</forenames></author></authors><title>Data-Efficient Weakly Supervised Learning for Low-Resource Audio Event
  Detection Using Deep Learning</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1807.03697</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a method to perform audio event detection under the common
constraint that only limited training data are available. In training a deep
learning system to perform audio event detection, two practical problems arise.
Firstly, most datasets are &quot;weakly labelled&quot; having only a list of events
present in each recording without any temporal information for training.
Secondly, deep neural networks need a very large amount of labelled training
data to achieve good quality performance, yet in practice it is difficult to
collect enough samples for most classes of interest. In this paper, we propose
a data-efficient training of a stacked convolutional and recurrent neural
network. This neural network is trained in a multi instance learning setting
for which we introduce a new loss function that leads to improved training
compared to the usual approaches for weakly supervised learning. We
successfully test our approach on two low-resource datasets that lack temporal
labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06976</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.06976</id><created>2018-07-18</created><authors><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author><author><keyname>Rawat</keyname><forenames>Ankit Singh</forenames></author></authors><title>The Generalized Lasso for Sub-gaussian Measurements with Dithered
  Quantization</title><categories>cs.IT eess.SP math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the problem of structured signal recovery from high-dimensional linear
observations, it is commonly assumed that full-precision measurements are
available. Under this assumption, the recovery performance of the popular
Generalized Lasso (G-Lasso) is by now well-established. In this paper, we
extend these types of results to the practically relevant settings with
quantized measurements. We study two extremes of the quantization schemes,
namely, uniform and one-bit quantization; the former imposes no limit on the
number of quantization bits, while the second only allows for one bit. In the
presence of a uniform dithering signal and when measurement vectors are
sub-gaussian, we show that the same algorithm (i.e., the G-Lasso) has favorable
recovery guarantees for both uniform and one-bit quantization schemes. Our
theoretical results, shed light on the appropriate choice of the range of
values of the dithering signal and accurately capture the error dependence on
the problem parameters. For example, our error analysis shows that the G-Lasso
with one-bit uniformly dithered measurements leads to only a logarithmic rate
loss compared to the full-precision measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07000</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07000</id><created>2018-07-18</created><authors><author><keyname>Mir</keyname><forenames>Mahdi</forenames></author></authors><title>Spectrum accessing optimization in congestion times in radio cognitive
  networks based on chaotic neural networks</title><categories>eess.SP</categories><comments>cognitive radio network, spectrum access, primary user, secondary
  user, chaotic recurrent neural network</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the theory of the Federal Communications Commission, the spectrum
available on cognitive radio networks is limit and the non-optimal use of the
spectrum necessitates the need for a telecommunications model, so that this
pattern can exploit the existing spectral positions. In this spectrum
subscription scenario, when the primary users are not present, it is also
possible to assign this telecommunication to tenants who are unauthorized or
secondary. The challenge of using this scenario is to allocate time-frequency
resources to them and how to access nodes in one channel without any
interactions between primary and secondary users and the throughput will
increase. The main idea of this research is using chaotic recurrent neural
network for improving access to spectrum in congestion times and the main
purposes are reduce interference and increase throughput in cognitive radio
networks. In this method, in addition to the throughput, the amount of unwanted
blockage of packets, the reduction of the cost of operations for secondary
users, the hardware requirements for secondary users and the coefficient of
justice are considered which in fact, it is a new channel assignment process
with respect to the environment response, the updates the probability that the
channels are empty in subsequent periods, and increases the permeability by
reducing interference with chaotic recurrent neural network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07001</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07001</id><created>2018-07-18</created><authors><author><keyname>Hardie</keyname><forenames>Russell C.</forenames></author><author><keyname>Ali</keyname><forenames>Redha</forenames></author><author><keyname>De Silva</keyname><forenames>Manawaduge Supun</forenames></author><author><keyname>Kebede</keyname><forenames>Temesguen Messay</forenames></author></authors><title>Skin Lesion Segmentation and Classification for ISIC 2018 Using
  Traditional Classifiers with Hand-Crafted Features</title><categories>eess.IV cs.CV</categories><comments>ISIC 2018 https://challenge2018.isic-archive.com/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides the required description of the methods used to obtain
submitted results for Task1 and Task 3 of ISIC 2018: Skin Lesion Analysis
Towards Melanoma Detection. The results have been created by a team of
researchers at the University of Dayton Signal and Image Processing Lab. In
this submission, traditional classifiers with hand-crafted features are
utilized for Task 1 and Task 3. Our team is providing additional separate
submissions using deep learning methods for comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07006</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07006</id><created>2018-07-18</created><authors><author><keyname>Mir</keyname><forenames>Mahdi</forenames></author></authors><title>Cruise Missile Target Trajectory Movement Prediction based on Optimal 3D
  Kalman Filter with Firefly Algorithm</title><categories>eess.SP cs.SY</categories><comments>Cruz Missile, Missile Movement Prediction and Trajectory, LQR
  Controller, 3d Kalman Filter, Firefly Algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is hoped that there will never be a war in the world, but one of the
defensive requirements of any country during the war is the missiles used for
destruction and defense. Todays, missiles movement from origin to destination
is an important problem due to abundant application of missiles in wars. This
is important because of the range of some missiles is low and other are very
high. Parametric indeterminacy are several factors in missile movement
prediction and trajectory such as speed, movement angle, accuracy, movement
time, and situation and direct control. So this research trying to provide a
method based on LQR controller with 3d Kalman filter and then set motion and
specify path without deviations based on Firefly Algorithm. It is expected that
the results of an appropriate evaluation can be obtained by simulating the
MATLAB environment and graphic display of a cruise missile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07009</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07009</id><created>2018-07-18</created><authors><author><keyname>Mir</keyname><forenames>Mahdi</forenames></author></authors><title>Probability Density Function Estimation in OFDM Transmitter and Receiver
  in Radio Cognitive Networks based on Recurrent Neural Network</title><categories>eess.SP</categories><comments>OFDM, Cognitive Radio Networks, Recurrent Neural Network, Probability
  Density Function</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most important problem in telecommunication is bandwidth limitation due
to the uncontrolled growth of wireless technology. Deploying dynamic spectrum
access techniques is one of the procedures provided for efficient use of
bandwidth. In recent years, cognitive radio network introduced as a tool for
efficient use of spectrum. These radios are able to use radio resources by
recognizing surroundings via sensors and signal operations that means use these
resources only when authorized users do not use their spectrum. Secondary users
are unauthorized ones that must avoid from interferences with primary users
transmission. Secondary users must leave channel due to preventing damages to
primary users whenever these users discretion. In this article, spectrum
opportunities prediction based on Recurrent Neural Network for bandwidth
optimization and reducing the amount of energy by predicting spectrum holes
discovery for quality of services optimization proposed in OFDM-based cognitive
radio network based on probability density function. The result of the
simulation represent acceptable value of SNR and bandwidth optimization in
these networks that allows secondary users to taking spectrum and sending data
without collision and overlapping with primary users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07099</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07099</id><created>2018-07-18</created><authors><author><keyname>Kharyuk</keyname><forenames>Pavel</forenames></author><author><keyname>Nazarenko</keyname><forenames>Dmitry</forenames></author><author><keyname>Oseledets</keyname><forenames>Ivan</forenames></author></authors><title>Comparative study of Discrete Wavelet Transforms and Wavelet Tensor
  Train decomposition to feature extraction of FTIR data of medicinal plants</title><categories>eess.SP cs.LG cs.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier-transform infra-red (FTIR) spectra of samples from 7 plant species
were used to explore the influence of preprocessing and feature extraction on
efficiency of machine learning algorithms. Wavelet Tensor Train (WTT) and
Discrete Wavelet Transforms (DWT) were compared as feature extraction
techniques for FTIR data of medicinal plants. Various combinations of signal
processing steps showed different behavior when applied to classification and
clustering tasks. Best results for WTT and DWT found through grid search were
similar, significantly improving quality of clustering as well as
classification accuracy for tuned logistic regression in comparison to original
spectra. Unlike DWT, WTT has only one parameter to be tuned (rank), making it a
more versatile and easier to use as a data processing tool in various signal
processing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07105</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07105</id><created>2018-07-18</created><authors><author><keyname>Lee</keyname><forenames>Jhinhwan</forenames></author></authors><title>Real-time digital signal recovery for a low-pass transfer function
  system with multiple complex poles</title><categories>physics.ins-det eess.SP</categories><comments>15 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to solve the problems of waveform distortion and signal delay by
many physical and electrical systems with linear low-pass transfer
characteristics with multiple complex poles, a general
digital-signal-processing (DSP)-based method of real-time recovery of the
original source waveform from the distorted output waveform is proposed. From
the convolution kernel representation of a multiple-pole low-pass transfer
function with an arbitrary denominator polynomial with real valued
coefficients, it is shown that the source waveform can be accurately recovered
in real time using a particular moving average algorithm with real-valued DSP
computations only, even though some or all of the poles are complex. The
proposed digital signal recovery method is DC-accurate and unaffected by
initial conditions, transient signals, and resonant amplitude enhancement. The
noise characteristics of the data recovery shows inverse of the low-pass filter
characteristics. This method can be applied to most sensors and amplifiers
operating close to their frequency response limits or around their resonance
frequencies to accurately deconvolute the multiple-pole characteristics and to
improve the overall performances of data acquisition systems and digital
feedback control systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07140</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07140</id><created>2018-07-18</created><authors><author><keyname>Herscovici-Schiller</keyname><forenames>Olivier</forenames></author><author><keyname>Mugnier</keyname><forenames>Laurent M.</forenames></author><author><keyname>Baudoz</keyname><forenames>Pierre</forenames></author><author><keyname>Galicher</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Sauvage</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Paul</keyname><forenames>Baptiste</forenames></author></authors><title>Experimental validation of joint phase and amplitude wave-front sensing
  with coronagraphic phase diversity for high-contrast imaging</title><categories>astro-ph.IM eess.IV physics.optics</categories><comments>Reproduced with permission from Astronomy &amp; Astrophysics, Copyright
  ESO</comments><journal-ref>Astronomy and Astrophysics, 614 (2018) A142</journal-ref><doi>10.1051/0004-6361/201732439</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context. The next generation of space-borne instruments dedicated to the
direct detection of exoplanets requires unprecedented levels of wavefront
control precision. Coronagraphic wavefront sensing techniques for these
instruments must measure both the phase and amplitude of the optical
aberrations using the scientific camera as a wavefront sensor.
  Aims. In this paper, we develop an extension of coronagraphic phase diversity
to the estimation of the complex electric field, that is, the joint estimation
of phase and amplitude.
  Methods. We introduced the formalism for complex coronagraphic phase
diversity. We have demonstrated experimentally on the Tr\`es Haute Dynamique
testbed at the Observatoire de Paris that it is possible to reconstruct phase
and amplitude aberrations with a subnanometric precision using coronagraphic
phase diversity. Finally, we have performed the first comparison between the
complex wavefront estimated using coronagraphic phase diversity (which relies
on time-modulation of the speckle pattern) and the one reconstructed by the
self-coherent camera (which relies on the spatial modulation of the speckle
pattern).
  Results. We demonstrate that coronagraphic phase diversity retrieves complex
wavefront with subnanometric precision with a good agreement with the
reconstruction performed using the self-coherent camera.
  Conclusions. This result paves the way to coronagraphic phase diversity as a
coronagraphic wave-front sensor candidate for very high contrast space
missions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07180</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07180</id><created>2018-07-18</created><authors><author><keyname>Mishra</keyname><forenames>Sakshi</forenames></author><author><keyname>Palanisamy</keyname><forenames>Praveen</forenames></author></authors><title>Efficient Power Flow Management and Peak Shaving in a Microgrid-PV
  System</title><categories>cs.SY eess.SP</categories><comments>Accepted at: IEEE Energy Conversion Congress and Exposition (ECCE
  2018), 7 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing penetration of the roof-top solar PV and the rising
interest in net-zero energy homes concept, there is a need of balancing the
performance of intelligent controllers, their cost-effectiveness and over-all
sophistication of the microgrid systems in order to manage the bi-directional
power flow in the small as well as large size microgrids. This paper proposes
solutions to efficiently manage power flow and to achieve peak shaving in a
renewable-source fed microgrid system. The paper details the design and
simulation of a photovoltaic source fed microgrid system that achieves peak
shaving and efficient power flow management using advanced metering and a smart
control unit. The proposed system enables microgrid to maintain the power
consumption within limits during peak hours by shedding luxurious loads
automatically. Under the grid-connected mode of the microgrid, the system feeds
the excess power available to the utility grid during lower load requirements
and withdraws the power deficit from the grid during high demand hours when
photovoltaic power generation is not sufficient to fulfill the load
requirement. The proposed system exhibits desirable power flow management
performance and is capable of functioning with distributed generation sources
other than PV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07184</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07184</id><created>2018-07-18</created><authors><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Shafipour</keyname><forenames>Rasoul</forenames></author><author><keyname>Vikalo</keyname><forenames>Haris</forenames></author><author><keyname>Mateos</keyname><forenames>Gonzalo</forenames></author></authors><title>A Novel Scheme for Support Identification and Iterative Sampling of
  Bandlimited Graph Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of sampling and reconstruction of bandlimited graph
signals where the objective is to select a node subset of prescribed
cardinality that ensures interpolation of the original signal with the lowest
reconstruction error. We propose an efficient iterative selection sampling
approach and show that in the noiseless case the original signal is exactly
recovered from the set of selected nodes. In the case of noisy measurements, a
bound on the reconstruction error of the proposed algorithm is established. We
further address the support identification of the bandlimited signal with
unknown support and show that under a pragmatic sufficient condition, the
proposed framework requires minimal number of samples to perfectly identify the
support. The efficacy of the proposed methods are illustrated through numerical
simulations on synthetic and real-world graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07190</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07190</id><created>2018-07-18</created><authors><author><keyname>Yan</keyname><forenames>Han</forenames></author><author><keyname>Boljanovic</keyname><forenames>Veljko</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Tracking Sparse mmWave Channel: Performance Analysis under Intra-Cluster
  Angular Spread</title><categories>eess.SP</categories><comments>Presented at IEEE SPAWC 2018, Kalamata, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) systems require a large number of antennas at both
base station and user equipment for a desirable link budget. Due to time
varying channel under user mobility, up-to-date channel state information (CSI)
is critical to obtain the required beamforming gain.. The mmWave sparse
multipath channel is commonly exploited in designing tracking algorithms but
practical angular spread is often overlooked. In this work, we study the
performance bound of tracking accuracy in sparse mmWave channel that includes
intra-cluster angular spreads. Power gain from angle-steering-based beamforming
using tracked CSI is then analyzed. The theoretical study provides a design
guideline beam-width in angle-steering under different intra-cluster angular
spreads. We verify the results with two common tracking algorithms including
sector beam tracking and maximum likelihood channel tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07201</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07201</id><created>2018-07-18</created><updated>2018-09-05</updated><authors><author><keyname>Yan</keyname><forenames>Han</forenames></author><author><keyname>Ramesh</keyname><forenames>Sridhar</forenames></author><author><keyname>Gallagher</keyname><forenames>Timothy</forenames></author><author><keyname>Ling</keyname><forenames>Curtis</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Performance, Power, and Area Design Trade-offs in Millimeter-Wave
  Transmitter Beamforming Architectures</title><categories>eess.SP</categories><comments>19 pages, 13 figures; Accepted for publication in IEEE Circuits and
  System Magazine</comments><doi>10.1109/MCAS.2019.2909447</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmW) communications is the key enabler of 5G cellular
networks due to vast spectrum availability that could boost peak rate and
capacity. Due to increased propagation loss in mmW band, transceivers with
massive antenna array are required to meet link budget, but their power
consumption and cost become limiting factors for commercial systems. Radio
designs based on hybrid digital and analog array architectures and the usage of
radio frequency (RF) signal processing via phase shifters have emerged as
potential solutions to improve energy efficiency and deliver performances close
to digital arrays. In this paper, we provide an overview of the
state-of-the-art mmW massive antenna array designs and comparison among three
architectures, namely digital array, sub-array, and fully-connected hybrid
array. The comparison of performance, power, and area for these three
architectures is performed for three representative 5G use cases, which cover a
range of pre-beamforming SNR and multiplexing regimes. This is the first study
to comprehensively model and analyze all design aspects and criteria including:
1) optimal linear precoder, 2) impact of quantization error in DAC and phase
shifters, 3) RF signal distribution network, 4) power and area estimation based
on state-of-the-art mmW circuits including baseband precoding, digital signal
distribution, DACs, oscillators and mixers, phase shifters, RF signal
distribution, and power amplifiers. The results show that the digital array is
the most power and area efficient compared against optimal design for each
architecture. Our analysis shows digital array benefits greatly from multi-user
multiplexing. The analysis also reveals that sub-array is limited by reduced
beamforming gain due to array partitioning, and system bottleneck of the
fully-connected hybrid architecture is the excessively power hungry RF signal
distribution network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07222</identifier>
 <datestamp>2018-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07222</id><created>2018-07-18</created><updated>2018-11-14</updated><authors><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Shafipour</keyname><forenames>Rasoul</forenames></author><author><keyname>Vikalo</keyname><forenames>Haris</forenames></author><author><keyname>Mateos</keyname><forenames>Gonzalo</forenames></author></authors><title>Accelerated Sampling of Bandlimited Graph Signals</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1807.07184</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of sampling and reconstructing bandlimited graph signals
where the objective is to select a subset of nodes of pre-specified cardinality
that ensures interpolation of the original signal with the lowest possible
reconstruction error. First, we consider a non-Bayesian scenario and propose an
efficient iterative sampling procedure that in the noiseless case enables exact
recovery of the original signal from the set of selected nodes. In the case of
noisy measurements, a bound on the reconstruction error of the proposed
algorithm is established. Then, we consider the Bayesian scenario where we
formulate the sampling task as the problem of maximizing a monotone weak
submodular function, and propose a randomized-greedy algorithm to find a
sub-optimal subset. We derive a worst-case performance guarantee on the
mean-square error achieved by the randomized-greedy algorithm for general
non-stationary graph signals. The efficacy of the proposed methods is
illustrated through extensive numerical simulations on synthetic and real-world
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07230</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07230</id><created>2018-07-18</created><authors><author><keyname>Fouda</keyname><forenames>Abdurrahman</forenames></author><author><keyname>Ibrahim</keyname><forenames>Ahmed S.</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Ghosh</keyname><forenames>Monisha</forenames></author></authors><title>UAV-Based in-band Integrated Access and Backhaul for 5G Communications</title><categories>eess.SP cs.NI</categories><comments>To be presented in the proceedings of VTC-Fall'18, Chicago, IL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of using unmanned aerial vehicles (UAVs) as drone
base stations for in-band Integrated Access and Backhaul (IB-IAB) scenarios for
5G networks. We first present a system model for forward link transmissions in
an IB-IAB multi-tier drone cellular network. We then investigate the key
challenges of this scenario and propose a framework that utilizes the flying
capabilities of the UAVs as the main degree of freedom to find the optimal
precoder design for the backhaul links, user-base station association, UAV 3D
hovering locations, and power allocations. We discuss how the proposed
algorithm can be utilized to optimize the network performance in both large and
small scales. Finally, we use an exhaustive search-based solution to
demonstrate the performance gains that can be achieved from the presented
algorithm in terms of the received signal to interference plus noise ratio
(SINR) and overall network sum-rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07260</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07260</id><created>2018-07-19</created><authors><author><keyname>Shakeel</keyname><forenames>Ismail</forenames></author></authors><title>Machine Learning Based Featureless Signalling</title><categories>eess.SP</categories><comments>Draft submitted to IEEE MILCOM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direct-sequence spread-spectrum (DSSS) is commonly used to mitigate the
effect of jamming and to operate under an adversary receiver's thermal noise
floor in order to avoid signal detection. Unfortunately, the discrete nature
and unique distribution of DSSS spreading sequences make it relatively easy to
detect the resulting transmitted signals. To overcome this issue, this paper
proposes a machine learning based scheme that generates featureless,
non-repetitive noise-like spread signals. The proposed scheme provides several
benefits over the standard DSSS system including the ability to generate
signals with low probabilities of detection/intercept, additional processing
gain and also an uncoordinated synchronisation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07278</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07278</id><created>2018-07-19</created><authors><author><keyname>Arzt</keyname><forenames>Andreas</forenames></author><author><keyname>Lattner</keyname><forenames>Stefan</forenames></author></authors><title>Audio-to-Score Alignment using Transposition-invariant Features</title><categories>cs.SD cs.MM eess.AS</categories><comments>19th International Society for Music Information Retrieval
  Conference, Paris, France, 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Audio-to-score alignment is an important pre-processing step for in-depth
analysis of classical music. In this paper, we apply novel
transposition-invariant audio features to this task. These low-dimensional
features represent local pitch intervals and are learned in an unsupervised
fashion by a gated autoencoder. Our results show that the proposed features are
indeed fully transposition-invariant and enable accurate alignments between
transposed scores and performances. Furthermore, they can even outperform
widely used features for audio-to-score alignment on `untransposed data', and
thus are a viable and more flexible alternative to well-established features
for music alignment and matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07281</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07281</id><created>2018-07-19</created><updated>2019-02-21</updated><authors><author><keyname>Ping</keyname><forenames>Wei</forenames></author><author><keyname>Peng</keyname><forenames>Kainan</forenames></author><author><keyname>Chen</keyname><forenames>Jitong</forenames></author></authors><title>ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech</title><categories>cs.CL cs.AI cs.LG cs.SD eess.AS</categories><comments>Published at ICLR 2019. (v3: add important details &amp; discussion in
  Appendix A)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a new solution for parallel wave generation by
WaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we
distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet
by minimizing a regularized KL divergence between their highly-peaked output
distributions. Our method computes the KL divergence in closed-form, which
simplifies the training algorithm and provides very efficient distillation. In
addition, we introduce the first text-to-wave neural architecture for speech
synthesis, which is fully convolutional and enables fast end-to-end training
from scratch. It significantly outperforms the previous pipeline that connects
a text-to-spectrogram model to a separately trained WaveNet (Ping et al.,
2018). We also successfully distill a parallel waveform synthesizer conditioned
on the hidden representation in this end-to-end model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07337</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07337</id><created>2018-07-19</created><authors><author><keyname>Qi</keyname><forenames>Yinan</forenames></author><author><keyname>Mach</keyname><forenames>Tomasz</forenames></author></authors><title>QoS and Coverage Aware Dynamic High Density Vehicle Platooning (HDVP)</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 9 figures, accepted by VTC Fall 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a self-driving environment, vehicles communicate with each other to create
a closely spaced multiple vehicle strings on a highway, i.e., high-density
vehicle platooning (HDVP). In this paper, we address the Cellular Vehicle to
Everything (C-V2X) quality of service (QoS) and radio coverage issues for HDVP
and propose a dynamic platooning mechanism taking into account the change of
coverage condition, the road capacity, medium access control (MAC) and spectrum
reuse while at the same time guaranteeing the stringent QoS requirements in
terms of latency and reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07395</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07395</id><created>2018-07-08</created><authors><author><keyname>Shahdoosti</keyname><forenames>Hamid Reza</forenames></author></authors><title>A New Noise-Assistant LMS Algorithm for Preventing the Stalling Effect</title><categories>eess.SP cs.IT math.IT</categories><comments>14 pages, 9 figures, scientific journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new algorithm to deal with the stalling effect
in the LMS algorithm used in adaptive filters. We modify the update rule of the
tap weight vectors by adding noise, generated by a noise generator. The
properties of the proposed method are investigated by two novel theorems. As it
is shown, the resulting algorithm, called Added Noise LMS (AN-LMS), improves
the resistance capability of the conventional LMS algorithm against the
stalling effect. The probability of update with additive white Gaussian noise
is calculated in the paper. Convergence of the proposed method is investigated
and it is proved that the rate of convergence of the introduced method is equal
to that of LMS algorithm in the expected value sense, provided that the
distribution of the added noise is uniform. Finally, it is shown that the order
of complexity of the proposed algorithm is linear as the conventional LMS
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07405</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07405</id><created>2018-07-18</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Periyasamy</keyname><forenames>Vijitha</forenames></author><author><keyname>Pramanik</keyname><forenames>Manojit</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Eigenspace-Based Minimum Variance Combined with Delay Multiply and Sum
  Beamformer: Application to Linear-Array Photoacoustic Imaging</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1709.07965</comments><journal-ref>IEEE Journal of Selected Topics in Quantum Electronics, 2018</journal-ref><doi>10.1109/JSTQE.2018.2856584</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Photoacoustic imaging, Delay-and-Sum (DAS) algorithm is the most commonly
used beamformer. However, it leads to a low resolution and high level of
sidelobes. Delay-Multiply-and-Sum (DMAS) was introduced to provide lower
sidelobes compared to DAS. In this paper, to improve the resolution and
sidelobes of DMAS, a novel beamformer is introduced using Eigenspace-Based
Minimum Variance (EIBMV) method combined with DMAS, namely EIBMV-DMAS. It is
shown that expanding the DMAS algebra leads to several terms which can be
interpreted as DAS. Using the EIBMV adaptive beamforming instead of the
existing DAS (inside the DMAS algebra expansion) is proposed to improve the
image quality. EIBMV-DMAS is evaluated numerically and experimentally. It is
shown that EIBMV-DMAS outperforms DAS, DMAS and EIBMV in terms of resolution
and sidelobes. In particular, at the depth of 11 mm of the experimental images,
EIBMV-DMAS results in about 113 dB and 50 dB sidelobe reduction, compared to
DMAS and EIBMV, respectively. At the depth of 7 mm, for the experimental
images, the quantitative results indicate that EIBMV-DMAS leads to improvement
in Signal-to-Noise Ratio (SNR) of about 75% and 34%, compared to DMAS and
EIBMV, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07436</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07436</id><created>2018-07-19</created><updated>2018-07-22</updated><authors><author><keyname>Liu</keyname><forenames>Yaming</forenames></author><author><keyname>Tang</keyname><forenames>Jian</forenames></author><author><keyname>Song</keyname><forenames>Yan</forenames></author><author><keyname>Dai</keyname><forenames>Lirong</forenames></author></authors><title>A Capsule based Approach for Polyphonic Sound Event Detection</title><categories>eess.AS cs.SD</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polyphonic sound event detection (polyphonic SED) is an interesting but
challenging task due to the concurrence of multiple sound events. Recently, SED
methods based on convolutional neural networks (CNN) and recurrent neural
networks (RNN) have shown promising performance. Generally, CNN are designed
for local feature extraction while RNN are used to model the temporal
dependency among these local features. Despite their success, it is still
insufficient for existing deep learning techniques to separate individual sound
event from their mixture, largely due to the overlapping characteristic of
features. Motivated by the success of Capsule Networks (CapsNet), we propose a
more suitable capsule based approach for polyphonic SED. Specifically, several
capsule layers are designed to effectively select representative frequency
bands for each individual sound event. The temporal dependency of capsule's
outputs is then modeled by a RNN. And a dynamic threshold method is proposed
for making the final decision based on RNN outputs. Experiments on the TUT-SED
Synthetic 2016 dataset show that the proposed approach obtains an F1-score of
68.8% and an error rate of 0.45, outperforming the previous state-of-the-art
method of 66.4% and 0.48, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07484</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07484</id><created>2018-07-19</created><authors><author><keyname>Damavandi</keyname><forenames>Hamidreza Ghasemi</forenames></author><author><keyname>Gupta</keyname><forenames>Ananya Sen</forenames></author><author><keyname>Canahuate</keyname><forenames>Guadalupe</forenames></author><author><keyname>Reddy</keyname><forenames>Christopher M.</forenames></author><author><keyname>Nelson</keyname><forenames>Robert</forenames></author></authors><title>Robust Oil-spill Forensics and Petroleum Source Differentiation using
  Quantized Peak Topography Maps</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification and classification of environmental forensics, with the
petroleum forensics as the main application, requires an effective technology
or method to distinguish between the closely located forensics as they share
many main biomarkers. Two-dimensional gas chromatography is one of these
technologies with which a petroleum forensic is separated into its chemical
compounds, resulting in a three-dimensional image, GCXGC image. Therefore,
distinguishing between two petroleum forensics is equivalent to the comparison
between their corresponding GCXGC images. In this paper, we present a
technique, called Quantized Peak Topography Map (QPTM), which results in a
better separation between the GCXGC images. We validate our proposed method on
a model dataset, consisting of thirtyfour GCXGC images, extracted from the
different parts of the world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07501</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07501</id><created>2018-07-19</created><updated>2019-07-01</updated><authors><author><keyname>Liao</keyname><forenames>Chien-Feng</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Lee</keyname><forenames>Hung-Yi</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author></authors><title>Noise Adaptive Speech Enhancement using Domain Adversarial Training</title><categories>cs.SD eess.AS</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we propose a novel noise adaptive speech enhancement (SE)
system, which employs a domain adversarial training (DAT) approach to tackle
the issue of a noise type mismatch between the training and testing conditions.
Such a mismatch is a critical problem in deep-learning-based SE systems. A
large mismatch may cause a serious performance degradation to the SE
performance. Because we generally use a well-trained SE system to handle
various unseen noise types, a noise type mismatch commonly occurs in real-world
scenarios. The proposed noise adaptive SE system contains an
encoder-decoder-based enhancement model and a domain discriminator model.
During adaptation, the DAT approach encourages the encoder to produce
noise-invariant features based on the information from the discriminator model
and consequentially increases the robustness of the enhancement model to unseen
noise types. Herein, we regard stationary noises as the source domain (with the
ground truth of clean speech) and non-stationary noises as the target domain
(without the ground truth). We evaluated the proposed system on TIMIT
sentences. The experiment results show that the proposed noise adaptive SE
system successfully provides significant improvements in PESQ (19.0%), SSNR
(39.3%), and STOI (27.0%) over the SE system without an adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07524</identifier>
 <datestamp>2018-07-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07524</id><created>2018-07-19</created><authors><author><keyname>Graeter</keyname><forenames>Johannes</forenames></author><author><keyname>Wilczynski</keyname><forenames>Alexander</forenames></author><author><keyname>Lauer</keyname><forenames>Martin</forenames></author></authors><title>LIMO: Lidar-Monocular Visual Odometry</title><categories>cs.RO eess.IV</categories><comments>Accepted at IROS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher level functionality in autonomous driving depends strongly on a
precise motion estimate of the vehicle. Powerful algorithms have been
developed. However, their great majority focuses on either binocular imagery or
pure LIDAR measurements. The promising combination of camera and LIDAR for
visual localization has mostly been unattended. In this work we fill this gap,
by proposing a depth extraction algorithm from LIDAR measurements for camera
feature tracks and estimating motion by robustified keyframe based Bundle
Adjustment. Semantic labeling is used for outlier rejection and weighting of
vegetation landmarks. The capability of this sensor combination is demonstrated
on the competitive KITTI dataset, achieving a placement among the top 15. The
code is released to the community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07622</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07622</id><created>2018-07-19</created><authors><author><keyname>Aslani</keyname><forenames>Rojin</forenames></author><author><keyname>Rasti</keyname><forenames>Mehdi</forenames></author></authors><title>Distributed Power Control Schemes for In-Band Full-Duplex Energy
  Harvesting Wireless Networks</title><categories>eess.SP cs.NI</categories><comments>11 pages, 8 figures</comments><journal-ref>in IEEE Transactions on Wireless Communications, vol. 16, no. 8,
  pp. 5233-5243, Aug. 2017</journal-ref><doi>10.1109/TWC.2017.2707086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies two power control problems in energy harvesting wireless
networks where one hybrid base station (HBS) and all user equipments (UEs) are
operating in in-band full-duplex mode. We consider minimizing the aggregate
power subject to the quality of service requirement constraint, and maximizing
the aggregate throughput. We address these two problems by proposing two
distributed power control schemes for controlling the uplink transmit power by
the UEs and the downlink energy harvesting signal power by the HBS. In our
proposed schemes, the HBS updates the downlink transmit power level of the
energy-harvesting signal so that each UE is enabled to harvest its required
energy for powering the operating circuit and transmitting its uplink
information signal with the power level determined by the proposed schemes. We
show that our proposed power control schemes converge to their corresponding
unique fixed points starting from any arbitrary initial transmit power. We will
show that our proposed schemes well address the stated problems, which is also
demonstrated by our extensive simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07650</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07650</id><created>2018-07-19</created><authors><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Kilic</keyname><forenames>Osman Fatih</forenames></author><author><keyname>Vikalo</keyname><forenames>Haris</forenames></author></authors><title>Near-Optimal Distributed Estimation for a Network of Sensing Units
  Operating Under Communication Constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of distributed state estimation in a network of sensing
units that can exchange their measurements but the rate of communication
between the units is constrained. The units collect noisy, possibly only
partial observations of the unknown state; they are assisted by a relay center
which can communicate at a higher rate and schedules the exchange of
measurements between the units. We consider the task of minimizing the total
mean-square estimation error of the network while promoting balance between the
individual units' performances. This problem is formulated as the maximization
of a monotone objective function subject to a cardinality constraint. By
leveraging the notion of weak submodularity, we develop an efficient greedy
algorithm for the proposed formulation and show that the greedy algorithm
achieves a constant factor approximation of the optimal objective. Our
extensive simulation studies illustrate the efficacy of the proposed
formulation and the greedy algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07682</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07682</id><created>2018-07-19</created><authors><author><keyname>Roheda</keyname><forenames>Siddharth</forenames></author><author><keyname>Riggan</keyname><forenames>Benjamin S.</forenames></author><author><keyname>Krim</keyname><forenames>Hamid</forenames></author><author><keyname>Dai</keyname><forenames>Liyi</forenames></author></authors><title>Cross-Modality Distillation: A case for Conditional Generative
  Adversarial Networks</title><categories>eess.IV</categories><comments>Accepted and Presented at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to use a Conditional Generative Adversarial Network
(CGAN) for distilling (i.e. transferring) knowledge from sensor data and
enhancing low-resolution target detection. In unconstrained surveillance
settings, sensor measurements are often noisy, degraded, corrupted, and even
missing/absent, thereby presenting a significant problem for multi-modal
fusion. We therefore specifically tackle the problem of a missing modality in
our attempt to propose an algorithm based on CGANs to generate representative
information from the missing modalities when given some other available
modalities. Despite modality gaps, we show that one can distill knowledge from
one set of modalities to another. Moreover, we demonstrate that it achieves
better performance than traditional approaches and recent teacher-student
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07690</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07690</id><created>2018-07-19</created><authors><author><keyname>Islam</keyname><forenames>Md Tauhidul</forenames></author><author><keyname>Righetti</keyname><forenames>Raffaella</forenames></author></authors><title>A novel filter for accurate estimation of fluid pressure and fluid
  velocity using poroelastography</title><categories>eess.IV physics.med-ph</categories><comments>16 pages, 10 figures, 2 tables, under review in Computers in biology
  and medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluid pressure and fluid velocity carry important information for cancer
diagnosis, prognosis and treatment. Recent work has demonstrated that
estimation of these parameters is theoretically possible using ultrasound
poroelastography. However, accurate estimation of these parameters requires
high quality axial and lateral strain estimates from noisy ultrasound radio
frequency (RF) data. In this paper, we propose a filtering technique combining
two efficient filters for removal of noise from strain images, i.e., Kalman and
nonlinear complex diffusion filters (NCDF). Our proposed filter is based on a
novel noise model, which takes into consideration both additive and amplitude
modulation noise in the estimated strains. Using finite element and ultrasound
simulations, we demonstrate that the proposed filtering technique can
significantly improve image quality of lateral strain elastograms along with
fluid pressure and velocity elastograms. Technical feasibility of the proposed
method on an in vivo set of data is also demonstrated. Our results show that
the CNRe of the lateral strain, fluid pressure and fluid velocity as estimated
using the proposed technique is higher by at least 10.9%, 51.3% and 334.4% when
compared to the results obtained using a Kalman filter only, by at least 8.9%,
27.6% and 219.5% when compared to the results obtained using a NCDF only and by
at least 152.3%, 1278% and 742% when compared to the results obtained using a
median filter only for all SNRs considered in this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07701</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07701</id><created>2018-07-19</created><authors><author><keyname>Rivenson</keyname><forenames>Yair</forenames></author><author><keyname>Liu</keyname><forenames>Tairan</forenames></author><author><keyname>Wei</keyname><forenames>Zhensong</forenames></author><author><keyname>Zhang</keyname><forenames>Yibo</forenames></author><author><keyname>Ozcan</keyname><forenames>Aydogan</forenames></author></authors><title>PhaseStain: Digital staining of label-free quantitative phase microscopy
  images using deep learning</title><categories>eess.IV cs.CV physics.med-ph</categories><msc-class>68T01, 68T05, 68U10, 62M45, 78M32, 92C50, 92C55, 94A08</msc-class><acm-class>I.2; I.2.1; I.2.6; I.2.10; I.3; I.3.3; I.4.3; I.4.4; I.4.9; J.3</acm-class><journal-ref>Light: Science and Applications, 8 (2019)</journal-ref><doi>10.1038/s41377-019-0129-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a deep neural network, we demonstrate a digital staining technique,
which we term PhaseStain, to transform quantitative phase images (QPI) of
labelfree tissue sections into images that are equivalent to brightfield
microscopy images of the same samples that are histochemically stained. Through
pairs of image data (QPI and the corresponding brightfield images, acquired
after staining) we train a generative adversarial network (GAN) and demonstrate
the effectiveness of this virtual staining approach using sections of human
skin, kidney and liver tissue, matching the brightfield microscopy images of
the same samples stained with Hematoxylin and Eosin, Jones' stain, and Masson's
trichrome stain, respectively. This digital staining framework might further
strengthen various uses of labelfree QPI techniques in pathology applications
and biomedical research in general, by eliminating the need for chemical
staining, reducing sample preparation related costs and saving time. Our
results provide a powerful example of some of the unique opportunities created
by data driven image transformations enabled by deep learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07771</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07771</id><created>2018-07-20</created><updated>2018-10-08</updated><authors><author><keyname>Hofmann</keyname><forenames>Fabian</forenames></author><author><keyname>Sch&#xe4;fer</keyname><forenames>Mirko</forenames></author><author><keyname>Brown</keyname><forenames>Tom</forenames></author><author><keyname>H&#xf6;rsch</keyname><forenames>Jonas</forenames></author><author><keyname>Schramm</keyname><forenames>Stefan</forenames></author><author><keyname>Greiner</keyname><forenames>Martin</forenames></author></authors><title>Principal Flow Patterns across renewable electricity networks</title><categories>eess.SP physics.soc-ph</categories><doi>10.1209/0295-5075/124/18005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Principal Component Analysis (PCA), the nodal injection and line flow
patterns in a network model of a future highly renewable European electricity
system are investigated. It is shown that the number of principal components
needed to describe 95$\%$ of the nodal power injection variance first increases
with the spatial resolution of the system representation. The number of
relevant components then saturates at around 76 components for network sizes
larger than 512 nodes, which can be related to the correlation length of wind
patterns over Europe. Remarkably, the application of PCA to the transmission
line power flow statistics shows that irrespective of the spatial scale of the
system representation a very low number of only 8 principal flow patterns is
sufficient to capture 95$\%$ of the corresponding spatio-temporal variance.
This result can be theoretically explained by a particular alignment of some
principal injection patterns with topological patterns inherent to the network
structure of the European transmission system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07778</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07778</id><created>2018-07-20</created><authors><author><keyname>Ao</keyname><forenames>Dongyang</forenames></author><author><keyname>Dumitru</keyname><forenames>Corneliu Octavian</forenames></author><author><keyname>Schwarz</keyname><forenames>Gottfried</forenames></author><author><keyname>Datcu</keyname><forenames>Mihai</forenames></author></authors><title>Dialectical GAN for SAR Image Translation: From Sentinel-1 to TerraSAR-X</title><categories>eess.IV cs.CV cs.LG</categories><comments>22 pages, 15 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Contrary to optical images, Synthetic Aperture Radar (SAR) images are in
different electromagnetic spectrum where the human visual system is not
accustomed to. Thus, with more and more SAR applications, the demand for
enhanced high-quality SAR images has increased considerably. However,
high-quality SAR images entail high costs due to the limitations of current SAR
devices and their image processing resources. To improve the quality of SAR
images and to reduce the costs of their generation, we propose a Dialectical
Generative Adversarial Network (Dialectical GAN) to generate high-quality SAR
images. This method is based on the analysis of hierarchical SAR information
and the &quot;dialectical&quot; structure of GAN frameworks. As a demonstration, a
typical example will be shown where a low-resolution SAR image (e.g., a
Sentinel-1 image) with large ground coverage is translated into a
high-resolution SAR image (e.g., a TerraSAR-X image). Three traditional
algorithms are compared, and a new algorithm is proposed based on a network
framework by combining conditional WGAN-GP (Wasserstein Generative Adversarial
Network - Gradient Penalty) loss functions and Spatial Gram matrices under the
rule of dialectics. Experimental results show that the SAR image translation
works very well when we compare the results of our proposed method with the
selected traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07811</identifier>
 <datestamp>2018-12-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07811</id><created>2018-07-20</created><updated>2018-10-15</updated><authors><author><keyname>Fortunati</keyname><forenames>Stefano</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Greco</keyname><forenames>Maria S.</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>Semiparametric Inference and Lower Bounds for Real Elliptically
  Symmetric Distributions</title><categories>eess.SP</categories><comments>This paper has been accepted for publication in IEEE Transactions on
  Signal Processing</comments><doi>10.1109/TSP.2018.2880724</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has a twofold goal. The first aim is to provide a deeper
understanding of the family of the Real Elliptically Symmetric (RES)
distributions by investigating their intrinsic semiparametric nature. The
second aim is to derive a semiparametric lower bound for the estimation of the
parametric component of the model. The RES distributions represent a
semiparametric model where the parametric part is given by the mean vector and
by the scatter matrix while the non-parametric, infinite-dimensional, part is
represented by the density generator. Since, in practical applications, we are
often interested only in the estimation of the parametric component, the
density generator can be considered as nuisance. The first part of the paper is
dedicated to conveniently place the RES distributions in the framework of the
semiparametric group models. The second part of the paper, building on the
mathematical tools previously introduced, the Constrained Semiparametric
Cram\'{e}r-Rao Bound (CSCRB) for the estimation of the mean vector and of the
constrained scatter matrix of a RES distributed random vector is introduced.
The CSCRB provides a lower bound on the Mean Squared Error (MSE) of any robust
$M$-estimator of mean vector and scatter matrix when no a-priori information on
the density generator is available. A closed form expression for the CSCRB is
derived. Finally, in simulations, we assess the statistical efficiency of the
Tyler's and Huber's scatter matrix $M$-estimators with respect to the CSCRB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07818</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07818</id><created>2018-07-20</created><authors><author><keyname>Cs&#xe1;ji</keyname><forenames>Bal&#xe1;zs Csan&#xe1;d</forenames></author><author><keyname>Kem&#xe9;ny</keyname><forenames>Zsolt</forenames></author><author><keyname>Pedone</keyname><forenames>Gianfranco</forenames></author><author><keyname>Kuti</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>V&#xe1;ncza</keyname><forenames>J&#xf3;zsef</forenames></author></authors><title>Wireless Multi-Sensor Networks for Smart Cities: A Prototype System with
  Statistical Data Analysis</title><categories>cs.CY cs.LG cs.NI eess.SP</categories><comments>9 pages, 8 figures, 3 tables, 27 references</comments><journal-ref>IEEE Sensors Journal, Volume 17, Issue 23, 2017, pp. 7667-7676</journal-ref><doi>10.1109/JSEN.2017.2736785</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As urbanization proceeds at an astonishing rate, cities have to continuously
improve their solutions that affect the safety, health and overall wellbeing of
their residents. Smart city projects worldwide build on advanced sensor,
information and communication technologies to help dealing with issues like air
pollution, waste management, traffic optimization, and energy efficiency. The
paper reports about the prototype of a smart city initiative in Budapest which
applies various sensors installed on the public lighting system and a
cloud-based analytical module. While the installed wireless multi-sensor
network gathers information about a number of stressors, the module integrates
and statistically processes the data. The module can handle inconsistent,
missing and noisy data and can extrapolate the measurements in time and space,
namely, it can create short-term forecasts and smoothed maps, both accompanied
by reliability estimates. The resulting database uses geometric representations
and can serve as an information centre for public services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07856</identifier>
 <datestamp>2018-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07856</id><created>2018-07-14</created><updated>2018-09-10</updated><authors><author><keyname>Liu</keyname><forenames>Hang</forenames></author><author><keyname>Li</keyname><forenames>Hengyu</forenames></author><author><keyname>Liu</keyname><forenames>Xiahua</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>Xie</keyname><forenames>Shaorong</forenames></author><author><keyname>Sun</keyname><forenames>Yu</forenames></author></authors><title>A Novel Method for Extrinsic Calibration of Multiple RGB-D Cameras Using
  Descriptor-Based Patterns</title><categories>eess.IV cs.RO</categories><comments>6 pages, 7 figures, under review by IEEE Robotics and Automation
  Letters &amp; ICRA</comments><acm-class>I.2.10; I.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents a novel method to estimate the relative poses between
RGB-D cameras with minimal overlapping fields of view in a panoramic RGB-D
camera system. This calibration problem is relevant to applications such as
indoor 3D mapping and robot navigation that can benefit from a 360$^\circ$
field of view using RGB-D cameras. The proposed approach relies on
descriptor-based patterns to provide well-matched 2D keypoints in the case of a
minimal overlapping field of view between cameras. Integrating the matched 2D
keypoints with corresponding depth values, a set of 3D matched keypoints are
constructed to calibrate multiple RGB-D cameras. Experiments validated the
accuracy and efficiency of the proposed calibration approach, both superior to
those of existing methods (800 ms vs. 5 seconds; rotation error of 0.56 degrees
vs. 1.6 degrees; and translation error of 1.80 cm vs. 2.5 cm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07858</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07858</id><created>2018-07-18</created><authors><author><keyname>Ou</keyname><forenames>Y.</forenames></author><author><keyname>Hugues-Salas</keyname><forenames>E.</forenames></author><author><keyname>Ntavou</keyname><forenames>F.</forenames></author><author><keyname>Wang</keyname><forenames>R.</forenames></author><author><keyname>Bi</keyname><forenames>Y.</forenames></author><author><keyname>Yan</keyname><forenames>SY.</forenames></author><author><keyname>Kanellos</keyname><forenames>G.</forenames></author><author><keyname>Nejabati</keyname><forenames>R.</forenames></author><author><keyname>Simeonidou</keyname><forenames>D.</forenames></author></authors><title>Field-Trial of Machine Learning-Assisted Quantum Key Distribution (QKD)
  Networking with SDN</title><categories>eess.SP quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrated, for the first time, a machine-learning method to assist the
coexistence between quantum and classical communication channels.
Software-defined networking was used to successfully enable the key generation
and transmission over a city and campus network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07902</identifier>
 <datestamp>2018-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07902</id><created>2018-07-18</created><authors><author><keyname>Hosseini</keyname><forenames>Zohreh S.</forenames></author><author><keyname>Mahoor</keyname><forenames>Mohsen</forenames></author><author><keyname>Khodaei</keyname><forenames>Amin</forenames></author></authors><title>Battery Swapping Station as an Energy Storage for Capturing
  Distribution-Integrated Solar Variability</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Managing the inherent variability of solar generation is a critical challenge
for utility grid operators, particularly as the distribution grid-integrated
solar generation is making fast inroads in power systems. This paper proposes
to leverage Battery Swapping Station (BSS) as an energy storage for mitigating
solar photovoltaic (PV) output fluctuations. Using mixed-integer programming, a
model for the BSS optimal scheduling is proposed to capture solar generation
variability. The proposed model aims at minimizing the BSS total operation
cost, which represents the accumulated cost of exchanging power with the
utility grid. The model is subject to four sets of constraints associated with
the utility grid, the BSS system, individual batteries, and solar variability.
Numerical simulations on a test BSS demonstrate the effectiveness of the
proposed model and show its viability in helping the utility grids host a
higher penetration of solar generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07959</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07959</id><created>2018-07-19</created><authors><author><keyname>Longueira</keyname><forenames>Frank</forenames></author><author><keyname>Keene</keyname><forenames>Sam</forenames></author></authors><title>A Fully Convolutional Neural Network Approach to End-to-End Speech
  Enhancement</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper will describe a novel approach to the cocktail party problem that
relies on a fully convolutional neural network (FCN) architecture. The FCN
takes noisy audio data as input and performs nonlinear, filtering operations to
produce clean audio data of the target speech at the output. Our method learns
a model for one specific speaker, and is then able to extract that speakers
voice from babble background noise. Results from experimentation indicate the
ability to generalize to new speakers and robustness to new noise environments
of varying signal-to-noise ratios. A potential application of this method would
be for use in hearing aids. A pre-trained model could be quickly fine tuned for
an individuals family members and close friends, and deployed onto a hearing
aid to assist listeners in noisy environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07960</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07960</id><created>2018-07-19</created><authors><author><keyname>Grigoryan</keyname><forenames>Artyom M.</forenames></author><author><keyname>John</keyname><forenames>Aparna</forenames></author><author><keyname>Agaian</keyname><forenames>Sos S.</forenames></author></authors><title>Alpha-rooting color image enhancement method by two-side 2-D quaternion
  discrete Fourier transform followed by spatial transformation</title><categories>eess.IV cs.CV</categories><comments>21 pages</comments><journal-ref>International Journal of Applied Control, Electrical and
  Electronics Engineering (IJACEEE) Vol 6, No. 1, February 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a quaternion approach of enhancement method is proposed in
which color in the image is considered as a single entity. This new method is
referred as the alpha-rooting method of color image enhancement by the
two-dimensional quaternion discrete Fourier transform (2-D QDFT) followed by a
spatial transformation. The results of the proposed color image enhancement
method are compared with its counterpart channel-by-channel enhancement
algorithm by the 2-D DFT. The image enhancements are quantified to the
enhancement measure that is based on visual perception referred as the color
enhancement measure estimation (CEME). The preliminary experiment results show
that the quaternion approach of image enhancement is an effective color image
enhancement technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07962</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07962</id><created>2018-07-20</created><authors><author><keyname>Grigoryan</keyname><forenames>Artyom M</forenames></author><author><keyname>John</keyname><forenames>Aparna</forenames></author><author><keyname>Agaian</keyname><forenames>Sos S</forenames></author></authors><title>A Novel Color Image Enhancement Method by the Transformation of Color
  Images to 2-D Grayscale Images</title><categories>eess.IV cs.CV</categories><comments>18 pages</comments><journal-ref>Int J Signal Process Anal 2017, 2:002</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel method of color image enhancement is proposed, in which three or four
color channels of the image are transformed to one channel 2-D grayscale image.
This paper describes different models of such transformations in the RGB and
other color models. Color image enhancement is achieved by enhancing first the
transformed grayscale image and, then, transforming back the grayscale image
into the colors. The color image enhancement is done on the transformed 2-D
grayscale image rather than on the color image. New algorithms of color image
enhancement are described in both frequency and time domains. The enhancement
by this novel method shows good results. The enhancement of the image is
measured with respect to the metric referred to as the Color Enhancement
Measure Estimation (CEME).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.07963</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.07963</id><created>2018-07-20</created><updated>2018-08-19</updated><authors><author><keyname>Wang</keyname><forenames>Jindong</forenames></author><author><keyname>Zheng</keyname><forenames>Vincent W.</forenames></author><author><keyname>Chen</keyname><forenames>Yiqiang</forenames></author><author><keyname>Huang</keyname><forenames>Meiyu</forenames></author></authors><title>Deep Transfer Learning for Cross-domain Activity Recognition</title><categories>eess.IV stat.ML</categories><comments>ICCSE 2018 best paper; 8 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Human activity recognition plays an important role in people's daily life.
However, it is often expensive and time-consuming to acquire sufficient labeled
activity data. To solve this problem, transfer learning leverages the labeled
samples from the source domain to annotate the target domain which has few or
none labels. Unfortunately, when there are several source domains available, it
is difficult to select the right source domains for transfer. The right source
domain means that it has the most similar properties with the target domain,
thus their similarity is higher, which can facilitate transfer learning.
Choosing the right source domain helps the algorithm perform well and prevents
the negative transfer. In this paper, we propose an effective Unsupervised
Source Selection algorithm for Activity Recognition (USSAR). USSAR is able to
select the most similar $K$ source domains from a list of available domains.
After this, we propose an effective Transfer Neural Network to perform
knowledge transfer for Activity Recognition (TNNAR). TNNAR could capture both
the time and spatial relationship between activities while transferring
knowledge. Experiments on three public activity recognition datasets
demonstrate that: 1) The USSAR algorithm is effective in selecting the best
source domains. 2) The TNNAR method can reach high accuracy when performing
activity knowledge transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08084</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08084</id><created>2018-07-21</created><authors><author><keyname>Coelho</keyname><forenames>D. F. G.</forenames></author><author><keyname>Cintra</keyname><forenames>R. J.</forenames></author><author><keyname>Frery</keyname><forenames>A. C.</forenames></author><author><keyname>Dimitrov</keyname><forenames>V. S.</forenames></author></authors><title>Fast Matrix Inversion and Determinant Computation for Polarimetric
  Synthetic Aperture Radar</title><categories>cs.NA cs.DS eess.SP math.NA stat.CO</categories><comments>7 pages, 1 figure</comments><journal-ref>Computers and Geosciences, no. 119 (2018), pages 109-114</journal-ref><doi>10.1016/j.cageo.2018.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a fast algorithm for simultaneous inversion and
determinant computation of small sized matrices in the context of fully
Polarimetric Synthetic Aperture Radar (PolSAR) image processing and analysis.
The proposed fast algorithm is based on the computation of the adjoint matrix
and the symmetry of the input matrix. The algorithm is implemented in a general
purpose graphical processing unit (GPGPU) and compared to the usual approach
based on Cholesky factorization. The assessment with simulated observations and
data from an actual PolSAR sensor show a speedup factor of about two when
compared to the usual Cholesky factorization. Moreover, the expressions
provided here can be implemented in any platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08089</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08089</id><created>2018-07-21</created><updated>2019-01-19</updated><authors><author><keyname>Chen</keyname><forenames>Yi-Chen</forenames></author><author><keyname>Huang</keyname><forenames>Sung-Feng</forenames></author><author><keyname>Shen</keyname><forenames>Chia-Hao</forenames></author><author><keyname>Lee</keyname><forenames>Hung-yi</forenames></author><author><keyname>Lee</keyname><forenames>Lin-shan</forenames></author></authors><title>Phonetic-and-Semantic Embedding of Spoken Words with Applications in
  Spoken Content Retrieval</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted at SLT2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Word embedding or Word2Vec has been successful in offering semantics for text
words learned from the context of words. Audio Word2Vec was shown to offer
phonetic structures for spoken words (signal segments for words) learned from
signals within spoken words. This paper proposes a two-stage framework to
perform phonetic-and-semantic embedding on spoken words considering the context
of the spoken words. Stage 1 performs phonetic embedding with speaker
characteristics disentangled. Stage 2 then performs semantic embedding in
addition. We further propose to evaluate the phonetic-and-semantic nature of
the audio embeddings obtained in Stage 2 by parallelizing with text embeddings.
In general, phonetic structure and semantics inevitably disturb each other. For
example the words &quot;brother&quot; and &quot;sister&quot; are close in semantics but very
different in phonetic structure, while the words &quot;brother&quot; and &quot;bother&quot; are in
the other way around. But phonetic-and-semantic embedding is attractive, as
shown in the initial experiments on spoken document retrieval. Not only spoken
documents including the spoken query can be retrieved based on the phonetic
structures, but spoken documents semantically related to the query but not
including the query can also be retrieved based on the semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08118</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08118</id><created>2018-07-21</created><updated>2019-09-02</updated><authors><author><keyname>Ferraris</keyname><forenames>Vinicius</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>Cavalcanti</keyname><forenames>Yanna</forenames></author><author><keyname>Oberlin</keyname><forenames>Thomas</forenames></author><author><keyname>Chabert</keyname><forenames>Marie</forenames></author></authors><title>Coupled dictionary learning for unsupervised change detection between
  multi-sensor remote sensing images</title><categories>eess.IV cs.CV physics.data-an</categories><comments>Submitted manuscript under consideration at Computer Vision and Image
  Understanding</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Archetypal scenarios for change detection generally consider two images
acquired through sensors of the same modality. However, in some specific cases
such as emergency situations, the only images available may be those acquired
through sensors of different modalities. This paper addresses the problem of
unsupervisedly detecting changes between two observed images acquired by
sensors of different modalities with possibly different resolutions. These
sensor dissimilarities introduce additional issues in the context of
operational change detection that are not addressed by most of the classical
methods. This paper introduces a novel framework to effectively exploit the
available information by modelling the two observed images as a sparse linear
combination of atoms belonging to a pair of coupled overcomplete dictionaries
learnt from each observed image. As they cover the same geographical location,
codes are expected to be globally similar, except for possible changes in
sparse spatial locations. Thus, the change detection task is envisioned through
a dual code estimation which enforces spatial sparsity in the difference
between the estimated codes associated with each image. This problem is
formulated as an inverse problem which is iteratively solved using an efficient
proximal alternating minimization algorithm accounting for nonsmooth and
nonconvex functions. The proposed method is applied to real images with
simulated yet realistic and real changes. A comparison with state-of-the-art
change detection methods evidences the accuracy of the proposed strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08216</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08216</id><created>2018-07-21</created><authors><author><keyname>Cs&#xe1;ji</keyname><forenames>Bal&#xe1;zs Cs.</forenames></author><author><keyname>Campi</keyname><forenames>Marco C.</forenames></author><author><keyname>Weyer</keyname><forenames>Erik</forenames></author></authors><title>Sign-Perturbed Sums: A New System Identification Approach for
  Constructing Exact Non-Asymptotic Confidence Regions in Linear Regression
  Models</title><categories>eess.SP cs.LG stat.ME</categories><comments>12 pages, 7 figures, 8 tables, 32 references</comments><journal-ref>IEEE Transactions on Signal Processing, Volume 63, Issue 1, 2015,
  pp. 169-181</journal-ref><doi>10.1109/TSP.2014.2369000</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new system identification method, called Sign-Perturbed Sums
(SPS), for constructing non-asymptotic confidence regions under mild
statistical assumptions. SPS is introduced for linear regression models,
including but not limited to FIR systems, and we show that the SPS confidence
regions have exact confidence probabilities, i.e., they contain the true
parameter with a user-chosen exact probability for any finite data set.
Moreover, we also prove that the SPS regions are star convex with the
Least-Squares (LS) estimate as a star center. The main assumptions of SPS are
that the noise terms are independent and symmetrically distributed about zero,
but they can be nonstationary, and their distributions need not be known. The
paper also proposes a computationally efficient ellipsoidal outer approximation
algorithm for SPS. Finally, SPS is demonstrated through a number of simulation
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08280</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08280</id><created>2018-07-22</created><authors><author><keyname>Tjandra</keyname><forenames>Andros</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>Multi-scale Alignment and Contextual History for Attention Mechanism in
  Sequence-to-sequence Model</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sequence-to-sequence model is a neural network module for mapping two
sequences of different lengths. The sequence-to-sequence model has three core
modules: encoder, decoder, and attention. Attention is the bridge that connects
the encoder and decoder modules and improves model performance in many tasks.
In this paper, we propose two ideas to improve sequence-to-sequence model
performance by enhancing the attention module. First, we maintain the history
of the location and the expected context from several previous time-steps.
Second, we apply multiscale convolution from several previous attention vectors
to the current decoder state. We utilized our proposed framework for
sequence-to-sequence speech recognition and text-to-speech systems. The results
reveal that our proposed extension could improve performance significantly
compared to a standard attention baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08312</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08312</id><created>2018-07-22</created><authors><author><keyname>Hajibabaei</keyname><forenames>Mahdi</forenames></author><author><keyname>Dai</keyname><forenames>Dengxin</forenames></author></authors><title>Unified Hypersphere Embedding for Speaker Recognition</title><categories>eess.AS cs.AI cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Incremental improvements in accuracy of Convolutional Neural Networks are
usually achieved through use of deeper and more complex models trained on
larger datasets. However, enlarging dataset and models increases the
computation and storage costs and cannot be done indefinitely. In this work, we
seek to improve the identification and verification accuracy of a
text-independent speaker recognition system without use of extra data or deeper
and more complex models by augmenting the training and testing data, finding
the optimal dimensionality of embedding space and use of more discriminative
loss functions. Results of experiments on VoxCeleb dataset suggest that: (i)
Simple repetition and random time-reversion of utterances can reduce prediction
errors by up to 18%. (ii) Lower dimensional embeddings are more suitable for
verification. (iii) Use of proposed logistic margin loss function leads to
unified embeddings with state-of-the-art identification and competitive
verification accuracies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08315</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08315</id><created>2018-07-22</created><updated>2019-05-05</updated><authors><author><keyname>Sharma</keyname><forenames>Nikhilesh</forenames></author><author><keyname>Mastronarde</keyname><forenames>Nicholas</forenames></author><author><keyname>Chakareski</keyname><forenames>Jacob</forenames></author></authors><title>Accelerated Structure-Aware Reinforcement Learning for Delay-Sensitive
  Energy Harvesting Wireless Sensors</title><categories>cs.NI cs.LG eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1803.09778</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate an energy-harvesting wireless sensor transmitting
latency-sensitive data over a fading channel. The sensor injects captured data
packets into its transmission queue and relies on ambient energy harvested from
the environment to transmit them. We aim to find the optimal scheduling policy
that decides whether or not to transmit the queue's head-of-line packet at each
transmission opportunity such that the expected packet queuing delay is
minimized given the available harvested energy. No prior knowledge of the
stochastic processes that govern the channel, captured data, or harvested
energy dynamics are assumed, thereby necessitating the use of online learning
to optimize the scheduling policy. We formulate this scheduling problem as a
Markov decision process (MDP) and analyze the structural properties of its
optimal value function. In particular, we show that it is non-decreasing and
has increasing differences in the queue backlog and that it is non-increasing
and has increasing differences in the battery state. We exploit this structure
to formulate a novel accelerated reinforcement learning (RL) algorithm to solve
the scheduling problem online at a much faster learning rate, while limiting
the induced computational complexity. Our experiments demonstrate that the
proposed algorithm closely approximates the performance of an optimal offline
solution that requires a priori knowledge of the channel, captured data, and
harvested energy dynamics. Simultaneously, by leveraging the value function's
structure, our approach achieves competitive performance relative to a
state-of-the-art RL algorithm, at potentially orders of magnitude lower
complexity. Finally, considerable performance gains are demonstrated over the
well-known and widely used Q-learning algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08316</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08316</id><created>2018-07-22</created><authors><author><keyname>Rajendran</keyname><forenames>Sreeraj</forenames></author><author><keyname>Meert</keyname><forenames>Wannes</forenames></author><author><keyname>Lenders</keyname><forenames>Vincent</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author></authors><title>SAIFE: Unsupervised Wireless Spectrum Anomaly Detection with
  Interpretable Features</title><categories>eess.SP</categories><comments>Copyright IEEE, Accepted for DySPAN 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting anomalous behavior in wireless spectrum is a demanding task due to
the sheer complexity of the electromagnetic spectrum use. Wireless spectrum
anomalies can take a wide range of forms from the presence of an unwanted
signal in a licensed band to the absence of an expected signal, which makes
manual labeling of anomalies difficult and suboptimal. We present, Spectrum
Anomaly Detector with Interpretable FEatures (SAIFE), an Adversarial
Autoencoder (AAE) based anomaly detector for wireless spectrum anomaly
detection using Power Spectral Density (PSD) data which achieves good anomaly
detection and localization in an unsupervised setting. In addition, we
investigate the model's capabilities to learn interpretable features such as
signal bandwidth, class and center frequency in a semi-supervised fashion.
Along with anomaly detection the model exhibits promising results for lossy PSD
data compression up to 120X and semisupervised signal classification accuracy
close to 100% on three datasets just using 20% labeled samples. Finally the
model is tested on data from one of the distributed Electrosense sensors over a
long term of 500 hours showing its anomaly detection capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08505</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08505</id><created>2018-07-23</created><updated>2019-02-25</updated><authors><author><keyname>Fortunati</keyname><forenames>Stefano</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Greco</keyname><forenames>Maria S.</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author></authors><title>The Semiparametric Cram\'er-Rao Bound for Complex Elliptically Symmetric
  Distributions</title><categories>eess.SP</categories><comments>This letter has been merged with another letter and resubmitted as a
  full IEEE TSP paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter aims at extending the Constrained Semiparametric Cramer-Rao Bound
(CSCRB) for the joint estimation of mean vector and scatter matrix of Real
Elliptically Symmetric (RES) distributions to Complex Elliptically Symmetric
(CES) distributions. A closed form expression for the complex CSCRB (CCSCRB) is
derived by exploiting the so-called \textit{Wirtinger} or
$\mathbb{C}\mathbb{R}$-\textit{calculus}. Finally, the CCSCRB for the
estimation of the complex mean vector and scatter matrix of a set of complex
$t$-distributed random vectors is provided as an example of application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08526</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08526</id><created>2018-07-23</created><authors><author><keyname>Rodionov</keyname><forenames>Sergey</forenames></author><author><keyname>Potapov</keyname><forenames>Alexey</forenames></author><author><keyname>Latapie</keyname><forenames>Hugo</forenames></author><author><keyname>Fenoglio</keyname><forenames>Enzo</forenames></author><author><keyname>Peterson</keyname><forenames>Maxim</forenames></author></authors><title>Improving Deep Models of Person Re-identification for Cross-Dataset
  Usage</title><categories>cs.CV eess.IV</categories><comments>AIAI 2018 (14th International Conference on Artificial Intelligence
  Applications and Innovations) proceeding. The final publication is available
  at link.springer.com</comments><doi>10.1007/978-3-319-92007-8_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person re-identification (Re-ID) is the task of matching humans across
cameras with non-overlapping views that has important applications in visual
surveillance. Like other computer vision tasks, this task has gained much with
the utilization of deep learning methods. However, existing solutions based on
deep learning are usually trained and tested on samples taken from same
datasets, while in practice one need to deploy Re-ID systems for new sets of
cameras for which labeled data is unavailable. Here, we mitigate this problem
for one state-of-the-art model, namely, metric embedding trained with the use
of the triplet loss function, although our results can be extended to other
models. The contribution of our work consists in developing a method of
training the model on multiple datasets, and a method for its online
practically unsupervised fine-tuning. These methods yield up to 19.1%
improvement in Rank-1 score in the cross-dataset evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08604</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08604</id><created>2018-07-23</created><authors><author><keyname>Fang</keyname><forenames>Song</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>A Frequency-Domain Characterization of Optimal Error Covariance for the
  Kalman-Bucy Filter</title><categories>cs.SY cs.RO eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discover that the trace of the division of the optimal
output estimation error covariance over the noise covariance attained by the
Kalman-Bucy filter can be explicitly expressed in terms of the plant dynamics
and noise statistics in a frequency-domain integral characterization. Towards
this end, we examine the algebraic Riccati equation associated with Kalman-Bucy
filtering using analytic function theory and relate it to the Bode integral.
Our approach features an alternative, frequency-domain framework for analyzing
algebraic Riccati equations and reduces to various existing related results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08606</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08606</id><created>2018-07-23</created><authors><author><keyname>Pan</keyname><forenames>Jian</forenames></author><author><keyname>Tang</keyname><forenames>Jun</forenames></author><author><keyname>Niu</keyname><forenames>Yong</forenames></author></authors><title>Fast Two-Dimensional Atomic Norm Minimization in Spectrum Estimation and
  Denoising</title><categories>eess.SP cs.IT math.IT</categories><comments>11 pages,9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by recent work on two dimensional (2D) harmonic component recovery
via atomic norm minimization (ANM), a fast 2D direction of arrival (DOA)
off-grid estimation based on ANM method was proposed. By introducing a matrix
atomic norm the 2D DOA estimation problem is turned into matrix atomic norm
minimization (MANM) problem. Since the 2D-ANM gridless DOA estimation is
processed by vectorizing the 2D into 1D estimation and solved via semi-definite
programming (SDP), which is with high computational cost in 2D processing when
the number of antennas increases to large size. In order to overcome this
difficulty, a detail formulation of MANM problem via SDP method is offered in
this paper, the MANM method converts the original $MN+1$ dimensions problem
into a $M+N$ dimensions SDP problem and greatly reduces the computational
complexity. In this paper we study the problem of 2D line spectrally-sparse
signal recovery from partial noiseless observations and full noisy
observations, both of which can be solved efficiently via MANM method and
obtain high accuracy estimation of the true 2D angles. We give a sufficient
condition of the optimality condition of the proposed method and prove an up
bound of the expected error rate for denoising. Finally, numerical simulations
are conducted to show the efficiency and performance of the proposed method,
with comparisons against several existed sparse methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08615</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08615</id><created>2018-07-19</created><updated>2018-07-24</updated><authors><author><keyname>Selim</keyname><forenames>Mohamed Y.</forenames></author><author><keyname>Alsharoa</keyname><forenames>Ahmad</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Short-term and Long-term Cell Outage Compensation Using UAVs in 5G
  Networks</title><categories>eess.SP cs.NI</categories><comments>Globecom 2018 (6 pages, 3 figures, 3 tables, conference)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of Unmanned Aerial Vehicles (UAVs) has gained interest in wireless
networks for its many uses and advantages such as rapid deployment and
multi-purpose functionality. This is why wide deployment of UAVs has the
potential to be integrated in the upcoming 5G standard. They can be used as
flying base-stations, which can be deployed in case of ground Base-Stations
(GBSs) failures. Such failures can be short-term or long-term. Based on the
type and duration of the failure, we propose a framework that uses drones or
helikites to mitigate GBS failures. Our proposed short-term and long-term cell
outage compensation framework aims to mitigate the effect of the failure of any
GBS in 5G networks. Within our framework, outage compensation is done with the
assistance of sky BSs (UAVs). An optimization problem is formulated to jointly
minimize communication power of the UAVs and maximize the minimum rates of the
Users' Equipment (UEs) affected by the failure. Also, the optimal placement of
the UAVs is determined. Simulation results show that the proposed framework
guarantees the minimum quality of service for each UE in addition to minimizing
the UAVs' consumed energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08627</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08627</id><created>2018-07-19</created><authors><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Ghasemi</keyname><forenames>Mahsa</forenames></author><author><keyname>Vikalo</keyname><forenames>Haris</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Randomized Greedy Sensor Selection: Leveraging Weak Submodularity</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1709.08823</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of estimating a random process from the observations
collected by a network of sensors that operate under resource constraints. When
the dynamics of the process and sensor observations are described by a
state-space model and the resource are unlimited, the conventional Kalman
filter provides the minimum mean-square error (MMSE) estimates. However, at any
given time, restrictions on the available communications bandwidth and
computational capabilities and/or power impose a limitation on the number of
network nodes whose observations can be used to compute the estimates. We
formulate the problem of selecting the most informative subset of the sensors
as a combinatorial problem of maximizing a monotone set function under a
uniform matroid constraint. For the MMSE estimation criterion we show that the
maximum element-wise curvature of the objective function satisfies a certain
upper-bound constraint and is, therefore, weak submodular. We develop an
efficient randomized greedy algorithm for sensor selection and establish
guarantees on the estimator's performance in this setting. Extensive simulation
results demonstrate the efficacy of the randomized greedy algorithm compared to
state-of-the-art greedy and semidefinite programming relaxation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08636</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08636</id><created>2018-07-23</created><authors><author><keyname>Grachten</keyname><forenames>Maarten</forenames></author><author><keyname>Deruty</keyname><forenames>Emmanuel</forenames></author><author><keyname>Tanguy</keyname><forenames>Alexandre</forenames></author></authors><title>Auto-adaptive Resonance Equalization using Dilated Residual Networks</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In music and audio production, attenuation of spectral resonances is an
important step towards a technically correct result. In this paper we present a
two-component system to automate the task of resonance equalization. The first
component is a dynamic equalizer that automatically detects resonances and
offers to attenuate them by a user-specified factor. The second component is a
deep neural network that predicts the optimal attenuation factor based on the
windowed audio. The network is trained and validated on empirical data gathered
from an experiment in which sound engineers choose their preferred attenuation
factors for a set of tracks. We test two distinct network architectures for the
predictive model and find that a dilated residual network operating directly on
the audio signal is on a par with a network architecture that requires a prior
audio feature extraction stage. Both architectures predict human-preferred
resonance attenuation factors significantly better than a baseline approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08671</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08671</id><created>2018-07-23</created><authors><author><keyname>You</keyname><forenames>Xiaohu</forenames><affiliation>National Mobile Communications Research Laboratory, Southeast University, China</affiliation></author><author><keyname>Zhang</keyname><forenames>Chuan</forenames><affiliation>National Mobile Communications Research Laboratory, Southeast University, China</affiliation></author><author><keyname>Tan</keyname><forenames>Xiaosi</forenames><affiliation>National Mobile Communications Research Laboratory, Southeast University, China</affiliation></author><author><keyname>Jin</keyname><forenames>Shi</forenames><affiliation>National Mobile Communications Research Laboratory, Southeast University, China</affiliation></author><author><keyname>Wu</keyname><forenames>Hequan</forenames><affiliation>Chinese Academy of Engineering, China</affiliation></author></authors><title>AI for 5G: Research Directions and Paradigms</title><categories>eess.SP</categories><comments>This paper is an overview paper composed in English</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 5th wireless communication (5G) techniques not only fulfil the
requirement of $1,000$ times increase of internet traffic in the next decade,
but also offer the underlying technologies to the entire industry and ecology
for internet of everything. Compared to the existing mobile communication
techniques, 5G techniques are more-widely applicable and the corresponding
system design is more complicated. The resurgence of artificial intelligence
(AI) techniques offers as an alternative option, which is possibly superior
over traditional ideas and performance. Typical and potential research
directions to which AI can make promising contributions need to be identified,
evaluated, and investigated. To this end, this overview paper first combs
through several promising research directions of AI for 5G, based on the
understanding of the 5G key techniques. Also, the paper devotes itself in
providing design paradigms including 5G network optimization, optimal resource
allocation, 5G physical layer unified acceleration, end-to-end physical layer
joint optimization, and so on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08720</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08720</id><created>2018-07-23</created><authors><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author><author><keyname>Kanna</keyname><forenames>Sithan</forenames></author><author><keyname>Xia</keyname><forenames>Yili</forenames></author><author><keyname>Moniri</keyname><forenames>Ahmad</forenames></author><author><keyname>Constantinides</keyname><forenames>Anthony G.</forenames></author></authors><title>A Data Analytics Perspective of the Clarke and Related Transforms in
  Power Grid Analysis</title><categories>eess.SP</categories><comments>20 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Affordable and reliable electric power is fundamental to modern society and
economy, with the Smart Grid becoming an increasingly important factor in power
generation and distribution. In order to fully exploit it advantages, the
analysis of modern Smart Grid requires close collaboration and convergence
between power engineers and signal processing and machine learning experts.
Current analysis techniques are typically derived from a Circuit Theory
perspective; such an approach is adequate for only fully balanced systems
operating at nominal conditions and non-obvious for data scientists - this is
prohibitive for the analysis of dynamically unbalanced smart grids, where Data
Analytics is not only well suited but also necessary. A common language that
bridges the gap between Circuit Theory and Data Analytics, and the respective
community of experts, would be a natural step forward. To this end, we revisit
the Clarke and related transforms from a subspace, latent component, and
spatial frequency analysis frameworks, to establish fundamental relationships
between the standard three-phase transforms and modern Data Analytics. We show
that the Clarke transform admits a physical interpretation as a &quot;spatial
dimensionality&quot; reduction technique which is equivalent to Principal Component
Analysis (PCA) for balanced systems, but is sub-optimal for dynamically
unbalanced systems, such as the Smart Grid, while the related Park transform
performs further &quot;temporal&quot; dimensionality reduction. Such a perspective opens
numerous new avenues for the use Signal Processing and Machine Learning in
power grid research, and paves the way for innovative optimisation,
transformation, and analysis techniques that are not accessible to arrive at
from the standard Circuit Theory principles, as demonstrated in this work
through the possibility of simultaneous frequency estimation and fault
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08792</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08792</id><created>2018-07-23</created><authors><author><keyname>Mehrabian</keyname><forenames>Armin</forenames></author><author><keyname>Al-Kabani</keyname><forenames>Yousra</forenames></author><author><keyname>Sorger</keyname><forenames>Volker J</forenames></author><author><keyname>El-Ghazawi</keyname><forenames>Tarek</forenames></author></authors><title>PCNNA: A Photonic Convolutional Neural Network Accelerator</title><categories>cs.ET cs.LG eess.SP</categories><comments>5 Pages, 6 Figures, IEEE SOCC 2018</comments><doi>10.1109/SOCC.2018.8618542</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNN) have been the centerpiece of many
applications including but not limited to computer vision, speech processing,
and Natural Language Processing (NLP). However, the computationally expensive
convolution operations impose many challenges to the performance and
scalability of CNNs. In parallel, photonic systems, which are traditionally
employed for data communication, have enjoyed recent popularity for data
processing due to their high bandwidth, low power consumption, and
reconfigurability. Here we propose a Photonic Convolutional Neural Network
Accelerator (PCNNA) as a proof of concept design to speedup the convolution
operation for CNNs. Our design is based on the recently introduced silicon
photonic microring weight banks, which use broadcast-and-weight protocol to
perform Multiply And Accumulate (MAC) operation and move data through layers of
a neural network. Here, we aim to exploit the synergy between the inherent
parallelism of photonics in the form of Wavelength Division Multiplexing (WDM)
and sparsity of connections between input feature maps and kernels in CNNs.
While our full system design offers up to more than 3 orders of magnitude
speedup in execution time, its optical core potentially offers more than 5
order of magnitude speedup compared to state-of-the-art electronic
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08855</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08855</id><created>2018-07-23</created><authors><author><keyname>Chen</keyname><forenames>Zhaozhong</forenames></author><author><keyname>Heckman</keyname><forenames>Christoffer</forenames></author><author><keyname>Julier</keyname><forenames>Simon</forenames></author><author><keyname>Ahmed</keyname><forenames>Nisar</forenames></author></authors><title>Weak in the NEES?: Auto-tuning Kalman Filters with Bayesian Optimization</title><categories>stat.ML cs.LG cs.RO cs.SY eess.SP</categories><comments>Final version presented at FUSION 2018 Conference, Cambridge, UK,
  July 2018 (submitted June 1, 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kalman filters are routinely used for many data fusion applications including
navigation, tracking, and simultaneous localization and mapping problems.
However, significant time and effort is frequently required to tune various
Kalman filter model parameters, e.g. process noise covariance, pre-whitening
filter models for non-white noise, etc. Conventional optimization techniques
for tuning can get stuck in poor local minima and can be expensive to implement
with real sensor data. To address these issues, a new &quot;black box&quot; Bayesian
optimization strategy is developed for automatically tuning Kalman filters. In
this approach, performance is characterized by one of two stochastic objective
functions: normalized estimation error squared (NEES) when ground truth state
models are available, or the normalized innovation error squared (NIS) when
only sensor data is available. By intelligently sampling the parameter space to
both learn and exploit a nonparametric Gaussian process surrogate function for
the NEES/NIS costs, Bayesian optimization can efficiently identify multiple
local minima and provide uncertainty quantification on its results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08869</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08869</id><created>2018-07-23</created><updated>2019-07-12</updated><authors><author><keyname>And&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Lostanlen</keyname><forenames>Vincent</forenames></author><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Joint Time-Frequency Scattering</title><categories>cs.SD eess.AS</categories><comments>14 pages, 10 figures</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 67, no. 14, pp.
  3704-3718, July 15, 2019</journal-ref><doi>10.1109/TSP.2019.2918992</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In time series classification and regression, signals are typically mapped
into some intermediate representation used for constructing models. Since the
underlying task is often insensitive to time shifts, these representations are
required to be time-shift invariant. We introduce the joint time-frequency
scattering transform, a time-shift invariant representation which characterizes
the multiscale energy distribution of a signal in time and frequency. It is
computed through wavelet convolutions and modulus non-linearities and may
therefore be implemented as a deep convolutional neural network whose filters
are not learned but calculated from wavelets. We consider the progression from
mel-spectrograms to time scattering and joint time-frequency scattering
transforms, illustrating the relationship between increased discriminability
and refinements of convolutional network architectures. The suitability of the
joint time-frequency scattering transform for time-shift invariant
characterization of time series is demonstrated through applications to chirp
signals and audio synthesis experiments. The proposed transform also obtains
state-of-the-art results on several audio classification tasks, outperforming
time scattering transforms and achieving accuracies comparable to those of
fully learned networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08914</identifier>
 <datestamp>2019-03-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08914</id><created>2018-07-24</created><updated>2019-03-14</updated><authors><author><keyname>Liu</keyname><forenames>Huan</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author><author><keyname>Tao</keyname><forenames>Ran</forenames></author></authors><title>Variation of a Signal in Schwarzschild Spacetime</title><categories>eess.SP</categories><comments>13 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the variation of a signal in Schwarzschild spacetime is
studied and a general equation for frequency shift parameter (FSP) is
presented. It shows that FSP depends on the gravitationally-modified Doppler
effects and the gravitational effects of observers. In addition, rates of time
of a transmitter and a receiver may be different. When FSP is a function of the
time of a receiver, FSP contributed by gravitational effect (GFSP) or
gravitationally-modified Doppler effect (GMDFSP) may lead a bandlimited signal
to a non-bandlimited signal. Based on the equation, FSP as a function of the
time of a receiver is calculated for three scenarios: a) a spaceship moves away
from a star with a constant velocity communicating with a transmitter at a
fixed position; b) a spaceship moves around a star with different conic
trajectories communicating with a transmitter at a fixed position; c) a signal
is transmitted at a fixed position in a star system to a receiver moving with
an elliptical trajectory in another star system. The studied stars are sun-like
star, white dwarf and neutron star, and some numerical examples are presented
to illustrate the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08936</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08936</id><created>2018-07-24</created><updated>2019-02-25</updated><authors><author><keyname>Fortunati</keyname><forenames>Stefano</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Greco</keyname><forenames>Maria S.</forenames></author></authors><title>Semiparametric Slepian-Bangs Formula for Complex Elliptically Symmetric
  Distributions</title><categories>eess.SP</categories><comments>This letter has been merged with another letter and resubmitted as a
  full IEEE TSP paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter aims at deriving a Semiparametric Slepian-Bangs (SSB) formula for
Complex Elliptically Symmetric (CES) distributed data vectors. The
Semiparametric Cram\'{e}r-Rao Bound (SCRB), related to the proposed SSB
formula, provides a lower bound on the Mean Square Error (MSE) of \textit{any}
robust estimator of a parameter vector parameterizing the mean vector and the
scatter matrix of the given CES-distributed vector in the presence of an
unknown, nuisance, density generator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08974</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08974</id><created>2018-07-24</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Su</keyname><forenames>Dan</forenames></author><author><keyname>Chen</keyname><forenames>Lianwu</forenames></author><author><keyname>Yu</keyname><forenames>Meng</forenames></author><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Deep Extractor Network for Target Speaker Recovery From Single Channel
  Speech Mixtures</title><categories>cs.SD eess.AS</categories><comments>Accepted in Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker-aware source separation methods are promising workarounds for major
difficulties such as arbitrary source permutation and unknown number of
sources. However, it remains challenging to achieve satisfying performance
provided a very short available target speaker utterance (anchor). Here we
present a novel &quot;deep extractor network&quot; which creates an extractor point for
the target speaker in a canonical high dimensional embedding space, and pulls
together the time-frequency bins corresponding to the target speaker. The
proposed model is different from prior works in that the canonical embedding
space encodes knowledges of both the anchor and the mixture during an
end-to-end training phase: First, embeddings for the anchor and mixture speech
are separately constructed in a primary embedding space, and then combined as
an input to feed-forward layers to transform to a canonical embedding space
which we discover more stable than the primary one. Experimental results show
that given a very short utterance, the proposed model can efficiently recover
high quality target speech from a mixture, which outperforms various baseline
models, with 5.2% and 6.6% relative improvements in SDR and PESQ respectively
compared with a baseline oracle deep attracor model. Meanwhile, we show it can
be generalized well to more than one interfering speaker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.08978</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.08978</id><created>2018-07-24</created><authors><author><keyname>Lopez-Fernandez</keyname><forenames>J.</forenames></author><author><keyname>Lopez-Martinez</keyname><forenames>F. J.</forenames></author></authors><title>Statistical Characterization of Second Order Scattering Fading Channels</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to the statistical characterization of the second
order scattering fading (SOSF) channel model, which greatly simplifies its
analysis. Exploiting the unadvertised fact that the SOSF channel can be seen as
a continuous mixture of Rician fading channels, we obtain expressions for its
probability density function and cumulative density function that are
numerically better-behaved than those available in the literature. Our approach
allows for obtaining new results for the SOSF model, such as a closed-form
expression for its moment-generating function, as well as the characterization
of the average channel capacity. Relevantly, and somehow counterintuitively, we
observe that in the presence of a strong line-of-sight (LOS) component, the
channel capacity of a LOS plus double-Rayleigh scattered diffuse component is
larger than its LOS plus Rayleigh (i.e Rician-like) counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09094</identifier>
 <datestamp>2018-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09094</id><created>2018-07-22</created><updated>2018-10-24</updated><authors><author><keyname>Nasim</keyname><forenames>Imtiaz</forenames></author><author><keyname>Kim</keyname><forenames>Seungmo</forenames></author></authors><title>Mitigation of Human RF Exposure in 5G Downlink</title><categories>eess.SP</categories><comments>This is an extension of our previous work, arXiv:1711.03683, and has
  been submitted to IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While research on communications at frequencies above 6 gigahertz (GHz) has
been primarily confined to performance improvement, their potentially harmful
impacts on human health are not studied as significantly. Most of the existing
studies that paid attention to the health impacts above 6 GHz focused only on
the uplink due to closer contact with a transmitter to a human body. In this
letter, we present the human electromagnetic field (EMF) exposure in the
downlink of Fifth-Generation Wireless Systems (5G). Moreover, we propose a
downlink protocol that guarantees the EMF exposure under a threshold while
keeping the data rate above the 5G requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09114</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09114</id><created>2018-07-24</created><authors><author><keyname>Kurisummoottil</keyname><forenames>Christo Thomas</forenames></author><author><keyname>Tabikh</keyname><forenames>Wassim</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author><author><keyname>Yuan-Wu</keyname><forenames>Yi</forenames></author></authors><title>Noncoherent Multi-User MIMO Communications using Covariance CSIT</title><categories>eess.SP</categories><comments>Published in: 2017 51st Asilomar Conference on Signals, Systems, and
  Computers</comments><doi>10.1109/ACSSC.2017.8335551</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Multi-User downlink, particularly in a Multi-Cell Massive MIMO setting,
requires enormous amounts of instantaneous CSIT (Channel State Information at
the Transmitter(s)), iCSIT. Here we focus on exploiting channel covariance CSIT
(coCSIT) only. In particular multipath induced structured low rank covariances
are considered that arise in Massive MIMO and mmWave settings, which we call
pathwise CSIT (pwCSIT). The resulting non-Kronecker MIMO channel covariance
structures lead to a split between the roles of transmitters and receivers in
MIMO systems. For the beamforming optimization, we consider a minorization
approach applied to the Massive MIMO limit of the Expected Weighted Sum Rate.
Simulations indicate that the pwCSIT based designs may lead to limited spectral
efficiency loss compared to iCSIT based designs, while trading fast fading CSIT
for slow fading CSIT. We also point out that the pathwise approach may lead to
distributed designs with only local pwCSIT, and analyze the sum rates for iCSIT
and pwCSIT in the low and high SNR limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09119</identifier>
 <datestamp>2018-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09119</id><created>2018-07-23</created><updated>2018-10-28</updated><authors><author><keyname>Aggarwal</keyname><forenames>Karan</forenames></author><author><keyname>Khadanga</keyname><forenames>Swaraj</forenames></author><author><keyname>Joty</keyname><forenames>Shafiq R.</forenames></author><author><keyname>Kazaglis</keyname><forenames>Louis</forenames></author><author><keyname>Srivastava</keyname><forenames>Jaideep</forenames></author></authors><title>A Structured Learning Approach with Neural Conditional Random Fields for
  Sleep Staging</title><categories>eess.SP cs.LG stat.ML</categories><comments>Accepted at IEEE International Conference on BigData 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sleep plays a vital role in human health, both mental and physical. Sleep
disorders like sleep apnea are increasing in prevalence, with the rapid
increase in factors like obesity. Sleep apnea is most commonly treated with
Continuous Positive Air Pressure (CPAP) therapy. Presently, however, there is
no mechanism to monitor a patient's progress with CPAP. Accurate detection of
sleep stages from CPAP flow signal is crucial for such a mechanism. We propose,
for the first time, an automated sleep staging model based only on the flow
signal. Deep neural networks have recently shown high accuracy on sleep staging
by eliminating handcrafted features. However, these methods focus exclusively
on extracting informative features from the input signal, without paying much
attention to the dynamics of sleep stages in the output sequence. We propose an
end-to-end framework that uses a combination of deep convolution and recurrent
neural networks to extract high-level features from raw flow signal with a
structured output layer based on a conditional random field to model the
temporal transition structure of the sleep stages. We improve upon the previous
methods by 10% using our model, that can be augmented to the previous sleep
staging deep learning methods. We also show that our method can be used to
accurately track sleep metrics like sleep efficiency calculated from sleep
stages that can be deployed for monitoring the response of CPAP therapy on
sleep apnea patients. Apart from the technical contributions, we expect this
study to motivate new research questions in sleep science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09126</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09126</id><created>2018-07-23</created><updated>2019-06-13</updated><authors><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Shoshan</keyname><forenames>Eli</forenames></author><author><keyname>Namer</keyname><forenames>Moshe</forenames></author><author><keyname>Meltsin</keyname><forenames>Maxim</forenames></author></authors><title>A Cognitive Sub-Nyquist MIMO Radar Prototype</title><categories>eess.SP cs.IT math.IT</categories><comments>15 pages, 18 figures, 4 tables. arXiv admin note: text overlap with
  arXiv:1803.01819</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a cognitive prototype that demonstrates a colocated,
frequency-division-multiplexed, multiple-input multiple-output (MIMO) radar
which implements both temporal and spatial sub-Nyquist sampling. The signal is
sampled and recovered via the Xampling framework. Cognition is due to the fact
that the transmitter adapts its signal spectrum by emitting only those subbands
that the receiver samples and processes. Real-time experiments demonstrate
sub-Nyquist MIMO recovery of target scenes with 87.5% spatio-temporal bandwidth
reduction and signal-to-noise-ratio of -10 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09196</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09196</id><created>2018-07-24</created><updated>2018-12-13</updated><authors><author><keyname>Kadu</keyname><forenames>Ajinkya</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Tristan</forenames></author></authors><title>A Convex Formulation for Binary Tomography</title><categories>eess.IV cs.CE eess.SP math.OC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Binary tomography is concerned with the recovery of binary images from a few
of their projections (i.e., sums of the pixel values along various directions).
To reconstruct an image from noisy projection data, one can pose it as a
constrained least-squares problem. As the constraints are non-convex, many
approaches for solving it rely on either relaxing the constraints or
heuristics. In this paper we propose a novel convex formulation, based on the
Lagrange dual of the constrained least-squares problem. The resulting problem
is a generalized LASSO problem which can be solved efficiently. It is a
relaxation in the sense that it can only be guaranteed to give a feasible
solution; not necessarily the optimal one. In exhaustive experiments on small
images (2x2, 3x3, 4x4) we find, however, that if the problem has a unique
solution, our dual approach finds it. In case of multiple solutions, our
approach finds the commonalities between the solutions. Further experiments on
realistic numerical phantoms and an experiment on X-ray dataset show that our
method compares favourably to Total Variation and DART.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09208</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09208</id><created>2018-07-24</created><authors><author><keyname>Park</keyname><forenames>Jiyoung</forenames></author><author><keyname>Kim</keyname><forenames>Donghyun</forenames></author><author><keyname>Lee</keyname><forenames>Jongpil</forenames></author><author><keyname>Kum</keyname><forenames>Sangeun</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>A Hybrid of Deep Audio Feature and i-vector for Artist Recognition</title><categories>cs.SD eess.AS</categories><comments>Joint Workshop on Machine Learning for Music, the 34th International
  Conference on Machine Learning (ICML), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artist recognition is a task of modeling the artist's musical style. This
problem is challenging because there is no clear standard. We propose a hybrid
method of the generative model i-vector and the discriminative model deep
convolutional neural network. We show that this approach achieves
state-of-the-art performance by complementing each other. In addition, we
briefly explain the advantages and disadvantages of each approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09213</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09213</id><created>2018-07-24</created><authors><author><keyname>Salehghaffari</keyname><forenames>Hossein</forenames></author></authors><title>Hardware-In-The-Loop Vulnerability Analysis of a Single-Machine
  Infinite-Bus Power System</title><categories>eess.SP</categories><comments>Pages1-6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic performance of the generators is a critical factor for the safe
operation of the power grid. To this extent, the stability of the frequency of
generators is the target of cyber attacks since its instability may lead to
sizable cascade failures in the whole network. In this paper, we perform the
vulnerability analysis in a developed power grid Hardware-In-The-Loop (HITL)
testbed with a Wago 750-881 PLC sending control commands to the generators and
a 750 Feeder Management Relay connected to a local load. A process-aware
coordinated attack is demonstrated by spoofing control commands sent by the PLC
and the relay to the simulated power system which is modeled as a
single-machine infinite-bus (SMIB). Based on the reachability analysis, the
attacker can find the optimal attack signal to drive the system state out of
their safe set of values. Thereafter, it is experimentally demonstrated that
the attacker does not need to send attack signal continuously if he implements
a carefully designed coordinated attack on the PLC and the relay. The presented
assessments provide information about the best time to launch an attack in
order to destabilize the power system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09220</identifier>
 <datestamp>2018-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09220</id><created>2018-07-09</created><authors><author><keyname>Tian</keyname><forenames>Rui</forenames></author></authors><title>Detecting gasoline in small public places based on wireless sensor
  network</title><categories>eess.SP cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fire accidents often cause unpredictable catastrophic losses. At present,
existing fire prevention measures in public places are mostly based on the
emergency treatments after the fire, which have limited protection capability
when the fire spreads rapidly, especially for the flammable liquid explosion
accident. Based on the gas sensor network, this paper proposes a detection
framework as well as detail technologies to detect flammable liquid existing in
small spaces. We propose to use sensor network to detect the flammable liquids
through monitoring the concentrations of the target liquid vapor diffused in
the air. Experiment results show that, the proposed surveillant system can
detect the gasoline components in small space with high sensitivity while
maintaining very low false detection rates to external interferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09221</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09221</id><created>2018-07-10</created><authors><author><keyname>Curiac</keyname><forenames>Daniel-Ioan</forenames></author><author><keyname>Banias</keyname><forenames>Ovidiu</forenames></author><author><keyname>Borza</keyname><forenames>Ioan</forenames></author></authors><title>Structural health monitoring with distributed wireless sensor networks</title><categories>eess.SP cs.NI</categories><journal-ref>Instalatii pentru constructii si mediul ambiental, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks(WSN) are a today technology with great
practicability in the real world. We focus on describing WSN architecture,
regarding usefulness in constructions like structural health monitoring and
importance, and advantages of using WSN in this domain
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09222</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09222</id><created>2018-07-11</created><authors><author><keyname>Banias</keyname><forenames>Ovidiu</forenames></author><author><keyname>Curiac</keyname><forenames>Daniel-Ioan</forenames></author><author><keyname>Precup</keyname><forenames>Radu-Emil</forenames></author></authors><title>Sensor Networks Architecture for Vehicles and Pedestrians Traffic
  Control</title><categories>eess.SP cs.NI cs.SE</categories><journal-ref>Scientific Bulletin of The Politehnica University of Timisoara,
  Romania, Transactions on Automatic Control and Computer Science, vol. 51, no.
  3, pp. 11-16, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a sensor network based architecture for urban
traffic management, hierarchically structured on three layers: sensing,
processing&amp; aggregation and control. On proposed architecture we define traffic
decongestion methods for vehicles and also for pedestrians. Finally, we
presented a case study on how traffic control can be implemented in a concrete
situation, based on the proposed architecture, pointing future directions of
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09305</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09305</id><created>2018-07-24</created><authors><author><keyname>Preiswerk</keyname><forenames>Frank</forenames></author><author><keyname>Cheng</keyname><forenames>Cheng-Chieh</forenames></author><author><keyname>Luo</keyname><forenames>Jie</forenames></author><author><keyname>Madore</keyname><forenames>Bruno</forenames></author></authors><title>Synthesizing dynamic MRI using long-term recurrent convolutional
  networks</title><categories>eess.IV</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is proposed for converting raw ultrasound signals of respiratory
organ motion into high frame rate dynamic MRI using a long-term recurrent
convolutional neural network. Ultrasound signals were acquired using a
single-element transducer, referred to here as `organ-configuration motion'
(OCM) sensor, while sagittal MR images were simultaneously acquired. Both
streams of data were used for training a cascade of convolutional layers, to
extract relevant features from raw ultrasound, followed by a recurrent neural
network, to learn its temporal dynamics. The network was trained with MR images
on the output, and was employed to predict MR images at a temporal resolution
of 100 frames per second, based on ultrasound input alone, without any further
MR scanner input. The method was validated on 7 subjects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09319</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09319</id><created>2018-07-24</created><authors><author><keyname>D'Souza</keyname><forenames>Niharika Shimona</forenames></author><author><keyname>Nebel</keyname><forenames>Mary Beth</forenames></author><author><keyname>Wymbs</keyname><forenames>Nicholas</forenames></author><author><keyname>Mostofsky</keyname><forenames>Stewart</forenames></author><author><keyname>Venkataraman</keyname><forenames>Archana</forenames></author></authors><title>A Generative-Discriminative Basis Learning Framework to Predict Clinical
  Severity from Resting State Functional MRI Data</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a matrix factorization technique that decomposes the resting state
fMRI (rs-fMRI) correlation matrices for a patient population into a sparse set
of representative subnetworks, as modeled by rank one outer products. The
subnetworks are combined using patient specific non-negative coefficients;
these coefficients are also used to model, and subsequently predict the
clinical severity of a given patient via a linear regression. Our
generative-discriminative framework is able to exploit the structure of rs-fMRI
correlation matrices to capture group level effects, while simultaneously
accounting for patient variability. We employ ten fold cross validation to
demonstrate the predictive power of our model on a cohort of fifty eight
patients diagnosed with Autism Spectrum Disorder. Our method outperforms
classical semi-supervised frameworks, which perform dimensionality reduction on
the correlation features followed by non-linear regression to predict the
clinical scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09338</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09338</id><created>2018-07-24</created><authors><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author></authors><title>C-V2X Security Requirements and Procedures: Survey and Research
  Directions</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3rd Generation Partnership Project (3GPP) defines the first
specifications for cellular-based vehicle-to-everything (C-V2X) communications
in Release 14. C-V2X extends LTE's device-to-device communication modes by
adding two new modes of operation for vehicular systems in coverage and out of
coverage of an LTE base station, or eNB. The vehicle-to-vehicle (V2V)
communication mode does not rely on the cellular infrastructure and the C-V2X
devices employ a distributed and sensing-based semi-persistent scheduling to
schedule their packet transmissions. As a promising alternative to dedicated
short range communications, the security aspects of C-V2X need to be carefully
designed and evaluated to ensure the availability and integrity of the service
and data. This paper discusses possible threat scenarios, reviews the 3GPP
specifications and finds that, despite the safety-critical nature of C-V2X,
only few mechanisms and procedures have be specified to secure the system. We
discuss emerging technologies and provide research directions to improve C-V2X
system security and reliability and ensure their widespread adoption in
civilian and mission-critical communication contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09359</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09359</id><created>2018-07-24</created><authors><author><keyname>Meng</keyname><forenames>Xiangyu</forenames></author><author><keyname>Houshmand</keyname><forenames>Arian</forenames></author><author><keyname>Cassandras</keyname><forenames>Christos G.</forenames></author></authors><title>Multi-Agent Coverage Control with Energy Depletion and Repletion</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a hybrid system model to describe the behavior of multiple agents
cooperatively solving an optimal coverage problem under energy depletion and
repletion constraints. The model captures the controlled switching of agents
between coverage (when energy is depleted) and battery charging (when energy is
replenished) modes. It guarantees the feasibility of the coverage problem by
defining a guard function on each agent's battery level to prevent it from
dying on its way to a charging station. The charging station plays the role of
a centralized scheduler to solve the contention problem of agents competing for
the only charging resource in the mission space. The optimal coverage problem
is transformed into a parametric optimization problem to determine an optimal
recharging policy. This problem is solved through the use of Infinitesimal
Perturbation Analysis (IPA), with simulation results showing that a full
recharging policy is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09414</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09414</id><created>2018-07-24</created><updated>2019-01-01</updated><authors><author><keyname>Cheng</keyname><forenames>Qingqing</forenames></author><author><keyname>Shi</keyname><forenames>Zhenguo</forenames></author><author><keyname>Nguyen</keyname><forenames>Diep N.</forenames></author><author><keyname>Dutkiewicz</keyname><forenames>Eryk</forenames></author></authors><title>Deep Learning Network Based Spectrum Sensing Methods for OFDM Systems</title><categories>eess.SP</categories><comments>32 pages, 15 figures, 4 table, two algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing plays a critical role in dynamic spectrum sharing, a
promising technology to address the radio spectrum shortage. In particular,
sensing of Orthogonal frequency division multiplexing (OFDM) signals, a widely
accepted multi-carrier transmission paradigm, has received paramount interest.
Despite various efforts, most conventional OFDM sensing methods suffer from
noise uncertainty, timing delay and carrier frequency offset (CFO) that
significantly degrade the sensing accuracy. To address these challenges, this
work develops two novel OFDM sensing frameworks drawing support from deep
learning networks. Specifically, we first propose a stacked autoencoder based
spectrum sensing method (SAE-SS), in which a stacked autoencoder network is
designed to extract the inherent features of OFDM signals. Using these features
to classify the OFDM user's activities, SAE-SS is much more robust to noise
uncertainty, timing delay, and CFO than the conventional OFDM sensing methods.
Moreover, SAE-SS doesn't require any prior information of signals (e.g., signal
structure, pilot tones, cyclic prefix) which are essential for the conventional
feature-based OFDM sensing methods. To further improve the sensing accuracy of
SAE-SS, especially under low SNR conditions, we propose a stacked autoencoder
based spectrum sensing method using time-frequency domain signals (SAE-TF).
SAE-TF achieves higher sensing accuracy than SAW-SS at the cost of higher
computational complexity. Extensive simulation results show that both SAE-SS
and SAE-TF can achieve significantly higher sensing accuracy, compared with
state of the art approaches that suffer from noise uncertainty, timing delay
and CFO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09458</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09458</id><created>2018-07-25</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana</forenames></author><author><keyname>Tato</keyname><forenames>Anxo</forenames></author><author><keyname>Mosquera</keyname><forenames>Carlos</forenames></author></authors><title>Channel Dependent Mutual Information in Index Modulations</title><categories>eess.SP cs.ET cs.IT math.IT</categories><journal-ref>In Proceedings of IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP) 2018, 15-20 April 2018, Alberta, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mutual Information is the metric that is used to perform link adaptation,
which allows to achieve rates near capacity. The computation of adaptive
transmission modes is achieved by employing the mapping between the Signal to
Noise Ratio and the Mutual Information. Due to the high complexity of the
computation of the Mutual Information, this process is performed off-line via
Monte Carlo simulations, whose results are stored in look-up tables. However,
in Index Modulations, such as Spatial Modulation or Polarized Modulation, this
is not feasible since the constellation and the Mutual Information are channel
dependent and it would require to compute this metric at each time instant if
the channel is time varying. In this paper, we propose different approximations
in order to obtain a simple closed-form expression that allows to compute the
Mutual Information at each time instant and thus, making feasible the link
adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09460</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09460</id><created>2018-07-25</created><authors><author><keyname>Tato</keyname><forenames>Anxo</forenames></author><author><keyname>Mosquera</keyname><forenames>Carlos</forenames></author><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>Perez-Neira</keyname><forenames>Ana</forenames></author></authors><title>Practical Implementation of Link Adaptation with Dual Polarized
  Modulation</title><categories>eess.SP cs.ET cs.IT math.IT</categories><journal-ref>In Proceedings of 11th IEEE/IET International Symposium on
  Communication Systems, Networks, and Digital Signal Processing, 18-20 July
  2018, Budapest, Hungary</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of dual polarization in mobile satellite systems is very promising
for increasing the channel capacity. Polarized Modulation is proposed in this
paper for use in practical systems, by providing simple equations for computing
its capacity and featuring a link adaptation algorithm. This scheme shows
remarkable gains in the spectral efficiency when compared with single
polarization and other multi-antenna techniques such as V-BLAST. Polarized
Modulation is a particular instance of more general Index Modulations, which
are being considered for 5G networks. Thus, the proposed link adaptation
algorithm could find synergies with current activities for future terrestrial
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09531</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09531</id><created>2018-07-25</created><authors><author><keyname>D&#xed;ez</keyname><forenames>Luis</forenames></author><author><keyname>Cort&#xe9;s</keyname><forenames>Jos&#xe9; A.</forenames></author><author><keyname>Ca&#xf1;ete</keyname><forenames>Francisco J.</forenames></author><author><keyname>Martos</keyname><forenames>Eduardo</forenames></author><author><keyname>Iranzo</keyname><forenames>Salvador</forenames></author></authors><title>A Generalized Spectral Shaping Method for OFDM Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal frequency division multiplexing (OFDM) signals with rectangularly
windowed pulses exhibit low spectral confinement. Two approaches usually
referred to as pulse-shaping and active interference cancellation (AIC) are
classically employed to reduce the out-of-band emission (OOBE) without
affecting the receiver. This paper proposes a spectral shaping method that
generalizes and unifies these two strategies. To this end, the OFDM carriers
are shaped with novel pulses, referred to as generalized pulses, that consist
of the ones used in conventional OFDM systems plus a series of cancellation
terms aimed at reducing the OOBE of the former. Hence, each generalized pulse
embeds all the terms required to reduce its spectrum in the desired bands. This
leads to a data-independent optimization problem that notably simplifies the
implementation complexity and allows the analytical calculation of the
resulting power spectral density (PSD), which in most methods found in the
literature can only be estimated by means of simulations. As an example of its
performance, the proposed technique allows complying with the stringent PSD
mask imposed by the EN 50561-1 with a data carrier loss lower than 4%. By
contrasts, 28% of the data carriers have to be nulled when pulse-shaping is
employed in this scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09584</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09584</id><created>2018-06-25</created><authors><author><keyname>Horta</keyname><forenames>Jos&#xe9;</forenames><affiliation>LINCS, INFRES</affiliation></author><author><keyname>Kofman</keyname><forenames>Daniel</forenames><affiliation>LINCS</affiliation></author><author><keyname>Menga</keyname><forenames>David</forenames><affiliation>EDF</affiliation></author><author><keyname>Caujolle</keyname><forenames>Mathieu</forenames><affiliation>EDF</affiliation></author></authors><title>Augmenting DER hosting capacity of distribution grids through local
  energy markets and dynamic phase switching</title><categories>eess.SP</categories><proxy>ccsd</proxy><journal-ref>e-Energy '18: The Ninth International Conference on Future Energy
  Systems, Jun 2018, Karlsruhe, Germany. ACM Press, 18</journal-ref><doi>10.1145/3208903.3208937</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The limited capacity of distribution grids for hosting renewable generation
is one of the main challenges towards the energy transition. Local energy
markets, enabling direct exchange of energy between prosumers, help to
integrate the growing number of residential photovoltaic panels by scheduling
flexible demand for balancing renewable energy locally. Nevertheless, existing
scheduling mechanisms do not take into account the phases to which households
are connected, increasing network unbalance and favoring bigger voltage
rises/drops and higher losses. In this paper, we reduce network unbalance by
leveraging market transactions information to dynamically allocate houses to
phases using solid state switches. We propose cost effective mechanisms for the
selection of households to switch and for their optimal allocation to phases.
Using load flow analysis we show that only 6% of houses in our case studies
need to be equipped with dynamic switches to counteract the negative impact of
local energy markets while maintaining all the benefits. Combining local energy
markets and dynamic phase switching we improve both overall load balancing and
network unbalance, effectively augmenting DER hosting capacity of distribution
grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09585</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09585</id><created>2018-06-28</created><authors><author><keyname>Sturtewagen</keyname><forenames>Leen</forenames></author><author><keyname>van Mil</keyname><forenames>Harald</forenames></author><author><keyname>de Lavergne</keyname><forenames>Marine Devezeaux</forenames></author><author><keyname>Stieger</keyname><forenames>Markus</forenames></author><author><keyname>van der Linden</keyname><forenames>Erik</forenames></author><author><keyname>Odijk</keyname><forenames>Theo</forenames></author></authors><title>A Quantitative Information Measure applied to Texture Perception
  Attributes during Mastication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have calculated a quantitative measure of information of experimentally
determined temporal dominance of sensations (TDS) frequencies of texture
attributes, for a set of diverse samples throughout the mastication cycle. The
samples were emulsion filled gels, two-layered emulsion filled gels, and
sausages. For the majority of the samples we find one master curve, where
swallowing takes place after the information increases from its minimum. The
master curve may indicate a simplifying principle during mastication and
subsequent swallowing. We have also calculated a particular complexity measure.
This measure displays an increase just before swallowing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09590</identifier>
 <datestamp>2018-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09590</id><created>2018-07-23</created><updated>2018-09-18</updated><authors><author><keyname>Guo</keyname><forenames>Qingbei</forenames></author><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author><author><keyname>Lloretz</keyname><forenames>Jaime</forenames></author><author><keyname>Kantarcix</keyname><forenames>Burak</forenames></author><author><keyname>Seah</keyname><forenames>Winston K. G.</forenames></author></authors><title>A Localization Method Avoiding Flip Ambiguities for micro-UAVs with
  Bounded Distance Measurement Errors</title><categories>eess.SP cs.OH</categories><comments>14 pages, 8 figures, IEEE Transactions on Mobile Computing(Accepted)</comments><journal-ref>Qingbei Guo, Yuan Zhang, Jaime Lloretz, Burak Kantarcix and
  Winston K.G. Seah, A Localization Method Avoiding Flip Ambiguities for
  micro-UAVs with Bounded Distance Measurement Errors, IEEE Transactions on
  Mobile Computing, 2018</journal-ref><doi>10.1109/TMC.2018.2865462</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization is a fundamental function in cooperative control of micro
unmanned aerial vehicles (UAVs), but is easily affected by flip ambiguities
because of measurement errors and flying motions. This study proposes a
localization method that can avoid the occurrence of flip ambiguities in
bounded distance measurement errors and constrained flying motions; to
demonstrate its efficacy, the method is implemented on bilateration and
trilateration. For bilateration, an improved bi-boundary model based on the
unit disk graph model is created to compensate for the shortage of distance
constraints, and two boundaries are estimated as the communication range
constraint. The characteristic of the intersections of the communication range
and distance constraints is studied to present a unique localization criterion
which can avoid the occurrence of flip ambiguities. Similarly, for
trilateration, another unique localization criterion for avoiding flip
ambiguities is proposed according to the characteristic of the intersections of
three distance constraints. The theoretical proof shows that these proposed
criteria are correct. A localization algorithm is constructed based on these
two criteria. The algorithm is validated using simulations for different
scenarios and parameters, and the proposed method is shown to provide excellent
localization performance in terms of average estimated error. Our code can be
found at: https://github.com/QingbeiGuo/AFALA.git.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09597</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09597</id><created>2018-07-23</created><updated>2018-08-21</updated><authors><author><keyname>Palaskar</keyname><forenames>Shruti</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Acoustic-to-Word Recognition with Sequence-to-Sequence Models</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>9 pages, 3 figures, Under Review at SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic-to-Word recognition provides a straightforward solution to
end-to-end speech recognition without needing external decoding, language model
re-scoring or lexicon. While character-based models offer a natural solution to
the out-of-vocabulary problem, word models can be simpler to decode and may
also be able to directly recognize semantically meaningful units. We present
effective methods to train Sequence-to-Sequence models for direct word-level
recognition (and character-level recognition) and show an absolute improvement
of 4.4-5.0\% in Word Error Rate on the Switchboard corpus compared to prior
work. In addition to these promising results, word-based models are more
interpretable than character models, which have to be composed into words using
a separate decoding step. We analyze the encoder hidden states and the
attention behavior, and show that location-aware attention naturally represents
words as a single speech-word-vector, despite spanning multiple frames in the
input. We finally show that the Acoustic-to-Word model also learns to segment
speech into words with a mean standard deviation of 3 frames as compared with
human annotated forced-alignments for the Switchboard corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09609</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09609</id><created>2018-07-24</created><authors><author><keyname>Chung</keyname><forenames>Hwei-Ming</forenames></author><author><keyname>Li</keyname><forenames>Wen-Tai</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Chung</keyname><forenames>Wei-Ho</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author></authors><title>Local Cyber-Physical Attack for Masking Line Outage and Topology Attack
  in Smart Grid</title><categories>math.OC eess.SP</categories><comments>accepted by IEEE Transactions on Smart Grid. arXiv admin note: text
  overlap with arXiv:1708.03201</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malicious attacks in the power system can eventually result in a large-scale
cascade failure if not attended on time. These attacks, which are traditionally
classified into \emph{physical} and \emph{cyber attacks}, can be avoided by
using the latest and advanced detection mechanisms. However, a new threat
called \emph{cyber-physical attacks} which jointly target both the physical and
cyber layers of the system to interfere the operations of the power grid is
more malicious as compared with the traditional attacks. In this paper, we
propose a new cyber-physical attack strategy where the transmission line is
first physically disconnected, and then the line-outage event is masked, such
that the control center is misled into detecting as an obvious line outage at a
different position in the local area of the power system. Therefore, the
topology information in the control center is interfered by our attack. We also
propose a novel procedure for selecting vulnerable lines, and analyze the
observability of our proposed framework. Our proposed method can effectively
and continuously deceive the control center into detecting fake line-outage
positions, and thereby increase the chance of cascade failure because the
attention is given to the fake outage. The simulation results validate the
efficiency of our proposed attack strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09637</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09637</id><created>2018-07-25</created><updated>2019-01-30</updated><authors><author><keyname>Bates</keyname><forenames>Alice P.</forenames></author><author><keyname>Khalid</keyname><forenames>Zubair</forenames></author><author><keyname>McEwen</keyname><forenames>Jason D.</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author><author><keyname>Daducci</keyname><forenames>Alessandro</forenames></author><author><keyname>Canales-Rodr&#xed;guez</keyname><forenames>Erick J.</forenames></author></authors><title>Efficient sampling and robust 3D diffusion magnetic resonance imaging
  signal reconstruction</title><categories>eess.SP</categories><comments>19 pages, with 6 pages supplementary material attached at the end,
  submitted to PLOS ONE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents novel single and multi-shell sampling schemes for
diffusion MRI. In diffusion MRI, it is paramount that the number of samples is
as small as possible in order that scan times are practical in a clinical
setting. The proposed schemes use an efficient number of measurements in that
the number of samples is equal to the degrees of freedom in the orthonormal
bases used for reconstruction. Novel reconstruction algorithms based on smaller
subsystems of linear equations, as compared to the standard regularized
least-squares method, are developed for both single and multi-shells sampling
schemes. The smaller matrices used in these novel reconstruction algorithms are
designed to be well-conditioned, leading to improved reconstruction accuracy.
Accurate and robust reconstruction is also achieved through incorporation of
regularization into the novel reconstruction algorithms and using a Rician or
non-central Chi noise model. We quantitatively validate our single and
multi-shell schemes against standard least-squares reconstruction methods to
show that they enable more accurate reconstruction when the number of samples
is equal to the degrees of freedom in the basis. Human brain data is also used
to qualitatively evaluate reconstruction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09680</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09680</id><created>2018-07-13</created><authors><author><keyname>Perera</keyname><forenames>Charith</forenames></author></authors><title>Rentable Internet of Things Infrastructure for Sensing as a Service
  (S2aaS)</title><categories>eess.SP cs.NI</categories><journal-ref>IEEE Internet of Things Newsletter July 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensing as a Service (S2aaS) model [1] [2] is inspired by the traditional
Everything as a service (XaaS) approaches [3]. It aims to better utilize the
existing Internet of Things (IoT) infrastructure. S2aaS vision aims to create
'rentable infrastructure' where interested parties can gather IoT data by
paying a fee for the infrastructure owners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09692</identifier>
 <datestamp>2018-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09692</id><created>2018-07-25</created><authors><author><keyname>Gorlow</keyname><forenames>Stanislaw</forenames></author><author><keyname>da Costa</keyname><forenames>Jo&#xe3;o Paulo C. L.</forenames></author><author><keyname>Haardt</keyname><forenames>and Martin</forenames></author></authors><title>An Adaptive CM Array Preconditioner for Blind Multi-User Separation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The family of constant-modulus algorithms is widely used in wireless
communication systems and in radar. The classical constant-modulus adaptive
(CMA) algorithm, however, fails to lock onto a single mode when used in
conjunction with an antenna array. Instead, it equalizes the entire spatial
spectrum. In this paper, we describe in full detail our recently proposed
approach for the separation of multiple users in a radio system with frequency
reuse, such as a cellular network, making use of the CMA algorithm. Based on
the observation that the differential filter weights resemble a superposition
of the array steering vectors, we cast the original task to a
direction-of-arrival estimation problem. With rigorous theoretical analysis of
the array response based on the discrete-space Fourier transform we elaborate a
solution that solves the problem by finding the roots of a polynomial equation.
We provide a numerical example to demonstrate the validity of the approach
under high-SNR conditions. In addition, we propose a more general preprocessor
for the CMA array which allows the modulated signals to differ in amplitude. As
a byproduct, the preprocessor yields a low-cost estimate of the number of
concurrent users, i.e. the model order, by simply counting the roots with the
strongest response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09811</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09811</id><created>2018-07-25</created><authors><author><keyname>Guedes</keyname><forenames>P. F. S.</forenames></author><author><keyname>Peixoto</keyname><forenames>M. L. C.</forenames></author><author><keyname>Freitas</keyname><forenames>O. A. R. O.</forenames></author><author><keyname>Barbosa</keyname><forenames>A. M.</forenames></author><author><keyname>Martins</keyname><forenames>S. A. M.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author></authors><title>Interval Simulation of Narmax Models Based on Computer Arithmetic</title><categories>eess.SP</categories><comments>CBA 2018 - XXII Congresso Brasileiro de Automatica, Joao Pessoa, p.
  1-6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System identification is an important area of science, which aims to describe
the characteristics of the system, representing them by mathematical models.
Since many of these models can be seen as recursive functions, it is extremely
important to control the errors in these functions, because small errors
introduced in each computational step can grow exponentially due to the
sensitivity to initial conditions present in this type of functions. One of the
ways to control rounding and truncation errors is through interval arithmetic,
since it is not possible to represent all numbers in the computer because of
the finite representation in them. Thus, in arithmetic interval a number is
represented by an interval in which the true number is within that interval. In
this manuscript we developed an algorithm that performs the operations of
interval arithmetic using basic functions. We have compared compared our
results with the Matlab-toolbox Intlab. Numerical experiments have shown that
our method is superior producing narrower intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09840</identifier>
 <datestamp>2018-10-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09840</id><created>2018-07-25</created><updated>2018-10-11</updated><authors><author><keyname>Mesaros</keyname><forenames>Annamaria</forenames></author><author><keyname>Heittola</keyname><forenames>Toni</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>A multi-device dataset for urban acoustic scene classification</title><categories>eess.AS cs.SD</categories><comments>accepted to DCASE 2018 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the acoustic scene classification task of DCASE 2018
Challenge and the TUT Urban Acoustic Scenes 2018 dataset provided for the task,
and evaluates the performance of a baseline system in the task. As in previous
years of the challenge, the task is defined for classification of short audio
samples into one of predefined acoustic scene classes, using a supervised,
closed-set classification setup. The newly recorded TUT Urban Acoustic Scenes
2018 dataset consists of ten different acoustic scenes and was recorded in six
large European cities, therefore it has a higher acoustic variability than the
previous datasets used for this task, and in addition to high-quality binaural
recordings, it also includes data recorded with mobile devices. We also present
the baseline system consisting of a convolutional neural network and its
performance in the subtasks using the recommended cross-validation setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09902</identifier>
 <datestamp>2018-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09902</id><created>2018-07-25</created><updated>2018-10-06</updated><authors><author><keyname>Fonseca</keyname><forenames>Eduardo</forenames></author><author><keyname>Plakal</keyname><forenames>Manoj</forenames></author><author><keyname>Font</keyname><forenames>Frederic</forenames></author><author><keyname>Ellis</keyname><forenames>Daniel P. W.</forenames></author><author><keyname>Favory</keyname><forenames>Xavier</forenames></author><author><keyname>Pons</keyname><forenames>Jordi</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>General-purpose Tagging of Freesound Audio with AudioSet Labels: Task
  Description, Dataset, and Baseline</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Camera ready for DCASE Workshop 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper describes Task 2 of the DCASE 2018 Challenge, titled
&quot;General-purpose audio tagging of Freesound content with AudioSet labels&quot;. This
task was hosted on the Kaggle platform as &quot;Freesound General-Purpose Audio
Tagging Challenge&quot;. The goal of the task is to build an audio tagging system
that can recognize the category of an audio clip from a subset of 41 diverse
categories drawn from the AudioSet Ontology. We present the task, the dataset
prepared for the competition, and a baseline system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09931</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09931</id><created>2018-07-25</created><authors><author><keyname>Adler</keyname><forenames>Amir</forenames></author><author><keyname>Wax</keyname><forenames>Mati</forenames></author></authors><title>Direct Localization of Multiple Sources by Partly Calibrated Arrays</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present novel solutions to the problem of direct localization of multiple
narrow-band and arbitrarily correlated sources by partly calibrated arrays,
i.e., arrays composed of fully calibrated sub-arrays yet lacking inter-array
calibration. The solutions presented vary in their performance and
computational complexity. We present first a relaxed maximum likelihood
solution whose concentrated likelihood involves only the unknown locations of
the sources and requires an eigen-decomposition of the array covariance matrix
at every potential location. To reduce the computational load, we introduce an
approximation which eliminates the need for such an eigen-decomposition at
every potential location. To further reduce the computational load, novel
MUSIC-like and MVDR-like solutions are presented which are computationally much
simpler than the existing solutions. The performance of these solutions is
evaluated and compared via simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09964</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.09964</id><created>2018-07-26</created><authors><author><keyname>Smolentsev</keyname><forenames>N. K.</forenames></author><author><keyname>Podkur</keyname><forenames>P. N.</forenames></author></authors><title>Wavelet analysis in problems of classification of ECG signals</title><categories>eess.SP math.FA</categories><comments>15 pages, 5 figures</comments><msc-class>46N60, 46N30, 42C40, 65T60, 92C55</msc-class><journal-ref>SCIENCE EVOLUTION, 2016, vol. 1, no. 1, 63-71</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the wavelet analysis is used to study the ECG signal. We show
that the high-frequency wavelet components of the ECG signal contain
information on the functioning of the heart and can be used in diagnosis. We
describe the automated classification system that separates the ECG of sick and
healthy persons using only a high-frequency ECG component.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10025</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10025</id><created>2018-07-26</created><updated>2019-03-09</updated><authors><author><keyname>Liang</keyname><forenames>Fei</forenames></author><author><keyname>Shen</keyname><forenames>Cong</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author><author><keyname>Wu</keyname><forenames>Feng</forenames></author></authors><title>Towards Optimal Power Control via Ensembling Deep Neural Networks</title><categories>eess.SP cs.IT math.IT stat.ML</categories><comments>30 pages, 27 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A deep neural network (DNN) based power control method is proposed, which
aims at solving the non-convex optimization problem of maximizing the sum rate
of a multi-user interference channel. Towards this end, we first present PCNet,
which is a multi-layer fully connected neural network that is specifically
designed for the power control problem. PCNet takes the channel coefficients as
input and outputs the transmit power of all users. A key challenge in training
a DNN for the power control problem is the lack of ground truth, i.e., the
optimal power allocation is unknown. To address this issue, PCNet leverages the
unsupervised learning strategy and directly maximizes the sum rate in the
training phase. Observing that a single PCNet does not globally outperform the
existing solutions, we further propose ePCNet, a network ensemble with multiple
PCNets trained independently. Simulation results show that for the standard
symmetric multi-user Gaussian interference channel, ePCNet can outperform all
state-of-the-art power control methods by 1.2%-4.6% under a variety of system
configurations. Furthermore, the performance improvement of ePCNet comes with a
reduced computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10058</identifier>
 <datestamp>2018-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10058</id><created>2018-07-26</created><authors><author><keyname>Seifert</keyname><forenames>Bastian</forenames></author><author><keyname>H&#xfc;per</keyname><forenames>Knut</forenames></author><author><keyname>Uhl</keyname><forenames>Christian</forenames></author></authors><title>Fast cosine transform for FCC lattices</title><categories>eess.SP cs.IT math.IT math.RT</categories><comments>Presented at 13th APCA International Conference on Automatic Control
  and Soft Computing (CONTROLO 2018); 9 figures</comments><doi>10.1109/CONTROLO.2018.8514300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voxel representation and processing is an important issue in a broad spectrum
of applications. E.g., 3D imaging in biomedical engineering applications, video
game development and volumetric displays are often based on data representation
by voxels. By replacing the standard sampling lattice with a face-centered
lattice one can obtain the same sampling density with less sampling points and
reduce aliasing error, as well. We introduce an analog of the discrete cosine
transform for the facecentered lattice relying on multivariate Chebyshev
polynomials. A fast algorithm for this transform is deduced based on algebraic
signal processing theory and the rich geometry of the special unitary Lie group
of degree four.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10108</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10108</id><created>2018-07-26</created><updated>2019-06-26</updated><authors><author><keyname>Roy</keyname><forenames>Prasun</forenames></author><author><keyname>Ghosh</keyname><forenames>Subhankar</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Saumik</forenames></author><author><keyname>Pal</keyname><forenames>Umapada</forenames></author></authors><title>Effects of Degradations on Deep Neural Network Architectures</title><categories>cs.CV eess.IV</categories><comments>Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, image classification methods based on capsules (groups of neurons)
and a novel dynamic routing protocol are proposed. The methods show promising
performances than the state-of-the-art CNN-based models in some of the existing
datasets. However, the behavior of capsule-based models and CNN-based models
are largely unknown in presence of noise. So it is important to study the
performance of these models under various noises. In this paper, we demonstrate
the effect of image degradations on deep neural network architectures for image
classification task. We select six widely used CNN architectures to analyse
their performances for image classification task on datasets of various
distortions. Our work has three main contributions: 1) we observe the effects
of degradations on different CNN models; 2) accordingly, we propose a network
setup that can enhance the robustness of any CNN architecture for certain
degradations, and 3) we propose a new capsule network that achieves high
recognition accuracy. To the best of our knowledge, this is the first study on
the performance of CapsuleNet (CapsNet) and other state-of-the-art CNN
architectures under different types of image degradations. Also, our datasets
and source code are available publicly to the researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10165</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10165</id><created>2018-07-18</created><authors><author><keyname>Zhou</keyname><forenames>Zongwei</forenames></author><author><keyname>Siddiquee</keyname><forenames>Md Mahfuzur Rahman</forenames></author><author><keyname>Tajbakhsh</keyname><forenames>Nima</forenames></author><author><keyname>Liang</keyname><forenames>Jianming</forenames></author></authors><title>UNet++: A Nested U-Net Architecture for Medical Image Segmentation</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>8 pages, 3 figures, 3 tables, accepted by 4th Deep Learning in
  Medical Image Analysis (DLMIA) Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present UNet++, a new, more powerful architecture for
medical image segmentation. Our architecture is essentially a deeply-supervised
encoder-decoder network where the encoder and decoder sub-networks are
connected through a series of nested, dense skip pathways. The re-designed skip
pathways aim at reducing the semantic gap between the feature maps of the
encoder and decoder sub-networks. We argue that the optimizer would deal with
an easier learning task when the feature maps from the decoder and encoder
networks are semantically similar. We have evaluated UNet++ in comparison with
U-Net and wide U-Net architectures across multiple medical image segmentation
tasks: nodule segmentation in the low-dose CT scans of chest, nuclei
segmentation in the microscopy images, liver segmentation in abdominal CT
scans, and polyp segmentation in colonoscopy videos. Our experiments
demonstrate that UNet++ with deep supervision achieves an average IoU gain of
3.9 and 3.4 points over U-Net and wide U-Net, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10169</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10169</id><created>2018-07-26</created><authors><author><keyname>Gheth</keyname><forenames>Waled</forenames></author><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Ijaz</keyname><forenames>Muhammad</forenames></author><author><keyname>Harris</keyname><forenames>Georgina</forenames></author></authors><title>Performance Analysis of Integrated Power-Line/Visible-Light
  Communication Systems with AF Relaying</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1806.10013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable data transmissions and offering better mobility to the end user can
be achieved by integrating different communication systems. In this paper, we
investigate the performance of a cascaded indoor power line communication
(PLC)/visible light communication (VLC) system with the presence of an
amplify-and-forward (AF) relay. Using the pre-installed infrastructure of
electricity wiring networks gives the advantage to use PLC as a backbone for
VLCs. The performance of the proposed hybrid system is discussed in terms of
the average capacity. A mathematical method is developed for this network to
formulate the capacity by exploiting the statistical properties of both the PLC
and VLC channels. The derived analytical expressions are validated by Monte
Carlo simulations. The results showed that there is a considerable improvement
in the performance of the hybrid system as the relay gain increases whereas it
deteriorates with increasing the end-to-end distance. A comparison between the
performance of a parallel hybrid/PLC and hybrid systems is also provided. It is
found that the hybrid/PLC system outperforms the hybrid one. However, the user
mobility offered by the latter system remains the main advantage over the
former approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10236</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10236</id><created>2018-07-26</created><authors><author><keyname>Dionelis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Brookes</keyname><forenames>Mike</forenames></author></authors><title>Modulation-Domain Kalman Filtering for Monaural Blind Speech Denoising
  and Dereverberation</title><categories>cs.SD eess.AS</categories><comments>13 pages, 13 figures, Submitted to IEEE Transactions on Audio, Speech
  and Language Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a monaural speech enhancement algorithm based on
modulation-domain Kalman filtering to blindly track the time-frequency
log-magnitude spectra of speech and reverberation. We propose an adaptive
algorithm that performs blind joint denoising and dereverberation, while
accounting for the inter-frame speech dynamics, by estimating the posterior
distribution of the speech log-magnitude spectrum given the log-magnitude
spectrum of the noisy reverberant speech. The Kalman filter update step models
the non-linear relations between the speech, noise and reverberation
log-spectra. The Kalman filtering algorithm uses a signal model that takes into
account the reverberation parameters of the reverberation time, $T_{60}$, and
the direct-to-reverberant energy ratio (DRR) and also estimates and tracks the
$T_{60}$ and the DRR in every frequency bin in order to improve the estimation
of the speech log-magnitude spectrum. The Kalman filtering algorithm is tested
and graphs that depict the estimated reverberation features over time are
examined. The proposed algorithm is evaluated in terms of speech quality,
speech intelligibility and dereverberation performance for a range of
reverberation parameters and SNRs, in different noise types, and is also
compared to competing denoising and dereverberation techniques. Experimental
results using noisy reverberant speech demonstrate the effectiveness of the
enhancement algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10256</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10256</id><created>2018-07-26</created><authors><author><keyname>Kihero</keyname><forenames>Abuu B.</forenames></author><author><keyname>Solaija</keyname><forenames>Muhammad Sohaib J.</forenames></author><author><keyname>Yazar</keyname><forenames>Ahmet</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author></authors><title>Inter-Numerology Interference Analysis for 5G and Beyond</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the defining characteristics of 5G is the flexibility it offers for
supporting different services and communication scenarios. For this purpose,
usage of multiple numerologies has been proposed by the 3rd Generation
Partnership Project (3GPP). The flexibility provided by multi-numerology system
comes at the cost of additional interference, known as inter-numerology
interference (INI). This paper comprehensively explains the primary cause of
INI, and then identifies and describes the factors affecting the amount of INI
experienced by each numerology in the system. These factors include subcarrier
spacing, number of used subcarriers, power offset, windowing operations and
guard bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10306</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10306</id><created>2018-06-10</created><authors><author><keyname>Abbasi</keyname><forenames>A.</forenames></author><author><keyname>Sulaiman</keyname><forenames>N.</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author></authors><title>High linear low noise amplifier based on self-biasing multiple gated
  transistors</title><categories>eess.SP</categories><comments>International conference on electrical, electronics and system
  engineering (iceese2014) Malaysia, pp1-4</comments><doi>10.1109/ICEESE.2014.7154594</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Noise level frequently set the basic limit on the smallest signal. New noise
reduction technology and amplifiers voltage-noise density, yet still offer high
speed, high accuracy, and low power solution. Low noise amplifiers always play
a significant role in RF technology. Hence in this paper, high linear low noise
amplifier (LNA) using cascade self-biased multiple gated transistors (MGTR) is
presented. The proposed system is covering 0.9 to 2.4 GHz applications. To
verify the functionality of the proposed LNA as a bottleneck of RF technology,
a cascade LNA without MGTR is implemented and synthesized. The comparison has
been done with the single-gate LNA. From the synthesized result, proposed LNA
obtained 10 dBm third-order input intercept point (IIP3) in compare with
single-gate LNA at 9dB gain. The proposed LNA is implemented in 90 nm CMOS
technology and reported 13 dBm IIP3, 1.9 dB NF and 9 dB gain while consuming
7.9 mW from 2 V supply.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10308</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10308</id><created>2018-06-10</created><authors><author><keyname>CV</keyname><forenames>Aravind</forenames></author><author><keyname>R</keyname><forenames>Rajparthiban</forenames></author><author><keyname>R</keyname><forenames>Rajprasad</forenames></author><author><keyname>I</keyname><forenames>Grace</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Norhisam</keyname><forenames>M.</forenames></author></authors><title>Mathematical Toolbox and its application in the Development of
  Laboratory Scale Vertical Axis Wind Turbine</title><categories>eess.SP</categories><comments>International Conference on Power and Energy Dec2012 - PECON. pp.
  99-104.ISBN: 978-1-4673-5017-4</comments><doi>10.1109/PECon.2012.6450362</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A wind turbine works with the principle of extracting energy from the wind to
generate electricity. The power generated is directly proportional to the wind
speed available. There are two major types of wind turbine design namely the
horizontal and vertical axis wind turbine depending on the orientation of the
turbine rotor and its generator. This paper deals with the design of vertical
turbine due to its advantage of operating at a low wind speed over that of the
horizontal turbine. The analysis of change in the parameters of a vertical axis
wind turbine is investigated to get the optimized way in which the rotor of the
turbine is to be designed. This is done through modeling and simulation of the
turbine using various parameters in the MATLAB/SIMULINK environment. A
graphical user interface is created for a generic model of vertical axis wind
turbine that is used to determine its parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10309</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10309</id><created>2018-06-09</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Algnabi</keyname><forenames>Yazan Samir</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author><author><keyname>Islam</keyname><forenames>Md Shabiul</forenames></author><author><keyname>Hong</keyname><forenames>Mok Vee</forenames></author></authors><title>VLSI Implementation of Novel Class of High Speed Pipelined Digital
  Signal Processing Filter for Wireless Receivers</title><categories>eess.SP cs.AR</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.00704</comments><journal-ref>American Journal of Engineering and Applied Sciences.
  3(4):663-669, 2010, ISSN 1941-7020</journal-ref><doi>10.3844/ajeassp.2010.663.669</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The need for a high-performance transceiver with high Signal to Noise Ratio
(SNR) has driven the communication system to utilize the latest technique
identified as oversampling systems. It was the most economical modulator and
decimation in the communication system. It has been proven to increase the SNR
and is used in many high-performance systems such as in the Analog to Digital
Converter (ADC) for wireless transceiver. This research work presented the
design of the novel class of decimation and it's VLSI implementation which was
the sub-component in the oversampling technique. The design and realization of
the main unit of decimation stage that was the Cascaded Integrator Comb (CIC)
filter, the associated half-band filters, and the droop correction are also
designed. The Verilog HDL code in Xilinx ISE environment has been derived to
describe the proposed advanced CIC filter properties. Consequently, Virtex-II
FPGA board was used to implement and test the design on the real hardware. The
ASIC design implementation was performed accordingly and resulted in power and
area measurement on-chip core layout. The proposed design focused on the
trade-off between the high speed and the low power consumption as well as the
silicon area and high resolution for the chip implementation which satisfies
wireless communication systems. The synthesis report illustrates the maximum
clock frequency of 332 MHz with the active core area of 0.308 x 0.308 mm2. It
can be concluded that VLSI implementation of proposed filter architecture is an
enabler in solving problems that affect communication capability in DSP
application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10371</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10371</id><created>2018-07-26</created><authors><author><keyname>Di Stasio</keyname><forenames>Francesco</forenames></author><author><keyname>Mondin</keyname><forenames>Marina</forenames></author><author><keyname>Daneshgaran</keyname><forenames>Fred</forenames></author></authors><title>Multirate 5G Downlink Performance Comparison for f-OFDM and w-OFDM
  Schemes with Different Numerologies</title><categories>eess.SP</categories><comments>Paper accepted for ISNCC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main open problems for next generation wireless networks, is to
find the new OFDM-based waveform to be used in 5G. The new modulation scheme
must primarily be able to achieve higher spectral efficiency than its
predecessor. The main 3GPP's candidate is a new version of OFDM, called
Filtered Orthogonal Frequency-Division Multiplexing (f-OFDM), which is similar
to OFDM but with additional filtering in order to reduce Out-Of-Band (OOB)
emissions and to obtain a better spectral-localization. Another option is
windowed-OFDM (w-OFDM), which is basically a classical OFDM scheme where each
symbol is windowed and overlapped in the time domain. In this paper we compare
classic OFDM signals using Cyclic Prefix (CP-OFDM) with f-OFDM and w-OFDM, each
one with multiple parametric options and numerologies. A multirate transmitter
simultaneously operating with multiple numerologies is considered, where the
transmitted sub-bands must be up-sampled and interpolated in order to generate
the composite numerical signal fed to the Digital to Analog Converter (DAC).
Finally, we discuss advantages and disadvantages of the various schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10384</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10384</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>kizito</keyname><forenames>Martin</forenames></author><author><keyname>Chan</keyname><forenames>Kok Wai</forenames></author><author><keyname>Hoong</keyname><forenames>Mok Vee</forenames></author></authors><title>Smart Analytical Signature Verification For DSP Applications</title><categories>eess.SP</categories><comments>Conference on Systems Process and Control Page(s) 301 _ 305</comments><doi>10.1109/SPC.2013.6735151</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Signature verification is an authentication technique that considers
handwritten signature as a biometric. From a biometric perspective this project
made use of automatic means through an integration of intelligent algorithms to
perform signal enhancement function such as filtering and smoothing for
optimization in conventional biometric systems. A handwritten signature is a 1D
Daubechies wavelet signal (db4) that utilizes Discrete Wavelet Transform (DWT)
and Discrete Cosine Transform (DCT) collectively to create a feature dataset
with d-dimensional space. In the proposed work the statistical features
characteristics are extracted from each particular signature per data source.
Two databases called Signature Verification Competition (SVC) 2004 database and
SUBCORPUS 100 MCYT Bimodal database are used to cooperate with the design
algorithm. Furthermore dimension reduction technique is applied to the large
feature vectors. A system model is trained and evaluated using the support
vector machine (SVM) classifier algorithm. Hence an equal error rate (EER) of
8.7 percent and an average correct verification rate of 91.3 percent
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10385</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10385</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Iwan</keyname><forenames>Mahmud</forenames></author><author><keyname>Abueida</keyname><forenames>Ahmad J. A.</forenames></author></authors><title>RFID-BASED Prepaid Power Meter</title><categories>eess.SP</categories><comments>Conference On Research and Development 2013, 978-1-4799-3656-5/13-pp</comments><doi>10.1109/SCOReD.2013.7002594</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An Electric power meter is an important component in electric energy service.
In the past, many consumers have complained about reading inaccurate of the
electric meter. This research presents the development of an electrical power
meter equipped with RFID reader. The RFID reader reads a valid RFID card and
activates the power meter so that it can supply electricity. When the credit is
about low or before the electricity is auto cut off, an SMS message will be
sent to the users handphone to alert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10386</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10386</id><created>2018-06-10</created><authors><author><keyname>Chockalingam</keyname><forenames>Aravind Vaithilingam</forenames></author><author><keyname>Olasehinde</keyname><forenames>Ikujuni Grace</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author></authors><title>Universal Computer aided design for electrical machines</title><categories>eess.SP</categories><comments>International colloquium on signal Processing Applications conference
  (CSPA 2012). pp: 99-104</comments><doi>10.1109/CSPA.2012.6194699</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Electrical machines are devices that change either mechanical or electrical
energy to the other and also can alternate the voltage levels of an alternating
current. The need for electrical machines cannot be overemphasized since they
are used in various applications in the world today. Its design is to meet the
specifications as stated by the user and this design has to be an economical
one. The design, therefore, revolves around designing the machine to meet the
stipulated performance required, the cost available and the lasting life of the
machine. This work aims to eliminate the tediousness involved in the manual
hand calculations of designing the machines by making use of a graphical user
interface and using iterations in situations where the data would have been
assumed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10392</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10392</id><created>2018-07-26</created><authors><author><keyname>Babqi</keyname><forenames>Abdulrahman J.</forenames></author><author><keyname>Yi</keyname><forenames>Zhehan</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Zhao</keyname><forenames>Xiaoying</forenames></author></authors><title>Model Predictive Control of H5 Inverter for Transformerless PV Systems
  with Maximum Power Point Tracking and Leakage Current Reduction</title><categories>math.OC eess.SP math.DS</categories><comments>This work has been accepted by the 44th Annual Conference of the IEEE
  Industrial Electronics Society (IECON 2018). This is a preprint. DOI is to be
  added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformerless grid-connected solar photovoltaic (PV) systems have given
rise to more research and commercial interests due to their multiple merits,
e.g., low leakage current and small size. In this paper, a
model-predictive-control (MPC)-based strategy for controlling transformerless
H5 inverter for single-phase PV distributed generation system is proposed. The
method further reduces the PV leakage current in a cost-effective and safe
manner and it shows a satisfactory fault-ride-through capability. Moreover, for
the first of its kind, PV maximum power point tracking is implemented in the
single-stage H5 inverter using MPC-based controllers. Various case studies are
carried out, which provide the result comparisons between the proposed and
conventional control methods and verify the promising performance of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10393</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10393</id><created>2018-07-26</created><updated>2018-08-29</updated><authors><author><keyname>Inamdar</keyname><forenames>Niraj K.</forenames></author></authors><title>Small Satellite Optical Communication Networks: Analytical Models</title><categories>eess.SP</categories><comments>21 pages, 12 figures. Fixed minor typographical errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Small satellites, especially picosatellites, appear poised to play an
important role in the future of space systems. Due to their size, however,
integrating them with high-throughput laser-based communication systems remains
a challenge. In this paper, we develop several analytical models that quantify
how optical communication networks can be implemented with picosatellites. We
do so with the goal of identifying design challenges that need to be addressed
if picosatellites and optical communication systems are indeed to be a standard
part of the future space technological landscape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10479</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10479</id><created>2018-07-27</created><authors><author><keyname>Yair</keyname><forenames>Or</forenames></author><author><keyname>Ben-Chen</keyname><forenames>Mirela</forenames></author><author><keyname>Talmon</keyname><forenames>Ronen</forenames></author></authors><title>Parallel Transport on the Cone Manifold of SPD Matrices for Domain
  Adaptation</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2894801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of domain adaptation. We propose to
view the data through the lens of covariance matrices and present a method for
domain adaptation using parallel transport on the cone manifold of symmetric
positive-definite matrices. We provide rigorous analysis using Riemanninan
geometry, illuminating the theoretical guarantees and benefits of the presented
method. In addition, we demonstrate these benefits using experimental results
on simulations and real-measured data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10501</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10501</id><created>2018-07-27</created><authors><author><keyname>Serizel</keyname><forenames>Romain</forenames><affiliation>MULTISPEECH</affiliation></author><author><keyname>Turpault</keyname><forenames>Nicolas</forenames><affiliation>MULTISPEECH</affiliation></author><author><keyname>Eghbal-Zadeh</keyname><forenames>Hamid</forenames><affiliation>LTI</affiliation></author><author><keyname>Shah</keyname><forenames>Ankit Parag</forenames><affiliation>LTI</affiliation></author></authors><title>Large-Scale Weakly Labeled Semi-Supervised Sound Event Detection in
  Domestic Environments</title><categories>cs.SD eess.AS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents DCASE 2018 task 4. The task evaluates systems for the
large-scale detection of sound events using weakly labeled data (without time
boundaries). The target of the systems is to provide not only the event class
but also the event time boundaries given that multiple events can be present in
an audio recording. Another challenge of the task is to explore the possibility
to exploit a large amount of unbalanced and unlabeled training data together
with a small weakly labeled training set to improve system performance. The
data are Youtube video excerpts from domestic context which have many
applications such as ambient assisted living. The domain was chosen due to the
scientific challenges (wide variety of sounds, time-localized events.. .) and
potential industrial applications .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10586</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10586</id><created>2018-07-17</created><updated>2019-07-24</updated><authors><author><keyname>Cheng</keyname><forenames>Wenshan Bi Dong</forenames></author><author><keyname>Kou</keyname><forenames>Kit Ian</forenames></author></authors><title>A Robust Color Edge Detection Algorithm Based on Quaternion Hardy Filter</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a robust filter called quaternion Hardy filter (QHF) for
color image edge detection. The QHF can be capable of color edge feature
enhancement and noise resistance. It is flexible to use QHF by selecting
suitable parameters to handle different levels of noise. In particular, the
quaternion analytic signal, which is an effective tool in color image
processing, can also be produced by quaternion Hardy filtering with specific
parameters. Based on the QHF and the improved Di Zenzo gradient operator, a
novel color edge detection algorithm is proposed. Importantly, it can be
efficiently implemented by using the fast discrete quaternion Fourier transform
technique. The experiments demonstrate that the proposed algorithm outperforms
several state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10619</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10619</id><created>2018-07-27</created><authors><author><keyname>Haqiqatnejad</keyname><forenames>A.</forenames></author><author><keyname>Kayhan</keyname><forenames>F.</forenames></author><author><keyname>Ottersten</keyname><forenames>B.</forenames></author></authors><title>Power Minimizer Symbol-Level Precoding: A Closed-Form Sub-Optimal
  Solution</title><categories>eess.SP cs.IT math.IT</categories><comments>7 pages, 1 figure, 1 table, submitted to IEEE signal processing
  letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we study the optimal solution of the multiuser symbol-level
precoding (SLP) for minimization of the total transmit power under given
signal-to-interference-plus-noise ratio (SINR) constraints. Adopting the
distance preserving constructive interference regions (DPCIR), we first derive
a simplified reformulation of the problem. Then, we analyze the structure of
the optimal solution using the Karush-Kuhn-Tucker (KKT) optimality conditions,
thereby we obtain the necessary and sufficient condition under which the power
minimizer SLP is equivalent to the conventional zero-forcing beamforming
(ZFBF). This further leads us to a closed-form sub-optimal SLP solution
(CF-SLP) for the original problem. Simulation results show that CF-SLP provides
significant gains over ZFBF, while performing quite close to the optimal SLP in
scenarios with rather small number of users. The results further indicate that
the CF-SLP method has a reduction of order $10^3$ in computational time
compared to the optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10629</identifier>
 <datestamp>2019-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10629</id><created>2018-07-26</created><updated>2019-03-18</updated><authors><author><keyname>Seifert</keyname><forenames>Bastian</forenames></author><author><keyname>Korn</keyname><forenames>Katharina</forenames></author><author><keyname>Hartmann</keyname><forenames>Steffen</forenames></author><author><keyname>Uhl</keyname><forenames>Christian</forenames></author></authors><title>Dynamical Component Analysis (DyCA): Dimensionality Reduction For
  High-Dimensional Deterministic Time-Series</title><categories>eess.SP cs.LG nlin.CD</categories><comments>Published in Proc. 2018 IEEE INTERNATIONAL WORKSHOP ON MACHINE
  LEARNING FOR SIGNAL PROCESSING; 7 figures; Corrected formula (16)</comments><doi>10.1109/MLSP.2018.8517024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multivariate signal processing is often based on dimensionality reduction
techniques. We propose a new method, Dynamical Component Analysis (DyCA),
leading to a classification of the underlying dynamics and - for a certain type
of dynamics - to a signal subspace representing the dynamics of the data. In
this paper the algorithm is derived leading to a generalized eigenvalue problem
of correlation matrices. The application of the DyCA on high-dimensional
chaotic signals is presented both for simulated data as well as real EEG data
of epileptic seizures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10679</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10679</id><created>2018-07-27</created><authors><author><keyname>Tom&#xe9;</keyname><forenames>A. M.</forenames></author><author><keyname>Malafaia</keyname><forenames>D.</forenames></author><author><keyname>Teixeira</keyname><forenames>A. R.</forenames></author><author><keyname>Lang</keyname><forenames>E. W.</forenames></author></authors><title>On the use of Singular Spectrum Analysis</title><categories>eess.SP</categories><comments>23 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Singular Spectrum Analysis (SSA) or Singular Value Decomposition (SVD) are
often used to de-noise univariate time series or to study their spectral
profile. Both techniques rely on the eigendecomposition of the cor- relation
matrix estimated after embedding the signal into its delayed coordi- nates. In
this work we show that the eigenvectors can be used to calculate the
coefficients of a set of filters which form a filter bank. The properties of
these filters are derived. In particular we show that their outputs can be
grouped according to their frequency response. Furthermore, the fre- quency at
the maximum of each frequency response and the corresponding eigenvalue can
provide a power spectrum estimation of the time series. Two different
applications illustrate how both characteristics can be applied to analyze
wideband signals in order to achieve narrow-band signals or to infer their
frequency occupation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10723</identifier>
 <datestamp>2018-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10723</id><created>2018-07-13</created><authors><author><keyname>Hamad</keyname><forenames>Asmaa</forenames></author><author><keyname>Hassanien</keyname><forenames>Aboul Ella</forenames></author><author><keyname>Fahmy</keyname><forenames>Aly A.</forenames></author><author><keyname>Houssein</keyname><forenames>Essam H.</forenames></author></authors><title>A hybrid automated detection of epileptic seizures in EEG based on
  wavelet and machine learning techniques</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epilepsy is a neurological condition such that it affects the brain and the
nervous system. It is characterized by recurrent seizures, which are physical
reactions to sudden, usually brief, excessive electrical discharges in a group
of brain cells. Hence, seizure identification has great importance in clinical
therapy of epileptic patients. Electroencephalogram (EEG) is one of the main
biomarker that can measure voltage fluctuations of the brain and EEG data
analysis helps to investigate the patient with epilepsy syndrome as epilepsy
leaves their signature in EEG signals. In this paper, the Discrete Wavelet
Transform (DWT) is applied to EEG signals to pre-processing, decompose it till
the 4th level of decomposition tree.Various features like Entropy, Min, Max,
Mean, Median, Standard deviation, Variance, Skewness, Energy and Relative Wave
Energy (RWE) were computed in terms of detailed coefficients and the
approximation coefficients of the last decomposition level.Then, the extracted
features are evaluated by three modern machine-learning classifiers such as
Radial Basis Function based Support Vector Machine (SVMRBF), k-Nearest Neighbor
(KNN) and Naive Bayes (NB). The experimental results demonstrate that the
highest classification accuracy (100\%) for normal subject data versus
epileptic data is obtained by SVMRBF. the corresponding accuracy between normal
subject data and epileptic data using KNN and NB is obtained as 99.50\% and
99\% for the eyes open and eyes closed conditions, respectively. The similar
accuracies, while comparing the interictal and ictal data, are obtained as
99\%, 97.50\% and 98.50\% using the SVMRBF, KNN and NB classifiers,
respectively. These accuracies are quite higher than earlier results published.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10752</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10752</id><created>2018-07-19</created><authors><author><keyname>Cheung</keyname><forenames>Sky C.</forenames></author><author><keyname>Shin</keyname><forenames>John Y.</forenames></author><author><keyname>Lau</keyname><forenames>Yenson</forenames></author><author><keyname>Chen</keyname><forenames>Zhengyu</forenames></author><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Zhang</keyname><forenames>Yuqian</forenames></author><author><keyname>Wright</keyname><forenames>John N.</forenames></author><author><keyname>Pasupathy</keyname><forenames>Abhay N.</forenames></author></authors><title>Dictionary Learning in Fourier Transform Scanning Tunneling Spectroscopy</title><categories>physics.comp-ph cond-mat.dis-nn cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern high-resolution microscopes, such as the scanning tunneling
microscope, are commonly used to study specimens that have dense and aperiodic
spatial structure. Extracting meaningful information from images obtained from
such microscopes remains a formidable challenge. Fourier analysis is commonly
used to analyze the underlying structure of fundamental motifs present in an
image. However, the Fourier transform fundamentally suffers from severe phase
noise when applied to aperiodic images. Here, we report the development of a
new algorithm based on nonconvex optimization, applicable to any microscopy
modality, that directly uncovers the fundamental motifs present in a real-space
image. Apart from being quantitatively superior to traditional Fourier
analysis, we show that this novel algorithm also uncovers phase sensitive
information about the underlying motif structure. We demonstrate its usefulness
by studying scanning tunneling microscopy images of a Co-doped iron arsenide
superconductor and prove that the application of the algorithm allows for the
complete recovery of quasiparticle interference in this material. Our phase
sensitive quasiparticle interference imaging results indicate that the pairing
symmetry in optimally doped NaFeAs is consistent with a sign-changing s+- order
parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10831</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10831</id><created>2018-07-29</created><authors><author><keyname>Pawar</keyname><forenames>Kamlesh</forenames></author><author><keyname>Chen</keyname><forenames>Zhaolin</forenames></author><author><keyname>Shah</keyname><forenames>N. Jon</forenames></author><author><keyname>Egan</keyname><forenames>Gary F.</forenames></author></authors><title>MoCoNet: Motion Correction in 3D MPRAGE images using a Convolutional
  Neural Network approach</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: The suppression of motion artefacts from MR images is a challenging
task. The purpose of this paper is to develop a standalone novel technique to
suppress motion artefacts from MR images using a data-driven deep learning
approach. Methods: A deep learning convolutional neural network (CNN) was
developed to remove motion artefacts in brain MR images. A CNN was trained on
simulated motion corrupted images to identify and suppress artefacts due to the
motion. The network was an encoder-decoder CNN architecture where the encoder
decomposed the motion corrupted images into a set of feature maps. The feature
maps were then combined by the decoder network to generate a motion-corrected
image. The network was tested on an unseen simulated dataset and an
experimental, motion corrupted in vivo brain dataset. Results: The trained
network was able to suppress the motion artefacts in the simulated motion
corrupted images, and the mean percentage error in the motion corrected images
was 2.69 % with a standard deviation of 0.95 %. The network was able to
effectively suppress the motion artefacts from the experimental dataset,
demonstrating the generalisation capability of the trained network. Conclusion:
A novel and generic motion correction technique has been developed that can
suppress motion artefacts from motion corrupted MR images. The proposed
technique is a standalone post-processing method that does not interfere with
data acquisition or reconstruction parameters, thus making it suitable for a
multitude of MR sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10834</identifier>
 <datestamp>2018-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10834</id><created>2018-07-27</created><updated>2018-09-17</updated><authors><author><keyname>Tward</keyname><forenames>Daniel J.</forenames></author><author><keyname>Mitra</keyname><forenames>Partha</forenames></author><author><keyname>Miller</keyname><forenames>Michael I.</forenames></author></authors><title>Estimating Diffeomorphic Mappings between Templates and Noisy Data:
  Variance Bounds on the Estimated Canonical Volume Form</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anatomy is undergoing a renaissance driven by availability of large digital
data sets generated by light microscopy. A central computational task is to map
individual data volumes to standardized templates. This is accomplished by
regularized estimation of a diffeomorphic transformation between the coordinate
systems of the individual data and the template, building the transformation
incrementally by integrating a smooth flow field. The canonical volume form of
this transformation is used to quantify local growth, atrophy, or cell density.
While multiple implementations exist for this estimation, less attention has
been paid to the variance of the estimated diffeomorphism for noisy data.
Notably, there is an infinite dimensional un-observable space defined by those
diffeomorphisms which leave the template invariant. These form the stabilizer
subgroup of the diffeomorphic group acting on the template. The corresponding
flat directions in the energy landscape are expected to lead to increased
estimation variance. Here we show that a least-action principle used to
generate geodesics in the space of diffeomorphisms connecting the subject brain
to the template removes the stabilizer. This provides reduced-variance
estimates of the volume form. Using simulations we demonstrate that the
asymmetric large deformation diffeomorphic mapping methods (LDDMM), which
explicitly incorporate the asymmetry between idealized template images and
noisy empirical images, provide lower variance estimators than their
symmetrized counterparts (cf. ANTs). We derive Cramer-Rao bounds for the
variances in the limit of small deformations. Analytical results are shown for
the Jacobian in terms of perturbations of the vector fields and divergence of
the vector field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10857</identifier>
 <datestamp>2018-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10857</id><created>2018-07-27</created><updated>2018-11-06</updated><authors><author><keyname>Toshniwal</keyname><forenames>Shubham</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N</forenames></author><author><keyname>Livescu</keyname><forenames>Karen</forenames></author></authors><title>A Comparison of Techniques for Language Model Integration in
  Encoder-Decoder Speech Recognition</title><categories>eess.AS cs.AI cs.CL cs.SD</categories><comments>Accepted in SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based recurrent neural encoder-decoder models present an elegant
solution to the automatic speech recognition problem. This approach folds the
acoustic model, pronunciation model, and language model into a single network
and requires only a parallel corpus of speech and text for training. However,
unlike in conventional approaches that combine separate acoustic and language
models, it is not clear how to use additional (unpaired) text. While there has
been previous work on methods addressing this problem, a thorough comparison
among methods is still lacking. In this paper, we compare a suite of past
methods and some of our own proposed methods for using unpaired text data to
improve encoder-decoder models. For evaluation, we use the medium-sized
Switchboard data set and the large-scale Google voice search and dictation data
sets. Our results confirm the benefits of using unpaired text across a range of
methods and data sets. Surprisingly, for first-pass decoding, the rather simple
approach of shallow fusion performs best across data sets. However, for Google
data sets we find that cold fusion has a lower oracle error rate and
outperforms other approaches after second-pass rescoring on the Google voice
search data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10911</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10911</id><created>2018-07-28</created><authors><author><keyname>Ding</keyname><forenames>Tian</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Sparsity Learning Based Multiuser Detection in Grant-Free Massive-Device
  Multiple Access</title><categories>eess.SP</categories><comments>12 pages, 9 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the multiuser detection (MUD) problem for a grant-free
massive-device multiple access (MaDMA) system, where a large number of
single-antenna user devices transmit sporadic data to a multi-antenna base
station (BS). Specifically, we put forth two MUD schemes, termed random
sparsity learning multiuser detection (RSL-MUD) and structured sparsity
learning multiuser detection (SSL-MUD) for the time-slotted and
non-time-slotted grant-free MaDMA systems, respectively. In the time-slotted
RSL-MUD scheme, active users generate and transmit data packets with random
sparsity. In the non-time-slotted SSL-MUD scheme, we introduce a
sliding-window-based detection framework, and the user signals in each
observation window naturally exhibit structured sparsity. We show that by
exploiting the sparsity embedded in the user signals, we can recover the user
activity state, the channel, and the user data in a single phase, without using
pilot signals for channel estimation and/or active user identification. To this
end, we develop a message-passing based statistical inference framework for the
BS to blindly detect the user data without any prior knowledge of the
identities and the channel state information (CSI) of the active users.
Simulation results show that our RSL-MUD and SSL-MUD schemes significantly
outperform their counterpart schemes in both reducing the transmission overhead
and improving the error behavior of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10917</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10917</id><created>2018-07-28</created><authors><author><keyname>Chang</keyname><forenames>Bei-Hao</forenames></author><author><keyname>Chang</keyname><forenames>Chia-Fu</forenames></author><author><keyname>Su</keyname><forenames>Pin-Wen</forenames></author><author><keyname>Yeh</keyname><forenames>I-Hsien</forenames></author><author><keyname>Cheng</keyname><forenames>Kai-Chuan</forenames></author><author><keyname>Lin</keyname><forenames>Ying-Chen</forenames></author><author><keyname>Lin</keyname><forenames>Mao-Chao</forenames></author></authors><title>Multiple Access for Transmissions Over Independent Fading Channels</title><categories>eess.SP</categories><comments>26 pages, 14 figures. Not published by now. Some results appear in
  the Master theses of Bei-Hao Chang, I-Hsien Yeh and Ying-Chen Lin
  respectively at National Taiwan University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to employ a multilevel detection (MLDT) technique to allow
multiple users which respectively transmit messages over independent fading
channels to share the same resource, e.g., the same signature sequence in the
CDMA (code division multiple access) system. The users are separated by the
different channel gains including amplitudes and phases resultant from the
independent fading channels. In a CDMA system with a fixed amount of available
signature sequences, the number of users can be doubled or tripled by using
MLDT although there is the cost of some BER performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10930</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10930</id><created>2018-07-28</created><authors><author><keyname>Moreira</keyname><forenames>J. S.</forenames></author><author><keyname>Filho</keyname><forenames>P. C. M. Lamim</forenames></author><author><keyname>Baccarini</keyname><forenames>L. M. R.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author><author><keyname>Guedes</keyname><forenames>P. F. S.</forenames></author></authors><title>Decimation analysis in the signal processing of current to detect broken
  bars in induction machine</title><categories>eess.SP</categories><comments>in Portuguese</comments><journal-ref>CBA 2018 - XXII Congresso Brasileiro de Automatica, Joao Pessoa,
  p. 1-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a study on the reduction of the sampling frequency of the
current signals of an induction motor, the reductions are performed by means
time-decimation technique for digital signal processing. We have used the Fast
Fourier Transform to obtain the fault signal spectrum of broken bars. The
results have shown how the decimation technique significantly reduces the
number of operations and the time required to calculate the Fast Fourier
Transform without loss of information. This approach provides a better
performance of embedded systems for fault diagnosis based on characteristic of
amplitude signal modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10941</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10941</id><created>2018-07-28</created><authors><author><keyname>Henter</keyname><forenames>Gustav Eje</forenames></author><author><keyname>King</keyname><forenames>Simon</forenames></author><author><keyname>Merritt</keyname><forenames>Thomas</forenames></author><author><keyname>Degottex</keyname><forenames>Gilles</forenames></author></authors><title>Analysing Shortcomings of Statistical Parametric Speech Synthesis</title><categories>eess.AS cs.SD</categories><comments>34 pages with 4 figures; draft book chapter</comments><acm-class>I.2.7; H.5.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Output from statistical parametric speech synthesis (SPSS) remains noticeably
worse than natural speech recordings in terms of quality, naturalness, speaker
similarity, and intelligibility in noise. There are many hypotheses regarding
the origins of these shortcomings, but these hypotheses are often kept vague
and presented without empirical evidence that could confirm and quantify how a
specific shortcoming contributes to imperfections in the synthesised speech.
Throughout speech synthesis literature, surprisingly little work is dedicated
towards identifying the perceptually most important problems in speech
synthesis, even though such knowledge would be of great value for creating
better SPSS systems.
  In this book chapter, we analyse some of the shortcomings of SPSS. In
particular, we discuss issues with vocoding and present a general methodology
for quantifying the effect of any of the many assumptions and design choices
that hold SPSS back. The methodology is accompanied by an example that
carefully measures and compares the severity of perceptual limitations imposed
by vocoding as well as other factors such as the statistical model and its use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10962</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10962</id><created>2018-07-28</created><authors><author><keyname>Ahmadi</keyname><forenames>Hamed</forenames></author><author><keyname>Fontanesi</keyname><forenames>Gianluca</forenames></author><author><keyname>Katzis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Shakir</keyname><forenames>Muhammad Zeeshan</forenames></author><author><keyname>Zhu</keyname><forenames>Anding</forenames></author></authors><title>Resilience of airborne networks</title><categories>eess.SP</categories><comments>2 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networked flying platforms can be used to provide cellular coverage and
capacity. Given that 5G and beyond networks are expected to be always available
and highly reliable, resilience and reliability of these networks must be
investigated. This paper introduces the specific features of airborne networks
that influence their resilience. We then discuss how machine learning and
blockchain technologies can enhance the resilience of networked flying
platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.10984</identifier>
 <datestamp>2018-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.10984</id><created>2018-07-28</created><updated>2018-09-30</updated><authors><author><keyname>Dalmia</keyname><forenames>Siddharth</forenames></author><author><keyname>Li</keyname><forenames>Xinjian</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author><author><keyname>Black</keyname><forenames>Alan W.</forenames></author></authors><title>Domain Robust Feature Extraction for Rapid Low Resource ASR Development</title><categories>cs.CL cs.SD eess.AS</categories><comments>To appear in SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing a practical speech recognizer for a low resource language is
challenging, not only because of the (potentially unknown) properties of the
language, but also because test data may not be from the same domain as the
available training data. In this paper, we focus on the latter challenge, i.e.
domain mismatch, for systems trained using a sequence-based criterion. We
demonstrate the effectiveness of using a pre-trained English recognizer, which
is robust to such mismatched conditions, as a domain normalizing feature
extractor on a low resource language. In our example, we use Turkish
Conversational Speech and Broadcast News data. This enables rapid development
of speech recognizers for new languages which can easily adapt to any domain.
Testing in various cross-domain scenarios, we achieve relative improvements of
around 25% in phoneme error rate, with improvements being around 50% for some
domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11073</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11073</id><created>2018-07-29</created><authors><author><keyname>Jaeger</keyname><forenames>Herman Alexander</forenames></author><author><keyname>Hinds</keyname><forenames>Stephen</forenames></author><author><keyname>Cantillon-Murphy</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>An Open Framework Enabling Electromagnetic Tracking in Image-Guided
  Interventions</title><categories>eess.SP</categories><comments>8 pages, Accepted to MICCAI 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electromagnetic tracking (EMT) is a core platform technology in the
navigation and visualisation of image-guided procedures. The technology
provides high tracking accuracy in non-line-of-sight environments, allowing
instrument navigation in locations where optical tracking is not feasible.
Integration of EMT in complex procedures, often coupled with multi-modal
imaging, is on the rise, yet the lack of exibility in the available hardware
platforms has been noted by many researchers and system designers. Advances in
the field of EMT include novel methods of improving tracking system accuracy,
precision and error compensation capabilities, though such system-level
improvements cannot be readily incorporated in current therapy applications due
to the `blackbox' nature of commercial tracking solving algorithms. This paper
defines a software framework to allow novel EMT designs and improvements become
part of the global design process for image-guided interventions. In an effort
to standardise EMT development, we define a generalised cross-platform software
framework in terms of the four system functions common to all EMT systems;
acquisition, filtering, modelling and solving. The interfaces between each
software component are defined in terms of their input and output data
structures. An exemplary framework is implemented in the Python programming
language and demonstrated with the open-source Anser EMT system. Performance
metrics are gathered from both Matlab and Python implementations of Anser EMT
considering the host operating system, hardware configuration and acquisition
settings used. Results show indicative system latencies of 5 ms can be achieved
using the framework on a Windows operating system, with decreased system
performance observed on UNIX-like platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11089</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11089</id><created>2018-07-29</created><authors><author><keyname>Saha</keyname><forenames>Pramit</forenames></author><author><keyname>Srungarapu</keyname><forenames>Praneeth</forenames></author><author><keyname>Fels</keyname><forenames>Sidney</forenames></author></authors><title>Towards Automatic Speech Identification from Vocal Tract Shape Dynamics
  in Real-time MRI</title><categories>cs.SD cs.CL cs.CV cs.LG eess.AS</categories><comments>To appear in the INTERSPEECH 2018 Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vocal tract configurations play a vital role in generating distinguishable
speech sounds, by modulating the airflow and creating different resonant
cavities in speech production. They contain abundant information that can be
utilized to better understand the underlying speech production mechanism. As a
step towards automatic mapping of vocal tract shape geometry to acoustics, this
paper employs effective video action recognition techniques, like Long-term
Recurrent Convolutional Networks (LRCN) models, to identify different
vowel-consonant-vowel (VCV) sequences from dynamic shaping of the vocal tract.
Such a model typically combines a CNN based deep hierarchical visual feature
extractor with Recurrent Networks, that ideally makes the network
spatio-temporally deep enough to learn the sequential dynamics of a short video
clip for video classification tasks. We use a database consisting of 2D
real-time MRI of vocal tract shaping during VCV utterances by 17 speakers. The
comparative performances of this class of algorithms under various parameter
settings and for various classification tasks are discussed. Interestingly, the
results show a marked difference in the model performance in the context of
speech classification with respect to generic sequence or video classification
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11094</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11094</id><created>2018-07-29</created><authors><author><keyname>Vera-Diaz</keyname><forenames>Juan Manuel</forenames></author><author><keyname>Pizarro</keyname><forenames>Daniel</forenames></author><author><keyname>Macias-Guarasa</keyname><forenames>Javier</forenames></author></authors><title>Towards End-to-End Acoustic Localization using Deep Learning: from Audio
  Signal to Source Position Coordinates</title><categories>cs.SD eess.AS</categories><comments>18 pages, 3 figures, 8 tables</comments><journal-ref>Sensors 2018, (volume 18(10), 3418)</journal-ref><doi>10.3390/s18103418</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a novel approach for indoor acoustic source localization
using microphone arrays and based on a Convolutional Neural Network (CNN). The
proposed solution is, to the best of our knowledge, the first published work in
which the CNN is designed to directly estimate the three dimensional position
of an acoustic source, using the raw audio signal as the input information
avoiding the use of hand crafted audio features. Given the limited amount of
available localization data, we propose in this paper a training strategy based
on two steps. We first train our network using semi-synthetic data, generated
from close talk speech recordings, and where we simulate the time delays and
distortion suffered in the signal that propagates from the source to the array
of microphones. We then fine tune this network using a small amount of real
data. Our experimental results show that this strategy is able to produce
networks that significantly improve existing localization methods based on
\textit{SRP-PHAT} strategies. In addition, our experiments show that our CNN
method exhibits better resistance against varying gender of the speaker and
different window sizes compared with the other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11116</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11116</id><created>2018-07-29</created><updated>2019-06-10</updated><authors><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author><author><keyname>Whitehouse</keyname><forenames>Daniel</forenames></author></authors><title>Sparse Representation of 3D Images for Piecewise Dimensionality
  Reduction with High Quality Reconstruction</title><categories>eess.IV</categories><comments>All the scripts and images for reproducing the results are available
  on http://www.nonlinear-approx.info/examples/node09.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representation of 3D images is considered within the context of data
reduction. The goal is to produce high quality approximations of 3D images
using fewer elementary components than the number of intensity points in the 3D
array. This is achieved by means of a highly redundant dictionary and a
dedicated pursuit strategy especially designed for low memory requirements. The
benefit of the proposed framework is illustrated in the first instance by
demonstrating the gain in dimensionality reduction obtained when approximating
true color images as very thin 3D arrays, instead of performing an independent
channel by channel approximation. The full power of the approach is further
exemplified by producing high quality approximations of hyper-spectral images
with a reduction of up to 371 times the number of data points in the
representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11138</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11138</id><created>2018-07-29</created><authors><author><keyname>Vidwans</keyname><forenames>Amruta</forenames></author><author><keyname>Deo</keyname><forenames>Nachiket</forenames></author><author><keyname>Rao</keyname><forenames>Preeti</forenames></author></authors><title>Audio segmentation based on melodic style with hand-crafted features and
  with convolutional neural networks</title><categories>cs.SD eess.AS</categories><comments>This work was done in 2015 at Indian Institute of Technology, Bombay,
  as a part of the ERC grant agreement 267583 (CompMusic) project</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate methods for the automatic labeling of the taan section, a
prominent structural component of the Hindustani Khayal vocal concert. The taan
contains improvised raga-based melody rendered in the highly distinctive style
of rapid pitch and energy modulations of the voice. We propose computational
features that capture these specific high-level characteristics of the singing
voice in the polyphonic context. The extracted local features are used to
achieve classification at the frame level via a trained multilayer perceptron
(MLP) network, followed by grouping and segmentation based on novelty
detection. We report high accuracies with reference to musician annotated taan
sections across artists and concerts. We also compare the performance obtained
by the compact specialized features with frame-level classification via a
convolutional neural network (CNN) operating directly on audio spectrogram
patches for the same task. While the relatively simple architecture we
experiment with does not quite attain the classification accuracy of the
hand-crafted features, it provides for a performance well above chance with
interesting insights about the ability of the network to learn discriminative
features effectively from labeled data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11161</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11161</id><created>2018-07-29</created><authors><author><keyname>Liu</keyname><forenames>Hao-Min</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Lead Sheet Generation and Arrangement by Conditional Generative
  Adversarial Network</title><categories>cs.SD cs.AI cs.LG eess.AS</categories><comments>7 pages, 7 figures and 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on automatic music generation has seen great progress due to the
development of deep neural networks. However, the generation of
multi-instrument music of arbitrary genres still remains a challenge. Existing
research either works on lead sheets or multi-track piano-rolls found in MIDIs,
but both musical notations have their limits. In this work, we propose a new
task called lead sheet arrangement to avoid such limits. A new recurrent
convolutional generative model for the task is proposed, along with three new
symbolic-domain harmonic features to facilitate learning from unpaired lead
sheets and MIDIs. Our model can generate lead sheets and their arrangements of
eight-bar long. Audio samples of the generated result can be found at
https://drive.google.com/open?id=1c0FfODTpudmLvuKBbc23VBCgQizY6-Rk
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11212</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11212</id><created>2018-07-30</created><authors><author><keyname>Favelier</keyname><forenames>Guillaume</forenames></author><author><keyname>Faraj</keyname><forenames>Noura</forenames></author><author><keyname>Summa</keyname><forenames>Brian</forenames></author><author><keyname>Tierny</keyname><forenames>Julien</forenames></author></authors><title>Persistence Atlas for Critical Point Variability in Ensembles</title><categories>cs.GR cs.CG cs.CV eess.IV</categories><report-no>2344815-v2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for the visualization and analysis of the
spatial variability of features of interest represented by critical points in
ensemble data. Our framework, called Persistence Atlas, enables the
visualization of the dominant spatial patterns of critical points, along with
statistics regarding their occurrence in the ensemble. The persistence atlas
represents in the geometrical domain each dominant pattern in the form of a
confidence map for the appearance of critical points. As a by-product, our
method also provides 2-dimensional layouts of the entire ensemble, highlighting
the main trends at a global level. Our approach is based on the new notion of
Persistence Map, a measure of the geometrical density in critical points which
leverages the robustness to noise of topological persistence to better
emphasize salient features. We show how to leverage spectral embedding to
represent the ensemble members as points in a low-dimensional Euclidean space,
where distances between points measure the dissimilarities between critical
point layouts and where statistical tasks, such as clustering, can be easily
carried out. Further, we show how the notion of mandatory critical point can be
leveraged to evaluate for each cluster confidence regions for the appearance of
critical points. Most of the steps of this framework can be trivially
parallelized and we show how to efficiently implement them. Extensive
experiments demonstrate the relevance of our approach. The accuracy of the
confidence regions provided by the persistence atlas is quantitatively
evaluated and compared to a baseline strategy using an off-the-shelf clustering
approach. We illustrate the importance of the persistence atlas in a variety of
real-life datasets, where clear trends in feature layouts are identified and
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11246</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11246</id><created>2018-07-30</created><updated>2018-08-01</updated><authors><author><keyname>Dekkers</keyname><forenames>Gert</forenames></author><author><keyname>Vuegen</keyname><forenames>Lode</forenames></author><author><keyname>van Waterschoot</keyname><forenames>Toon</forenames></author><author><keyname>Vanrumste</keyname><forenames>Bart</forenames></author><author><keyname>Karsmakers</keyname><forenames>Peter</forenames></author></authors><title>DCASE 2018 Challenge - Task 5: Monitoring of domestic activities based
  on multi-channel acoustics</title><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The DCASE 2018 Challenge consists of five tasks related to automatic
classification and detection of sound events and scenes. This paper presents
the setup of Task 5 which includes the description of the task, dataset and the
baseline system. In this task, it is investigated to which extent multi-channel
acoustic recordings are beneficial for the purpose of classifying domestic
activities. The goal is to exploit spectral and spatial cues independent of
sensor location using multi-channel audio. For this purpose we provided a
development and evaluation dataset which are derivatives of the SINS database
and contain domestic activities recorded by multiple microphone arrays. The
baseline system, based on a Neural Network architecture using convolutional and
dense layer(s), is intended to lower the hurdle to participate the challenge
and to provide a reference performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11284</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11284</id><created>2018-07-30</created><authors><author><keyname>Denisov</keyname><forenames>Pavel</forenames></author><author><keyname>Vu</keyname><forenames>Ngoc Thang</forenames></author><author><keyname>Font</keyname><forenames>Marc Ferras</forenames></author></authors><title>Unsupervised Domain Adaptation by Adversarial Learning for Robust Speech
  Recognition</title><categories>eess.AS cs.AI cs.CL cs.SD</categories><comments>5 pages, 2 figures, the 13th ITG conference on Speech Communication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the use of adversarial learning for
unsupervised adaptation to unseen recording conditions, more specifically,
single microphone far-field speech. We adapt neural networks based acoustic
models trained with close-talk clean speech to the new recording conditions
using untranscribed adaptation data. Our experimental results on Italian
SPEECON data set show that our proposed method achieves 19.8% relative word
error rate (WER) reduction compared to the unadapted models. Furthermore, this
adaptation method is beneficial even when performed on data from another
language (i.e. French) giving 12.6% relative WER reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11296</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11296</id><created>2018-07-30</created><authors><author><keyname>Rajan</keyname><forenames>Raj Thilak</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>van der Veen</keyname><forenames>Alle-Jan</forenames></author></authors><title>Relative kinematics of an anchorless network</title><categories>eess.SP</categories><comments>In submission, Elsevier signal processing</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Estimating the location of N coordinates in a P dimensional Euclidean space
from pairwise distances (or proximity measurements), is a principal challenge
in a wide variety of fields. Conventionally, when localizing a static network
of immobile nodes, non-linear dimensional reduction techniques are applied on
the measured Euclidean distance matrix (EDM) to obtain the relative coordinates
upto a rotation and translation. In this article, we focus on an anchorless
network of mobile nodes, where the distance measurements between the mobile
nodes are time-varying in nature. Furthermore, in an anchorless network the
absolute knowledge of any node positions, motion or reference frame is absent.
We derive a novel data model which relates the time-varying EDMs to the
time-varying relative positions of an anchorless network. Using this data
model, we estimate the relative position, relative velocity and higher order
derivatives, which are collectively termed as the relative kinematics of the
anchorless network. The derived data model is inherently ill-posed, however can
be solved using certain relative immobility constraints. We propose elegant
closed form solutions to recursively estimate the relative kinematics of the
network. For the sake of completeness, estimators are also proposed to find the
absolute kinematics of the nodes, given known reference anchors. Cramer-Rao
bounds are derived for the new data model and simulations are performed to
analyze the performance of the proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11298</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11298</id><created>2018-07-30</created><authors><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Magron</keyname><forenames>Paul</forenames></author><author><keyname>Mimilakis</keyname><forenames>Stylianos Ioannis</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Harmonic-Percussive Source Separation with Deep Neural Networks and
  Phase Recovery</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Harmonic/percussive source separation (HPSS) consists in separating the
pitched instruments from the percussive parts in a music mixture. In this
paper, we propose to apply the recently introduced Masker-Denoiser with twin
networks (MaD TwinNet) system to this task. MaD TwinNet is a deep learning
architecture that has reached state-of-the-art results in monaural singing
voice separation. Herein, we propose to apply it to HPSS by using it to
estimate the magnitude spectrogram of the percussive source. Then, we retrieve
the complex-valued short-time Fourier transform of the sources by means of a
phase recovery algorithm, which minimizes the reconstruction error and enforces
the phase of the harmonic part to follow a sinusoidal phase model. Experiments
conducted on realistic music mixtures show that this novel separation system
outperforms the previous state-of-the art kernel additive model approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11314</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11314</id><created>2018-07-30</created><authors><author><keyname>Ollier</keyname><forenames>Virginie</forenames></author><author><keyname>Korso</keyname><forenames>Mohammed Nabil El</forenames></author><author><keyname>Ferrari</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Boyer</keyname><forenames>R&#xe9;my</forenames></author><author><keyname>Larzabal</keyname><forenames>Pascal</forenames></author></authors><title>Robust Calibration of Radio Interferometers in Multi-Frequency Scenario</title><categories>stat.AP astro-ph.IM eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates calibration of sensor arrays in the radio astronomy
context. Current and future radio telescopes require computationally efficient
algorithms to overcome the new technical challenges as large collecting area,
wide field of view and huge data volume. Specifically, we study the calibration
of radio interferometry stations with significant direction dependent
distortions. We propose an iterative robust calibration algorithm based on a
relaxed maximum likelihood estimator for a specific context: i) observations
are affected by the presence of outliers and ii) parameters of interest have a
specific structure depending on frequency. Variation of parameters across
frequency is addressed through a distributed procedure, which is consistent
with the new radio synthesis arrays where the full observing bandwidth is
divided into multiple frequency channels. Numerical simulations reveal that the
proposed robust distributed calibration estimator outperforms the conventional
non-robust algorithm and/or the mono-frequency case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11320</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11320</id><created>2018-07-30</created><authors><author><keyname>Henter</keyname><forenames>Gustav Eje</forenames></author><author><keyname>Leijon</keyname><forenames>Arne</forenames></author><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author></authors><title>Kernel Density Estimation-Based Markov Models with Hidden State</title><categories>cs.LG eess.SP stat.ML</categories><comments>14 pages, 6 figures</comments><msc-class>62M10, 62G07</msc-class><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Markov models of stochastic processes where the next-step
conditional distribution is defined by a kernel density estimator (KDE),
similar to Markov forecast densities and certain time-series bootstrap schemes.
The KDE Markov models (KDE-MMs) we discuss are nonlinear, nonparametric, fully
probabilistic representations of stationary processes, based on techniques with
strong asymptotic consistency properties. The models generate new data by
concatenating points from the training data sequences in a context-sensitive
manner, together with some additive driving noise. We present novel EM-type
maximum-likelihood algorithms for data-driven bandwidth selection in KDE-MMs.
Additionally, we augment the KDE-MMs with a hidden state, yielding a new model
class, KDE-HMMs. The added state variable captures non-Markovian long memory
and signal structure (e.g., slow oscillations), complementing the short-range
dependences described by the Markov process. The resulting joint Markov and
hidden-Markov structure is appealing for modelling complex real-world processes
such as speech signals. We present guaranteed-ascent EM-update equations for
model parameters in the case of Gaussian kernels, as well as relaxed update
formulas that greatly accelerate training in practice. Experiments demonstrate
increased held-out set probability for KDE-HMMs on several challenging natural
and synthetic data series, compared to traditional techniques such as
autoregressive models, HMMs, and their combinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11359</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11359</id><created>2018-07-30</created><updated>2019-07-17</updated><authors><author><keyname>Romero</keyname><forenames>Francisco Perdigon</forenames></author><author><keyname>Romaguera</keyname><forenames>Liset Vazquez</forenames></author><author><keyname>V&#xe1;zquez-Seisdedos</keyname><forenames>Carlos Rom&#xe1;n</forenames></author><author><keyname>Filho</keyname><forenames>C&#xed;cero Ferreira Fernandes Costa</forenames></author><author><keyname>Costa</keyname><forenames>Marly Guimar&#xe3;es Fernandes</forenames></author><author><keyname>Neto</keyname><forenames>Jo&#xe3;o Evangelista</forenames></author></authors><title>Baseline wander removal methods for ECG signals: A comparative study</title><categories>eess.SP</categories><comments>10 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiovascular diseases are the leading cause of death worldwide, accounting
for 17.3 million deaths per year. The electrocardiogram (ECG) is a non-invasive
technique widely used for the detection of cardiac diseases. To increase
diagnostic sensitivity, ECG is acquired during exercise stress tests or in an
ambulatory way. Under these acquisition conditions, the ECG is strongly
affected by some types of noise, mainly by baseline wander (BLW). In this work
were implemented nine methods widely used for the elimination of BLW, which
are: interpolation using cubic splines, FIR filter, IIR filter, least mean
square adaptive filtering, moving-average filter, independent component
analysis, interpolation and successive subtraction of median values in RR
interval, empirical mode decomposition and wavelet filtering. For the
quantitative evaluation, the following similarity metrics were used: absolute
maximum distance, the sum of squares of distances and percentage
root-mean-square difference. Several experiments were performed using synthetic
ECG signals generated by ECGSYM software, real ECG signals from QT Database,
artificial BLW generated by software and real BLW from the Noise Stress Test
Database. The best results were obtained by the method based on FIR high-pass
filter with a cut-off frequency of 0.67 Hz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11382</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11382</id><created>2018-07-30</created><authors><author><keyname>Ollier</keyname><forenames>Virginie</forenames></author><author><keyname>Korso</keyname><forenames>Mohammed Nabil El</forenames></author><author><keyname>Ferrari</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Boyer</keyname><forenames>R&#xe9;my</forenames></author><author><keyname>Larzabal</keyname><forenames>Pascal</forenames></author></authors><title>Bayesian Calibration using Different Prior Distributions: an Iterative
  Maximum A Posteriori Approach for Radio Interferometers</title><categories>stat.AP astro-ph.IM eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim to design robust estimation techniques based on the
compound-Gaussian (CG) process and adapted for calibration of radio
interferometers. The motivation beyond this is due to the presence of outliers
leading to an unrealistic traditional Gaussian noise assumption. Consequently,
to achieve robustness, we adopt a maximum a posteriori (MAP) approach which
exploits Bayesian statistics and follows a sequential updating procedure here.
The proposed algorithm is applied in a multi-frequency scenario in order to
enhance the estimation and correction of perturbation effects. Numerical
simulations assess the performance of the proposed algorithm for different
noise models, Student's t, K, Laplace, Cauchy and inverse-Gaussian
compound-Gaussian distributions w.r.t. the classical non-robust Gaussian noise
assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11384</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11384</id><created>2018-07-30</created><authors><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Karrenbauer</keyname><forenames>Michael</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Security Solutions for Local Wireless Networks in Control Applications
  based on Physical Layer Security</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Design of new wireless communication systems for industrial applications,
e.g. control applications, is currently a hot research topic, as they deal as a
key enabler for more flexible solutions at a lower cost compared to systems
based on wired communication. However, one of their main drawbacks is, that
they provide a huge potential for miscellaneous cyber attacks due to the open
nature of the wireless channel in combination with the huge economic potential
they are able to provide. Therefore, security measures need to be taken into
account for the design of such systems. Within this work, an approach for the
security architecture of local wireless systems with respect to the needs of
control applications is presented and discussed. Further, new security
solutions based on Physical Layer Security are introduced in order to overcome
the drawbacks of state of the art security technologies within that scope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11455</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11455</id><created>2018-07-30</created><updated>2019-03-26</updated><authors><author><keyname>Cavalcanti</keyname><forenames>Yanna Cruz</forenames></author><author><keyname>Oberlin</keyname><forenames>Thomas</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>F&#xe9;votte</keyname><forenames>C&#xe9;dric</forenames></author><author><keyname>Stute</keyname><forenames>Simon</forenames></author><author><keyname>Ribeiro</keyname><forenames>Maria-Joao</forenames></author><author><keyname>Tauber</keyname><forenames>Clovis</forenames></author></authors><title>Factor analysis of dynamic PET images: beyond Gaussian noise</title><categories>eess.IV cs.CV physics.data-an stat.ML</categories><comments>This manuscript has been accepted for publication in IEEE Trans.
  Medical Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Factor analysis has proven to be a relevant tool for extracting tissue
time-activity curves (TACs) in dynamic PET images, since it allows for an
unsupervised analysis of the data. Reliable and interpretable results are
possible only if considered with respect to suitable noise statistics. However,
the noise in reconstructed dynamic PET images is very difficult to
characterize, despite the Poissonian nature of the count-rates. Rather than
explicitly modeling the noise distribution, this work proposes to study the
relevance of several divergence measures to be used within a factor analysis
framework. To this end, the $\beta$-divergence, widely used in other
applicative domains, is considered to design the data-fitting term involved in
three different factor models. The performances of the resulting algorithms are
evaluated for different values of $\beta$, in a range covering Gaussian,
Poissonian and Gamma-distributed noises. The results obtained on two different
types of synthetic images and one real image show the interest of applying
non-standard values of $\beta$ to improve factor analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11470</identifier>
 <datestamp>2018-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11470</id><created>2018-07-30</created><updated>2018-09-09</updated><authors><author><keyname>Henter</keyname><forenames>Gustav Eje</forenames></author><author><keyname>Lorenzo-Trueba</keyname><forenames>Jaime</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Deep Encoder-Decoder Models for Unsupervised Learning of Controllable
  Speech Synthesis</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>17 pages, 4 figures</comments><msc-class>62F99</msc-class><acm-class>I.2.7; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating versatile and appropriate synthetic speech requires control over
the output expression separate from the spoken text. Important non-textual
speech variation is seldom annotated, in which case output control must be
learned in an unsupervised fashion. In this paper, we perform an in-depth study
of methods for unsupervised learning of control in statistical speech
synthesis. For example, we show that popular unsupervised training heuristics
can be interpreted as variational inference in certain autoencoder models. We
additionally connect these models to VQ-VAEs, another, recently-proposed class
of deep variational autoencoders, which we show can be derived from a very
similar mathematical argument. The implications of these new probabilistic
interpretations are discussed. We illustrate the utility of the various
approaches with an application to acoustic modelling for emotional speech
synthesis, where the unsupervised methods for learning expression control
(without access to emotional labels) are found to give results that in many
aspects match or surpass the previous best supervised approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11542</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11542</id><created>2018-07-30</created><authors><author><keyname>Cohen</keyname><forenames>Deborah</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Sub-Nyquist Radar Systems: Temporal, Spectral and Spatial Compression</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/MSP.2018.2868137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional radar transmits electromagnetic waves towards the targets of
interest. In between the outgoing pulses, the radar measures the signal
reflected from the targets to determine their presence, range, velocity and
other characteristics. Radar systems face multiple challenges, generating many
trade-offs such as bandwidth versus range resolution and dwell time versus
Doppler resolution. In MIMO radar, high resolution requires a large aperture
and high number of antennas, increasing hardware and processing requirements.
  Recently, novel approaches in sampling theory and radar signal processing
have been proposed to allow target detection and parameter recovery from
samples obtained below the Nyquist rate. These techniques exploit the sparsity
of the target scene in order to reduce the required number of samples, pulses
and antennas, breaking the link between bandwidth, dwell time and number of
antennas on the one hand and range, Doppler and azimuth resolution,
respectively, on the other.
  This review introduces this so-called sub-Nyquist radar paradigm and
describes the corresponding sampling and recovery algorithms, that leverage
compressed sensing techniques to perform time and spatial compression. We focus
on non radar imaging applications and survey many recent compressed radar
systems. Our goal is to review the main impacts of compressed radar on
parameter resolution as well as digital and analog complexity. The survey
includes fast and slow time compression schemes as well as spatial compression
approaches. We show that beyond substantial rate reduction, compression may
also enable communication and radar spectrum sharing. Throughout the paper, we
consider both theoretical and practical aspects of compressed radar, and
present hardware prototype implementations, demonstrating real-time target
parameter recovery from low rate samples in pulse-Doppler and MIMO radars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11551</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11551</id><created>2018-07-30</created><updated>2019-01-17</updated><authors><author><keyname>Antczak</keyname><forenames>Karol</forenames></author></authors><title>Deep Recurrent Neural Networks for ECG Signal Denoising</title><categories>cs.NE eess.SP</categories><comments>7 pages + 2 pages of references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrocardiographic signal is a subject to multiple noises, caused by
various factors. It is therefore a standard practice to denoise such signal
before further analysis. With advances of new branch of machine learning,
called deep learning, new methods are available that promises state-of-the-art
performance for this task. We present a novel approach to denoise
electrocardiographic signals with deep recurrent denoising neural networks. We
utilize a transfer learning technique by pretraining the network using
synthetic data, generated by a dynamic ECG model, and fine-tuning it with a
real data. We also investigate the impact of the synthetic training data on the
network performance on real signals. The proposed method was tested on a real
dataset with varying amount of noise. The results indicate that four-layer deep
recurrent neural network can outperform reference methods for heavily noised
signal. Moreover, networks pretrained with synthetic data seem to have better
results than network trained with real data only. We show that it is possible
to create state-of-the art denoising neural network that, pretrained on
artificial data, can perform exceptionally well on real ECG signals after
proper fine-tuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11571</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11571</id><created>2018-07-10</created><authors><author><keyname>Mastriani</keyname><forenames>Mario</forenames></author><author><keyname>Giraldez</keyname><forenames>Alberto. E.</forenames></author></authors><title>Microarrays denoising via smoothing of coefficients in wavelet domain</title><categories>eess.SP</categories><comments>8 pages, 4 figures, 2 tables. arXiv admin note: text overlap with
  arXiv:1611.02302, arXiv:1607.03105; text overlap with arXiv:1212.0291 by
  other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a novel method for removing noise (in wavelet domain) of unknown
variance from microarrays. The method is based on a smoothing of the
coefficients of the highest subbands. Specifically, we decompose the noisy
microarray into wavelet subbands, apply smoothing within each highest subband,
and reconstruct a microarray from the modified wavelet coefficients. This
process is applied a single time, and exclusively to the first level of
decomposition, i.e., in most of the cases, it is not necessary a
multirresoltuion analysis. Denoising results compare favorably to the most of
methods in use at the moment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11578</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11578</id><created>2018-07-25</created><authors><author><keyname>Ghazzai</keyname><forenames>Hakim</forenames></author><author><keyname>Ghorbel</keyname><forenames>Mahdi Ben</forenames></author><author><keyname>Kassler</keyname><forenames>Andreas</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Jahangir</forenames></author></authors><title>Trajectory Optimization for Cooperative Dual-band UAV Swarms</title><categories>eess.SP cs.RO cs.SY</categories><comments>8 pages, 5 figures, conference Globecom 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) have gained a lot of popularity in diverse
wireless communication fields. They can act as high-altitude flying relays to
support communications between ground nodes due to their ability to provide
line-of-sight links. With the flourishing Internet of Things, several types of
new applications are emerging. In this paper, we focus on bandwidth hungry and
delay-tolerant applications where multiple pairs of transceivers require the
support of UAVs to complete their transmissions. To do so, the UAVs have the
possibility to employ two different bands namely the typical microwave and the
high-rate millimeter wave bands. In this paper, we develop a generic framework
to assign UAVs to supported transceivers and optimize their trajectories such
that a weighted function of the total service time is minimized. Taking into
account both the communication time needed to relay the message and the flying
time of the UAVs, a mixed non-linear programming problem aiming at finding the
stops at which the UAVs hover to forward the data to the receivers is
formulated. An iterative approach is then developed to solve the problem.
First, a mixed linear programming problem is optimally solved to determine the
path of each available UAV. Then, a hierarchical iterative search is executed
to enhance the UAV stops' locations and reduce the service time. The behavior
of the UAVs and the benefits of the proposed framework are showcased for
selected scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11619</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11619</id><created>2018-07-30</created><authors><author><keyname>Jaffry</keyname><forenames>Shan</forenames></author><author><keyname>Hasan</keyname><forenames>Syed Faraz</forenames></author><author><keyname>Gui</keyname><forenames>Xiang</forenames></author></authors><title>Shared Spectrum for Mobile-Cells Backhaul and Access Link</title><categories>eess.SP</categories><comments>This paper has been accepted for presentation and publication in IEEE
  Globecom2018 NGNI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Offloading cellular hotspot regions to small-cells has been the main theme
for the fifth generation of cellular network. One such hotspot is the public
transport which carries a large number of cellular users who frequently receive
low quality of service (QoS) due to vehicular penetration effect (VPE). Hence
installation of mobile-cell (MC) within public transport is seen as a potential
enabler to enhance QoS for commuting users. However, unlike fixed cells, MC
requires wireless backhaul (BH) connectivity along with in-vehicle Access-Link
(AL) communication. These additional wireless links for MC communication will
pose an excessive burden on an already scarce frequency spectrum. Hence, in
this research, we exploit VPE and line-of-sight (LOS) communication to allow
the downlink backhaul (DL-BH) sub-channels to be shared by in-vehicle downlink
access-link (DL-AL) transmission. Our analysis and simulations show that using
the above-mentioned technique, both links maintain high success probability,
especially in regions with low signal to interference ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11631</identifier>
 <datestamp>2018-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11631</id><created>2018-07-30</created><authors><author><keyname>Khobahi</keyname><forenames>Shahin</forenames></author><author><keyname>Soltanalian</keyname><forenames>Mojtaba</forenames></author></authors><title>Optimized Transmission for Consensus in Wireless Sensor Networks</title><categories>cs.SY eess.SP</categories><comments>In Proceedings of IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP) 2018, 15-20 April 2018, Alberta, Canada</comments><journal-ref>2018 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)</journal-ref><doi>10.1109/ICASSP.2018.8461401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a consensus-based framework for decentralized
estimation of deterministic parameters in wireless sensor networks (WSNs). In
particular, we propose an optimization algorithm to design (possibly complex)
sensor gains in order to achieve an estimate of the parameter of interest that
is as accurate as possible. The proposed design algorithm employs a cyclic
approach capable of handling various sensor gain constraints. In addition, each
iteration of the proposed design framework is comprised of the Gram-Schmidt
process and power-method like iterations, and as a result, enjoys a
low-computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11632</identifier>
 <datestamp>2018-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11632</id><created>2018-07-30</created><updated>2018-09-30</updated><authors><author><keyname>Luong</keyname><forenames>Hieu-Thi</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Scaling and bias codes for modeling speaker-adaptive DNN-based speech
  synthesis systems</title><categories>eess.AS cs.SD stat.ML</categories><comments>Accepted for 2018 IEEE Workshop on Spoken Language Technology (SLT),
  Athens, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most neural-network based speaker-adaptive acoustic models for speech
synthesis can be categorized into either layer-based or input-code approaches.
Although both approaches have their own pros and cons, most existing works on
speaker adaptation focus on improving one or the other. In this paper, after we
first systematically overview the common principles of neural-network based
speaker-adaptive models, we show that these approaches can be represented in a
unified framework and can be generalized further. More specifically, we
introduce the use of scaling and bias codes as generalized means for
speaker-adaptive transformation. By utilizing these codes, we can create a more
efficient factorized speaker-adaptive model and capture advantages of both
approaches while reducing their disadvantages. The experiments show that the
proposed method can improve the performance of speaker adaptation compared with
speaker adaptation based on the conventional input code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11679</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11679</id><created>2018-07-31</created><authors><author><keyname>Zhao</keyname><forenames>Yi</forenames></author><author><keyname>Takaki</keyname><forenames>Shinji</forenames></author><author><keyname>Luong</keyname><forenames>Hieu-Thi</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Saito</keyname><forenames>Daisuke</forenames></author><author><keyname>Minematsu</keyname><forenames>Nobuaki</forenames></author></authors><title>Wasserstein GAN and Waveform Loss-based Acoustic Model Training for
  Multi-speaker Text-to-Speech Synthesis Systems Using a WaveNet Vocoder</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent neural networks such as WaveNet and sampleRNN that learn directly from
speech waveform samples have achieved very high-quality synthetic speech in
terms of both naturalness and speaker similarity even in multi-speaker
text-to-speech synthesis systems. Such neural networks are being used as an
alternative to vocoders and hence they are often called neural vocoders. The
neural vocoder uses acoustic features as local condition parameters, and these
parameters need to be accurately predicted by another acoustic model. However,
it is not yet clear how to train this acoustic model, which is problematic
because the final quality of synthetic speech is significantly affected by the
performance of the acoustic model. Significant degradation happens, especially
when predicted acoustic features have mismatched characteristics compared to
natural ones. In order to reduce the mismatched characteristics between natural
and generated acoustic features, we propose frameworks that incorporate either
a conditional generative adversarial network (GAN) or its variant, Wasserstein
GAN with gradient penalty (WGAN-GP), into multi-speaker speech synthesis that
uses the WaveNet vocoder. We also extend the GAN frameworks and use the
discretized mixture logistic loss of a well-trained WaveNet in addition to mean
squared error and adversarial losses as parts of objective functions.
Experimental results show that acoustic models trained using the WGAN-GP
framework using back-propagated discretized-mixture-of-logistics (DML) loss
achieves the highest subjective evaluation scores in terms of both quality and
speaker similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11722</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11722</id><created>2018-07-31</created><authors><author><keyname>Chakrabarty</keyname><forenames>Soumitro</forenames></author><author><keyname>Habets</keyname><forenames>Emanu&#xeb;l A. P.</forenames></author></authors><title>Multi-Speaker DOA Estimation Using Deep Convolutional Networks Trained
  with Noise Signals</title><categories>eess.AS cs.LG cs.SD</categories><doi>10.1109/JSTSP.2019.2901664</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised learning based methods for source localization, being data driven,
can be adapted to different acoustic conditions via training and have been
shown to be robust to adverse acoustic environments. In this paper, a
convolutional neural network (CNN) based supervised learning method for
estimating the direction-of-arrival (DOA) of multiple speakers is proposed.
Multi-speaker DOA estimation is formulated as a multi-class multi-label
classification problem, where the assignment of each DOA label to the input
feature is treated as a separate binary classification problem. The phase
component of the short-time Fourier transform (STFT) coefficients of the
received microphone signals are directly fed into the CNN, and the features for
DOA estimation are learnt during training. Utilizing the assumption of disjoint
speaker activity in the STFT domain, a novel method is proposed to train the
CNN with synthesized noise signals. Through experimental evaluation with both
simulated and measured acoustic impulse responses, the ability of the proposed
DOA estimation approach to adapt to unseen acoustic conditions and its
robustness to unseen noise type is demonstrated. Through additional empirical
investigation, it is also shown that with an array of M microphones our
proposed framework yields the best localization performance with M-1
convolution layers. The ability of the proposed method to accurately localize
speakers in a dynamic acoustic scenario with varying number of sources is also
shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11812</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11812</id><created>2018-07-31</created><updated>2019-06-01</updated><authors><author><keyname>Tahir</keyname><forenames>Waleed</forenames></author><author><keyname>Kamilov</keyname><forenames>Ulugbek S.</forenames></author><author><keyname>Tian</keyname><forenames>Lei</forenames></author></authors><title>Holographic particle localization under multiple scattering</title><categories>eess.SP physics.optics</categories><journal-ref>Advanced Photonics, 1(3), 036003 (2019)</journal-ref><doi>10.1117/1.AP.1.3.036003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel framework that incorporates multiple scattering for
large-scale 3D particle-localization using single-shot in-line holography.
Traditional holographic techniques rely on single-scattering models which
become inaccurate under high particle-density. We demonstrate that by
exploiting multiple-scattering, localization is significantly improved. Both
forward and back-scattering are computed by our method under a tractable
recursive framework, in which each recursion estimates the next higher-order
field within the volume. The inverse scattering is presented as a nonlinear
optimization that promotes sparsity, and can be implemented efficiently. We
experimentally reconstruct 100 million object voxels from a single 1-megapixel
hologram. Our work promises utilization of multiple scattering for versatile
large-scale applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11830</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11830</id><created>2018-07-31</created><authors><author><keyname>Simmross-Wattenberg</keyname><forenames>Federico</forenames></author><author><keyname>Rodr&#xed;guez-Cayetano</keyname><forenames>Manuel</forenames></author><author><keyname>Royuela-del-Val</keyname><forenames>Javier</forenames></author><author><keyname>Mart&#xed;n-Gonz&#xe1;lez</keyname><forenames>Elena</forenames></author><author><keyname>Moya-S&#xe1;ez</keyname><forenames>Elisa</forenames></author><author><keyname>Mart&#xed;n-Fern&#xe1;ndez</keyname><forenames>Marcos</forenames></author><author><keyname>Alberola-L&#xf3;pez</keyname><forenames>Carlos</forenames></author></authors><title>OpenCLIPER: an OpenCL-based C++ Framework for Overhead-Reduced Medical
  Image Processing and Reconstruction on Heterogeneous Devices</title><categories>cs.DC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical image processing is often limited by the computational cost of the
involved algorithms. Whereas dedicated computing devices (GPUs in particular)
exist and do provide significant efficiency boosts, they have an extra cost of
use in terms of housekeeping tasks (device selection and initialization, data
streaming, synchronization with the CPU and others), which may hinder
developers from using them. This paper describes an OpenCL-based framework that
is capable of handling dedicated computing devices seamlessly and that allows
the developer to concentrate on image processing tasks.
  The framework handles automatically device discovery and initialization, data
transfers to and from the device and the file system and kernel loading and
compiling. Data structures need to be defined only once independently of the
computing device; code is unique, consequently, for every device, including the
host CPU. Pinned memory/buffer mapping is used to achieve maximum performance
in data transfers.
  Code fragments included in the paper show how the computing device is almost
immediately and effortlessly available to the users algorithms, so they can
focus on productive work. Code required for device selection and
initialization, data loading and streaming and kernel compilation is minimal
and systematic. Algorithms can be thought of as mathematical operators (called
processes), with input, output and parameters, and they may be chained one
after another easily and efficiently. Also for efficiency, processes can have
their initialization work split from their core workload, so process chains and
loops do not incur in performance penalties. Algorithm code is independent of
the device type targeted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11861</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11861</id><created>2018-07-31</created><authors><author><keyname>Eiselt</keyname><forenames>Michael</forenames></author><author><keyname>Dochhan</keyname><forenames>Annika</forenames></author><author><keyname>Elbers</keyname><forenames>Joerg-Peter</forenames></author></authors><title>Data Center Interconnects at 400G and Beyond</title><categories>cs.NI eess.SP</categories><comments>This project has received funding from the European Union Horizon
  2020 research and innovation programme under grant agreement No 762055
  (BlueSpace project) and from the German ministry of education and research
  (BMBF) under contract 16KIS0477K (SENDATE Secure-DCI project)</comments><doi>10.1109/OECC.2018.8730011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current trends in Data Center Interconnectivity are considered in the light
of increasing traffic and under the constraint of limited cost and power
consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11878</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11878</id><created>2018-07-31</created><authors><author><keyname>Sim&#xf5;es</keyname><forenames>Ant&#xf3;nio</forenames></author><author><keyname>Xavier</keyname><forenames>Jo&#xe3;o</forenames></author></authors><title>FADE: Fast and Asymptotically efficient Distributed Estimator for
  dynamic networks</title><categories>cs.SY cs.DC eess.SP</categories><doi>10.1109/TSP.2019.2901355</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a set of agents that wish to estimate a vector of parameters of
their mutual interest. For this estimation goal, agents can sense and
communicate. When sensing, an agent measures (in additive gaussian noise)
linear combinations of the unknown vector of parameters. When communicating, an
agent can broadcast information to a few other agents, by using the channels
that happen to be randomly at its disposal at the time.
  To coordinate the agents towards their estimation goal, we propose a novel
algorithm called FADE (Fast and Asymptotically efficient Distributed
Estimator), in which agents collaborate at discrete time-steps; at each
time-step, agents sense and communicate just once, while also updating their
own estimate of the unknown vector of parameters.
  FADE enjoys five attractive features: first, it is an intuitive estimator,
simple to derive; second, it withstands dynamic networks, that is, networks
whose communication channels change randomly over time; third, it is strongly
consistent in that, as time-steps play out, each agent's local estimate
converges (almost surely) to the true vector of parameters; fourth, it is both
asymptotically unbiased and efficient, which means that, across time, each
agent's estimate becomes unbiased and the mean-square error (MSE) of each
agent's estimate vanishes to zero at the same rate of the MSE of the optimal
estimator at an almighty central node; fifth, and most importantly, when
compared with a state-of-art consensus+innovation (CI) algorithm, it yields
estimates with outstandingly lower mean-square errors, for the same number of
communications -- for example, in a sparsely connected network model with 50
agents, we find through numerical simulations that the reduction can be
dramatic, reaching several orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11893</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11893</id><created>2018-07-31</created><authors><author><keyname>Fong</keyname><forenames>Judy Y.</forenames></author><author><keyname>Borsky</keyname><forenames>Michal</forenames></author><author><keyname>Helgad&#xf3;ttir</keyname><forenames>Inga R.</forenames></author><author><keyname>Gudnason</keyname><forenames>Jon</forenames></author></authors><title>Manual Post-editing of Automatically Transcribed Speeches from the
  Icelandic Parliament - Althingi</title><categories>eess.AS cs.SD</categories><comments>submitted to IEEE SLT 2018, Athens</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design objectives for an automatic transcription system are to produce
text readable by humans and to minimize the impact on manual post-editing. This
study reports on a recognition system used for transcribing speeches in the
Icelandic parliament - Althingi. It evaluates the system performance and its
effect on manual post-editing. The results are compared against the original
manual transcription process. 239 total speeches, consisting of 11 hours and 33
minutes, were processed, both manually and automatically, and the editing
process was analysed. The dependence of word edit distance on edit time and the
editing real-time factor has been estimated and compared to user evaluations of
the transcription system. The main findings show that the word edit distance is
positively correlated with edit time and a system achieving a 12.6% edit
distance would match the performance of manual transcribers. Producing perfect
transcriptions would result in a real-time factor of 2.56. The study also shows
that 99% of low error rate speeches received a medium or good grade in
subjective evaluations. On the contrary, 21% of high error rate speeches
received a bad grade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11913</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11913</id><created>2018-07-28</created><authors><author><keyname>Wei</keyname><forenames>Xinran</forenames></author><author><keyname>Xie</keyname><forenames>Jiyang</forenames></author><author><keyname>He</keyname><forenames>Wenrui</forenames></author><author><keyname>Min</keyname><forenames>Min</forenames></author><author><keyname>Ma</keyname><forenames>Zhanyu</forenames></author><author><keyname>Guo</keyname><forenames>Jun</forenames></author></authors><title>Quantitative Comparisons of Linked Color Imaging and White-Light
  Colonoscopy for Colorectal Polyp Analysis</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of imaging techniques has an important influence on the
clinical diagnostic strategy of colorectal cancer. Linked color imaging (LCI)
by laser endoscopy is a recently developed techniques, and its advantage in
improving the analysis accuracy of colorectal polyps over white-light (WL)
endoscopy has been demonstrated in previous clinical studies. However, there
are no objective criteria to evaluate and compare the aforementioned endoscopy
methods. This paper presents a new criterion, namely entropy of color gradients
image (ECGI), which is based on color gradients distribution and provides a
comprehensive and objective evaluating indicator of the performance of
colorectal images. Our method extracts the color gradient image pairs of 143
colonoscopy polyps in the LCI-PairedColon database, which are generated with WL
and LCI conditions, respectively. Then, we apply the morphological method to
fix the deviation of light-reflecting regions, and the ECGI scores of sample
pairs are calculated. Experimental results show that the average ECGI scores of
LCI images (5.7071) were significantly higher than that of WL (4.6093). This
observation is consistent with the clinical studies. Therefore, the
effectiveness of the proposed criterion is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.11921</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1807.11921</id><created>2018-07-31</created><authors><author><keyname>Bas</keyname><forenames>C. Umit</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Sangodoyin</keyname><forenames>Seun</forenames></author><author><keyname>Psychoudakis</keyname><forenames>Dimitris</forenames></author><author><keyname>Henige</keyname><forenames>Thomas</forenames></author><author><keyname>Monroe</keyname><forenames>Robert</forenames></author><author><keyname>Park</keyname><forenames>Jeongho</forenames></author><author><keyname>Zhang</keyname><forenames>Jianzhong</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Real-Time Millimeter-Wave MIMO Channel Sounder for Dynamic Directional
  Measurements</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel real-time multiple-input-multiple-output
(MIMO) channel sounder for the 28 GHz band. Until now, most investigations of
the directional characteristics of millimeter-wave channels have used
mechanically rotating horn antennas. In contrast, the sounder presented here is
capable of performing horizontal and vertical beam steering with the help of
phased arrays. Due to its fast beam-switching capability, the proposed sounder
can perform measurements that are directionally resolved both at the
transmitter(TX) and receiver (RX) in 1.44 milliseconds compared to the minutes
or even hours required for rotating horn antenna sounders. This not only
enables measurement of more TX-RX locations for a better statistical validity
but also allows to perform directional analysis in dynamic environments. The
short measurement time combined with the high phase stability limits the phase
drift between TX and RX, enabling phase-coherent sounding of all beam pairs
even when TX and RX have no cabled connection for synchronization without any
delay ambiguity. Furthermore, the phase stability over time enables complex RX
waveform averaging to improve the signal to noise ratio during high path loss
measurements. The paper discusses both the system design as well as the
measurements performed for verification of the sounder performance.
Furthermore, we present sample results from double directional measurements in
dynamic environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00046</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00046</id><created>2018-07-31</created><authors><author><keyname>Adeel</keyname><forenames>Ahsan</forenames></author><author><keyname>Gogate</keyname><forenames>Mandar</forenames></author><author><keyname>Hussain</keyname><forenames>Amir</forenames></author><author><keyname>Whitmer</keyname><forenames>William M.</forenames></author></authors><title>Lip-Reading Driven Deep Learning Approach for Speech Enhancement</title><categories>cs.CV cs.LG cs.SD eess.AS</categories><comments>11 pages, 13 figures</comments><acm-class>I.4; I.5; I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel lip-reading driven deep learning framework for
speech enhancement. The proposed approach leverages the complementary strengths
of both deep learning and analytical acoustic modelling (filtering based
approach) as compared to recently published, comparatively simpler benchmark
approaches that rely only on deep learning. The proposed audio-visual (AV)
speech enhancement framework operates at two levels. In the first level, a
novel deep learning-based lip-reading regression model is employed. In the
second level, lip-reading approximated clean-audio features are exploited,
using an enhanced, visually-derived Wiener filter (EVWF), for the clean audio
power spectrum estimation. Specifically, a stacked long-short-term memory
(LSTM) based lip-reading regression model is designed for clean audio features
estimation using only temporal visual features considering different number of
prior visual frames. For clean speech spectrum estimation, a new
filterbank-domain EVWF is formulated, which exploits estimated speech features.
The proposed EVWF is compared with conventional Spectral Subtraction and
Log-Minimum Mean-Square Error methods using both ideal AV mapping and LSTM
driven AV mapping. The potential of the proposed speech enhancement framework
is evaluated under different dynamic real-world commercially-motivated
scenarios (e.g. cafe, public transport, pedestrian area) at different SNR
levels (ranging from low to high SNRs) using benchmark Grid and ChiME3 corpora.
For objective testing, perceptual evaluation of speech quality is used to
evaluate the quality of restored speech. For subjective testing, the standard
mean-opinion-score method is used with inferential statistics. Comparative
simulation results demonstrate significant lip-reading and speech enhancement
improvement in terms of both speech quality and speech intelligibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00058</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00058</id><created>2018-07-31</created><authors><author><keyname>Peng</keyname><forenames>Han</forenames></author><author><keyname>Razi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author><author><keyname>Ashdown</keyname><forenames>Jonathan</forenames></author></authors><title>A Unified Framework for Joint Mobility Prediction and Object Profiling
  of Drones in UAV Networks</title><categories>cs.NI cs.LG cs.SY eess.SP</categories><comments>8 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, using a network of autonomous and cooperative unmanned
aerial vehicles (UAVs) without command and communication from the ground
station has become more imperative, in particular in search-and-rescue
operations, disaster management, and other applications where human
intervention is limited. In such scenarios, UAVs can make more efficient
decisions if they acquire more information about the mobility, sensing and
actuation capabilities of their neighbor nodes. In this paper, we develop an
unsupervised online learning algorithm for joint mobility prediction and object
profiling of UAVs to facilitate control and communication protocols. The
proposed method not only predicts the future locations of the surrounding
flying objects, but also classifies them into different groups with similar
levels of maneuverability (e.g. rotatory, and fixed-wing UAVs) without prior
knowledge about these classes. This method is flexible in admitting new object
types with unknown mobility profiles, thereby applicable to emerging flying
Ad-hoc networks with heterogeneous nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00060</identifier>
 <datestamp>2018-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00060</id><created>2018-07-31</created><authors><author><keyname>Gogate</keyname><forenames>Mandar</forenames></author><author><keyname>Adeel</keyname><forenames>Ahsan</forenames></author><author><keyname>Marxer</keyname><forenames>Ricard</forenames></author><author><keyname>Barker</keyname><forenames>Jon</forenames></author><author><keyname>Hussain</keyname><forenames>Amir</forenames></author></authors><title>DNN driven Speaker Independent Audio-Visual Mask Estimation for Speech
  Separation</title><categories>cs.SD cs.CV cs.LG eess.AS</categories><comments>Accepted for Interspeech 2018, 5 pages, 4 figures</comments><acm-class>I.5; I.4; I.2</acm-class><doi>10.21437/Interspeech.2018-2516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human auditory cortex excels at selectively suppressing background noise to
focus on a target speaker. The process of selective attention in the brain is
known to contextually exploit the available audio and visual cues to better
focus on target speaker while filtering out other noises. In this study, we
propose a novel deep neural network (DNN) based audiovisual (AV) mask
estimation model. The proposed AV mask estimation model contextually integrates
the temporal dynamics of both audio and noise-immune visual features for
improved mask estimation and speech separation. For optimal AV features
extraction and ideal binary mask (IBM) estimation, a hybrid DNN architecture is
exploited to leverages the complementary strengths of a stacked long short term
memory (LSTM) and convolution LSTM network. The comparative simulation results
in terms of speech quality and intelligibility demonstrate significant
performance improvement of our proposed AV mask estimation model as compared to
audio-only and visual-only mask estimation approaches for both speaker
dependent and independent scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00082</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00082</id><created>2018-07-31</created><authors><author><keyname>Corey</keyname><forenames>Ryan M.</forenames></author><author><keyname>Tsuda</keyname><forenames>Naoki</forenames></author><author><keyname>Singer</keyname><forenames>Andrew C.</forenames></author></authors><title>Delay-Performance Tradeoffs in Causal Microphone Array Processing</title><categories>eess.AS cs.SD</categories><comments>To appear at the International Workshop on Acoustic Signal
  Enhancement (IWAENC 2018)</comments><journal-ref>2018 16th International Workshop on Acoustic Signal Enhancement
  (IWAENC)</journal-ref><doi>10.1109/IWAENC.2018.8521263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In real-time listening enhancement applications, such as hearing aid signal
processing, sounds must be processed with no more than a few milliseconds of
delay to sound natural to the listener. Listening devices can achieve better
performance with lower delay by using microphone arrays to filter acoustic
signals in both space and time. Here, we analyze the tradeoff between delay and
squared-error performance of causal multichannel Wiener filters for microphone
array noise reduction. We compute exact expressions for the delay-error curves
in two special cases and present experimental results from real-world
microphone array recordings. We find that delay-performance characteristics are
determined by both the spatial and temporal correlation structures of the
signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00095</identifier>
 <datestamp>2018-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00095</id><created>2018-07-31</created><updated>2018-09-11</updated><authors><author><keyname>Wang</keyname><forenames>Yubo</forenames></author><author><keyname>Song</keyname><forenames>Zhen</forenames></author><author><keyname>De Angelis</keyname><forenames>Valerio</forenames></author><author><keyname>Srivastava</keyname><forenames>Sanjeev</forenames></author></authors><title>Battery Life-Cycle Optimization and Runtime Control for Commercial
  Buildings Demand Side Management: A New York City Case Study</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In metropolitan areas populated with commercial buildings, electric power
supply is stringent especially during business hours. Demand side management
using battery is a promising solution to mitigate peak demands, however long
payback time creates barriers for large scale adoption. In this paper, we have
developed a design phase battery life-cycle cost assessment tool and a runtime
controller for the building owners, taking into account the degradation of
battery. In the design phase, perfect knowledge on building load profile is
assumed to estimate ideal payback time. In runtime, stochastic programming and
load predictions are applied to address the uncertainties in loads for
producing optimal battery operation. For validation, we have performed
numerical experiments using the real-life tariff model serves New York City,
Zn/MnO2 battery, and state-of-the-art building simulation tool. Experimental
results shows a small gap between design phase assessment and runtime control.
To further examine the proposed methods, we have applied the same tariff model
and performed numerical experiments on nine weather zones and three types of
commercial buildings. On contrary to the common practice of shallow discharging
battery for preventing phenomenal degradation, experimental results show
promising payback time achieved by optimally deep discharge a battery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00096</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00096</id><created>2018-07-31</created><authors><author><keyname>Corey</keyname><forenames>Ryan M.</forenames></author><author><keyname>Singer</keyname><forenames>Andrew C.</forenames></author></authors><title>Speech Separation Using Partially Asynchronous Microphone Arrays Without
  Resampling</title><categories>eess.AS cs.SD</categories><comments>To appear at the International Workshop on Acoustic Signal
  Enhancement (IWAENC 2018)</comments><journal-ref>2018 16th International Workshop on Acoustic Signal Enhancement
  (IWAENC)</journal-ref><doi>10.1109/IWAENC.2018.8521260</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of separating speech sources captured by multiple
spatially separated devices, each of which has multiple microphones and samples
its signals at a slightly different rate. Most asynchronous array processing
methods rely on sample rate offset estimation and resampling, but these offsets
can be difficult to estimate if the sources or microphones are moving. We
propose a source separation method that does not require offset estimation or
signal resampling. Instead, we divide the distributed array into several
synchronous subarrays. All arrays are used jointly to estimate the time-varying
signal statistics, and those statistics are used to design separate
time-varying spatial filters in each array. We demonstrate the method for
speech mixtures recorded on both stationary and moving microphone arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00147</identifier>
 <datestamp>2018-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00147</id><created>2018-07-31</created><updated>2018-10-17</updated><authors><author><keyname>Mohammed</keyname><forenames>Mohammed M. A.</forenames></author><author><keyname>He</keyname><forenames>Cuiwei</forenames></author><author><keyname>Armstrong</keyname><forenames>Jean</forenames></author></authors><title>Mitigation of Side-Effect Modulation in Optical OFDM VLC Systems</title><categories>eess.SP</categories><journal-ref>in IEEE Access, vol. 6, pp. 58161-58170, 2018</journal-ref><doi>10.1109/ACCESS.2018.2874269</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Side-effect modulation (SEM) has the potential to be a significant source of
interference in future visible light communication (VLC) systems. SEM is a
variation in the intensity of the light emitted by a luminaire and is usually a
side-effect caused by the power supply used to drive the luminaires. For LED
luminaires powered by a switched mode power supply, the SEM can be at much
higher frequencies than that emitted by conventional incandescent or
fluorescent lighting. It has been shown that the SEM caused by commercially
available LED luminaires is often periodic and of low power. In this paper, we
investigate the impact of typical forms of SEM on the performance of optical
OFDM VLC systems; both ACO-OFDM and DCO-OFDM are considered. Our results show
that even low levels of SEM power can significantly degrade the bit-error-rate
performance. To solve this problem, an SEM mitigation scheme is described. The
mitigation scheme is decision-directed and is based on estimating and
subtracting the fundamental component of the SEM from the received signal. We
describe two forms of the algorithm; one uses blind estimation while the other
uses pilot-assisted estimation based on a training sequence. Decision errors,
resulting in decision noise, limit the performance of the blind estimator even
when estimation is based on very long signals. However, the pilot system can
achieve more accurate estimations, thus better performance. Results are first
presented for typical SEM waveforms for the case where the fundamental
frequency of the SEM is known. The algorithms are then extended to include a
frequency estimation step and the mitigation algorithm is shown also to be
effective in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00158</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00158</id><created>2018-07-29</created><updated>2019-08-09</updated><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Speaker Recognition from Raw Waveform with SincNet</title><categories>eess.AS cs.LG cs.SD eess.SP</categories><comments>In Proceedings of SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is progressively gaining popularity as a viable alternative to
i-vectors for speaker recognition. Promising results have been recently
obtained with Convolutional Neural Networks (CNNs) when fed by raw speech
samples directly. Rather than employing standard hand-crafted features, the
latter CNNs learn low-level speech representations from waveforms, potentially
allowing the network to better capture important narrow-band speaker
characteristics such as pitch and formants. Proper design of the neural network
is crucial to achieve this goal. This paper proposes a novel CNN architecture,
called SincNet, that encourages the first convolutional layer to discover more
meaningful filters. SincNet is based on parametrized sinc functions, which
implement band-pass filters. In contrast to standard CNNs, that learn all
elements of each filter, only low and high cutoff frequencies are directly
learned from data with the proposed method. This offers a very compact and
efficient way to derive a customized filter bank specifically tuned for the
desired application. Our experiments, conducted on both speaker identification
and speaker verification tasks, show that the proposed architecture converges
faster and performs better than a standard CNN on raw waveforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00164</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00164</id><created>2018-08-01</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Lin</keyname><forenames>Zihuai</forenames></author></authors><title>Rate Adaptive Coded Digital Phase Modulation</title><categories>eess.SP</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, rate adaptive coded Digital Phase Modulation (DPM) schemes
based on punctured ring convolutional codes are presented. We first present an
upper bound on symbol error probability for punctured convolutional coded
Continuous Phase Modulation (CPM) over rings with Maximum Likelihood Sequence
Detection (MLSD). The bound is based on the transfer function technique, which
is modified and generalized to punctured convolutional codes over rings. The
novelty of this paper is the development of the analytical upper bound on the
symbol error probability for the investigated system. This work provides a
systematic way to analyze and design the rate adaptive ring convolutional coded
CPM systems. The analysis method is very general. It may be applied to any
trellis based coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00166</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00166</id><created>2018-08-01</created><authors><author><keyname>Bharadwaj</keyname><forenames>Pawan</forenames></author><author><keyname>Demanet</keyname><forenames>Laurent</forenames></author><author><keyname>Fournier</keyname><forenames>Aim&#xe9;</forenames></author></authors><title>Focused blind deconvolution</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2908911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel multichannel blind deconvolution (BD) method that
extracts sparse and front-loaded impulse responses from the channel outputs,
i.e., their convolutions with a single arbitrary source. A crucial feature of
this formulation is that it doesn't encode support restrictions on the
unknowns, unlike most prior work on BD. The indeterminacy inherent to BD, which
is difficult to resolve with a traditional L1 penalty on the impulse responses,
is resolved in our method because it seeks a first approximation where the
impulse responses are: &quot;maximally white&quot; -- encoded as the energy focusing near
zero lag of the impulse-response auto-correlations; and &quot;maximally
front-loaded&quot; -- encoded as the energy focusing near zero time of the impulse
responses. Hence we call the method focused blind deconvolution (FBD). The
focusing constraints are relaxed as the iterations progress. Note that FBD
requires the duration of the channel outputs to be longer than that of the
unknown impulse responses.
  A multichannel blind deconvolution problem that is appropriately formulated
by sparse and front-loaded impulse responses arises in seismic inversion, where
the impulse responses are the Green's function evaluations at different
receiver locations, and the operation of a drill bit inputs the noisy and
correlated source signature into the subsurface. We demonstrate the benefits of
FBD using seismic-while-drilling numerical experiments, where the noisy data
recorded at the receivers are hard to interpret, but FBD can provide the
processing essential to separate the drill-bit (source) signature from the
interpretable Green's function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00201</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00201</id><created>2018-08-01</created><authors><author><keyname>Eiselt</keyname><forenames>Michael</forenames></author><author><keyname>Dochhan</keyname><forenames>Annika</forenames></author></authors><title>Single-Ended Fiber Latency Measurement with Picosecond-Accuracy Using
  Correlation OTDR</title><categories>eess.SP</categories><comments>This project has received funding from the European Union Horizon
  2020 research and innovation programme under grant agreement No 762055</comments><doi>10.1109/OECC.2018.8729866</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correlation OTDR with a bit rate of 10 Gbit/s is used to measure fiber
latency with an accuracy of a few picoseconds. The concept is demonstrated
measuring the chromatic dispersion of a 2.2-km fiber section.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00263</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00263</id><created>2018-08-01</created><authors><author><keyname>Papadopoulos</keyname><forenames>Athanasios</forenames></author><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Georgiadis</keyname><forenames>Leonidas</forenames></author></authors><title>Network Coding Techniques in Cooperative Cognitive Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate transmission techniques for a fundamental
cooperative cognitive radio network, i.e., a radio system where a Secondary
user may act as relay for messages sent by the Primary user, hence offering
performance improvement of Primary user transmissions, while at the same time
obtaining more transmission opportunities for its own transmissions.
Specifically, we examine the possibility of improving the overall system
performance by employing network coding techniques. The objective is to achieve
this while affecting Primary user transmissions only positively, namely: 1)
avoid network coding operations at the Primary transmitter in order avoid
increase of its complexity and storage requirements, 2) keep the order of
packets received by the Primary receiver the same as in the non cooperative
case and 3) induce packet service times that are stochastically smaller than
packet service times induced in the non-cooperative case. A network coding
algorithm is investigated in terms of achieved throughput region and it is
shown to enlarge Secondary user throughput as compared to the case where the
Secondary transmitter acts as a simple relay, while leaving the Primary user
stability region unaffected. A notable feature of this algorithm is that it
operates without knowledge of channel and packet arrival rate statistics. We
also investigate a second network coding algorithm which increases the
throughput region of the system; however, the latter algorithm requires
knowledge of channel and packet arrival rate statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00297</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00297</id><created>2018-08-01</created><authors><author><keyname>Singh</keyname><forenames>Gurkirt</forenames></author><author><keyname>Saha</keyname><forenames>Suman</forenames></author><author><keyname>Cuzzolin</keyname><forenames>Fabio</forenames></author></authors><title>TraMNet - Transition Matrix Network for Efficient Action Tube Proposals</title><categories>eess.IV cs.CV cs.RO</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current state-of-the-art methods solve spatiotemporal action localisation by
extending 2D anchors to 3D-cuboid proposals on stacks of frames, to generate
sets of temporally connected bounding boxes called \textit{action micro-tubes}.
However, they fail to consider that the underlying anchor proposal hypotheses
should also move (transition) from frame to frame, as the actor or the camera
does. Assuming we evaluate $n$ 2D anchors in each frame, then the number of
possible transitions from each 2D anchor to the next, for a sequence of $f$
consecutive frames, is in the order of $O(n^f)$, expensive even for small
values of $f$. To avoid this problem, we introduce a Transition-Matrix-based
Network (TraMNet) which relies on computing transition probabilities between
anchor proposals while maximising their overlap with ground truth bounding
boxes across frames, and enforcing sparsity via a transition threshold. As the
resulting transition matrix is sparse and stochastic, this reduces the proposal
hypothesis search space from $O(n^f)$ to the cardinality of the thresholded
matrix. At training time, transitions are specific to cell locations of the
feature maps, so that a sparse (efficient) transition matrix is used to train
the network. At test time, a denser transition matrix can be obtained either by
decreasing the threshold or by adding to it all the relative transitions
originating from any cell location, allowing the network to handle transitions
in the test data that might not have been present in the training data, and
making detection translation-invariant. Finally, we show that our network can
handle sparse annotations such as those available in the DALY dataset. We
report extensive experiments on the DALY, UCF101-24 and Transformed-UCF101-24
datasets to support our claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00298</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00298</id><created>2018-08-01</created><authors><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Gacanin</keyname><forenames>Haris</forenames></author><author><keyname>Nauryzbayev</keyname><forenames>Galymzhan</forenames></author><author><keyname>Ikpehai</keyname><forenames>Augustine</forenames></author></authors><title>Performance Evaluation of Multi-hop Relaying over Non-Gaussian PLC
  Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relaying over power line communication (PLC) channels can considerably
enhance the performance and reliability of PLC systems. This paper is dedicated
to study and analyze the energy efficiency of multi-hop cooperative relaying
PLC systems. Incremental decode-and-forward (IDF) relying is exploited to
reduce the transmit power consumption. The PLC channel is assumed to experience
log-normal fading with impulsive noise. The performances of single-hop and
conventional DF relaying systems are also analyzed in terms of outage
probability and energy efficiency for which analytical expressions are derived.
Results show that using more relays can improve the outage probability
performance; however, this is achieved at the expense of increased power
consumption due to the increased static power of the relays, especially when
the total source-to-destination distance is relatively small. Results also
demonstrate that the IDF PLC system has better energy efficiency performance
compared to the other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00366</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00366</id><created>2018-08-01</created><authors><author><keyname>Khomchuk</keyname><forenames>Petro</forenames></author><author><keyname>Stainvas</keyname><forenames>Inna</forenames></author><author><keyname>Bilik</keyname><forenames>Igal</forenames></author></authors><title>Pedestrian Motion Direction Estimation Using Simulated Automotive MIMO
  Radar</title><categories>eess.SP cs.IT math.IT</categories><journal-ref>P. Khomchuk, I. Stainvas, I. Bilik, &quot;Pedestrian motion direction
  estimation using automotive MIMO radar&quot;, IEEE Transactions on Aerospace and
  Electronic Systems, 52.3 (2016): 1132-1145</journal-ref><doi>10.1109/TAES.2016.140682</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Micro-Doppler-based target classification capabilities of the automotive
radars can provide high reliability and short latency to the future active
safety automotive features. A large number of pedestrians surrounding vehicle
in practical urban scenarios mandate prioritization of their treat level.
Classification between relevant pedestrians that cross the street or are within
the vehicle path and those that are on the sidewalks and move along the vehicle
rout can significantly minimize a number of vehicle-to-pedestrian accidents.
  This work proposes a novel technique for a pedestrian direction of motion
estimation which treats pedestrians as complex distributed targets and utilizes
their micro-Doppler (MD) radar signatures. The MD signatures are shown to be
indicative of pedestrian direction of motion, and the supervised regression is
used to estimate the mapping between the directions of motion and the
corresponding MD signatures. In order to achieve higher regression performance,
the state of the art sparse dictionary learning based feature extraction
algorithm was adopted from the field of computer vision by drawing a parallel
between the Doppler effect and the video temporal gradient.
  The performance of the proposed approach is evaluated in a practical
automotive scenario simulations, where a walking pedestrian is observed by a
multiple-input-multiple-output (MIMO) automotive radar with a 2D rectangular
array. The simulated data was generated using the statistical Boulic-Thalman
human locomotion model. Accurate direction of motion estimation was achieved by
using a support vector regression (SVR) and a multilayer perceptron (MLP) based
regression algorithms. The results show that the direction estimation error is
less than $10^{\circ}$ in $95\%$ of the tested cases, for pedestrian at the
range of $100$m from the radar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00458</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00458</id><created>2018-08-01</created><updated>2019-05-21</updated><authors><author><keyname>Pai</keyname><forenames>Sunil</forenames></author><author><keyname>Bartlett</keyname><forenames>Ben</forenames></author><author><keyname>Solgaard</keyname><forenames>Olav</forenames></author><author><keyname>Miller</keyname><forenames>David A. B.</forenames></author></authors><title>Matrix optimization on universal unitary photonic devices</title><categories>eess.SP cs.ET cs.NE physics.optics</categories><comments>18 pages, 2 tables, 14 figures, 6 videos (videos provided in Appendix
  via external URL link)</comments><journal-ref>Phys. Rev. Applied 11, 064044 (2019)</journal-ref><doi>10.1103/PhysRevApplied.11.064044</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universal unitary photonic devices can apply arbitrary unitary
transformations to a vector of input modes and provide a promising hardware
platform for fast and energy-efficient machine learning using light. We
simulate the gradient-based optimization of random unitary matrices on
universal photonic devices composed of imperfect tunable interferometers. If
device components are initialized uniform-randomly, the locally-interacting
nature of the mesh components biases the optimization search space towards
banded unitary matrices, limiting convergence to random unitary matrices. We
detail a procedure for initializing the device by sampling from the
distribution of random unitary matrices and show that this greatly improves
convergence speed. We also explore mesh architecture improvements such as
adding extra tunable beamsplitters or permuting waveguide layers to further
improve the training speed and scalability of these devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00490</identifier>
 <datestamp>2019-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00490</id><created>2018-08-01</created><updated>2019-04-08</updated><authors><author><keyname>Nasir</keyname><forenames>Yasar Sinan</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Multi-Agent Deep Reinforcement Learning for Dynamic Power Allocation in
  Wireless Networks</title><categories>eess.SP cs.IT math.IT stat.ML</categories><comments>12 pages, 7 figures, submitted. v2: the updated title, in addition to
  improved readability. v3: revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work demonstrates the potential of deep reinforcement learning
techniques for transmit power control in wireless networks. Existing techniques
typically find near-optimal power allocations by solving a challenging
optimization problem. Most of these algorithms are not scalable to large
networks in real-world scenarios because of their computational complexity and
instantaneous cross-cell channel state information (CSI) requirement. In this
paper, a distributively executed dynamic power allocation scheme is developed
based on model-free deep reinforcement learning. Each transmitter collects CSI
and quality of service (QoS) information from several neighbors and adapts its
own transmit power accordingly. The objective is to maximize a weighted
sum-rate utility function, which can be particularized to achieve maximum
sum-rate or proportionally fair scheduling. Both random variations and delays
in the CSI are inherently addressed using deep Q-learning. For a typical
network architecture, the proposed algorithm is shown to achieve near-optimal
power allocation in real time based on delayed CSI measurements available to
the agents. The proposed scheme is especially suitable for practical scenarios
where the system model is inaccurate and CSI delay is non-negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00509</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00509</id><created>2018-08-01</created><authors><author><keyname>Mahjoub</keyname><forenames>Hossein Nourkhiz</forenames></author><author><keyname>Tahmasbi-Sarvestani</keyname><forenames>Amin</forenames></author><author><keyname>Gani</keyname><forenames>S M Osman</forenames></author><author><keyname>Fallah</keyname><forenames>Yaser P.</forenames></author></authors><title>Composite {\alpha}-{\mu} Based DSRC Channel Model Using Large Data Set
  of RSSI Measurements</title><categories>eess.SP</categories><journal-ref>H. Nourkhiz Mahjoub, A. Tahmasbi-Sarvestani, S. M. O. Gani and Y.
  P. Fallah, &quot;Composite {\alpha}-{\mu} Based DSRC Channel Model Using Large
  Data Set of RSSI Measurements,&quot; in IEEE Transactions on Intelligent
  Transportation Systems. 2018</journal-ref><doi>10.1109/TITS.2018.2803628</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel modeling is essential for design and performance evaluation of
numerous protocols in vehicular networks. In this work, we study and provide
results for largescale and small-scale modeling of communication channel in
dense vehicular networks. We first propose an approach to remove the effect of
fading on deterministic part of the large-scale model and verify its accuracy
using a single transmitter-receiver scenario. Two-ray model is then utilized
for path-loss characterization and its parameters are derived from the
empirical data based on a newly proposed method. Afterward, we use
{\alpha}-{\mu} distribution to model the fading behavior of vehicular networks
for the first time, and validate its precision by Kolmogorov-Smirnov (K-S)
goodness-of-fit test. To this end, the significantly better performance of
utilizing {\alpha}-{\mu} distribution over the most adopted fading distribution
in the vehicular channels literature, i.e. Nakagami-m, in terms of passing K-S
test has been investigated and statistically verified in this paper. A large
received signal strength indicator (RSSI) dataset from a measurement campaign
is used to evaluate our claims. Moreover, the whole model is implemented in a
reliable discrete event network simulator which is widely used in the academic
and industrial research for network analysis, i.e. network simulator-3 (ns-3),
to show the outcome of the proposed model in the presence of upper layer
network protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00533</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00533</id><created>2018-07-30</created><authors><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Sillekens</keyname><forenames>Eric</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>The ISRS GN Model, an Efficient Tool in Modeling Ultra-Wideband
  Transmission in Point-to-Point and Network Scenarios</title><categories>eess.SP</categories><doi>10.1109/ECOC.2018.8535146</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An analytical model to estimate nonlinear performance in ultra-wideband
optical transmission networks is presented. The model accurately accounts for
inter-channel stimulated Raman scattering, variably loaded fibre spans and is
validated through C+L band simulations for uniform and probabilistically shaped
64-QAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00606</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00606</id><created>2018-08-01</created><updated>2018-08-23</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Sourish</forenames></author><author><keyname>Roth</keyname><forenames>Joseph</forenames></author><author><keyname>Ellis</keyname><forenames>Daniel P. W.</forenames></author><author><keyname>Gallagher</keyname><forenames>Andrew</forenames></author><author><keyname>Kaver</keyname><forenames>Liat</forenames></author><author><keyname>Marvin</keyname><forenames>Radhika</forenames></author><author><keyname>Pantofaru</keyname><forenames>Caroline</forenames></author><author><keyname>Reale</keyname><forenames>Nathan</forenames></author><author><keyname>Reid</keyname><forenames>Loretta Guarino</forenames></author><author><keyname>Wilson</keyname><forenames>Kevin</forenames></author><author><keyname>Xi</keyname><forenames>Zhonghua</forenames></author></authors><title>AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies</title><categories>cs.SD eess.AS</categories><comments>Interspeech, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech activity detection (or endpointing) is an important processing step
for applications such as speech recognition, language identification and
speaker diarization. Both audio- and vision-based approaches have been used for
this task in various settings, often tailored toward end applications. However,
much of the prior work reports results in synthetic settings, on task-specific
datasets, or on datasets that are not openly available. This makes it difficult
to compare approaches and understand their strengths and weaknesses. In this
paper, we describe a new dataset which we will release publicly containing
densely labeled speech activity in YouTube videos, with the goal of creating a
shared, available dataset for this task. The labels in the dataset annotate
three different speech activity conditions: clean speech, speech co-occurring
with music, and speech co-occurring with noise, which enable analysis of model
performance in more challenging conditions based on the presence of overlapping
noise. We report benchmark performance numbers on AVA-Speech using
off-the-shelf, state-of-the-art audio and vision models that serve as a
baseline to facilitate future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00617</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00617</id><created>2018-08-01</created><updated>2019-03-18</updated><authors><author><keyname>Hosseini</keyname><forenames>Mahdi S.</forenames></author><author><keyname>Zhang</keyname><forenames>Yueyang</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author></authors><title>Encoding Visual Sensitivity by MaxPol Convolution Filters for Image
  Sharpness Assessment</title><categories>eess.IV</categories><comments>15 pages</comments><doi>10.1109/TIP.2019.2906582</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel design of Human Visual System (HVS)
response in a convolution filter form to decompose meaningful features that are
closely tied with image sharpness level. No-reference (NR) Image sharpness
assessment (ISA) techniques have emerged as the standard of image quality
assessment in diverse imaging applications. Despite their high correlation with
subjective scoring, they are challenging for practical considerations due to
high computational cost and lack of scalability across different image blurs.
We bridge this gap by synthesizing the HVS response as a linear combination of
Finite Impulse Response (FIR) derivative filters to boost the falloff of high
band frequency magnitudes in natural imaging paradigm. The numerical
implementation of the HVS filter is carried out with MaxPol filter library that
can be arbitrarily set for any differential orders and cutoff frequencies to
balance out the estimation of informative features and noise sensitivities. We
then design an innovative NR-ISA metric called `HVS-MaxPol' that (a) requires
minimal computational cost, (b) produce high correlation accuracy with image
blurriness, and (c) scales to assess synthetic and natural image blur.
Specifically, the synthetic blur images are constructed by blurring the raw
images using Gaussian filter, while natural blur is observed from real-life
application such as motion, out-of-focus, etc. Furthermore, we create a natural
benchmark database in digital pathology for validation of image focus quality
in whole slide imaging systems called `FocusPath' consisting of 864 blurred
images. Thorough experiments are designed to test and validate the efficiency
of HVS-MaxPol across different blur databases and state-of-the-art NR-ISA
metrics. The experiment result indicates that our metric has the best overall
performance with respect to speed, accuracy and scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00641</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00641</id><created>2018-08-01</created><authors><author><keyname>SrirangamSridharan</keyname><forenames>ShreeRanjani</forenames></author><author><keyname>Ulutan</keyname><forenames>Oytun</forenames></author><author><keyname>Priyo</keyname><forenames>Shehzad Noor Taus</forenames></author><author><keyname>Rallapalli</keyname><forenames>Swati</forenames></author><author><keyname>Srivatsa</keyname><forenames>Mudhakar</forenames></author></authors><title>Object Localization and Size Estimation from RGB-D Images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depth sensing cameras (e.g., Kinect sensor, Tango phone) can acquire color
and depth images that are registered to a common viewpoint. This opens the
possibility of developing algorithms that exploit the advantages of both
sensing modalities. Traditionally, cues from color images have been used for
object localization (e.g., YOLO). However, the addition of a depth image can be
further used to segment images that might otherwise have identical color
information. Further, the depth image can be used for object size
(height/width) estimation (in real-world measurements units, such as meters) as
opposed to image based segmentation that would only support drawing bounding
boxes around objects of interest. In this paper, we first collect color camera
information along with depth information using a custom Android application on
Tango Phab2 phone. Second, we perform timing and spatial alignment between the
two data sources. Finally, we evaluate several ways of measuring the height of
the object of interest within the captured images under a variety of settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00646</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00646</id><created>2018-08-01</created><authors><author><keyname>Xia</keyname><forenames>Guiyang</forenames></author><author><keyname>Jia</keyname><forenames>Linqiong</forenames></author><author><keyname>Qian</keyname><forenames>Yuwen</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhihong</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author></authors><title>Power Allocation Strategies for Secure Spatial Modulation</title><categories>eess.SP</categories><doi>10.1109/JSYST.2019.2918168</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In secure spatial modulation (SM) networks, power allocation (PA) strategies
are investigated in this paper under the total power constraint. Considering
that there is no closed-form expression for secrecy rate (SR), an approximate
closed-form expression of SR is presented, which is used as an efficient metric
to optimize PA factor and can greatly reduce the computation complexity. Based
on this expression, a convex optimization (CO) method of maximizing SR (Max-SR)
is proposed accordingly. Furthermore, a method of maximizing the product of
signal-to-leakage and noise ratio (SLNR) and artificial noise-to-leakage-and
noise ratio (ANLNR) (Max-P-SAN) is proposed to provide an analytic solution to
PA with extremely low-complexity. Simulation results demonstrate that the SR
performance of the proposed CO method is close to that of the optimal PA
strategy of Max-SR with exhaustive search and better than that of Max-P-SAN in
the high signal-to-noise ratio (SNR) region. However, in the low and medium SNR
regions, the SR performance of the proposed Max-P-SAN slightly exceeds that of
the proposed CO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00665</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00665</id><created>2018-08-02</created><authors><author><keyname>Luong</keyname><forenames>Hieu-Thi</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Nishizawa</keyname><forenames>Nobuyuki</forenames></author></authors><title>Investigating accuracy of pitch-accent annotations in neural
  network-based speech synthesis and denoising effects</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>Accepted for Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigated the impact of noisy linguistic features on the performance of
a Japanese speech synthesis system based on neural network that uses WaveNet
vocoder. We compared an ideal system that uses manually corrected linguistic
features including phoneme and prosodic information in training and test sets
against a few other systems that use corrupted linguistic features. Both
subjective and objective results demonstrate that corrupted linguistic
features, especially those in the test set, affected the ideal system's
performance significantly in a statistical sense due to a mismatched condition
between the training and test sets. Interestingly, while an utterance-level
Turing test showed that listeners had a difficult time differentiating
synthetic speech from natural speech, it further indicated that adding noise to
the linguistic features in the training set can partially reduce the effect of
the mismatch, regularize the model, and help the system perform better when
linguistic features of the test set are noisy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00667</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00667</id><created>2018-08-02</created><authors><author><keyname>Ahmed</keyname><forenames>K. I.</forenames></author><author><keyname>Tabassum</keyname><forenames>H.</forenames></author><author><keyname>Hossain</keyname><forenames>E.</forenames></author></authors><title>Deep Learning for Radio Resource Allocation in Multi-Cell Networks</title><categories>cs.NI cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increased complexity and heterogeneity of emerging 5G and beyond 5G (B5G)
wireless networks will require a paradigm shift from traditional resource
allocation mechanisms. Deep learning (DL) is a powerful tool where a
multi-layer neural network can be trained to model a resource management
algorithm using network data.Therefore, resource allocation decisions can be
obtained without intensive online computations which would be required
otherwise for the solution of resource allocation problems. In this context,
this article focuses on the application of DL to obtain solutions for the radio
resource allocation problems in multi-cell networks. Starting with a brief
overview of a deep neural network (DNN) as a DL model, relevant DNN
architectures and the data training procedure, we provide an overview of
existing state-of-the-art applying DL in the context of radio resource
allocation. A qualitative comparison is provided in terms of their objectives,
inputs/outputs, learning and data training methods. Then, we present a
supervised DL model to solve the sub-band and power allocation problem in a
multi-cell network. Using the data generated by a genetic algorithm, we first
train the model and then test the accuracy of the proposed model in predicting
the resource allocation solutions. Simulation results show that the trained DL
model is able to provide the desired optimal solution 86.3% of time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00724</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00724</id><created>2018-08-02</created><updated>2018-12-21</updated><authors><author><keyname>Castella</keyname><forenames>Marc</forenames></author><author><keyname>Pesquet</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Marmin</keyname><forenames>Arthur</forenames></author></authors><title>Rational Optimization for Nonlinear Reconstruction with Approximate
  $\ell_0$ Penalization</title><categories>eess.SP</categories><journal-ref>IEEE Transactions Signal Processing 2019</journal-ref><doi>10.1109/TSP.2018.2890065</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering nonlinearly degraded signal in the presence of noise is a
challenging problem. In this work, this problem is tackled by minimizing the
sum of a non convex least-squares fit criterion and a penalty term. We assume
that the nonlinearity of the model can be accounted for by a rational function.
In addition, we suppose that the signal to be sought is sparse and a rational
approximation of the $\ell_0$ pseudo-norm thus constitutes a suitable
penalization. The resulting composite cost function belongs to the broad class
of semi-algebraic functions. To find a globally optimal solution to such an
optimization problem, it can be transformed into a generalized moment problem,
for which a hierarchy of semidefinite programming relaxations can be built.
Global optimality comes at the expense of an increased dimension and, to
overcome computational limitations concerning the number of involved variables,
the structure of the problem has to be carefully addressed. A situation of
practical interest is when the nonlinear model consists of a convolutive
transform followed by a componentwise nonlinear rational saturation. We then
propose to use a sparse relaxation able to deal with up to several hundreds of
optimized variables. In contrast with the naive approach consisting of
linearizing the model, our experiments show that the proposed approach offers
good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00773</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00773</id><created>2018-08-02</created><updated>2018-09-29</updated><authors><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Iqbal</keyname><forenames>Turab</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>DCASE 2018 Challenge Surrey Cross-Task convolutional neural network
  baseline</title><categories>cs.SD eess.AS</categories><comments>Accepted by DCASE 2018 Workshop. 4 pages. Source code available</comments><journal-ref>Workshop on Detection and Classification of Acoustic Scenes and
  Events (DCASE), 2018, pp. 217-221</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Detection and Classification of Acoustic Scenes and Events (DCASE)
consists of five audio classification and sound event detection tasks: 1)
Acoustic scene classification, 2) General-purpose audio tagging of Freesound,
3) Bird audio detection, 4) Weakly-labeled semi-supervised sound event
detection and 5) Multi-channel audio classification. In this paper, we create a
cross-task baseline system for all five tasks based on a convlutional neural
network (CNN): a &quot;CNN Baseline&quot; system. We implemented CNNs with 4 layers and 8
layers originating from AlexNet and VGG from computer vision. We investigated
how the performance varies from task to task with the same configuration of
neural networks. Experiments show that deeper CNN with 8 layers performs better
than CNN with 4 layers on all tasks except Task 1. Using CNN with 8 layers, we
achieve an accuracy of 0.680 on Task 1, an accuracy of 0.895 and a mean average
precision (MAP) of 0.928 on Task 2, an accuracy of 0.751 and an area under the
curve (AUC) of 0.854 on Task 3, a sound event detection F1 score of 20.8% on
Task 4, and an F1 score of 87.75% on Task 5. We released the Python source code
of the baseline systems under the MIT license for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00794</identifier>
 <datestamp>2019-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00794</id><created>2018-08-02</created><updated>2019-04-17</updated><authors><author><keyname>Kapelko</keyname><forenames>Rafal</forenames></author></authors><title>Analysis of the Threshold for Energy Consumption in Displacement of
  Random Sensors</title><categories>cs.NI cs.DM cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider $n$ mobile sensors placed randomly in $m-$dimensional unit cube for
fixed $m\in\{1,2\}.$ The sensors have identical sensing range, say $r.$ We are
interested in moving the sensors from their initial random positions to new
locations so that every point in the unit cube is within the range of at least
one sensor, while at the same time each pair of sensors is placed at
interference distance greater or equal to $s.$ Suppose the displacement of the
$i-$th sensor is a distance $d_i$. As a \textit{energy consumption} for the
displacement of a set of $n$ sensors we consider the $a-$total displacement
defined as the sum $\sum_{i=1}^n d_i^a,$ for some constant $a&gt; 0.$
  The main contribution of this paper can be summarized as follows. For the
case of unit interval we \textit{explain a threshold} around the sensing radius
equal to $\frac{1}{2n}$ and the interference distance equal to $\frac{1}{n}$
for the expected minimum $a-$total displacement. For the sensors placed in the
unit square we \textit{explain a threshold} around the square sensing radius
equal to $\frac{1}{2 \sqrt{n}}$ and the interference distance equal to
$\frac{1}{\sqrt{n}}$ for the expected minimum $a-$total displacement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00814</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00814</id><created>2018-08-02</created><updated>2020-02-02</updated><authors><author><keyname>Ma</keyname><forenames>Zhanyu</forenames></author></authors><title>Classification of EEG Signal based on non-Gaussian Neutral Vector</title><categories>cs.LG eess.SP stat.ML</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the design of brain-computer interface systems, classification of
Electroencephalogram (EEG) signals is the essential part and a challenging
task. Recently, as the marginalized discrete wavelet transform (mDWT)
representations can reveal features related to the transient nature of the EEG
signals, the mDWT coefficients have been frequently used in EEG signal
classification. In our previous work, we have proposed a super-Dirichlet
distribution-based classifier, which utilized the nonnegative and sum-to-one
properties of the mDWT coefficients. The proposed classifier performed better
than the state-of-the-art support vector machine-based classifier. In this
paper, we further study the neutrality of the mDWT coefficients. Assuming the
mDWT vector coefficients to be a neutral vector, we transform them non-linearly
into a set of independent scalar coefficients. Feature selection strategy is
proposed on the transformed feature domain. Experimental results show that the
feature selection strategy helps improving the classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00818</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00818</id><created>2018-08-02</created><updated>2020-02-02</updated><authors><author><keyname>Ma</keyname><forenames>Zhanyu</forenames></author></authors><title>Dirichlet Mixture Model based VQ Performance Prediction for Line
  Spectral Frequency</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we continue our previous work on the Dirichlet mixture model
(DMM)-based VQ to derive the performance bound of the LSF VQ. The LSF
parameters are transformed into the $\Delta$LSF domain and the underlying
distribution of the $\Delta$LSF parameters are modelled by a DMM with finite
number of mixture components. The quantization distortion, in terms of the mean
squared error (MSE), is calculated with the high rate theory. The mapping
relation between the perceptually motivated log spectral distortion (LSD) and
the MSE is empirically approximated by a polynomial. With this mapping
function, the minimum required bit rate for transparent coding of the LSF is
estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00857</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00857</id><created>2018-08-02</created><updated>2019-02-09</updated><authors><author><keyname>Fascista</keyname><forenames>Alessio</forenames></author><author><keyname>Coluccia</keyname><forenames>Angelo</forenames></author><author><keyname>Ricci</keyname><forenames>Giuseppe</forenames></author></authors><title>Mobile Positioning in Multipath Environments: a Pseudo Maximum
  Likelihood approach</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of mobile position estimation in multipath scenarios is
addressed. A low-complexity, fully-adaptive algorithm is proposed, based on the
pseudo maximum likelihood approach. The processing is done exclusively on-board
at the mobile node by exploiting narrowband downlink radio signals. The
proposed algorithm is able to estimate via adaptive beamforming (with spatial
smoothing) the optimal projection matrices that maximize the likelihood; in
addition, it can associate the line-of-sight over the trajectory, hence
achieving an integration gain. The performance assessment shows that the
proposed algorithm is very effective in (even severe) multipath conditions,
outperforming natural competitors also when the number of antennas and
snapshots is kept at the theoretical minimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00876</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00876</id><created>2018-08-02</created><updated>2018-08-05</updated><authors><author><keyname>Huang</keyname><forenames>Che-Wei</forenames></author><author><keyname>Narayanan</keyname><forenames>Shrikanth S.</forenames></author></authors><title>Normalization Before Shaking Toward Learning Symmetrically Distributed
  Representation Without Margin in Speech Emotion Recognition</title><categories>cs.LG cs.HC cs.MM cs.SD eess.AS</categories><comments>Submission to The IEEE Transactions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularization is crucial to the success of many practical deep learning
models, in particular in a more often than not scenario where there are only a
few to a moderate number of accessible training samples. In addition to weight
decay, data augmentation and dropout, regularization based on multi-branch
architectures, such as Shake-Shake regularization, has been proven successful
in many applications and attracted more and more attention. However, beyond
model-based representation augmentation, it is unclear how Shake-Shake
regularization helps to provide further improvement on classification tasks,
let alone the baffling interaction between batch normalization and shaking. In
this work, we present our investigation on Shake-Shake regularization, drawing
connections to the vicinal risk minimization principle and discriminative
feature learning in verification tasks. Furthermore, we identify a strong
resemblance between batch normalized residual blocks and batch normalized
recurrent neural networks, where both of them share a similar convergence
behavior, which could be mitigated by a proper initialization of batch
normalization. Based on the findings, our experiments on speech emotion
recognition demonstrate simultaneously an improvement on the classification
accuracy and a reduction on the generalization gap both with statistical
significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00878</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00878</id><created>2018-08-02</created><authors><author><keyname>Ali</keyname><forenames>Hazrat</forenames></author><author><keyname>Awan</keyname><forenames>Adnan Ali</forenames></author><author><keyname>Khan</keyname><forenames>Sanaullah</forenames></author><author><keyname>Shafique</keyname><forenames>Omer</forenames></author><author><keyname>Rahman</keyname><forenames>Atiq ur</forenames></author><author><keyname>Khan</keyname><forenames>Shahid</forenames></author></authors><title>Supervised classification for object identification in urban areas using
  satellite imagery</title><categories>cs.LG cs.CV eess.SP stat.ML</categories><comments>2018 International Conference on Computing, Mathematics and
  Engineering Technologies (iCoMET)</comments><journal-ref>H. Ali et al., 2018 International Conference on Computing,
  Mathematics and Engineering Technologies (iCoMET), Sukkur, 2018, pp. 1-4</journal-ref><doi>10.1109/ICOMET.2018.8346383</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper presents a useful method to achieve classification in satellite
imagery. The approach is based on pixel level study employing various features
such as correlation, homogeneity, energy and contrast. In this study gray-scale
images are used for training the classification model. For supervised
classification, two classification techniques are employed namely the Support
Vector Machine (SVM) and the Naive Bayes. With textural features used for
gray-scale images, Naive Bayes performs better with an overall accuracy of 76%
compared to 68% achieved by SVM. The computational time is evaluated while
performing the experiment with two different window sizes i.e., 50x50 and
70x70. The required computational time on a single image is found to be 27
seconds for a window size of 70x70 and 45 seconds for a window size of 50x50.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00930</identifier>
 <datestamp>2018-08-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00930</id><created>2018-08-02</created><authors><author><keyname>Tuladhar</keyname><forenames>Saurav R</forenames></author><author><keyname>Khomchuk</keyname><forenames>Peter</forenames></author><author><keyname>Sivananthan</keyname><forenames>Siva</forenames></author></authors><title>Estimating Passenger Loading on Train Cars Using Accelerometer</title><categories>eess.SP cs.SY</categories><comments>Work performed under Phase I SBIR grant DTRT5717C10231 from the Volpe
  National Transportation Systems Center, US Department of Transportation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowding on train cars is a common problem plaguing the major public transit
agencies around the world. On one hand a crowded train car presents a negative
experience for the passengers, while on the other hand it indicated
inefficiencies in the train system. The Federal Transit Agency is interested in
reducing the crowding level on public transit train cars. Automatic passenger
counters (APC) are commonly used to count the passengers boarding and alighting
the train cars. Advanced APC solutions are available based on EO/IR sensors and
visual object detection technology, but are considerably expensive for large
scale deployment. This report discusses a low-cost approach to APC by using
accelerometer measurements from train car to estimate approximate passenger
loading. Accelerometer sensor can measure train car vibration as the train
moves along the rail tracks. The train car vibration changes with the passenger
loading on the car. Detecting this change in vibration pattern with changing
passenger loading level is key to the accelerometer based APC solution.
Moreover, accelerometer sensors present a low-cost APC solution compared to
existing EO/IR based APCs. This work presents a (i) theoretical model analysis
(ii) experimental data driven approach to demonstrate the feasibility of using
accelerometer for passenger loading estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00959</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00959</id><created>2018-08-02</created><updated>2020-02-02</updated><authors><author><keyname>Ma</keyname><forenames>Zhanyu</forenames></author><author><keyname>Yu</keyname><forenames>Hong</forenames></author></authors><title>Histogram Transform-based Speaker Identification</title><categories>cs.SD eess.AS stat.ML</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel text-independent speaker identification (SI) method is proposed. This
method uses the Mel-frequency Cepstral coefficients (MFCCs) and the dynamic
information among adjacent frames as feature sets to capture speaker's
characteristics. In order to utilize dynamic information, we design super-MFCCs
features by cascading three neighboring MFCCs frames together. The probability
density function (PDF) of these super-MFCCs features is estimated by the
recently proposed histogram transform~(HT) method, which generates more
training data by random transforms to realize the histogram PDF estimation and
recedes the commonly occurred discontinuity problem in multivariate histograms
computing. Compared to the conventional PDF estimation methods, such as
Gaussian mixture models, the HT model shows promising improvement in the SI
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00960</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.00960</id><created>2018-08-02</created><updated>2020-02-02</updated><authors><author><keyname>Ma</keyname><forenames>Zhanyu</forenames></author><author><keyname>Leijon</keyname><forenames>Arne</forenames></author></authors><title>Statistical Speech Model Description with VMF Mixture Model</title><categories>cs.SD eess.AS</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the LSF parameters by a unit vector form, which has
directional characteristics. The underlying distribution of this unit vector
variable is modeled by a von Mises-Fisher mixture model (VMM). With the high
rate theory, the optimal inter-component bit allocation strategy is proposed
and the distortion-rate (D-R) relation is derived for the VMM based-VQ (VVQ).
Experimental results show that the VVQ outperforms our recently introduced DVQ
and the conventional GVQ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01001</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01001</id><created>2018-08-02</created><authors><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Millimeter-Wave V2X Channels: PropagationStatistics, Beamforming, and
  Blockage</title><categories>eess.SP</categories><comments>6 Pages. To appear in VTC2018-Fall - Chicago</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G millimeter wave (mmWave) technology is envisioned to be an integral part
of next-generation vehicle-to-everything (V2X) networks and autonomous vehicles
due to its broad bandwidth, wide field of view sensing, and precise
localization capabilities. The reliability of mmWave links may be compromised
due to difficulties in beam alignment for mobile channels and due to blocking
effects between a mmWave transmitter and a receiver. In this paper, we study
the channel characteristics for mmWave and sub-6 GHz V2X communications using
ray-tracing simulations. We present results for time-varying path-loss, delay
spread, and angular spreads in the presence of a moving vehicle for
line-of-sight (LOS) and non-LOS (NLOS) trajectory, respectively. Additionally,
we study the effect of delay spread and angular spread when the base station
(BS) and user equipment (UE) are capable of adjusting the beam directions and
beamwidths dynamically. Finally, we explore the impact of blockage effects on
the quality of receive beams at 28 GHz for the considered vehicle trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01018</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01018</id><created>2018-08-02</created><authors><author><keyname>Wu</keyname><forenames>Fang-Jing</forenames></author><author><keyname>Solmaz</keyname><forenames>G&#xfc;rkan</forenames></author></authors><title>Are You in the Line? RSSI-based Queue Detection in Crowds</title><categories>cs.NI eess.SP</categories><comments>This work has been partially funded by the European Union's Horizon
  2020 research and innovation programme within the project &quot;Worldwide
  Interoperability for SEmantics IoT&quot; under grant agreement Number 723156</comments><doi>10.1109/ICC.2017.7997193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowd behaviour analytics focuses on behavioural characteristics of groups of
people instead of individuals' activities. This work considers human queuing
behaviour which is a specific crowd behavior of groups. We design a
plug-and-play system solution to the queue detection problem based on
Wi-Fi/Bluetooth Low Energy (BLE) received signal strength indicators (RSSIs)
captured by multiple signal sniffers. The goal of this work is to determine if
a device is in the queue based on only RSSIs. The key idea is to extract
features not only from individual device's data but also mobility similarity
between data from multiple devices and mobility correlation observed by
multiple sniffers. Thus, we propose single-device feature extraction,
cross-device feature extraction, and cross-sniffer feature extraction for model
training and classification. We systematically conduct experiments with
simulated queue movements to study the detection accuracy. Finally, we compare
our signal-based approach against camera-based face detection approach in a
real-world social event with a real human queue. The experimental results
indicate that our approach can reach minimum accuracy of 77% and it
significantly outperforms the camera-based face detection because people block
each other's visibility whereas wireless signals can be detected without
blocking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01019</identifier>
 <datestamp>2018-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01019</id><created>2018-08-02</created><updated>2018-10-11</updated><authors><author><keyname>Zhang</keyname><forenames>Zhe</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Tian</keyname><forenames>Zhi</forenames></author></authors><title>Efficient Two-Dimensional Line Spectrum Estimation Based on Decoupled
  Atomic Norm Minimization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient optimization technique for gridless {2-D}
line spectrum estimation, named decoupled atomic norm minimization (D-ANM). The
framework of atomic norm minimization (ANM) is considered, which has been
successfully applied in 1-D problems to allow super-resolution frequency
estimation for correlated sources even when the number of snapshots is highly
limited. The state-of-the-art 2-D ANM approach vectorizes the 2-D measurements
to their 1-D equivalence, which incurs huge computational cost and may become
too costly for practical applications. We develop a novel decoupled approach of
2-D ANM via semi-definite programming (SDP), which introduces a new matrix-form
atom set to naturally decouple the joint observations in both dimensions
without loss of optimality. Accordingly, the original large-scale 2-D problem
is equivalently reformulated via two decoupled one-level Toeplitz matrices,
which can be solved by simple 1-D frequency estimation with pairing. Compared
with the conventional vectorized approach, the proposed D-ANM technique reduces
the computational complexity by several orders of magnitude with respect to the
problem size. It also retains the benefits of ANM in terms of precise signal
recovery, small number of required measurements, and robustness to source
correlation. The complexity benefits are particularly attractive for
large-scale antenna systems such as massive MIMO, radar signal processing and
radio astronomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01023</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01023</id><created>2018-08-02</created><authors><author><keyname>Solmaz</keyname><forenames>G&#xfc;rkan</forenames></author><author><keyname>Wu</keyname><forenames>Fang-Jing</forenames></author></authors><title>Together or Alone: Detecting Group Mobility with Wireless Fingerprints</title><categories>cs.NI eess.SP</categories><comments>This work has received funding from the European Union's Horizon 2020
  research and innovation programme within the project &quot;Worldwide
  Interoperability for SEmantics IoT&quot; under grant agreement Number 723156</comments><doi>10.1109/ICC.2017.7997426</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel approach for detecting groups of people that walk
&quot;together&quot; (group mobility) as well as the people who walk &quot;alone&quot; (individual
movements) using wireless signals. We exploit multiple wireless sniffers to
pervasively collect human mobility data from people with mobile devices and
identify similarities and the group mobility based on the wireless
fingerprints. We propose a method which initially converts the wireless packets
collected by the sniffers into people's wireless fingerprints. The method then
determines group mobility by finding the statuses of people at certain times
(dynamic/static) and the space correlation of dynamic people. To evaluate the
feasibility of our approach, we conduct real world experiments by collecting
data from 10 participants carrying Bluetooth Low Energy (BLE) beacons in an
office environment for a two-week period. The proposed approach captures space
correlation with 95% and group mobility with 79% accuracies on average. With
the proposed approach we successfully 1) detect the groups and individual
movements and 2) generate social networks based on the group mobility
characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01026</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01026</id><created>2018-07-31</created><authors><author><keyname>Soleymani</keyname><forenames>Sobhan</forenames></author><author><keyname>Dabouei</keyname><forenames>Ali</forenames></author><author><keyname>Iranmanesh</keyname><forenames>Seyed Mehdi</forenames></author><author><keyname>Kazemi</keyname><forenames>Hadi</forenames></author><author><keyname>Dawson</keyname><forenames>Jeremy</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser M.</forenames></author></authors><title>Prosodic-Enhanced Siamese Convolutional Neural Networks for Cross-Device
  Text-Independent Speaker Verification</title><categories>eess.AS cs.CV cs.LG cs.SD</categories><comments>Accepted in 9th IEEE International Conference on Biometrics: Theory,
  Applications, and Systems (BTAS 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel cross-device text-independent speaker verification
architecture is proposed. Majority of the state-of-the-art deep architectures
that are used for speaker verification tasks consider Mel-frequency cepstral
coefficients. In contrast, our proposed Siamese convolutional neural network
architecture uses Mel-frequency spectrogram coefficients to benefit from the
dependency of the adjacent spectro-temporal features. Moreover, although
spectro-temporal features have proved to be highly reliable in speaker
verification models, they only represent some aspects of short-term acoustic
level traits of the speaker's voice. However, the human voice consists of
several linguistic levels such as acoustic, lexicon, prosody, and phonetics,
that can be utilized in speaker verification models. To compensate for these
inherited shortcomings in spectro-temporal features, we propose to enhance the
proposed Siamese convolutional neural network architecture by deploying a
multilayer perceptron network to incorporate the prosodic, jitter, and shimmer
features. The proposed end-to-end verification architecture performs feature
extraction and verification simultaneously. This proposed architecture displays
significant improvement over classical signal processing approaches and deep
algorithms for forensic cross-device speaker verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01027</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01027</id><created>2018-08-02</created><authors><author><keyname>Wu</keyname><forenames>Fang-Jing</forenames></author><author><keyname>Solmaz</keyname><forenames>G&#xfc;rkan</forenames></author></authors><title>We Hear Your Activities through Wi-Fi Signals</title><categories>cs.NI cs.CY eess.SP</categories><comments>This work has received funding from the European Union's Horizon 2020
  research and innovation programme within the project &quot;Worldwide
  Interoperability for SEmantics IoT&quot; under grant agreement Number 723156</comments><doi>10.1109/WF-IoT.2016.7845478</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we focus on the problem of human activity recognition without
identification of the individuals in a scene. We consider using Wi-Fi signals
to detect certain human mobility behaviors such as stationary, walking, or
running. The main objective is to successfully detect these behaviors for the
individuals and based on that enable detection of the crowd's overall mobility
behavior. We propose a method which infers mobility behaviors in two stages:
from Wi-Fi signals to trajectories and from trajectories to the mobility
behaviors. We evaluate the applicability of the proposed approach using the
StudentLife dataset which contains Wi-Fi, GPS, and accelerometer measurements
collected from smartphones of 49 students within a three-month period. The
experimental results indicate that there is high correlation between stability
of Wi-Fi signals and mobility activity. This unique characteristic provides
sufficient evidences to extend the proposed idea to mobility analytics of
groups of people in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01035</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01035</id><created>2018-08-02</created><authors><author><keyname>Tian</keyname><forenames>Zhi</forenames></author><author><keyname>Zhang</keyname><forenames>Zhe</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author></authors><title>Low-complexity optimization for Two-Dimensional Direction-of-arrival
  Estimation via Decoupled Atomic Norm Minimization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient optimization technique for super-resolution
two-dimensional (2D) direction of arrival (DOA) estimation by introducing a new
formulation of atomic norm minimization (ANM). ANM allows gridless angle
estimation for correlated sources even when the number of snapshots is far less
than the antenna size, yet it incurs huge computational cost in 2D processing.
This paper introduces a novel formulation of ANM via semi-definite programming,
which expresses the original high-dimensional problem by two decoupled Toeplitz
matrices in one dimension, followed by 1D angle estimation with automatic angle
pairing. Compared with the state-of-the-art 2D ANM, the proposed technique
reduces the computational complexity by several orders of magnitude with
respect to the antenna size, while retaining the benefits of ANM in terms of
super-resolution performance with use of a small number of measurements, and
robustness to source correlation and noise. The complexity benefits are
particularly attractive for large-scale antenna systems such as massive MIMO
and radio astronomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01036</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01036</id><created>2018-08-02</created><authors><author><keyname>Zhang</keyname><forenames>Zhe</forenames></author><author><keyname>Tian</keyname><forenames>Zhi</forenames></author></authors><title>ANM-PhaseLift: Structured Line Spectrum Estimation from Quadratic
  Measurements</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PhaseLift is a noted convex optimization technique for phase retrieval that
can recover a signal exactly from amplitude measurements only, with high
probability. Conventional PhaseLift requires a relatively large number of
samples that sometimes can be costly to acquire. % to compensate for the
missing phase information and achieve effective phase retrieval. This paper
focuses on some practical applications where the signal of interest is composed
of a few Vandermonde components, such as line spectra.A novel phase retrieval
framework, namely ANM-PhaseLift, is developed that exploits the Vandermonde
structure to alleviate the sampling requirements. Specifically, the atom set of
amplitude-based quadratic measurements is identified, and atomic norm
minimization (ANM) is introduced into PhaseLift to considerably reduce the
number of measurements that are needed for accurate phase retrieval. The
benefit of ANM-PhaseLift is particularly attractive in applications where the
Vandermonde structure is presented, such as massive MIMO and radar imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01039</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01039</id><created>2018-08-02</created><updated>2019-03-08</updated><authors><author><keyname>Vashishth</keyname><forenames>Vidushi</forenames></author><author><keyname>Chhabra</keyname><forenames>Anshuman</forenames></author><author><keyname>Khanna</keyname><forenames>Anirudh</forenames></author><author><keyname>Sharma</keyname><forenames>Deepak Kumar</forenames></author><author><keyname>Singh</keyname><forenames>Jyotsna</forenames></author></authors><title>An Energy Efficient Routing Protocol for Wireless Internet-of-Things
  Sensor Networks</title><categories>cs.NI eess.SP</categories><journal-ref>International Journal of Communication Systems (applied for review
  in 2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things (IoT) are increasingly being adopted into practical
applications such as security systems, smart infrastructure, traffic
management, weather systems, among others. While the scale of these
applications is enormous, device capabilities, particularly in terms of battery
life and energy efficiency are limited. Despite research being done to
ameliorate these shortcomings, wireless IoT networks still cannot guarantee
satisfactory network lifetimes and prolonged sensing coverage. Moreover,
proposed schemes in literature are convoluted and cannot be easily implemented
in real-world scenarios. This necessitates the development of a simple yet
energy efficient routing scheme for wireless IoT sensor networks. This paper
models the energy constraint problem of devices in IoT applications as an
optimization problem. To conserve the energy of device nodes, the routing
protocol first aggregates devices into clusters based on a number of different
features such as distance from base station, data/message length and data
sensed from the environment in the current epoch. Then, a cluster head is
elected for each cluster and a directed acyclic graph (DAG) is generated with
all the cluster heads as nodes. Edges represent communication intent from
transmitter to receiver and the edge weights are computed using a formulated
equation. The minimum cost path to the base station is computed to allow for
efficient real-time routing. Sleep scheduling is also optionally used to
further boost network energy efficiency. The proposed routing protocol has been
simulated and outperforms existing routing protocols in terms of metrics such
as number of active nodes, energy dynamics and network coverage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01149</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01149</id><created>2018-08-03</created><updated>2019-02-21</updated><authors><author><keyname>Huo</keyname><forenames>Yinjia</forenames></author><author><keyname>Prasad</keyname><forenames>Gautham</forenames></author><author><keyname>Atanackovic</keyname><forenames>Lazar</forenames></author><author><keyname>Lampe</keyname><forenames>Lutz</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Cable Diagnostics with Power Line Modems for Smart Grid Monitoring</title><categories>eess.SP</categories><comments>Submitted to an IEEE journal. A version of this paper won the &quot;Best
  Paper Award&quot; at IEEE ISPLC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote monitoring of electrical cable conditions is an essential
characteristic of the next-generation smart grid, which features the ability to
consistently surveil and control the grid infrastructure. In this paper, we
propose a technique that harnesses power line modems (PLMs) as sensors for
monitoring cable health. We envisage that all or most of these PLMs have
already been deployed for data communication purposes and focus on the
distribution grid or neighborhood area networks in the smart grid. For such a
setting, we propose a machine learning (ML) based framework for automatic cable
diagnostics by continuously monitoring the cable status to identify, assess,
and locate possible degradations. As part of our technique, we also synthesize
state-of-the-art reflectometry methods within the PLMs to extract beneficial
features for effective performance of our proposed ML solution. Simulation
results demonstrate the effectiveness of our solution under different aging
conditions and varying load configurations. Finally, we reflect on our proposed
diagnostics method by evaluating its robustness and comparing it with existing
alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01161</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01161</id><created>2018-08-03</created><authors><author><keyname>Nimr</keyname><forenames>Ahmad</forenames></author><author><keyname>Chafii</keyname><forenames>Marwa</forenames></author><author><keyname>Matthe</keyname><forenames>Maximilian</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Extended GFDM Framework: OTFS and GFDM Comparison</title><categories>eess.SP</categories><comments>Accepted in IEEE Global Communications Conference 9-13 December 2018
  Abu Dhabi, UAE</comments><journal-ref>2018 IEEE Global Communications Conference (GLOBECOM)</journal-ref><doi>10.1109/GLOCOM.2018.8647704</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Orthogonal time frequency space modulation (OTFS) has been recently proposed
to achieve time and frequency diversity, especially in linear time-variant
(LTV) channels with large Doppler frequencies. The idea is based on the
precoding of the data symbols using symplectic finite Fourier transform (SFFT)
then transmitting them by mean of orthogonal frequency division multiplexing
(OFDM) waveform. Consequently, the demodulator and channel equalization can be
coupled in one processing step. As a distinguished feature, the demodulated
data symbols have roughly equal gain independent of the channel selectivity. On
the other hand, generalized frequency division multiplexing (GFDM) modulation
also employs the spreading over the time and frequency domains using circular
filtering. Accordingly, the data symbols are implicitly precoded in a similar
way as applying SFFT in OTFS. In this paper, we present an extended
representation of GFDM which shows that OTFS can be processed as a GFDM signal
with simple permutation. Nevertheless, this permutation is the key factor
behind the outstanding performance of OTFS in LTV channels, as demonstrated in
this work. Furthermore, the representation of OTFS in the GFDM framework
provides an efficient implementation, that has been intensively investigated
for GFDM, and facilitates the understanding of the OTFS distinct features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01228</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01228</id><created>2018-08-02</created><authors><author><keyname>Jain</keyname><forenames>Ish Kumar</forenames></author><author><keyname>Kumar</keyname><forenames>Rajeev</forenames></author><author><keyname>Panwar</keyname><forenames>Shivendra</forenames></author></authors><title>Limited by Capacity or Blockage? A Millimeter Wave Blockage Analysis</title><categories>eess.SP</categories><comments>accepted for publication in ITC 2018. arXiv admin note: substantial
  text overlap with arXiv:1807.04388</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) communication systems can provide high data rates
but the system performance may degrade significantly due to mobile blockers and
the user's own body. A high frequency of interruptions and long duration of
blockage may degrade the quality of experience. For example, delays of more
than about 10ms cause nausea to VR viewers. Macro-diversity of base stations
(BSs) has been considered a promising solution where the user equipment (UE)
can handover to other available BSs, if the current serving BS gets blocked.
However, an analytical model for the frequency and duration of dynamic blockage
events in this setting is largely unknown.In this paper, we consider an open
park-like scenario and obtain closed-form expressions for the blockage
probability, expected frequency and duration of blockage events using
stochastic geometry. Our results indicate that the minimum density of BS that
is required to satisfy the Quality of Service (QoS) requirements of AR/VR and
other low latency applications is largely driven by blockage events rather than
capacity requirements. Placing the BS at a greater height reduces the
likelihood of blockage. We present a closed-form expression for the BS
density-height trade-off that can be used for network planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01297</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01297</id><created>2018-08-03</created><updated>2018-08-22</updated><authors><author><keyname>Rezaabad</keyname><forenames>Ali Lotfi</forenames></author><author><keyname>Beyranvand</keyname><forenames>Hamzeh</forenames></author><author><keyname>Salehi</keyname><forenames>Jawad A.</forenames></author><author><keyname>Maier</keyname><forenames>Martin</forenames></author></authors><title>Ultra-Dense 5G Small Cell Deployment for Fiber and Wireless
  Backhaul-Aware Infrastructures</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the cell planning problem for a two-tier cellular
network containing two types of base stations (BSs)-- i.e. with fiber backhaul,
referred to as wired BSs (W-BSs), and BSs with wireless backhaul, referred to
as unwired-BSs (U-BSs). In-band full-duplex wireless communications is used to
connect U-BSs and W-BSs. We propose an algorithm to determine the minimum
number of W-BSs and U-BSs to satisfy given cell and capacity coverage
constraints. Furthermore, we apply our proposed non-dominated sorting genetic
algorithm II (NSGA-II) to solve both cell planning and joint cell and backhaul
planning problem to minimize the cost of planning, while maximizing the
coverage simultaneously. Additionally, the considered cell planning program is
developed into an optimization by including the problem of minimizing the cost
of fiber backhaul deployment. In order to analyze the performance of the
proposed algorithm, we study three different deployment scenarios based on
different spatial distributions of users and coverage areas. The results show
the superiority of our proposed NSGA-II algorithm for both cell planning and
joint cell and backhaul planning to other well-known optimization algorithms.
The results also reveal that there is a trade-off between cell deployment costs
and SINR/rate coverage, and W-BSs are placed in congested areas to consume less
resources for wireless backhauls. Similarly, a trade-off between cell and fiber
deployment costs and SINR/rate coverage is observed in planning. We show that
for realistic scenarios desirable solutions can be selected from the Pareto
front of the introduced multi-objective problem based on given cellular
operator policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01410</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01410</id><created>2018-08-03</created><authors><author><keyname>Stanton</keyname><forenames>Daisy</forenames></author><author><keyname>Wang</keyname><forenames>Yuxuan</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author></authors><title>Predicting Expressive Speaking Style From Text In End-To-End Speech
  Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS stat.ML</categories><msc-class>eess.AS</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global Style Tokens (GSTs) are a recently-proposed method to learn latent
disentangled representations of high-dimensional data. GSTs can be used within
Tacotron, a state-of-the-art end-to-end text-to-speech synthesis system, to
uncover expressive factors of variation in speaking style. In this work, we
introduce the Text-Predicted Global Style Token (TP-GST) architecture, which
treats GST combination weights or style embeddings as &quot;virtual&quot; speaking style
labels within Tacotron. TP-GST learns to predict stylistic renderings from text
alone, requiring neither explicit labels during training nor auxiliary inputs
for inference. We show that, when trained on a dataset of expressive speech,
our system generates audio with more pitch and energy variation than two
state-of-the-art baseline models. We further demonstrate that TP-GSTs can
synthesize speech with background noise removed, and corroborate these analyses
with positive results on human-rated listener preference audiobook tasks.
Finally, we demonstrate that multi-speaker TP-GST models successfully factorize
speaker identity and speaking style. We provide a website with audio samples
for each of our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01486</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01486</id><created>2018-08-04</created><updated>2018-12-15</updated><authors><author><keyname>Cui</keyname><forenames>Wei</forenames></author><author><keyname>Shen</keyname><forenames>Kaiming</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Spatial Deep Learning for Wireless Scheduling</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>This paper is the full version of the paper presented at IEEE Global
  Communications Conference 2018. It includes 15 pages and 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal scheduling of interfering links in a dense wireless network with
full frequency reuse is a challenging task. The traditional method involves
first estimating all the interfering channel strengths then optimizing the
scheduling based on the model. This model-based method is however resource
intensive and computationally hard, because channel estimation is expensive in
dense networks; further, finding even a locally optimal solution of the
resulting optimization problem may be computationally complex. This paper shows
that by using a deep learning approach, it is possible to bypass channel
estimation and to schedule links efficiently based solely on the geographic
locations of transmitters and receivers for networks in which the channels are
largely functions of distance dependent path-losses. This is accomplished by
unsupervised training over randomly deployed networks, and by using a novel
neural network architecture that takes the geographic spatial convolutions of
the interfering or interfered neighboring nodes as input over multiple feedback
stages to learn the optimum solution. The resulting neural network gives
near-optimal performance for sum-rate maximization and is capable of
generalizing to larger deployment areas and to deployments of different link
densities. Moreover, to provide fairness, this paper proposes a novel
scheduling approach that utilizes the sum-rate optimal scheduling algorithm
over judiciously chosen subsets of links for maximizing a proportional fairness
objective over the network. The proposed approach shows highly competitive and
generalizable network utility maximization results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01535</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01535</id><created>2018-08-04</created><authors><author><keyname>Song</keyname><forenames>Huan</forenames></author><author><keyname>Willi</keyname><forenames>Megan</forenames></author><author><keyname>Thiagarajan</keyname><forenames>Jayaraman J.</forenames></author><author><keyname>Berisha</keyname><forenames>Visar</forenames></author><author><keyname>Spanias</keyname><forenames>Andreas</forenames></author></authors><title>Triplet Network with Attention for Speaker Diarization</title><categories>eess.AS cs.CL cs.LG stat.ML</categories><comments>Interspeech2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automatic speech processing systems, speaker diarization is a crucial
front-end component to separate segments from different speakers. Inspired by
the recent success of deep neural networks (DNNs) in semantic inferencing,
triplet loss-based architectures have been successfully used for this problem.
However, existing work utilizes conventional i-vectors as the input
representation and builds simple fully connected networks for metric learning,
thus not fully leveraging the modeling power of DNN architectures. This paper
investigates the importance of learning effective representations from the
sequences directly in metric learning pipelines for speaker diarization. More
specifically, we propose to employ attention models to learn embeddings and the
metric jointly in an end-to-end fashion. Experiments are conducted on the
CALLHOME conversational speech corpus. The diarization results demonstrate
that, besides providing a unified model, the proposed approach achieves
improved performance when compared against existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01603</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01603</id><created>2018-08-05</created><authors><author><keyname>Gosain</keyname><forenames>Devashish</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author><author><keyname>Sajwan</keyname><forenames>Mohit</forenames></author></authors><title>Simulating Raga Notes with a Markov Chain of Order 1-2</title><categories>cs.SD cs.CE eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi Natural Algorithmic composition (SNCA) is the technique of using
algorithms to create music note sequences in computer with the understanding
that how to render them would be decided by the composer. In our approach we
are proposing an SNCA2 algorithm (extension of SNCA algorithm) with an
illustrative example in Raga Bageshree. For this, Transition probability matrix
(tpm) was created for the note sequences of Raga Bageshree, then first order
Markov chain (using SNCA) and second order Markov chain (using SNCA2)
simulations were performed for generating arbitrary sequences of notes of Raga
Bageshree. The choice between first and second order Markov model, is best left
to the composer who has to decide how to render these music notes sequences. We
have confirmed that Markov chain of order of three and above are not promising,
as the tpm of these become sparse matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01640</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01640</id><created>2018-08-05</created><authors><author><keyname>Dresp-Langley</keyname><forenames>Birgitta</forenames></author></authors><title>Principles of perceptual grouping: implications for image-guided surgery</title><categories>cs.HC eess.IV q-bio.NC</categories><journal-ref>2015, Frontiers in Psychology, 6, 1565</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gestalt theory has provided perceptual science with a conceptual framework
which has inspired researchers ever since, taking the field of perceptual
organization into the 21st century. This opinion article discusses the
importance of rules of perceptual organization for the testing and design of
visual interface technology. It is argued that major Gestalt principles, such
as the law of good continuation or the principle of Praegnanz (suggested
translation: salience), taken as examples here, are important to our
understanding of visual image processing by a human observer. Perceptual
integration of contrast information across collinear space, and the
organization of objects in the 2D image plane into figure and ground are of a
particular importance here. Visual interfaces for image-guided surgery
illustrate the criticality of these two types of perceptual processes for
reliable decision making and action. It is concluded that Gestalt theory
continues to generate powerful concepts and insights for perceptual science
placed within the context of major technological challenges of today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01656</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01656</id><created>2018-08-05</created><authors><author><keyname>Gishkori</keyname><forenames>Shahzad</forenames></author><author><keyname>Mulgrew</keyname><forenames>Bernard</forenames></author></authors><title>Graph Based Imaging for Synthetic Aperture Radar</title><categories>eess.SP</categories><doi>10.1109/LGRS.2019.2919147</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose graph signal processing based imaging for synthetic
aperture radar. We present a modified version of fused least absolute shrinkage
and selection operator to cater for graph structure of the radar image. We
solve the cost function via alternating direction method of multipliers. Our
method provides improved denoising and resolution enhancing capabilities. It
can also accommodate the compressed sensing framework quite easily.
Experimental results corroborate the validity of our proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01672</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01672</id><created>2018-08-05</created><updated>2019-06-15</updated><authors><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author><author><keyname>Lam</keyname><forenames>Thanh Tu</forenames></author><author><keyname>Qian</keyname><forenames>Xuewen</forenames></author></authors><title>Model-Aided Wireless Artificial Intelligence: Embedding Expert Knowledge
  in Deep Neural Networks Towards Wireless Systems Optimization</title><categories>cs.IT eess.SP math.IT</categories><comments>Accepted for publication on the IEEE Vehicular Technology Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning based on artificial neural networks is a powerful machine
learning method that, in the last few years, has been successfully used to
realize tasks, e.g., image classification, speech recognition, translation of
languages, etc., that are usually simple to execute by human beings but
extremely difficult to perform by machines. This is one of the reasons why deep
learning is considered to be one of the main enablers to realize the notion of
artificial intelligence. In order to identify the best architecture of an
artificial neural network that allows one to fit input-output data pairs, the
current methodology in deep learning methods consists of employing a
data-driven approach. Once the artificial neural network is trained, it is
capable of responding to never-observed inputs by providing the optimum output
based on past acquired knowledge. In this context, a recent trend in the deep
learning community is to complement pure data-driven approaches with prior
information based on expert knowledge. In this work, we describe two methods
that implement this strategy, which aim at optimizing wireless communication
networks. In addition, we illustrate numerical results in order to assess the
performance of the proposed approaches compared with pure data-driven
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01686</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01686</id><created>2018-08-05</created><authors><author><keyname>Kvinge</keyname><forenames>Henry</forenames></author><author><keyname>Farnell</keyname><forenames>Elin</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author></authors><title>Too many secants: a hierarchical approach to secant-based dimensionality
  reduction on large data sets</title><categories>cs.CV cs.LG eess.IV eess.SP</categories><comments>To appear in the Proceedings of the 2018 IEEE High Performance
  Extreme Computing Conference, Waltham, MA USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental question in many data analysis settings is the problem of
discerning the &quot;natural&quot; dimension of a data set. That is, when a data set is
drawn from a manifold (possibly with noise), a meaningful aspect of the data is
the dimension of that manifold. Various approaches exist for estimating this
dimension, such as the method of Secant-Avoidance Projection (SAP).
Intuitively, the SAP algorithm seeks to determine a projection which best
preserves the lengths of all secants between points in a data set; by applying
the algorithm to find the best projections to vector spaces of various
dimensions, one may infer the dimension of the manifold of origination. That
is, one may learn the dimension at which it is possible to construct a
diffeomorphic copy of the data in a lower-dimensional Euclidean space. Using
Whitney's embedding theorem, we can relate this information to the natural
dimension of the data. A drawback of the SAP algorithm is that a data set with
$T$ points has $O(T^2)$ secants, making the computation and storage of all
secants infeasible for very large data sets. In this paper, we propose a novel
algorithm that generalizes the SAP algorithm with an emphasis on addressing
this issue. That is, we propose a hierarchical secant-based
dimensionality-reduction method, which can be employed for data sets where
explicitly calculating all secants is not feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01700</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01700</id><created>2018-08-05</created><authors><author><keyname>Jaffry</keyname><forenames>Shan</forenames></author><author><keyname>Hasan</keyname><forenames>Syed Faraz</forenames></author><author><keyname>Gui</keyname><forenames>Xiang</forenames></author></authors><title>Effective Resource Sharing in Mobile-Cell Environments</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper has been submitted to IEEE Transactions on Vehicular
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mobile users on board vehicles often experience low quality of service
due to the vehicular penetration effect, especially at the cell edges. The
so-called mobile-cells are installed inside public transport vehicles to serve
the commuters. On one end, the mobile-cells have a wireless backhaul connection
with the nearest base station, and on the other, they connect wirelessly to the
in-vehicle users over access links. This paper integrates the mobile-cells
within the cellular networks by reusing their sub-channels. Firstly, this paper
proposes an algorithm that allows spectrum sharing for access-link with
out-of-vehicle cellular users or MC's backhaul-links. Secondly, it proposes a
scheme for controlling the transmit power over the access link to mitigate
interference to the backhaul-link, while maintaining high link quality for
in-vehicle users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01935</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01935</id><created>2018-08-06</created><authors><author><keyname>Hou</keyname><forenames>Yuanbo</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Li</keyname><forenames>Shengchen</forenames></author></authors><title>Audio Tagging With Connectionist Temporal Classification Model Using
  Sequential Labelled Data</title><categories>cs.SD cs.CL eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio tagging aims to predict one or several labels in an audio clip. Many
previous works use weakly labelled data (WLD) for audio tagging, where only
presence or absence of sound events is known, but the order of sound events is
unknown. To use the order information of sound events, we propose sequential
labelled data (SLD), where both the presence or absence and the order
information of sound events are known. To utilize SLD in audio tagging, we
propose a Convolutional Recurrent Neural Network followed by a Connectionist
Temporal Classification (CRNN-CTC) objective function to map from an audio clip
spectrogram to SLD. Experiments show that CRNN-CTC obtains an Area Under Curve
(AUC) score of 0.986 in audio tagging, outperforming the baseline CRNN of 0.908
and 0.815 with Max Pooling and Average Pooling, respectively. In addition, we
show CRNN-CTC has the ability to predict the order of sound events in an audio
clip.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.01940</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.01940</id><created>2018-07-30</created><authors><author><keyname>Dowling</keyname><forenames>Lachlan</forenames></author><author><keyname>Poblete</keyname><forenames>Tomas</forenames></author><author><keyname>Hook</keyname><forenames>Isaac</forenames></author><author><keyname>Tang</keyname><forenames>Hao</forenames></author><author><keyname>Tan</keyname><forenames>Ying</forenames></author><author><keyname>Glenn</keyname><forenames>Will</forenames></author><author><keyname>Unnithan</keyname><forenames>Ranjith R</forenames></author></authors><title>Accurate indoor mapping using an autonomous unmanned aerial vehicle
  (UAV)</title><categories>cs.RO eess.IV</categories><comments>This manuscript will be sent to IEEE TRANSACTIONS ON INDUSTRIAL
  ELECTRONICS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An autonomous indoor aerial vehicle requires reliable simul- taneous
localization and mapping (SLAM), accurate flight control, and robust path
planning for navigation. This paper presents a system level combination of
these existing technologies for 2D navigation. An Unmanned aerial vehicle (UAV)
called URSA (Unmanned Recon and Safety Aircraft) that can autonomously flight
and mapping indoors environments with an accuracy of 2 cm was developed.
Performance in indoor environments was assessed in terms of mapping and
navigation precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02064</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02064</id><created>2018-06-09</created><authors><author><keyname>Hoe</keyname><forenames>Choo Kian</forenames></author><author><keyname>Vaithlingam</keyname><forenames>Aravind Chokalingam</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Rajkumar</keyname><forenames>Rajparthiban</forenames></author></authors><title>Design of Automatic Soil Humidity Control using Maximum Power Point
  Tracking Controller</title><categories>eess.SP</categories><journal-ref>Conference on Research and Development, SCOReD 2010. pp 1_5</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The photovoltaic system uses the photovoltaic array as a source of electrical
power for the direct conversion of the sun radiation to direct current without
any environmental hazards. The main purpose of this research is to design a
converter with Maximum Power Point Tracker MPPT algorithm for any typical
application of soil humidity control. Using this setup the major energy from
the solar panel is used for the control of soil humidity. The design of the
converter with MPPT together with the soil humidity control logic is presented
in this paper. Experimental testing of the designed controller is implemented
and evaluated for performance under laboratory environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02079</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02079</id><created>2018-08-06</created><authors><author><keyname>Jiang</keyname><forenames>Xiaolin</forenames></author><author><keyname>Ghadikolaei</keyname><forenames>Hossein S.</forenames></author><author><keyname>Fodor</keyname><forenames>Gabor</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan</forenames></author><author><keyname>Pang</keyname><forenames>Zhibo</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author><author><keyname>Fischione</keyname><forenames>Carlo</forenames></author></authors><title>Low-latency Networking: Where Latency Lurks and How to Tame It</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the current generation of mobile and fixed communication networks has
been standardized for mobile broadband services, the next generation is driven
by the vision of the Internet of Things and mission critical communication
services requiring latency in the order of milliseconds or sub-milliseconds.
However, these new stringent requirements have a large technical impact on the
design of all layers of the communication protocol stack. The cross layer
interactions are complex due to the multiple design principles and technologies
that contribute to the layers' design and fundamental performance limitations.
We will be able to develop low-latency networks only if we address the problem
of these complex interactions from the new point of view of sub-milliseconds
latency. In this article, we propose a holistic analysis and classification of
the main design principles and enabling technologies that will make it possible
to deploy low-latency wireless communication networks. We argue that these
design principles and enabling technologies must be carefully orchestrated to
meet the stringent requirements and to manage the inherent trade-offs between
low latency and traditional performance metrics. We also review currently
ongoing standardization activities in prominent standards associations, and
discuss open problems for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02085</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02085</id><created>2018-06-16</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Laadi</keyname><forenames>Amirize Alpha</forenames></author><author><keyname>Samir</keyname><forenames>Yazan</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author></authors><title>Design an Advance computer-aided tool for Image Authentication and
  Classification</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.04576</comments><journal-ref>American Journal of Applied Sciences, (ISI Index. Published Online
  10 (7): 696-705. ISSN: 1546-9239</journal-ref><doi>10.3844/ajassp.2013.696.705</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Over the years, advancements in the fields of digital image processing and
artificial intelligence have been applied in solving many real-life problems.
This could be seen in facial image recognition for security systems, identity
registrations. Hence a bottleneck of identity registration is image processing.
These are carried out in form of image preprocessing, image region extraction
by cropping, feature extraction using Principal Component Analysis (PCA) and
image compression using Discrete Cosine Transform (DCT). Other processing
includes filtering and histogram equalization using contrast stretching is
performed while enhancing the image as part of the analytical tool. Hence, this
research work presents a universal integration image forgery detection analysis
tool with image facial recognition using Back Propagation Neural Network (BPNN)
processor. The proposed designed tool is a multi-function smart tool with the
novel architecture of programmable error goal and light intensity. Furthermore,
its advance dual database increases the efficiency of a high-performance
application. With the fact that, the facial image recognition will always, give
a matching output or closest possible output image for every input image
irrespective of the authenticity, the universal smart GUI tool is proposed and
designed to perform image forgery detection with the high accuracy of 2% error
rate. Meanwhile, a novel structure that provides efficient automatic image
forgery detection for all input test images for the BPNN recognition is
presented. Hence, an input image will be authenticated before being fed into
the recognition tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02096</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02096</id><created>2018-07-27</created><authors><author><keyname>Du</keyname><forenames>Changde</forenames></author><author><keyname>Du</keyname><forenames>Changying</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Li</keyname><forenames>Jinpeng</forenames></author><author><keyname>Zheng</keyname><forenames>Wei-Long</forenames></author><author><keyname>Lu</keyname><forenames>Bao-Liang</forenames></author><author><keyname>He</keyname><forenames>Huiguang</forenames></author></authors><title>Semi-supervised Deep Generative Modelling of Incomplete Multi-Modality
  Emotional Data</title><categories>eess.SP cs.CV cs.LG cs.MM</categories><comments>arXiv admin note: text overlap with arXiv:1704.07548, 2018 ACM
  Multimedia Conference (MM'18)</comments><doi>10.1145/3240508.3240528</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are threefold challenges in emotion recognition. First, it is difficult
to recognize human's emotional states only considering a single modality.
Second, it is expensive to manually annotate the emotional data. Third,
emotional data often suffers from missing modalities due to unforeseeable
sensor malfunction or configuration issues. In this paper, we address all these
problems under a novel multi-view deep generative framework. Specifically, we
propose to model the statistical relationships of multi-modality emotional data
using multiple modality-specific generative networks with a shared latent
space. By imposing a Gaussian mixture assumption on the posterior approximation
of the shared latent variables, our framework can learn the joint deep
representation from multiple modalities and evaluate the importance of each
modality simultaneously. To solve the labeled-data-scarcity problem, we extend
our multi-view model to semi-supervised learning scenario by casting the
semi-supervised classification problem as a specialized missing data imputation
task. To address the missing-modality problem, we further extend our
semi-supervised multi-view model to deal with incomplete data, where a missing
view is treated as a latent variable and integrated out during inference. This
way, the proposed overall framework can utilize all available (both labeled and
unlabeled, as well as both complete and incomplete) data to improve its
generalization ability. The experiments conducted on two real multi-modal
emotion datasets demonstrated the superiority of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02111</identifier>
 <datestamp>2019-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02111</id><created>2018-08-06</created><authors><author><keyname>Schaub</keyname><forenames>Michael T.</forenames></author><author><keyname>Segarra</keyname><forenames>Santiago</forenames></author></authors><title>Flow Smoothing and Denoising: Graph Signal Processing in the Edge-Space</title><categories>cs.DM cs.SI cs.SY eess.SP</categories><comments>5 pages, 2 figure</comments><journal-ref>2018 IEEE Global Conference on Signal and Information Processing
  (GlobalSIP), Anaheim, CA, USA, 2018, pp. 735-739</journal-ref><doi>10.1109/GlobalSIP.2018.8646701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on devising graph signal processing tools for the
treatment of data defined on the edges of a graph. We first show that
conventional tools from graph signal processing may not be suitable for the
analysis of such signals. More specifically, we discuss how the underlying
notion of a `smooth signal' inherited from (the typically considered variants
of) the graph Laplacian are not suitable when dealing with edge signals that
encode a notion of flow. To overcome this limitation we introduce a class of
filters based on the Edge-Laplacian, a special case of the Hodge-Laplacian for
simplicial complexes of order one. We demonstrate how this Edge-Laplacian leads
to low-pass filters that enforce (approximate) flow-conservation in the
processed signals. Moreover, we show how these new filters can be combined with
more classical Laplacian-based processing methods on the line-graph. Finally,
we illustrate the developed tools by denoising synthetic traffic flows on the
London street network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02151</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02151</id><created>2018-08-06</created><authors><author><keyname>Reddy</keyname><forenames>Vishnupraneeth</forenames></author><author><keyname>Gupta</keyname><forenames>Pravir Singh</forenames></author><author><keyname>Choi</keyname><forenames>Gwan Seong</forenames></author></authors><title>High Order M-QAM Massive MIMO Detector with Low Computational Complexity
  for 5G Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the behaviour of bit error rates for both conventional and
massive MIMO systems with high order constellations, which are essential to
achieve spectral efficiency for 5G standard communications, has been evaluated.
We have used real-domain Schnorr Euchner enumeration with K-best algorithm to
reduce computational complexity of detection. The results, presented in this
letter, have outperformed existing detection algorithms in terms of complexity
and BER, especially in low SNR regions, for both massive and conventional MIMO
systems. We performed simulations for N $\times$ N MIMO system, where N = 8,
25, 40, 50, 60, 80, 100 and 120, for both 256-QAM and 1024-QAM high order
transmission systems as per the latest 3GPP standards for 5G systems and
beyond. All the analyses and results that are given in this letter are from our
MIMO detector, prior to usage of error correction decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02229</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02229</id><created>2018-08-07</created><updated>2018-08-12</updated><authors><author><keyname>Zhang</keyname><forenames>Jiayao</forenames></author><author><keyname>Zhu</keyname><forenames>Guangxu</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>Grassmannian Learning: Embedding Geometry Awareness in Shallow and Deep
  Learning</title><categories>cs.LG cs.CV cs.IT eess.SP math.IT stat.ML</categories><comments>Submitted to IEEE Signal Processing Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern machine learning algorithms have been adopted in a range of
signal-processing applications spanning computer vision, natural language
processing, and artificial intelligence. Many relevant problems involve
subspace-structured features, orthogonality constrained or low-rank constrained
objective functions, or subspace distances. These mathematical characteristics
are expressed naturally using the Grassmann manifold. Unfortunately, this fact
is not yet explored in many traditional learning algorithms. In the last few
years, there have been growing interests in studying Grassmann manifold to
tackle new learning problems. Such attempts have been reassured by substantial
performance improvements in both classic learning and learning using deep
neural networks. We term the former as shallow and the latter deep Grassmannian
learning. The aim of this paper is to introduce the emerging area of
Grassmannian learning by surveying common mathematical problems and primary
solution approaches, and overviewing various applications. We hope to inspire
practitioners in different fields to adopt the powerful tool of Grassmannian
learning in their research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02240</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02240</id><created>2018-08-07</created><updated>2018-10-02</updated><authors><author><keyname>Ozfatura</keyname><forenames>Emre</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Speeding Up Distributed Gradient Descent by Utilizing Non-persistent
  Stragglers</title><categories>cs.IT cs.DC cs.LG eess.SP math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed gradient descent (DGD) is an efficient way of implementing
gradient descent (GD), especially for large data sets, by dividing the
computation tasks into smaller subtasks and assigning to different computing
servers (CSs) to be executed in parallel. In standard parallel execution,
per-iteration waiting time is limited by the execution time of the straggling
servers. Coded DGD techniques have been introduced recently, which can tolerate
straggling servers via assigning redundant computation tasks to the CSs. In
most of the existing DGD schemes, either with coded computation or coded
communication, the non-straggling CSs transmit one message per iteration once
they complete all their assigned computation tasks. However, although the
straggling servers cannot complete all their assigned tasks, they are often
able to complete a certain portion of them. In this paper, we allow multiple
transmissions from each CS at each iteration in order to make sure a maximum
number of completed computations can be reported to the aggregating server
(AS), including the straggling servers. We numerically show that the average
completion time per iteration can be reduced significantly by slightly
increasing the communication load per server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02242</identifier>
 <datestamp>2019-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02242</id><created>2018-08-07</created><updated>2019-04-16</updated><authors><author><keyname>Vu</keyname><forenames>Tuyet</forenames></author><author><keyname>Evans</keyname><forenames>Rob</forenames></author></authors><title>Optimal Subpattern Assignment Metric for Multiple Tracks (OSPAMT Metric)</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new metric which measures the distance between
two finite sets of tracks (a track is a path of either a real or estimated
target). This metric is based on the same principle as the Optimal Subpattern
Assignment (OSPA) metric devised by Schuhmacher et al. Importantly however, the
new metric measures the distance between two finite sets of tracks whereas the
OSPA metric measures the distance between two finite sets of target states. By
also considering the properties of false tracks, missed tracks and many tracks
assigned to one track situations caused by missed detections and false alarms,
the minimization of all distances between tracks across two finite sets of
tracks employed by the new OSPAMT metric enables performance evaluation of
multi-target tracking (MTT) algorithms in a more comprehensive and accurate
manner than existing metrics such as the OSPA metric and the enhanced OSPAT
metric introduced by Ristic et al which measures the distance between two
finite sets of labeled target states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02316</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02316</id><created>2018-08-07</created><authors><author><keyname>Kharyuk</keyname><forenames>Pavel</forenames></author><author><keyname>Oseledets</keyname><forenames>Ivan</forenames></author></authors><title>Modelling hidden structure of signals in group data analysis with
  modified (Lr, 1) and block-term decompositions</title><categories>cs.NA eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is devoted to elaboration on the idea to use block term
decomposition for group data analysis and to raise the possibility of modelling
group activity with (Lr, 1) and Tucker blocks. A new generalization of block
tensor decomposition was considered in application to group data analysis.
Suggested approach was evaluated on multilabel classification task for a set of
images. This contribution also reports results of investigation on clustering
with proposed tensor models in comparison with known matrix models, namely
common orthogonal basis extraction and group independent component analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02344</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02344</id><created>2018-06-09</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author></authors><title>An Improved Recursive and Non-recursive Comb filter for DSP applications</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.00704</comments><journal-ref>Asian Control Conference. Institute Technology Bandung Indonesia,
  413-417</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recursive and non-recursive comb filters are commonly used as decimators
for the sigma-delta modulators. This paper presents the analysis and design of
low power and high-speed comb filters. The comparison is made between the
recursive and the non-recursive comb filters with the focus on high speed and
saving power consumption. Design procedures and examples are given by using
Matlab and Verilog HDL for both recursive and non-recursive comb filter with
emphasis on frequency response, transfer function and register width. The
implementation results show that non-recursive comb filter has the capability
of speeding up the circuit and reducing power compared to recursive one when
the decimation ratio and filter order are high. Using Modified Carry Look-ahead
Adder for summation and also apply pipelined filter structure makes it more
compatible with DSP application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02349</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02349</id><created>2018-06-09</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author></authors><title>An Overview of the Decimation process and Its VLSI Implementation</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.00704</comments><journal-ref>Research Seminar SPS06. Faculty of Engineering, National
  University of Malaysia, pp. 207-211, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Decimation process plays an important task in a communication system.
It mostly is applied in transceiver when the frequency reduction is required.
However, the decimation process for sigma-delta modulator is considered in this
research work. The proposed design was simulated using MATLAB software and
implemented by hardware description language in Xilinx environment.
Furthermore, the proposed advance arithmetic unit is applied to improve the
system efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02350</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02350</id><created>2018-08-07</created><authors><author><keyname>Ali</keyname><forenames>Waleed</forenames></author><author><keyname>Abdelkarim</keyname><forenames>Sherif</forenames></author><author><keyname>Zahran</keyname><forenames>Mohamed</forenames></author><author><keyname>Zidan</keyname><forenames>Mahmoud</forenames></author><author><keyname>Sallab</keyname><forenames>Ahmad El</forenames></author></authors><title>YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection
  from LiDAR Point Cloud</title><categories>cs.CV eess.IV</categories><comments>Paper accepted in ECCV 2018, &quot;3D Reconstruction meets Semantics&quot;
  workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object detection and classification in 3D is a key task in Automated Driving
(AD). LiDAR sensors are employed to provide the 3D point cloud reconstruction
of the surrounding environment, while the task of 3D object bounding box
detection in real time remains a strong algorithmic challenge. In this paper,
we build on the success of the one-shot regression meta-architecture in the 2D
perspective image space and extend it to generate oriented 3D object bounding
boxes from LiDAR point cloud. Our main contribution is in extending the loss
function of YOLO v2 to include the yaw angle, the 3D box center in Cartesian
coordinates and the height of the box as a direct regression problem. This
formulation enables real-time performance, which is essential for automated
driving. Our results are showing promising figures on KITTI benchmark,
achieving real-time performance (40 fps) on Titan X GPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02357</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02357</id><created>2018-08-02</created><authors><author><keyname>Gharib</keyname><forenames>Shayan</forenames></author><author><keyname>Derrar</keyname><forenames>Honain</forenames></author><author><keyname>Niizumi</keyname><forenames>Daisuke</forenames></author><author><keyname>Senttula</keyname><forenames>Tuukka</forenames></author><author><keyname>Tommola</keyname><forenames>Janne</forenames></author><author><keyname>Heittola</keyname><forenames>Toni</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author><author><keyname>Huttunen</keyname><forenames>Heikki</forenames></author></authors><title>Acoustic Scene Classification: A Competition Review</title><categories>eess.AS cs.CV cs.LG cs.SD stat.ML</categories><comments>This work has been accepted in IEEE International Workshop on Machine
  Learning for Signal Processing (MLSP 2018). Copyright may be transferred
  without notice, after which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of acoustic scene classification, i.e.,
categorization of audio sequences into mutually exclusive classes based on
their spectral content. We describe the methods and results discovered during a
competition organized in the context of a graduate machine learning course;
both by the students and external participants. We identify the most suitable
methods and study the impact of each by performing an ablation study of the
mixture of approaches. We also compare the results with a neural network
baseline, and show the improvement over that. Finally, we discuss the impact of
using a competition as a part of a university course, and justify its
importance in the curriculum based on student feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02369</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02369</id><created>2018-08-07</created><authors><author><keyname>Wong</keyname><forenames>Lauren J.</forenames></author><author><keyname>Headley</keyname><forenames>William C.</forenames></author><author><keyname>Michaels</keyname><forenames>Alan J.</forenames></author></authors><title>Emitter Identification Using CNN IQ Imbalance Estimators</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Specific Emitter Identification is the association of a received signal to a
unique emitter, and is made possible by the naturally occurring and
unintentional characteristics an emitter imparts onto each transmission, known
as its radio frequency fingerprint. This work presents an approach for
identifying emitters using Convolutional Neural Networks to estimate the IQ
imbalance parameters of each emitter, using only raw IQ data as input. Because
an emitter's IQ imbalance parameters will not change as it changes modulation
schemes, the proposed approach has the ability to track emitters, even as they
change modulation scheme. The performance of the developed approach is
evaluated using simulated quadrature amplitude modulation and phase-shift
keying signals, and the impact of signal-to-noise ratio, imbalance value, and
modulation scheme are considered. Further, the developed approach is shown to
outperform a comparable feature-based approach, while making fewer assumptions
and using less data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02394</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02394</id><created>2018-08-07</created><authors><author><keyname>Lee</keyname><forenames>Woongsup</forenames></author><author><keyname>Jo</keyname><forenames>Ohyun</forenames></author><author><keyname>Kim</keyname><forenames>Minhoe</forenames></author></authors><title>Application of End-to-End Deep Learning in Wireless Communications
  Systems</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is a potential paradigm changer for the design of wireless
communications systems (WCS), from conventional handcrafted schemes based on
sophisticated mathematical models with assumptions to autonomous schemes based
on the end-to-end deep learning using a large number of data. In this article,
we present a basic concept of the deep learning and its application to WCS by
investigating the resource allocation (RA) scheme based on a deep neural
network (DNN) where multiple goals with various constraints can be satisfied
through the end-to-end deep learning. Especially, the optimality and
feasibility of the DNN based RA are verified through simulation. Then, we
discuss the technical challenges regarding the application of deep learning in
WCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02401</identifier>
 <datestamp>2018-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02401</id><created>2018-08-07</created><authors><author><keyname>Kim</keyname><forenames>Minhoe</forenames></author><author><keyname>Lee</keyname><forenames>Woonsup</forenames></author><author><keyname>Yoon</keyname><forenames>Jungmin</forenames></author><author><keyname>Jo</keyname><forenames>Ohyun</forenames></author></authors><title>Building Encoder and Decoder with Deep Neural Networks: On the Way to
  Reality</title><categories>cs.IT eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has been a groundbreaking technology in various fields as well
as in communications systems. In spite of the notable advancements of deep
neural network (DNN) based technologies in recent years, the high computational
complexity has been a major obstacle to apply DNN in practical communications
systems which require real-time operation. In this sense, challenges regarding
practical implementation must be addressed before the proliferation of
DNN-based intelligent communications becomes a reality. To the best of the
authors' knowledge, for the first time, this article presents an efficient
learning architecture and design strategies including link level verification
through digital circuit implementations using hardware description language
(HDL) to mitigate this challenge and to deduce feasibility and potential of DNN
for communications systems. In particular, DNN is applied for an encoder and a
decoder to enable flexible adaptation with respect to the system environments
without needing any domain specific information. Extensive investigations and
interdisciplinary design considerations including the DNN-based autoencoder
structure, learning framework, and low-complexity digital circuit
implementations for real-time operation are taken into account by the authors
which ascertains the use of DNN-based communications in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02462</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02462</id><created>2018-08-07</created><updated>2019-03-03</updated><authors><author><keyname>Trichili</keyname><forenames>Abderrahmen</forenames></author><author><keyname>Park</keyname><forenames>Ki-Hong</forenames></author><author><keyname>Zghal</keyname><forenames>Mourad</forenames></author><author><keyname>Ooi</keyname><forenames>Boon S.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Communicating Using Spatial Mode Multiplexing: Potentials, Challenges
  and Perspectives</title><categories>cs.IT eess.SP math.IT physics.optics</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Time, polarization, and wavelength multiplexing schemes have been used to
satisfy the growing need of transmission capacity. Using space as a new
dimension for communication systems has been recently suggested as a versatile
technique to address future bandwidth issues. We review the potentials of
harnessing the space as an additional degree of freedom for communication
applications including free space optics, optical fiber installation,
underwater wireless optical links, on-chip interconnects, data center indoor
connections, radio frequency and acoustic communications. We focus on the
orbital angular momentum (OAM) modes and equally identify the challenges
related to each of the applications of spatial modes and the particular OAM
modes in communication. We further discuss the perspectives of this emerging
technology. Finally, we provide the open research directions and we discuss the
practical deployment of OAM communication links for different applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02480</identifier>
 <datestamp>2018-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02480</id><created>2018-08-07</created><authors><author><keyname>Pundak</keyname><forenames>Golan</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Zhao</keyname><forenames>Ding</forenames></author></authors><title>Deep context: end-to-end contextual speech recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automatic speech recognition (ASR) what a user says depends on the
particular context she is in. Typically, this context is represented as a set
of word n-grams. In this work, we present a novel, all-neural, end-to-end (E2E)
ASR sys- tem that utilizes such context. Our approach, which we re- fer to as
Contextual Listen, Attend and Spell (CLAS) jointly- optimizes the ASR
components along with embeddings of the context n-grams. During inference, the
CLAS system can be presented with context phrases which might contain out-of-
vocabulary (OOV) terms not seen during training. We com- pare our proposed
system to a more traditional contextualiza- tion approach, which performs
shallow-fusion between inde- pendently trained LAS and contextual n-gram models
during beam search. Across a number of tasks, we find that the pro- posed CLAS
system outperforms the baseline method by as much as 68% relative WER,
indicating the advantage of joint optimization over individually trained
components. Index Terms: speech recognition, sequence-to-sequence models,
listen attend and spell, LAS, attention, embedded speech recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02504</identifier>
 <datestamp>2018-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02504</id><created>2018-08-07</created><authors><author><keyname>Mallidi</keyname><forenames>Sri Harish</forenames></author><author><keyname>Maas</keyname><forenames>Roland</forenames></author><author><keyname>Goehner</keyname><forenames>Kyle</forenames></author><author><keyname>Rastrow</keyname><forenames>Ariya</forenames></author><author><keyname>Matsoukas</keyname><forenames>Spyros</forenames></author><author><keyname>Hoffmeister</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Device-directed Utterance Detection</title><categories>cs.CL eess.AS</categories><comments>Interspeech 2018 (accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a classifier for distinguishing device-directed
queries from background speech in the context of interactions with voice
assistants. Applications include rejection of false wake-ups or unintended
interactions as well as enabling wake-word free follow-up queries. Consider the
example interaction: $&quot;Computer,~play~music&quot;, &quot;Computer,~reduce~the~volume&quot;$.
In this interaction, the user needs to repeat the wake-word ($Computer$) for
the second query. To allow for more natural interactions, the device could
immediately re-enter listening state after the first query (without wake-word
repetition) and accept or reject a potential follow-up as device-directed or
background speech. The proposed model consists of two long short-term memory
(LSTM) neural networks trained on acoustic features and automatic speech
recognition (ASR) 1-best hypotheses, respectively. A feed-forward deep neural
network (DNN) is then trained to combine the acoustic and 1-best embeddings,
derived from the LSTMs, with features from the ASR decoder. Experimental
results show that ASR decoder, acoustic embeddings, and 1-best embeddings yield
an equal-error-rate (EER) of $9.3~\%$, $10.9~\%$ and $20.1~\%$, respectively.
Combination of the features resulted in a $44~\%$ relative improvement and a
final EER of $5.2~\%$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02521</identifier>
 <datestamp>2018-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02521</id><created>2018-06-09</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Samir</keyname><forenames>Yazan</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author><author><keyname>Hong</keyname><forenames>Mok Vee</forenames></author></authors><title>On-Chip Implementation of Pipeline Digit-Slicing Multiplier-Less
  Butterfly for Fast Fourier Transform Architecture</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.04570</comments><journal-ref>American Journal of Engineering and Applied Sciences. 3(4):757-764</journal-ref><doi>10.3844/ajeassp.2010.757.764</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The need for wireless communication has driven the communication systems to
high performance. However, the main bottleneck that affects the communication
capability is the Fast Fourier Transform (FFT), which is the core of most
modulators. This study presents an on-chip implementation of pipeline
digit-slicing multiplier-less butterfly for FFT structure. The approach is
taken, in order to reduce computation complexity in the butterfly,
digit-slicing multiplier-less single constant technique was utilized in the
critical path of Radix-2 Decimation In Time (DIT) FFT structure. The proposed
design focused on the trade-off between the speed and active silicon area for
the chip implementation. The new architecture was investigated and simulated
with MATLAB software. The Verilog HDL code in Xilinx ISE environment was
derived to describe the FFT Butterfly functionality and was downloaded to
Virtex II FPGA board. Consequently, the Virtex-II FG456 Proto board was used to
implement and test the design on the real hardware. As a result, from the
findings, the synthesis report indicates the maximum clock frequency of 549.75
MHz with the total equivalent gate count of 31,159 is a marked and significant
improvement over Radix 2 FFT butterfly. In comparison with the conventional
butterfly architecture, the design that can only run at a maximum clock
frequency of 198.987 MHz and the conventional multiplier can only run at a
maximum clock frequency of 220.160 MHz, the proposed system exhibits better
results. The resulting maximum clock frequency increases by about 276.28% for
the FFT butterfly and about 277.06% for the multiplier. It can be concluded
that on-chip implementation of pipeline digit-slicing multiplier-less butterfly
for FFT structure is an enabler in solving problems that affect communications
capability in FFT and possesses huge potentials for future related works and
research areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02522</identifier>
 <datestamp>2018-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02522</id><created>2018-06-10</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Abueida</keyname><forenames>Ahmed JA</forenames></author><author><keyname>Chan</keyname><forenames>Kok Wai</forenames></author><author><keyname>S</keyname><forenames>Mohamud Iwan</forenames></author><author><keyname>Mok</keyname><forenames>Vee Hoong</forenames></author></authors><title>Advanced Frequency Identification Power Metering System for Energy Usage</title><categories>eess.SP</categories><comments>International Conference on Smart Instrumentation, Measurement and
  Applications. Malaysia</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Energy meter measures the amount of power consumed by electrical loads in
residential, industrial and commercial applications. In this project, the focus
goes to the implementation of a smart power measurement system to allocate
identification for individuals and determine the clients energy usage. The
incorporation of two PIC 16F877A microcontrollers and radio-frequency
identification (RFID) reader in this research work make the system operation
smooth and reliable. This paper presents the development of an intelligent
prepaid power metering system enabling power utilities to collect electricity
bills from consumers prior to the usage of power. Homeowners are able to
monitor reliable power consumption data for efficient power management. To
conclude, a graphical user interface (GUI) has been designed to be applied for
data transmission between the personal computer and RFID a smart card which
allows the credit to be transferred to the smart card.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02523</identifier>
 <datestamp>2019-03-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02523</id><created>2018-08-07</created><updated>2019-03-14</updated><authors><author><keyname>Sattar</keyname><forenames>Zeeshan</forenames></author><author><keyname>Evangelista</keyname><forenames>Joao V. C.</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author><author><keyname>Batani</keyname><forenames>Na&#xef;m</forenames></author></authors><title>Spectral Efficiency Analysis of the Decoupled Access for Downlink and
  Uplink in Two Tier Network</title><categories>eess.SP</categories><doi>10.1109/TVT.2019.2905785</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the efficacy of decoupled wireless access in a two-tier
heterogeneous network. The decoupled wireless access and its performance
benefits have been studied in different scenarios recently. In this paper, an
in-depth analysis on its efficacy from spectral efficiency perspective is
provided. To achieve this task, (i) new closed form expressions for probability
of association of user equipment with different tiers employing different
frequency bands (i.e., microwave and millimeter wave) with different pathloss
exponents are derived using univariate Fox's H-functions; (ii) Distributions of
the distance to the serving base stations are also derived; (iii) Exact
expressions of spectral efficiency for different association cases are further
obtained using bivariate Fox's H-functions. Furthermore, rigorous simulation
results are provided which validate the aforementioned analytical results. In
addition to that, a detailed discussion on the decoupling gain of decoupled
wireless access and its efficacy is also provided. Lastly, despite the
improvement provided by the decoupled wireless access, which is evident from
the results presented in this paper, few questions are raised on its pragmatic
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02570</identifier>
 <datestamp>2018-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02570</id><created>2018-08-07</created><authors><author><keyname>Nauryzbayev</keyname><forenames>Galymzhan</forenames></author><author><keyname>Abdallah</keyname><forenames>Mohamed</forenames></author><author><keyname>Rabie</keyname><forenames>Khaled M.</forenames></author></authors><title>Outage Probability of the EH-based Full-Duplex AF and DF Relaying
  Systems in \alpha-\mu Environment</title><categories>eess.SP</categories><journal-ref>IEEE VTC-Fall 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless power transfer and energy harvesting have attracted a significant
research attention in terms of their application in cooperative relaying
systems. Most of existing works in this field focus on the half-duplex (HD)
relaying mechanism over certain fading channels, however, in contrast, this
paper considers a dual-hop full-duplex (FD) relaying system over a generalized
independent but not identically distributed \alpha-\mu fading channel, where
the relay node is energy-constrained and entirely depends on the energy signal
from the source node. Three special cases of the \alpha-\mu model are
investigated, namely, Rayleigh, Nakagami-m and Weibull fading. As the system
performance, we investigate the outage probability (OP) for which we derive
exact unified closed-form expressions. The provided Monte Carlo simulations
validate the accuracy of our analysis. Moreover, the results obtained for the
FD scenario are compared to the ones related to the HD. The results demonstrate
that the decode-andforward relaying outperforms the amplify-and-forward
relaying for both HD and FD scenarios. It is also shown that the FD scenario
performs better than the HD relaying systems. Finally, we analyzed the impact
of the fading parameters \alpha and \mu on the achievable OP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02814</identifier>
 <datestamp>2019-03-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02814</id><created>2018-08-08</created><updated>2019-03-24</updated><authors><author><keyname>Bilgic</keyname><forenames>Berkin</forenames></author><author><keyname>Chatnuntawech</keyname><forenames>Itthi</forenames></author><author><keyname>Manhard</keyname><forenames>Mary Kate</forenames></author><author><keyname>Tian</keyname><forenames>Qiyuan</forenames></author><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>Cauley</keyname><forenames>Stephen F.</forenames></author><author><keyname>Huang</keyname><forenames>Susie Y.</forenames></author><author><keyname>Polimeni</keyname><forenames>Jonathan R.</forenames></author><author><keyname>Wald</keyname><forenames>Lawrence L.</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author></authors><title>Highly Accelerated Multishot EPI through Synergistic Machine Learning
  and Joint Reconstruction</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To introduce a combined machine learning (ML) and physics-based
image reconstruction framework that enables navigator-free, highly accelerated
multishot echo planar imaging (msEPI), and demonstrate its application in
high-resolution structural and diffusion imaging.
  Methods: Singleshot EPI is an efficient encoding technique, but does not lend
itself well to high-resolution imaging due to severe distortion artifacts and
blurring. While msEPI can mitigate these artifacts, high-quality msEPI has been
elusive because of phase mismatch arising from shot-to-shot variations which
preclude the combination of the multiple-shot data into a single image. We
employ deep learning to obtain an interim image with minimal artifacts, which
permits estimation of image phase variations due to shot-to-shot changes. These
variations are then included in a Joint Virtual Coil Sensitivity Encoding
(JVC-SENSE) reconstruction to utilize data from all shots and improve upon the
ML solution.
  Results: Our combined ML + physics approach enabled Rinplane x MultiBand (MB)
= 8x2-fold acceleration using 2 EPI-shots for multi-echo imaging, so that
whole-brain T2 and T2* parameter maps could be derived from an 8.3 sec
acquisition at 1x1x3mm3 resolution. This has also allowed high-resolution
diffusion imaging with high geometric fidelity using 5-shots at Rinplane x MB =
9x2-fold acceleration. To make these possible, we extended the state-of-the-art
MUSSELS reconstruction technique to Simultaneous MultiSlice (SMS) encoding and
used it as an input to our ML network.
  Conclusion: Combination of ML and JVC-SENSE enabled navigator-free msEPI at
higher accelerations than previously possible while using fewer shots, with
reduced vulnerability to poor generalizability and poor acceptance of
end-to-end ML approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02824</identifier>
 <datestamp>2018-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02824</id><created>2018-08-08</created><authors><author><keyname>Han</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Joint Frequency Reuse and Cache Optimization in Backhaul-Limited
  Small-Cell Wireless Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Caching at base stations (BSs) is a promising approach for supporting the
tremendous traffic growth of content delivery over future small-cell wireless
networks with limited backhaul. This paper considers exploiting spatial caching
diversity (i.e., caching different subsets of popular content files at
neighboring BSs) that can greatly improve the cache hit probability, thereby
leading to a better overall system performance. A key issue in exploiting
spatial caching diversity is that the cached content may not be located at the
nearest BS, which means that to access such content, a user needs to overcome
strong interference from the nearby BSs; this significantly limits the gain of
spatial caching diversity. In this paper, we consider a joint design of
frequency reuse and caching, such that the benefit of an improved cache hit
probability induced by spatial caching diversity and the benefit of
interference coordination induced by frequency reuse can be achieved
simultaneously. We obtain a closed-form characterization of the approximate
successful transmission probability for the proposed scheme and analyze the
impact of key operating parameters on the performance. We design a
low-complexity algorithm to optimize the frequency reuse factor and the cache
storage allocation. Simulations show that the proposed scheme achieves a higher
successful transmission probability than existing caching schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02924</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02924</id><created>2018-08-08</created><authors><author><keyname>Sharma</keyname><forenames>Shree Krishna</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author></authors><title>Towards Massive Machine Type Communications in Ultra-Dense Cellular IoT
  Networks: Current Issues and Machine Learning-Assisted Solutions</title><categories>eess.SP</categories><comments>37 pages, 8 figures, 7 tables, submitted for a possible future
  publication in IEEE Communications Surveys and Tutorials</comments><doi>10.1109/COMST.2019.2916177</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever-increasing number of resource-constrained Machine-Type Communication
(MTC) devices is leading to the critical challenge of fulfilling diverse
communication requirements in dynamic and ultra-dense wireless environments.
Among different application scenarios that the upcoming 5G and beyond cellular
networks are expected to support, such as eMBB, mMTC and URLLC, mMTC brings the
unique technical challenge of supporting a huge number of MTC devices, which is
the main focus of this paper. The related challenges include QoS provisioning,
handling highly dynamic and sporadic MTC traffic, huge signalling overhead and
Radio Access Network (RAN) congestion. In this regard, this paper aims to
identify and analyze the involved technical issues, to review recent advances,
to highlight potential solutions and to propose new research directions. First,
starting with an overview of mMTC features and QoS provisioning issues, we
present the key enablers for mMTC in cellular networks. Along with the
highlights on the inefficiency of the legacy Random Access (RA) procedure in
the mMTC scenario, we then present the key features and channel access
mechanisms in the emerging cellular IoT standards, namely, LTE-M and NB-IoT.
Subsequently, we present a framework for the performance analysis of
transmission scheduling with the QoS support along with the issues involved in
short data packet transmission. Next, we provide a detailed overview of the
existing and emerging solutions towards addressing RAN congestion problem, and
then identify potential advantages, challenges and use cases for the
applications of emerging Machine Learning (ML) techniques in ultra-dense
cellular networks. Out of several ML techniques, we focus on the application of
low-complexity Q-learning approach in the mMTC scenarios. Finally, we discuss
some open research challenges and promising future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02939</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02939</id><created>2018-08-08</created><authors><author><keyname>Gong</keyname><forenames>Yuan</forenames></author><author><keyname>Poellabauer</keyname><forenames>Christian</forenames></author></authors><title>Towards Learning Fine-Grained Disentangled Representations from Speech</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning disentangled representations of high-dimensional data is currently
an active research area. However, compared to the field of computer vision,
less work has been done for speech processing. In this paper, we provide a
review of two representative efforts on this topic and propose the novel
concept of fine-grained disentangled speech representation learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02940</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02940</id><created>2018-06-09</created><authors><author><keyname>Samir</keyname><forenames>Yazan</forenames></author><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author></authors><title>The Effect of the Digit Slicing Architecture on the FFT Butterfly</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1808.02521,
  arXiv:1806.04570</comments><journal-ref>International Conference on Information Science Signal Processing
  and their Application. ISSPA 2010. Malaysia. pp. 802-80</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Most communications systems tend to achieve bandwidth, power and cost
efficiencies to capable to describe modulation scheme. Hence for signal
modulation, orthogonal frequency division multiplexing (OFDM) transceiver is
introduced to cover communications demand in four generation. However
high-performance Fast Fourier Transforms (FFT) as a main heart of OFDM acts
beyond the view. In order to achieve capable FFT, design, and realization of
its efficient internal structure is key issues of this research work. In this
paper implementation of a high-performance butterfly for FFT by applying digit
slicing technique is presented. The proposed design focused on the trade-off
between the speed and active silicon area for the chip implementation. The new
architecture was investigated and simulated with the MATLAB software. The
Verilog HDL code in Xilinx ISE environment was derived to describe the FFT
Butterfly functionality and was downloaded to Virtex II FPGA board.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02950</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.02950</id><created>2018-08-08</created><authors><author><keyname>Oliveira</keyname><forenames>R. S.</forenames></author><author><keyname>Cintra</keyname><forenames>R. J.</forenames></author><author><keyname>Bayer</keyname><forenames>F. M.</forenames></author><author><keyname>da Silveira</keyname><forenames>T. L. T.</forenames></author><author><keyname>Madanayake</keyname><forenames>A.</forenames></author><author><keyname>Leite</keyname><forenames>A.</forenames></author></authors><title>Low-complexity 8-point DCT Approximation Based on Angle Similarity for
  Image and Video Coding</title><categories>eess.IV cs.MM eess.SP stat.CO</categories><comments>16 pages, 12 figures, 10 tables</comments><journal-ref>Multidimensional Systems and Signal Processing, 1-32, 2018</journal-ref><doi>10.1007/s11045-018-0601-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The principal component analysis (PCA) is widely used for data decorrelation
and dimensionality reduction. However, the use of PCA may be impractical in
real-time applications, or in situations were energy and computing constraints
are severe. In this context, the discrete cosine transform (DCT) becomes a
low-cost alternative to data decorrelation. This paper presents a method to
derive computationally efficient approximations to the DCT. The proposed method
aims at the minimization of the angle between the rows of the exact DCT matrix
and the rows of the approximated transformation matrix. The resulting
transformations matrices are orthogonal and have extremely low arithmetic
complexity. Considering popular performance measures, one of the proposed
transformation matrices outperforms the best competitors in both matrix error
and coding capabilities. Practical applications in image and video coding
demonstrate the relevance of the proposed transformation. In fact, we show that
the proposed approximate DCT can outperform the exact DCT for image encoding
under certain compression ratios. The proposed transform and its direct
competitors are also physically realized as digital prototype circuits using
FPGA technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03004</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03004</id><created>2018-08-08</created><authors><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Isufi</keyname><forenames>Elvin</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Advances in Distributed Graph Filtering</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2904925</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph filters are one of the core tools in graph signal processing. A central
aspect of them is their direct distributed implementation. However, the
filtering performance is often traded with distributed communication and
computational savings. To improve this tradeoff, this work generalizes
state-of-the-art distributed graph filters to filters where every node weights
the signal of its neighbors with different values while keeping the aggregation
operation linear. This new implementation, labeled as edge-variant graph
filter, yields a significant reduction in terms of communication rounds while
preserving the approximation accuracy. In addition, we characterize the subset
of shift-invariant graph filters that can be described with edge-variant
recursions. By using a low-dimensional parametrization the proposed graph
filters provide insights in approximating linear operators through the
succession and composition of local operators, i.e., fixed support matrices,
which span applications beyond the field of graph signal processing. A set of
numerical results shows the benefits of the edge-variant filters over current
methods and illustrates their potential to a wider range of applications than
graph filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03007</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03007</id><created>2018-08-08</created><authors><author><keyname>Kubiak</keyname><forenames>Ireneusz</forenames></author><author><keyname>Loughry</keyname><forenames>Joe</forenames></author></authors><title>LED Arrays of Laser Printers as Sources of Valuable Emissions for
  Electromagnetic Penetration Process</title><categories>cs.CR eess.SP</categories><comments>11 pages, 23 figures</comments><acm-class>K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protection of information against electromagnetic eavesdropping is an
important issue. Information may be derivable from the shape of an unintended
electromagnetic signal. The resulting electromagnetic emanations can be
correlated with processing of classified information. The problem extends to
computer printers. This article presents a technical analysis of LED arrays
used in monochrome computer printers and their contribution to unintentional
electromagnetic emanations. We analysed two printers from different
manufacturers, designated $A$ and $B$. The forms of useful signals and their
dependence on parameters of printing data are presented. Analyses were based on
realistic type sizes and distribution of glyphs. Pictures were reconstructed
from received radio frequency (RF) emanations. We observed differences in
legibility of information receivable at a distance that we attribute to
different ways used by printer designers to control the LED arrays,
particularly the difference between relatively high voltage single-ended
waveforms and lower-voltage differential signals. To decode the compromising
emanations required knowledge of---or guessing---printer operating parameters
including resolution, printing speed, and paper size. The optimal RF bandwidth
for detecting individual pixels has been determined. Measurements were carried
out across differences in construction and control of the LED arrays in tested
printers, and the levels of RF emissions compared for selected operating modes
(fast, high quality, or toner saving mode) of the printing device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03050</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03050</id><created>2018-08-09</created><authors><author><keyname>Amer</keyname><forenames>Ramy</forenames></author><author><keyname>Butt</keyname><forenames>M. Majid</forenames></author><author><keyname>ElSawy</keyname><forenames>Hesham</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Kibi&#x142;da</keyname><forenames>Jacek</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author></authors><title>On Minimizing Energy Consumption for D2D Clustered Caching Networks</title><categories>cs.DC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate and solve the energy minimization problem for a clustered
device-to-device (D2D) network with cache-enabled mobile devices. Devices are
distributed according to a Poisson cluster process (PCP) and are assumed to
have a surplus memory which is exploited to proactively cache files from a
library. Devices can retrieve the requested files from their caches, from
neighboring devices in their proximity (cluster), or from the base station as a
last resort. We minimize the energy consumption of the proposed network under a
random prob- abilistic caching scheme, where files are independently cached
according to a specific probability distribution. A closed-form expression for
the D2D coverage probability is obtained. The energy consumption problem is
then formulated as a function of the caching distribution, and the optimal
probabilistic caching distribution is obtained. Results reveal that the
proposed caching distribution reduces energy consumption up to 33% as compared
to caching popular files scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03113</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03113</id><created>2018-08-09</created><authors><author><keyname>Yeh</keyname><forenames>Cheng-chieh</forenames></author><author><keyname>Hsu</keyname><forenames>Po-chun</forenames></author><author><keyname>Chou</keyname><forenames>Ju-chieh</forenames></author><author><keyname>Lee</keyname><forenames>Hung-yi</forenames></author><author><keyname>Lee</keyname><forenames>Lin-shan</forenames></author></authors><title>Rhythm-Flexible Voice Conversion without Parallel Data Using Cycle-GAN
  over Phoneme Posteriorgram Sequences</title><categories>cs.SD eess.AS</categories><comments>8 pages, 6 figures, Submitted to SLT 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaking rate refers to the average number of phonemes within some unit time,
while the rhythmic patterns refer to duration distributions for realizations of
different phonemes within different phonetic structures. Both are key
components of prosody in speech, which is different for different speakers.
Models like cycle-consistent adversarial network (Cycle-GAN) and variational
auto-encoder (VAE) have been successfully applied to voice conversion tasks
without parallel data. However, due to the neural network architectures and
feature vectors chosen for these approaches, the length of the predicted
utterance has to be fixed to that of the input utterance, which limits the
flexibility in mimicking the speaking rates and rhythmic patterns for the
target speaker. On the other hand, sequence-to-sequence learning model was used
to remove the above length constraint, but parallel training data are needed.
In this paper, we propose an approach utilizing sequence-to-sequence model
trained with unsupervised Cycle-GAN to perform the transformation between the
phoneme posteriorgram sequences for different speakers. In this way, the length
constraint mentioned above is removed to offer rhythm-flexible voice conversion
without requiring parallel data. Preliminary evaluation on two datasets showed
very encouraging results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03242</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03242</id><created>2018-08-09</created><authors><author><keyname>Zhu</keyname><forenames>Banghua</forenames></author><author><keyname>Wang</keyname><forenames>Jintao</forenames></author><author><keyname>He</keyname><forenames>Longzhuang</forenames></author><author><keyname>Song</keyname><forenames>Jian</forenames></author></authors><title>Joint Transceiver Optimization for Wireless Communication PHY with
  Convolutional Neural Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Learning has a wide application in the area of natural language
processing and image processing due to its strong ability of generalization. In
this paper, we propose a novel neural network structure for jointly optimizing
the transmitter and receiver in communication physical layer under fading
channels. We build up a convolutional autoencoder to simultaneously conduct the
role of modulation, equalization and demodulation. The proposed system is able
to design different mapping scheme from input bit sequences of arbitrary length
to constellation symbols according to different channel environments. The
simulation results show that the performance of neural network based system is
superior to traditional modulation and equalization methods in terms of time
complexity and bit error rate (BER) under fading channels. The proposed system
can also be combined with other coding techniques to further improve the
performance. Furthermore, the proposed system network is more robust to channel
variation than traditional communication methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03318</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03318</id><created>2018-07-09</created><authors><author><keyname>Haley</keyname><forenames>James</forenames></author><author><keyname>Caus</keyname><forenames>Angel Farguell</forenames></author><author><keyname>Kochanski</keyname><forenames>Adam K.</forenames></author><author><keyname>Schranz</keyname><forenames>Sher</forenames></author><author><keyname>Mandel</keyname><forenames>Jan</forenames></author></authors><title>Data Likelihood of Active Fires Satellite Detection and Applications to
  Ignition Estimation and Data Assimilation</title><categories>stat.AP cs.OH eess.IV</categories><comments>12 pages, 6 figures; VIII International Conference on Forest Fire
  Research, Coimbra, Portugal, November 2018</comments><msc-class>62F15, 65D19</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data likelihood of fire detection is the probability of the observed
detection outcome given the state of the fire spread model. We derive fire
detection likelihood of satellite data as a function of the fire arrival time
on the model grid. The data likelihood is constructed by a combination of the
burn model, the logistic regression of the active fires detections, and the
Gaussian distribution of the geolocation error. The use of the data likelihood
is then demonstrated by an estimation of the ignition point of a wildland fire
by the maximization of the likelihood of MODIS and VIIRS data over multiple
possible ignition points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03336</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03336</id><created>2018-08-09</created><authors><author><keyname>Almansouri</keyname><forenames>Hani</forenames></author><author><keyname>Venkatakrishnan</keyname><forenames>Singanallur</forenames></author><author><keyname>Bouman</keyname><forenames>Charles</forenames></author><author><keyname>Santos-Villalobos</keyname><forenames>Hector</forenames></author></authors><title>Model-Based Iterative Reconstruction for One-Sided Ultrasonic
  Non-Destructive Evaluation</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-sided ultrasonic non-destructive evaluation (UNDE) is extensively used to
characterize structures that need to be inspected and maintained from defects
and flaws that could affect the performance of power plants, such as nuclear
power plants. Most UNDE systems send acoustic pulses into the structure of
interest, measure the received waveform and use an algorithm to reconstruct the
quantity of interest. The most widely used algorithm in UNDE systems is the
synthetic aperture focusing technique (SAFT) because it produces acceptable
results in real time. A few regularized inversion techniques with linear models
have been proposed which can improve on SAFT, but they tend to make simplifying
assumptions that do not address how to obtain reconstructions from large real
data sets. In this paper, we propose a model-based iterative reconstruction
(MBIR) algorithm designed for scanning UNDE systems. To further reduce some of
the artifacts in the results, we enhance the forward model to account for the
transmitted beam profile, the occurrence of direct arrival signals, and the
correlation between scans from adjacent regions. Next, we combine the forward
model with a spatially variant prior model to account for the attenuation of
deeper regions. We also present an algorithm to jointly reconstruct
measurements from large data sets. Finally, using simulated and extensive
experimental data, we show MBIR results and demonstrate how we can improve over
SAFT as well as existing regularized inversion techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03337</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03337</id><created>2018-08-09</created><authors><author><keyname>Dittmann</keyname><forenames>Jonas</forenames></author></authors><title>Cone Beam Geometry Calibration for Micro Computed Tomography Systems
  using Arbitrary Fiducial Markers and the Relation Between Projection Matrices
  and Real Space Geometry</title><categories>eess.IV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for the determination of the projection geometry within high
resolution cone beam computed tomography systems (micro CT) based on few
fiducial markers of unknown position within the field of view is described. By
employing the projection matrix formalism commonly used in computer graphics, a
very clear presentation of the resulting self consistent calibration problem
can be given relating the sought-for matrix to observable parameters of the
markers' projections. Both an easy to implement solution procedure for both the
unknown projection matrix and the marker assembly as well as the mapping from
projection matrices to real space positions and orientations of source and
detector relative to the rotary axis will be derived.
  The separate treatment of the calibration problem in terms of projection
matrices on the one hand and the independent transformation to a more intuitive
geometry representation on the other hand proves to be very helpful also with
respect to the discussion of the ambiguities occurring in reference-free
calibration. In particular, a link between methods based on knowledge on the
sample and those based on knowledge solely on the detector geometry can be
drawn. This further provides another intuitive view on the often reported
difficulty in the estimation of the detector tilt towards the rotational axis.
  A simulation study considering a wide range of typical cone beam imaging
configurations and fiducial marker distributions with in the field of view is
performed in order to assess the noise propagation properties of the proposed
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03354</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03354</id><created>2018-08-09</created><authors><author><keyname>Sahin</keyname><forenames>Alphan</forenames></author><author><keyname>Yang</keyname><forenames>Rui</forenames></author></authors><title>Sequence-Based OOK for Orthogonal Multiplexing of Wake-up Radio Signals
  and OFDM Waveforms</title><categories>eess.SP cs.IT math.IT</categories><comments>To appear in IEEE Global Communications Conference (GLOBECOM), Abu
  Dhabi, December 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we propose an approach to constructing on-off keying (OOK)
symbols for wake-up radios (WURs) by using sequences in the frequency domain.
The proposed method enables orthogonal multiplexing of wake-up signals (WUSs)
and orthogonal frequency division multiplexing (OFDM) waveforms. We optimize
the sequences with a tractable algorithm by considering the reliability of WUSs
in fading channels. The proposed algorithm relies on an alternating
minimization technique, i.e. cyclic algorithm-new (CAN), which was originally
proposed for obtaining a unimodular sequence with good aperiodic correlation
properties. In this study, we extend CAN to generate OOK waveforms with
Manchester coding. We demonstrate the performance of four optimized sequences
and compare with state-of-the-art approaches. We show that the proposed scheme
improves the wake-up radio receiver (WURx) performance by controlling the
energy distribution in frequency domain while removing the interference-floor
at the OFDM receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03480</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03480</id><created>2018-08-10</created><authors><author><keyname>Perumpalot</keyname><forenames>Valsaraj</forenames></author><author><keyname>Drisya</keyname><forenames>G. V.</forenames></author><author><keyname>Kumar</keyname><forenames>K. Satheesh</forenames></author></authors><title>Cross-location wind speed forecasting for wind energy applications using
  machine learning based models</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread utilisation of grid-integrated wind electricity necessitates
accurate and reliable wind speed forecasting to ensure stable grid and quality
power. Machine learning algorithm based wind speed forecasting models are
getting increased attention in the literature owing to its superior ability to
learn by effectively capturing the changing patterns from the data. Most of the
reported wind forecasting models built on machine learning algorithms are
location specific and tested against data adjacent to the training data. In
this work, we develop the machine learning based wind speed forecasting models
and analyse their performance when applied to data from different cross-
locations up to a year ahead. Two distinct machine learning models based on
Support Vector Machine (SVM) and Random Forest (RF) algorithms have been
developed and tested separately for a relatively large geographical area. The
results of analysis of 1-hour forecasts obtained at various cross-locations and
points of time up to a year ahead show 80% of predictions within a Root Mean
Square Error (RMSE) of 1.5 m/s, 95% within 2.5 m/s and 98% within an RMSEof 3.5
m/s. The 75% of 2-hour predictions are within RMSE of 1.5 m/s, 16-hour
predictions within RMSE of 2.5 m / s and 48-hour predictions within RMSE of 3.5
m/s. When applied to thesame location of training data, the models generate
reliable forecasts for periods up to 22 hours, with the added advantage that
the models perform consistently throughout the year ahead horizon, independent
of the lead time from the training data. The output of the analysis is highly
promising to the wind energy industry in wind forecasting for locations where
historical wind speed data are not available for model building and training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03486</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03486</id><created>2018-08-10</created><authors><author><keyname>Xu</keyname><forenames>Ruixiong</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Xu</keyname><forenames>Zhengyuan</forenames></author></authors><title>Pulse-laser Based Long-range Non-line-of-sight Ultraviolet Communication
  with Pulse Response Position Estimation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose pulse laser-based ultra-violet communication over long distance,
such that the pulse response signals can be detected at the receiver at the
cost of low data transmission rate. We characterize the signal and achievable
performance for the pulse laser-based communication. Since the detection
performance critically depends on the pulse response position estimation, we
also propose two approaches to estimate the pulse response positions, one based
on counting the number pulses in a window, and the other based on the
correlation of pulse response shape and the number of detected photoelectrons.
It is seen that the correlation-based position estimation approach can achieve
more accurate estimation compared with the counting-based one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03506</identifier>
 <datestamp>2019-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03506</id><created>2018-08-10</created><updated>2019-03-05</updated><authors><author><keyname>Lyu</keyname><forenames>Yecheng</forenames></author><author><keyname>Bai</keyname><forenames>Lin</forenames></author><author><keyname>Huang</keyname><forenames>Xinming</forenames></author></authors><title>ChipNet: Real-Time LiDAR Processing for Drivable Region Segmentation on
  an FPGA</title><categories>eess.SP eess.IV</categories><comments>11 pages. IEEE Transactions on Circuits and Systems I: Regular Papers
  (2018)</comments><doi>10.1109/TCSI.2018.2881162</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a field-programmable gate array (FPGA) design of a
segmentation algorithm based on convolutional neural network (CNN) that can
process light detection and ranging (LiDAR) data in real-time. For autonomous
vehicles, drivable region segmentation is an essential step that sets up the
static constraints for planning tasks. Traditional drivable region segmentation
algorithms are mostly developed on camera data, so their performance is
susceptible to the light conditions and the qualities of road markings. LiDAR
sensors can obtain the 3D geometry information of the vehicle surroundings with
high precision. However, it is a computational challenge to process a large
amount of LiDAR data in real-time. In this paper, a convolutional neural
network model is proposed and trained to perform semantic segmentation using
data from the LiDAR sensor. An efficient hardware architecture is proposed and
implemented on an FPGA that can process each LiDAR scan in 17.59 ms, which is
much faster than the previous works. Evaluated using Ford and KITTI road
detection benchmarks, the proposed solution achieves both high accuracy in
performance and real-time processing in speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03549</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03549</id><created>2018-08-10</created><authors><author><keyname>Kurras</keyname><forenames>Martin</forenames></author><author><keyname>Dai</keyname><forenames>Sida</forenames></author><author><keyname>Jaeckel</keyname><forenames>Stephan</forenames></author><author><keyname>Thiele</keyname><forenames>Lars</forenames></author></authors><title>Evaluation of the Spatial Consistency Feature in the 3GPP GSCM Channel
  Model</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the development of 4G networks, Multiple-Input Multiple-Output (MIMO)
and later multiple-user MIMO became a mature part to increase the spectral
efficiency of mobile communication networks. An essential part of simultaneous
multiple-user communication is the grouping of users with complementing channel
properties. With the introduction of Base Station (BS) with large amount of
antenna ports, i.e. transceiver units, the focus in spatial precoding is moved
from uniform to heterogeneous cell coverage with changing traffic demands
throughout the cell and 3D beamforming. In order to deal with the increasing
feedback requirement for Frequency-Division Duplex (FDD) systems, concepts for
user clustering on second order statistics are suggested in both the scientific
and standardization literature. Former 3rd Generation Partnership Project
(3GPP) Geometry-based Stochastic Channel Model (GSCM) channel models lack the
required spatial correlation of small-scale fading. Since the latest release of
3GPP Geometry-based Stochastic Channel Model this issue is claimed to be solved
and hence our contribution is an evaluation of this spatial consistency
feature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03571</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03571</id><created>2018-08-10</created><updated>2019-02-05</updated><authors><author><keyname>Kellman</keyname><forenames>Michael R.</forenames></author><author><keyname>Bostan</keyname><forenames>Emrah</forenames></author><author><keyname>Repina</keyname><forenames>Nicole</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>Physics-based Learned Design: Optimized Coded-Illumination for
  Quantitative Phase Imaging</title><categories>eess.SP cs.CV</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coded-illumination can enable quantitative phase microscopy of transparent
samples with minimal hardware requirements. Intensity images are captured with
different source patterns and a non-linear phase retrieval optimization
reconstructs the image. The non-linear nature of the processing makes
optimizing the illumination pattern designs complicated. Traditional techniques
for experimental design (e.g. condition number optimization, spectral analysis)
consider only linear measurement formation models and linear reconstructions.
Deep neural networks (DNNs) can efficiently represent the non-linear process
and can be optimized over via training in an end-to-end framework. However,
DNNs typically require a large amount of training examples and parameters to
properly learn the phase retrieval process, without making use of the known
physical models. Here, we aim to use both our knowledge of the physics and the
power of machine learning together. We develop a new data-driven approach to
optimizing coded-illumination patterns for a LED array microscope for a given
phase reconstruction algorithm. Our method incorporates both the physics of the
measurement scheme and the non-linearity of the reconstruction algorithm into
the design problem. This enables efficient parameterization, which allows us to
use only a small number of training examples to learn designs that generalize
well in the experimental setting without retraining. We show experimental
results for both a well-characterized phase target and mouse fibroblast cells
using coded-illumination patterns optimized for a sparsity-based phase
reconstruction algorithm. Our learned design results using 2 measurements
demonstrate similar accuracy to Fourier Ptychography with 69 measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03630</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03630</id><created>2018-08-10</created><authors><author><keyname>Craley</keyname><forenames>Jeff</forenames></author><author><keyname>Johnson</keyname><forenames>Emily</forenames></author><author><keyname>Venkataraman</keyname><forenames>Archana</forenames></author></authors><title>A Novel Method for Epileptic Seizure Detection Using Coupled Hidden
  Markov Models</title><categories>eess.SP q-bio.NC</categories><comments>To appear in MICCAI 2018 Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel Coupled Hidden Markov Model to detect epileptic seizures
in multichannel electroencephalography (EEG) data. Our model defines a network
of seizure propagation paths to capture both the temporal and spatial evolution
of epileptic activity. To address the intractability introduced by the coupled
interactions, we derive a variational inference procedure to efficiently infer
the seizure evolution from spectral patterns in the EEG data. We validate our
model on EEG aquired under clinical conditions in the Epilepsy Monitoring Unit
of the Johns Hopkins Hospital. Using 5-fold cross validation, we demonstrate
that our model outperforms three baseline approaches which rely on a classical
detection framework. Our model also demonstrates the potential to localize
seizure onset zones in focal epilepsy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03656</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03656</id><created>2018-08-10</created><authors><author><keyname>Benzamin</keyname><forenames>Avula</forenames></author><author><keyname>Chakraborty</keyname><forenames>Chandan</forenames></author></authors><title>Detection of Hard Exudates in Retinal Fundus Images using Deep Learning</title><categories>eess.IV</categories><comments>5 Pages, 3 figures, 2 tables, International Conference on Systems,
  Computation, Automation and Networking http://icscan.in/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diabetic Retinopathy (DR) is a retinal disorder that affects the people
having diabetes mellitus for a long time (20 years). DR is one of the main
reasons for the preventable blindness all over the world. If not detected early
the patient may progress to severe stages of irreversible blindness. Lack of
Ophthalmologists poses a serious problem for the growing diabetes patients. It
is advised to develop an automated DR screening system to assist the
Ophthalmologist in decision making. Hard exudates develop when DR is present.
It is important to detect hard exudates in order to detect DR in an early
stage. Research has been done to detect hard exudates using regular image
processing techniques and Machine Learning techniques. Here, a deep learning
algorithm has been presented in this paper that detects hard exudates in fundus
images of the retina.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03705</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03705</id><created>2018-08-10</created><authors><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Unified power system analyses and models using equivalent circuit
  formulation</title><categories>eess.SP</categories><journal-ref>2016 IEEE Power &amp; Energy Society Innovative Smart Grid
  Technologies Conference (ISGT)</journal-ref><doi>10.1109/ISGT.2016.7781182</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose and demonstrate the potential for unifying models
and algorithms for the steady state and transient simulation of single-phase
and three-phase power systems. At present, disparate algorithms and models are
used for the different analyses, which can lead to inconsistencies such as the
transient analysis as time approaches infinity not matching the steady state
analysis of the same conditions. Using our equivalent circuit formulation of
the power system, we propose a methodology for forming physics-based models
that can facilitate transient, balanced power flow, and three-phase power flow
in one simulation environment. The approach is demonstrated on a three-phase
induction motor. Existing industry tools are used to validate the model and
simulation results for the different analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03711</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03711</id><created>2018-08-10</created><authors><author><keyname>Pires</keyname><forenames>Marcelo Bissi</forenames></author><author><keyname>Junior</keyname><forenames>Jos&#xe9; Jair Alves Mendes</forenames></author><author><keyname>Stevan</keyname><forenames>Sergio Luiz</forenames><suffix>Jr</suffix></author></authors><title>Development of an 8 channel sEMG wireless device based on ADS1299 with
  Virtual Instrumentation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a different approach on the use of the ADS1299 (an analog
front-end with features for electroencephalogram and electrocardiography signal
acquisition) is considered, proposing the development of a surface
electromyography (sEMG) device. The main features of the device include
simultaneous recordings of eight muscular channels, wireless transmission and
virtual instrumentation with the use of LabVIEWTM software. The proposed sEMG
device contains a specifically designed protocol to accommodate data
transmission by reducing the data size while still delivering adequate
resolution (34.33 uV), amplitude range (17.57 mV) and sampling rate (1000 Hz)
for sEMG signals. For the validation methods, a generated sine wave and a known
sEMG data were evaluated. Moreover, the muscular recordings for all the eight
channels of a human arm were successful and the results expose the isolated
contractions of the triceps and the biceps with their amplitude range and
frequency spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03715</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03715</id><created>2018-08-10</created><authors><author><keyname>Oore</keyname><forenames>Sageev</forenames></author><author><keyname>Simon</keyname><forenames>Ian</forenames></author><author><keyname>Dieleman</keyname><forenames>Sander</forenames></author><author><keyname>Eck</keyname><forenames>Douglas</forenames></author><author><keyname>Simonyan</keyname><forenames>Karen</forenames></author></authors><title>This Time with Feeling: Learning Expressive Musical Performance</title><categories>cs.SD cs.LG eess.AS</categories><comments>Includes links to urls for audio samples</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Music generation has generally been focused on either creating scores or
interpreting them. We discuss differences between these two problems and
propose that, in fact, it may be valuable to work in the space of direct $\it
performance$ generation: jointly predicting the notes $\it and$ $\it also$
their expressive timing and dynamics. We consider the significance and
qualities of the data set needed for this. Having identified both a problem
domain and characteristics of an appropriate data set, we show an LSTM-based
recurrent network model that subjectively performs quite well on this task.
Critically, we provide generated examples. We also include feedback from
professional composers and musicians about some of these examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03735</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03735</id><created>2018-08-10</created><updated>2019-10-21</updated><authors><author><keyname>Guan</keyname><forenames>Bochen</forenames></author><author><keyname>Ye</keyname><forenames>Hanrong</forenames></author><author><keyname>Liu</keyname><forenames>Hong</forenames></author><author><keyname>Sethares</keyname><forenames>William</forenames></author></authors><title>Video Logo Retrieval based on local Features</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Estimation of the frequency and duration of logos in videos is important in
the advertisement industry as a way of estimating the impact of ad purchases.
Since logos occupy only a small area in the videos, the popular methods of
image retrieval could fail. This paper develops an algorithm called Video Logo
Retrieval (VLR), which is an image-to-video retrieval algorithm based on the
spatial distribution of local image descriptors that measure the distance
between the query image (the logo) and a collection of down-sampled video
images. VLR uses local features to overcome the weakness of global
feature-based models such as convolutional neural networks (CNN). Meanwhile,
VLR is flexible and does not require training. The performance of VLR is
evaluated on two challenging open benchmark tasks (SoccerNet and Standford
I2V), and compared with other state-of-the-art logo retrieval or detection
algorithms. Overall, VLR shows significantly higher accuracy compared with the
existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03817</identifier>
 <datestamp>2018-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03817</id><created>2018-08-11</created><authors><author><keyname>Wu</keyname><forenames>Yuanxin</forenames></author><author><keyname>Cai</keyname><forenames>Qi</forenames></author><author><keyname>Truong</keyname><forenames>Tnieu-Kien</forenames></author></authors><title>Fast RodFIter for Attitude Reconstruction from Inertial Measurements</title><categories>cs.RO eess.SP</categories><comments>7 figures</comments><journal-ref>IEEE T-AES, 2018</journal-ref><doi>10.1109/TAES.2018.2866034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attitude computation is of vital importance for a variety of applications.
Based on the functional iteration of the Rodrigues vector integration equation,
the RodFIter method can be advantageously applied to analytically reconstruct
the attitude from discrete gyroscope measurements over the time interval of
interest. It is promising to produce ultra-accurate attitude reconstruction.
However, the RodFIter method imposes high computational load and does not lend
itself to onboard implementation. In this paper, a fast approach to
significantly reduce RodFIter's computation complexity is presented while
maintaining almost the same accuracy of attitude reconstruction. It
reformulates the Rodrigues vector iterative integration in terms of the
Chebyshev polynomial iteration. Due to the excellent property of Chebyshev
polynomials, the fast RodFIter is achieved by means of appropriate truncation
of Chebyshev polynomials, with provably guaranteed convergence. Moreover,
simulation results validate the speed and accuracy of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03883</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03883</id><created>2018-08-11</created><authors><author><keyname>Wei</keyname><forenames>Shengyun</forenames></author><author><keyname>Xu</keyname><forenames>Kele</forenames></author><author><keyname>Wang</keyname><forenames>Dezhi</forenames></author><author><keyname>Liao</keyname><forenames>Feifan</forenames></author><author><keyname>Wang</keyname><forenames>Huaimin</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author></authors><title>Sample Mixed-Based Data Augmentation for Domestic Audio Tagging</title><categories>cs.SD eess.AS</categories><comments>submitted to the workshop of Detection and Classification of Acoustic
  Scenes and Events 2018 (DCASE 2018), 19-20 November 2018, Surrey, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio tagging has attracted increasing attention since last decade and has
various potential applications in many fields. The objective of audio tagging
is to predict the labels of an audio clip. Recently deep learning methods have
been applied to audio tagging and have achieved state-of-the-art performance,
which provides a poor generalization ability on new data. However due to the
limited size of audio tagging data such as DCASE data, the trained models tend
to result in overfitting of the network. Previous data augmentation methods
such as pitch shifting, time stretching and adding background noise do not show
much improvement in audio tagging. In this paper, we explore the sample mixed
data augmentation for the domestic audio tagging task, including mixup,
SamplePairing and extrapolation. We apply a convolutional recurrent neural
network (CRNN) with attention module with log-scaled mel spectrum as a baseline
system. In our experiments, we achieve an state-of-the-art of equal error rate
(EER) of 0.10 on DCASE 2016 task4 dataset with mixup approach, outperforming
the baseline system without data augmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03897</identifier>
 <datestamp>2018-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03897</id><created>2018-08-12</created><authors><author><keyname>Luo</keyname><forenames>Chao</forenames></author></authors><title>Engineering and Economic Analysis for Electric Vehicle Charging
  Infrastructure --- Placement, Pricing, and Market Design</title><categories>econ.EM eess.SP</categories><comments>Doctoral Dissertation, University of Notre Dame, 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This dissertation is to study the interplay between large-scale electric
vehicle (EV) charging and the power system. We address three important issues
pertaining to EV charging and integration into the power system: (1) charging
station placement, (2) pricing policy and energy management strategy, and (3)
electricity trading market and distribution network design to facilitate
integrating EV and renewable energy source (RES) into the power system.
  For charging station placement problem, we propose a multi-stage consumer
behavior based placement strategy with incremental EV penetration rates and
model the EV charging industry as an oligopoly where the entire market is
dominated by a few charging service providers (oligopolists). The optimal
placement policy for each service provider is obtained by solving a Bayesian
game.
  For pricing and energy management of EV charging stations, we provide
guidelines for charging service providers to determine charging price and
manage electricity reserve to balance the competing objectives of improving
profitability, enhancing customer satisfaction, and reducing impact on the
power system. Two algorithms --- stochastic dynamic programming (SDP) algorithm
and greedy algorithm (benchmark algorithm) are applied to derive the pricing
and electricity procurement strategy.
  We design a novel electricity trading market and distribution network, which
supports seamless RES integration, grid to vehicle (G2V), vehicle to grid
(V2G), vehicle to vehicle (V2V), and distributed generation (DG) and storage.
We apply a sharing economy model to the electricity sector to stimulate
different entities to exchange and monetize their underutilized electricity. A
fitness-score (FS)-based supply-demand matching algorithm is developed by
considering consumer surplus, electricity network congestion, and economic
dispatch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03898</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03898</id><created>2018-08-12</created><authors><author><keyname>Bampis</keyname><forenames>Christos G.</forenames></author><author><keyname>Li</keyname><forenames>Zhi</forenames></author><author><keyname>Katsavounidis</keyname><forenames>Ioannis</forenames></author><author><keyname>Huang</keyname><forenames>Te-Yuan</forenames></author><author><keyname>Ekanadham</keyname><forenames>Chaitanya</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>Towards Perceptually Optimized End-to-end Adaptive Video Streaming</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring Quality of Experience (QoE) and integrating these measurements into
video streaming algorithms is a multi-faceted problem that fundamentally
requires the design of comprehensive subjective QoE databases and metrics. To
achieve this goal, we have recently designed the LIVE-NFLX-II database, a
highly-realistic database which contains subjective QoE responses to various
design dimensions, such as bitrate adaptation algorithms, network conditions
and video content. Our database builds on recent advancements in
content-adaptive encoding and incorporates actual network traces to capture
realistic network variations on the client device. Using our database, we study
the effects of multiple streaming dimensions on user experience and evaluate
video quality and quality of experience models. We believe that the tools
introduced here will help inspire further progress on the development of
perceptually-optimized client adaptation and video streaming strategies. The
database is publicly available at
http://live.ece.utexas.edu/research/LIVE_NFLX_II/live_nflx_plus.html.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.03944</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.03944</id><created>2018-08-12</created><authors><author><keyname>Wang</keyname><forenames>Chengjia</forenames></author><author><keyname>Macnaught</keyname><forenames>Gillian</forenames></author><author><keyname>Papanastasiou</keyname><forenames>Giorgos</forenames></author><author><keyname>MacGillivray</keyname><forenames>Tom</forenames></author><author><keyname>Newby</keyname><forenames>David</forenames></author></authors><title>Unsupervised learning for cross-domain medical image synthesis using
  deformation invariant cycle consistency networks</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the cycle-consistent generative adversarial networks (CycleGAN) has
been widely used for synthesis of multi-domain medical images. The
domain-specific nonlinear deformations captured by CycleGAN make the
synthesized images difficult to be used for some applications, for example,
generating pseudo-CT for PET-MR attenuation correction. This paper presents a
deformation-invariant CycleGAN (DicycleGAN) method using deformable
convolutional layers and new cycle-consistency losses. Its robustness dealing
with data that suffer from domain-specific nonlinear deformations has been
evaluated through comparison experiments performed on a multi-sequence brain MR
dataset and a multi-modality abdominal dataset. Our method has displayed its
ability to generate synthesized data that is aligned with the source while
maintaining a proper quality of signal compared to CycleGAN-generated data. The
proposed model also obtained comparable performance with CycleGAN when data
from the source and target domains are alignable through simple affine
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04004</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04004</id><created>2018-08-12</created><authors><author><keyname>Yang</keyname><forenames>Hong</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Multi-Cell Massive MIMO in LoS</title><categories>eess.SP</categories><comments>IEEE Global Communications Conference (GLOBECOM) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-cell Massive MIMO system in a line-of-sight (LoS)
propagation environment, for which each user is served by one base station,
with no cooperation among the base stations. Each base station knows the
channel between its service antennas and its users, and uses these channels for
precoding and decoding. Under these assumptions we derive explicit downlink and
uplink effective SINR formulas for maximum-ratio (MR) processing and
zero-forcing (ZF) processing. We also derive formulas for power control to meet
pre-determined SINR targets. A numerical example demonstrating the usage of the
derived formulas is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04032</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04032</id><created>2018-08-12</created><authors><author><keyname>Khodaparastan</keyname><forenames>M.</forenames></author><author><keyname>Mohamed</keyname><forenames>A.</forenames></author></authors><title>Modeling and Simulation of Regenerative Braking Energy in DC Electric
  Rail Systems</title><categories>eess.SP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Regenerative braking energy is the energy produced by a train during
deceleration. When a train decelerates, the motors act as generators and
produce electricity. This energy can be fed back to the third rail and consumed
by other trains accelerating nearby. If there are no nearby trains, this energy
is dumped as heat to avoid over voltage. Regenerative braking energy can be
saved by installing energy storage systems (ESS) and reused later when it is
needed. To find a suitable design, size and placement of energy storage, a good
understanding of this energy is required. The aim of this paper is to model and
simulate regenerative braking energy. The dc electric rail transit system model
introduced in this paper includes trains, substations and rail systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04108</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04108</id><created>2018-08-13</created><authors><author><keyname>Wan</keyname><forenames>Chia-Hung</forenames></author><author><keyname>Chuang</keyname><forenames>Shun-Po</forenames></author><author><keyname>Lee</keyname><forenames>Hung-Yi</forenames></author></authors><title>Towards Audio to Scene Image Synthesis using Generative Adversarial
  Network</title><categories>cs.CL cs.CV cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans can imagine a scene from a sound. We want machines to do so by using
conditional generative adversarial networks (GANs). By applying the techniques
including spectral norm, projection discriminator and auxiliary classifier,
compared with naive conditional GAN, the model can generate images with better
quality in terms of both subjective and objective evaluations. Almost
three-fourth of people agree that our model have the ability to generate images
related to sounds. By inputting different volumes of the same sound, our model
output different scales of changes based on the volumes, showing that our model
truly knows the relationship between sounds and images to some extent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04244</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04244</id><created>2018-08-08</created><updated>2019-03-25</updated><authors><author><keyname>Wu</keyname><forenames>Dongrui</forenames></author><author><keyname>Huang</keyname><forenames>Jian</forenames></author></authors><title>Affect Estimation in 3D Space Using Multi-Task Active Learning for
  Regression</title><categories>cs.LG cs.HC cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquisition of labeled training samples for affective computing is usually
costly and time-consuming, as affects are intrinsically subjective, subtle and
uncertain, and hence multiple human assessors are needed to evaluate each
affective sample. Particularly, for affect estimation in the 3D space of
valence, arousal and dominance, each assessor has to perform the evaluations in
three dimensions, which makes the labeling problem even more challenging. Many
sophisticated machine learning approaches have been proposed to reduce the data
labeling requirement in various other domains, but so far few have considered
affective computing. This paper proposes two multi-task active learning for
regression approaches, which select the most beneficial samples to label, by
considering the three affect primitives simultaneously. Experimental results on
the VAM corpus demonstrated that our optimal sample selection approaches can
result in better estimation performance than random selection and several
traditional single-task active learning approaches. Thus, they can help
alleviate the data labeling problem in affective computing, i.e., better
estimation performance can be obtained from fewer labeling queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04256</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04256</id><created>2018-08-10</created><updated>2018-09-06</updated><authors><author><keyname>You</keyname><forenames>Chenyu</forenames></author><author><keyname>Li</keyname><forenames>Guang</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoliu</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Ju</keyname><forenames>Shenghong</forenames></author><author><keyname>Zhao</keyname><forenames>Zhen</forenames></author><author><keyname>Zhang</keyname><forenames>Zhuiyang</forenames></author><author><keyname>Cong</keyname><forenames>Wenxiang</forenames></author><author><keyname>Vannier</keyname><forenames>Michael W.</forenames></author><author><keyname>Saha</keyname><forenames>Punam K.</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>CT Super-resolution GAN Constrained by the Identical, Residual, and
  Cycle Learning Ensemble(GAN-CIRCLE)</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><report-no>TMI-2019-0250</report-no><journal-ref>IEEE Transactions on Medical Imaging 2019</journal-ref><doi>10.1109/TMI.2019.2922960</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computed tomography (CT) is widely used in screening, diagnosis, and
image-guided therapy for both clinical and research purposes. Since CT involves
ionizing radiation, an overarching thrust of related technical research is
development of novel methods enabling ultrahigh quality imaging with fine
structural details while reducing the X-ray radiation. In this paper, we
present a semi-supervised deep learning approach to accurately recover
high-resolution (HR) CT images from low-resolution (LR) counterparts.
Specifically, with the generative adversarial network (GAN) as the building
block, we enforce the cycle-consistency in terms of the Wasserstein distance to
establish a nonlinear end-to-end mapping from noisy LR input images to denoised
and deblurred HR outputs. We also include the joint constraints in the loss
function to facilitate structural preservation. In this deep imaging process,
we incorporate deep convolutional neural network (CNN), residual learning, and
network in network techniques for feature extraction and restoration. In
contrast to the current trend of increasing network depth and complexity to
boost the CT imaging performance, which limit its real-world applications by
imposing considerable computational and memory overheads, we apply a parallel
$1\times1$ CNN to compress the output of the hidden layer and optimize the
number of layers and the number of filters for each convolutional layer.
Quantitative and qualitative evaluations demonstrate that our proposed model is
accurate, efficient and robust for super-resolution (SR) image restoration from
noisy LR input images. In particular, we validate our composite SR networks on
three large-scale CT datasets, and obtain promising results as compared to the
other state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04316</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04316</id><created>2018-08-13</created><updated>2018-08-15</updated><authors><author><keyname>Guo</keyname><forenames>Huayan</forenames></author><author><keyname>Zhang</keyname><forenames>Qianqian</forenames></author><author><keyname>Li</keyname><forenames>Dong</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author></authors><title>Noncoherent Multiantenna Receivers for Cognitive Backscatter System with
  Multiple RF Sources</title><categories>eess.SP</categories><comments>12 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive backscattering, an integration of cognitive radio and backsatter
modulation, is emerging as a potential candidate for green Internet of Things
(IoT). In cognitive backscatter systems, the backscatter device (BD) shares not
only the same spectrum, but also the same radio-frequency (RF) source with the
legacy system. In this paper, we investigate the signal transmission problem,
in which a basic transmission model is considered which consists of K RF
sources, one BD and one reader equipped with M antennas. A non-cooperative
scenario is considered, where there is no cooperation between the legacy
systems and the backscatter system, and no pilots are transmitted from the RF
sources or BD to the reader. The on-off keying differential modulation is
adopted to achieve noncoherent transmission. Firstly, through the capacity
analyses, we point out that high-throughput backscatter transmission can be
achieved when the number of the receive antennas satisfies M&gt;K. The Chernoff
Information (CI) is also derived to predict the detection performance. Next, we
address the signal detection problem at the reader. The optimal soft decision
(SD) and suboptimal hard decision (HD) detectors are designed based on the
maximum likelihood criterion. To tackle the non-cooperation challenge, a fully
blind channel estimation method is proposed to learn the detection-required
parameters based on clustering. Extensive numerical results verify the
effectiveness of the proposed detectors and the channel estimation method. In
addition, it is illustrated that the increase of K may not necessarily lead to
performance degradation when multiple receive antennas are exploited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04411</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04411</id><created>2018-08-13</created><authors><author><keyname>Alam</keyname><forenames>Shahnawaz</forenames></author><author><keyname>Banerjee</keyname><forenames>Rohan</forenames></author><author><keyname>Bandyopadhyay</keyname><forenames>Soma</forenames></author></authors><title>Murmur Detection Using Parallel Recurrent &amp; Convolutional Neural
  Networks</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>4 pages, Machine Learning for Medicine and Healthcare Workshop, KDD
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose a novel technique for classification of the
Murmurs in heart sound. We introduce a novel deep neural network architecture
using parallel combination of the Recurrent Neural Network (RNN) based
Bidirectional Long Short-Term Memory (BiLSTM) &amp; Convolutional Neural Network
(CNN) to learn visual and time-dependent characteristics of Murmur in PCG
waveform. Set of acoustic features are presented to our proposed deep neural
network to discriminate between Normal and Murmur class. The proposed method
was evaluated on a large dataset using 5-fold cross-validation, resulting in a
sensitivity and specificity of 96 +- 0.6 % , 100 +- 0 % respectively and F1
Score of 98 +- 0.3 %.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04443</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04443</id><created>2018-08-06</created><authors><author><keyname>Tan</keyname><forenames>Chuanqi</forenames></author><author><keyname>Sun</keyname><forenames>Fuchun</forenames></author><author><keyname>Zhang</keyname><forenames>Wenchang</forenames></author><author><keyname>Liu</keyname><forenames>Shaobo</forenames></author><author><keyname>Liu</keyname><forenames>Chunfang</forenames></author></authors><title>Spatial and Spectral Features Fusion for EEG Classification during Motor
  Imagery in BCI</title><categories>q-bio.QM eess.SP</categories><comments>International Conference on Biomedical and Health Informatics (BHI
  2017)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain computer interface (BCI) is the only way for some special patients to
communicate with the outside world and provide a direct control channel between
brain and the external devices. As a non-invasive interface, the scalp
electroencephalography (EEG) has a significant potential to be a major input
signal for future BCI systems. Traditional methods only focus on a particular
feature in the EEG signal, which limits the practical applications of EEG-based
BCI. In this paper, we propose a algorithm for EEG classification with the
ability to fuse multiple features. First, use the common spatial pattern (CSP)
as the spatial feature and use wavelet coefficient as the spectral feature.
Second, fuse these features with a fusion algorithm in orchestrate way to
improve the accuracy of classification. Our algorithms are applied to the
dataset IVa from BCI complete \uppercase\expandafter{\romannumeral3}. By
analyzing the experimental results, it is possible to conclude that we can
speculate that our algorithm perform better than traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04450</identifier>
 <datestamp>2019-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04450</id><created>2018-08-10</created><updated>2019-03-05</updated><authors><author><keyname>Lyu</keyname><forenames>Yecheng</forenames></author><author><keyname>Bai</keyname><forenames>Lin</forenames></author><author><keyname>Huang</keyname><forenames>Xinming</forenames></author></authors><title>Road Segmentation Using CNN and Distributed LSTM</title><categories>cs.CV eess.IV</categories><comments>6 pages. arXiv admin note: text overlap with arXiv:1804.05164</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automated driving systems (ADS) and advanced driver-assistance systems
(ADAS), an efficient road segmentation is necessary to perceive the drivable
region and build an occupancy map for path planning. The existing algorithms
implement gigantic convolutional neural networks (CNNs) that are
computationally expensive and time consuming. In this paper, we introduced
distributed LSTM, a neural network widely used in audio and video processing,
to process rows and columns in images and feature maps. We then propose a new
network combining the convolutional and distributed LSTM layers to solve the
road segmentation problem. In the end, the network is trained and tested in
KITTI road benchmark. The result shows that the combined structure enhances the
feature extraction and processing but takes less processing time than pure CNN
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04454</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04454</id><created>2018-08-13</created><authors><author><keyname>Cui</keyname><forenames>Qiushi</forenames></author><author><keyname>El-Arroudi</keyname><forenames>Khalil</forenames></author><author><keyname>Weng</keyname><forenames>Yang</forenames></author></authors><title>A Feature Selection Method for High Impedance Fault Detection</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High impedance fault (HIF) has been a challenging task to detect in
distribution networks. On one hand, although several types of HIF models are
available for HIF study, they are still not exhibiting satisfactory fault
waveforms. On the other hand, utilizing historical data has been a trend
recently for using machine learning methods to improve HIF detection.
Nonetheless, most proposed methodologies address the HIF issue starting with
investigating a limited group of features and can hardly provide a practical
and implementable solution. This paper, however, proposes a systematic design
of feature extraction, based on an HIF detection and classification method. For
example, features are extracted according to when, how long, and what magnitude
the fault events create. Complementary power expert information is also
integrated into the feature pools. Subsequently, we propose a ranking procedure
in the feature pool for balancing the information gain and the complexity to
avoid over-fitting. For implementing the framework, we create an HIF detection
logic from a practical perspective. Numerical methods show the proposed HIF
detector has very high dependability and security performance under multiple
fault scenarios comparing with other traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04473</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04473</id><created>2018-08-13</created><updated>2019-06-20</updated><authors><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Li</keyname><forenames>Kaipeng</forenames></author><author><keyname>Cavallaro</keyname><forenames>Joseph R.</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Decentralized Equalization with Feedforward Architectures for Massive
  MU-MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>to appear in the IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2019.2928947</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear data-detection algorithms that build on zero forcing (ZF) or linear
minimum mean-square error (L-MMSE) equalization achieve near-optimal spectral
efficiency in massive multi-user multiple-input multiple-output (MU-MIMO)
systems. Such algorithms, however, typically rely on centralized processing at
the base-station (BS) which results in (i) excessive interconnect and chip
input/output (I/O) data rates and (ii) high computational complexity.
Decentralized baseband processing (DBP) partitions the BS antenna array into
independent clusters that are associated with separate radio-frequency
circuitry and computing fabrics in order to overcome the limitations of
centralized processing. In this paper, we investigate decentralized
equalization with feedforward architectures that minimize the latency
bottlenecks of existing DBP solutions. We propose two distinct architectures
with different interconnect and I/O bandwidth requirements that fuse the local
equalization results of each cluster in a feedforward network. For both
architectures, we consider maximum ratio combining, ZF, L-MMSE, and a nonlinear
equalization algorithm that relies on approximate message passing, and we
analyze the associated post-equalization signal-to-noise-and-interference-ratio
(SINR). We provide reference implementation results on a multi graphics
processing unit (GPU) system which demonstrate that decentralized equalization
with feedforward architectures enables throughputs in the Gb/s regime and
incurs no or only a small performance loss compared to centralized solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04530</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04530</id><created>2018-08-14</created><authors><author><keyname>Sung</keyname><forenames>Junmo</forenames></author><author><keyname>Sayed</keyname><forenames>Mostafa</forenames></author><author><keyname>Elgenedy</keyname><forenames>Mahmoud</forenames></author><author><keyname>Evans</keyname><forenames>Brian L.</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author><author><keyname>Kim</keyname><forenames>Il Han</forenames></author><author><keyname>Waheed</keyname><forenames>Khurram</forenames></author></authors><title>Hybrid Powerline/Wireless Diversity for Smart Grid Communications:
  Design Challenges and Real-time Implementation</title><categories>eess.SP</categories><comments>IEEE Communications Magazine, submitted July 5, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The demand for energy is growing at an unprecedented pace that is much higher
than the energy generation capacity growth rate using both conventional and
green technologies.In particular, the electric power sector is consistently
rated among the most dynamic growth markets over all other energy markets.
Distributed (decentralized) energy generation based on renewable energy sources
is an efficient and reliable solution to serve such huge energy demand growth
[1]. However, to manage dynamic and complex distributed systems, a massive
amount of data has to be measured, collected, exchanged and processed in real
time. Smart grids manage an intelligent energy delivery network enabled two-way
communications between data concentrators operated by utility companies and
smart meters installed at the end users. In particular, dynamic power-grid
loading and peak load management are the two main driving forces for
bidirectional communications over the grid. Narrowband power line
communications (NB-PLC) and wireless communications in the unlicensed frequency
band (sub-1 GHz or 2.4 GHz) are the two main communications systems adopted to
support the growing smart grid applications. Moreover, since NB-PLC and
unlicensed wireless links experience channel and interference with markedly
different statistics, transmitting the same information signal concurrently
over both links significantly enhances the smart grid communications
reliability. In this article, we compare various diversity combining schemes
for simultaneous power line and wireless transmissions. Furthermore, we
developed a real-time testbed for the hybrid PLC/wireless system to demonstrate
the performance enhancement achieved by PLC/wireless diversity combining over a
single link performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04573</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04573</id><created>2018-08-14</created><authors><author><keyname>Chin</keyname><forenames>Hou-Man</forenames></author><author><keyname>Jain</keyname><forenames>Nitin</forenames></author><author><keyname>Zibar</keyname><forenames>Darko</forenames></author><author><keyname>Gehring</keyname><forenames>Tobias</forenames></author><author><keyname>Andersen</keyname><forenames>Ulrik L.</forenames></author></authors><title>Effect of filter shape on excess noise performance in continuous
  variable quantum key distribution with Gaussian modulation</title><categories>eess.SP quant-ph</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An attractive implementation for quantum cryptography is the continuous
variable variation, as it relies on standard telecommunication components.
Modulating the quantum signal using a Gaussian format is attractive since it
has been proven to be secure. This work investigates the effect of the roll-off
of a root raised cosine pulse shaping and matched filter on the excess noise
performance of a Gaussian modulated quantum key distribution system in a
simulated back to back configuration. Contrary to intuition, it is found that
the roll-off parameter does not significantly impact the performance of the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04659</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04659</id><created>2018-08-14</created><authors><author><keyname>Jaeckel</keyname><forenames>Stephan</forenames></author><author><keyname>Raschkowski</keyname><forenames>Leszek</forenames></author><author><keyname>Burkhardt</keyname><forenames>Frank</forenames></author><author><keyname>Thiele</keyname><forenames>Lars</forenames></author></authors><title>Efficient Sum-of-Sinusoids based Spatial Consistency for the 3GPP
  New-Radio Channel Model</title><categories>eess.SP</categories><journal-ref>2018 IEEE Globecom Workshops (GC Wkshps), Abu Dhabi, United Arab
  Emirates, 2018, pp. 1-7</journal-ref><doi>10.1109/GLOCOMW.2018.8644265</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial consistency was proposed in the 3GPP TR 38.901 channel model to
ensure that closely spaced mobile terminals have similar channels. Future
extensions of this model might incorporate mobility at both ends of the link.
This requires that all random variables in the model must be correlated in 3
(single-mobility) and up to 6 spatial dimensions (dual-mobility). Existing
filtering methods cannot be used due to the large requirements of memory and
computing time. The sum-of-sinusoids model promises to be an efficient
solution. To use it in the 3GPP channel model, we extended the existing model
to a higher number of spatial dimensions and propose a new method to calculate
the sinusoid coefficients in order to control the shape of the autocorrelation
function. The proposed method shows good results for 2, 3, and 6 dimensions and
achieves a four times better approximation accuracy compared to the existing
model. This provides a very efficient implementation of the 3GPP proposal and
enables the simulation of many communication scenarios that were thought to be
impossible to realize with geometry-based stochastic channel models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04741</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04741</id><created>2018-08-14</created><authors><author><keyname>Cameron</keyname><forenames>Karleigh J.</forenames></author><author><keyname>Pine</keyname><forenames>Samuel J.</forenames></author></authors><title>A Novel Method for Determining DOA from Far-Field TDOA or FDOA</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive source localization is often performed using time difference of
arrival (TDOA) measurements, frequency difference of arrival (FDOA)
measurements, direction of arrival (DOA) measurements, or a combination of all
of these. For a source in the far-field, DOA can be extracted from the TDOA and
FDOA measurements due to simplifications that arise in the far-field
approximation. This paper presents this relationship and the corresponding DOA
estimation method. Utilizing TDOA and FDOA measurements for computation of
signal DOA requires only a linear solve, which makes the corresponding source
localization technique very efficient. Additionally, the method provides an
inherent de-noising of receiver measurements, since they are being projected
onto the range of the receiver differencing matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04804</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04804</id><created>2018-08-14</created><authors><author><keyname>Kalyakulina</keyname><forenames>Alena I.</forenames></author><author><keyname>Yusipov</keyname><forenames>Igor I.</forenames></author><author><keyname>Moskalenko</keyname><forenames>Victor A.</forenames></author><author><keyname>Nikolskiy</keyname><forenames>Alexander V.</forenames></author><author><keyname>Kozlov</keyname><forenames>Artem A.</forenames></author><author><keyname>Zolotykh</keyname><forenames>Nikolay Yu.</forenames></author><author><keyname>Ivanchenko</keyname><forenames>Mikhail V.</forenames></author></authors><title>Finding morphology points of electrocardiographic signal waves using
  wavelet analysis</title><categories>q-bio.QM eess.SP</categories><comments>Submitted to Radiophysics and Quantum Electronics</comments><doi>10.1007/s11141-019-09929-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm has been developed for delineation of significant points of
various electrocardiographic signal (ECG) waves, taking into account
information from all available leads and providing similar or higher accuracy
in comparison with other modern technologies. The test results for the QT
database show a sensitivity above 97% when detecting ECG wave peaks and 96% for
their onsets and offsets, as well as better positive predictive value compared
to the previously known algorithms. In contrast to the previously published
algorithms, the proposed approach also allows one to determine the morphology
of waves. The segmentation mean errors of all significant points are below the
tolerances defined by the Committee of General Standards for
Electrocardiography (CSE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04841</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04841</id><created>2018-08-14</created><authors><author><keyname>Arvinte</keyname><forenames>Marius</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H.</forenames></author></authors><title>A Relax-and-Round Approach to Complex Lattice Basis Reduction</title><categories>eess.SP</categories><comments>Accepted at IEEE GLOBECOM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a relax-and-round approach combined with a greedy search strategy
for performing complex lattice basis reduction. Taking an optimization
perspective, we introduce a relaxed version of the problem that, while still
nonconvex, has an easily identifiable family of solutions. We construct a
subset of such solutions by performing a greedy search and applying a
projection operator (element-wise rounding) to enforce the original constraint.
We show that, for lattice basis reduction, such a family of solutions to the
relaxed problem is the set of unitary matrices multiplied by a real, positive
constant and propose a search strategy based on modifying the complex
eigenvalues. We apply our algorithm to lattice-reduction aided multiple-input
multiple-output (MIMO) detection and show a considerable performance gain
compared to state of the art algorithms. We perform a complexity analysis to
show that the proposed algorithm has polynomial complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04879</identifier>
 <datestamp>2019-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04879</id><created>2018-08-14</created><authors><author><keyname>Hosseinalipour</keyname><forenames>Seyyedali</forenames></author><author><keyname>Wang</keyname><forenames>Jie</forenames></author><author><keyname>Tian</keyname><forenames>Yuanzhe</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author></authors><title>Infection Analysis on Irregular Networks through Graph Signal Processing</title><categories>cs.SI eess.SP</categories><comments>13 pages, 9 figures</comments><journal-ref>IEEE Transactions on Network Science and Engineering, 2019</journal-ref><doi>10.1109/TNSE.2019.2958892</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a networked system, functionality can be seriously endangered when nodes
are infected, due to internal random failures or a contagious virus that
develops into an epidemic. Given a snapshot of the network representing the
nodes' states (infected or healthy), infection analysis refers to
distinguishing an epidemic from random failures and gathering information for
effective countermeasure design. This analysis is challenging due to irregular
network structure, heterogeneous epidemic spreading, and noisy observations.
This paper treats a network snapshot as a graph signal, and develops effective
approaches for infection analysis based on graph signal processing. For the
macro (network-level) analysis aiming to distinguish an epidemic from random
failures, 1) multiple detection metrics are defined based on the graph Fourier
transform (GFT) and neighborhood characteristics of the graph signal; 2) a new
class of graph wavelets, distance-based graph wavelets (DBGWs), are developed;
and 3) a machine learning-based framework is designed employing either the GFT
spectrum or the graph wavelet coefficients as features for infection analysis.
DBGWs also enable the micro (node-level) infection analysis, through which the
performance of epidemic countermeasures can be improved. Extensive simulations
are conducted to demonstrate the effectiveness of all the proposed algorithms
in various network settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04938</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04938</id><created>2018-08-14</created><authors><author><keyname>Wang</keyname><forenames>Xiangrong</forenames></author><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author><author><keyname>Amin</keyname><forenames>Moeness</forenames></author></authors><title>Sparse Transmit Array Design for Dual-Function Radar Communications by
  Antenna Selection</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual-function radar communications (DFRC) systems have recently been proposed
to enable the coexistence of radar and wireless communications, which in turn
alleviates the increased spectrum congestion crisis. In this paper, we consider
the problem of sparse transmit array design for DFRC systems by antenna
selection where same or different antennas are assigned to different functions.
We consider three different types of DFRC systems which implement different
simultaneous beamformers associated with single and different sparse arrays
with shared aperture. We utilize the array configuration as an additional
spatial degree of freedom (DoF) to suppress the cross-interference and
facilitate the cohabitation of the two system functions. It is shown that the
use of sparse arrays adds to improved angular resolution with well-controlled
sidelobes on DFRC system paradigm. The utilization of sparse arrays in DFRC
systems is validated using simulation examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04940</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04940</id><created>2018-08-14</created><authors><author><keyname>Wang</keyname><forenames>Xiangrong</forenames></author><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author><author><keyname>Amin</keyname><forenames>Moeness</forenames></author></authors><title>Dual-Function MIMO Radar Communications System Design Via Sparse Array
  Optimization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum congestion and competition over frequency bandwidth could be
alleviated by deploying dual-function radar-communications systems, where the
radar platform presents itself as a system of opportunity to secondary
communication functions. In this paper, we propose a new technique for
communication information embedding into the emission of multiple-input
multiple-output (MIMO) radar using sparse antenna array configurations. The
phases induced by antenna displacements in a sensor array are unique, which
makes array configuration feasible for symbol embedding. We also exploit the
fact that in a MIMO radar system, the association of independent waveforms with
the transmit antennas can change over different pulse repetition periods
without impacting the radar functionality. We show that by reconfiguring sparse
transmit array through antenna selection and reordering waveform-antenna
paring, a data rate of megabits per second can be achieved for a moderate
number of transmit antennas. To counteract practical implementation issues, we
propose a regularized antenna selection based signaling scheme. The possible
data rate is analyzed and the symbol/bit error rates are derived. Simulation
examples are provided for performance evaluations and to demonstrate the
effectiveness of proposed DFRC techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.04955</identifier>
 <datestamp>2018-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.04955</id><created>2018-08-14</created><authors><author><keyname>Han</keyname><forenames>Shuai</forenames></author><author><keyname>Tai</keyname><forenames>Xiangxue</forenames></author><author><keyname>Meng</keyname><forenames>Weixiao</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author></authors><title>Physical Layer Security Enhancement for Satellite Communication among
  Similar Channels: Relay Selection and Power Allocation</title><categories>cs.IT eess.SP math.IT</categories><comments>19 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channels of satellite communication are usually modeled as Rician fading
channels with very large Rician factor or Gaussian channels. Therefore, when a
legitimate user is close to an eavesdropping user, the legitimate channel is
approximately the same as the eavesdropping channel. The physical layer
security technology of traditional terrestrial wireless communication mainly
takes advantage of the difference be-tween the legitimate channel and the
eaves-dropping channel; thus, it is not suitable for satellite communication.
To implement secure communication in similar channels for satellite
communications, a secure communication mod-el based on collaboration of the
interference relay of the satellite physical layer is proposed. Relay selection
and power allocation are further studied to enhance the security performance of
the satellite communication system based on the model. The relay selection
standard under known instantaneous channel state information (CSI) and
statistical CSI conditions is theoreti-cally derived, thereby accomplishing
minimiza-tion of the probability of secrecy relay. In addi-tion, the power
allocation factor is optimized based on minimization of the secrecy outage
probability. Moreover, a power allocation method based on the statistical CSI
is present-ed. The secrecy outage probability performance of each relay
selection criterion and power al-location scheme are analyzed via a simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05006</identifier>
 <datestamp>2018-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05006</id><created>2018-08-15</created><updated>2018-10-25</updated><authors><author><keyname>Nakamura</keyname><forenames>Eita</forenames></author><author><keyname>Yoshii</keyname><forenames>Kazuyoshi</forenames></author></authors><title>Statistical Piano Reduction Controlling Performance Difficulty</title><categories>cs.AI cs.SD eess.AS</categories><comments>12 pages, 7 figures, version accepted to APSIPA Transactions on
  Signal and Information Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a statistical-modelling method for piano reduction, i.e.
converting an ensemble score into piano scores, that can control performance
difficulty. While previous studies have focused on describing the condition for
playable piano scores, it depends on player's skill and can change continuously
with the tempo. We thus computationally quantify performance difficulty as well
as musical fidelity to the original score, and formulate the problem as
optimization of musical fidelity under constraints on difficulty values. First,
performance difficulty measures are developed by means of probabilistic
generative models for piano scores and the relation to the rate of performance
errors is studied. Second, to describe musical fidelity, we construct a
probabilistic model integrating a prior piano-score model and a model
representing how ensemble scores are likely to be edited. An iterative
optimization algorithm for piano reduction is developed based on statistical
inference of the model. We confirm the effect of the iterative procedure; we
find that subjective difficulty and musical fidelity monotonically increase
with controlled difficulty values; and we show that incorporating sequential
dependence of pitches and fingering motion in the piano-score model improves
the quality of reduction scores in high-difficulty cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05013</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05013</id><created>2018-08-15</created><updated>2019-07-18</updated><authors><author><keyname>Simmons</keyname><forenames>Nidhi</forenames></author><author><keyname>da Silva</keyname><forenames>Carlos Rafael Nogueira</forenames></author><author><keyname>Cotton</keyname><forenames>Simon L.</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Yoo</keyname><forenames>Seong Ki</forenames></author><author><keyname>Yacoub</keyname><forenames>Michel Daoud</forenames></author></authors><title>On Shadowing the $\kappa$-$\mu$ Fading Model</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extensively investigate the way in which $\kappa$-$\mu$
fading channels can be impacted by shadowing. A family of shadowed
$\kappa$-$\mu$ fading models are introduced and classified according to whether
the underlying $\kappa$-$\mu$ fading undergoes single or double shadowing. We
discuss three types of single shadowed $\kappa$-$\mu$ model (denoted Type I to
Type III) and three types of double shadowed $\kappa$-$\mu$ model (denoted Type
I to Type III). The taxonomy of the single shadowed Type I - III models is
dependent upon whether the fading model assumes that the dominant component,
the scattered waves, or both experience shadowing. The categorization of the
double shadowed Type I - III models is dependent upon whether a) the envelope
experiences shadowing of the dominant component, which is preceded (or
succeeded) by a secondary round of shadowing (multiplicative), or b) the
dominant and scattered contributions are fluctuated by two independent
shadowing processes, or c) the scattered waves of the envelope are subject to
shadowing, which is also preceded (or succeeded) by a secondary round of
multiplicative shadowing. Although the physical definition of the examined
models make no predetermination of the statistics of the shadowing process, for
illustrative purposes, two example cases are provided for each type of single
and double shadowed model by assuming that the shadowing is shaped by a
Nakagami-$m$ random variable (RV), an inverse Nakagami-$m$ RV or their mixture.
The double shadowed $\kappa$-$\mu$ models offer remarkable flexibility as they
include the $\kappa$-$\mu$, $\eta$-$\mu$, and the various types of single
shadowed $\kappa$-$\mu$ distribution as special cases. Moreover, we demonstrate
a practical application of the double shadowed $\kappa$-$\mu$ Type I model by
applying it to channel measurements obtained for body area networks operating
at 2.45 GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05092</identifier>
 <datestamp>2019-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05092</id><created>2018-08-13</created><updated>2018-08-26</updated><authors><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author><author><keyname>Kaneko</keyname><forenames>Takuhiro</forenames></author><author><keyname>Tanaka</keyname><forenames>Kou</forenames></author><author><keyname>Hojo</keyname><forenames>Nobukatsu</forenames></author></authors><title>ACVAE-VC: Non-parallel many-to-many voice conversion with auxiliary
  classifier variational autoencoder</title><categories>stat.ML cs.LG cs.SD eess.AS</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.02169</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a non-parallel many-to-many voice conversion (VC) method
using a variant of the conditional variational autoencoder (VAE) called an
auxiliary classifier VAE (ACVAE). The proposed method has three key features.
First, it adopts fully convolutional architectures to construct the encoder and
decoder networks so that the networks can learn conversion rules that capture
time dependencies in the acoustic feature sequences of source and target
speech. Second, it uses an information-theoretic regularization for the model
training to ensure that the information in the attribute class label will not
be lost in the conversion process. With regular CVAEs, the encoder and decoder
are free to ignore the attribute class label input. This can be problematic
since in such a situation, the attribute class label will have little effect on
controlling the voice characteristics of input speech at test time. Such
situations can be avoided by introducing an auxiliary classifier and training
the encoder and decoder so that the attribute classes of the decoder outputs
are correctly predicted by the classifier. Third, it avoids producing
buzzy-sounding speech at test time by simply transplanting the spectral details
of the input speech into its converted version. Subjective evaluation
experiments revealed that this simple method worked reasonably well in a
non-parallel many-to-many speaker identity conversion task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05294</identifier>
 <datestamp>2018-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05294</id><created>2018-08-15</created><authors><author><keyname>Mohammadi</keyname><forenames>Seyed Hamidreza</forenames></author><author><keyname>Kim</keyname><forenames>Taehwan</forenames></author></authors><title>Investigation of Using Disentangled and Interpretable Representations
  for One-shot Cross-lingual Voice Conversion</title><categories>cs.SD eess.AS</categories><comments>Proceedings of Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of cross-lingual voice conversion in non-parallel speech
corpora and one-shot learning setting. Most prior work require either parallel
speech corpora or enough amount of training data from a target speaker.
However, we convert an arbitrary sentences of an arbitrary source speaker to
target speaker's given only one target speaker training utterance. To achieve
this, we formulate the problem as learning disentangled speaker-specific and
context-specific representations and follow the idea of [1] which uses
Factorized Hierarchical Variational Autoencoder (FHVAE). After training FHVAE
on multi-speaker training data, given arbitrary source and target speakers'
utterance, we estimate those latent representations and then reconstruct the
desired utterance of converted voice to that of target speaker. We investigate
the effectiveness of the approach by conducting voice conversion experiments
with varying size of training utterances and it was able to achieve reasonable
performance with even just one training utterance. We also examine the speech
representation and show that World vocoder outperforms Short-time Fourier
Transform (STFT) used in [1]. Finally, in the subjective tests, for one
language and cross-lingual voice conversion, our approach achieved
significantly better or comparable results compared to VAE-STFT and GMM
baselines in speech quality and similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05312</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05312</id><created>2018-08-15</created><authors><author><keyname>Narayanan</keyname><forenames>Arun</forenames></author><author><keyname>Misra</keyname><forenames>Ananya</forenames></author><author><keyname>Sim</keyname><forenames>Khe Chai</forenames></author><author><keyname>Pundak</keyname><forenames>Golan</forenames></author><author><keyname>Tripathi</keyname><forenames>Anshuman</forenames></author><author><keyname>Elfeky</keyname><forenames>Mohamed</forenames></author><author><keyname>Haghani</keyname><forenames>Parisa</forenames></author><author><keyname>Strohman</keyname><forenames>Trevor</forenames></author><author><keyname>Bacchiani</keyname><forenames>Michiel</forenames></author></authors><title>Toward domain-invariant speech recognition via large scale training</title><categories>cs.CL eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current state-of-the-art automatic speech recognition systems are trained to
work in specific `domains', defined based on factors like application, sampling
rate and codec. When such recognizers are used in conditions that do not match
the training domain, performance significantly drops. This work explores the
idea of building a single domain-invariant model for varied use-cases by
combining large scale training data from multiple application domains. Our
final system is trained using 162,000 hours of speech. Additionally, each
utterance is artificially distorted during training to simulate effects like
background noise, codec distortion, and sampling rates. Our results show that,
even at such a scale, a model thus trained works almost as well as those
fine-tuned to specific subsets: A single model can be robust to multiple
application domains, and variations like codecs and noise. More importantly,
such models generalize better to unseen conditions and allow for rapid
adaptation -- we show that by using as little as 10 hours of data from a new
domain, an adapted domain-invariant model can match performance of a
domain-specific model trained from scratch using 70 times as much data. We also
highlight some of the limitations of such models and areas that need addressing
in future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05335</identifier>
 <datestamp>2018-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05335</id><created>2018-08-15</created><authors><author><keyname>Korzeniowski</keyname><forenames>Filip</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Improved Chord Recognition by Combining Duration and Harmonic Language
  Models</title><categories>cs.SD cs.LG eess.AS</categories><comments>Published at 19th International Society for Music Information
  Retrieval Conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Chord recognition systems typically comprise an acoustic model that predicts
chords for each audio frame, and a temporal model that casts these predictions
into labelled chord segments. However, temporal models have been shown to only
smooth predictions, without being able to incorporate musical information about
chord progressions. Recent research discovered that it might be the low
hierarchical level such models have been applied to (directly on audio frames)
which prevents learning musical relationships, even for expressive models such
as recurrent neural networks (RNNs). However, if applied on the level of chord
sequences, RNNs indeed can become powerful chord predictors. In this paper, we
disentangle temporal models into a harmonic language model---to be applied on
chord sequences---and a chord duration model that connects the chord-level
predictions of the language model to the frame-level predictions of the
acoustic model. In our experiments, we explore the impact of each model on the
chord recognition score, and show that using harmonic language and duration
models improves the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05340</identifier>
 <datestamp>2018-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05340</id><created>2018-08-15</created><authors><author><keyname>Korzeniowski</keyname><forenames>Filip</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Genre-Agnostic Key Classification With Convolutional Neural Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>Published at the 19th International Society for Music Information
  Retrieval Conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose modifications to the model structure and training procedure to a
recently introduced Convolutional Neural Network for musical key
classification. These modifications enable the network to learn a
genre-independent model that performs better than models trained for specific
music styles, which has not been the case in existing work. We analyse this
generalisation capability on three datasets comprising distinct genres. We then
evaluate the model on a number of unseen data sets, and show its superior
performance compared to the state of the art. Finally, we investigate the
model's performance on short excerpts of audio. From these experiments, we
conclude that models need to consider the harmonic coherence of the whole piece
when classifying the local key of short segments of audio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05341</identifier>
 <datestamp>2018-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05341</id><created>2018-08-16</created><authors><author><keyname>Korzeniowski</keyname><forenames>Filip</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Automatic Chord Recognition with Higher-Order Harmonic Language
  Modelling</title><categories>cs.SD cs.LG eess.AS</categories><comments>First published in the Proceedings of the 26th European Signal
  Processing Conference (EUSIPCO-2018) in 2018, published by EURASIP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common temporal models for automatic chord recognition model chord changes on
a frame-wise basis. Due to this fact, they are unable to capture musical
knowledge about chord progressions. In this paper, we propose a temporal model
that enables explicit modelling of chord changes and durations. We then apply
N-gram models and a neural-network-based acoustic model within this framework,
and evaluate the effect of model overconfidence. Our results show that model
overconfidence plays only a minor role (but target smoothing still improves the
acoustic model), and that stronger chord language models do improve recognition
results, however their effects are small compared to other domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05344</identifier>
 <datestamp>2018-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05344</id><created>2018-08-16</created><updated>2018-08-17</updated><authors><author><keyname>Fu</keyname><forenames>Szu-Wei</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Hwang</keyname><forenames>Hsin-Te</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author></authors><title>Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model
  based on BLSTM</title><categories>cs.SD cs.AI eess.AS</categories><comments>Accepted in Interspeech2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, most of the objective speech quality assessment tools (e.g.,
perceptual evaluation of speech quality (PESQ)) are based on the comparison of
the degraded/processed speech with its clean counterpart. The need of a
&quot;golden&quot; reference considerably restricts the practicality of such assessment
tools in real-world scenarios since the clean reference usually cannot be
accessed. On the other hand, human beings can readily evaluate the speech
quality without any reference (e.g., mean opinion score (MOS) tests), implying
the existence of an objective and non-intrusive (no clean reference needed)
quality assessment mechanism. In this study, we propose a novel end-to-end,
non-intrusive speech quality evaluation model, termed Quality-Net, based on
bidirectional long short-term memory. The evaluation of utterance-level quality
in Quality-Net is based on the frame-level assessment. Frame constraints and
sensible initializations of forget gate biases are applied to learn meaningful
frame-level quality assessment from the utterance-level quality label.
Experimental results show that Quality-Net can yield high correlation to PESQ
(0.9 for the noisy speech and 0.84 for the speech processed by speech
enhancement). We believe that Quality-Net has potential to be used in a wide
variety of applications of speech signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05403</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05403</id><created>2018-08-16</created><updated>2019-06-06</updated><authors><author><keyname>Wen</keyname><forenames>Fei</forenames></author><author><keyname>Chu</keyname><forenames>Lei</forenames></author><author><keyname>Liu</keyname><forenames>Peilin</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author></authors><title>A Survey on Nonconvex Regularization Based Sparse and Low-Rank Recovery
  in Signal Processing, Statistics, and Machine Learning</title><categories>cs.IT cs.LG eess.SP math.IT stat.ML</categories><comments>22 pages</comments><journal-ref>Published in IEEE Access 2018:
  https://ieeexplore.ieee.org/abstract/document/8531588</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past decade, sparse and low-rank recovery have drawn much attention in
many areas such as signal/image processing, statistics, bioinformatics and
machine learning. To achieve sparsity and/or low-rankness inducing, the
$\ell_1$ norm and nuclear norm are of the most popular regularization penalties
due to their convexity. While the $\ell_1$ and nuclear norm are convenient as
the related convex optimization problems are usually tractable, it has been
shown in many applications that a nonconvex penalty can yield significantly
better performance. In recent, nonconvex regularization based sparse and
low-rank recovery is of considerable interest and it in fact is a main driver
of the recent progress in nonconvex and nonsmooth optimization. This paper
gives an overview of this topic in various fields in signal processing,
statistics and machine learning, including compressive sensing (CS), sparse
regression and variable selection, sparse signals separation, sparse principal
component analysis (PCA), large covariance and inverse covariance matrices
estimation, matrix completion, and robust PCA. We present recent developments
of nonconvex regularization based sparse and low-rank recovery in these fields,
addressing the issues of penalty selection, applications and the convergence of
nonconvex algorithms. Code is available at https://github.com/FWen/ncreg.git.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05410</identifier>
 <datestamp>2018-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05410</id><created>2018-08-16</created><authors><author><keyname>Koyuncu</keyname><forenames>Erdem</forenames></author><author><keyname>Zou</keyname><forenames>Xun</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Interleaving Channel Estimation and Limited Feedback for Point-to-Point
  Systems with a Large Number of Transmit Antennas</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and investigate the opportunities of multi-antenna communication
schemes whose training and feedback stages are interleaved and mutually
interacting. Specifically, unlike the traditional schemes where the transmitter
first trains all of its antennas at once and then receives a single feedback
message, we consider a scenario where the transmitter instead trains its
antennas one by one and receives feedback information immediately after
training each one of its antennas. The feedback message may ask the transmitter
to train another antenna; or, it may terminate the feedback/training phase and
provide the quantized codeword (e.g., a beamforming vector) to be utilized for
data transmission. As a specific application, we consider a multiple-input
single-output system with $t$ transmit antennas, a short-term power constraint
$P$, and target data rate $\rho$. We show that for any $t$, the same outage
probability as a system with perfect transmitter and receiver channel state
information can be achieved with a feedback rate of $R_1$ bits per channel
state and via training $R_2$ transmit antennas on average, where $R_1$ and
$R_2$ are independent of $t$, and depend only on $\rho$ and $P$. In addition,
we design variable-rate quantizers for channel coefficients to further minimize
the feedback rate of our scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05488</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05488</id><created>2018-08-15</created><updated>2019-03-04</updated><authors><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>CBinfer: Exploiting Frame-to-Frame Locality for Faster Convolutional
  Network Inference on Video Streams</title><categories>cs.CV cs.AI cs.NE eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1704.04313</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last few years have brought advances in computer vision at an amazing
pace, grounded on new findings in deep neural network construction and training
as well as the availability of large labeled datasets. Applying these networks
to images demands a high computational effort and pushes the use of
state-of-the-art networks on real-time video data out of reach of embedded
platforms. Many recent works focus on reducing network complexity for real-time
inference on embedded computing platforms. We adopt an orthogonal viewpoint and
propose a novel algorithm exploiting the spatio-temporal sparsity of pixel
changes. This optimized inference procedure resulted in an average speed-up of
9.1x over cuDNN on the Tegra X2 platform at a negligible accuracy loss of &lt;0.1%
and no retraining of the network for a semantic segmentation application.
Similarly, an average speed-up of 7.0x has been achieved for a pose detection
DNN and a reduction of 5x of the number of arithmetic operations to be
performed for object detection on static camera video surveillance data. These
throughput gains combined with a lower power consumption result in an energy
efficiency of 511 GOp/s/W compared to 70 GOp/s/W for the baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05665</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05665</id><created>2018-08-16</created><updated>2018-10-30</updated><authors><author><keyname>Sch&#xf6;nherr</keyname><forenames>Lea</forenames></author><author><keyname>Kohls</keyname><forenames>Katharina</forenames></author><author><keyname>Zeiler</keyname><forenames>Steffen</forenames></author><author><keyname>Holz</keyname><forenames>Thorsten</forenames></author><author><keyname>Kolossa</keyname><forenames>Dorothea</forenames></author></authors><title>Adversarial Attacks Against Automatic Speech Recognition Systems via
  Psychoacoustic Hiding</title><categories>cs.CR cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice interfaces are becoming accepted widely as input methods for a diverse
set of devices. This development is driven by rapid improvements in automatic
speech recognition (ASR), which now performs on par with human listening in
many tasks. These improvements base on an ongoing evolution of DNNs as the
computational core of ASR. However, recent research results show that DNNs are
vulnerable to adversarial perturbations, which allow attackers to force the
transcription into a malicious output.
  In this paper, we introduce a new type of adversarial examples based on
psychoacoustic hiding. Our attack exploits the characteristics of DNN-based ASR
systems, where we extend the original analysis procedure by an additional
backpropagation step. We use this backpropagation to learn the degrees of
freedom for the adversarial perturbation of the input signal, i.e., we apply a
psychoacoustic model and manipulate the acoustic signal below the thresholds of
human perception. To further minimize the perceptibility of the perturbations,
we use forced alignment to find the best fitting temporal alignment between the
original audio sample and the malicious target transcription. These extensions
allow us to embed an arbitrary audio input with a malicious voice command that
is then transcribed by the ASR system, with the audio signal remaining barely
distinguishable from the original signal. In an experimental evaluation, we
attack the state-of-the-art speech recognition system Kaldi and determine the
best performing parameter and analysis setup for different types of input. Our
results show that we are successful in up to 98% of cases with a computational
effort of fewer than two minutes for a ten-second audio file. Based on user
studies, we found that none of our target transcriptions were audible to human
listeners, who still understand the original speech content with unchanged
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05691</identifier>
 <datestamp>2018-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05691</id><created>2018-08-16</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Yang</keyname><forenames>Zhen</forenames></author><author><keyname>Li</keyname><forenames>Guoqing</forenames></author><author><keyname>Zhao</keyname><forenames>Dongbo</forenames></author><author><keyname>Tian</keyname><forenames>Wei</forenames></author></authors><title>Optimal Scheduling of an Isolated Microgrid with Battery Storage
  Considering Load and Renewable Generation Uncertainties</title><categories>eess.SP math.OC</categories><comments>Accepted by IEEE Transactions on Industrial Electronics, 10 pages, 10
  figures</comments><journal-ref>IEEE Transactions on Industrial Electronics 66 (2019) 1565-1575</journal-ref><doi>10.1109/TIE.2018.2840498</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By modeling the uncertainty of spinning reserves provided by energy storage
with probabilistic constraints, a new optimal scheduling mode is proposed for
minimizing the operating costs of an isolated microgrid (MG) by using
chance-constrained programming. The model is transformed into a readily
solvable mixed integer linear programming (MILP) formulation in GAMS via a
proposed discretized step transformation (DST) approach and finally solved by
applying the CPLEX solver. By properly setting the confidence levels of the
spinning reserve probability constraints, the MG operation can be achieved a
trade-off between reliability and economy. The test results on the modified
ORNL DECC lab MG test system reveal that the proposal significantly exceeds the
commonly used hybrid intelligent algorithm with much better and more stable
optimization results and significantly reduced calculation times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05762</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05762</id><created>2018-08-17</created><updated>2019-04-13</updated><authors><author><keyname>Yang</keyname><forenames>Haosen</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author><author><keyname>Shi</keyname><forenames>Xin</forenames></author><author><keyname>He</keyname><forenames>Xing</forenames></author></authors><title>Deep Learning Architecture for Voltage Stability Evaluation in Smart
  Grid based on Variational Autoencoders</title><categories>eess.SP</categories><comments>There are some mistakes in this paper, including the operation of
  AAE,the choice of indicators. And I haven't come up with a solution yet. So I
  would like to withdraw this paper. kind regards</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning, as one of the most popular rising technology, is being applied
in power industry widely and gradually. This study explored a novel application
of deep learning in voltage stability assessment based on variational
autoencoder (VAE). VAE is a novel application of variational inference which
have clear mathematical formula, it regularize latent variables in a expected
stochastic distribution. VAE have distinctive ability to obtain near P-V curve
by mere voltage data. An indicator based on VAE is proposed. For comparison and
testing, multiple data-driven indicators based on sparse stacked autoencoder
(SSAE) and adversarial autoencoder (AAE) are proposed. All of them extract
important low-dimension expression of whole sampling data, showing the
distinctive advantages of unsupervised learning [1]. A deep neural network
based on proposed index is constructed to estimate voltage stability margin
(VSM). Our methods are tested in IEEE-14, IEEE-57 and IEEE-118 bus standard
system, and compared mutually. Other experimental cases show the effect of our
approach in power grids state awareness, and the effects by limited field data.
These testing case illustrate the accuracy and effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05777</identifier>
 <datestamp>2018-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05777</id><created>2018-08-17</created><authors><author><keyname>Gharib</keyname><forenames>Shayan</forenames></author><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>&#xc7;akir</keyname><forenames>Emre</forenames></author><author><keyname>Serdyuk</keyname><forenames>Dmitriy</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Unsupervised adversarial domain adaptation for acoustic scene
  classification</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general problem in acoustic scene classification task is the mismatched
conditions between training and testing data, which significantly reduces the
performance of the developed methods on classification accuracy. As a
countermeasure, we present the first method of unsupervised adversarial domain
adaptation for acoustic scene classification. We employ a model pre-trained on
data from one set of conditions and by using data from other set of conditions,
we adapt the model in order that its output cannot be used for classifying the
set of conditions that input data belong to. We use a freely available dataset
from the DCASE 2018 challenge Task 1, subtask B, that contains data from
mismatched recording devices. We consider the scenario where the annotations
are available for the data recorded from one device, but not for the rest. Our
results show that with our model agnostic method we can achieve $\sim 10\%$
increase at the accuracy on an unseen and unlabeled dataset, while keeping
almost the same performance on the labeled dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05802</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05802</id><created>2018-08-17</created><updated>2018-09-24</updated><authors><author><keyname>Chang</keyname><forenames>Huibin</forenames></author><author><keyname>Enfedaque</keyname><forenames>Pable</forenames></author><author><keyname>Marchesini</keyname><forenames>Stefano</forenames></author></authors><title>Blind Ptychographic Phase Retrieval via Convergent Alternating Direction
  Method of Multipliers</title><categories>math.OC eess.IV</categories><comments>23 pages</comments><journal-ref>SIAM J. Imaging Sci., 12, pp. 153-185 (2019)</journal-ref><doi>10.1137/18M1188446</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ptychography has risen as a reference X-ray imaging technique: it achieves
resolutions of one billionth of a meter, macroscopic field of view, or the
capability to retrieve chemical or magnetic contrast, among other features. A
ptychographyic reconstruction is normally formulated as a blind phase retrieval
problem, where both the image (sample) and the probe (illumination) have to be
recovered from phaseless measured data. In this article we address a nonlinear
least squares model for the blind ptychography problem with constraints on the
image and the probe by maximum likelihood estimation of the Poisson noise
model. We formulate a variant model that incorporates the information of
phaseless measurements of the probe to eliminate possible artifacts. Next, we
propose a generalized alternating direction method of multipliers designed for
the proposed nonconvex models with convergence guarantee under mild conditions,
where their subproblems can be solved by fast element-wise operations.
Numerically, the proposed algorithm outperforms state-of-the-art algorithms in
both speed and image quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05870</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05870</id><created>2018-08-17</created><updated>2019-01-02</updated><authors><author><keyname>Soler</keyname><forenames>Maxime</forenames></author><author><keyname>Plainchault</keyname><forenames>M&#xe9;lanie</forenames></author><author><keyname>Conche</keyname><forenames>Bruno</forenames></author><author><keyname>Tierny</keyname><forenames>Julien</forenames></author></authors><title>Lifted Wasserstein Matcher for Fast and Robust Topology Tracking</title><categories>eess.IV cs.CG cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a robust and efficient method for tracking topological
features in time-varying scalar data. Structures are tracked based on the
optimal matching between persistence diagrams with respect to the Wasserstein
metric. This fundamentally relies on solving the assignment problem, a special
case of optimal transport, for all consecutive timesteps. Our approach relies
on two main contributions. First, we revisit the seminal assignment algorithm
by Kuhn and Munkres which we specifically adapt to the problem of matching
persistence diagrams in an efficient way. Second, we propose an extension of
the Wasserstein metric that significantly improves the geometrical stability of
the matching of domain-embedded persistence pairs. We show that this
geometrical lifting has the additional positive side-effect of improving the
assignment matrix sparsity and therefore computing time. The global framework
implements a coarse-grained parallelism by computing persistence diagrams and
finding optimal matchings in parallel for every couple of consecutive
timesteps. Critical trajectories are constructed by associating successively
matched persistence pairs over time. Merging and splitting events are detected
with a geometrical threshold in a post-processing stage. Extensive experiments
on real-life datasets show that our matching approach is an order of magnitude
faster than the seminal Munkres algorithm. Moreover, compared to a modern
approximation method, our method provides competitive runtimes while yielding
exact results. We demonstrate the utility of our global framework by extracting
critical point trajectories from various simulated time-varying datasets and
compare it to the existing methods based on associated overlaps of volumes.
Robustness to noise and temporal resolution downsampling is empirically
demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05889</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05889</id><created>2018-08-17</created><updated>2019-05-20</updated><authors><author><keyname>Svensson</keyname><forenames>Andreas</forenames></author><author><keyname>Zachariah</keyname><forenames>Dave</forenames></author><author><keyname>Stoica</keyname><forenames>Petre</forenames></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas B.</forenames></author></authors><title>Data Consistency Approach to Model Validation</title><categories>stat.ME eess.SP stat.CO stat.ML</categories><journal-ref>IEEE Access, 7(1):59788-59796, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In scientific inference problems, the underlying statistical modeling
assumptions have a crucial impact on the end results. There exist, however,
only a few automatic means for validating these fundamental modelling
assumptions. The contribution in this paper is a general criterion to evaluate
the consistency of a set of statistical models with respect to observed data.
This is achieved by automatically gauging the models' ability to generate data
that is similar to the observed data. Importantly, the criterion follows from
the model class itself and is therefore directly applicable to a broad range of
inference problems with varying data types, ranging from independent univariate
data to high-dimensional time-series. The proposed data consistency criterion
is illustrated, evaluated and compared to several well-established methods
using three synthetic and two real data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05938</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05938</id><created>2018-08-17</created><authors><author><keyname>Khodaparastan</keyname><forenames>Mahdiyeh</forenames></author><author><keyname>Mohamed</keyname><forenames>Ahmed A.</forenames></author><author><keyname>Brandauer</keyname><forenames>Werner</forenames></author></authors><title>Recuperation of Regenerative Braking Energy in Electric Rail Transit
  Systems</title><categories>eess.SP</categories><doi>10.1109/TITS.2018.2886809</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Electric rail transit systems are large consumers of energy. In trains with
regenerative braking capability, a fraction of the energy used to power a train
is regenerated during braking. This regenerated energy, if not properly
captured, is typically dumped in the form of heat to avoid overvoltage. Finding
a way to recuperate regenerative braking energy can result in economic as well
as technical merits. In this comprehensive paper, the various methods and
technologies that were proposed for regenerative energy recuperation have been
analyzed, investigated and compared. These technologies include: train
timetable optimization, energy storage systems (onboard and wayside), and
reversible substations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.05965</identifier>
 <datestamp>2018-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.05965</id><created>2018-08-17</created><updated>2018-11-21</updated><authors><author><keyname>Li</keyname><forenames>Chun-Guang</forenames></author><author><keyname>You</keyname><forenames>Chong</forenames></author><author><keyname>Vidal</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>On Geometric Analysis of Affine Sparse Subspace Clustering</title><categories>eess.SP cs.CV cs.LG</categories><comments>15 pages, 6 figures, 2 tables. To appear on IEEE Journal of Selected
  Topics in Signal Processing</comments><doi>10.1109/JSTSP.2018.2867446</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse subspace clustering (SSC) is a state-of-the-art method for segmenting
a set of data points drawn from a union of subspaces into their respective
subspaces. It is now well understood that SSC produces subspace-preserving data
affinity under broad geometric conditions but suffers from a connectivity
issue. In this paper, we develop a novel geometric analysis for a variant of
SSC, named affine SSC (ASSC), for the problem of clustering data from a union
of affine subspaces. Our contributions include a new concept called affine
independence for capturing the arrangement of a collection of affine subspaces.
Under the affine independence assumption, we show that ASSC is guaranteed to
produce subspace-preserving affinity. Moreover, inspired by the phenomenon that
the $\ell_1$ regularization no longer induces sparsity when the solution is
nonnegative, we further show that subspace-preserving recovery can be achieved
under much weaker conditions for all data points other than the extreme points
of samples from each subspace. In addition, we confirm a curious observation
that the affinity produced by ASSC may be subspace-dense---which could
guarantee the subspace-preserving affinity of ASSC to produce correct
clustering under rather weak conditions. We validate the theoretical findings
on carefully designed synthetic data and evaluate the performance of ASSC on
several real data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06045</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06045</id><created>2018-08-18</created><authors><author><keyname>Dubey</keyname><forenames>Harishchandra</forenames></author><author><keyname>Sangwan</keyname><forenames>Abhijeet</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Robust Speaker Clustering using Mixtures of von Mises-Fisher
  Distributions for Naturalistic Audio Streams</title><categories>cs.SD eess.AS</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker Diarization (i.e. determining who spoke and when?) for multi-speaker
naturalistic interactions such as Peer-Led Team Learning (PLTL) sessions is a
challenging task. In this study, we propose robust speaker clustering based on
mixture of multivariate von Mises-Fisher distributions. Our diarization
pipeline has two stages: (i) ground-truth segmentation; (ii) proposed speaker
clustering. The ground-truth speech activity information is used for extracting
i-Vectors from each speechsegment. We post-process the i-Vectors with principal
component analysis for dimension reduction followed by lengthnormalization.
Normalized i-Vectors are high-dimensional unit vectors possessing
discriminative directional characteristics. We model the normalized i-Vectors
with a mixture model consisting of multivariate von Mises-Fisher distributions.
K-means clustering with cosine distance is chosen as baseline approach. The
evaluation data is derived from: (i) CRSS-PLTL corpus; and (ii) three-meetings
subset of AMI corpus. The CRSSPLTL data contain audio recordings of PLTL
sessions which is student-led STEM education paradigm. Proposed approach is
consistently better than baseline leading to upto 44.48% and 53.68% relative
improvements for PLTL and AMI corpus, respectively. Index Terms: Speaker
clustering, von Mises-Fisher distribution, Peer-led team learning, i-Vector,
Naturalistic Audio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06155</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06155</id><created>2018-08-14</created><authors><author><keyname>Shahzad</keyname><forenames>Muhammad</forenames></author><author><keyname>Maurer</keyname><forenames>Michael</forenames></author><author><keyname>Fraundorfer</keyname><forenames>Friedrich</forenames></author><author><keyname>Wang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Buildings Detection in VHR SAR Images Using Fully Convolution Neural
  Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted publication in IEEE TGRS</comments><doi>10.1109/TGRS.2018.2864716</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the highly challenging problem of automatically
detecting man-made structures especially buildings in very high resolution
(VHR) synthetic aperture radar (SAR) images. In this context, the paper has two
major contributions: Firstly, it presents a novel and generic workflow that
initially classifies the spaceborne TomoSAR point clouds $ - $ generated by
processing VHR SAR image stacks using advanced interferometric techniques known
as SAR tomography (TomoSAR) $ - $ into buildings and non-buildings with the aid
of auxiliary information (i.e., either using openly available 2-D building
footprints or adopting an optical image classification scheme) and later back
project the extracted building points onto the SAR imaging coordinates to
produce automatic large-scale benchmark labelled (buildings/non-buildings) SAR
datasets. Secondly, these labelled datasets (i.e., building masks) have been
utilized to construct and train the state-of-the-art deep Fully Convolution
Neural Networks with an additional Conditional Random Field represented as a
Recurrent Neural Network to detect building regions in a single VHR SAR image.
Such a cascaded formation has been successfully employed in computer vision and
remote sensing fields for optical image classification but, to our knowledge,
has not been applied to SAR images. The results of the building detection are
illustrated and validated over a TerraSAR-X VHR spotlight SAR image covering
approximately 39 km$ ^2 $ $ - $ almost the whole city of Berlin $ - $ with mean
pixel accuracies of around 93.84%
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06223</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06223</id><created>2018-08-19</created><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Ezuma</keyname><forenames>Martins</forenames></author><author><keyname>Kakishimay</keyname><forenames>Yuichi</forenames></author></authors><title>Indoor Coverage Enhancement for mmWave Systems with Passive Reflectors:
  Measurements and Ray Tracing Simulations</title><categories>eess.SP physics.app-ph</categories><comments>IEEE Wireless Communications Magazine (Currently in review) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future 5G networks are expected to use millimeter wave (mmWave) frequency
bands, mainly due to the availability of large unused spectrum. However, due to
high path loss at mmWave frequencies, coverage of mmWave signals can get
severely reduced, especially for non-line-of-sight (NLOS) scenarios. In this
work, we study the use of passive metallic reflectors of different shapes/sizes
to improve mmWave signal coverage for indoor NLOS scenarios. Software defined
radio based mmWave transceiver platforms operating at 28 GHz are used for
indoor measurements. Subsequently, ray tracing (RT) simulations are carried out
in a similar environment using Remcom Wireless InSite software. The cumulative
distribution functions of the received signal strength for the RT simulations
in the area of interest are observed to be reasonably close with those obtained
from the measurements. Our measurements and RT simulations both show that there
is significant (on the order of 20 dB) power gain obtained with square metallic
reflectors, when compared to no reflector scenario for an indoor corridor. We
also observe that overall mmWave signal coverage can be improved utilizing
reflectors of different shapes and orientations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06288</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06288</id><created>2018-08-19</created><authors><author><keyname>Luong</keyname><forenames>Hieu-Thi</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Multimodal speech synthesis architecture for unsupervised speaker
  adaptation</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>Accepted for Interspeech 2018, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new architecture for speaker adaptation of
multi-speaker neural-network speech synthesis systems, in which an unseen
speaker's voice can be built using a relatively small amount of speech data
without transcriptions. This is sometimes called &quot;unsupervised speaker
adaptation&quot;. More specifically, we concatenate the layers to the audio inputs
when performing unsupervised speaker adaptation while we concatenate them to
the text inputs when synthesizing speech from text. Two new training schemes
for the new architecture are also proposed in this paper. These training
schemes are not limited to speech synthesis, other applications are suggested.
Experimental results show that the proposed model not only enables adaptation
to unseen speakers using untranscribed speech but it also improves the
performance of multi-speaker modeling and speaker adaptation using transcribed
audio files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06353</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06353</id><created>2018-08-20</created><authors><author><keyname>Li</keyname><forenames>Jiaji</forenames></author><author><keyname>Chen</keyname><forenames>Qian</forenames></author><author><keyname>Sun</keyname><forenames>Jiasong</forenames></author><author><keyname>Zhang</keyname><forenames>Jialin</forenames></author><author><keyname>Pan</keyname><forenames>Xiangpeng</forenames></author><author><keyname>Zuo</keyname><forenames>Chao</forenames></author></authors><title>Optimal illumination pattern for transport-of-intensity quantitative
  phase microscopy</title><categories>eess.IV physics.optics</categories><comments>15 pages, 8 figures</comments><doi>10.1364/OE.26.027599</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transport-of-intensity equation (TIE) is a well-established
non-interferometric phase retrieval approach, which enables quantitative phase
imaging (QPI) of transparent sample simply by measuring the intensities at
multiple axially displaced planes. Nevertheless, it still suffers from two
fundamentally limitations. First, it is quite susceptible to low-frequency
errors (such as \cloudy&quot; artifacts), which results from the poor contrast of
the phase transfer function (PTF) near the zero frequency. Second, the
reconstructed phase tends to blur under spatially low-coherent illumination,
especially when the defocus distance is beyond the near Fresnel region. Recent
studies have shown that the shape of the illumination aperture has a
significant impact on the resolution and phase reconstruction quality, and by
simply replacing the conventional circular illumination aperture with an
annular one, these two limitations can be addressed, or at least significantly
alleviated. However, the annular aperture was previously empirically designed
based on intuitive criteria related to the shape of PTF, which does not
guarantee optimality. In this work, we optimize the illumination pattern to
maximize TIE's performance based on a combined quantitative criterion for
evaluating the \goodness&quot; of an aperture. In order to make the size of the
solution search space tractable, we restrict our attention to binary coded
axis-symmetric illumination patterns only, which are easier to implement and
can generate isotropic TIE PTFs. We test the obtained optimal illumination by
imaging both a phase resolution target and HeLa cells based on a small-pitch
LED array, suggesting superior performance over other suboptimal patterns in
terms of both signal-to-noise ratio (SNR) and spatial resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06429</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06429</id><created>2018-08-20</created><authors><author><keyname>Suvorov</keyname><forenames>Dmitry</forenames></author><author><keyname>Dong</keyname><forenames>Ge</forenames></author><author><keyname>Zhukov</keyname><forenames>Roman</forenames></author></authors><title>Deep Residual Network for Sound Source Localization in the Time Domain</title><categories>cs.SD eess.AS</categories><comments>8 pages, 8 figures</comments><journal-ref>Journal of Engineering and Applied Sciences, 2018, vol. 13, no.
  13, P. 5096-5104</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This study presents a system for sound source localization in time domain
using a deep residual neural network. Data from the linear 8 channel microphone
array with 3 cm spacing is used by the network for direction estimation. We
propose to use the deep residual network for sound source localization
considering the localization task as a classification task. This study
describes the gathered dataset and developed architecture of the neural
network. We will show the training process and its result in this study. The
developed system was tested on validation part of the dataset and on new data
capture in real time. The accuracy classification of 30 m sec sound frames is
99.2%. The standard deviation of sound source localization is 4{\deg}. The
proposed method of sound source localization was tested inside of speech
recognition pipeline. Its usage decreased word error rate by 1.14% in
comparison with similar speech recognition pipeline using GCC-PHAT sound source
localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06469</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06469</id><created>2018-08-20</created><authors><author><keyname>Koutsoumpa</keyname><forenames>Christina</forenames></author><author><keyname>Keegan</keyname><forenames>Jennifer</forenames></author><author><keyname>Firmin</keyname><forenames>David</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author><author><keyname>Gillies</keyname><forenames>Duncan</forenames></author></authors><title>Translational Motion Compensation for Soft Tissue Velocity Images</title><categories>physics.med-ph cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Advancements in MRI Tissue Phase Velocity Mapping (TPM) allow for
the acquisition of higher quality velocity cardiac images providing better
assessment of regional myocardial deformation for accurate disease diagnosis,
pre-operative planning and post-operative patient surveillance. Translation of
TPM velocities from the scanner's reference coordinate system to the regional
cardiac coordinate system requires decoupling of translational motion and
motion due to myocardial deformation. Despite existing techniques for
respiratory motion compensation in TPM, there is still a remaining
translational velocity component due to the global motion of the beating heart.
To compensate for translational motion in cardiac TPM, we propose an
image-processing method, which we have evaluated on synthetic data and applied
on in vivo TPM data. Methods: Translational motion is estimated from a suitable
region of velocities automatically defined in the left-ventricular volume. The
region is generated by dilating the medial axis of myocardial masks in each
slice and the translational velocity is estimated by integration in this
region. The method was evaluated on synthetic data and in vivo data corrupted
with a translational velocity component (200% of the maximum measured
velocity). Accuracy and robustness were examined and the method was applied on
10 in vivo datasets. Results: The results from synthetic and in vivo corrupted
data show excellent performance with an estimation error less than 0.3% and
high robustness in both cases. The effectiveness of the method is confirmed
with visual observation of results from the 10 datasets. Conclusion: The
proposed method is accurate and suitable for translational motion correction of
the left ventricular velocity fields. The current method for translational
motion compensation could be applied to any annular contracting (tissue)
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06474</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06474</id><created>2018-08-17</created><updated>2018-10-30</updated><authors><author><keyname>Hsu</keyname><forenames>Yi-Te</forenames></author><author><keyname>Lin</keyname><forenames>Yu-Chen</forenames></author><author><keyname>Fu</keyname><forenames>Szu-Wei</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Kuo</keyname><forenames>Tei-Wei</forenames></author></authors><title>A study on speech enhancement using exponent-only floating point
  quantized neural network (EOFP-QNN)</title><categories>eess.AS cs.AI cs.LG cs.SD eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous studies have investigated the effectiveness of neural network
quantization on pattern classification tasks. The present study, for the first
time, investigated the performance of speech enhancement (a regression task in
speech processing) using a novel exponent-only floating-point quantized neural
network (EOFP-QNN). The proposed EOFP-QNN consists of two stages:
mantissa-quantization and exponent-quantization. In the mantissa-quantization
stage, EOFP-QNN learns how to quantize the mantissa bits of the model
parameters while preserving the regression accuracy using the least mantissa
precision. In the exponent-quantization stage, the exponent part of the
parameters is further quantized without causing any additional performance
degradation. We evaluated the proposed EOFP quantization technique on two types
of neural networks, namely, bidirectional long short-term memory (BLSTM) and
fully convolutional neural network (FCN), on a speech enhancement task.
Experimental results showed that the model sizes can be significantly reduced
(the model sizes of the quantized BLSTM and FCN models were only 18.75% and
21.89%, respectively, compared to those of the original models) while
maintaining satisfactory speech-enhancement performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06490</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06490</id><created>2018-08-16</created><authors><author><keyname>Bitar</keyname><forenames>Ahmad W.</forenames></author><author><keyname>Cheong</keyname><forenames>Loong-Fah</forenames></author><author><keyname>Ovarlez</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Target And Background Separation in Hyperspectral Imagery for Automatic
  Target Detection</title><categories>eess.IV eess.SP</categories><comments>This paper has been submitted to IEEE ICASSP'18 in October 2017 and
  got accepted for publication in 29 January 2018. The paper has been presented
  at the conference in Calgary in 18 April 2018. arXiv admin note: substantial
  text overlap with arXiv:1711.08970</comments><journal-ref>2018 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a method for separating known targets of interests
from the background in hyperspectral imagery. More precisely, we regard the
given hyperspectral image (HSI) as being made up of the sum of low-rank
background HSI and a sparse target HSI that contains the known targets based on
a pre-learned target dictionary specified by the user. Based on the proposed
method, two strategies are outlined and evaluated independently to realize the
target detection on both synthetic and real experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06495</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06495</id><created>2018-08-16</created><authors><author><keyname>Kobayashi</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Bitstream-Based JPEG Image Encryption with File-Size Preserving</title><categories>eess.IV cs.CV</categories><comments>to appear in 2018 IEEE 7th Global Conference on Consumer Electronics,
  Nara, JAPAN, 10th Oct., 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encryption scheme of JPEG images in the bitstream domain is proposed. The
proposed scheme preserves the JPEG format even after encrypting the images, and
the file size of encrypted images is the exact same as that of the original
JPEG images. Several methods for encrypting JPEG images in the bitstream domain
have been proposed. However, since some marker codes are generated or lost in
the encryption process, the file size of JPEG bitstreams is generally changed
due to the encryption operations. The proposed method inputs JPEG bitstreams
and selectively encrypts the additional bit components of the Huffman code in
the bitstreams. This feature allows us to have encrypted images with the same
data size as that recoded in the image transmission process, when JPEG images
are replaced with the encrypted ones by the hooking, so that the image
transmission are successfully carried out after the hooking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06500</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06500</id><created>2018-08-17</created><updated>2018-11-20</updated><authors><author><keyname>Haselmayr</keyname><forenames>Werner</forenames></author><author><keyname>Wiesinger</keyname><forenames>Daniel</forenames></author><author><keyname>Lunglmayr</keyname><forenames>Michael</forenames></author></authors><title>High-Accuracy and Fault Tolerant Stochastic Inner Product Design</title><categories>cs.ET eess.SP</categories><comments>This paper has been submitted to IEEE Transactions on Circuits and
  Systems II: Express Briefs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a novel inner product design for stochastic
computing. Stochastic computing is an emerging computing technique, that
encodes a number in the probability of observing a one in a random bit stream.
This leads to reduced hardware costs and high error tolerance. The proposed
inner product design is based on a two-line bipolar encoding format and applies
sequential processing of the input in a central accumulation unit. Sequential
processing significantly increases the computation accuracy, since it allows
for preliminary cancelation of carry bits. Moreover, the central accumulation
unit gives a much better scalability compared to conventional adder tree
approaches. We show that the proposed inner product design outperforms
state-of-the-art designs in terms of hardware costs for high accuracy
requirements and fault tolerance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06530</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06530</id><created>2018-08-07</created><updated>2018-08-21</updated><authors><author><keyname>Abdelreheem</keyname><forenames>Ahmed</forenames></author><author><keyname>Nor</keyname><forenames>Ahmed M.</forenames></author><author><keyname>Mubarak</keyname><forenames>Ahmed S. A.</forenames></author><author><keyname>Esmaiel</keyname><forenames>Hamada</forenames></author><author><keyname>Mohamed</keyname><forenames>Ehab Mahmoud</forenames></author></authors><title>Comparative Study on Millimeter Wave Location-Based Beamforming</title><categories>eess.SP cs.IT math.IT</categories><comments>4 pages, 2 figures, 2018 International Conference on Innovative
  Trends in Computer Engineering (ITCE)</comments><doi>10.1109/ITCE.2018.8316631</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a comparative study on millimeter wave (mmWave)
location-based analog beamforming (BF) techniques based on channel estimation.
Localization and compressive sensing (CS) effectively reduces mmWave BF
complexity and enhance the performance of mmWave system comparable to the
conventional mmWave analog BF techniques. BF techniques based on channel state
information (CSI) has high complexity in constructing mmWave channel sensing
matrix using CS. Location services based techniques highly reduce this
complexity by defining the area within which the user equipment (UE) mostly
probable to be exist. In this paper, we study the performance of mmWave
location-based BF using various location services. Where, the BF is conducted
using channel estimation based CS to estimate both the angle of departures
(AoDs) and the angle of arrivals (AoAs) of the mmWave channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06531</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06531</id><created>2018-08-07</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Fei-Yue</forenames></author></authors><title>Blockchain based Digital Asset Management System Architecture for Power
  Grid Big Data</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chinese power grid enterprises are in need for development of digital asset
management system. The characteristics of decentralization, self-trust and
self-confidence, pave a promising technical path for power grid digital assess
management and Big Data applications. This article firstly introduces the
state-of-the-art of power grid Big Data and digital asset management, and the
related issues in power grid enterprises. The solution of blockchain based
digital asset management technology and its implementation are presented in
details, followed by a discussion of their future developmental directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06532</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06532</id><created>2018-08-07</created><authors><author><keyname>Da Ros</keyname><forenames>Francesco</forenames></author><author><keyname>da Silva</keyname><forenames>Edson Porto</forenames></author><author><keyname>Zibar</keyname><forenames>Darko</forenames></author><author><keyname>Chu</keyname><forenames>Sai T.</forenames></author><author><keyname>Little</keyname><forenames>Brent E.</forenames></author><author><keyname>Morandotti</keyname><forenames>Roberto</forenames></author><author><keyname>Galili</keyname><forenames>Michael</forenames></author><author><keyname>Moss</keyname><forenames>David J.</forenames></author><author><keyname>Oxenl&#xf8;we</keyname><forenames>Leif K.</forenames></author></authors><title>Optical wavelength conversion of high bandwidth phase-encoded signals in
  a high FOM 50cm CMOS compatible waveguide</title><categories>physics.app-ph eess.SP physics.optics</categories><comments>14 pages, 8 figures, 23 references</comments><journal-ref>Applied Physics Letters Photonics Volume 2 Article 046105 (2017)</journal-ref><doi>10.1063/1.4978945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate wavelength conversion of QAM signals including 32GBd QPSK and
10GBd 16QAM in a 50cm long high index doped glass spiral waveguide. The quality
of the generated idlers over a 10nm bandwidth is sufficient to achieve a BER
performance below the HD FEC threshold (less than 3.8 x 10-3), with an OSNR
penalty of less than 0.3 dB compared to the original signal. Our results
confirm that this is a promising platform for nonlinear optical signal
processing, a result of both very low linear propagation loss (less than 0.07
dB/cm) and the large material bandgap that ensures negligible nonlinear loss at
telecom wavelengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06533</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06533</id><created>2018-08-08</created><authors><author><keyname>He</keyname><forenames>He</forenames></author><author><keyname>Wu</keyname><forenames>Dongrui</forenames></author></authors><title>Spatial Filtering for Brain Computer Interfaces: A Comparison between
  the Common Spatial Pattern and Its Variant</title><categories>eess.SP cs.HC cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electroencephalogram (EEG) is the most popular form of input for brain
computer interfaces (BCIs). However, it can be easily contaminated by various
artifacts and noise, e.g., eye blink, muscle activities, powerline noise, etc.
Therefore, the EEG signals are often filtered both spatially and temporally to
increase the signal-to-noise ratio before they are fed into a machine learning
algorithm for recognition. This paper considers spatial filtering,
particularly, the common spatial pattern (CSP) filters for EEG classification.
In binary classification, CSP seeks a set of filters to maximize the variance
for one class while minimizing it for the other. We first introduce the
traditional solution, and then a new solution based on a slightly different
objective function. We performed comprehensive experiments on motor imagery to
compare the two approaches, and found that generally the traditional CSP
solution still gives better results. We also showed that adding regularization
to the covariance matrices can improve the final classification performance, no
matter which objective function is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06535</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06535</id><created>2018-08-14</created><updated>2018-12-15</updated><authors><author><keyname>Shekhar</keyname><forenames>Aditya</forenames></author><author><keyname>Ram&#xed;rez-Elizondo</keyname><forenames>Laura</forenames></author><author><keyname>Bauer</keyname><forenames>Pavol</forenames></author></authors><title>Boundaries of Operation for Refurbished Parallel AC-DC Reconfigurable
  Links in Distribution Grids</title><categories>eess.SP</categories><comments>\c{opyright} 2018 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, including
  reprinting/republishing this material for advertising or promotional
  purposes, collecting new collected works for resale or redistribution to
  servers or lists, or reuse of any copyrighted component of this work in other
  works</comments><journal-ref>IEEE Transactions on Power Delivery, 2019</journal-ref><doi>10.1109/TPWRD.2019.2915198</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel ac-dc reconfigurable link technology can find interesting
applications in medium voltage power distribution. A given system can operate
in different configurations while maintaining equivalent capacity during (n-1)
contingencies. It is proved that within the defined operating boundaries, a
parallel ac-dc configuration has higher efficiency as compared to pure ac or
pure dc power delivery. Using sensitivity analysis, the variations in these
efficiency boundaries with power demand, power factor, grid voltages, link
lengths, conductor areas and converter efficiency is described. It is shown
that parallel ac-dc system can have smaller payback time as compared to a
purely dc power transmission for the same capacity due to lower investment cost
in converter station and superior efficiency. As compared to a purely ac
system, the payback of a refurbished parallel acdc configuration can be less
than 5 years for a 10 km, 10 kV distribution link within the specified
assumptions and operating conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06536</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06536</id><created>2018-08-15</created><authors><author><keyname>Flores</keyname><forenames>A.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Study of Set-Membership Adaptive Kernel Algorithms</title><categories>eess.SP cs.LG stat.ML</categories><comments>34 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last decade, a considerable research effort has been devoted to
developing adaptive algorithms based on kernel functions. One of the main
features of these algorithms is that they form a family of universal
approximation techniques, solving problems with nonlinearities elegantly. In
this paper, we present data-selective adaptive kernel normalized least-mean
square (KNLMS) algorithms that can increase their learning rate and reduce
their computational complexity. In fact, these methods deal with kernel
expansions, creating a growing structure also known as the dictionary, whose
size depends on the number of observations and their innovation. The algorithms
described herein use an adaptive step-size to accelerate the learning and can
offer an excellent tradeoff between convergence speed and steady state, which
allows them to solve nonlinear filtering and estimation problems with a large
number of parameters without requiring a large computational cost. The
data-selective update scheme also limits the number of operations performed and
the size of the dictionary created by the kernel expansion, saving
computational resources and dealing with one of the major problems of kernel
adaptive algorithms. A statistical analysis is carried out along with a
computational complexity analysis of the proposed algorithms. Simulations show
that the proposed KNLMS algorithms outperform existing algorithms in examples
of nonlinear system identification and prediction of a time series originating
from a nonlinear difference equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06537</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06537</id><created>2018-08-15</created><authors><author><keyname>Wang</keyname><forenames>Kun</forenames></author></authors><title>Ricean K-factor Estimation based on Channel Quality Indicator in OFDM
  Systems using Neural Network</title><categories>eess.SP cs.LG stat.ML</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ricean channel model is widely used in wireless communications to
characterize the channels with a line-of-sight path. The Ricean K factor,
defined as the ratio of direct path and scattered paths, provides a good
indication of the link quality. Most existing works estimate K factor based on
either maximum-likelihood criterion or higher-order moments, and the existing
works are targeted at K-factor estimation at receiver side. In this work, a
novel approach is proposed. Cast as a classification problem, the estimation of
K factor by neural network provides high accuracy. Moreover, the proposed
K-factor estimation is done at transmitter side for transmit processing, thus
saving the limited feedback bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06538</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06538</id><created>2018-08-16</created><authors><author><keyname>Loffeld</keyname><forenames>Otmar</forenames><affiliation>Center for Sensorsystems, University of Siegen</affiliation></author><author><keyname>Hage</keyname><forenames>Dunja Alexandra</forenames><affiliation>Center for Sensorsystems, University of Siegen</affiliation></author><author><keyname>Conde</keyname><forenames>Miguel Heredia</forenames><affiliation>Center for Sensorsystems, University of Siegen</affiliation></author><author><keyname>Wang</keyname><forenames>Ling</forenames><affiliation>Key Lab. of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics</affiliation></author></authors><title>Some New Results on l1-Minimizing Nullspace Kalman Filtering for Remote
  Sensing Applications</title><categories>eess.SP</categories><comments>Preprint of EUSAR 2018 publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes some new results on recursive l_1-minimizing by Kalman
filtering. We consider the l_1-norm as an explicit constraint, formulated as a
nonlinear observation of the state to be estimated. Interpretiing a sparse
vector to be estimated as a state which is observed from erroneous
(undersampled) measurements we can address time- and space-variant sparsity,
any kind of a priori information and also easily address nonstationary error
influences in the measurements available. Inherently in our approach we move
slightly away from the classical RIP-based approaches to a more intuitive
understanding of the structure of the nullspace which is implicitly related to
the well understood engineering concepts of deterministic and stochastic
observability in estimation theory
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06540</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06540</id><created>2018-07-28</created><authors><author><keyname>Zhang</keyname><forenames>Weite</forenames></author><author><keyname>Molaei</keyname><forenames>Ali</forenames></author><author><keyname>Heredia-Juesas</keyname><forenames>Juan</forenames></author><author><keyname>Tirado</keyname><forenames>Luis</forenames></author><author><keyname>Graham</keyname><forenames>Katherine</forenames></author><author><keyname>Bisulco</keyname><forenames>A.</forenames></author><author><keyname>Gomez-Sousa</keyname><forenames>Hipolito</forenames></author><author><keyname>Martinez-Lorenzo</keyname><forenames>Jose A.</forenames></author></authors><title>Experimental Results of a 3D Millimeter-Wave
  Compressive-Reflector-Antenna Imaging System</title><categories>eess.SP physics.app-ph</categories><comments>5 pages, 6 figures</comments><doi>10.1109/LAWP.2018.2875628</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents the first experimental results of our three-dimensional
(3D) millimeter-wave (mm-wave) Compressive-Reflector-Antenna (CRA) imaging
system. In this prototype, the CRA is 3D-printed and coated with a metallic
spray to easily introduce pseudo-random scatterers on the surface of a
traditional reflector antenna (TRA). The CRA performs a pseudo random coding of
the incident wavefront, thus adding spatial diversity in the imaging region and
enabling the effective use of compressive sensing (CS) and imaging techniques.
The CRA is fed with a multiple-input-multiple-output (MIMO) radar, which
consists of four transmitting and four receiving ports. Consequently, the
mechanical scanning parts and phase shifters, which are necessary in
conventional physical or synthetic aperture arrays, are not needed in this
system. Experimental results show the effectiveness of the prototype to perform
a successful 3D reconstruction of a T-shaped metallic target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06541</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06541</id><created>2018-07-30</created><updated>2019-04-30</updated><authors><author><keyname>Ditthapron</keyname><forenames>Apiwat</forenames></author><author><keyname>Banluesombatkul</keyname><forenames>Nannapas</forenames></author><author><keyname>Ketrat</keyname><forenames>Sombat</forenames></author><author><keyname>Chuangsuwanich</keyname><forenames>Ekapol</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Universal Joint Feature Extraction for P300 EEG Classification using
  Multi-task Autoencoder</title><categories>eess.SP</categories><journal-ref>IEEE Access 2019</journal-ref><doi>10.1109/ACCESS.2019.2919143</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of recording Electroencephalography (EEG) signals is onerous and
requires massive storage to store signals at an applicable frequency rate. In
this work, we propose the EventRelated Potential Encoder Network (ERPENet); a
multi-task autoencoder-based model, that can be applied to any ERP-related
tasks. The strength of ERPENet lies in its capability to handle various kinds
of ERP datasets and its robustness across multiple recording setups, enabling
joint training across datasets. ERPENet incorporates Convolutional Neural
Networks (CNNs) and Long Short-Term Memory (LSTM), in an autoencoder setup,
which tries to simultaneously compress the input EEG signal and extract related
P300 features into a latent vector. Here, we can infer the process for
generating the latent vector as universal joint feature extraction. The network
also includes a classification part for attended and unattended events
classification as an auxiliary task. We experimented on six different P300
datasets. The results show that the latent vector exhibits better compression
capability than the previous state-of-the-art semi-supervised autoencoder
model. For attended and unattended events classification, pre-trained weights
are adopted as initial weights and tested on unseen P300 datasets to evaluate
the adaptability of the model, which shortens the training process as compared
to using random Xavier weight initialization. At the compression rate of 6.84,
the classification accuracy outperforms conventional P300 classification
models: XdawnLDA, DeepConvNet, and EEGNet achieving 79.37% - 88.52%
classification accuracy depending on the dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06548</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06548</id><created>2018-08-07</created><updated>2019-08-13</updated><authors><author><keyname>Noda</keyname><forenames>Akihito</forenames></author><author><keyname>Shinoda</keyname><forenames>Hiroyuki</forenames></author></authors><title>Inter-IC for Wearables (I2We): Power and Data Transfer over Double-sided
  Conductive Textile</title><categories>eess.SP cs.HC physics.app-ph</categories><comments>11 pages, 16 figures, accepted for publication in IEEE TBioCAS</comments><journal-ref>IEEE Transactions on Biomedical Circuits and Systems, vol. 13, no.
  1, pp. 80-90, Feb. 2019</journal-ref><doi>10.1109/TBCAS.2018.2881219</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a power and data transfer network on a conductive fabric material
based on an existing serial communication protocol, Inter-Integrated Circuit
(I2C). We call the proposed network Inter-IC for Wearables (I2We). Continuous
dc power and I2C-formatted data are simultaneously transferred to tiny sensor
nodes distributed on a double-sided conductive textile. The textile has two
conductive sides isolated from each other and is used as a single planar
transmission line. I2C data are transferred along with dc power supply based on
frequency division multiplexing (FDM). Two carriers are modulated with the
clock (SCL) and the data (SDA) signals of I2C. A modulation and demodulation
circuit is designed to enable using off-the-shelf I2C-interfaced sensor ICs.
One significant originality of this work is that a special filter to enable
passive modulation is designed by locating its impedance poles and zeros at
appropriate frequencies. The proposed scheme enables flexible implementation of
wearable sensor systems in which multiple off-the-shelf tiny sensors are
distributed all over a wear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06549</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06549</id><created>2018-08-01</created><authors><author><keyname>Orth</keyname><forenames>P. H. Robert</forenames></author></authors><title>The Geometry of Spaceborne Synthetic Aperture Radar</title><categories>physics.hist-ph astro-ph.IM eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper defines a new coordinate system that was developed in 1977-78 for
the world's first digital synthetic aperture radar (SAR) ground processor for
images from the Seasat-A satellite. The coordinate system is for the
range-Doppler paradigm in the context of a spaceborne platform orbiting a
rotating planet. The mathematical expressions for the azimuth FM rate,
isodoppler lines, target illumination trajectories and antenna attitude
determination from Doppler centroid measurements are derived. The method for
transforming the SAR images from that SAR digital signal processor that used
these parametric inputs is also presented. The paper concludes with a report of
the measurement of the map accuracy of the resulting images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06550</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06550</id><created>2018-08-02</created><updated>2018-09-02</updated><authors><author><keyname>Singh</keyname><forenames>Pushpendra</forenames></author></authors><title>Studies on Generalized Fourier Representations and Phase Transforms</title><categories>eess.SP</categories><comments>23 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier representation (FR) is an indispensable mathematical formulation for
modeling and analysis of physical phenomenon, engineering systems and signals
in numerous applications. In this study, we present the generalized Fourier
representation (GFR) that is completely based on the FR of a signal, and
introduce the phase transform (PT) which is a special case of the GFR and a
true generalization of the Hilbert transform. We derive the PT kernel to obtain
any constant phase shift, discuss the various properties of the PT, and
demonstrate that (i) a constant phase shift in a signal corresponds to variable
time-delays in all harmonics, (ii) to obtain a constant time-delay in a signal,
one need to provide variable phase shift in all harmonics, (iii) a constant
phase shift is same as the constant time-delay only for single frequency
sinusoid. The time derivative and time integral, including fractional order, of
a signal can be obtained using the GFR. We propose to use discrete cosine
transform (DCT) based implementation to avoid end artifacts due to
discontinuities present in both end of the signal. We introduce fractional
delay of a discrete time signal using the FR, and present the fast Fourier
transform (FFT) implementation of all the above proposed representations. Using
the analytic wavelet transform (AWT), we propose wavelet phase transform (WPT)
to obtain a desired phase-shift in a signal under-analysis, and propose the two
representations of wavelet quadrature transform (WQT) which is special case of
the WPT where phase-shift is $\pi/2$ radians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06551</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06551</id><created>2018-08-02</created><authors><author><keyname>Servin</keyname><forenames>Manuel</forenames></author><author><keyname>Padilla</keyname><forenames>Moises</forenames></author><author><keyname>Choque</keyname><forenames>Ivan</forenames></author><author><keyname>Ordones</keyname><forenames>Sotero</forenames></author></authors><title>Phase-stepping algorithms for synchronous demodulation of nonlinear
  phase-shifted fringes</title><categories>eess.SP physics.optics</categories><comments>10 pages, 11 figures</comments><doi>10.1364/OE.27.005824</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard phase-stepping algorithms (PSAs) estimate the measuring phase of
linear carrier temporal-fringes with respect to a linear-reference.
Linear-carrier fringes are normally obtained using feedback, closed-loop,
optical phase-shifting devices. On the other hand, open-loop, phase-shifting
devices, usually give fringe patterns with nonlinear phase-shifts. The Fourier
spectrum of linear-carrier fringes is composed by Dirac deltas only. In
contrast, nonlinear phase-shifted fringes are wideband, spread-spectrum
signals. It is well known that using linear-phase reference PSA to demodulate
nonlinear phase-shifted fringes, one obtains an spurious-piston. The problem
with this spurious-piston, is that it may wrongly be taken as a real optical
thickness. Here we mathematically find the origin of this spurious-piston and
design nonlinear phase-stepping PSAs to cope with open-loop, nonlinear
phase-shifted interferometric fringes. We give a general theory to tailor
nonlinear phase-stepping PSAs to demodulate nonlinear phase-shifted wideband
fringes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06552</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06552</id><created>2018-08-03</created><authors><author><keyname>Tang</keyname><forenames>Xinyao</forenames></author><author><keyname>Mandal</keyname><forenames>Soumyajit</forenames></author></authors><title>Digital Communication using Synchronized Hyperchaotic Maps</title><categories>eess.SP nlin.CD</categories><comments>Paper under review (International Journal of Bifurcation and Chaos)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the analysis and practical implementation of
synchronized hyperchaotic maps for private communication of digital data. The
data is transmitted using chaotic masking and demodulated using a matched
filter (integrate and dump) receiver, which is shown to be nearly optimal in
this case. Simulation results were validated by implementing two maps on
circuit boards using high-speed discrete components. Experimental results show
a bit error rate (BER) of 2x10-6 at a bit rate of 10 kbps and a clock frequency
of 0.5 MHz, which is sufficient for high-fidelity real-time speech and image
transmission without additional error control coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06553</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06553</id><created>2018-08-08</created><authors><author><keyname>Xu</keyname><forenames>Peng-fei</forenames></author><author><keyname>Jia</keyname><forenames>Yin-jie</forenames></author><author><keyname>Wang</keyname><forenames>Zhi-jian</forenames></author></authors><title>Sliding Z Transform: Applications to convolutive blind source separation</title><categories>eess.SP</categories><comments>4 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Z Transform is a mathematical operation in signal processing, which gives
a tractable way to solve linear, constant-coefficient difference equations.
Based on the classical Z transform and inspired by the thought of sliding DFT,
a new definition of Sliding Z Transform(SZT) is introduced and deduced. Then
this method is applied to blind source separation, four simulation results are
presented to demonstrate its performance when the sliding window WIN is set. It
can directly recover time-domain sources from the convolutive mixtures with the
help of robust linear mixed blind separation algorithms(such as JADE) . It has
simple principle and good transplantation capability and can be widely applied
in various fields of digital signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06627</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06627</id><created>2018-08-20</created><authors><author><keyname>Kao</keyname><forenames>Chieh-Chi</forenames></author><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Sun</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio
  Event Detection</title><categories>cs.SD eess.AS</categories><comments>Accepted by Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Region-based Convolutional Recurrent Neural Network
(R-CRNN) for audio event detection (AED). The proposed network is inspired by
Faster-RCNN, a well known region-based convolutional network framework for
visual object detection. Different from the original Faster-RCNN, a recurrent
layer is added on top of the convolutional network to capture the long-term
temporal context from the extracted high level features. While most of the
previous works on AED generate predictions at frame level first, and then use
post-processing to predict the onset/offset timestamps of events from a
probability sequence; the proposed method generates predictions at event level
directly and can be trained end-to-end with a multitask loss, which optimizes
the classification and localization of audio events simultaneously. The
proposed method is tested on DCASE 2017 Challenge dataset. To the best of our
knowledge, R-CRNN is the best performing single-model method among all methods
without using ensembles both on development and evaluation sets. Compared to
the other region-based network for AED (R-FCN) with an event-based error rate
(ER) of 0.18 on the development set, our method reduced the ER to half.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06676</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06676</id><created>2018-08-20</created><authors><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Kao</keyname><forenames>Chieh-chi</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>A simple model for detection of rare sound events</title><categories>cs.SD eess.AS</categories><comments>Accepted by Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple recurrent model for detecting rare sound events, when the
time boundaries of events are available for training. Our model optimizes the
combination of an utterance-level loss, which classifies whether an event
occurs in an utterance, and a frame-level loss, which classifies whether each
frame corresponds to the event when it does occur. The two losses make use of a
shared vectorial representation the event, and are connected by an attention
mechanism. We demonstrate our model on Task 2 of the DCASE 2017 challenge, and
achieve competitive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06699</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06699</id><created>2018-08-20</created><authors><author><keyname>Conway</keyname><forenames>Thomas</forenames></author></authors><title>An Isolated Power Factor Corrected Power Supply Utilizing the
  Transformer Leakage Inductance</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread use of electronic devices increases the need for compact power
factor corrected power supplies. This paper describes an isolated power factor
corrected power supply that utilizes the leakage inductance of the isolation
transformer to provide boost inductor functionality. The bulk capacitor is in
the isolated part of the power supply allowing for controlled startup without
dedicated surge limiting components. A control method based on switch timing
and input/output voltage measurements is developed to jointly achieve voltage
regulation and input power factor control. A prototype design is implemented
with detailed measurements and waveforms shown to confirm the desired
functionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06719</identifier>
 <datestamp>2018-12-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06719</id><created>2018-08-20</created><updated>2018-11-05</updated><authors><author><keyname>Arik</keyname><forenames>Sercan O.</forenames></author><author><keyname>Jun</keyname><forenames>Heewoo</forenames></author><author><keyname>Diamos</keyname><forenames>Gregory</forenames></author></authors><title>Fast Spectrogram Inversion using Multi-head Convolutional Neural
  Networks</title><categories>cs.SD cs.LG eess.AS</categories><doi>10.1109/LSP.2018.2880284</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the multi-head convolutional neural network (MCNN) architecture
for waveform synthesis from spectrograms. Nonlinear interpolation in MCNN is
employed with transposed convolution layers in parallel heads. MCNN achieves
more than an order of magnitude higher compute intensity than commonly-used
iterative algorithms like Griffin-Lim, yielding efficient utilization for
modern multi-core processors, and very fast (more than 300x real-time) waveform
synthesis. For training of MCNN, we use a large-scale speech recognition
dataset and losses defined on waveforms that are related to perceptual audio
quality. We demonstrate that MCNN constitutes a very promising approach for
high-quality speech synthesis, without any iterative algorithms or
autoregression in computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06764</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06764</id><created>2018-08-21</created><authors><author><keyname>M.</keyname><forenames>Shree Prasad</forenames></author><author><keyname>Panigrahi</keyname><forenames>Trilochan</forenames></author><author><keyname>Hassan</keyname><forenames>Mahbub</forenames></author></authors><title>Energy Efficient Event Localization and Classification for Nano IoT</title><categories>eess.SP</categories><comments>6 pages, 18 Figures, accepted for publication in IEEE GLOBECOM
  Conference 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Advancements in nanotechnology promises new capabilities for Internet of
Things (IoT) to monitor extremely fine-grained events by deploying sensors as
small as a few hundred nanometers. Researchers predict that such tiny sensors
can transmit wireless data using graphene-based nano-antenna radiating in the
terahertz band (0.1-10 THz). Powering such wireless communications with
nanoscale energy supply, however, is a major challenge to overcome. In this
paper, we propose an energy efficient event monitoring framework for nano IoT
that enables nanosensors to update a remote base station about the location and
type of the detected event using only a single short pulse. Nanosensors encode
different events using different center frequencies with non overlapping half
power bandwidth over the entire terahertz band. Using uniform linear array
(ULA) antenna, the base station localizes the events by estimating the
direction of arrival of the pulse and classifies them from the center frequency
estimated by spectral centroid of the received signal. Simulation results
confirm that, from a distance of 1 meter, a 6th derivative Gaussian pulse
consuming only 1 atto Joule can achieve localization and classification
accuracies of 1.58 degree and 98.8%, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06765</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06765</id><created>2018-08-21</created><authors><author><keyname>M.</keyname><forenames>Shree Prasad</forenames></author><author><keyname>Panigrahi</keyname><forenames>Trilochan</forenames></author><author><keyname>Hassan</keyname><forenames>Mahbub</forenames></author></authors><title>Direction of Arrival and Center Frequency Estimation for Impulse Radio
  Millimeter Wave Communications</title><categories>eess.SP</categories><comments>6 pages, 35 figures, Camera Ready version, Accepted for publication
  in 2nd ACM Workshop on Millimeter Wave Networks and Sensing Systems</comments><doi>10.1145/3264492.3264503</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The 30-300GHz millimeter wave (mmWave) band is currently being pursued to
combat the rising capacity demands in 5G, WiFi, and IoT networks. Due to the
high frequency, impulse radio (IR) in this band is better suited for
positioning than other existing low-frequency bands. Besides precision
positioning, the exceptionally wide bandwidth also enables concurrent use of
multiple center frequencies in the same application, which opens up additional
avenues of information encoding in IR mmWave networks. In this paper, we
propose a new mmWave IR framework that can simultaneously detect direction of
arrival (DOA) as well as the center frequency of the transmitted pulse. Based
on the emerging graphene-based transceivers, we evaluate the performance of the
proposed framework in the higher frequency region of mmWave band (100-300GHz).
Numerical experiments demonstrate that the proposed framework can detect the
DOA of a 0.1 $\mu$Watt mmWave pulse within 1 degree of precision at 20 meters,
and classify three different center frequencies with 100% accuracy from a
distance of 10 meters. These performances could be further improved by trading
off the pulse rate of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06767</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06767</id><created>2018-08-21</created><authors><author><keyname>Sahami</keyname><forenames>Amirreza</forenames></author><author><keyname>Kouhsari</keyname><forenames>Shahram Montaser</forenames></author></authors><title>Making a Dynamic Interaction Between Two Power System Analysis Software</title><categories>eess.SP</categories><doi>10.1109/NAPS.2017.8107318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a distributed simulation based method for harmonic
resonance assessment (HRA) in multi-area large-scale power systems. Further
consideration is devoted to the early harmonic frequency-scan formulation to
shape them into a Bordered Blocked Diagonal Form (BBDF), which is suitable for
parallel processing. The proposed algorithm (BBDF) allows operator of each area
of an interconnected system to independently conduct the HRA. A large-change
sensitivity based approach is then handled in a secure platform to apply the
effects of whole network to each single area. The introduced decentralized HRA
is capable to find the exact values as those of the interconnected system
through TCP/IP communication media. The developed method is successfully
implemented in an existing software package and applied to IEEE 14-bus harmonic
test system, followed by a discussion on results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06768</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06768</id><created>2018-08-21</created><authors><author><keyname>Geraee</keyname><forenames>S.</forenames></author><author><keyname>Shafiei</keyname><forenames>M.</forenames></author><author><keyname>Sahami</keyname><forenames>A. R.</forenames></author><author><keyname>Alavi</keyname><forenames>S.</forenames></author></authors><title>Position Sensor-less and Adaptive Speed Design for Controlling
  Brush-less DC Motor Drives</title><categories>cs.SY eess.SP</categories><doi>10.1109/NAPS.2017.8107246</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for direct torque control of Brushless DC (BLDC)
motors. Evaluating the trapezium of back-EMF is needed, and is done via a
sliding mode observer employing just one measurement of stator current. The
effect of the proposed estimation algorithm is reducing the impact of switching
noise and consequently eliminating the required filter. Furthermore, to
overcome the uncertainties related to BLDC motors, Recursive Least Square (RLS)
is regarded as a real-time estimator of inertia and viscous damping
coefficients of the BLDC motor. By substituting the estimated load torque in
mechanical dynamic equations, the rotor speed can be calculated. Also, to
increase the robustness and decrease the rise time of the system, Modified
Model Reference Adaptive System (MMRAS) is applied in order to design a new
speed controller. Simulation results confirm the validity of this recommended
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06942</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06942</id><created>2018-08-20</created><updated>2019-06-04</updated><authors><author><keyname>Paulino</keyname><forenames>Ignacio Francisco Ram&#xed;rez</forenames></author></authors><title>PACO: Global Signal Restoration via PAtch COnsensus</title><categories>eess.SP cs.DC cs.LG math.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many signal processing algorithms break the target signal into overlapping
segments (also called windows, or patches), process them separately, and then
stitch them back into place to produce a unified output. At the overlaps, the
final value of those samples that are estimated more than once needs to be
decided in some way. Averaging, the simplest approach, tends to produce blurred
results. Significant work has been devoted to this issue in recent years:
several works explore the idea of a weighted average of the overlapped patches
and/or pixels; a more recent approach is to promote agreement (consensus)
between the patches at their intersections. This work investigates the case
where consensus is imposed as a hard constraint on the restoration problem.
This leads to a general framework applicable to all sorts of signals, problems,
decomposition strategies, and featuring a number of theoretical and practical
advantages over other similar methods. The framework itself consists of a
general optimization problem and a simple and efficient \admm-based algorithm
for solving it. We also show that the consensus step of the algorithm, which is
the main bottleneck of similar methods, can be solved efficiently and easily
for any arbitrary patch decomposition scheme. As an example of the potential of
our framework, we propose a method for filling missing samples (inpainting)
which can be applied to signals of any dimension, and show its effectiveness on
audio, image and video signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06962</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06962</id><created>2018-08-01</created><authors><author><keyname>Khomchuk</keyname><forenames>Peter</forenames></author><author><keyname>Tuladhar</keyname><forenames>Saurav R</forenames></author><author><keyname>Sivananthan</keyname><forenames>Siva</forenames></author></authors><title>Predicting passenger loading level on a train car: A Bayesian approach</title><categories>eess.SP cs.SY</categories><comments>Work supported by Phase I SBIR grant from the Volpe National
  Transportation Systems Center</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowding in train cars is increasingly a major concern for transit agencies.
From the perspective of the passengers and the transit agencies, overcrowding
of the train cars has several negative consequences such as: (i) extended
duration of passengers boarding and alighting which leads to longer dwell
times, (ii) subsequent disruption of the headway and the schedule, and (iii)
passenger dissatisfaction (e.g. increased stress and lack of privacy).
Moreover, overcrowding during peak service hours also indicates inadequate
infrastructure to meet the passenger demands. Realizing the importance of the
crowding issue, transit agencies have developed measures to assess the crowding
levels. The Transit Capacity and Quality of Service Manual provides guidelines
on thresholds for crowding in transit systems in the United States.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06971</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06971</id><created>2018-08-21</created><authors><author><keyname>Wang</keyname><forenames>Xiaoyi</forenames></author><author><keyname>Deck-L&#xe9;ger</keyname><forenames>Zo&#xe9;-Lise</forenames></author><author><keyname>Zou</keyname><forenames>Lianfeng</forenames></author><author><keyname>Aza&#xf1;a</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Caloz</keyname><forenames>Christophe</forenames></author></authors><title>Microwave Hilbert Transformer and its Applications in Real-time Analog
  Processing (RAP)</title><categories>eess.SP</categories><doi>10.1109/TMTT.2019.2905596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A microwave Hilbert transformer is introduced as a new component for
Real-time Analog Processing (RAP). In contrast to its optical counterpart, that
resort to optical fiber gratings, this Hilbert transformer is based on the
combination of a branch-line coupler and a loop resonator. The transfer
function of the transformer is derived using signal flow graphs, and two
figures of merits are introduced to effectively characterize the device: the
rotated phase and the transition bandwidth. Moreover, a detailed physical
explanation of its physical operation is given, using both a steady-state
regime perspective and a transient regime perspective. The microwave RAP
Hilbert transformer is demonstrated experimentally, and demonstrated in three
applications: edge detection, peak suppression and single sideband modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.06982</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.06982</id><created>2018-08-21</created><authors><author><keyname>Zhong</keyname><forenames>Yuncheng</forenames></author><author><keyname>Vinogradskiy</keyname><forenames>Yevgeniy</forenames></author><author><keyname>Chen</keyname><forenames>Liyuan</forenames></author><author><keyname>Myziuk</keyname><forenames>Nick</forenames></author><author><keyname>Castillo</keyname><forenames>Richard</forenames></author><author><keyname>Castillo</keyname><forenames>Edward</forenames></author><author><keyname>Guerrero</keyname><forenames>Thomas</forenames></author><author><keyname>Jiang</keyname><forenames>Steve</forenames></author><author><keyname>Wang</keyname><forenames>Jing</forenames></author></authors><title>Deriving ventilation imaging from 4DCT by deep convolutional neural
  network</title><categories>physics.med-ph eess.IV</categories><doi>10.1002/mp.13421</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Functional imaging is emerging as an important tool for lung cancer
treatment planning and evaluation. Compared with traditional methods such as
nuclear medicine ventilation-perfusion (VQ), positron emission tomography
(PET), single photon emission computer tomography (SPECT), or magnetic
resonance imaging (MRI), which use contrast agents to form 2D or 3D functional
images, ventilation imaging obtained from 4DCT lung images is convenient and
cost-effective because of its availability during radiation treatment planning.
Current methods of obtaining ventilation images from 4DCT lung images involve
deformable image registration (DIR) and a density (HU) change-based algorithm
(DIR/HU); therefore the resulting ventilation images are sensitive to the
selection of DIR algorithms. Methods: We propose a deep convolutional neural
network (CNN)-based method to derive the ventilation images from 4DCT directly
without explicit DIR, thereby improving consistency and accuracy of ventilation
images. A total of 82 sets of 4DCT and ventilation images from patients with
lung cancer were studied using this method. Results: The predicted images were
comparable to the label images of the test data. The similarity index and
correlation coefficient averaged over the ten-fold cross validation were
0.883+-0.034 and 0.878+-0.028, respectively. Conclusions: The results
demonstrate that deep CNN can generate ventilation imaging from 4DCT without
explicit deformable image registration, reducing the associated uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07017</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07017</id><created>2018-08-21</created><authors><author><keyname>Yahya</keyname><forenames>Muhammad</forenames></author><author><keyname>Shah</keyname><forenames>Jawad Ali</forenames></author><author><keyname>Warsi</keyname><forenames>Arif</forenames></author><author><keyname>Kadir</keyname><forenames>Kushsairy</forenames></author><author><keyname>Khan</keyname><forenames>Sheroz</forenames></author><author><keyname>Izani</keyname><forenames>M</forenames></author></authors><title>Real Time Elbow Angle Estimation Using Single RGB Camera</title><categories>cs.CV eess.IV</categories><comments>10 pages, 7 figures, 1 table, jounal</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The use of motion capture has increased from last decade in a varied spectrum
of applications like film special effects, controlling games and robots,
rehabilitation system, animations etc. The current human motion capture
techniques use markers, structured environment, and high resolution cameras in
a dedicated environment. Because of rapid movement, elbow angle estimation is
observed as the most difficult problem in human motion capture system. In this
paper, we take elbow angle estimation as our research subject and propose a
novel, markerless and cost-effective solution that uses RGB camera for
estimating elbow angle in real time using part affinity field. We have
recruited five (5) participants to perform cup to mouth movement and at the
same time measured the angle by both RGB camera and Microsoft Kinect. The
experimental results illustrate that markerless and cost-effective RGB camera
has a median RMS errors of 3.06{\deg} and 0.95{\deg} in sagittal and coronal
plane respectively as compared to Microsoft Kinect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07034</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07034</id><created>2018-08-21</created><updated>2018-08-22</updated><authors><author><keyname>Fehrenbach</keyname><forenames>Thomas</forenames></author><author><keyname>Datta</keyname><forenames>Rohit</forenames></author><author><keyname>G&#xf6;ktepe</keyname><forenames>Bar&#x131;&#x15f;</forenames></author><author><keyname>Wirth</keyname><forenames>Thomas</forenames></author><author><keyname>Hellge</keyname><forenames>Cornelius</forenames></author></authors><title>URLLC Services in 5G - Low Latency Enhancements for LTE</title><categories>eess.SP</categories><comments>Accepted for publication at IEEE Vehicular Technology Conference
  (VTC), Fall 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G is envisioned to support three broad categories of services: eMBB, URLLC,
and mMTC. URLLC services refer to future applications which require reliable
data communications from one end to another, while fulfilling ultra-low latency
constraints. In this paper, we highlight the requirements and mechanisms that
are necessary for URLLC in LTE. Design challenges faced when reducing the
latency in LTE are shown. The performance of short processing time and frame
structure enhancements are analyzed. Our proposed DCI Duplication method to
increase LTE control channel reliability is presented and evaluated. The
feasibility of achieving low latency and high reliability for the IMT-2020
submission of LTE is shown. We further anticipate the opportunities and
technical design challenges when evolving 3GPP's LTE and designing the new 5G
NR standard to meet the requirements of novel URLLC services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07117</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07117</id><created>2018-08-21</created><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Leveque</keyname><forenames>Olivier</forenames></author></authors><title>Satellite Positioning with Large Constellations</title><categories>eess.SP</categories><comments>Presented in part at the 2018 Information Theory and Applications
  Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern global navigation satellite system receivers can access signals from
several satellite constellations (including GPS, GLONASS, Galileo, BeiDou).
Once these constellations are all fully operational, a typical receiver can
expect to have on the order of 40-50 satellites in view. Motivated by that
observation, this paper presents an asymptotic analysis of positioning
algorithms in the large-constellation regime. We determine the exact asymptotic
behavior for both pseudo-range and carrier-phase positioning. One interesting
insight from our analysis is that the standard carrier-phase positioning
approach based on resolving the carrier-phase integer ambiguities fails for
large satellite constellations. Instead, we adopt a Bayesian approach, in which
the ambiguities are treated as noise terms and not explicitly estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07120</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07120</id><created>2018-08-21</created><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>He</keyname><forenames>Liang</forenames></author><author><keyname>Liu</keyname><forenames>Weiwei</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author></authors><title>Exploring a Unified Attention-Based Pooling Framework for Speaker
  Verification</title><categories>cs.SD eess.AS</categories><comments>Accepted by ISCSLP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pooling layer is an essential component in the neural network based
speaker verification. Most of the current networks in speaker verification use
average pooling to derive the utterance-level speaker representations. Average
pooling takes every frame as equally important, which is suboptimal since the
speaker-discriminant power is different between speech segments. In this paper,
we present a unified attention-based pooling framework and combine it with the
multi-head attention. Experiments on the Fisher and NIST SRE 2010 dataset show
that involving outputs from lower layers to compute the attention weights can
outperform average pooling and achieve better results than vanilla attention
method. The multi-head attention further improves the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07173</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07173</id><created>2018-08-21</created><authors><author><keyname>Hosseini</keyname><forenames>Kianoush</forenames></author><author><keyname>Zhu</keyname><forenames>Caiyi</forenames></author><author><keyname>Khan</keyname><forenames>Ahmad</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Optimizing the MIMO Cellular Downlink: Multiplexing, Diversity, or
  Interference Nulling?</title><categories>cs.IT eess.SP math.IT</categories><comments>12 pages, 9 figures, to appear in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A base-station (BS) equipped with multiple antennas can use its spatial
dimensions in three different ways: (1) to serve multiple users, thereby
achieving a multiplexing gain, (2) to provide spatial diversity in order to
improve user rates and (3) to null interference in neighboring cells. This
paper answers the following question: What is the optimal balance between these
three competing benefits? We answer this question in the context of the
downlink of a cellular network, where multi-antenna BSs serve multiple
single-antenna users using zero-forcing beamforming with equal power
assignment, while nulling interference at a subset of out-of-cell users. Any
remaining spatial dimensions provide transmit diversity for the scheduled
users. Utilizing tools from stochastic geometry, we show that, surprisingly, to
maximize the per-BS ergodic sum rate, with an optimal allocation of spatial
resources, interference nulling does not provide a tangible benefit. The
strategy of avoiding inter-cell interference nulling, reserving some fraction
of spatial resources for multiplexing and using the rest to provide diversity,
is already close-to-optimal in terms of the sum-rate. However, interference
nulling does bring significant benefit to cell-edge users, particularly when
adopting a range-adaptive nulling strategy where the size of the cooperating BS
cluster is increased for cell-edge users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07312</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07312</id><created>2018-08-22</created><authors><author><keyname>Shnitzer</keyname><forenames>Tal</forenames></author><author><keyname>Ben-Chen</keyname><forenames>Mirela</forenames></author><author><keyname>Guibas</keyname><forenames>Leonidas</forenames></author><author><keyname>Talmon</keyname><forenames>Ronen</forenames></author><author><keyname>Wu</keyname><forenames>Hau-Tieng</forenames></author></authors><title>Recovering Hidden Components in Multimodal Data with Composite Diffusion
  Operators</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding appropriate low dimensional representations of high-dimensional
multi-modal data can be challenging, since each modality embodies unique
deformations and interferences. In this paper, we address the problem using
manifold learning, where the data from each modality is assumed to lie on some
manifold. In this context, the goal is to characterize the relations between
the different modalities by studying their underlying manifolds. We propose two
new diffusion operators that allow to isolate, enhance and attenuate the hidden
components of multi-modal data in a data-driven manner. Based on these new
operators, efficient low-dimensional representations can be constructed for
such data, which characterize the common structures and the differences between
the manifolds underlying the different modalities. The capabilities of the
proposed operators are demonstrated on 3D shapes and on a fetal heart rate
monitoring application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07373</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07373</id><created>2018-08-22</created><updated>2019-06-04</updated><authors><author><keyname>Kakkavas</keyname><forenames>Anastasios</forenames></author><author><keyname>Garc&#xed;a</keyname><forenames>Mario H. Casta&#xf1;eda</forenames></author><author><keyname>Stirling-Gallacher</keyname><forenames>Richard A.</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>Multi-Array 5G V2V Relative Positioning: Performance Bounds</title><categories>eess.SP cs.IT math.IT</categories><journal-ref>IEEE Global Communications Conference (GLOBECOM), Abu Dhabi,
  United Arab Emirates, 2018, pp. 206-212</journal-ref><doi>10.1109/GLOCOM.2018.8647812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance bounds of vehicle-to-vehicle (V2V) relative
positioning for vehicles with multiple antenna arrays. The Cram\'{e}r-Rao bound
for the estimation of the relative position and the orientation of the Tx
vehicle is derived, when angle of arrival (AOA) measurements with or without
time-difference of arrival (TDOA) measurements are used. In addition,
geometrically intuitive expressions for the corresponding Fisher information
are provided. The derived bounds are numerically evaluated for different
carrier frequencies, bandwidths and array configurations under different V2V
scenarios, i.e. overtaking and platooning. The significance of the AOA and TDOA
measurements for position estimation is investigated. The achievable
positioning accuracy is then compared with the present requirements of the 3rd
Generation Partnership Project (3GPP) 5G New Radio (NR) vehicle-to-everything
(V2X) standardization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07505</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07505</id><created>2018-08-22</created><updated>2019-04-29</updated><authors><author><keyname>Li</keyname><forenames>Conghui</forenames></author><author><keyname>Gan</keyname><forenames>Lu</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Coprime Sensing via Chinese Remaindering over Quadratic Fields, Part I:
  Array Designs</title><categories>eess.SP</categories><comments>14 pages, 10 figures</comments><doi>10.1109/TSP.2019.2910498</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coprime antenna array consists of two or more sparse subarrays featuring
enhanced degrees of freedom (DOF) and reduced mutual coupling. This paper
introduces a new class of planar coprime arrays, based on the theory of ideal
lattices. In quadratic number fields, a splitting prime $p$ can be decomposed
into the product of two distinct prime ideals, which give rise to the two
sparse subarrays. Their virtual difference coarray enjoys a quadratic gain in
DOF, thanks to the generalized Chinese Remainder Theorem (CRT). To enlarge the
contiguous aperture of the coarray, we present hole-free symmetric CRT arrays
with simple closed-form expressions. The ring of Gaussian integers and the ring
of Eisenstein integers are considered as examples to demonstrate the procedure
of designing coprime arrays. With Eisenstein integers, our design yields a
difference coarray that is a subset of the hexagonal lattice, offering a
significant gain in DOF over the rectangular lattice, given the same physical
areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07511</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07511</id><created>2018-08-22</created><updated>2019-04-29</updated><authors><author><keyname>Li</keyname><forenames>Conghui</forenames></author><author><keyname>Gan</keyname><forenames>Lu</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Coprime Sensing via Chinese Remaindering over Quadratic Fields, Part II:
  Generalizations and Applications</title><categories>eess.SP</categories><comments>13 pages, 15 figures</comments><doi>10.1109/TSP.2019.2910480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The practical application of a new class of coprime arrays based on the
Chinese remainder theorem (CRT) over quadratic fields is presented in this
paper. The proposed CRT arrays are constructed by ideal lattices embedded from
coprime quadratic integers. The geometrical constructions and theoretical
foundations were discussed in the accompanying paper in great detail, while
this paper focuses on aspects of the application of the proposed arrays in
two-dimensional (2D) remote sensing. A generalization of CRT arrays based on
two or more pairwise coprime ideal lattices is proposed with closed-form
expressions on sensor locations, the total number of sensors and the achievable
DOF. The issues pertaining to the coprimality of any two quadratic integers are
also addressed to explore all possible ideal lattices. Exploiting the symmetry
of lattices, sensor reduction methods are discussed with the coarray remaining
intact for economic maximization. In order to extend conventional angle
estimation techniques based on uniformly distributed arrays to the method that
can exploit any coarray configurations based on lattices, this paper introduces
a hexagon-to-rectangular transformation to 2D spatial smoothing, providing the
possibility of finding more compact sensor arrays. Examples are provided to
verify the feasibility of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07620</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07620</id><created>2018-08-22</created><updated>2018-09-04</updated><authors><author><keyname>Jia</keyname><forenames>Mengshuo</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwen</forenames></author></authors><title>Discussion of Parameters Setting for A Distributed Probabilistic
  Modeling Algorithm</title><categories>eess.SP eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript provides additional case analysis for the parameters setting
of the distributed probabilistic modeling algorithm for the aggregated wind
power forecast error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07713</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07713</id><created>2018-08-23</created><authors><author><keyname>Sadeghi</keyname><forenames>Meysam</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Adversarial Attacks on Deep-Learning Based Radio Signal Classification</title><categories>cs.IT cs.CR cs.LG eess.SP math.IT stat.ML</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning (DL), despite its enormous success in many computer vision and
language processing applications, is exceedingly vulnerable to adversarial
attacks. We consider the use of DL for radio signal (modulation) classification
tasks, and present practical methods for the crafting of white-box and
universal black-box adversarial attacks in that application. We show that these
attacks can considerably reduce the classification performance, with extremely
small perturbations of the input. In particular, these attacks are
significantly more powerful than classical jamming attacks, which raises
significant security and robustness concerns in the use of DL-based algorithms
for the wireless physical layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07755</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07755</id><created>2018-08-21</created><authors><author><keyname>Hannula</keyname><forenames>Jari-Matti</forenames></author><author><keyname>Saarinen</keyname><forenames>Tapio O.</forenames></author><author><keyname>Lehtovuori</keyname><forenames>Anu</forenames></author><author><keyname>Holopainen</keyname><forenames>Jari</forenames></author><author><keyname>Viikari</keyname><forenames>Ville</forenames></author></authors><title>Tunable Eight-Element MIMO Antenna Based on the Antenna Cluster Concept</title><categories>eess.SP physics.app-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Realizing capacity demands of future wireless communications requires
improved spectral efficiency in the sub-6-GHz frequency bands. This paper
proposes a novel eight-element multiple-input multiple-output (MIMO) antenna
that can be tuned from 1.7 to 6 GHz. The design is based on the antenna cluster
concept, where weighted feeding of multiple antenna elements is used to modify
the operating frequency. This paper extends the theory of the concept to
account for multiple separate clusters, thus enabling it to be used for MIMO.
The proposed antenna achieves over 60% efficiency at frequencies above 3 GHz,
and the system exceeds the ergodic capacity of the ideal 7x7 MIMO in that band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07769</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07769</id><created>2018-08-23</created><authors><author><keyname>Baron</keyname><forenames>Matthew</forenames></author></authors><title>Topology and Prediction Focused Research on Graph Convolutional Neural
  Networks</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Important advances have been made using convolutional neural network (CNN)
approaches to solve complicated problems in areas that rely on grid structured
data such as image processing and object classification. Recently, research on
graph convolutional neural networks (GCNN) has increased dramatically as
researchers try to replicate the success of CNN for graph structured data.
Unfortunately, traditional CNN methods are not readily transferable to GCNN,
given the irregularity and geometric complexity of graphs. The emerging field
of GCNN is further complicated by research papers that differ greatly in their
scope, detail, and level of academic sophistication needed by the reader.
  The present paper provides a review of some basic properties of GCNN. As a
guide to the interested reader, recent examples of GCNN research are then
grouped according to techniques that attempt to uncover the underlying topology
of the graph model and those that seek to generalize traditional CNN methods on
graph data to improve prediction of class membership. Discrete Signal
Processing on Graphs (DSPg) is used as a theoretical framework to better
understand some of the performance gains and limitations of these recent GCNN
approaches. A brief discussion of Topology Adaptive Graph Convolutional
Networks (TAGCN) is presented as an approach motivated by DSPg and future
research directions using this approach are briefly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07864</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07864</id><created>2018-08-23</created><updated>2019-01-31</updated><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Shin</keyname><forenames>Wonjae</forenames></author><author><keyname>Vaezi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Secure Relaying in Non-Orthogonal Multiple Access: Trusted and Untrusted
  Scenarios</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1805.01449</comments><doi>10.1109/TIFS.2019.2911162</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A downlink single-input single-output non-orthogonal multiple access setting
is considered, in which a base station (BS) is communicating with two
legitimate users in two possible scenarios of unsecure environments: existence
of an external eavesdropper and communicating through an untrusted relay. For
the first scenario, a number of trusted cooperative half-duplex relays is
employed to assist with the BS's transmission and secure its signals from the
external eavesdropper. Various relaying schemes are proposed and analyzed for
that matter: cooperative jamming, decode-and-forward, and amplify-and-forward.
For each scheme, secure beamforming signals are devised at the relays to
maximize the achievable secrecy rate regions. For the second scenario, with the
untrusted relay, achievable secrecy rate regions are derived for two different
relaying schemes: compress-and-forward and amplify-and-forward, under two
different modes of operation. In the first mode, coined passive user mode, the
users receive signals from both the BS and the untrusted relay, and combine
them to decode their messages. In the second mode, coined active user mode, the
users transmit a cooperative jamming signal simultaneously with the BS's
transmission to further confuse the relay. Focusing on half-duplex nodes, the
users cannot receive the BS's signal while jamming the relay, i.e., while being
active, and rely only on the signals forwarded to them by the relay. It is
shown that the best relaying scheme highly depends on the system parameters, in
particular distances between the nodes, and also on which part of the secrecy
rate region the system is to operate at.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07940</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07940</id><created>2018-08-23</created><updated>2018-08-27</updated><authors><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>A Closed-Form Approximation of the Gaussian Noise Model in the Presence
  of Inter-Channel Stimulated Raman Scattering</title><categories>eess.SP</categories><comments>Version 2: The plots of figure 4 and 5 were placed out of order in
  version 1. In version 2, they have been swapped and are now in correct order</comments><doi>10.1109/JLT.2019.2895237</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An accurate, closed-form expression evaluating the nonlinear interference
(NLI) power in coherent optical transmission systems in the presence of
inter-channel stimulated Raman scattering (ISRS) is derived. The analytical
result enables a rapid estimate of the signal-to-noise ratio (SNR) and avoids
the need for integral evaluations and split-step simulations. The formula also
provides new insight into the underlying parameter dependence of ISRS on the
NLI. The proposed result is applicable for dispersion unmanaged, ultra-wideband
transmission systems that use optical bandwidths of up to 15 THz. The accuracy
of the closed-form expression is compared to numerical integration of the ISRS
Gaussian Noise model and split-step simulations in a point-to-point
transmission, as well as in a mesh optical network scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07971</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07971</id><created>2018-08-23</created><updated>2019-01-07</updated><authors><author><keyname>Matthews</keyname><forenames>Richard</forenames></author><author><keyname>Sorell</keyname><forenames>Matthew</forenames></author><author><keyname>Falkner</keyname><forenames>Nickolas</forenames></author></authors><title>Rethinking Image Sensor Noise for Forensic Advantage</title><categories>eess.IV astro-ph.IM</categories><comments>17 pages, 10 figures, preprint for journal submission, paper is based
  on a chapter of a thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor pattern noise has been found to be a reliable tool for providing
information relating to the provenance of an image. Conventionally sensor
pattern noise is modelled as a mutual interaction of pixel non-uniformity noise
and dark current. By using a wavelet denoising filter it is possible to isolate
a unique signal within a sensor caused by the way the silicon reacts
non-uniformly to light. This signal is often referred to as a fingerprint. To
obtain the estimate of this photo response non-uniformity multiple sample
images are averaged and filtered to derive a noise residue. This process and
model, while useful at providing insight into an images provenance, fails to
take into account additional sources of noise that are obtained during this
process. These other sources of noise include digital processing artefacts
collectively known as camera noise, image compression artefacts, lens
artefacts, and image content. By analysing the diversity of sources of noise
remaining within the noise residue, we show that further insight is possible
within a unified sensor pattern noise concept which opens the field to
approaches for obtaining fingerprints utilising fewer resources with comparable
performance to existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07989</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07989</id><created>2018-08-23</created><authors><author><keyname>Onu</keyname><forenames>Charles C.</forenames></author><author><keyname>Kanbar</keyname><forenames>Lara J.</forenames></author><author><keyname>Shalish</keyname><forenames>Wissam</forenames></author><author><keyname>Brown</keyname><forenames>Karen A.</forenames></author><author><keyname>Sant'Anna</keyname><forenames>Guilherme M.</forenames></author><author><keyname>Kearney</keyname><forenames>Robert E.</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>A Semi-Markov Chain Approach to Modeling Respiratory Patterns Prior to
  Extubation in Preterm Infants</title><categories>eess.SP stat.AP stat.ML</categories><comments>Published in: 2017 39th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After birth, extremely preterm infants often require specialized respiratory
management in the form of invasive mechanical ventilation (IMV). Protracted IMV
is associated with detrimental outcomes and morbidities. Premature extubation,
on the other hand, would necessitate reintubation which is risky, technically
challenging and could further lead to lung injury or disease. We present an
approach to modeling respiratory patterns of infants who succeeded extubation
and those who required reintubation which relies on Markov models. We compare
the use of traditional Markov chains to semi-Markov models which emphasize
cross-pattern transitions and timing information, and to multi-chain Markov
models which can concisely represent non-stationarity in respiratory behavior
over time. The models we developed expose specific, unique similarities as well
as vital differences between the two populations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07991</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07991</id><created>2018-08-23</created><authors><author><keyname>Onu</keyname><forenames>Charles C.</forenames></author><author><keyname>Kanbar</keyname><forenames>Lara J.</forenames></author><author><keyname>Shalish</keyname><forenames>Wissam</forenames></author><author><keyname>Brown</keyname><forenames>Karen A.</forenames></author><author><keyname>Sant'Anna</keyname><forenames>Guilherme M.</forenames></author><author><keyname>Kearney</keyname><forenames>Robert E.</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Predicting Extubation Readiness in Extreme Preterm Infants based on
  Patterns of Breathing</title><categories>cs.LG eess.SP stat.ML</categories><comments>Published in: 2017 IEEE Symposium Series on Computational
  Intelligence (SSCI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extremely preterm infants commonly require intubation and invasive mechanical
ventilation after birth. While the duration of mechanical ventilation should be
minimized in order to avoid complications, extubation failure is associated
with increases in morbidities and mortality. As part of a prospective
observational study aimed at developing an accurate predictor of extubation
readiness, Markov and semi-Markov chain models were applied to gain insight
into the respiratory patterns of these infants, with more robust time-series
modeling using semi-Markov models. This model revealed interesting similarities
and differences between newborns who succeeded extubation and those who failed.
The parameters of the model were further applied to predict extubation
readiness via generative (joint likelihood) and discriminative (support vector
machine) approaches. Results showed that up to 84\% of infants who failed
extubation could have been accurately identified prior to extubation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07992</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.07992</id><created>2018-08-23</created><authors><author><keyname>Kanbar</keyname><forenames>Lara J.</forenames></author><author><keyname>Onu</keyname><forenames>Charles C.</forenames></author><author><keyname>Shalish</keyname><forenames>Wissam</forenames></author><author><keyname>Brown</keyname><forenames>Karen A.</forenames></author><author><keyname>Sant'Anna</keyname><forenames>Guilherme M.</forenames></author><author><keyname>Kearney</keyname><forenames>Robert E.</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Undersampling and Bagging of Decision Trees in the Analysis of
  Cardiorespiratory Behavior for the Prediction of Extubation Readiness in
  Extremely Preterm Infants</title><categories>cs.LG eess.SP stat.ML</categories><comments>Published in: 2018 40th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extremely preterm infants often require endotracheal intubation and
mechanical ventilation during the first days of life. Due to the detrimental
effects of prolonged invasive mechanical ventilation (IMV), clinicians aim to
extubate infants as soon as they deem them ready. Unfortunately, existing
strategies for prediction of extubation readiness vary across clinicians and
institutions, and lead to high reintubation rates. We present an approach using
Random Forest classifiers for the analysis of cardiorespiratory variability to
predict extubation readiness. We address the issue of data imbalance by
employing random undersampling of examples from the majority class before
training each Decision Tree in a bag. By incorporating clinical domain
knowledge, we further demonstrate that our classifier could have identified 71%
of infants who failed extubation, while maintaining a success detection rate of
78%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08021</identifier>
 <datestamp>2018-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08021</id><created>2018-08-24</created><updated>2018-10-21</updated><authors><author><keyname>Shinoda</keyname><forenames>Kazuma</forenames></author><author><keyname>Yoshiba</keyname><forenames>Shoichiro</forenames></author><author><keyname>Hasegawa</keyname><forenames>Madoka</forenames></author></authors><title>Deep demosaicking for multispectral filter arrays</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel demosaicking method for multispectral filter arrays based
on a deep convolutional neural network. The proposed method first interpolates
mosaicked multispectral images utilizing a bilinear approach, then applies a
residual network to initial demosaicked images. The residual network consists
of various three-dimensional convolutional layers and a rectified linear unit
for describing the features of a multispectral data cube. Experimental results
reveal that the proposed method outperforms conventional demosaicking methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08024</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08024</id><created>2018-08-24</created><authors><author><keyname>Tuia</keyname><forenames>Devis</forenames></author><author><keyname>Volpi</keyname><forenames>Michele</forenames></author><author><keyname>Moser</keyname><forenames>Gabriele</forenames></author></authors><title>Decision fusion with multiple spatial supports by conditional random
  fields</title><categories>eess.IV cs.CV</categories><journal-ref>IEEE Transactions on Geoscience and Remote Sensing, 56(6),
  3277-3289, 2018</journal-ref><doi>10.1109/TGRS.2018.2797316</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification of remotely sensed images into land cover or land use is
highly dependent on geographical information at least at two levels. First,
land cover classes are observed in a spatially smooth domain separated by sharp
region boundaries. Second, land classes and observation scale are also tightly
intertwined: they tend to be consistent within areas of homogeneous appearance,
or regions, in the sense that all pixels within a roof should be classified as
roof, independently on the spatial support used for the classification. In this
paper, we follow these two observations and encode them as priors in an energy
minimization framework based on conditional random fields (CRFs), where
classification results obtained at pixel and region levels are
probabilistically fused. The aim is to enforce the final maps to be consistent
not only in their own spatial supports (pixel and region) but also across
supports, i.e., by getting the predictions on the pixel lattice and on the set
of regions to agree. To this end, we define an energy function with three
terms: 1) a data term for the individual elements in each support
(support-specific nodes); 2) spatial regularization terms in a neighborhood for
each of the supports (support-specific edges); and 3) a regularization term
between individual pixels and the region containing each of them (intersupports
edges). We utilize these priors in a unified energy minimization problem that
can be optimized by standard solvers. The proposed 2LCRF model consists of a
CRF defined over a bipartite graph, i.e., two interconnected layers within a
single graph accounting for interlattice connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08056</identifier>
 <datestamp>2018-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08056</id><created>2018-08-24</created><authors><author><keyname>Mogami</keyname><forenames>Shinichi</forenames></author><author><keyname>Takamune</keyname><forenames>Norihiro</forenames></author><author><keyname>Kitamura</keyname><forenames>Daichi</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author><author><keyname>Takahashi</keyname><forenames>Yu</forenames></author><author><keyname>Kondo</keyname><forenames>Kazunobu</forenames></author><author><keyname>Nakajima</keyname><forenames>Hiroaki</forenames></author><author><keyname>Ono</keyname><forenames>Nobutaka</forenames></author></authors><title>Independent Low-Rank Matrix Analysis Based on Time-Variant Sub-Gaussian
  Source Model</title><categories>eess.AS</categories><comments>8 pages, 5 figures, To appear in the Proceedings of APSIPA ASC 2018</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Independent low-rank matrix analysis (ILRMA) is a fast and stable method for
blind audio source separation. Conventional ILRMAs assume time-variant
(super-)Gaussian source models, which can only represent signals that follow a
super-Gaussian distribution. In this paper, we focus on ILRMA based on a
generalized Gaussian distribution (GGD-ILRMA) and propose a new type of
GGD-ILRMA that adopts a time-variant sub-Gaussian distribution for the source
model. By using a new update scheme called generalized iterative projection for
homogeneous source models, we obtain a convergence-guaranteed update rule for
demixing spatial parameters. In the experimental evaluation, we show the
versatility of the proposed method, i.e., the proposed time-variant
sub-Gaussian source model can be applied to various types of source signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08299</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08299</id><created>2018-08-24</created><authors><author><keyname>Onu</keyname><forenames>Charles C.</forenames></author></authors><title>Harnessing Infant Cry for swift, cost-effective Diagnosis of Perinatal
  Asphyxia in low-resource settings</title><categories>stat.AP cs.SD eess.AS</categories><comments>Presented at 2014 IEEE Canada International Humanitarian Technology
  Conference - (IHTC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perinatal Asphyxia is one of the top three causes of infant mortality in
developing countries, resulting to the death of about 1.2 million newborns
every year. At its early stages, the presence of asphyxia cannot be
conclusively determined visually or via physical examination, but by medical
diagnosis. In resource-poor settings, where skilled attendance at birth is a
luxury, most cases only get detected when the damaging consequences begin to
manifest or worse still, after death of the affected infant. In this project,
we explored the approach of machine learning in developing a low-cost
diagnostic solution. We designed a support vector machine-based pattern
recognition system that models patterns in the cries of known asphyxiating
infants (and normal infants) and then uses the developed model for
classification of `new' infants as having asphyxia or not. Our prototype has
been tested in a laboratory setting to give prediction accuracy of up to
88.85%. If higher accuracies can be obtained, this research may be a key
contributor to the 4th Millennium Development Goal (MDG) of reducing mortality
in under-five children.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08311</identifier>
 <datestamp>2018-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08311</id><created>2018-08-24</created><authors><author><keyname>Zhou</keyname><forenames>Cong</forenames></author><author><keyname>Horgan</keyname><forenames>Michael</forenames></author><author><keyname>Kumar</keyname><forenames>Vivek</forenames></author><author><keyname>Vasco</keyname><forenames>Cristina</forenames></author><author><keyname>Darcy</keyname><forenames>Dan</forenames></author></authors><title>Voice Conversion with Conditional SampleRNN</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted at Interspeech 2018, Hyderabad, India. This version matches
  the final version submitted to the conference</comments><doi>10.21437/Interspeech.2018-1121</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we present a novel approach to conditioning the SampleRNN generative
model for voice conversion (VC). Conventional methods for VC modify the
perceived speaker identity by converting between source and target acoustic
features. Our approach focuses on preserving voice content and depends on the
generative network to learn voice style. We first train a multi-speaker
SampleRNN model conditioned on linguistic features, pitch contour, and speaker
identity using a multi-speaker speech corpus. Voice-converted speech is
generated using linguistic features and pitch contour extracted from the source
speaker, and the target speaker identity. We demonstrate that our system is
capable of many-to-many voice conversion without requiring parallel data,
enabling broad applications. Subjective evaluation demonstrates that our
approach outperforms conventional VC methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08321</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08321</id><created>2018-08-24</created><authors><author><keyname>Bencivenni</keyname><forenames>C.</forenames></author><author><keyname>Glazunov</keyname><forenames>A. A.</forenames></author><author><keyname>Maaskant</keyname><forenames>R.</forenames></author><author><keyname>Ivashina</keyname><forenames>M. V.</forenames></author></authors><title>Aperiodic Array Synthesis for Multi-User MIMO Applications</title><categories>eess.SP</categories><comments>Manuscript submitted to IEEE Trans. Antennas Propag. on March 18,
  2017; published and defended as part of the PhD dissertation Aperiodic Array
  Synthesis for Telecommunications on May 31, 2017, Goteborg, Sweden,
  candidate: Carlo Bencivenni, Chalmers University of Technology, faculty
  opponent: Andrea Massa, ELEDIA center</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates the advantages of aperiodic arrays in multi-user
multiple-input multiple-output systems for future mobile communication
applications. We propose a novel aperiodic array synthesis method which account
for the statistics of the propagation channel and the adaptive beamforming
algorithm. Clear performance gains in line-of-sight dominated propagation
environments are achieved in terms of the signal-to-interference-plus-noise
ratio, the sum rate capacity, as well as the spread of the amplifier output
power as compared to their regular counterparts. We also show that the
performance is not sacrificed in rich scattering environments. Hence, aperiodic
array layouts can provide performance gains in millimeter-wave applications
with a dominating line-of-sight component.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08340</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08340</id><created>2018-08-24</created><updated>2019-11-03</updated><authors><author><keyname>Susuki</keyname><forenames>Yoshihiko</forenames></author><author><keyname>Mezi&#x107;</keyname><forenames>Igor</forenames></author></authors><title>Invariant Sets in Quasiperiodically Forced Dynamical Systems</title><categories>math.DS cs.SY eess.SP nlin.CD</categories><comments>23 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses structures of state space in quasiperiodically forced
dynamical systems. We develop a theory of ergodic partition of state space in a
class of measure-preserving and dissipative flows, which is a natural extension
of the existing theory for measure-preserving maps. The ergodic partition
result is based on eigenspace at eigenvalue 0 of the associated Koopman
operator, which is realized via time-averages of observables, and provides a
constructive way to visualize a low-dimensional slice through a
high-dimensional invariant set. We apply the result to the systems with a
finite number of attractors and show that the time-average of a continuous
observable is well-defined and reveals the invariant sets, namely, a finite
number of basins of attraction. We provide a characterization of invariant sets
in the quasiperiodically forced systems. A theoretical result on uniform
boundedness of the invariant sets is presented. The series of theoretical
results enables numerical analysis of invariant sets in the quasiperiodically
forced systems based on the ergodic partition and time-averages. Using this, we
analyze a nonlinear model of complex power grids that represents the short-term
swing instability, named the coherent swing instability. We show that our
theoretical results can be used to understand stability regions in such complex
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08344</identifier>
 <datestamp>2018-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08344</id><created>2018-08-24</created><updated>2018-11-11</updated><authors><author><keyname>He</keyname><forenames>Liang</forenames></author><author><keyname>Chen</keyname><forenames>Xianhong</forenames></author><author><keyname>Xu</keyname><forenames>Can</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author></authors><title>Multiobjective Optimization Training of PLDA for Speaker Verification</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most current state-of-the-art text-independent speaker verification systems
take probabilistic linear discriminant analysis (PLDA) as their backend
classifiers. The parameters of PLDA are often estimated by maximizing the
objective function, which focuses on increasing the value of log-likelihood
function, but ignoring the distinction between speakers. In order to better
distinguish speakers, we propose a multi-objective optimization training for
PLDA. Experiment results show that the proposed method has more than 10%
relative performance improvement in both EER and MinDCF on the NIST SRE14
i-vector challenge dataset, and about 20% relative performance improvement in
EER on the MCE18 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08352</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08352</id><created>2018-08-24</created><authors><author><keyname>Tuladhar</keyname><forenames>Saurav R</forenames></author><author><keyname>Buck</keyname><forenames>John R</forenames></author><author><keyname>Wage</keyname><forenames>Kathleen E</forenames></author></authors><title>Random Matrix Theory Model for Mean Notch Depth of the Diagonally Loaded
  MVDR Beamformer for a Single Interferer Case</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive beamformers (ABFs) suppress interferers by placing a notch in the
beampattern at the interferer direction. This suppres- sion improves detection
of a weaker signals in the presence of strong interferers. Hence the notch
depth plays a crucial role in determining the adaptive gain obtained from using
ABF over conventional beam- forming. This research derives models for the mean
notch depth of a diagonally loaded MVDR ABF for a single interferer case. The
model describes the mean notch depth as a function of number of snapshots, the
number of sensors in the array, the interferer to noise ratio (INR) level, the
interferer direction and the diagonal loading level. The derivation uses random
matrix theory results on the be- havior of the eigenvectors of sample
covariance matrix. The notch depth predicted by the model is shown to be in
close agreement with simulation results over a range of INRs and snapshots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08383</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08383</id><created>2018-08-25</created><authors><author><keyname>Zhang</keyname><forenames>Bo</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author></authors><title>Antenna Array Based Positional Modulation with a Two-Ray Multi-Path
  Model</title><categories>eess.SP</categories><comments>6 pages, 5 figures. The paper has been accepted by SAM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional directional modulation (DM) designs are based on the assumption
that there is no multi-path effect between transmitters and receivers. One
problem with these designs is that the resultant systems will be vulnerable to
eavesdroppers which are aligned with or very close to the desired directions,
as the received modulation pattern at these positions is similar to the given
one. To solve the problem, a two-ray multi-path model is studied for positional
modulation and the coefficients design problem for a given array geometry and a
location-optimised antenna array is solved, where the multi-path effect is
exploited to generate a given modulation pattern at desired positions, with
scrambled values at positions around them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08405</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08405</id><created>2018-08-25</created><authors><author><keyname>Zhang</keyname><forenames>Zhichao</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author></authors><title>Deep Convolutional Neural Network with Mixup for Environmental Sound
  Classification</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental sound classification (ESC) is an important and challenging
problem. In contrast to speech, sound events have noise-like nature and may be
produced by a wide variety of sources. In this paper, we propose to use a novel
deep convolutional neural network for ESC tasks. Our network architecture uses
stacked convolutional and pooling layers to extract high-level feature
representations from spectrogram-like features. Furthermore, we apply mixup to
ESC tasks and explore its impacts on classification performance and feature
distribution. Experiments were conducted on UrbanSound8K, ESC-50 and ESC-10
datasets. Our experimental results demonstrated that our ESC system has
achieved the state-of-the-art performance (83.7%) on UrbanSound8K and
competitive performance on ESC-50 and ESC-10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08413</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08413</id><created>2018-08-25</created><authors><author><keyname>Kaymak</keyname><forenames>&#xc7;a&#x11f;r&#x131;</forenames></author><author><keyname>U&#xe7;ar</keyname><forenames>Ay&#x15f;eg&#xfc;l</forenames></author></authors><title>A Brief Survey and an Application of Semantic Image Segmentation for
  Autonomous Driving</title><categories>eess.IV</categories><comments>A chapter for Springer Book: Handbook of Deep Learning Applications,
  2018,[ Pijush Samui, Editor]. (be published)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is a fast-growing machine learning approach to perceive and
understand large amounts of data. In this paper, general information about the
deep learning approach which is attracted much attention in the field of
machine learning is given in recent years and an application about semantic
image segmentation is carried out in order to help autonomous driving of
autonomous vehicles. This application is implemented with Fully Convolutional
Network (FCN) architectures obtained by modifying the Convolutional Neural
Network (CNN) architectures based on deep learning. Experimental studies for
the application are utilized 4 different FCN architectures named
FCN-AlexNet,FCN-8s, FCN-16s and FCN-32s. For the experimental studies, FCNs are
first trained separately and validation accuracies of these trained network
models on the used dataset is compared. In addition, image segmentation
inferences are visualized to take account of how precisely FCN architectures
can segment objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08442</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08442</id><created>2018-08-25</created><authors><author><keyname>Fan</keyname><forenames>Wenzhi</forenames></author><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Lu</keyname><forenames>Jing</forenames></author><author><keyname>Tao</keyname><forenames>Jiancheng</forenames></author></authors><title>Efficient improvement of frequency-domain Kalman filter</title><categories>eess.SP cs.SD eess.AS</categories><comments>5 pages, 3 figures</comments><doi>10.1109/LSP.2019.2890965</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The frequency-domain Kalman filter (FKF) has been utilized in many audio
signal processing applications due to its fast convergence speed and
robustness. However, the performance of the FKF in under-modeling situations
has not been investigated. This paper presents an analysis of the steady-state
behavior of the commonly used diagonalized FKF and reveals that it suffers from
a biased solution in under-modeling scenarios. Two efficient improvements of
the FKF are proposed, both having the benefits of the guaranteed optimal
steady-state behavior at the cost of a very limited increase of the
computational burden. The convergence behavior of the proposed algorithms is
also compared analytically. Computer simulations are conducted to validate the
improved performance of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08519</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08519</id><created>2018-08-26</created><authors><author><keyname>Liu</keyname><forenames>Pei</forenames></author><author><keyname>Luo</keyname><forenames>Kai</forenames></author><author><keyname>Chen</keyname><forenames>Da</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author></authors><title>Spectral Efficiency Analysis of Multi-Cell Massive MIMO Systems with
  Ricean Fading</title><categories>cs.IT eess.SP math.IT</categories><comments>15 pages, 2 figures, the tenth International Conference on Wireless
  Communications and Signal Processing (WCSP 2018), to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the spectral efficiency of multi-cell massive
multiple-input multiple-output systems with Ricean fading that utilize the
linear maximal-ratio combining detector. We firstly present closed-form
expressions for the effective signal-to-interference-plus-noise ratio (SINR)
with the least squares and minimum mean squared error (MMSE) estimation
methods, respectively, which apply for any number of base-station antennas $M$
and any Ricean $K$-factor. Also, the obtained results can be particularized in
Rayleigh fading conditions when the Ricean $K$-factor is equal to zero. In the
following, novel exact asymptotic expressions of the effective SINR are derived
in the high $M$ and high Ricean $K$-factor regimes. The corresponding analysis
shows that pilot contamination is removed by the MMSE estimator when we
consider both infinite $M$ and infinite Ricean $K$-factor, while the pilot
contamination phenomenon persists for the rest of cases. All the theoretical
results are verified via Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08579</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08579</id><created>2018-08-26</created><authors><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Meng</keyname><forenames>Xiangming</forenames></author><author><keyname>Xu</keyname><forenames>Zhiwei</forenames></author></authors><title>Vector Approximate Message Passing Algorithm for Structured Perturbed
  Sensing Matrix</title><categories>eess.SP</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a general form of noisy compressive sensing (CS)
where the sensing matrix is not precisely known. Such cases exist when there
are imperfections or unknown calibration parameters during the measurement
process. Particularly, the sensing matrix may have some structure, which makes
the perturbation follow a fixed pattern. While previous work has focused on
extending the approximate message passing (AMP) and LASSO algorithm to deal
with the independent and identically distributed (i.i.d.) perturbation, we
propose the robust variant vector approximate message passing (VAMP) algorithm
with the perturbation being structured, based on the recent VAMP algorithm. The
performance of the robust version of VAMP is demonstrated numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08658</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08658</id><created>2018-08-26</created><authors><author><keyname>Gao</keyname><forenames>Jingkun</forenames></author><author><keyname>Deng</keyname><forenames>Bin</forenames></author><author><keyname>Qin</keyname><forenames>Yuliang</forenames></author><author><keyname>Wang</keyname><forenames>Hongqiang</forenames></author><author><keyname>Li</keyname><forenames>Xiang</forenames></author></authors><title>Fast Super-resolution 3D SAR Imaging Using an Unfolded Deep Network</title><categories>eess.SP eess.IV</categories><comments>5 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For 3D Synthetic Aperture Radar (SAR) imaging, one typical approach is to
achieve the cross-track 1D focusing for each range-azimuth pixel after
obtaining a stack of 2D complex-valued images. The cross-track focusing is the
main difficulty as its aperture length is limited and the antenna positions are
usually non-uniformly distributed. Sparsity regularization methods are widely
used to tackle these problems. However, these methods are of obvious
limitations. The most well-known ones are their heavy computational burdens and
unsatisfied stabilities. In this letter, an efficient deep network-based
cross-track imaging method is proposed. When trained, the imaging process, i.e.
the forward propagation of the network, is made up of simple matrix-vector
calculations and element-wise nonlinearity operations, which significantly
speed up the imaging. Also, we find that the deep network is of good robustness
against noise and model errors. Comprehensive simulations and experiments have
been carried out, and the superiority of the proposed method can be clearly
seen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08684</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08684</id><created>2018-08-27</created><updated>2018-11-30</updated><authors><author><keyname>Matthews</keyname><forenames>Richard</forenames></author><author><keyname>Sorell</keyname><forenames>Matthew</forenames></author><author><keyname>Falkner</keyname><forenames>Nickolas</forenames></author></authors><title>An Analysis of Optical Contributions to a Photo-Sensor's Ballistic
  Fingerprints</title><categories>eess.IV</categories><comments>16 pages, 9 figures, preprint for journal submission, paper is based
  on a thesis chapter</comments><journal-ref>R. Matthews, M. Sorell, N. Falkner, An analysis of optical
  contributions to a photo-sensor's ballistic fingerprints, Digital
  Investigation, 2019,</journal-ref><doi>10.1016/j.diin.2019.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lens aberrations have previously been used to determine the provenance of an
image. However, this is not necessarily unique to an image sensor, as lens
systems are often interchanged. Photo-response non-uniformity noise was
proposed in 2005 by Luk\'a\v{s}, Goljan and Fridrich as a stochastic signal
which describes a sensor uniquely, akin to a &quot;ballistic&quot; fingerprint. This
method, however, did not account for additional sources of bias such as lens
artefacts and temperature.
  In this paper, we propose a new additive signal model to account for
artefacts previously thought to have been isolated from the ballistic
fingerprint. Our proposed model separates sensor level artefacts from the lens
optical system and thus accounts for lens aberrations previously thought to be
filtered out. Specifically, we apply standard image processing theory, an
understanding of frequency properties relating to the physics of light and
temperature response of sensor dark current to classify artefacts. This model
enables us to isolate and account for bias from the lens optical system and
temperature within the current model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08702</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08702</id><created>2018-08-27</created><authors><author><keyname>Lee</keyname><forenames>Moa</forenames></author><author><keyname>Chang</keyname><forenames>Joon Hyuk</forenames></author></authors><title>Augmenting Bottleneck Features of Deep Neural Network Employing Motor
  State for Speech Recognition at Humanoid Robots</title><categories>cs.SD cs.AI eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As for the humanoid robots, the internal noise, which is generated by motors,
fans and mechanical components when the robot is moving or shaking its body,
severely degrades the performance of the speech recognition accuracy. In this
paper, a novel speech recognition system robust to ego-noise for humanoid
robots is proposed, in which on/off state of the motor is employed as auxiliary
information for finding the relevant input features. For this, we consider the
bottleneck features, which have been successfully applied to deep neural
network (DNN) based automatic speech recognition (ASR) system. When learning
the bottleneck features to catch, we first exploit the motor on/off state data
as supplementary information in addition to the acoustic features as the input
of the first deep neural network (DNN) for preliminary acoustic modeling. Then,
the second DNN for primary acoustic modeling employs both the bottleneck
features tossed from the first DNN and the acoustics features. When the
proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT
database, the experimental results show that achieve obvious improvement (11%
relative) is achieved by our algorithm over the conventional systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08786</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08786</id><created>2018-08-27</created><authors><author><keyname>Levanen</keyname><forenames>Toni</forenames></author><author><keyname>Pirskanen</keyname><forenames>Juho</forenames></author><author><keyname>Pajukoski</keyname><forenames>Kari</forenames></author><author><keyname>Renfors</keyname><forenames>Markku</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Transparent Tx and Rx Waveform Processing for 5G New Radio Mobile
  Communications</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Wireless Communications Magazine in
  June 2018. This is the revised version of the original article, and it is in
  press at the moment</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several different waveform processing techniques have been studied and
proposed for the 5G new radio (NR) physical layer, to support new mixed
numerology and asynchronous services. The evaluation and comparison of these
different techniques is commonly based on matched waveform processing in the
transmitter and receiver units. In this article, it is shown that different
techniques can be flexibly mixed, allowing to separately optimize
complexity-performance trade-offs for transmitter and receiver implementations.
Mixing of different waveform processing techniques is possible by setting
adequate requirements for transmitter and receiver baseband processing allowing
transparent design. The basic framework of how transmitter and receiver units
can be independently applied and evaluated in the context of transparent design
and an extensive set of examples of the achievable radio link performance with
unmatched transmitter and receiver waveform processing are provided. The
discussed approach and solutions simplify standardization, improve transparent
transmitter and receiver coexistence, and allow future-proof evolution path for
performance improvements in 5G NR physical layer hardware and algorithm design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08790</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08790</id><created>2018-08-17</created><authors><author><keyname>Gu</keyname><forenames>Xueping</forenames></author><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Jia</keyname><forenames>Jinghua</forenames></author></authors><title>Feature selection for transient stability assessment based on kernelized
  fuzzy rough sets and memetic algorithm</title><categories>eess.SP</categories><comments>Accepted by International Journal of Electrical Power &amp; Energy
  Systems</comments><journal-ref>International Journal of Electrical Power &amp; Energy Systems 64
  (2015) 664-670</journal-ref><doi>10.1016/j.ijepes.2014.07.070</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new feature selection method based on kernelized fuzzy rough sets (KFRS)
and the memetic algorithm (MA) is proposed for transient stability assessment
of power systems. Considering the possible real-time information provided by
wide-area measurement systems, a group of system-level classification features
are extracted from the power system operation parameters to build the original
feature set. By defining a KFRS-based generalized classification function as
the separability criterion, the memetic algorithm based on binary differential
evolution (BDE) and Tabu search (TS) is employed to obtain the optimal feature
subsets with the maximized classification capability. The proposed method may
avoid the information loss caused by the feature discretization process of the
rough-set based attribute selection, and comprehensively utilize the advantages
of BDE and TS to improve the solution quality and search efficiency. The
effectiveness of the proposed method is validated by the application results on
the New England 39-bus power system and the southern power system of Hebei
province.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08791</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08791</id><created>2018-08-27</created><updated>2019-08-12</updated><authors><author><keyname>Ye</keyname><forenames>Siqi</forenames></author><author><keyname>Ravishankar</keyname><forenames>Saiprasad</forenames></author><author><keyname>Long</keyname><forenames>Yong</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>SPULTRA: Low-Dose CT Image Reconstruction with Joint Statistical and
  Learned Image Models</title><categories>eess.SP eess.IV math.OC physics.med-ph</categories><comments>Accepted to IEEE Transaction on Medical Imaging</comments><doi>10.1109/TMI.2019.2934933</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-dose CT image reconstruction has been a popular research topic in recent
years. A typical reconstruction method based on post-log measurements is called
penalized weighted-least squares (PWLS). Due to the underlying limitations of
the post-log statistical model, the PWLS reconstruction quality is often
degraded in low-dose scans. This paper investigates a shifted-Poisson (SP)
model based likelihood function that uses the pre-log raw measurements that
better represents the measurement statistics, together with a data-driven
regularizer exploiting a Union of Learned TRAnsforms (SPULTRA). Both the SP
induced data-fidelity term and the regularizer in the proposed framework are
nonconvex. The proposed SPULTRA algorithm uses quadratic surrogate functions
for the SP induced data-fidelity term. Each iteration involves a quadratic
subproblem for updating the image, and a sparse coding and clustering
subproblem that has a closed-form solution. The SPULTRA algorithm has a similar
computational cost per iteration as its recent counterpart PWLS-ULTRA that uses
post-log measurements, and it provides better image reconstruction quality than
PWLS-ULTRA, especially in low-dose scans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08808</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08808</id><created>2018-08-16</created><authors><author><keyname>Zhu</keyname><forenames>Shilin</forenames></author><author><keyname>Li</keyname><forenames>Yilong</forenames></author></authors><title>2DR: Towards Fine-Grained 2-D RFID Touch Sensing</title><categories>eess.SP cs.ET cs.HC cs.NI</categories><comments>RFID Touch Sensing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce 2DR, a single RFID tag which can seamlessly sense
two-dimensional human touch using off-the-shelf RFID readers. Instead of using
a two-dimensional tag array to sense human finger touch on a surface, 2DR only
uses one or two RFID chip(s), which reduces the manufacturing cost and makes
the tag more suitable for printing on flexible materials. The key idea behind
2DR is to design a custom-shape antenna and classify human finger touch based
on unique phase information using statistical learning. We printed 2DR tag on
FR-4 substrate and use off-the-shelf UHF-RFID readers (FCC frequency band) to
sense different touch activities. Experiments show great potential of our
design. Moreover, 2DR can be further extended to 3D by building stereoscopic
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08828</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08828</id><created>2018-08-07</created><authors><author><keyname>Xu</keyname><forenames>Xingyuan</forenames></author><author><keyname>Wu</keyname><forenames>Jiayang</forenames></author><author><keyname>Tan</keyname><forenames>Mengxi</forenames></author><author><keyname>Nguyen</keyname><forenames>Thach G.</forenames></author><author><keyname>Chu</keyname><forenames>Sai T.</forenames></author><author><keyname>Little</keyname><forenames>Brent E.</forenames></author><author><keyname>Morandotti</keyname><forenames>Roberto</forenames></author><author><keyname>Mitchell</keyname><forenames>Arnan</forenames></author><author><keyname>Moss</keyname><forenames>David J.</forenames></author></authors><title>Photonic single sideband RF generator based on an integrated optical
  micro-ring resonator</title><categories>eess.SP</categories><comments>10 pages, 13 Figures, 53 references</comments><journal-ref>IEEE Journal of Lightwave Technology (JLT) Volume 36 (2018)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate narrowband orthogonally polarized optical RF single sideband
generation as well as dual-channel equalization based on an integrated
dual-polarization-mode high-Q microring resonator. The device operates in the
optical communications band and enables narrowband RF operation at either 16.6
GHz or 32.2 GHz, determined by the free spectral range and TE/TM mode interval
in the resonator. We achieve a very large dynamic tuning range of over 55 dB
for both the optical carrier-to-sideband ratio and the dual-channel RF
equalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08929</identifier>
 <datestamp>2018-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08929</id><created>2018-08-27</created><authors><author><keyname>de Andrade</keyname><forenames>Douglas Coimbra</forenames></author><author><keyname>Leo</keyname><forenames>Sabato</forenames></author><author><keyname>Viana</keyname><forenames>Martin Loesener Da Silva</forenames></author><author><keyname>Bernkopf</keyname><forenames>Christoph</forenames></author></authors><title>A neural attention model for speech command recognition</title><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper introduces a convolutional recurrent network with attention for
speech command recognition. Attention models are powerful tools to improve
performance on natural language, image captioning and speech tasks. The
proposed model establishes a new state-of-the-art accuracy of 94.1% on Google
Speech Commands dataset V1 and 94.5% on V2 (for the 20-commands recognition
task), while still keeping a small footprint of only 202K trainable parameters.
Results are compared with previous convolutional implementations on 5 different
tasks (20 commands recognition (V1 and V2), 12 commands recognition (V1), 35
word recognition (V1) and left-right (V1)). We show detailed performance
results and demonstrate that the proposed attention mechanism not only improves
performance but also allows inspecting what regions of the audio were taken
into consideration by the network when outputting a given category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.08950</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.08950</id><created>2018-08-25</created><authors><author><keyname>Amer</keyname><forenames>Ramy</forenames></author></authors><title>Techniques for Cooperative Cognitive Radio Networks</title><categories>eess.SP</categories><comments>Master's thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The frequency spectrum is an essential resource for wireless communication.
Special sections of the spectrum are used for military purposes, governments
sell some frequency bands to broadcasting and mobile communications companies
for commercial use, others such as ISM (Industrial, Science and Medical) bands
are available for the public free of charge. As the spectrum becomes
overcrowded, there seem to be two possible solutions: pushing the frequency
limits higher to frequencies of 60 GHz and above, or reaggregating the densely
used licensed frequency bands. The new Cognitive Radio (CR) approach comes with
the feasible solution to spectrum scarcity. Secondary utilization of a licensed
spectrum band can enhance the spectrum usage and introduce a reliable solution
to its dearth. In such a cognitive radio network, secondary users can access
the spectrum under the constraint that a minimum quality of service is
guaranteed for the licensed primary users. In this thesis, we focus on spectrum
sharing techniques in cognitive radio network where there is a number of
secondary users sharing unoccupied spectrum holes. More specifically, we
introduce two collaborative cognitive radio networks in which the secondary
user cooperate with the primary user to deliver the data of the primary user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09025</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09025</id><created>2018-08-27</created><authors><author><keyname>Tzang</keyname><forenames>Omer</forenames></author><author><keyname>Niv</keyname><forenames>Eyal</forenames></author><author><keyname>Singh</keyname><forenames>Sakshi</forenames></author><author><keyname>Labouesse</keyname><forenames>Simon</forenames></author><author><keyname>Myatt</keyname><forenames>Greg</forenames></author><author><keyname>Piestun</keyname><forenames>Rafael</forenames></author></authors><title>Wavefront shaping in complex media at 350 KHz with a 1D-to-2D transform</title><categories>eess.IV physics.optics</categories><comments>8 pages, 5 figures</comments><doi>10.1038/s41566-019-0503-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controlling the propagation and interaction of light in complex media has
sparked major interest in the last few years. Unfortunately, spatial light
modulation devices suffer from limited speed that precludes real-time
applications such as imaging in live tissue. To address this critical problem
we introduce a phase-control technique to characterize complex media based on
the use of fast 1D spatial light modulators and a 1D-to-2D transformation
performed by the same medium being analyzed. We implement the concept using a
micro-electro-mechanical grating light valve (GLV) with 1088 degrees of freedom
modulated at 350 KHz, enabling unprecedented high-speed wavefront measurements.
We continuously measure the transmission matrix, calculate the optimal
wavefront and project a focus through various dynamic scattering samples in
real-time, all within 2.4 ms per cycle. These results improve prior wavefront
shaping modulation speed by more than an order of magnitude and open new
opportunities for optical processing using 1D-to-2D transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09106</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09106</id><created>2018-08-28</created><authors><author><keyname>Shinoda</keyname><forenames>Kazuma</forenames></author></authors><title>Snapshot multispectral imaging using a filter array</title><categories>eess.IV</categories><comments>This paper has been submitted to International Workshop on Image
  Sensors and Imaging Systems (IWISS2018) (Invited talk)</comments><journal-ref>International Workshop on Image Sensors and Imaging Systems
  (IWISS2018)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multispectral filter array (MSFA) is one solution for capturing a
multispectral image (MSI) in a single shot at low cost. We introduce our
optimization method of the spectral sensitivity of the MSFAs and demosaicking,
and show a new prototype filter array for snapshot imaging based on a photonic
crystal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09124</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09124</id><created>2018-08-28</created><updated>2018-10-12</updated><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Xu</keyname><forenames>Xingyu</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Analysis of Frequency Agile Radar via Compressed Sensing</title><categories>cs.IT eess.SP math.IT</categories><comments>12 pages, 10 figures</comments><journal-ref>IEEE Transactions on Signal Processing, DECEMBER 1,.2018</journal-ref><doi>10.1109/TSP.2018.2876301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency agile radar (FAR) is known to have excellent electronic
counter-countermeasures (ECCM) performance and the potential to realize
spectrum sharing in dense electromagnetic environments. Many compressed sensing
(CS) based algorithms have been developed for joint range and Doppler
estimation in FAR. This paper considers theoretical analysis of FAR via CS
algorithms. In particular, we analyze the properties of the sensing matrix,
which is a highly structured random matrix. We then derive bounds on the number
of recoverable targets. Numerical simulations and field experiments validate
the theoretical findings and demonstrate the effectiveness of CS approaches to
FAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09269</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09269</id><created>2018-08-28</created><authors><author><keyname>Purwita</keyname><forenames>Ardimas Andi</forenames></author><author><keyname>Soltani</keyname><forenames>Mohammad Dehghani</forenames></author><author><keyname>Safari</keyname><forenames>Majid</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Terminal Orientation in OFDM-based LiFi Systems</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light-fidelity (LiFi) is a wireless communication technology that employs
both infrared and visible light spectra to support multiuser access and user
mobility. Considering the small wavelength of light, the optical channel is
affected by the random orientation of a user equipment (UE). In this paper, a
random process model for changes in the UE orientation is proposed based on
data measurements. We show that the coherence time of the random orientation is
in the order of hundreds of milliseconds. Therefore, an indoor optical wireless
channel can be treated as a slowly-varying channel as its delay spread is
typically in the order of nanoseconds. A study of the orientation model on the
performance of direct-current-biased orthogonal frequency-division multiplexing
(DC-OFDM) is also presented. The performance analysis of the DC-OFDM system
incorporates the effect of diffuse link due to reflection and blockage by the
user. The results show that the diffuse link and the blockage have significant
effects, especially if the UE is located relatively far away from an access
point (AP). It is shown that the effect is notable if the horizontal distance
between the UE and the AP is greater than $1.5$ m in a typical
$5\times3.5\times3$ m$^3$ indoor room.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09275</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09275</id><created>2018-08-28</created><authors><author><keyname>Cerovi&#x107;</keyname><forenames>Stefan</forenames></author><author><keyname>Visoz</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Madier</keyname><forenames>Louis</forenames></author></authors><title>Efficient Cooperative HARQ for Multi-Source Multi-Relay Wireless
  Networks</title><categories>eess.SP</categories><comments>Paper accepted to Eleventh International Workshop on Selected Topics
  in Wireless and Mobile computing (STWiMob'2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we compare the performance of three different cooperative
Hybrid Automatic Repeat reQuest (HARQ) protocols for slow-fading half-duplex
orthogonal multiple access multiple relay channel. Channel State Information
(CSI) is available at the receiving side of each link only. Time Division
Multiplexing is assumed, where each orthogonal transmission occurs during a
time-slot. Sources transmit in turns in consecutive time slots during the first
transmission phase. During the second phase, the destination schedules in each
time-slot one node (source or relay) to transmit redundancies based on its
correctly decoded source messages (its decoding set) with the goal to maximize
the average spectral efficiency. Bidirectional limited control channels are
available from sources and relays towards the destination to implement the
necessary control signaling of the HARQ protocols. Among the three proposed
HARQ, two follow the Incremental Redundancy (IR) approach. One consists in
sending incremental redundancies on all the messages from the scheduled node
decoding set (Multi-User encoding) while the other one helps a single source
(Single User encoding) chosen randomly. The third one is of the Chase Combining
(CC) type, where the selected node repeats the transmission (including
modulation and coding scheme) of one source chosen randomly from its decoding
set. Monte-Carlo simulations confirm that the IR-type of HARQ with Multi-User
encoding offers the best performance, followed by IR-type of HARQ with Single
User encoding and CC-type of HARQ. We conclude that IR-type of HARQ with Single
User encoding offers the best trade-off between performance and complexity for
a small number of sources in our setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09287</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09287</id><created>2018-08-28</created><authors><author><keyname>Sanchez</keyname><forenames>Jesus Rodriguez</forenames></author><author><keyname>Rusek</keyname><forenames>Fredrik</forenames></author><author><keyname>Sarajlic</keyname><forenames>Muris</forenames></author><author><keyname>Edfors</keyname><forenames>Ove</forenames></author><author><keyname>Liu</keyname><forenames>Liang</forenames></author></authors><title>Fully Decentralized Massive MIMO Detection Based on Recursive Methods</title><categories>eess.SP cs.IT math.IT</categories><comments>Manuscript accepted for presentation at IEEE SiPS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms for Massive MIMO uplink detection typically rely on a centralized
approach, by which baseband data from all antennas modules are routed to a
central node in order to be processed. In case of Massive MIMO, where hundreds
or thousands of antennas are expected in the base-station, this architecture
leads to a bottleneck, with critical limitations in terms of interconnection
bandwidth requirements. This paper presents a fully decentralized architecture
and algorithms for Massive MIMO uplink based on recursive methods, which do not
require a central node for the detection process. Through a recursive approach
and very low complexity operations, the proposed algorithms provide a sequence
of estimates that converge asymptotically to the zero-forcing solution, without
the need of specific hardware for matrix inversion. The proposed solution
achieves significantly lower interconnection data-rate than other
architectures, enabling future scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09351</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09351</id><created>2018-08-28</created><updated>2018-12-18</updated><authors><author><keyname>Yao</keyname><forenames>Shunyu</forenames></author><author><keyname>Hsu</keyname><forenames>Tzu Ming Harry</forenames></author><author><keyname>Zhu</keyname><forenames>Jun-Yan</forenames></author><author><keyname>Wu</keyname><forenames>Jiajun</forenames></author><author><keyname>Torralba</keyname><forenames>Antonio</forenames></author><author><keyname>Freeman</keyname><forenames>William T.</forenames></author><author><keyname>Tenenbaum</keyname><forenames>Joshua B.</forenames></author></authors><title>3D-Aware Scene Manipulation via Inverse Graphics</title><categories>cs.CV cs.GR eess.IV</categories><comments>NeurIPS 2018. Code: https://github.com/ysymyth/3D-SDN Website:
  http://3dsdn.csail.mit.edu/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We aim to obtain an interpretable, expressive, and disentangled scene
representation that contains comprehensive structural and textural information
for each object. Previous scene representations learned by neural networks are
often uninterpretable, limited to a single object, or lacking 3D knowledge. In
this work, we propose 3D scene de-rendering networks (3D-SDN) to address the
above issues by integrating disentangled representations for semantics,
geometry, and appearance into a deep generative model. Our scene encoder
performs inverse graphics, translating a scene into a structured object-wise
representation. Our decoder has two components: a differentiable shape renderer
and a neural texture generator. The disentanglement of semantics, geometry, and
appearance supports 3D-aware scene manipulation, e.g., rotating and moving
objects freely while keeping the consistent shape and texture, and changing the
object appearance without affecting its shape. Experiments demonstrate that our
editing scheme based on 3D-SDN is superior to its 2D counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09369</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09369</id><created>2018-06-09</created><authors><author><keyname>Teymourzadeh</keyname><forenames>Rozita</forenames></author><author><keyname>Othman</keyname><forenames>Masuri</forenames></author></authors><title>VLSI Implementation of Cascaded Integrator comb filters for DSP
  applications</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1807.10309 and
  arXiv:1806.00704, arXiv:1808.02344, arXiv:1808.02349</comments><journal-ref>National Technical Postgraduate Symposium, TechPos 2006. Faculty
  of Engineering, University of Malaya, Malaysia, pp. 54-58</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recursive comb filters or Cascaded Integrator Comb filter (CIC) are
commonly used as decimators for the sigma-delta modulators. This paper presents
the VLSI implementation, analysis and design of high-speed CIC filters which
are based on a low-pass filter. These filters are used in the signal decimation
which has the effect on reducing the sampling rate. It is also chosen because
its attractive property of both low power and low complexity since it does not
require a multiplier. Simulink toolbox available in Matlab software which is
used to simulator and Verilog HDL coding help to verify the functionality of
the CIC filters. Design procedures and examples are given for CIC filter with
emphasis on frequency response, transfer function and register width. The
implementation results show using Modified Carry Look-ahead Adder for summation
and also apply pipelined filter structure enhanced high speed and make it more
compatible with DSP applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09399</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09399</id><created>2018-08-28</created><authors><author><keyname>Lakiotakis</keyname><forenames>Emmanouil</forenames></author><author><keyname>Liaskos</keyname><forenames>Christos</forenames></author><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author></authors><title>Application-Network Collaboration Using SDN for Ultra-Low Delay
  Teleorchestras</title><categories>cs.SY eess.SP</categories><doi>10.1109/ISCC.2017.8024507</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networked Music Performance (NMP) constitutes a class of ultra-low delay
sensitive applications, allowing geographically separate musicians to perform
seamlessly as a tele-orchestra. For this application type, the QoS indicator is
the mouth-to-ear delay, which should be kept under 25 milliseconds. The
mouth-to-ear delay comprises signal processing latency and network delay. We
propose a strong collaboration between the network and NMP applications to
\emph{actively} keep the to mouth-to-ear delay minimal, using direct state
notifications. Related approaches can be characterized as \emph{passive}, since
they try to estimate the network state indirectly, based on the end application
performance. Our solution employs Software Defined Networking (SDN) to
implement the network-to-application collaboration, being facilitated by the
well-defined network interface that SDN offers. Emulation results show that the
proposed scheme achieves an improvement of up to 59% in mouth-to-ear delay over
the existing passive solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09405</identifier>
 <datestamp>2018-09-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09405</id><created>2018-08-28</created><updated>2018-09-06</updated><authors><author><keyname>Lakiotakis</keyname><forenames>Emmanouil</forenames></author><author><keyname>Liaskos</keyname><forenames>Christos</forenames></author><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author></authors><title>Improving Networked Music Performance Systems Using Application-Network
  Collaboration</title><categories>cs.SY eess.SP</categories><comments>Published at Elsevier Concurrency Computat. Pract. Exper. 2018.
  https://doi.org/10.1002/cpe.4730</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networked Music Performance (NMP) systems involve musicians located in
different places who perform music while staying synchronized via the Internet.
The maximum end-to-end delay in NMP applications is called Ensemble Performance
Threshold (EPT) and should be less than 25 milliseconds. Due to this
constraint, NMPs require ultra-low delay solutions for audio coding, network
transmission, relaying and decoding, each one a challenging task on its own.
There are two directions for study in the related work referring to the NMP
systems. From the audio perspective, researchers experiment on low-delay
encoders and transmission patterns, aiming to reduce the processing delay of
the audio transmission, but they ignore the network performance. On the other
hand, network-oriented researchers try to reduce the network delay, which
contributes to reduced end-to-end delay. In our proposed approach, we introduce
an integration of dynamic audio and network configuration to satisfy the EPT
constraint. The basic idea is that the major components participating in an NMP
system the application and the network interact during the live music
performance. As the network delay increases, the network tries to equalize it
by modifying the routing behavior using Software Defined Networking principles.
If the network delay exceeds a maximum affordable threshold, the network reacts
by informing the application to change the audio processing pattern to overcome
the delay increase, resulting in below EPT end-to-end delay. A full prototype
of the proposed system was implemented and extensively evaluated in an emulated
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09432</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09432</id><created>2018-08-28</created><authors><author><keyname>M.</keyname><forenames>Nazreen P.</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>A. G.</forenames></author></authors><title>Using Monte Carlo dropout for non-stationary noise reduction from speech</title><categories>eess.AS cs.SD</categories><comments>This article draws from our previous work arXiv:1806.00516</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose the use of dropout as a Bayesian estimator for
increasing the generalizability of a deep neural network (DNN) for speech
enhancement. By using Monte Carlo (MC) dropout, we show that the DNN performs
better enhancement in unseen noise and SNR conditions. The DNN is trained on
speech corrupted with Factory2, M109, Babble, Leopard and Volvo noises at SNRs
of 0, 5 and 10 dB. Speech samples are obtained from the TIMIT database and
noises from NOISEX-92. In another experiment, we train five DNN models
separately on speech corrupted with Factory2, M109, Babble, Leopard and Volvo
noises, at 0, 5 and 10 dB SNRs. The model precision (estimated using MC
dropout) is used as a proxy for squared error to dynamically select the best of
the DNN models based on their performance on each frame of test data. We
propose an algorithm with a threshold on the model precision to switch between
classifier based model selection scheme and model precision based selection
scheme. Testing is done on speech corrupted with unseen noises White, Pink and
Factory1 and all five seen noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09634</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09634</id><created>2018-08-29</created><authors><author><keyname>Huang</keyname><forenames>Wen-Chin</forenames></author><author><keyname>Hwang</keyname><forenames>Hsin-Te</forenames></author><author><keyname>Peng</keyname><forenames>Yu-Huai</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author></authors><title>Voice Conversion Based on Cross-Domain Features Using Variational Auto
  Encoders</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted to ISCSLP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An effective approach to non-parallel voice conversion (VC) is to utilize
deep neural networks (DNNs), specifically variational auto encoders (VAEs), to
model the latent structure of speech in an unsupervised manner. A previous
study has confirmed the ef- fectiveness of VAE using the STRAIGHT spectra for
VC. How- ever, VAE using other types of spectral features such as mel- cepstral
coefficients (MCCs), which are related to human per- ception and have been
widely used in VC, have not been prop- erly investigated. Instead of using one
specific type of spectral feature, it is expected that VAE may benefit from
using multi- ple types of spectral features simultaneously, thereby improving
the capability of VAE for VC. To this end, we propose a novel VAE framework
(called cross-domain VAE, CDVAE) for VC. Specifically, the proposed framework
utilizes both STRAIGHT spectra and MCCs by explicitly regularizing multiple
objectives in order to constrain the behavior of the learned encoder and de-
coder. Experimental results demonstrate that the proposed CD- VAE framework
outperforms the conventional VAE framework in terms of subjective tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09638</identifier>
 <datestamp>2018-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09638</id><created>2018-08-29</created><updated>2018-10-25</updated><authors><author><keyname>Shim</keyname><forenames>Hye-Jin</forenames></author><author><keyname>Jung</keyname><forenames>Jee-weon</forenames></author><author><keyname>Heo</keyname><forenames>Hee-Soo</forenames></author><author><keyname>Yoon</keyname><forenames>Sunghyun</forenames></author><author><keyname>Yu</keyname><forenames>Ha-Jin</forenames></author></authors><title>Replay spoofing detection system for automatic speaker verification
  using multi-task learning of noise classes</title><categories>eess.AS cs.LG cs.SD eess.SP stat.ML</categories><comments>5 pages, accepted by Technologies and Applications of Artificial
  Intelligence(TAAI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a replay attack spoofing detection system for
automatic speaker verification using multitask learning of noise classes. We
define the noise that is caused by the replay attack as replay noise. We
explore the effectiveness of training a deep neural network simultaneously for
replay attack spoofing detection and replay noise classification. The
multi-task learning includes classifying the noise of playback devices,
recording environments, and recording devices as well as the spoofing
detection. Each of the three types of the noise classes also includes a genuine
class. The experiment results on the ASVspoof2017 datasets demonstrate that the
performance of our proposed system is improved by 30% relatively on the
evaluation set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09730</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09730</id><created>2018-08-29</created><authors><author><keyname>Lostanlen</keyname><forenames>Vincent</forenames></author><author><keyname>And&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Lagrange</keyname><forenames>Mathieu</forenames></author></authors><title>Extended playing techniques: The next milestone in musical instrument
  recognition</title><categories>cs.SD eess.AS</categories><comments>10 pages, 9 figures. The source code to reproduce the experiments of
  this paper is made available at:
  https://www.github.com/mathieulagrange/dlfm2018</comments><journal-ref>Proceedings of the 5th International Workshop on Digital Libraries
  for Musicology (DLfM), Paris, France, September 2018. Published by ACM's
  International Conference Proceedings Series (ICPS)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The expressive variability in producing a musical note conveys information
essential to the modeling of orchestration and style. As such, it plays a
crucial role in computer-assisted browsing of massive digital music corpora.
Yet, although the automatic recognition of a musical instrument from the
recording of a single &quot;ordinary&quot; note is considered a solved problem, automatic
identification of instrumental playing technique (IPT) remains largely
underdeveloped. We benchmark machine listening systems for query-by-example
browsing among 143 extended IPTs for 16 instruments, amounting to 469 triplets
of instrument, mute, and technique. We identify and discuss three necessary
conditions for significantly outperforming the traditional mel-frequency
cepstral coefficient (MFCC) baseline: the addition of second-order scattering
coefficients to account for amplitude modulation, the incorporation of
long-range temporal dependencies, and metric learning using large-margin
nearest neighbors (LMNN) to reduce intra-class variability. Evaluating on the
Studio On Line (SOL) dataset, we obtain a precision at rank 5 of 99.7% for
instrument recognition (baseline at 89.0%) and of 61.0% for IPT recognition
(baseline at 44.5%). We interpret this gain through a qualitative assessment of
practical usability and visualization using nonlinear dimensionality reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09740</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09740</id><created>2018-08-29</created><updated>2018-10-30</updated><authors><author><keyname>Qin</keyname><forenames>Yao</forenames></author><author><keyname>Bruzzone</keyname><forenames>Lorenzo</forenames></author><author><keyname>Li</keyname><forenames>Biao</forenames></author><author><keyname>Ye</keyname><forenames>Yuanxin</forenames></author></authors><title>Cross-Domain Collaborative Learning via Cluster Canonical Correlation
  Analysis and Random Walker for Hyperspectral Image Classification</title><categories>eess.IV cs.CV</categories><comments>14 pages, 10 figures</comments><doi>10.1109/TGRS.2018.2889195</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel heterogenous domain adaptation (HDA) method for
hyperspectral image classification with a limited amount of labeled samples in
both domains. The method is achieved in the way of cross-domain collaborative
learning (CDCL), which is addressed via cluster canonical correlation analysis
(C-CCA) and random walker (RW) algorithms. To be specific, the proposed CDCL
method is an iterative process of three main stages, i.e. twice of RW-based
pseudolabeling and cross domain learning via C-CCA. Firstly, given the
initially labeled target samples as training set ($\mathbf{TS}$), the RW-based
pseudolabeling is employed to update $\mathbf{TS}$ and extract target clusters
($\mathbf{TCs}$) by fusing the segmentation results obtained by RW and extended
RW (ERW) classifiers. Secondly, cross domain learning via C-CCA is applied
using labeled source samples and $\mathbf{TCs}$. The unlabeled target samples
are then classified with the estimated probability maps using the model trained
in the projected correlation subspace. Thirdly, both $\mathbf{TS}$ and
estimated probability maps are used for updating $\mathbf{TS}$ again via
RW-based pseudolabeling. When the iterative process finishes, the result
obtained by the ERW classifier using the final $\mathbf{TS}$ and estimated
probability maps is regarded as the final classification map. Experimental
results on four real HSIs demonstrate that the proposed method can achieve
better performance compared with the state-of-the-art HDA and ERW methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09769</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09769</id><created>2018-08-29</created><updated>2018-09-04</updated><authors><author><keyname>Qin</keyname><forenames>Yao</forenames></author><author><keyname>Bruzzone</keyname><forenames>Lorenzo</forenames></author><author><keyname>Li</keyname><forenames>Biao</forenames></author></authors><title>Tensor Alignment Based Domain Adaptation for Hyperspectral Image
  Classification</title><categories>eess.IV cs.CV</categories><comments>15 pages, 10 figures</comments><doi>10.1109/TGRS.2019.2926069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a tensor alignment (TA) based domain adaptation method
for hyperspectral image (HSI) classification. To be specific, HSIs in both
domains are first segmented into superpixels and tensors of both domains are
constructed to include neighboring samples from single superpixel. Then we
consider the subspace invariance between two domains as projection matrices and
original tensors are projected as core tensors with lower dimensions into the
invariant tensor subspace by applying Tucker decomposition. To preserve
geometric information in original tensors, we employ a manifold regularization
term for core tensors into the decomposition progress. The projection matrices
and core tensors are solved in an alternating optimization manner and the
convergence of TA algorithm is analyzed. In addition, a post-processing
strategy is defined via pure samples extraction for each superpixel to further
improve classification performance. Experimental results on four real HSIs
demonstrate that the proposed method can achieve better performance compared
with the state-of-the-art subspace learning methods when a limited amount of
source labeled samples are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09825</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09825</id><created>2018-08-28</created><authors><author><keyname>Adeel</keyname><forenames>Ahsan</forenames></author><author><keyname>Gogate</keyname><forenames>Mandar</forenames></author><author><keyname>Hussain</keyname><forenames>Amir</forenames></author></authors><title>Contextual Audio-Visual Switching For Speech Enhancement in Real-World
  Environments</title><categories>cs.CV cs.SD eess.AS</categories><comments>16 pages, 7 figures. arXiv admin note: substantial text overlap with
  arXiv:1808.00046</comments><report-no>ISSN 1566-2535</report-no><journal-ref>Information Fusion, 2019</journal-ref><doi>10.1016/j.inffus.2019.08.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human speech processing is inherently multimodal, where visual cues (lip
movements) help to better understand the speech in noise. Lip-reading driven
speech enhancement significantly outperforms benchmark audio-only approaches at
low signal-to-noise ratios (SNRs). However, at high SNRs or low levels of
background noise, visual cues become fairly less effective for speech
enhancement. Therefore, a more optimal, context-aware audio-visual (AV) system
is required, that contextually utilises both visual and noisy audio features
and effectively accounts for different noisy conditions. In this paper, we
introduce a novel contextual AV switching component that contextually exploits
AV cues with respect to different operating conditions to estimate clean audio,
without requiring any SNR estimation. The switching module switches between
visual-only (V-only), audio-only (A-only), and both AV cues at low, high and
moderate SNR levels, respectively. The contextual AV switching component is
developed by integrating a convolutional neural network and long-short-term
memory network. For testing, the estimated clean audio features are utilised by
the developed novel enhanced visually derived Wiener filter for clean audio
power spectrum estimation. The contextual AV speech enhancement method is
evaluated under real-world scenarios using benchmark Grid and ChiME3 corpora.
For objective testing, perceptual evaluation of speech quality is used to
evaluate the quality of the restored speech. For subjective testing, the
standard mean-opinion-score method is used. The critical analysis and
comparative study demonstrate the outperformance of proposed contextual AV
approach, over A-only, V-only, spectral subtraction, and log-minimum mean
square error based speech enhancement methods at both low and high SNRs,
revealing its capability to tackle spectro-temporal variation in any real-world
noisy condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.09904</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.09904</id><created>2018-08-29</created><authors><author><keyname>Span</keyname><forenames>Alexander</forenames></author><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Buelow</keyname><forenames>Henning</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>Precoding for Dual Polarization Soliton Transmission</title><categories>cs.IT eess.SP math.IT</categories><comments>Presented at OECC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider dual-polarized optical multi-soliton pulse transmission.
Modulating the nonlinear spectrum, it becomes highly correlated in noisy fiber
links. We propose a simple precoding to significantly reduce the correlation,
allowing disjoint detection of spectral amplitudes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10081</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10081</id><created>2018-08-29</created><authors><author><keyname>Adhikary</keyname><forenames>Rojina</forenames></author><author><keyname>Daigle</keyname><forenames>John N.</forenames></author><author><keyname>Cao</keyname><forenames>Lei</forenames></author></authors><title>DCSM Protocol for Content Transfer in Deep Space Network</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To maximize file transfer from space vehicles to the Earth, we propose a new
space-to-earth content transfer protocol that combines turbo codes, RaptorQ
codes, real-time channel prediction, and dynamic code-rate selection. The
protocol features a practical signal-to-noise ratio prediction model that
facilitates periodic adjustment of the turbo encoder to achieve adaptive rate
transmission. Our simulation results indicate that an increase of about 20% in
file transfer rate is achievable using the proposed protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10086</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10086</id><created>2018-08-29</created><authors><author><keyname>Hasan</keyname><forenames>Md Mehedi</forenames></author><author><keyname>Rahman</keyname><forenames>Tasneem</forenames></author><author><keyname>Ahn</keyname><forenames>Kiok</forenames></author><author><keyname>Chae</keyname><forenames>Oksam</forenames></author></authors><title>Artifacts Detection and Error Block Analysis from Broadcasted Videos</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advancement of IPTV and HDTV technology, previous subtle errors in
videos are now becoming more prominent because of the structure oriented and
compression based artifacts. In this paper, we focus towards the development of
a real-time video quality check system. Light weighted edge gradient magnitude
information is incorporated to acquire the statistical information and the
distorted frames are then estimated based on the characteristics of their
surrounding frames. Then we apply the prominent texture patterns to classify
them in different block errors and analyze them not only in video error
detection application but also in error concealment, restoration and retrieval.
Finally, evaluating the performance through experiments on prominent datasets
and broadcasted videos show that the proposed algorithm is very much efficient
to detect errors for video broadcast and surveillance applications in terms of
computation time and analysis of distorted frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10088</identifier>
 <datestamp>2018-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10088</id><created>2018-08-29</created><updated>2018-09-25</updated><authors><author><keyname>Li</keyname><forenames>Mohan</forenames></author><author><keyname>Liu</keyname><forenames>Min</forenames></author><author><keyname>Hattori</keyname><forenames>Masanori</forenames></author></authors><title>End-to-end Speech Recognition with Adaptive Computation Steps</title><categories>eess.AS cs.CL cs.SD</categories><comments>5 pages, 2 figures, submitted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present Adaptive Computation Steps (ACS) algo-rithm, which
enables end-to-end speech recognition models to dy-namically decide how many
frames should be processed to predict a linguistic output. The model that
applies ACS algorithm follows the encoder-decoder framework, while unlike the
attention-based mod-els, it produces alignments independently at the encoder
side using the correlation between adjacent frames. Thus, predictions can be
made as soon as sufficient acoustic information is received, which makes the
model applicable in online cases. Besides, a small change is made to the
decoding stage of the encoder-decoder framework, which allows the prediction to
exploit bidirectional contexts. We verify the ACS algorithm on a Mandarin
speech corpus AIShell-1, and it achieves a 31.2% CER in the online occasion,
compared to the 32.4% CER of the attention-based model. To fully demonstrate
the advantage of ACS algorithm, offline experiments are conducted, in which our
ACS model achieves an 18.7% CER, outperforming the attention-based counterpart
with the CER of 22.0%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10094</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10094</id><created>2018-08-29</created><authors><author><keyname>Yang</keyname><forenames>Yizhou</forenames></author><author><keyname>Smith</keyname><forenames>David</forenames></author></authors><title>Robust Wireless Body Area Networks Coexistence: A Game Theoretic
  Approach to Time-Division MAC</title><categories>eess.SP</categories><comments>31 pages, 17 figures, submitted for possible publication on ACM
  Transactions on Sensor Networks (TOSN)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The enabling of wireless body area networks (WBANs) coexistence by radio
interference mitigation is very important due to a rapid growth in potential
users, and a lack of a central coordinator among WBANs that are closely
located. In this paper, we propose a TDMA based MAC layer Scheme, with a
back-off mechanism that reduces packet collision probability; and estimate
performance using a Markov chain model. Based on the MAC layer scheme, a novel
non-cooperative game is proposed to jointly adjust sensor node's transmit power
and rate. In comparison with the state-of-art, simulation that includes
empirical data shows that the proposed approach leads to higher throughput and
longer node lifespan as WBAN wearers dynamically move into each other's
vicinity. Moreover, by adaptively tuning contention windows size an alternative
game is developed, which significantly reduces the latency. Both proposed games
provide robust transmission under strong inter-WBAN interferences, but are
demonstrated to be applicable to different scenarios. The uniqueness and
existence of Nash Equilibrium (NE), as well as close-to-optimum social
efficiency, is also proven for both games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10128</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10128</id><created>2018-08-30</created><authors><author><keyname>Chung</keyname><forenames>Yu-An</forenames></author><author><keyname>Wang</keyname><forenames>Yuxuan</forenames></author><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author></authors><title>Semi-Supervised Training for Improving Data Efficiency in End-to-End
  Speech Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although end-to-end text-to-speech (TTS) models such as Tacotron have shown
excellent results, they typically require a sizable set of high-quality &lt;text,
audio&gt; pairs for training, which are expensive to collect. In this paper, we
propose a semi-supervised training framework to improve the data efficiency of
Tacotron. The idea is to allow Tacotron to utilize textual and acoustic
knowledge contained in large, publicly-available text and speech corpora.
Importantly, these external data are unpaired and potentially noisy.
Specifically, first we embed each word in the input text into word vectors and
condition the Tacotron encoder on them. We then use an unpaired speech corpus
to pre-train the Tacotron decoder in the acoustic domain. Finally, we fine-tune
the model using available paired data. We demonstrate that the proposed
framework enables Tacotron to generate intelligible speech using less than half
an hour of paired training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10198</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10198</id><created>2018-08-30</created><authors><author><keyname>Aboughalia</keyname><forenames>Raneem A.</forenames></author><author><keyname>Alkishriwo</keyname><forenames>Osama A. S.</forenames></author></authors><title>Color Image Encryption Based on Chaotic Block Permutation and XOR
  Operation</title><categories>eess.IV cs.CR</categories><comments>6 pages</comments><journal-ref>Libyan International Conference on Electrical Engineering and
  Technologies (LICEET2018)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, chaotic block image permutation and XOR operation are
performed to achieve image encryption. The studied method of encryption makes
use of chaotic systems properties for secure and speed image encryption.
Firstly, the original image is divided into blocks of equal size. Then, two
chaotic maps are used to generate two key streams which are permuted among
themselves to produce one key steam. The image blocks are then shuffled using
part of key stream. Finally, scrambled image is diffused by XOR operation with
the key stream to get the encrypted image. The experimental results of several
performance analyses about the pixel correlation, various statistical analysis,
information entropy analysis, differential analysis, the key space and key
sensitivity analysis, show that the algorithm can resist several know attacks
effectively and has the advantages of large key space, high security, and high
speed, assuring safety performance and secure image encryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10210</identifier>
 <datestamp>2018-08-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10210</id><created>2018-08-30</created><authors><author><keyname>Onireti</keyname><forenames>Oluwakayode</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Imran</keyname><forenames>Ali</forenames></author><author><keyname>Imran</keyname><forenames>Muhammad Ali</forenames></author></authors><title>Outage Probability of Millimeter Wave Cellular Uplink with Truncated
  Power Control</title><categories>eess.SP</categories><comments>11 Figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, using the stochastic geometry, we develop a tractable uplink
modeling framework for the outage probability of both the single and multi-tier
millimeter wave (mmWave) cellular networks. Each tier's mmWave base stations
(BSs) are randomly located and they have particular spatial density, antenna
gain, receiver sensitivity, blockage parameter and pathloss exponents. Our
model takes account of the maximum power limitation and the per-user power
control. More specifically, each user, which could be in line-of-sight (LOS) or
non-LOS to its serving mmWave BS, controls its transmit power such that the
received signal power at its serving BS is equal to a predefined threshold.
Hence, a truncated channel inversion power control scheme is implemented for
the uplink of mmWave cellular networks. We derive closed-form expressions for
the signal-to-interference-and-noise-ratio (SINR) outage probability for the
uplink of both the single and multi-tier mmWave cellular networks. Furthermore,
we analyze the case with a dense network by utilizing the simplified model,
where the LOS region is approximated as a fixed LOS disc. The results show that
imposing a maximum power constraint on the user significantly affects the SINR
outage probability in the uplink of mmWave cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10277</identifier>
 <datestamp>2018-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10277</id><created>2018-08-26</created><updated>2018-11-20</updated><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>On the Performance of a Relay-Assisted Multi-Hop Asymmetric FSO/RF
  Communication System over Negative Exponential atmospheric turbulence with
  the effect of pointing error</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.02269</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a multi-user multi-hop hybrid FSO / RF system is presented.
This structure is consisted of two main parts. The main motivation of
presenting this structure is communication in long-range impassable links or
some specific atmospheric conditions under which RF connection becomes easily
disrupted. Although these effects could be mitigated by consuming more power or
adding processing complexity, but a small user mobile phone cannot deserve more
complexity or power supply. The fact that FSO and RF links are complementary of
each other brings a new solution in mind; an access point that amplifies
received signal via short-range RF link and forwards it to via long-range FSO
link, could solve the mentioned problem. This scenario is exactly implemented
at the first part of the proposed structure. At the second part, a multi-hop
hybrid parallel FSO / RF link is implemented to connect source and destination
Base Stations. It is the first time that in a multi-hop FSO / RF system,
multi-user scheme, signal selection at each hop, known and un-known CSI in
amplify and forward relaying, and saturate atmospheric turbulence with the
effect of pointing error are considered. New expressions are derived in
closed-form for Bit Error Rate (BER) and Outage Probability of the proposed
structure and verified by MATLAB simulations. The proposed structure has
advantages of FSO, RF, relay-assisted, and multi-user systems at the same time.
Results indicate that it has low dependence on number of users and number of
relays. Therefore, it is suitable for areas with varying population and
long-range links. This structure offers independent performance without
additional power consumption, processing latency, and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10298</identifier>
 <datestamp>2018-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10298</id><created>2018-08-30</created><updated>2018-09-08</updated><authors><author><keyname>Nait-Meziane</keyname><forenames>Mohamed</forenames></author><author><keyname>Abed-Meraim</keyname><forenames>Karim</forenames></author><author><keyname>Seghouane</keyname><forenames>Abd-Krim</forenames></author><author><keyname>Mesloub</keyname><forenames>Ammar</forenames></author></authors><title>Hybrid Joint Diagonalization Algorithms</title><categories>eess.SP</categories><comments>Supplementary material (ref. [18]) is included in this file</comments><doi>10.1109/LSP.2018.2868408</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with a hybrid joint diagonalization (JD) problem considering
both Hermitian and transpose congruences. Such problem can be encountered in
certain non-circular signal analysis applications including blind source
separation. We introduce new Jacobi-like algorithms using Givens or a
combination of Givens and hyperbolic rotations. These algorithms are compared
with state-of-the-art methods and their performance gain, especially in the
high dimensional case, is assessed through simulation experiments including
examples related to blind separation of non-circular sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10489</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10489</id><created>2018-08-30</created><authors><author><keyname>Sadeghi</keyname><forenames>Mohammad</forenames></author><author><keyname>Behnia</keyname><forenames>Fereidoon</forenames></author></authors><title>Optimum window length of Savitzky-Golay filters with arbitrary order</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the widely used denoising methods in different domains is the
Savitzky-Golay (SG) filter. The SG filter has two design parameters: window
length and the filter order. As the length of the window increases, the
estimation variance decreases, but the bias error increases at the same time.
Mean square error (MSE) measure includes both bias and variance criteria. In
this paper, we obtain the optimal window length of an SG filter with arbitrary
order which minimizes the MSE. To achieve the optimal window length, we propose
an algorithm whose performance is better than the existing methods. In this
paper, we follow the viewpoint proposed by Persson and Strang and design the
filter on the basis of Chebyshev orthogonal polynomials
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10564</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10564</id><created>2018-08-30</created><updated>2018-10-11</updated><authors><author><keyname>Zhou</keyname><forenames>Kang</forenames></author><author><keyname>Gu</keyname><forenames>Zaiwang</forenames></author><author><keyname>Liu</keyname><forenames>Wen</forenames></author><author><keyname>Luo</keyname><forenames>Weixin</forenames></author><author><keyname>Cheng</keyname><forenames>Jun</forenames></author><author><keyname>Gao</keyname><forenames>Shenghua</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author></authors><title>Multi-Cell Multi-Task Convolutional Neural Networks for Diabetic
  Retinopathy Grading</title><categories>cs.CV eess.IV</categories><comments>Accepted by EMBC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diabetic Retinopathy (DR) is a non-negligible eye disease among patients with
Diabetes Mellitus, and automatic retinal image analysis algorithm for the DR
screening is in high demand. Considering the resolution of retinal image is
very high, where small pathological tissues can be detected only with large
resolution image and large local receptive field are required to identify those
late stage disease, but directly training a neural network with very deep
architecture and high resolution image is both time computational expensive and
difficult because of gradient vanishing/exploding problem, we propose a
\textbf{Multi-Cell} architecture which gradually increases the depth of deep
neural network and the resolution of input image, which both boosts the
training time but also improves the classification accuracy. Further,
considering the different stages of DR actually progress gradually, which means
the labels of different stages are related. To considering the relationships of
images with different stages, we propose a \textbf{Multi-Task} learning
strategy which predicts the label with both classification and regression.
Experimental results on the Kaggle dataset show that our method achieves a
Kappa of 0.841 on test set which is the 4-th rank of all state-of-the-arts
methods. Further, our Multi-Cell Multi-Task Convolutional Neural Networks
(M$^2$CNN) solution is a general framework, which can be readily integrated
with many other deep neural network architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10600</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10600</id><created>2018-08-31</created><updated>2018-09-03</updated><authors><author><keyname>Lee</keyname><forenames>Seungjin</forenames></author><author><keyname>Lee</keyname><forenames>Juheon</forenames></author><author><keyname>lee</keyname><forenames>Kyogu</forenames></author></authors><title>Content-based feature exploration for transparent music recommendation
  using self-attentive genre classification</title><categories>cs.IR cs.SD eess.AS</categories><comments>to appear at ACM RecSys '18 poster(LBR) session</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Interpretation of retrieved results is an important issue in music
recommender systems, particularly from a user perspective. In this study, we
investigate the methods for providing interpretability of content features
using self-attention. We extract lyric features with the self-attentive genre
classification model trained on 140,000 tracks of lyrics. Likewise, we extract
acoustic features using the acoustic model with self-attention trained on
120,000 tracks of acoustic signals. The experimental results show that the
proposed methods provide the characteristics that are interpretable in terms of
both lyrical and musical contents. We demonstrate this by visualizing the
attention weights, and by presenting the most similar songs found using lyric
or audio features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10620</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10620</id><created>2018-08-31</created><updated>2018-12-04</updated><authors><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author></authors><title>Single-Microphone Speech Enhancement and Separation Using Deep Learning</title><categories>cs.SD eess.AS</categories><comments>PhD Thesis. 233 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cocktail party problem comprises the challenging task of understanding a
speech signal in a complex acoustic environment, where multiple speakers and
background noise signals simultaneously interfere with the speech signal of
interest. A signal processing algorithm that can effectively increase the
speech intelligibility and quality of speech signals in such complicated
acoustic situations is highly desirable. Especially for applications involving
mobile communication devices and hearing assistive devices. Due to the
re-emergence of machine learning techniques, today, known as deep learning, the
challenges involved with such algorithms might be overcome. In this PhD thesis,
we study and develop deep learning-based techniques for two sub-disciplines of
the cocktail party problem: single-microphone speech enhancement and
single-microphone multi-talker speech separation. Specifically, we conduct
in-depth empirical analysis of the generalizability capability of modern deep
learning-based single-microphone speech enhancement algorithms. We show that
performance of such algorithms is closely linked to the training data, and good
generalizability can be achieved with carefully designed training data.
Furthermore, we propose uPIT, a deep learning-based algorithm for
single-microphone speech separation and we report state-of-the-art results on a
speaker-independent multi-talker speech separation task. Additionally, we show
that uPIT works well for joint speech separation and enhancement without
explicit prior knowledge about the noise type or number of speakers. Finally,
we show that deep learning-based speech enhancement algorithms designed to
minimize the classical short-time spectral amplitude mean squared error leads
to enhanced speech signals which are essentially optimal in terms of STOI, a
state-of-the-art speech intelligibility estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10638</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10638</id><created>2018-08-31</created><authors><author><keyname>Na</keyname><forenames>Siqi</forenames></author><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>TenDSuR: Tensor-Based 4D Sub-Nyquist Radar</title><categories>eess.SP</categories><comments>5 pages, 2 figures</comments><doi>10.1109/LSP.2018.2885617</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Tensor-based 4D Sub-Nyquist Radar (TenDSuR) that samples in
spectral, spatial, Doppler, and temporal domains at sub-Nyquist rates while
simultaneously recovering the target's direction, Doppler velocity, and range
without loss of native resolutions. We formulate the radar signal model wherein
the received echo samples are represented by a partial third-order tensor. We
then apply compressed sensing in the tensor domain and use our tensor-OMP and
tensor completion algorithms for signal recovery. Our numerical experiments
demonstrate joint estimation of all three target parameters at the same native
resolutions as a conventional radar but with reduced measurements. Furthermore,
tensor completion methods show enhanced performance in off-grid target recovery
with respect to tensor-OMP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10678</identifier>
 <datestamp>2018-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10678</id><created>2018-08-31</created><updated>2018-11-05</updated><authors><author><keyname>Pascual</keyname><forenames>Santiago</forenames></author><author><keyname>Bonafonte</keyname><forenames>Antonio</forenames></author><author><keyname>Serr&#xe0;</keyname><forenames>Joan</forenames></author></authors><title>Self-Attention Linguistic-Acoustic Decoder</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conversion from text to speech relies on the accurate mapping from
linguistic to acoustic symbol sequences, for which current practice employs
recurrent statistical models like recurrent neural networks. Despite the good
performance of such models (in terms of low distortion in the generated
speech), their recursive structure tends to make them slow to train and to
sample from. In this work, we try to overcome the limitations of recursive
structure by using a module based on the transformer decoder network, designed
without recurrent connections but emulating them with attention and positioning
codes. Our results show that the proposed decoder network is competitive in
terms of distortion when compared to a recurrent baseline, whilst being
significantly faster in terms of CPU inference time. On average, it increases
Mel cepstral distortion between 0.1 and 0.3 dB, but it is over an order of
magnitude faster on average. Fast inference is important for the deployment of
speech synthesis systems on devices with restricted resources, like mobile
phones or embedded systems, where speaking virtual assistants are gaining
importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10687</identifier>
 <datestamp>2018-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10687</id><created>2018-08-31</created><updated>2018-11-05</updated><authors><author><keyname>Pascual</keyname><forenames>Santiago</forenames></author><author><keyname>Bonafonte</keyname><forenames>Antonio</forenames></author><author><keyname>Serr&#xe0;</keyname><forenames>Joan</forenames></author><author><keyname>Gonzalez</keyname><forenames>Jose A.</forenames></author></authors><title>Whispered-to-voiced Alaryngeal Speech Conversion with Generative
  Adversarial Networks</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most methods of voice restoration for patients suffering from aphonia either
produce whispered or monotone speech. Apart from intelligibility, this type of
speech lacks expressiveness and naturalness due to the absence of pitch
(whispered speech) or artificial generation of it (monotone speech). Existing
techniques to restore prosodic information typically combine a vocoder, which
parameterises the speech signal, with machine learning techniques that predict
prosodic information. In contrast, this paper describes an end-to-end neural
approach for estimating a fully-voiced speech waveform from whispered
alaryngeal speech. By adapting our previous work in speech enhancement with
generative adversarial networks, we develop a speaker-dependent model to
perform whispered-to-voiced speech conversion. Preliminary qualitative results
show effectiveness in re-generating voiced speech, with the creation of
realistic pitch contours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10743</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10743</id><created>2018-08-31</created><authors><author><keyname>Rabie</keyname><forenames>Khaled</forenames></author><author><keyname>Adebisi</keyname><forenames>Bamidele</forenames></author><author><keyname>Nauryzbayev</keyname><forenames>Galymzhan</forenames></author><author><keyname>Badarneh</keyname><forenames>Osamah S.</forenames></author><author><keyname>Li</keyname><forenames>Xingwang</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Full-Duplex Energy-Harvesting Enabled Relay Networks in Generalized
  Fading Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the performance of a full-duplex decode-and-forward
relaying network over the generalized \kappa-\mu fading channel. The relay is
energy-constrained and relies entirely on harvesting the power signal
transmitted by the source based on the time-switching relaying protocol. A
unified analytical expression for the ergodic outage probability is derived for
the system under consideration. This is then used to derive closed-form
analytical expressions for three special cases of the \kappa-\mu fading model,
namely, Nakagami-m, Rice and Rayleigh. Monte Carlo simulations are provided
throughout to verify the correctness of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10747</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10747</id><created>2018-08-23</created><authors><author><keyname>Barnett</keyname><forenames>Alexander</forenames></author><author><keyname>Epstein</keyname><forenames>Charles L.</forenames></author><author><keyname>Greengard</keyname><forenames>Leslie</forenames></author><author><keyname>Magland</keyname><forenames>Jeremy</forenames></author></authors><title>Geometry of the Phase Retrieval Problem</title><categories>math.NA eess.IV math-ph math.DG math.MP</categories><comments>The pdf is a very large file (9.3MB), due to a large number of
  high-res images</comments><msc-class>49N45, 94A08, 92C55, 94A12, 65R32, 65H99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most powerful approaches to imaging at the nanometer or
subnanometer length scale is coherent diffraction imaging using X-ray sources.
For amorphous (non-crystalline) samples, the raw data can be interpreted as the
modulus of the continuous Fourier transform of the unknown object. Making use
of prior information about the sample (such as its support), a natural goal is
to recover the phase through computational means, after which the unknown
object can be visualized at high resolution. While many algorithms have been
proposed for this phase retrieval problem, careful analysis of its
well-posedness has received relatively little attention. In this paper, we show
that the problem is, in general, not well-posed and describe some of the
underlying issues that are responsible for the ill-posedness. We then show how
this analysis can be used to develop experimental protocols that lead to better
conditioned inverse problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10753</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10753</id><created>2018-08-29</created><authors><author><keyname>Li</keyname><forenames>Shuai</forenames></author><author><keyname>Barbastathis</keyname><forenames>George</forenames></author></authors><title>Spectral pre-modulation of training examples enhances the spatial
  resolution of the Phase Extraction Neural Network (PhENN)</title><categories>eess.IV physics.optics</categories><comments>12 pages, 10 figures</comments><doi>10.1364/OE.26.029340</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Phase Extraction Neural Network (PhENN) is a computational architecture,
based on deep machine learning, for lens-less quantitative phase retrieval from
raw intensity data. PhENN is a deep convolutional neural network trained
through examples consisting of pairs of true phase objects and their
corresponding intensity diffraction patterns; thereafter, given a test raw
intensity pattern PhENN is capable of reconstructing the original phase object
robustly, in many cases even for objects outside the database where the
training examples were drawn from. Here, we show that the spatial frequency
content of the training examples is an important factor limiting PhENN's
spatial frequency response. For example, if the training database is relatively
sparse in high spatial frequencies, as most natural scenes are, PhENN's ability
to resolve fine spatial features in test patterns will be correspondingly
limited. To combat this issue, we propose &quot;flattening&quot; the power spectral
density of the training examples before presenting them to PhENN. For phase
objects following the statistics of natural scenes, we demonstrate
experimentally that the spectral pre-modulation method enhances the spatial
resolution of PhENN by a factor of 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10844</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10844</id><created>2018-08-31</created><authors><author><keyname>Banluesombatkul</keyname><forenames>Nannapas</forenames></author><author><keyname>Rakthanmanon</keyname><forenames>Thanawin</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Single Channel ECG for Obstructive Sleep Apnea Severity Detection using
  a Deep Learning Approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obstructive sleep apnea (OSA) is a common sleep disorder caused by abnormal
breathing. The severity of OSA can lead to many symptoms such as sudden cardiac
death (SCD). Polysomnography (PSG) is a gold standard for OSA diagnosis. It
records many signals from the patient's body for at least one whole night and
calculates the Apnea-Hypopnea Index (AHI) which is the number of apnea or
hypopnea incidences per hour. This value is then used to classify patients into
OSA severity levels. However, it has many disadvantages and limitations.
Consequently, we proposed a novel methodology of OSA severity classification
using a Deep Learning approach. We focused on the classification between normal
subjects (AHI $&lt;$ 5) and severe OSA patients (AHI $&gt;$ 30). The 15-second raw
ECG records with apnea or hypopnea events were used with a series of deep
learning models. The main advantages of our proposed method include easier data
acquisition, instantaneous OSA severity detection, and effective feature
extraction without domain knowledge from expertise. To evaluate our proposed
method, 545 subjects of which 364 were normal and 181 were severe OSA patients
obtained from the MrOS sleep study (Visit 1) database were used with the k-fold
cross-validation technique. The accuracy of 79.45\% for OSA severity
classification with sensitivity, specificity, and F-score was achieved. This is
significantly higher than the results from the SVM classifier with RR Intervals
and ECG derived respiration (EDR) signal feature extraction. The promising
result shows that this proposed method is a good start for the detection of OSA
severity from a single channel ECG which can be obtained from wearable devices
at home and can also be applied to near real-time alerting systems such as
before SCD occurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10845</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10845</id><created>2018-08-31</created><authors><author><keyname>Lakhan</keyname><forenames>Payongkit</forenames></author><author><keyname>Ditthapron</keyname><forenames>Apiwat</forenames></author><author><keyname>Banluesombatkul</keyname><forenames>Nannapas</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Deep Neural Networks with Weighted Averaged Overnight Airflow Features
  for Sleep Apnea-Hypopnea Severity Classification</title><categories>eess.SP physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dramatic raising of Deep Learning (DL) approach and its capability in
biomedical applications lead us to explore the advantages of using DL for sleep
Apnea-Hypopnea severity classification. To reduce the complexity of clinical
diagnosis using Polysomnography (PSG), which is multiple sensing platform, we
incorporates our proposed DL scheme into one single Airflow (AF) sensing signal
(subset of PSG). Seventeen features have been extracted from AF and then fed
into Deep Neural Networks to classify in two studies. First, we proposed a
binary classifications which use the cutoff indices at AHI = 5, 15 and 30
events/hour. Second, the multiple Sleep Apnea-Hypopnea Syndrome (SAHS) severity
classification was proposed to classify patients into 4 groups including no
SAHS, mild SAHS, moderate SAHS, and severe SAHS. For methods evaluation, we
used a higher number of patients than related works to accommodate more
diversity which includes 520 AF records obtained from the MrOS sleep study
(Visit 2) database. We then applied the 10-fold cross-validation technique to
get the accuracy, sensitivity and specificity. Moreover, we compared the
results from our main classifier with other two approaches which were used in
previous researches including the Support Vector Machine (SVM) and the
Adaboost-Classification and Regression Trees (AB-CART). From the binary
classification, our proposed method provides significantly higher performance
than other two approaches with the accuracy of 83.46 %, 85.39 % and 92.69 % in
each cutoff, respectively. For the multiclass classification, it also returns a
highest accuracy of all approaches with 63.70 %.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10852</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10852</id><created>2018-08-31</created><authors><author><keyname>Cheng</keyname><forenames>Patcharin</forenames></author><author><keyname>Autthasan</keyname><forenames>Phairot</forenames></author><author><keyname>Pijarana</keyname><forenames>Boriwat</forenames></author><author><keyname>Chuangsuwanich</keyname><forenames>Ekapol</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Towards Asynchronous Motor Imagery-Based Brain-Computer Interfaces: a
  joint training scheme using deep learning</title><categories>eess.SP cs.HC q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the deep learning (DL) approach is applied to a joint training
scheme for asynchronous motor imagery-based Brain-Computer Interface (BCI). The
proposed DL approach is a cascade of one-dimensional convolutional neural
networks and fully-connected neural networks (CNN-FC). The focus is mainly on
three types of brain responses: non-imagery EEG (\textit{background EEG}),
(\textit{pure imagery}) EEG, and EEG during the transitional period between
background EEG and pure imagery (\textit{transitional imagery}). The study of
transitional imagery signals should provide greater insight into real-world
scenarios. It may be inferred that pure imagery and transitional EEG are high
and low power EEG imagery, respectively. Moreover, the results from the CNN-FC
are compared to the conventional approach for motor imagery-BCI, namely the
common spatial pattern (CSP) for feature extraction and support vector machine
(SVM) for classification (CSP-SVM). Under a joint training scheme, pure and
transitional imagery are treated as the same class, while background EEG is
another class. Ten-fold cross-validation is used to evaluate whether the joint
training scheme significantly improves the performance task of classifying pure
and transitional imagery signals from background EEG. Using sparse of just a
few electrode channels ($C_{z}$, $C_{3}$ and $C_{4}$), mean accuracy reaches
71.52 % and 70.27 % for CNN-FC and CSP-SVM, respectively. On the other hand,
mean accuracy without the joint training scheme achieve only 62.68 % and 52.41
% for CNN-FC and CSP-SVM, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.10858</identifier>
 <datestamp>2018-09-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1808.10858</id><created>2018-08-31</created><authors><author><keyname>Ausawalaithong</keyname><forenames>Worawate</forenames></author><author><keyname>Marukatat</keyname><forenames>Sanparith</forenames></author><author><keyname>Thirach</keyname><forenames>Arjaree</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Automatic Lung Cancer Prediction from Chest X-ray Images Using Deep
  Learning Approach</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since, cancer is curable when diagnosed at an early stage, lung cancer
screening plays an important role in preventive care. Although both low dose
computed tomography (LDCT) and computed tomography (CT) scans provide more
medical information than normal chest x-rays, there is very limited access to
these technologies in rural areas. Recently, there is a trend in using
computer-aided diagnosis (CADx) to assist in screening and diagnosing of cancer
from biomedical images. In this study, the 121-layer convolutional neural
network also known as DenseNet-121 by G. Huang et. al., along with the transfer
learning scheme was explored as a means to classify lung cancer using chest
X-ray images. The model was trained on a lung nodules dataset before training
on the lung cancer dataset to alleviate the problem of a small dataset. The
proposed model yields 74.43$\pm$6.01\% of mean accuracy, 74.96$\pm$9.85\% of
mean specificity, and 74.68$\pm$15.33\% of mean sensitivity. The proposed model
also provides a heatmap for identifying the location of the lung nodule. These
findings are promising for further development of chest x-ray-based lung cancer
diagnosis using the deep learning approach. Moreover, these findings solve the
problem of small dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00020</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00020</id><created>2018-08-31</created><updated>2019-05-17</updated><authors><author><keyname>Chan</keyname><forenames>Stanley H.</forenames></author></authors><title>Performance Analysis of Plug-and-Play ADMM: A Graph Signal Processing
  Perspective</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Plug-and-Play (PnP) ADMM algorithm is a powerful image restoration
framework that allows advanced image denoising priors to be integrated into
physical forward models to generate high quality image restoration results.
However, despite the enormous number of applications and several theoretical
studies trying to prove the convergence by leveraging tools in convex analysis,
very little is known about why the algorithm is doing so well. The goal of this
paper is to fill the gap by discussing the performance of PnP ADMM. By
restricting the denoisers to the class of graph filters under a linearity
assumption, or more specifically the symmetric smoothing filters, we offer
three contributions: (1) We show conditions under which an equivalent
maximum-a-posteriori (MAP) optimization exists, (2) we present a geometric
interpretation and show that the performance gain is due to an intrinsic
pre-denoising characteristic of the PnP prior, (3) we introduce a new analysis
technique via the concept of consensus equilibrium, and provide interpretations
to problems involving multiple priors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00132</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00132</id><created>2018-09-01</created><authors><author><keyname>Ge</keyname><forenames>Yinghao</forenames></author><author><keyname>Zhang</keyname><forenames>Weile</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Minn</keyname><forenames>Hlaing</forenames></author></authors><title>Angle-Domain Approach for Parameter Estimation in High-Mobility OFDM
  with Fully/Partly Calibrated Massive ULA</title><categories>eess.SP</categories><comments>Single columns, 32 pages, 12 figures, transactions paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a downlink orthogonal frequency division
multiplexing (OFDM) system from a base station to a high-speed train (HST)
equipped with fully/partly calibrated massive uniform linear antenna-array
(ULA) in wireless environments with abundant scatterers. Multiple Doppler
frequency offsets (DFOs) stemming from intensive propagation paths together
with transceiver oscillator frequency offset (OFO) result in a fast
time-varying frequency-selective channel. We develop an angle domain carrier
frequency offset (CFO, general designation for DFO and OFO) estimation
approach. A high-resolution beamforming network is designed to separate
different DFOs into a set of parallel branches in angle domain such that each
branch is mainly affected by a single dominant DFO. Then, a joint estimation
algorithm for both maximum DFO and OFO is developed for fully calibrated ULA.
Next, its estimation mean square error (MSE) performance is analyzed under
inter-subarray mismatches. To mitigate the detrimental effects of
inter-subarray mismatches, we introduce a calibration-oriented beamforming
parameter (COBP) and develop the corresponding modified joint estimation
algorithm for partly calibrated ULA. Moreover, the Cramer-Rao lower bound of
CFO estimation is derived. Both theoretical and numerical results are provided
to corroborate the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00137</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00137</id><created>2018-09-01</created><updated>2019-07-01</updated><authors><author><keyname>Ge</keyname><forenames>Yinghao</forenames></author><author><keyname>Zhang</keyname><forenames>Weile</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Zhang</keyname><forenames>Shun</forenames></author><author><keyname>Ma</keyname><forenames>Xiaoli</forenames></author></authors><title>Beamforming Network Optimization for Reducing Channel Time Variation in
  High-Mobility Massive MIMO</title><categories>eess.SP</categories><comments>Double columns, 13 pages, 10 figures, transactions paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communications in high-mobility environments have caught a lot of attentions
recently. In this paper, fast time-varying channels for massive multiple-input
multiple-output (MIMO) systems are addressed. We derive the exact channel power
spectrum density (PSD) for the uplink from a high-speed railway (HSR) to a base
station (BS) and propose to further reduce the channel time variation via
beamforming network optimization. A large-scale uniform linear array (ULA) is
equipped at the HSR to separate multiple Doppler shifts in angle domain through
high-resolution transmit beamforming. Each branch comprises a dominant Doppler
shift, which can be compensated to suppress the channel time variation, and we
derive the channel PSD and the Doppler spread to assess the residual channel
time variation. Interestingly, the channel PSD can be exactly expressed as the
product of a pattern function and a beam-distortion function. The former
reflects the impact of array aperture and is the converted radiation pattern of
ULA, while the latter depends on the configuration of beamforming directions.
Inspired by the PSD analysis, we introduce a common configurable amplitudes and
phases (CCAP) parameter to optimize the beamforming network, by partly removing
the constant modulus quantized phase constraints of matched filter (MF)
beamformers. In this way, the residual Doppler shifts can be ulteriorly
suppressed, further reducing the residual channel time variation. The optimal
CCAP parameter minimizing the Doppler spread is derived in a closed form.
Numerical results are provided to corroborate both the channel PSD analysis and
the superiority of beamforming network optimization technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00233</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00233</id><created>2018-09-01</created><authors><author><keyname>Acikalin</keyname><forenames>Serife</forenames></author><author><keyname>Eken</keyname><forenames>Suleyman</forenames></author><author><keyname>Sayar</keyname><forenames>Ahmet</forenames></author></authors><title>Sleep Stage Classification: Scalability Evaluations of Distributed
  Approaches</title><categories>cs.DC cs.LG eess.SP</categories><comments>Proceedings of The Third International Conference on Data Mining,
  Internet Computing, and Big Data, Konya, Turkey 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Processing and analyzing of massive clinical data are resource intensive and
time consuming with traditional analytic tools. Electroencephalogram (EEG) is
one of the major technologies in detecting and diagnosing various brain
disorders, and produces huge volume big data to process. In this study, we
propose a big data framework to diagnose sleep disorders by classifying the
sleep stages from EEG signals. The framework is developed with open source
SparkMlib Libraries. We also tested and evaluated the proposed framework by
measuring the scalabilities of well-known classification algorithms on
physionet sleep records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00238</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00238</id><created>2018-09-01</created><authors><author><keyname>Alsouda</keyname><forenames>Yasser</forenames></author><author><keyname>Pllana</keyname><forenames>Sabri</forenames></author><author><keyname>Kurti</keyname><forenames>Arianit</forenames></author></authors><title>A Machine Learning Driven IoT Solution for Noise Classification in Smart
  Cities</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a machine learning based method for noise classification using a
low-power and inexpensive IoT unit. We use Mel-frequency cepstral coefficients
for audio feature extraction and supervised classification algorithms (that is,
support vector machine and k-nearest neighbors) for noise classification. We
evaluate our approach experimentally with a dataset of about 3000 sound samples
grouped in eight sound classes (such as, car horn, jackhammer, or street
music). We explore the parameter space of support vector machine and k-nearest
neighbors algorithms to estimate the optimal parameter values for
classification of sound samples in the dataset under study. We achieve a noise
classification accuracy in the range 85% -- 100%. Training and testing of our
k-nearest neighbors (k = 1) implementation on Raspberry Pi Zero W is less than
a second for a dataset with features of more than 3000 sound samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00305</identifier>
 <datestamp>2018-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00305</id><created>2018-09-02</created><authors><author><keyname>Iida</keyname><forenames>Kenta</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Robust Image Identification for Double-Compressed and Resized JPEG
  Images</title><categories>eess.IV</categories><comments>This paper will be presented at APSIPA Annual Summit and Conference
  2018. arXiv admin note: text overlap with arXiv:1807.06928</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the case that images are shared via social networking services (SNS) and
cloud photo sharing services (CPSS), it is known that the JPEG images uploaded
to the services are often re-compressed and resized by the providers. Because
of such a situation, a new image identification scheme for double-compressed
JPEG images having different sizes from that of a singled-compressed one is
proposed in this paper. The aim is to detect a single-compressed image that has
the same original image as the double-compressed ones, even when the sizes of
those compressed images are different. In the proposed scheme, a feature
extracted from only DC coefficients in DCT coefficients is used for the
identification. The use of the feature allows us not only to robustly avoid
errors caused by double-compression but also to perform the identification for
different size images. The simulation results demonstrate the effectiveness of
the proposed one in terms of the querying performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.00343</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1809.00343</id><created>2018-09-02</created><authors><author><keyname>Zhu</keyname><forenames>Guangxu</forenames></author><author><keyname>Liu</keyname><forenames>Dongzhu</forenames></author><author><keyname>Du</keyname><forenames>Yuqing</forenames></author><author><keyname>You</keyname><forenames>Changsheng</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>Towards an Intelligent Edge: Wireless Communication Meets Machine
  Learning</title><categories>cs.IT cs.LG cs.NI eess.SP math.IT</categories><comments>submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent revival of artificial intelligence (AI) is revolutionizing almost
every branch of science and technology. Given the ubiquitous smart mobile
gadgets and Internet of Things (IoT) devices, it is expected that a majority of
intelligent applications will be deployed at the edge of wireless networks.
This trend has generated strong interests in realizing an &quot;intelligent edge&quot; to
support AI-enabled applications at various edge devices. Accordingly, a new
research area, called edge learning, emerges, which crosses and revolutionizes
two disciplines: wireless communication and machine learning. A major theme in
edge learning is to overcome the limited computing power, as well as limited
data, at each edge device. This is accomplished by leveraging the mobile edge
computing (MEC) platform and exploiting the massive data distributed over a
large number of edge devices. In such systems, learning from distributed data
and communicating between the edge server and devices are two critical and
coupled aspects, and their fusion poses many new research challenges. This
article advocates a new set of design principles for wireless communication in
edge learning, collectively called learning-driven communication. Illustrative
examples are provided to demonstrate the effectiveness of these design
principles, and unique research opportunities are identified.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="2000" completeListSize="16166">4250076|3001</resumptionToken>
</ListRecords>
</OAI-PMH>
