<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T07:02:17Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|8001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07495</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07495</id><created>2019-07-17</created><authors><author><keyname>Michau</keyname><forenames>Gabriel</forenames></author><author><keyname>Pustelnik</keyname><forenames>Nelly</forenames></author><author><keyname>Borgnat</keyname><forenames>Pierre</forenames></author><author><keyname>Abry</keyname><forenames>Patrice</forenames></author><author><keyname>Bhaskar</keyname><forenames>Ashish</forenames></author><author><keyname>Chung</keyname><forenames>Edward</forenames></author></authors><title>Combining traffic counts and Bluetooth data for link-origin-destination
  matrix estimation in large urban networks: The Brisbane case study</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Origin-Destination matrix estimation is a keystone for traffic representation
and analysis. Traditionally estimated thanks to traffic counts, surveys and
socio-economic models, recent technological advances permit to rethink the
estimation problem. Road user identification technologies, such as connected
GPS, Bluetooth or Wifi detectors bring additional information, that is, for a
fraction of the users, the origin, the destination and to some extend the
itinerary taken. In the present work, this additional information is used for
the estimation of a more comprehensive traffic representation tool: the
link-origin-destination matrix. Such three-dimensional matrices extend the
concept of traditional origin-destination matrices by also giving information
on the traffic assignment. Their estimation is solved as an inverse problem
whose objective function represents a trade-off between important properties
the traffic has to satisfy. This article presents the theory and how to
implement such method on real dataset. With the case study of Brisbane City
where over 600 hundreds Bluetooth detectors have been installed it also
illustrates the opportunities such link-origin-destination matrices create for
traffic analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07502</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07502</id><created>2019-07-17</created><authors><author><keyname>Bu</keyname><forenames>Zhiqi</forenames></author><author><keyname>Klusowski</keyname><forenames>Jason</forenames></author><author><keyname>Rush</keyname><forenames>Cynthia</forenames></author><author><keyname>Su</keyname><forenames>Weijie</forenames></author></authors><title>Algorithmic Analysis and Statistical Estimation of SLOPE via Approximate
  Message Passing</title><categories>stat.ML cs.LG eess.SP math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SLOPE is a relatively new convex optimization procedure for high-dimensional
linear regression via the sorted l1 penalty: the larger the rank of the fitted
coefficient, the larger the penalty. This non-separable penalty renders many
existing techniques invalid or inconclusive in analyzing the SLOPE solution. In
this paper, we develop an asymptotically exact characterization of the SLOPE
solution under Gaussian random designs through solving the SLOPE problem using
approximate message passing (AMP). This algorithmic approach allows us to
approximate the SLOPE solution via the much more amenable AMP iterates.
Explicitly, we characterize the asymptotic dynamics of the AMP iterates relying
on a recently developed state evolution analysis for non-separable penalties,
thereby overcoming the difficulty caused by the sorted l1 penalty. Moreover, we
prove that the AMP iterates converge to the SLOPE solution in an asymptotic
sense, and numerical simulations show that the convergence is surprisingly
fast. Our proof rests on a novel technique that specifically leverages the
SLOPE problem. In contrast to prior literature, our work not only yields an
asymptotically sharp analysis but also offers an algorithmic, flexible, and
constructive approach to understanding the SLOPE problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07528</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07528</id><created>2019-07-17</created><authors><author><keyname>Gromova</keyname><forenames>Ekaterina</forenames></author><author><keyname>Marova</keyname><forenames>Ekaterina</forenames></author><author><keyname>Gromov</keyname><forenames>Dmitry</forenames></author></authors><title>A substitute for the classical Neumann--Morgenstern characteristic
  function in cooperative differential games</title><categories>cs.GT cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a systematic overview of different endogenous
optimization-based characteristic functions and discuss their properties.
Furthermore, we define and analyze in detail a new, $\eta$-characteristic
function. This characteristic function has a substantial advantage over other
characteristic functions in that it can be obtained with a minimal
computational effort and has a reasonable economic interpretation. In
particular, the new characteristic function can be seen as a reduced version of
the classical Neumann-Morgenstern characteristic function, where the players
both from the coalition and from the complementary coalition use their
previously computed strategies instead of solving respective optimization
problems. Our finding are illustrated by a pollution control game with $n$
non-identical players. For the considered game, we compute all characteristic
functions and compare their properties. Quite surprisingly, it turns out that
both the characteristic functions and the resulting cooperative solutions
satisfy some symmetry relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07556</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07556</id><created>2019-07-17</created><authors><author><keyname>Niu</keyname><forenames>Luyao</forenames></author><author><keyname>Clark</keyname><forenames>Andrew</forenames></author></authors><title>Optimal Secure Control with Linear Temporal Logic Constraints</title><categories>eess.SY cs.SY</categories><doi>10.1109/TAC.2019.2930039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prior work on automatic control synthesis for cyber-physical systems under
logical constraints has primarily focused on environmental disturbances or
modeling uncertainties, however, the impact of deliberate and malicious attacks
has been less studied. In this paper, we consider a discrete-time dynamical
system with a linear temporal logic (LTL) constraint in the presence of an
adversary, which is modeled as a stochastic game. We assume that the adversary
observes the control policy before choosing an attack strategy. We investigate
two problems. In the first problem, we synthesize a robust control policy for
the stochastic game that maximizes the probability of satisfying the LTL
constraint. A value iteration based algorithm is proposed to compute the
optimal control policy. In the second problem, we focus on a subclass of LTL
constraints, which consist of an arbitrary LTL formula and an invariant
constraint. We then investigate the problem of computing a control policy that
minimizes the expected number of invariant constraint violations while
maximizing the probability of satisfying the arbitrary LTL constraint. We
characterize the optimality condition for the desired control policy. A policy
iteration based algorithm is proposed to compute the control policy. We
illustrate the proposed approaches using two numerical case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07564</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07564</id><created>2019-07-16</created><authors><author><keyname>Jhawar</keyname><forenames>Madan Gopal</forenames></author><author><keyname>Vangala</keyname><forenames>Vipindeep</forenames></author><author><keyname>Sharma</keyname><forenames>Nishchay</forenames></author><author><keyname>Hayatnagarkar</keyname><forenames>Ankur</forenames></author><author><keyname>Saxena</keyname><forenames>Mansi</forenames></author><author><keyname>Valecha</keyname><forenames>Swati</forenames></author></authors><title>Conversational Help for Task Completion and Feature Discovery in
  Personal Assistants</title><categories>cs.HC cs.CL cs.LG cs.SD eess.AS stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Intelligent Personal Assistants (IPAs) have become widely popular in recent
times. Most of the commercial IPAs today support a wide range of skills
including Alarms, Reminders, Weather Updates, Music, News, Factual
Questioning-Answering, etc. The list grows every day, making it difficult to
remember the command structures needed to execute various tasks. An IPA must
have the ability to communicate information about supported skills and direct
users towards the right commands needed to execute them. Users interact with
personal assistants in natural language. A query is defined to be a Help Query
if it seeks information about a personal assistant's capabilities, or asks for
instructions to execute a task. In this paper, we propose an interactive system
which identifies help queries and retrieves appropriate responses. Our system
comprises of a C-BiLSTM based classifier, which is a fusion of Convolutional
Neural Networks (CNN) and Bidirectional LSTM (BiLSTM) architectures, to detect
help queries and a semantic Approximate Nearest Neighbours (ANN) module to map
the query to an appropriate predefined response. Evaluation of our system on
real-world queries from a commercial IPA and a detailed comparison with popular
traditional machine learning and deep learning based models reveal that our
system outperforms other approaches and returns relevant responses for help
queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07565</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07565</id><created>2019-07-17</created><updated>2020-01-13</updated><authors><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Optimal Energy Allocation and Task Offloading Policy for Wireless
  Powered Mobile Edge Computing Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>One-column 32 pages, 6 figures, and accepted for publication in IEEE
  Transactions on Wireless Communications</comments><doi>10.1109/TWC.2020.2964765</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a wireless powered mobile edge computing (MEC) system with
fluctuating channels and dynamic task arrivals over time. We jointly optimize
the transmission energy allocation at the energy transmitter (ET) for WPT and
the task allocation at the user for local computing and offloading over a
particular finite horizon, with the objective of minimizing the total
transmission energy consumption at the ET while ensuring the user's successful
task execution. First, in order to characterize the fundamental performance
limit, we consider the offline optimization by assuming that the perfect
knowledge of channel state information and task state information (i.e., task
arrival timing and amounts) is known a-priori. In this case, we obtain the
well-structured optimal solution in a closed form to the energy minimization
problem via convex optimization techniques. Next, inspired by the structured
offline solutions obtained above, we develop heuristic online designs for the
joint energy and task allocation when the knowledge of CSI/TSI is only causally
known. Finally, numerical results are provided to show that the proposed joint
designs achieve significantly smaller energy consumption than benchmark schemes
with only local computing or full offloading at the user, and the proposed
heuristic online designs perform close to the optimal offline solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07585</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07585</id><created>2019-07-17</created><updated>2019-11-27</updated><authors><author><keyname>Can</keyname><forenames>O&#x11f;ul</forenames></author><author><keyname>G&#xfc;rb&#xfc;z</keyname><forenames>Yeti Ziya</forenames></author><author><keyname>Alatan</keyname><forenames>A. Ayd&#x131;n</forenames></author></authors><title>Deep Metric Learning with Alternating Projections onto Feasible Sets</title><categories>cs.CV cs.LG eess.IV</categories><comments>10 pages, 3 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the training of networks for distance metric learning, minimizers of
the typical loss functions can be considered as &quot;feasible points&quot; satisfying a
set of constraints imposed by the training data. To this end, we reformulate
distance metric learning problem as finding a feasible point of a constraint
set where the embedding vectors of the training data satisfy desired
intra-class and inter-class proximity. The feasible set induced by the
constraint set is expressed as the intersection of the relaxed feasible sets
which enforce the proximity constraints only for particular samples (a sample
from each class) of the training data. Then, the feasible point problem is to
be approximately solved by performing alternating projections onto those
feasible sets. Such an approach introduces a regularization term and results in
minimizing a typical loss function with a systematic batch set construction
where these batches are constrained to contain the same sample from each class
for a certain number of iterations. Moreover, these particular samples can be
considered as the class representatives, allowing efficient utilization of hard
class mining during batch construction. The proposed technique is applied with
the well-accepted losses and evaluated on Stanford Online Products, CAR196 and
CUB200-2011 datasets for image retrieval and clustering. Outperforming
state-of-the-art, the proposed approach consistently improves the performance
of the integrated loss functions with no additional computational cost and
boosts the performance further by hard negative class mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07600</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07600</id><created>2019-07-17</created><authors><author><keyname>Zholbaryssov</keyname><forenames>Madi</forenames></author><author><keyname>Hadjicostis</keyname><forenames>Christoforos N.</forenames></author><author><keyname>Dominguez-Garcia</keyname><forenames>Alejandro D.</forenames></author></authors><title>Fast Distributed Coordination of Distributed Energy Resources Over
  Time-Varying Communication Networks</title><categories>eess.SY cs.MA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of optimally coordinating the response
of a group of distributed energy resources (DERs) to meet total electric power
demand while minimizing the total generation cost and respecting the DER
capacity limits. This problem can be cast as a convex optimization problem,
where the global objective is to minimize a sum of convex functions
corresponding to the costs of generating power from the DERs while satisfying
linear inequality constraints corresponding to the DER capacity limits and a
linear equality constraint corresponding to the total power generated by the
DERs being equal to the total power demand. We develop distributed algorithms
to solve the DER coordination problem over time-varying communication networks
with either (i) bidirectional or (ii) unidirectional communication links. The
algorithms proposed for directed communication graphs have the geometric
convergence rate when communication out-degrees are unknown to agents. The
algorithms can be seen as the distributed versions of a centralized primal-dual
algorithm. We showcase the algorithms using the standard IEEE 39 - bus test
system, and compare their performance against that of existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07626</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07626</id><created>2019-07-15</created><updated>2019-09-01</updated><authors><author><keyname>Tang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Song</keyname><forenames>Liming</forenames></author></authors><title>AP19-OLR Challenge: Three Tasks and Their Baselines</title><categories>eess.AS cs.CL cs.SD</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.00616,
  arXiv:1706.09742, arXiv:1609.08445</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the fourth oriental language recognition (OLR)
challenge AP19-OLR, including the data profile, the tasks and the evaluation
principles. The OLR challenge has been held successfully for three consecutive
years, along with APSIPA Annual Summit and Conference (APSIPA ASC). The
challenge this year still focuses on practical and challenging tasks, precisely
(1) short-utterance LID, (2) cross-channel LID and (3) zero-resource LID. The
event this year includes more languages and more real-life data provided by
SpeechOcean and the NSFC M2ASR project. All the data is free for participants.
Recipes for x-vector system and back-end evaluation are also conducted as
baselines for the three tasks. The participants can refer to these
online-published recipes to deploy LID systems for convenience. We report the
baseline results on the three tasks and demonstrate that the three tasks are
worth some efforts to achieve better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07643</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07643</id><created>2019-07-17</created><authors><author><keyname>Castiglione</keyname><forenames>Luca Maria</forenames></author><author><keyname>Falcone</keyname><forenames>Paolo</forenames></author><author><keyname>Petrillo</keyname><forenames>Alberto</forenames></author><author><keyname>Romano</keyname><forenames>Simon Pietro</forenames></author><author><keyname>Santini</keyname><forenames>Stefania</forenames></author></authors><title>Cooperative Intersection Crossing over 5G</title><categories>cs.NI cs.SY eess.SY</categories><comments>15 pages, 16 figures, submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous driving is a safety critical application of sensing and
decision-making technologies. Communication technologies extend the awareness
capabilities of vehicles, beyond what is achievable with the on-board systems
only. Nonetheless, issues typically related to wireless networking must be
taken into account when designing safe and reliable autonomous systems. The aim
of this work is to present a control algorithm and a communication paradigm
over 5G networks for negotiating traffic junctions in urban areas. The proposed
control framework has been shown to converge in a finite time and the
supporting communication software has been designed with the objective of
minimising communication delays. At the same time, the underlying network
guarantees reliability of the communication. The proposed framework has been
successfully deployed and tested, in partnership with Ericsson AB, at the
AstaZero proving ground in Goteborg, Sweden. In our experiments, three
autonomous vehicles successfully drove through an intersection of 235 square
meters in a urban scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07645</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07645</id><created>2019-07-17</created><authors><author><keyname>Aripov</keyname><forenames>Iskandar</forenames></author></authors><title>The Statistical Analysis of the Live TV Bit Rate</title><categories>cs.NI cs.MM eess.IV</categories><journal-ref>Dhinaharan Nagamalai et al. (Eds) : SAI, NCO, SOFT, ICAITA, CDKP,
  CMC, SIGNAL - 2019 pp. 213-223, 2019. CS &amp; IT-CSCP 2019</journal-ref><doi>10.5121/csit.2019.90716</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the statistical nature of TV channels streaming variable
bit rate distribution and allocation. The goal of the paper is to derive the
best-fit rate distribution to describe TV streaming bandwidth allocation, which
can reveal traffic demands of users. Our analysis uses multiplexers channel
bandwidth allocation (PID) data of 13 TV live channels. We apply 17 continuous
and 3 discrete distributions to determine the best-fit distribution function
for each individual channel and for the whole set of channels. We found that
the generalized extreme distribution fitting most of our channels most
precisely according to the Bayesian information criterion. By the same
criterion tlocationscale distribution matches best for the whole system. We use
these results to propose parameters for streaming server queuing model. Results
are useful for streaming servers scheduling policy design process targeting to
improve limited infrastructural resources, traffic engineering through dynamic
routing at CDN, SDN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07668</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07668</id><created>2019-07-16</created><authors><author><keyname>Yang</keyname><forenames>Yuan</forenames></author><author><keyname>Shi</keyname><forenames>Yang</forenames></author><author><keyname>Constantinescu</keyname><forenames>Daniela</forenames></author></authors><title>Connectivity-Preserving Swarm Teleoperation Over A Tree Network With
  Time-Varying Delays</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A teleoperated swarm must follow the unpredictable commands of its human
operator while remaining connected. When the swarm communications are limited
by distance and affected by delays, both the user input and the transmission
delays endanger the connectivity of the swarm. This paper presents a
constructive control strategy that overcomes both threats. The strategy
modulates the intra-swarm couplings and the damping injected to each slave in
the swarm based on a customized potential. Lyapunov-based set invariance
analysis proves that the proposed explicit gain updating law limits the impact
of the operator input and preserves the initial tree connectivity of a
delay-free swarm. Further augmentation with stricter selection of control gains
robustifies the design to time-varying delays in intra-swarm communications.
The paper also establishes the input-to-state stability of a teleoperated
time-delay swarm under the proposed dynamic control. Experiments validate
connectivity maintenance and synchronization during time-delay swarm
teleoperation with the proposed control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07671</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07671</id><created>2019-07-16</created><authors><author><keyname>Saeed</keyname><forenames>Sanay Muhammad Umar</forenames></author><author><keyname>Anwar</keyname><forenames>Syed Muhammad</forenames></author><author><keyname>Khalid</keyname><forenames>Humaira</forenames></author><author><keyname>Majid</keyname><forenames>Muhammad</forenames></author><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author></authors><title>Electroencephalography based Classification of Long-term Stress using
  Psychological Labeling</title><categories>eess.SP cs.LG stat.ML</categories><comments>Submitted to IEEE JBHI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stress research is a rapidly emerging area in thefield of
electroencephalography (EEG) based signal processing.The use of EEG as an
objective measure for cost effective andpersonalized stress management becomes
important in particularsituations such as the non-availability of mental health
facilities.In this study, long-term stress is classified using baseline
EEGsignal recordings. The labelling for the stress and control groupsis
performed using two methods (i) the perceived stress scalescore and (ii) expert
evaluation. The frequency domain featuresare extracted from five-channel EEG
recordings in addition tothe frontal and temporal alpha and beta asymmetries.
The alphaasymmetry is computed from four channels and used as a feature.Feature
selection is also performed using a t-test to identifystatistically significant
features for both stress and control groups.We found that support vector
machine is best suited to classifylong-term human stress when used with alpha
asymmetry asa feature. It is observed that expert evaluation based
labellingmethod has improved the classification accuracy up to 85.20%.Based on
these results, it is concluded that alpha asymmetry maybe used as a potential
bio-marker for stress classification, when labels are assigned using expert
evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07675</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07675</id><created>2019-07-17</created><authors><author><keyname>Yan</keyname><forenames>Yaxi</forenames></author><author><keyname>Guo</keyname><forenames>Changjian</forenames></author><author><keyname>Wu</keyname><forenames>Xiong</forenames></author><author><keyname>Lin</keyname><forenames>Ziqi</forenames></author><author><keyname>Zhou</keyname><forenames>Xian</forenames></author><author><keyname>Khan</keyname><forenames>Faisal Nadeem</forenames></author><author><keyname>Lau</keyname><forenames>Alan Pak Tao</forenames></author><author><keyname>Lu</keyname><forenames>Chao</forenames></author></authors><title>Distributed vibration sensing based on forward transmission and coherent
  detection</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel ultra-long distributed vibration sensing (DVS) system using forward
transmission and coherent detection is proposed and experimentally
demonstrated. In the proposed scheme, a pair of multi-span optical fibers are
deployed for sensing, and a loop-back configuration is used by connecting the
two fibers at the far end. The homodyne coherent detection is used to retrieve
the phase and state-of-polarization (SOP) fluctuations caused by a vibration
while the localization of the vibration is realized by tracking the phase
changes along the two fibers. The proposed scheme has the advantage of high
signal-to-noise ratio (SNR) and ultra-long sensing range due to the nature of
forward transmission and coherent detection. In addition, using forward rather
than backward scattering allows detection of high frequency vibration signal
over a long sensing range. More than 50dB sensing SNR can be obtained after
long-haul transmission. Meanwhile, localization of 400 Hz, 1 kHz and 10 kHz
vibrations has been experimentally demonstrated with a spatial resolution of
less than 50 m over a total of 1008 km sensing fiber. The sensing length can be
further extended to even trans-oceanic distances using more fiber spans and
erbium-doped fiber amplifiers (EDFAs), making it a promising candidate for
proactive fault detection and localization in long-haul and ultra-long-haul
fiber links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07676</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07676</id><created>2019-07-17</created><authors><author><keyname>Kopelowitz</keyname><forenames>Evi</forenames></author><author><keyname>Engelhard</keyname><forenames>Guy</forenames></author></authors><title>Lung Nodules Detection and Segmentation Using 3D Mask-RCNN</title><categories>eess.IV cs.CV cs.LG</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/Hkxqw5ilcV</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate assessment of Lung nodules is a time consuming and error prone
ingredient of the radiologist interpretation work. Automating 3D volume
detection and segmentation can improve workflow as well as patient care.
Previous works have focused either on detecting lung nodules from a full CT
scan or on segmenting them from a small ROI. We adapt the state of the art
architecture for 2D object detection and segmentation, MaskRCNN, to handle 3D
images and employ it to detect and segment lung nodules from CT scans. We
report on competitive results for the lung nodule detection on LUNA16 data set.
The added value of our method is that in addition to lung nodule detection, our
framework produces 3D segmentations of the detected nodules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07677</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07677</id><created>2019-07-17</created><authors><author><keyname>Liu</keyname><forenames>Hongying</forenames></author><author><keyname>Shen</keyname><forenames>Xiongjie</forenames></author><author><keyname>Shang</keyname><forenames>Fanhua</forenames></author><author><keyname>Wang</keyname><forenames>Fei</forenames></author></authors><title>CU-Net: Cascaded U-Net with Loss Weighted Sampling for Brain Tumor
  Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel cascaded U-Net for brain tumor segmentation.
Inspired by the distinct hierarchical structure of brain tumor, we design a
cascaded deep network framework, in which the whole tumor is segmented firstly
and then the tumor internal substructures are further segmented. Considering
that the increase of the network depth brought by cascade structures leads to a
loss of accurate localization information in deeper layers, we construct many
skip connections to link features at the same resolution and transmit detailed
information from shallow layers to the deeper layers. Then we present a loss
weighted sampling (LWS) scheme to eliminate the issue of imbalanced data during
training the network. Experimental results on BraTS 2017 data show that our
architecture framework outperforms the state-of-the-art segmentation
algorithms, especially in terms of segmentation sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07713</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07713</id><created>2019-07-17</created><authors><author><keyname>Hunt</keyname><forenames>Xin J.</forenames></author><author><keyname>Abbey</keyname><forenames>Ralph</forenames></author><author><keyname>Tharrington</keyname><forenames>Ricky</forenames></author><author><keyname>Huiskens</keyname><forenames>Joost</forenames></author><author><keyname>Wesdorp</keyname><forenames>Nina</forenames></author></authors><title>An AI-Augmented Lesion Detection Framework For Liver Metastases With
  Model Interpretability</title><categories>eess.IV cs.LG q-bio.QM stat.ML</categories><comments>4 pages, 2 figures, 2019 KDD Workshop on Applied Data Science for
  Healthcare</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colorectal cancer (CRC) is the third most common cancer and the second
leading cause of cancer-related deaths worldwide. Most CRC deaths are the
result of progression of metastases. The assessment of metastases is done using
the RECIST criterion, which is time consuming and subjective, as clinicians
need to manually measure anatomical tumor sizes. AI has many successes in image
object detection, but often suffers because the models used are not
interpretable, leading to issues in trust and implementation in the clinical
setting. We propose a framework for an AI-augmented system in which an
interactive AI system assists clinicians in the metastasis assessment. We
include model interpretability to give explanations of the reasoning of the
underlying models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07736</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07736</id><created>2019-07-17</created><authors><author><keyname>Ding</keyname><forenames>Yifu</forenames></author><author><keyname>Moreira</keyname><forenames>Roberto</forenames></author><author><keyname>Cedillos</keyname><forenames>Dagoberto</forenames></author></authors><title>Assessment of the Value of Frequency Response Times in Power Systems</title><categories>eess.SY cs.SY</categories><comments>Accepted by the 2019 IEEE PES Innovative Smart Grid Technologies
  Europe (ISGT-Europe) conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the increasing penetration in renewable generation, the UK power system
is experiencing a decline in system inertia and an increase in frequency
response (FR) requirements. Faster FR products are a mitigating solution that
can cost-effectively meet the system balancing requirements. Thus, this paper
proposes a mixed integer linear programming (MILP) unit commitment model which
can simultaneously schedule inertial response, mandatory FR, as well as a
sub-second FR product - enhanced frequency response (EFR). The model quantifies
the value of providing faster reacting FR products in comparison with other
response times from typical FR products. The performance and value of EFR are
determined in a series of future energy scenarios with respect to the UK market
and system conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07745</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07745</id><created>2019-07-17</created><authors><author><keyname>Rahnama</keyname><forenames>Oscar</forenames></author><author><keyname>Cavallari</keyname><forenames>Tommaso</forenames></author><author><keyname>Golodetz</keyname><forenames>Stuart</forenames></author><author><keyname>Tonioni</keyname><forenames>Alessio</forenames></author><author><keyname>Joy</keyname><forenames>Thomas</forenames></author><author><keyname>Di Stefano</keyname><forenames>Luigi</forenames></author><author><keyname>Walker</keyname><forenames>Simon</forenames></author><author><keyname>Torr</keyname><forenames>Philip H. S.</forenames></author></authors><title>Real-Time Highly Accurate Dense Depth on a Power Budget using an
  FPGA-CPU Hybrid SoC</title><categories>cs.CV eess.IV eess.SP</categories><comments>6 pages, 7 figures, 2 tables, journal</comments><journal-ref>IEEE Transactions on Circuits and Systems II: Express Briefs, vol.
  66, no. 5, pp. 773-777, May 2019</journal-ref><doi>10.1109/TCSII.2019.2909169</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obtaining highly accurate depth from stereo images in real time has many
applications across computer vision and robotics, but in some contexts, upper
bounds on power consumption constrain the feasible hardware to embedded
platforms such as FPGAs. Whilst various stereo algorithms have been deployed on
these platforms, usually cut down to better match the embedded architecture,
certain key parts of the more advanced algorithms, e.g. those that rely on
unpredictable access to memory or are highly iterative in nature, are difficult
to deploy efficiently on FPGAs, and thus the depth quality that can be achieved
is limited. In this paper, we leverage a FPGA-CPU chip to propose a novel,
sophisticated, stereo approach that combines the best features of SGM and
ELAS-based methods to compute highly accurate dense depth in real time. Our
approach achieves an 8.7% error rate on the challenging KITTI 2015 dataset at
over 50 FPS, with a power consumption of only 5W.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07746</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07746</id><created>2019-07-17</created><authors><author><keyname>Schirrmeister</keyname><forenames>Robin Tibor</forenames></author><author><keyname>Ball</keyname><forenames>Tonio</forenames></author></authors><title>Deep Invertible Networks for EEG-based brain-signal decoding</title><categories>cs.LG cs.NE eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript, we investigate deep invertible networks for EEG-based
brain signal decoding and find them to generate realistic EEG signals as well
as classify novel signals above chance. Further ideas for their regularization
towards better decoding accuracies are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07747</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07747</id><created>2019-07-17</created><authors><author><keyname>Sui</keyname><forenames>Wenbo</forenames></author><author><keyname>Hall</keyname><forenames>Carrie M.</forenames></author><author><keyname>Kapadia</keyname><forenames>Gina</forenames></author></authors><title>Cylinder-Specific Model-Based Control of Combustion Phasing for
  Multiple-Cylinder Diesel Engines Operating with High Dilution and Boost
  Levels</title><categories>eess.SY cs.SY</categories><comments>nternational Journal of Engine Research, 2018</comments><doi>10.1177/1468087418804087</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate control of combustion phasing is indispensable for diesel engines
due to the strong impact of combustion timing on efficiency. In this work, a
non-linear combustion phasing model is developed and integrated with a
cylinder-specific model of intake gas. The combustion phasing model uses a
knock integral model, a burn duration model and a Wiebe function to predict
CA50 (the crank angle at which 50% of the mass of fuel has burned). Meanwhile,
the intake gas property model predicts the EGR fraction and the in-cylinder
pressure and temperature at intake valve closing (IVC) for different cylinders.
As such, cylinder-to-cylinder variation of the pressure and temperature at
intake valves closing is also considered in this model. This combined model is
simplified for controller design and validated. Based on these models, two
combustion phasing control strategies are explored. The first is an adaptive
controller that is designed for closed-loop control and the second is a
feedforward model-based control strategy for open-loop control. These two
control approaches were tested in simulations for all six cylinders and the
results demonstrate that the CA50 can reach steady state conditions within 10
cycles. In addition, the steady state errors are less than +/-0.1 crank angle
degree (CAD) with the adaptive control approach, and less than +/-1.3 CAD with
feedforward model-based control. The impact of errors on the control algorithms
is also discussed in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07748</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07748</id><created>2019-07-17</created><authors><author><keyname>Elmadawi</keyname><forenames>Khaled</forenames></author><author><keyname>Abdelrazek</keyname><forenames>Moemen</forenames></author><author><keyname>Elsobky</keyname><forenames>Mohamed</forenames></author><author><keyname>Eraqi</keyname><forenames>Hesham M.</forenames></author><author><keyname>Zahran</keyname><forenames>Mohamed</forenames></author></authors><title>End-to-end sensor modeling for LiDAR Point Cloud</title><categories>eess.IV cs.CV</categories><comments>Accepted in IEEE Intelligent Transportation Systems Conference - ITSC
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advanced sensors are a key to enable self-driving cars technology. Laser
scanner sensors (LiDAR, Light Detection And Ranging) became a fundamental
choice due to its long-range and robustness to low light driving conditions.
The problem of designing a control software for self-driving cars is a complex
task to explicitly formulate in rule-based systems, thus recent approaches rely
on machine learning that can learn those rules from data. The major problem
with such approaches is that the amount of training data required for
generalizing a machine learning model is big, and on the other hand LiDAR data
annotation is very costly compared to other car sensors. An accurate LiDAR
sensor model can cope with such problem. Moreover, its value goes beyond this
because existing LiDAR development, validation, and evaluation platforms and
processes are very costly, and virtual testing and development environments are
still immature in terms of physical properties representation. In this work we
propose a novel Deep Learning-based LiDAR sensor model. This method models the
sensor echos, using a Deep Neural Network to model echo pulse widths learned
from real data using Polar Grid Maps (PGM). We benchmark our model performance
against comprehensive real sensor data and very promising results are achieved
that sets a baseline for future works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07755</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07755</id><created>2019-07-18</created><authors><author><keyname>Subramanian</keyname><forenames>Renganathan</forenames></author><author><keyname>Singh</keyname><forenames>Shweta</forenames></author></authors><title>Can Machine Learning Identify Governing Laws For Dynamics in Complex
  Engineered Systems ? : A Study in Chemical Engineering</title><categories>eess.SY cs.LG cs.SY stat.ML</categories><comments>8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning recently has been used to identify the governing equations
for dynamics in physical systems. The promising results from applications on
systems such as fluid dynamics and chemical kinetics inspire further
investigation of these methods on complex engineered systems. Dynamics of these
systems play a crucial role in design and operations. Hence, it would be
advantageous to learn about the mechanisms that may be driving the complex
dynamics of systems. In this work, our research question was aimed at
addressing this open question about applicability and usefulness of novel
machine learning approach in identifying the governing dynamical equations for
engineered systems. We focused on distillation column which is an ubiquitous
unit operation in chemical engineering and demonstrates complex dynamics i.e.
it's dynamics is a combination of heuristics and fundamental physical laws. We
tested the method of Sparse Identification of Non-Linear Dynamics (SINDy)
because of it's ability to produce white-box models with terms that can be used
for physical interpretation of dynamics. Time series data for dynamics was
generated from simulation of distillation column using ASPEN Dynamics. One
promising result was reduction of number of equations for dynamic simulation
from 1000s in ASPEN to only 13 - one for each state variable. Prediction
accuracy was high on the test data from system within the perturbation range,
however outside perturbation range equations did not perform well. In terms of
physical law extraction, some terms were interpretable as related to Fick's law
of diffusion (with concentration terms) and Henry's law (with ratio of
concentration and pressure terms). While some terms were interpretable, we
conclude that more research is needed on combining engineering systems with
machine learning approach to improve understanding of governing laws for
unknown dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07762</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07762</id><created>2019-07-11</created><authors><author><keyname>da Fonseca</keyname><forenames>Eug&#xea;nio Pacceli Reis</forenames></author><author><keyname>Caldeira</keyname><forenames>Evandro</forenames></author><author><keyname>Filho</keyname><forenames>Heitor Soares Ramos</forenames></author><author><keyname>Oliveira</keyname><forenames>Leonardo Barbosa e</forenames></author><author><keyname>Pereira</keyname><forenames>Adriano C&#xe9;sar Machado</forenames></author><author><keyname>Vilela</keyname><forenames>Pierre Santos</forenames></author></authors><title>Agro 4.0: A Green Information System for Sustainable Agroecosystem
  Management</title><categories>cs.CY cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agriculture is one of the most critical activities developed today by
humankind and is in constant technical evolution to supply food and other
essential products to everlasting and increasing demand. New machines, seeds,
and fertilizers were developed to increase the productivity of cultivated
areas. It is estimated that by 2050 we will have a population of 9 billion
people and the production of food to meet this demand must occur sustainably.
To achieve this goal, it is paramount the adoption of sustainable management
techniques for agroecosystems. However, this is a complex task due to a large
number of variables involved. One of the solutions for the handling and
treatment of such diverse data is the use of Green IS. In this work, we adopt a
methodology called Indicators of Sustainability in Agroecosystems (Indicadores
de Sustentabilidade em Agroecossistemas -- ISA), implement an information
system based on it and apply Data Science techniques over the gathered data -
from 100 real rural properties - to compute which are the most relevant ISA
Indicators for the final ISA Sustainability Index Score. As a result, we have
developed a set of tools for data collection, processing, visualization, and
analysis of the sustainability of a rural property or region, following the ISA
methodology. We also have that with only 7 of the 21 Indicators present in ISA
we can identify the level of sustainability in more than 90% of cases, allowing
for a new discussion about shrinking the amount of data needed for the
computation of ISA, or remodelling the final computation of the Sustainability
Index so other Indicators can be more expressive. Users of the solutions
developed in this work can identify best practices for sustainability in
participating agroecosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07769</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07769</id><created>2019-07-15</created><authors><author><keyname>Narayanan</keyname><forenames>Praveen</forenames></author><author><keyname>Chakravarty</keyname><forenames>Punarjay</forenames></author><author><keyname>Charette</keyname><forenames>Francois</forenames></author><author><keyname>Puskorius</keyname><forenames>Gint</forenames></author></authors><title>Hierarchical Sequence to Sequence Voice Conversion with Limited Data</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a voice conversion solution using recurrent sequence to sequence
modeling for DNNs. Our solution takes advantage of recent advances in attention
based modeling in the fields of Neural Machine Translation (NMT),
Text-to-Speech (TTS) and Automatic Speech Recognition (ASR). The problem
consists of converting between voices in a parallel setting when {\it
$&lt;$source,target$&gt;$} audio pairs are available. Our seq2seq architecture makes
use of a hierarchical encoder to summarize input audio frames. On the decoder
side, we use an attention based architecture used in recent TTS works. Since
there is a dearth of large multispeaker voice conversion databases needed for
training DNNs, we resort to training the network with a large single speaker
dataset as an autoencoder. This is then adapted for the smaller multispeaker
voice conversion datasets available for voice conversion. In contrast with
other voice conversion works that use $F_0$, duration and linguistic features,
our system uses mel spectrograms as the audio representation. Output mel frames
are converted back to audio using a wavenet vocoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07774</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07774</id><created>2019-07-16</created><authors><author><keyname>Scheufele</keyname><forenames>Klaudius</forenames></author><author><keyname>Subramanian</keyname><forenames>Shashank</forenames></author><author><keyname>Mang</keyname><forenames>Andreas</forenames></author><author><keyname>Biros</keyname><forenames>George</forenames></author><author><keyname>Mehl</keyname><forenames>Miriam</forenames></author></authors><title>Image-Driven Biophysical Tumor Growth Model Calibration</title><categories>q-bio.QM eess.IV</categories><comments>24 pages, 8 figures</comments><msc-class>35K40, 49M15, 49M20, 65K10, 65N35, 65Y05, 92C50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel formulation for the calibration of a biophysical tumor
growth model from a single-time snapshot, MRI scan of a glioblastoma patient.
Tumor growth models are typically nonlinear parabolic partial differential
equations (PDEs). Thus, we have to generate a second snapshot to be able to
extract significant information from a single patient snapshot. We create this
two-snapshot scenario as follows. We use an atlas (an average of several scans
of healthy individuals) as a substitute for an earlier, pretumor, MRI scan of
the patient. Then, using the patient scan and the atlas, we combine
image-registration algorithms and parameter estimation algorithms to achieve a
better estimate of the healthy patient scan and the tumor growth parameters
that are consistent with the data. Our scheme is based on our recent work
(Scheufele et al, &quot;Biophysically constrained diffeomorphic image registration,
Tumor growth, Atlas registration, Adjoint-based methods, Parallel algorithms&quot;,
CMAME, 2018), but apply a different and novel scheme where the tumor growth
simulation in contrast to the previous work is executed in the patient brain
domain and not in the atlas domain yielding more meaningful patient-specific
results. As a basis, we use a PDE-constrained optimization framework. We derive
a modified Picard-iteration-type solution strategy in which we alternate
between registration and tumor parameter estimation in a new way. In addition,
we consider an $\ell_1$ sparsity constraint on the initial condition for the
tumor and integrate it with the new joint inversion scheme. We solve the
subproblems with a reduced-space, inexact Gauss-Newton-Krylov/quasi-Newton
methods. We present results using real brain data with synthetic tumor data
that show that the new scheme reconstructs the tumor parameters in a more
accurate and reliable way compared to our earlier scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07775</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07775</id><created>2019-07-16</created><updated>2019-08-24</updated><authors><author><keyname>Ikemoto</keyname><forenames>Junya</forenames></author><author><keyname>Ushio</keyname><forenames>Toshimitsu</forenames></author></authors><title>Model-free Control of Chaos with Continuous Deep Q-learning</title><categories>eess.SY cs.SY stat.ML</categories><comments>7 pages, 8 figures, Submitted to Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The OGY method is one of control methods for a chaotic system. In the method,
we have to calculate a stabilizing periodic orbit embedded in its chaotic
attractor. Thus, we cannot use this method in the case where a precise
mathematical model of the chaotic system cannot be identified. In this case,
the delayed feedback control proposed by Pyragas is useful. However, even in
the delayed feedback control, we need the mathematical model to determine a
feedback gain that stabilizes the periodic orbit. To overcome this problem, we
propose a model-free reinforcement learning algorithm to the design of a
controller for the chaotic system. In recent years, model-free reinforcement
learning algorithms with deep neural networks have been paid much attention to.
Those algorithms make it possible to control complex systems. However, it is
known that model-free reinforcement learning algorithms are not efficient
because learners must explore their control policies over the entire state
space. Moreover, model-free reinforcement learning algorithms with deep neural
networks have the disadvantage in taking much time to learn their control
optimal policies. Thus, we propose a data-based control policy consisting of
two steps, where we determine a region including the stabilizing periodic orbit
first, and make the controller learn an optimal control policy for its
stabilization. In the proposed method, the controller efficiently explores its
control policy only in the region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07783</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07783</id><created>2019-07-17</created><authors><author><keyname>Egger</keyname><forenames>Bernhard</forenames></author><author><keyname>Schirmer</keyname><forenames>Markus D.</forenames></author><author><keyname>Dubost</keyname><forenames>Florian</forenames></author><author><keyname>Nardin</keyname><forenames>Marco J.</forenames></author><author><keyname>Rost</keyname><forenames>Natalia S.</forenames></author><author><keyname>Golland</keyname><forenames>Polina</forenames></author></authors><title>Patient-specific Conditional Joint Models of Shape, Image Features and
  Clinical Indicators</title><categories>eess.IV cs.CG cs.CV cs.LG</categories><comments>Supplementary material: https://www.youtube.com/watch?v=gPoHP_iFQIA</comments><journal-ref>MICCAI 2019, the 22nd International Conference on Medical Image
  Computing and Computer Assisted Intervention, in Shenzhen, China</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose and demonstrate a joint model of anatomical shapes, image features
and clinical indicators for statistical shape modeling and medical image
analysis. The key idea is to employ a copula model to separate the joint
dependency structure from the marginal distributions of variables of interest.
This separation provides flexibility on the assumptions made during the
modeling process. The proposed method can handle binary, discrete, ordinal and
continuous variables. We demonstrate a simple and efficient way to include
binary, discrete and ordinal variables into the modeling. We build Bayesian
conditional models based on observed partial clinical indicators, features or
shape based on Gaussian processes capturing the dependency structure. We apply
the proposed method on a stroke dataset to jointly model the shape of the
lateral ventricles, the spatial distribution of the white matter hyperintensity
associated with periventricular white matter disease, and clinical indicators.
The proposed method yields interpretable joint models for data exploration and
patient-specific statistical shape models for medical image analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07805</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07805</id><created>2019-07-17</created><authors><author><keyname>Bartunik</keyname><forenames>Max</forenames></author><author><keyname>L&#xfc;bke</keyname><forenames>Maximilian</forenames></author><author><keyname>Unterweger</keyname><forenames>Harald</forenames></author><author><keyname>Alexiou</keyname><forenames>Christoph</forenames></author><author><keyname>Meyer</keyname><forenames>Sebastian</forenames></author><author><keyname>Ahmed</keyname><forenames>Doaa</forenames></author><author><keyname>Fischer</keyname><forenames>Georg</forenames></author><author><keyname>Wicke</keyname><forenames>Wayan</forenames></author><author><keyname>Kooshkghazi</keyname><forenames>Vahid Jamali</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Kirchner</keyname><forenames>Jens</forenames></author></authors><title>Novel Receiver for Superparamagnetic Iron Oxide Nanoparticles in a
  Molecular Communication Setting</title><categories>eess.SP</categories><comments>ACM NanoCom 2019</comments><doi>10.1145/1122445.1122456</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superparamagnetic iron oxide nanoparticles (SPIONs) have recently been
introduced as information carriers in a testbed for molecular communication
(MC) in duct flow. Here, a new receiver for this testbed is presented, based on
the concept of a bridge circuit. The capability for a reliable transmission
using the testbed and detection of the proposed receiver was evaluated by
sending a text message and a 80 bit random sequence at a bit rate of 1/s, which
resulted in a bit error rate of 0 %. Furthermore, the sensitivity of the device
was assessed by a dilution series, which gave a limit for the detectability of
peaks between 0.1 to 0.5 mg/mL. Compared to the commercial susceptometer that
was previously used as receiver, the new detector provides an increased
sampling rate of 100 samples/s and flexibility in the dimensions of the
propagation channel. Furthermore, it allows to implement both single-ended and
differential signaling in SPION-bases MC testbeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07807</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07807</id><created>2019-07-17</created><updated>2019-11-16</updated><authors><author><keyname>Xue</keyname><forenames>Yunzhe</forenames></author><author><keyname>Xie</keyname><forenames>Meiyan</forenames></author><author><keyname>Farhat</keyname><forenames>Fadi G.</forenames></author><author><keyname>Boukrina</keyname><forenames>Olga</forenames></author><author><keyname>Barrett</keyname><forenames>A. M.</forenames></author><author><keyname>Binder</keyname><forenames>Jeffrey R.</forenames></author><author><keyname>Roshan</keyname><forenames>Usman W.</forenames></author><author><keyname>Graves</keyname><forenames>William W.</forenames></author></authors><title>A fully 3D multi-path convolutional neural network with feature fusion
  and feature weighting for automatic lesion identification in brain MRI images</title><categories>eess.IV cs.CV cs.LG</categories><comments>Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended
  Abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a fully 3D multi-path convolutional network to predict stroke
lesions from 3D brain MRI images. Our multi-path model has independent encoders
for different modalities containing residual convolutional blocks, weighted
multi-path feature fusion from different modalities, and weighted fusion
modules to combine encoder and decoder features. Compared to existing 3D CNNs
like DeepMedic, 3D U-Net, and AnatomyNet, our networks achieves the highest
statistically significant cross-validation accuracy of 60.5% on the large ATLAS
benchmark of 220 patients. We also test our model on multi-modal images from
the Kessler Foundation and Medical College Wisconsin and achieve a
statistically significant cross-validation accuracy of 65%, significantly
outperforming the multi-modal 3D U-Net and DeepMedic. Overall our model offers
a principled, extensible multi-path approach that outperforms multi-channel
alternatives and achieves high Dice accuracies on existing benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07825</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07825</id><created>2019-07-17</created><authors><author><keyname>Ajanovic</keyname><forenames>Zlatan</forenames></author><author><keyname>Regolin</keyname><forenames>Enrico</forenames></author><author><keyname>Stettinger</keyname><forenames>Georg</forenames></author><author><keyname>Horn</keyname><forenames>Martin</forenames></author><author><keyname>Ferrara</keyname><forenames>Antonella</forenames></author></authors><title>Search-Based Motion Planning for Performance Autonomous Driving</title><categories>cs.RO cs.SY eess.SY math.OC</categories><comments>Accepted to IAVSD 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driving on the limits of vehicle dynamics requires predictive planning of
future vehicle states. In this work, a search-based motion planning is used to
generate suitable reference trajectories of dynamic vehicle states with the
goal to achieve the minimum lap time on slippery roads. The search-based
approach enables to explicitly consider a nonlinear vehicle dynamics model as
well as constraints on states and inputs so that even challenging scenarios can
be achieved in a safe and optimal way. The algorithm performance is evaluated
in simulated driving on a track with segments of different curvatures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07836</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07836</id><created>2019-07-17</created><updated>2019-07-18</updated><authors><author><keyname>Dong</keyname><forenames>Ming</forenames></author><author><keyname>Xie</keyname><forenames>Kaigui</forenames></author><author><keyname>Shi</keyname><forenames>QingXin</forenames></author></authors><title>Multi-year Long-term Load Forecast for Area Distribution Feeders based
  on Selective Sequence Learning</title><categories>eess.SY cs.LG cs.SY</categories><comments>22 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long-term load forecast (LTLF) for area distribution feeders is one of the
most critical tasks frequently performed in electric distribution utility
companies. For a specific planning area, cost-effective system upgrades can
only be planned out based on accurate feeder LTLF results. In our previous
research, we established a unique sequence prediction method which has the
tremendous advantage of combining area top-down, feeder bottom-up and
multi-year historical data all together for forecast and achieved a superior
performance over various traditional methods by real-world tests. However, the
previous method only focused on the forecast of the next one-year. In our
current work, we significantly improved this method: the forecast can now be
extended to a multi-year forecast window in the future; unsupervised learning
techniques are used to group feeders by their load composition features to
improve accuracy; we also propose a novel selective sequence learning mechanism
which uses Gated Recurrent Unit network to not only learn how to predict
sequence values but also learn to select the best-performing sequential
configuration for each individual feeder. The proposed method was tested on an
actual urban distribution system in West Canada. It was compared with
traditional methods and our previous sequence prediction method. It
demonstrates the best forecasting performance as well as the possibility of
using sequence prediction models for multi-year component-level load forecast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07841</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07841</id><created>2019-07-17</created><updated>2019-10-06</updated><authors><author><keyname>Huang</keyname><forenames>Kang</forenames></author><author><keyname>Liu</keyname><forenames>Wanchun</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author><author><keyname>Savkin</keyname><forenames>Andrey</forenames></author></authors><title>Optimal Downlink-Uplink Scheduling of Wireless Networked Control for
  Industrial IoT</title><categories>cs.IT cs.SY eess.SY math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a wireless networked control system (WNCS) consisting of
a dynamic system to be controlled (i.e., a plant), a sensor, an actuator and a
remote controller for mission-critical Industrial Internet of Things (IIoT)
applications. A WNCS has two types of wireless transmissions, i.e., the
sensor's measurement transmission to the controller and the controller's
command transmission to the actuator. In this work, we consider a practical
half-duplex controller, which introduces a novel transmission-scheduling
problem for WNCSs. A frequent scheduling of sensor's transmission results in a
better estimation of plant states at the controller and thus a higher quality
of control command, but it leads to a less frequent/timely control of the
plant. Therefore, considering the overall control performance of the plant in
terms of its average cost function, there exists a fundamental tradeoff between
the sensor's and the controller's transmissions. We formulate a new problem to
optimize the transmission-scheduling policy for minimizing the long-term
average cost function. We derive the necessary and sufficient condition of the
existence of a stationary and deterministic optimal policy that results in a
bounded average cost in terms of the transmission reliabilities of the
sensor-to-controller and controller-to-actuator channels. Also, we derive an
easy-to-compute suboptimal policy, which notably reduces the average cost of
the plant compared to a naive alternative-scheduling policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07862</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07862</id><created>2019-07-17</created><authors><author><keyname>Shafin</keyname><forenames>Rubayet</forenames><affiliation>Charlie</affiliation></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames><affiliation>Charlie</affiliation></author><author><keyname>Chandrasekhar</keyname><forenames>Vikram</forenames><affiliation>Charlie</affiliation></author><author><keyname>Chen</keyname><forenames>Hao</forenames><affiliation>Charlie</affiliation></author><author><keyname>Reed</keyname><forenames>Jeffrey</forenames><affiliation>Charlie</affiliation></author><author><keyname>Jianzhong</keyname><affiliation>Charlie</affiliation></author><author><keyname>Zhang</keyname></author></authors><title>Artificial Intelligence-Enabled Cellular Networks: A Critical Path to
  Beyond-5G and 6G</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Network Operators (MNOs) are in process of overlaying their
conventional macro cellular networks with shorter range cells such as outdoor
pico cells. The resultant increase in network complexity creates substantial
overhead in terms of operating expenses, time, and labor for their planning and
management. Artificial intelligence (AI) offers the potential for MNOs to
operate their networks in a more organic and cost-efficient manner. We argue
that deploying AI in 5G and Beyond will require surmounting significant
technical barriers in terms of robustness, performance, and complexity. We
outline future research directions, identify top 5 challenges, and present a
possible roadmap to realize the vision of AI-enabled cellular networks for
Beyond-5G and 6G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07863</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07863</id><created>2019-07-17</created><authors><author><keyname>Anwar</keyname><forenames>Saeed</forenames></author><author><keyname>Li</keyname><forenames>Chongyi</forenames></author></authors><title>Diving Deeper into Underwater Image Enhancement: A Survey</title><categories>cs.CV cs.LG eess.IV</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The powerful representation capacity of deep learning has made it inevitable
for the underwater image enhancement community to employ its potential. The
exploration of deep underwater image enhancement networks is increasing over
time, and hence; a comprehensive survey is the need of the hour. In this paper,
our main aim is two-fold, 1): to provide a comprehensive and in-depth survey of
the deep learning-based underwater image enhancement, which covers various
perspectives ranging from algorithms to open issues, and 2): to conduct a
qualitative and quantitative comparison of the deep algorithms on diverse
datasets to serve as a benchmark, which has been barely explored before. To be
specific, we first introduce the underwater image formation models, which are
the base of training data synthesis and design of deep networks, and also
helpful for understanding the process of underwater image degradation. Then, we
review deep underwater image enhancement algorithms, and a glimpse of some of
the aspects of the current networks is presented including network
architecture, network parameters, training data, loss function, and training
configurations. We also summarize the evaluation metrics and underwater image
datasets. Following that, a systematically experimental comparison is carried
out to analyze the robustness and effectiveness of deep algorithms. Meanwhile,
we point out the shortcomings of current benchmark datasets and evaluation
metrics. Finally, we discuss several unsolved open issues and suggest possible
research directions. We hope that all efforts done in this paper might serve as
a comprehensive reference for future research and call for the development of
deep learning-based underwater image enhancement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07875</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07875</id><created>2019-07-18</created><authors><author><keyname>Lu</keyname><forenames>Keng-Shih</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Fast Graph Fourier Transforms Based on Graph Symmetry and Bipartition</title><categories>eess.SP</categories><comments>14 pages, 15 figures</comments><doi>10.1109/TSP.2019.2932882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The graph Fourier transform (GFT) is an important tool for graph signal
processing, with applications ranging from graph-based image processing to
spectral clustering. However, unlike the discrete Fourier transform, the GFT
typically does not have a fast algorithm. In this work, we develop new
approaches to accelerate the GFT computation. In particular, we show that Haar
units (Givens rotations with angle $\pi/4$) can be used to reduce GFT
computation cost when the graph is bipartite or satisfies certain symmetry
properties based on node pairing. We also propose a graph decomposition method
based on graph topological symmetry, which allows us to identify and exploit
butterfly structures in stages. This method is particularly useful for graphs
that are nearly regular or have some specific structures, e.g., line graphs,
cycle graphs, grid graphs, and human skeletal graphs. Though butterfly stages
based on graph topological symmetry cannot be used for general graphs, they are
useful in applications, including video compression and human action analysis,
where symmetric graphs, such as symmetric line graphs and human skeletal
graphs, are used. Our proposed fast GFT implementations are shown to reduce
computation costs significantly, in terms of both number of operations and
empirical runtimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07888</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07888</id><created>2019-07-18</created><authors><author><keyname>Emara</keyname><forenames>Mustafa</forenames></author><author><keyname>ElSawy</keyname><forenames>Hesham</forenames></author><author><keyname>Bauch</keyname><forenames>Gerhard</forenames></author></authors><title>Prioritized Multi-stream Traffic in Uplink IoT Networks: Spatially
  Interacting Vacation Queues</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive Internet of Things (IoT) is foreseen to introduce plethora of
applications for a fully connected world. Heterogeneous traffic is envisaged,
where packets generated at each IoT device should be differentiated and served
according to their priority. This paper develops a novel priority-aware
spatiotemporal mathematical model to characterize massive IoT networks with
uplink prioritized multistream traffic (PMT). Particularly, stochastic geometry
is utilized to account for the macroscopic network wide mutual interference
between the coexisting IoT devices. Discrete time Markov chains (DTMCs) are
employed to track the microscopic evolution of packets within each priority
stream at each device. To alleviate the curse of dimensionality, we decompose
the prioritized queueing model at each device to a single-queue system with
server vacation. To this end, the IoT network with PMT is modeled as spatially
interacting vacation queues. Interactions between queues, in terms of the
packet departure probabilities, occur due to mutual interference. Service
vacations occur to lower priority packets to address higher priority packets.
Based on the proposed model, dedicated and shared channel access strategies for
different priority classes are presented and compared. The results show that
shared access provides better performance when considering the transmission
success probability, queues overflow probability and latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07890</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07890</id><created>2019-07-18</created><updated>2019-10-07</updated><authors><author><keyname>Schulte</keyname><forenames>Julia</forenames></author><author><keyname>Staps</keyname><forenames>Daniel</forenames></author><author><keyname>Lampe</keyname><forenames>Alexander</forenames></author></authors><title>A feasibility study of deep neural networks for the recognition of
  banknotes regarding central bank requirements</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>6 pages, 4 figures</comments><acm-class>I.7.5; I.5.1; I.2.6; G.1.6; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contains a feasibility study of deep neural networks for the
classification of Euro banknotes with respect to requirements of central banks
on the ATM and high speed sorting industry. Instead of concentrating on the
accuracy for a large number of classes as in the famous ImageNet Challenge we
focus thus on conditions with few classes and the requirement of rejection of
images belonging clearly to neither of the trained classes (i.e. classification
in a so-called 0-class). These special requirements are part of frameworks
defined by central banks as the European Central Bank and are met by current
ATMs and high speed sorting machines. We also consider training and
classification time on state of the art GPU hardware. The study concentrates on
the banknote recognition whereas banknote class dependent authenticity and
fitness checks are a topic of its own which is not considered in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07943</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07943</id><created>2019-07-18</created><authors><author><keyname>Grossi</keyname><forenames>Emanuele</forenames></author><author><keyname>Lops</keyname><forenames>Marco</forenames></author><author><keyname>Venturino</keyname><forenames>Luca</forenames></author></authors><title>Joint Design of surveillance radar and MIMO communication in cluttered
  environments</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Transaction on Signal Processing on June 24, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we consider a spectrum sharing architecture, wherein a
multiple-input multiple-output communication system cooperatively coexists with
a surveillance radar. The degrees of freedom for system design are the transmit
powers of both systems, the receive linear filters used for pulse compression
and interference mitigation at the radar receiver, and the space-time
communication codebook. The design criterion is the maximization of the mutual
information between the input and output symbols of the communication system,
subject to constraints aimed at safeguarding the radar performance. Unlike
previous studies, we do not require any time-synchronization between the two
systems, and we guarantee the radar performance on all of the range-azimuth
cells of the patrolled region under signal-dependent (endogenous) and
signal-independent (exogenous) interference. This leads to a non-convex
problem, and an approximate solution is thus introduced using a block
coordinate ascent method. A thorough analysis is provided to show the merits of
the proposed approach and emphasize the inherent tradeoff among the achievable
mutual information, the density of scatterers in the environment, and the
number of protected radar cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07951</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07951</id><created>2019-07-18</created><updated>2020-01-09</updated><authors><author><keyname>Eslami</keyname><forenames>Mohammad</forenames></author><author><keyname>Neuschaefer-Rube</keyname><forenames>Christiane</forenames></author><author><keyname>Serrurier</keyname><forenames>Antoine</forenames></author></authors><title>Automatic vocal tract landmark localization from midsagittal MRI data</title><categories>eess.IV cs.CV cs.LG cs.SD eess.AS</categories><doi>10.1038/s41598-020-58103-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The various speech sounds of a language are obtained by varying the shape and
position of the articulators surrounding the vocal tract. Analyzing their
variations is crucial for understanding speech production, diagnosing speech
disorders and planning therapy. Identifying key anatomical landmarks of these
structures on medical images is a pre-requisite for any quantitative analysis
and the rising amount of data generated in the field calls for an automatic
solution. The challenge lies in the high inter- and intra-speaker variability,
the mutual interaction between the articulators and the moderate quality of the
images. This study addresses this issue for the first time and tackles it by
means by means of Deep Learning. It proposes a dedicated network architecture
named Flat-net and its performance are evaluated and compared with eleven
state-of-the-art methods from the literature. The dataset contains midsagittal
anatomical Magnetic Resonance Images for 9 speakers sustaining 62 articulations
with 21 annotated anatomical landmarks per image. Results show that the
Flat-net approach outperforms the former methods, leading to an overall Root
Mean Square Error of 3.6 pixels/0.36 cm obtained in a leave-one-out procedure
over the speakers. The implementation codes are also shared publicly on GitHub.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07959</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07959</id><created>2019-07-18</created><authors><author><keyname>Brihuega</keyname><forenames>Alberto</forenames></author><author><keyname>Abdelaziz</keyname><forenames>Mahmoud</forenames></author><author><keyname>Turunen</keyname><forenames>Matias</forenames></author><author><keyname>Eriksson</keyname><forenames>Thomas</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Linearizing Active Antenna Arrays: Method and Measurements</title><categories>eess.SP</categories><comments>Accepted for presentation in IEEE MTT-S International Microwave
  Conference on Hardware and Systems for 5G and Beyond, August 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a novel framework for efficient digital
predistortion (DPD) based linearization of active antenna arrays with multiple
and mutually different nonlinear power amplifiers. The proposed method builds
on the use of a combined feedback signal essentially characterizing the
observable nonlinear distortion at the receiving end. The proposed method is
validated with extensive over-the-air RF measurements on a 64-element active
antenna array transmitter operating at 28 GHz carrier frequency and
transmitting a 200 MHz wide 5G New Radio (NR) waveform. The obtained results
demonstrate the excellent linearization capabilities of the proposed solution,
which allows for a very efficient implementation in practical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07980</identifier>
 <datestamp>2020-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07980</id><created>2019-07-18</created><authors><author><keyname>Bulten</keyname><forenames>Wouter</forenames></author><author><keyname>Pinckaers</keyname><forenames>Hans</forenames></author><author><keyname>van Boven</keyname><forenames>Hester</forenames></author><author><keyname>Vink</keyname><forenames>Robert</forenames></author><author><keyname>de Bel</keyname><forenames>Thomas</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author><author><keyname>van der Laak</keyname><forenames>Jeroen</forenames></author><author><keyname>de Kaa</keyname><forenames>Christina Hulsbergen-van</forenames></author><author><keyname>Litjens</keyname><forenames>Geert</forenames></author></authors><title>Automated Gleason Grading of Prostate Biopsies using Deep Learning</title><categories>eess.IV cs.CV</categories><comments>13 pages, 6 figures</comments><journal-ref>The Lancet Oncology, Available online 8 January 2020</journal-ref><doi>10.1016/S1470-2045(19)30739-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gleason score is the most important prognostic marker for prostate cancer
patients but suffers from significant inter-observer variability. We developed
a fully automated deep learning system to grade prostate biopsies. The system
was developed using 5834 biopsies from 1243 patients. A semi-automatic labeling
technique was used to circumvent the need for full manual annotation by
pathologists. The developed system achieved a high agreement with the reference
standard. In a separate observer experiment, the deep learning system
outperformed 10 out of 15 pathologists. The system has the potential to improve
prostate cancer prognostics by acting as a first or second reader.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08009</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08009</id><created>2019-07-18</created><authors><author><keyname>Kose</keyname><forenames>Neslihan</forenames></author><author><keyname>Kopuklu</keyname><forenames>Okan</forenames></author><author><keyname>Unnervik</keyname><forenames>Alexander</forenames></author><author><keyname>Rigoll</keyname><forenames>Gerhard</forenames></author></authors><title>Real-Time Driver State Monitoring Using a CNN Based Spatio-Temporal
  Approach</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted for publication by the IEEE Intelligent Transportation
  Systems Conference (ITSC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many road accidents occur due to distracted drivers. Today, driver monitoring
is essential even for the latest autonomous vehicles to alert distracted
drivers in order to take over control of the vehicle in case of emergency. In
this paper, a spatio-temporal approach is applied to classify drivers'
distraction level and movement decisions using convolutional neural networks
(CNNs). We approach this problem as action recognition to benefit from temporal
information in addition to spatial information. Our approach relies on features
extracted from sparsely selected frames of an action using a pre-trained
BN-Inception network. Experiments show that our approach outperforms the
state-of-the art results on the Distracted Driver Dataset (96.31%), with an
accuracy of 99.10% for 10-class classification while providing real-time
performance. We also analyzed the impact of fusion using RGB and optical flow
modalities with a very recent data level fusion strategy. The results on the
Distracted Driver and Brain4Cars datasets show that fusion of these modalities
further increases the accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08020</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08020</id><created>2019-07-18</created><authors><author><keyname>Tiulpin</keyname><forenames>Aleksei</forenames></author><author><keyname>Saarakkala</keyname><forenames>Simo</forenames></author></authors><title>Automatic Grading of Individual Knee Osteoarthritis Features in Plain
  Radiographs using Deep Convolutional Neural Networks</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knee osteoarthritis (OA) is the most common musculoskeletal disease in the
world. In primary healthcare, knee OA is diagnosed using clinical examination
and radiographic assessment. Osteoarthritis Research Society International
(OARSI) atlas of OA radiographic features allows to perform independent
assessment of knee osteophytes, joint space narrowing and other knee features.
This provides a fine-grained OA severity assessment of the knee, compared to
the gold standard and most commonly used Kellgren-Lawrence (KL) composite
score. However, both OARSI and KL grading systems suffer from moderate
inter-rater agreement, and therefore, the use of computer-aided methods could
help to improve the reliability of the process. In this study, we developed a
robust, automatic method to simultaneously predict KL and OARSI grades in knee
radiographs. Our method is based on Deep Learning and leverages an ensemble of
deep residual networks with 50 layers, squeeze-excitation and ResNeXt blocks.
Here, we used transfer learning from ImageNet with a fine-tuning on the whole
Osteoarthritis Initiative (OAI) dataset. An independent testing of our model
was performed on the whole Multicenter Osteoarthritis Study (MOST) dataset. Our
multi-task method yielded Cohen's kappa coefficients of 0.82 for KL-grade and
0.79, 0.84, 0.94, 0.83, 0.84, 0.90 for femoral osteophytes, tibial osteophytes
and joint space narrowing for lateral and medial compartments respectively.
Furthermore, our method yielded area under the ROC curve of 0.98 and average
precision of 0.98 for detecting the presence of radiographic OA (KL $\geq 2$),
which is better than the current state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08125</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08125</id><created>2019-07-18</created><authors><author><keyname>Olivella-Rosell</keyname><forenames>P.</forenames></author><author><keyname>Rullan</keyname><forenames>F.</forenames></author><author><keyname>Lloret-Gallego</keyname><forenames>P.</forenames></author><author><keyname>Prieto-Araujo</keyname><forenames>E.</forenames></author><author><keyname>Ferrer-San-Jos&#xe9;</keyname><forenames>R.</forenames></author><author><keyname>Barja-Martinez</keyname><forenames>S.</forenames></author><author><keyname>Bjarghov</keyname><forenames>S.</forenames></author><author><keyname>Lakshmanan</keyname><forenames>V.</forenames></author><author><keyname>Hentunen</keyname><forenames>A.</forenames></author><author><keyname>Forsstr&#xf6;m</keyname><forenames>J.</forenames></author><author><keyname>Ottesen</keyname><forenames>S.</forenames></author><author><keyname>Villafafila-Robles</keyname><forenames>R.</forenames></author><author><keyname>Sumper</keyname><forenames>A.</forenames></author></authors><title>Centralised and Distributed Optimization for Aggregated Flexibility
  Services Provision</title><categories>eess.SY cs.SY math.OC</categories><comments>10 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent deployment of distributed battery units in prosumer premises offer
new opportunities for providing aggregated flexibility services to both
distribution system operators and balance responsible parties. The optimization
problem presented in this paper is formulated with an objective of cost
minimization which includes energy and battery degradation cost to provide
flexibility services. A decomposed solution approach with the alternating
direction method of multipliers (ADMM) is used instead of commonly adopted
centralised optimization to reduce the computational burden and time, and then
reduce scalability limitations. In this work we apply a modified version of
ADMM that includes two new features with respect to the original algorithm:
first, the primal variables are updated concurrently, which reduces
significantly the computational cost when we have a large number of involved
prosumers; second, it includes a regularization term named Proximal Jacobian
(PJ) that ensures the stability of the solution. A case study is presented for
optimal battery operation of 100 prosumer sites with real-life data. The
proposed method finds a solution which is equivalent to the centralised
optimization problem and is computed between 5 and 12 times faster. Thus,
aggregators or large-scale energy communities can use this scalable algorithm
to provide flexibility services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08135</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08135</id><created>2019-07-17</created><updated>2019-10-20</updated><authors><author><keyname>Amin</keyname><forenames>Ahmed Al</forenames></author><author><keyname>Shin</keyname><forenames>Soo Young</forenames></author><author><keyname>Narottama</keyname><forenames>Bhaskara</forenames></author></authors><title>Channel Capacity Enhancement of SWIPT based CNOMA Downlink Transmission
  with Orbital Angular Momentum over Rician Fading Channel</title><categories>cs.NI eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, the integration of cooperative non-orthogonal multiple access
(CNOMA) and power splitting based simultaneous wireless information and power
transfer (SWIPT) is proposed to improve the spectral and energy efficiency.
Moreover, different orbital angular momentum (OAM) based signals are also
considered in this paper to transmit additional symbols to cell center user
(CCU) and cell edge user (CEU). In the proposed technique, CCU is used as
energy-constrained relay to forward signal to CEU. CCU harvests energy from the
transmitted signal by the BS using the power splitting technique. The
additional symbols are transmitted from the BS to CCU and CEU by utilizing
different modes of OAM. This paper investigates the ergodic sum capacity (ESC)
of the proposed technique along with analytical derivations over Rician fading
channels. Finally, the performance in terms of ESC and energy efficiency over
conventional technique compared to conventional multiple access is demonstrated
by analysis and simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08137</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08137</id><created>2019-07-18</created><authors><author><keyname>Hosseini</keyname><forenames>Seyed Amir Hossein</forenames><affiliation>Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN</affiliation><affiliation>Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN</affiliation></author><author><keyname>Zhang</keyname><forenames>Chi</forenames><affiliation>Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN</affiliation><affiliation>Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN</affiliation></author><author><keyname>Weing&#xe4;rtner</keyname><forenames>Sebastian</forenames><affiliation>Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN</affiliation><affiliation>Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN</affiliation><affiliation>Department of Imaging Physics, Delft University of Technology, Delft, Netherlands</affiliation></author><author><keyname>Moeller</keyname><forenames>Steen</forenames><affiliation>Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN</affiliation></author><author><keyname>Stuber</keyname><forenames>Matthias</forenames><affiliation>Department of Radiology, University Hospital</affiliation><affiliation>Center for Biomedical Imaging</affiliation></author><author><keyname>U&#x1e7;urbil</keyname><forenames>K&#xe2;mil</forenames><affiliation>Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN</affiliation></author><author><keyname>Ak&#xe7;akaya</keyname><forenames>Mehmet</forenames><affiliation>Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN</affiliation><affiliation>Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN</affiliation></author></authors><title>Accelerated Coronary MRI with sRAKI: A Database-Free Self-Consistent
  Neural Network k-space Reconstruction for Arbitrary Undersampling</title><categories>eess.IV</categories><comments>This work has been partially presented at ISMRM Workshop on Machine
  Learning Part 2 (October 2018), SCMR/ISMRM Co-Provided Workshop (February
  2019), IEEE International Symposium on Biomedical Imaging (April 2019) and
  ISMRM 27$^{th}$ Annual Meeting and Exhibition (May 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study aims to accelerate coronary MRI using a novel reconstruction
algorithm, called self-consistent robust artificial-neural-networks for k-space
interpolation (sRAKI). sRAKI performs iterative parallel imaging reconstruction
by enforcing coil self-consistency using subject-specific neural networks. This
approach extends the linear convolutions in SPIRiT to nonlinear interpolation
using convolutional neural networks (CNNs). These CNNs are trained individually
for each scan using the scan-specific autocalibrating signal (ACS) data.
Reconstruction is performed by imposing the learned self-consistency and
data-consistency enabling sRAKI to support random undersampling patterns.
Fully-sampled targeted right coronary artery MRI was acquired in six healthy
subjects for evaluation. The data were retrospectively undersampled, and
reconstructed using SPIRiT, $\ell_1$-SPIRiT and sRAKI for acceleration rates of
2 to 5. Additionally, prospectively undersampled whole-heart coronary MRI was
acquired to further evaluate performance. The results indicate that sRAKI
reduces noise amplification and blurring artifacts compared with SPIRiT and
$\ell_1$-SPIRiT, especially at high acceleration rates in targeted data.
Quantitative analysis shows that sRAKI improves normalized mean-squared-error
(~44% and ~21% over SPIRiT and $\ell_1$-SPIRiT at rate 5) and vessel sharpness
(~10% and ~20% over SPIRiT and $\ell_1$-SPIRiT at rate 5). In addition,
whole-heart data shows the sharpest coronary arteries when resolved using
sRAKI, with 11% and 15% improvement in vessel sharpness over SPIRiT and
$\ell_1$-SPIRiT, respectively. Thus, sRAKI is a database-free neural
network-based reconstruction technique that may further accelerate coronary MRI
with arbitrary undersampling patterns, while improving noise resilience over
linear parallel imaging and image sharpness over $\ell_1$ regularization
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08145</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08145</id><created>2019-07-18</created><authors><author><keyname>Chand</keyname><forenames>Ganesh B</forenames></author><author><keyname>Habes</keyname><forenames>Mohamad</forenames></author><author><keyname>Dolui</keyname><forenames>Sudipto</forenames></author><author><keyname>Detre</keyname><forenames>John A</forenames></author><author><keyname>Wolk</keyname><forenames>David A</forenames></author><author><keyname>Davatzikos</keyname><forenames>Christos</forenames></author></authors><title>Estimating regional cerebral blood flow using resting-state functional
  MRI via machine learning</title><categories>eess.IV eess.SP q-bio.NC</categories><comments>20 pages, 6 main figures or tables, 4 supplementary figures or tables</comments><doi>10.1016/j.jneumeth.2019.108528</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfusion MRI is an important modality in many brain imaging protocols, since
it probes cerebrovascular changes in aging and many diseases; however, it may
not be always available. Here we introduce a method that seeks to estimate
regional perfusion properties using spectral information of resting-state
functional MRI (rsfMRI) via machine learning. We used pairs of rsfMRI and
arterial spin labeling (ASL) images from the same elderly individuals with
normal cognition (NC; n = 45) and mild cognitive impairment (MCI; n = 26), and
built support vector machine models aiming to estimate regional cerebral blood
flow (CBF) from the rsfMRI signal alone. This method demonstrated higher
associations between the estimated CBF and actual CBF (ASL-CBF) at the total
lobar gray matter (r = 0.40; FDR-p = 1.9e-03), parietal lobe (r = 0.46, FDR-p =
8e-04), and occipital lobe (r = 0.35; FDR-p = 0.01) using rsfMRI signals of
frequencies [0.01-0.15] Hertz compared to frequencies [0.01-0.10] Hertz and
[0.01-0.20] Hertz, respectively. We further observed significant associations
between the estimated CBF and actual CBF in 24 regions of interest (p &lt; 0.05),
with the highest association observed in the superior parietal lobule (r =
0.50, FDR-p = 0.002). Moreover, the estimated CBF at superior parietal lobule
showed significant correlation with the mini-mental state exam (MMSE) score (r
= 0.27; FDR-p = 0.04) and decreased in MCI with lower MMSE score compared to NC
group (FDR-p = 0.04). Overall, these results suggest that the proposed
framework can obtain estimates of regional perfusion from rsfMRI, which can
serve as surrogate perfusion measures in the absence of ASL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08175</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08175</id><created>2019-07-11</created><updated>2019-12-23</updated><authors><author><keyname>DeVries</keyname><forenames>Terrance</forenames></author><author><keyname>Romero</keyname><forenames>Adriana</forenames></author><author><keyname>Pineda</keyname><forenames>Luis</forenames></author><author><keyname>Taylor</keyname><forenames>Graham W.</forenames></author><author><keyname>Drozdzal</keyname><forenames>Michal</forenames></author></authors><title>On the Evaluation of Conditional GANs</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional Generative Adversarial Networks (cGANs) are finding increasingly
widespread use in many application domains. Despite outstanding progress,
quantitative evaluation of such models often involves multiple distinct metrics
to assess different desirable properties, such as image quality, conditional
consistency, and intra-conditioning diversity. In this setting, model
benchmarking becomes a challenge, as each metric may indicate a different
&quot;best&quot; model. In this paper, we propose the Frechet Joint Distance (FJD), which
is defined as the Frechet distance between joint distributions of images and
conditioning, allowing it to implicitly capture the aforementioned properties
in a single metric. We conduct proof-of-concept experiments on a controllable
synthetic dataset, which consistently highlight the benefits of FJD when
compared to currently established metrics. Moreover, we use the newly
introduced metric to compare existing cGAN-based models for a variety of
conditioning modalities (e.g. class labels, object masks, bounding boxes,
images, and text captions). We show that FJD can be used as a promising single
metric for cGAN benchmarking and model selection. Code can be found at
https://github.com/facebookresearch/fjd.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08196</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08196</id><created>2019-07-18</created><authors><author><keyname>Raina</keyname><forenames>Kevin</forenames></author><author><keyname>Yahorau</keyname><forenames>Uladzimir</forenames></author><author><keyname>Schmah</keyname><forenames>Tanya</forenames></author></authors><title>Exploiting bilateral symmetry in brain lesion segmentation</title><categories>eess.IV cs.CV cs.LG q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain lesions, including stroke and tumours, have a high degree of
variability in terms of location, size, intensity and form, making automatic
segmentation difficult. We propose an improvement to existing segmentation
methods by exploiting the bilateral quasi-symmetry of healthy brains, which
breaks down when lesions are present. Specifically, we use nonlinear
registration of a neuroimage to a reflected version of itself (&quot;reflective
registration&quot;) to determine for each voxel its homologous (corresponding) voxel
in the other hemisphere. A patch around the homologous voxel is added as a set
of new features to the segmentation algorithm. To evaluate this method, we
implemented two different CNN-based multimodal MRI stroke lesion segmentation
algorithms, and then augmented them by adding extra symmetry features using the
reflective registration method described above. For each architecture, we
compared the performance with and without symmetry augmentation, on the SISS
Training dataset of the Ischemic Stroke Lesion Segmentation Challenge (ISLES)
2015 challenge. Using affine reflective registration improves performance over
baseline, but nonlinear reflective registration gives significantly better
results: an improvement in Dice coefficient of 13 percentage points over
baseline for one architecture and 9 points for the other. We argue for the
broad applicability of adding symmetric features to existing segmentation
algorithms, specifically using nonlinear, template-free methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08254</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08254</id><created>2019-07-18</created><authors><author><keyname>Davis</keyname><forenames>Andrew F.</forenames></author><author><keyname>Fabien</keyname><forenames>Brian C.</forenames></author></authors><title>Wave Excitation Force Estimation of Wave Energy Floats Using Extended
  Kalman Filters</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many advanced control strategies the wave excitation force is key to
determining the control input. However, it is often difficult to measure the
excitation force on a Wave Energy Converter (WEC). The use of Kalman filters to
estimate the wave excitation force based on readily available measurement data
can potentially fill the gap between the development of WEC control strategies
and the data that is available. Two different estimation methods using an
nonlinear Extended Kalman Filter are tested on experimental wave tank data for
a heaving semi-submerged float. The first method relies on directly including
the excitation force as a state in the first order dynamics---which allows the
&quot;random walk&quot; of the Kalman filter to identify an estimate of the excitation
force. The second method of estimation involves modeling the wave excitation
force as a harmonic oscillator comprised of sinusoidal components. Both methods
are evaluated for a variety of incident waves and additional sensitivity
analyses are performed to investigate the susceptibility of these estimation
methods to changes in the model, measurement noise, and sampling rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08279</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08279</id><created>2019-07-18</created><authors><author><keyname>Meyers</keyname><forenames>Bennet</forenames></author><author><keyname>Tabone</keyname><forenames>Michaelangelo</forenames></author><author><keyname>Kara</keyname><forenames>Emre Can</forenames></author></authors><title>Statistical Clear Sky Fitting Algorithm</title><categories>eess.SY cs.SY eess.SP</categories><comments>Presented at 45th IEEE Photovoltaic Specialists Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm that estimates a clear sky performance signal from
the measured power of a PV system. The algorithm uses only observed power
output, and assumes no knowledge of weather, irradiance data, or system
configuration metadata. This is a novel approach to understanding the clear sky
behavior of an installed PV system, that does not rely on traditional
atmospheric and geometric modeling techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08283</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08283</id><created>2019-07-18</created><authors><author><keyname>Acharya</keyname><forenames>Samrat</forenames></author><author><keyname>Dvorkin</keyname><forenames>Yury</forenames></author><author><keyname>Karri</keyname><forenames>Ramesh</forenames></author></authors><title>Public Plug-in Electric Vehicles + Grid Data: Is a New Cyberattack
  Vector Viable?</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Such high-wattage demand-side appliances as Plug-in Electric Vehicles (PEVs)
are proliferating. As a result, information on the charging patterns of PEVs is
becoming accessible via smartphone applications, which aggregate real-time
availability and historical usage of public PEV charging stations. Moreover,
information on the power grid infrastructure and operations is available in
white papers, technical documents, and real-time dashboards of the utilities,
affiliates, and the power grid operators. The research question that this study
explores is: Can one combine high-wattage demand-side appliances with public
information to launch cyberattacks on the power grid? To answer this question
and report a proof of concept demonstration, the study scrapes data from public
sources for Manhattan, NY using the electric vehicle charging station
smartphone application and the power grid data circulated by the US Energy
Information Administration, New York Independent System Operator, and the local
utility in New York City. It then designs a novel data-driven cyberattack
strategy using state-feedback based partial eigenvalue relocation, which
targets small-signal stability of the power grid. The study establishes that
while such an attack is not possible at the current penetration level of PEVs,
it will be practical once the number of PEVs increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08289</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08289</id><created>2019-07-18</created><authors><author><keyname>Xu</keyname><forenames>Ying</forenames></author><author><keyname>Qu</keyname><forenames>Zhihua</forenames></author><author><keyname>Harvey</keyname><forenames>Roland</forenames></author><author><keyname>Namerikawa</keyname><forenames>Toru</forenames></author></authors><title>Data-Driven Wide-Area Control Design of Power System Using the Passivity
  Shortage Framework</title><categories>eess.SY cs.SY</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel wide-area control design is presented to mitigate inter-area power
frequency oscillations. A large-scale power system is decomposed into a network
of passivity-short subsystems whose nonlinear interconnections have a
state-dependent affine form, and by utilizing the passivity shortage framework
a two-level design procedure is developed. At the lower level, any generator
control can be viewed as one that makes the generator passivity-short and $L_2$
stable, and the stability impact of the lower-level control on the overall
system can be characterized in terms of two parameters. While the system is
nonlinear, the impact parameters can be optimized by solving a data-driven
matrix inequality (DMI), and the high-level wide-area control is then designed
by solving another Lyapunov matrix inequality in terms of the design
parameters. The proposed methodology makes the design modular, and the
resulting control is adaptive with respect to operating conditions of the power
system. A test system is used to illustrate the proposed design, including DMI
and the wide-area control, and simulation results demonstrate effectiveness in
damping out inter-area oscillations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08293</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08293</id><created>2019-07-15</created><authors><author><keyname>Dhawan</keyname><forenames>Kunal</forenames></author><author><keyname>Sreeram</keyname><forenames>Ganji</forenames></author><author><keyname>Priyadarshi</keyname><forenames>Kumar</forenames></author><author><keyname>Sinha</keyname><forenames>Rohit</forenames></author></authors><title>Investigating Target Set Reduction for End-to-End Speech Recognition of
  Hindi-English Code-Switching Data</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end (E2E) systems are fast replacing the conventional systems in the
domain of automatic speech recognition. As the target labels are learned
directly from speech data, the E2E systems need a bigger corpus for effective
training. In the context of code-switching task, the E2E systems face two
challenges: (i) the expansion of the target set due to multiple languages
involved, and (ii) the lack of availability of sufficiently large
domain-specific corpus. Towards addressing those challenges, we propose an
approach for reducing the number of target labels for reliable training of the
E2E systems on limited data. The efficacy of the proposed approach has been
demonstrated on two prominent architectures, namely CTC-based and
attention-based E2E networks. The experimental validations are performed on a
recently created Hindi-English code-switching corpus. For contrast purpose, the
results for the full target set based E2E system and a hybrid DNN-HMM system
are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08294</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08294</id><created>2019-07-19</created><authors><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>DNN-based Speaker Embedding Using Subjective Inter-speaker Similarity
  for Multi-speaker Modeling in Speech Synthesis</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>6 pages, 7 figures, accepted for The 10th ISCA Speech Synthesis
  Workshop (SSW10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes novel algorithms for speaker embedding using subjective
inter-speaker similarity based on deep neural networks (DNNs). Although
conventional DNN-based speaker embedding such as a $d$-vector can be applied to
multi-speaker modeling in speech synthesis, it does not correlate with the
subjective inter-speaker similarity and is not necessarily appropriate speaker
representation for open speakers whose speech utterances are not included in
the training data. We propose two training algorithms for DNN-based speaker
embedding model using an inter-speaker similarity matrix obtained by
large-scale subjective scoring. One is based on similarity vector embedding and
trains the model to predict a vector of the similarity matrix as speaker
representation. The other is based on similarity matrix embedding and trains
the model to minimize the squared Frobenius norm between the similarity matrix
and the Gram matrix of $d$-vectors, i.e., the inter-speaker similarity derived
from the $d$-vectors. We crowdsourced the inter-speaker similarity scores of
153 Japanese female speakers, and the experimental results demonstrate that our
algorithms learn speaker embedding that is highly correlated with the
subjective similarity. We also apply the proposed speaker embedding to
multi-speaker modeling in DNN-based speech synthesis and reveal that the
proposed similarity vector embedding improves synthetic speech quality for open
speakers whose speech utterances are unseen during the training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08303</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08303</id><created>2019-07-18</created><authors><author><keyname>Nalepa</keyname><forenames>Jakub</forenames></author><author><keyname>Lorenzo</keyname><forenames>Pablo Ribalta</forenames></author><author><keyname>Marcinkiewicz</keyname><forenames>Michal</forenames></author><author><keyname>Bobek-Billewicz</keyname><forenames>Barbara</forenames></author><author><keyname>Wawrzyniak</keyname><forenames>Pawel</forenames></author><author><keyname>Walczak</keyname><forenames>Maksym</forenames></author><author><keyname>Kawulok</keyname><forenames>Michal</forenames></author><author><keyname>Dudzik</keyname><forenames>Wojciech</forenames></author><author><keyname>Mrukwa</keyname><forenames>Grzegorz</forenames></author><author><keyname>Ulrych</keyname><forenames>Pawel</forenames></author><author><keyname>Hayball</keyname><forenames>Michael P.</forenames></author></authors><title>Fully-automated deep learning-powered system for DCE-MRI analysis of
  brain tumors</title><categories>eess.IV cs.CV</categories><comments>Submitted for publication in Artificial Intelligence in Medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) plays an
important role in diagnosis and grading of brain tumor. Although manual DCE
biomarker extraction algorithms boost the diagnostic yield of DCE-MRI by
providing quantitative information on tumor prognosis and prediction, they are
time-consuming and prone to human error. In this paper, we propose a
fully-automated, end-to-end system for DCE-MRI analysis of brain tumors. Our
deep learning-powered technique does not require any user interaction, it
yields reproducible results, and it is rigorously validated against benchmark
(BraTS'17 for tumor segmentation, and a test dataset released by the
Quantitative Imaging Biomarkers Alliance for the contrast-concentration
fitting) and clinical (44 low-grade glioma patients) data. Also, we introduce a
cubic model of the vascular input function used for pharmacokinetic modeling
which significantly decreases the fitting error when compared with the state of
the art, alongside a real-time algorithm for determination of the vascular
input region. An extensive experimental study, backed up with statistical
tests, showed that our system delivers state-of-the-art results (in terms of
segmentation accuracy and contrast-concentration fitting) while requiring less
than 3 minutes to process an entire input DCE-MRI study using a single GPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08310</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08310</id><created>2019-07-18</created><updated>2019-07-31</updated><authors><author><keyname>Patel</keyname><forenames>Yash</forenames></author><author><keyname>Appalaraju</keyname><forenames>Srikar</forenames></author><author><keyname>Manmatha</keyname><forenames>R.</forenames></author></authors><title>Deep Perceptual Compression</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several deep learned lossy compression techniques have been proposed in the
recent literature. Most of these are optimized by using either MS-SSIM
(multi-scale structural similarity) or MSE (mean squared error) as a loss
function. Unfortunately, neither of these correlate well with human perception
and this is clearly visible from the resulting compressed images. In several
cases, the MS-SSIM for deep learned techniques is higher than say a
conventional, non-deep learned codec such as JPEG-2000 or BPG. However, the
images produced by these deep learned techniques are in many cases clearly
worse to human eyes than those produced by JPEG-2000 or BPG.
  We propose the use of an alternative, deep perceptual metric, which has been
shown to align better with human perceptual similarity. We then propose Deep
Perceptual Compression (DPC) which makes use of an encoder-decoder based image
compression model to jointly optimize on the deep perceptual metric and
MS-SSIM. Via extensive human evaluations, we show that the proposed method
generates visually better results than previous learning based compression
methods and JPEG-2000, and is comparable to BPG. Furthermore, we demonstrate
that for tasks like object-detection, images compressed with DPC give better
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08320</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08320</id><created>2019-07-18</created><authors><author><keyname>Maciel-Pearson</keyname><forenames>Bruna G.</forenames></author><author><keyname>Akcay</keyname><forenames>Samet</forenames></author><author><keyname>Atapour-Abarghouei</keyname><forenames>Amir</forenames></author><author><keyname>Holder</keyname><forenames>Christopher</forenames></author><author><keyname>Breckon</keyname><forenames>Toby P.</forenames></author></authors><title>Multi-Task Regression-based Learning for Autonomous Unmanned Aerial
  Vehicle Flight Control within Unstructured Outdoor Environments</title><categories>cs.RO cs.CV cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increased growth in the global Unmanned Aerial Vehicles (UAV) (drone)
industry has expanded possibilities for fully autonomous UAV applications. A
particular application which has in part motivated this research is the use of
UAV in wide area search and surveillance operations in unstructured outdoor
environments. The critical issue with such environments is the lack of
structured features that could aid in autonomous flight, such as road lines or
paths. In this paper, we propose an End-to-End Multi-Task Regression-based
Learning approach capable of defining flight commands for navigation and
exploration under the forest canopy, regardless of the presence of trails or
additional sensors (i.e. GPS). Training and testing are performed using a
software in the loop pipeline which allows for a detailed evaluation against
state-of-the-art pose estimation techniques. Our extensive experiments
demonstrate that our approach excels in performing dense exploration within the
required search perimeter, is capable of covering wider search regions,
generalises to previously unseen and unexplored environments and outperforms
contemporary state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08328</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08328</id><created>2019-07-18</created><authors><author><keyname>Fotin</keyname><forenames>Sergei V.</forenames></author><author><keyname>Yankelevitz</keyname><forenames>David F.</forenames></author><author><keyname>Henschke</keyname><forenames>Claudia I.</forenames></author><author><keyname>Reeves</keyname><forenames>Anthony P.</forenames></author></authors><title>A multiscale Laplacian of Gaussian (LoG) filtering approach to pulmonary
  nodule detection from whole-lung CT scans</title><categories>eess.IV cs.CV</categories><comments>16 pages, 23 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Candidate generation, the first stage for most computer aided detection (CAD)
systems, rapidly scans the entire image data for any possible abnormality
locations, while the subsequent stages of the CAD system refine the candidates
list to determine the most probable or significant of these candidates. The
candidate generator creates a list of the locations and provides a size
estimate for each candidate. A multiscale scale-normalized Laplacian of
Gaussian (LoG) filtering method for detecting pulmonary nodules in whole-lung
CT scans, presented in this paper, achieves a high sensitivity for both solid
and nonsolid pulmonary nodules. The pulmonary nodule LoG filtering method was
validated on a size-enriched database of 706 whole-lung low-dose CT scans
containing 499 solid (&gt;= 4 mm) and 107 nonsolid (&gt;= 6 mm) pulmonary nodules.
The method achieved a sensitivity of 0.998 (498/499) for solid nodules and a
sensitivity of 1.000 (107/107) for nonsolid nodules. Furthermore, compared to
radiologist measurements, the method provided low average nodule size
estimation error of 0.12 mm for solid and 1.27 mm for nonsolid nodules. The
average distance between automatically and manually determined nodule centroids
were 1.41 mm and 1.43 mm, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08338</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08338</id><created>2019-07-18</created><authors><author><keyname>Koizumi</keyname><forenames>Yuma</forenames></author><author><keyname>Saito</keyname><forenames>Shoichiro</forenames></author><author><keyname>Yamaguchi</keyname><forenames>Masataka</forenames></author><author><keyname>Murata</keyname><forenames>Shin</forenames></author><author><keyname>Harada</keyname><forenames>Noboru</forenames></author></authors><title>Batch Uniformization for Minimizing Maximum Anomaly Score of DNN-based
  Anomaly Detection in Sounds</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>5 pages, to appear in IEEE WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of an autoencoder (AE) as a normal model is a state-of-the-art technique
for unsupervised-anomaly detection in sounds (ADS). The AE is trained to
minimize the sample mean of the anomaly score of normal sounds in a mini-batch.
One problem with this approach is that the anomaly score of rare-normal sounds
becomes higher than that of frequent-normal sounds, because the sample mean is
strongly affected by frequent-normal samples, resulting in preferentially
decreasing the anomaly score of frequent-normal samples. To decrease anomaly
scores for both frequent- and rare-normal sounds, we propose batch
uniformization, a training method for unsupervised-ADS for minimizing a
weighted average of the anomaly score on each sample in a mini-batch. We used
the reciprocal of the probabilistic density of each sample as the weight, more
intuitively, a large weight is given for rare-normal sounds. Such a weight
works to give a constant anomaly score for both frequent- and rare-normal
sounds. Since the probabilistic density is unknown, we estimate it by using the
kernel density estimation on each training mini-batch. Verification- and
objective-experiments show that the proposed batch uniformization improves the
performance of unsupervised-ADS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08363</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08363</id><created>2019-07-18</created><authors><author><keyname>Li</keyname><forenames>Zhuoying</forenames></author><author><keyname>Zhou</keyname><forenames>Pan</forenames></author><author><keyname>Zhang</keyname><forenames>Yanru</forenames></author><author><keyname>Gao</keyname><forenames>Lin</forenames></author></authors><title>Joint Coverage and Power Control in Highly Dynamic and Massive UAV
  Networks: An Aggregative Game-theoretic Learning Approach</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAV) ad-hoc network is a significant contingency
plan for communication after a natural disaster, such as typhoon and
earthquake. To achieve efficient and rapid networks deployment, we employ
noncooperative game theory and amended binary log-linear algorithm (BLLA)
seeking for the Nash equilibrium which achieves the optimal network
performance. We not only take channel overlap and power control into account
but also consider coverage and the complexity of interference. However,
extensive UAV game theoretical models show limitations in post-disaster
scenarios which require large-scale UAV network deployments. Besides, the
highly dynamic post-disaster scenarios cause strategies updating constraint and
strategy-deciding error on UAV ad-hoc networks. To handle these problems, we
employ aggregative game which could capture and cover those characteristics.
Moreover, we propose a novel synchronous payoff-based binary log-linear
learning algorithm (SPBLLA) to lessen information exchange and reduce time
consumption. Ultimately, the experiments indicate that, under the same
strategy-deciding error rate, SPBLLA's learning rate is manifestly faster than
that of the revised BLLA. Hence, the new model and algorithm are more suitable
and promising for large-scale highly dynamic scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08448</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08448</id><created>2019-07-19</created><authors><author><keyname>Valsesia</keyname><forenames>Diego</forenames></author><author><keyname>Fracastoro</keyname><forenames>Giulia</forenames></author><author><keyname>Magli</keyname><forenames>Enrico</forenames></author></authors><title>Deep Graph-Convolutional Image Denoising</title><categories>eess.IV cs.CV cs.LG cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-local self-similarity is well-known to be an effective prior for the
image denoising problem. However, little work has been done to incorporate it
in convolutional neural networks, which surpass non-local model-based methods
despite only exploiting local information. In this paper, we propose a novel
end-to-end trainable neural network architecture employing layers based on
graph convolution operations, thereby creating neurons with non-local receptive
fields. The graph convolution operation generalizes the classic convolution to
arbitrary graphs. In this work, the graph is dynamically computed from
similarities among the hidden features of the network, so that the powerful
representation learning capabilities of the network are exploited to uncover
self-similar patterns. We introduce a lightweight Edge-Conditioned Convolution
which addresses vanishing gradient and over-parameterization issues of this
particular graph convolution. Extensive experiments show state-of-the-art
performance with improved qualitative and quantitative results on both
synthetic Gaussian noise and real noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08457</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08457</id><created>2019-07-19</created><authors><author><keyname>Salem</keyname><forenames>Abdelhamid</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author></authors><title>Rate Splitting with Finite Constellations: The Benefits of Interference
  Exploitation vs Suppression</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rate-Splitting (RS) has been proposed recently to enhance the performance of
multi-user multiple-input multiple-output (MU-MIMO) systems. In RS, a user
message is split into a common and a private part, where the common part is
decoded by all users, while the private part is decoded only by the intended
user. In this paper, we study RS under a phase-shift keying (PSK) input
alphabet for multi-user multi-antenna system and propose a constructive
interference (CI) exploitation approach to further enhance the sum-rate
achieved by RS under PSK signaling. To that end, new analytical expressions for
the ergodic sum-rate are derived for two precoding techniques of the private
messages, namely, 1) a traditional interference suppression zero-forcing (ZF)
precoding approach, 2) a closed-form CI precoding approach. Our analysis is
presented for perfect channel state information at the transmitter (CSIT), and
is extended to imperfect CSIT knowledge. A novel power allocation strategy,
specifically suited for the finite alphabet setup, is derived and shown to lead
to superior performance for RS over conventional linear precoding not relying
on RS (NoRS). The results in this work validate the significant sum-rate gain
of RS with CI over the conventional RS with ZF and NoRS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08487</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08487</id><created>2019-07-19</created><authors><author><keyname>Shen</keyname><forenames>Yifei</forenames></author><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>A Graph Neural Network Approach for Scalable Wireless Power Control</title><categories>cs.IT cs.LG eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have recently emerged as a disruptive technology to
solve NP-hard wireless resource allocation problems in a real-time manner.
However, the adopted neural network structures, e.g., multi-layer perceptron
(MLP) and convolutional neural network (CNN), are inherited from deep learning
for image processing tasks, and thus are not tailored to problems in wireless
networks. In particular, the performance of these methods deteriorates
dramatically when the wireless network size becomes large. In this paper, we
propose to utilize graph neural networks (GNNs) to develop scalable methods for
solving the power control problem in $K$-user interference channels.
Specifically, a $K$-user interference channel is first modeled as a complete
graph, where the quantitative information of wireless channels is incorporated
as the features of the graph. We then propose an interference graph
convolutional neural network (IGCNet) to learn the optimal power control in an
unsupervised manner. It is shown that one-layer IGCNet is a universal
approximator to continuous set functions, which well matches the permutation
invariance property of interference channels and it is robust to imperfect
channel state information (CSI). Extensive simulations will show that the
proposed IGCNet outperforms existing methods and achieves significant speedup
over the classic algorithm for power control, namely, WMMSE. The code is
available on https://github.com/yshenaw/Globecom2019.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08488</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08488</id><created>2019-07-19</created><authors><author><keyname>Effland</keyname><forenames>Alexander</forenames></author><author><keyname>Kobler</keyname><forenames>Erich</forenames></author><author><keyname>Kunisch</keyname><forenames>Karl</forenames></author><author><keyname>Pock</keyname><forenames>Thomas</forenames></author></authors><title>An Optimal Control Approach to Early Stopping Variational Methods for
  Image Restoration</title><categories>math.OC cs.LG eess.IV</categories><comments>14 figures</comments><msc-class>68T45, 93A30, 34H05, 49K15, 65L05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a well-known phenomenon of variational approaches in image
processing, where typically the best image quality is achieved when the
gradient flow process is stopped before converging to a stationary point. This
paradox originates from a tradeoff between optimization and modelling errors of
the underlying variational model and holds true even if deep learning methods
are used to learn highly expressive regularizers from data. In this paper, we
take advantage of this paradox and introduce an optimal stopping time into the
gradient flow process, which in turn is learned from data by means of an
optimal control approach. As a result, we obtain highly efficient numerical
schemes that achieve competitive results for image denoising and image
deblurring. A nonlinear spectral analysis of the gradient of the learned
regularizer gives enlightening insights about the different regularization
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08494</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08494</id><created>2019-07-19</created><authors><author><keyname>Papsotiriou</keyname><forenames>Evangelos N.</forenames></author><author><keyname>Boulogeorgos</keyname><forenames>Alexandros-Apostolos A.</forenames></author><author><keyname>Alexiou</keyname><forenames>Angeliki</forenames></author></authors><title>Performance evaluation of THz wireless systems under the joint impact of
  misalignment fading and phase noise</title><categories>cs.IT eess.SP math.IT</categories><comments>2 pages, 4 figures, Presented in EuCNC2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the joint impact of misalignment fading and
local oscillator (LO) phase noise (PHN) in multi-carrier terahertz (THz)
wireless systems. In more detail, after establishing a suitable system model
that takes into account the particularities of the THz channel, as well as the
transceivers characteristics, we present simulation results that quantify the
joint impact of misalignment fading and PHN in terms of average
signal-to-interference-plus-noise-ratio (SINR) and outage probability (OP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08500</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08500</id><created>2019-07-19</created><authors><author><keyname>Singh</keyname><forenames>Durgesh</forenames></author><author><keyname>Ghosh</keyname><forenames>Sasthi C.</forenames></author></authors><title>Network-Assisted D2D Relay Selection Under the Presence of Dynamic
  Obstacles</title><categories>cs.NI eess.SP</categories><comments>A preliminary version of this paper has been accepted for publication
  in the proceedings of the 44th IEEE Conference on Local Computer Networks
  (LCN), October 14-17, 2019, Osnabr\&quot;{u}ck, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (\texttt{mmWave}) channels in device to device (\texttt{D2D})
communication are susceptible to blockages in spite of using directional beams
from multi-input multi-output (\texttt{MIMO}) antennas to compensate for high
propagation loss. This motivates one to look for the presence of obstacles
while forming \texttt{D2D} links among user equipments (\texttt{UEs}) which are
in motion. In \texttt{D2D} communication, moving \texttt{UEs} also act as
relays to forward data from one \texttt{UE} to another which introduces the
problem of relay selection. The problem becomes more challenging when the
obstacles are also in motion (dynamic obstacles) along with the moving
\texttt{UEs}. First we have developed a probabilistic model for relay selection
which considers both moving \texttt{UEs} and dynamic obstacles. Then we have
analyzed the probability of dynamic obstacles blocking a link in 3D Euclidean
space by exploiting the information from \texttt{MIMO} radar connected to the
base station. Finally, using this information, we have developed unique
strategies based on simple geometry to find the best relay which maximizes the
expected data rate. Through simulations we have shown that our proposed
strategy gives a significant improvement in packet loss due to mobility of
nodes and dynamic obstacles in a \texttt{mmWave} channel over traditional
approaches which do not consider dynamic obstacle's presence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08506</identifier>
 <datestamp>2019-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08506</id><created>2019-07-19</created><updated>2019-11-06</updated><authors><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Gharib</keyname><forenames>Shayan</forenames></author><author><keyname>Magron</keyname><forenames>Paul</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Language Modelling for Sound Event Detection with Teacher Forcing and
  Scheduled Sampling</title><categories>cs.SD cs.LG eess.AS</categories><comments>Fixed the display of URLs at footnote, updated the results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sound event detection (SED) method typically takes as an input a sequence
of audio frames and predicts the activities of sound events in each frame. In
real-life recordings, the sound events exhibit some temporal structure: for
instance, a &quot;car horn&quot; will likely be followed by a &quot;car passing by&quot;. While
this temporal structure is widely exploited in sequence prediction tasks (e.g.,
in machine translation), where language models (LM) are exploited, it is not
satisfactorily modeled in SED. In this work we propose a method which allows a
recurrent neural network (RNN) to learn an LM for the SED task. The method
conditions the input of the RNN with the activities of classes at the previous
time step. We evaluate our method using F1 score and error rate (ER) over three
different and publicly available datasets; the TUT-SED Synthetic 2016 and the
TUT Sound Events 2016 and 2017 datasets. The obtained results show an increase
of 9% and 2% at the F1 (higher is better) and a decrease of 7% and 2% at ER
(lower is better) for the TUT Sound Events 2016 and 2017 datasets,
respectively, when using our method. On the contrary, with our method there is
a decrease of 4% at F1 score and an increase of 7% at ER for the TUT-SED
Synthetic 2016 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08511</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08511</id><created>2019-07-19</created><updated>2020-02-14</updated><authors><author><keyname>Lagrange</keyname><forenames>Adrien</forenames></author><author><keyname>Fauvel</keyname><forenames>Mathieu</forenames></author><author><keyname>May</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author></authors><title>Matrix cofactorization for joint spatial-spectral unmixing of
  hyperspectral images</title><categories>cs.CV eess.IV</categories><doi>10.1109/TGRS.2020.2968541</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral unmixing aims at identifying a set of elementary spectra and
the corresponding mixture coefficients for each pixel of an image. As the
elementary spectra correspond to the reflectance spectra of real materials,
they are often very correlated yielding an ill-conditioned problem. To enrich
the model and to reduce ambiguity due to the high correlation, it is common to
introduce spatial information to complement the spectral information. The most
common way to introduce spatial information is to rely on a spatial
regularization of the abundance maps. In this paper, instead of considering a
simple but limited regularization process, spatial information is directly
incorporated through the newly proposed context of spatial unmixing. Contextual
features are extracted for each pixel and this additional set of observations
is decomposed according to a linear model. Finally the spatial and spectral
observations are unmixed jointly through a cofactorization model. In
particular, this model introduces a coupling term used to identify clusters of
shared spatial and spectral signatures. An evaluation of the proposed method is
conducted on synthetic and real data and shows that results are accurate and
also very meaningful since they describe both spatially and spectrally the
various areas of the scene.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08520</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08520</id><created>2019-07-19</created><authors><author><keyname>Ramires</keyname><forenames>Ant&#xf3;nio</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Data Augmentation for Instrument Classification Robust to Audio Effects</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reusing recorded sounds (sampling) is a key component in Electronic Music
Production (EMP), which has been present since its early days and is at the
core of genres like hip-hop or jungle. Commercial and non-commercial services
allow users to obtain collections of sounds (sample packs) to reuse in their
compositions. Automatic classification of one-shot instrumental sounds allows
automatically categorising the sounds contained in these collections, allowing
easier navigation and better characterisation. Automatic instrument
classification has mostly targeted the classification of unprocessed isolated
instrumental sounds or detecting predominant instruments in mixed music tracks.
For this classification to be useful in audio databases for EMP, it has to be
robust to the audio effects applied to unprocessed sounds. In this paper we
evaluate how a state of the art model trained with a large dataset of one-shot
instrumental sounds performs when classifying instruments processed with audio
effects. In order to evaluate the robustness of the model, we use data
augmentation with audio effects and evaluate how each effect influences the
classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08531</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08531</id><created>2019-07-19</created><authors><author><keyname>Alessandretti</keyname><forenames>Andrea</forenames></author><author><keyname>Aguiar</keyname><forenames>A. Pedro</forenames></author></authors><title>An optimization-based cooperative path-following framework for multiple
  robotic vehicles</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the design of an optimization-based cooperative
path-following control law for multiple robotic vehicles that optimally
balances the transient trade-off between coordination and path-following
errors. To this end, we formulate a more general multi-agent framework where
each agent is associated with (i) a continuous-time dynamical model, which
governs the evolution of its state, and (ii) an output equation that is a
function of both the state of the agent and a coordination vector. According to
a given network topology, each agent can access its state and coordination
vector, as well as the coordination vectors of the neighboring agents. In this
setup, the goal is to design a distributed control law that steers the output
signals to the origin, while simultaneously driving the coordination vectors of
the agents of the network to consensus. To solve this, we propose a model
predictive control scheme that builds on a pre-existing auxiliary consensus
control law to design a performance index that combines the output regulation
objective with the consensus objective. Convergence guarantees under which one
can solve this coordinated output regulation problem are provided. Numerical
simulations display the effectiveness of the proposed scheme applied to a
cooperative path following control problem of a network of 3D nonholonomic
robotic vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08533</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08533</id><created>2019-07-19</created><updated>2019-10-18</updated><authors><author><keyname>Abramian</keyname><forenames>David</forenames></author><author><keyname>Eklund</keyname><forenames>Anders</forenames></author></authors><title>Generating fMRI volumes from T1-weighted volumes using 3D CycleGAN</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Registration between an fMRI volume and a T1-weighted volume is challenging,
since fMRI volumes contain geometric distortions. Here we present preliminary
results showing that 3D CycleGAN can be used to synthesize fMRI volumes from
T1-weighted volumes, and vice versa, which can facilitate registration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08535</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08535</id><created>2019-07-19</created><authors><author><keyname>Jones</keyname><forenames>Rasmus T.</forenames></author><author><keyname>Yankov</keyname><forenames>Metodi P.</forenames></author><author><keyname>Zibar</keyname><forenames>Darko</forenames></author></authors><title>End-to-end Learning for GMI Optimized Geometric Constellation Shape</title><categories>cs.IT eess.SP math.IT stat.ML</categories><comments>submitted to ECOC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autoencoder-based geometric shaping is proposed that includes optimizing bit
mappings. Up to 0.2 bits/QAM symbol gain in GMI is achieved for a variety of
data rates and in the presence of transceiver impairments. The gains can be
harvested with standard binary FEC at no cost w.r.t. conventional BICM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08587</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08587</id><created>2019-07-19</created><authors><author><keyname>Raj</keyname><forenames>Nidhish</forenames></author><author><keyname>Banavar</keyname><forenames>Ravi</forenames></author><author><keyname>Abhishek</keyname></author><author><keyname>Kothari</keyname><forenames>Mangal</forenames></author></authors><title>Attitude Control of a Novel Tailsitter: Swiveling Biplane-Quadrotor</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a solution to the attitude tracking problem for a novel
quadrotor tailsitter unmanned aerial vehicle called swiveling biplane
quadrotor. The proposed vehicle design addresses the lack of yaw control
authority in conventional biplane quadrotor tailsitters by proposing a new
design wherein two wings with two attached propellers are joined together with
a rod through a swivel mechanism. The yaw torque is generated by relative
rotation of the thrust vector of each wing. The unique design of this
configuration having two rigid bodies interconnected through a rod with zero
torsional rigidity makes the vehicle underactuated in the attitude
configuration manifold. An output tracking problem is posed which results in a
single equivalent rigid body attitude tracking problem with second-order moment
dynamics. The proposed controller is uniformly valid for all attitudes and is
based on dynamic feedback linearization in a geometric control framework.
Almost-global asymptotic stability of the desired equilibrium of the tracking
error dynamics is shown. The efficacy of the controller is shown with numerical
simulation and flight tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08591</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08591</id><created>2019-07-17</created><updated>2019-09-26</updated><authors><author><keyname>Biferale</keyname><forenames>Luca</forenames></author><author><keyname>Bonaccorso</keyname><forenames>Fabio</forenames></author><author><keyname>Buzzicotti</keyname><forenames>Michele</forenames></author><author><keyname>Di Leoni</keyname><forenames>Patricio Clark</forenames></author><author><keyname>Gustavsson</keyname><forenames>Kristian</forenames></author></authors><title>Zermelo's problem: Optimal point-to-point navigation in 2D turbulent
  flows using Reinforcement Learning</title><categories>nlin.CD cs.AI cs.LG cs.SY eess.SY physics.flu-dyn</categories><doi>10.1063/1.5120370</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To find the path that minimizes the time to navigate between two given points
in a fluid flow is known as Zermelo's problem. Here, we investigate it by using
a Reinforcement Learning (RL) approach for the case of a vessel which has a
slip velocity with fixed intensity, Vs , but variable direction and navigating
in a 2D turbulent sea. We show that an Actor-Critic RL algorithm is able to
find quasi-optimal solutions for both time-independent and chaotically evolving
flow configurations. For the frozen case, we also compared the results with
strategies obtained analytically from continuous Optimal Navigation (ON)
protocols. We show that for our application, ON solutions are unstable for the
typical duration of the navigation process, and are therefore not useful in
practice. On the other hand, RL solutions are much more robust with respect to
small changes in the initial conditions and to external noise, even when V s is
much smaller than the maximum flow velocity. Furthermore, we show how the RL
approach is able to take advantage of the flow properties in order to reach the
target, especially when the steering speed is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08612</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08612</id><created>2019-05-21</created><updated>2019-07-22</updated><authors><author><keyname>Cardoso</keyname><forenames>M. Jorge</forenames></author><author><keyname>Feragen</keyname><forenames>Aasa</forenames></author><author><keyname>Glocker</keyname><forenames>Ben</forenames></author><author><keyname>Konukoglu</keyname><forenames>Ender</forenames></author><author><keyname>Oguz</keyname><forenames>Ipek</forenames></author><author><keyname>Unal</keyname><forenames>Gozde</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author></authors><title>Medical Imaging with Deep Learning: MIDL 2019 -- Extended Abstract Track</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted extended abstracts can also be found at
  https://openreview.net/group?id=MIDL.io/2019/Conference#abstract-accept-papers</comments><proxy>Tom Vercauteren</proxy><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This compendium gathers all the accepted extended abstracts from the Second
International Conference on Medical Imaging with Deep Learning (MIDL 2019),
held in London, UK, 8-10 July 2019. Note that only accepted extended abstracts
are listed here, the Proceedings of the MIDL 2019 Full Paper Track are
published as Volume 102 of the Proceedings of Machine Learning Research (PMLR)
http://proceedings.mlr.press/v102/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08619</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08619</id><created>2019-07-18</created><authors><author><keyname>Hady</keyname><forenames>Mohamad Abdul</forenames></author><author><keyname>Kocer</keyname><forenames>Basaran Bahadir</forenames></author><author><keyname>Kandath</keyname><forenames>Harikumar</forenames></author><author><keyname>Pratama</keyname><forenames>Mahardhika</forenames></author></authors><title>Real-time UAV Complex Missions Leveraging Self-Adaptive Controller with
  Elastic Structure</title><categories>eess.SY cs.RO cs.SY</categories><comments>18 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The expectation of unmanned air vehicles (UAVs) pushes the operation
environment to narrow spaces, where the systems may fly very close to an object
and perform an interaction. This phase brings the variation in UAV dynamics:
thrust and drag coefficient of the propellers might change under different
proximity. At the same time, UAVs may need to operate under external
disturbances to follow time-based trajectories. Under these challenging
conditions, a standard controller approach may not handle all missions with a
fixed structure, where there may be a need to adjust its parameters for each
different case. With these motivations, practical implementation and evaluation
of an autonomous controller applied to a quadrotor UAV are proposed in this
work. A self-adaptive controller based on a composite control scheme where a
combination of sliding mode control (SMC) and evolving neuro-fuzzy control is
used. The parameter vector of the neuro-fuzzy controller is updated adaptively
based on the sliding surface of the SMC. The autonomous controller possesses a
new elastic structure, where the number of fuzzy rules keeps growing or get
pruned based on bias and variance balance. The interaction of the UAV is
experimentally evaluated in real time considering the ground effect, ceiling
effect and flight through a strong fan-generated wind while following
time-based trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08661</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08661</id><created>2019-07-19</created><authors><author><keyname>Zhang</keyname><forenames>Yichi</forenames></author><author><keyname>Zhang</keyname><forenames>Yiting</forenames></author><author><keyname>Duan</keyname><forenames>Zhiyao</forenames></author></authors><title>Sound Search by Text Description or Vocal Imitation?</title><categories>cs.HC cs.SD eess.AS</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Searching sounds by text labels is often difficult, as text descriptions
cannot describe the audio content in detail. Query by vocal imitation bridges
such gap and provides a novel way to sound search. Several algorithms for sound
search by vocal imitation have been proposed and evaluated in a simulation
environment, however, they have not been deployed into a real search engine nor
evaluated by real users. This pilot work conducts a subjective study to compare
these two approaches to sound search, and tries to answer the question of which
approach works better for what kinds of sounds. To do so, we developed two
web-based search engines for sound, one by vocal imitation (Vroom!) and the
other by text description (TextSearch). We also developed an experimental
framework to host these engines to collect statistics of user behaviors and
ratings. Results showed that Vroom! received significantly higher search
satisfaction ratings than TextSearch did for sound categories that were
difficult for subjects to describe by text. Results also showed a better
overall ease-of-use rating for Vroom! than TextSearch on the limited sound
library in our experiments. These findings suggest advantages of
vocal-imitation-based search for sound in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08689</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08689</id><created>2019-07-19</created><updated>2019-07-23</updated><authors><author><keyname>Badakhsh</keyname><forenames>Hamed</forenames></author><author><keyname>Pirhooshyaran</keyname><forenames>Mohammad</forenames></author><author><keyname>Eshragh-Jahromi</keyname><forenames>Abdolhamid</forenames></author></authors><title>Replacement Policy of Systems with Dependent Components via Integration
  of Dynamic Programming and Simulated Annealing</title><categories>eess.SY cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a dependent multi-component system, increasing the deterioration of a part
leads to the increased deterioration rate of other parts as well. In these
systems, a deterioration limit is usually pre-determined for each part and the
considered part is replaced while reaching this limit. In this paper,
replacement conditions of these parts were examined according to the
replacement times in the past. Using dynamic programming, for every
deterioration rate of part 1, there is a deterioration limit for part 2, after
which either part 2 or both parts should be replaced. The only available system
data are the replacement time of the parts in the past according to the
replacement policy at the time of reaching deterioration limit. Therefore,
simulated annealing optimization method was used for estimating deterioration
rates. Finally, two examples were presented for comparing the proposed method
with the special limit replacement method, which showed the significance
superiority of the former.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08697</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08697</id><created>2019-07-18</created><updated>2019-10-23</updated><authors><author><keyname>Rusu</keyname><forenames>Cristian</forenames></author><author><keyname>Rosasco</keyname><forenames>Lorenzo</forenames></author></authors><title>Fast approximation of orthogonal matrices and application to PCA</title><categories>math.NA cs.LG cs.NA eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of approximating orthogonal matrices so that their
application is numerically fast and yet accurate. We find an approximation by
solving an optimization problem over a set of structured matrices, that we call
extended orthogonal Givens transformations, including Givens rotations as a
special case. We propose an efficient greedy algorithm to solve such a problem
and show that it strikes a balance between approximation accuracy and speed of
computation. The approach is relevant to spectral methods and we illustrate its
application to PCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08698</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08698</id><created>2019-07-18</created><updated>2019-07-27</updated><authors><author><keyname>Epure</keyname><forenames>Elena V.</forenames></author><author><keyname>Khlif</keyname><forenames>Anis</forenames></author><author><keyname>Hennequin</keyname><forenames>Romain</forenames></author></authors><title>Leveraging Knowledge Bases And Parallel Annotations For Music Genre
  Translation</title><categories>cs.SD cs.IR cs.LG eess.AS stat.ML</categories><comments>Published in ISMIR 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Prevalent efforts have been put in automatically inferring genres of musical
items. Yet, the propose solutions often rely on simplifications and fail to
address the diversity and subjectivity of music genres. Accounting for these
has, though, many benefits for aligning knowledge sources, integrating data and
enriching musical items with tags. Here, we choose a new angle for the genre
study by seeking to predict what would be the genres of musical items in a
target tag system, knowing the genres assigned to them within source tag
systems. We call this a translation task and identify three cases: 1) no common
annotated corpus between source and target tag systems exists, 2) such a large
corpus exists, 3) only few common annotations exist. We propose the related
solutions: a knowledge-based translation modeled as taxonomy mapping, a
statistical translation modeled with maximum likelihood logistic regression; a
hybrid translation modeled with maximum a posteriori logistic regression with
priors given by the knowledge-based translation. During evaluation, the
solutions fit well the identified cases and the hybrid translation is
systematically the most effective w.r.t. multilabel classification metrics.
This is a first attempt to unify genre tag systems by leveraging both
representation and interpretation diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08705</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08705</id><created>2019-07-19</created><updated>2020-01-15</updated><authors><author><keyname>Mehdizavareh</keyname><forenames>Mohammad Hadi</forenames></author><author><keyname>Hemati</keyname><forenames>Sobhan</forenames></author><author><keyname>Soltanian-Zadeh</keyname><forenames>Hamid</forenames></author></authors><title>Enhancing performance of subject-specific models via subject-independent
  information for SSVEP-based BCIs</title><categories>q-bio.NC cs.HC eess.SP</categories><comments>22 pages, 8 figures, 1 table, 1 appendix, published in PLOS ONE
  journal. This is a draft version. The published version is available in the
  following link:
  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0226048</comments><journal-ref>PLOS ONE 15(1): e0226048 (2020)</journal-ref><doi>10.1371/journal.pone.0226048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, brain-computer interface (BCI) systems developed based on
steady-state visual evoked potential (SSVEP) have attracted much attention due
to their high information transfer rate (ITR) and increasing number of targets.
However, SSVEP-based methods can be improved in terms of their accuracy and
target detection time. We propose a new method based on canonical correlation
analysis (CCA) to integrate subject-specific models and subject-independent
information and enhance BCI performance. We propose to use training data of
other subjects to optimize hyperparameters for CCA-based model of a specific
subject. An ensemble version of the proposed method is also developed for a
fair comparison with ensemble task-related component analysis (TRCA). The
proposed method is compared with TRCA and extended CCA methods. A publicly
available, 35-subject SSVEP benchmark dataset is used for comparison studies
and performance is quantified by classification accuracy and ITR. The ITR of
the proposed method is higher than those of TRCA and extended CCA. The proposed
method outperforms extended CCA in all conditions and TRCA for time windows
greater than 0.3 s. The proposed method also outperforms TRCA when there are
limited training blocks and electrodes. This study illustrates that adding
subject-independent information to subject-specific models can improve
performance of SSVEP-based BCIs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08707</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08707</id><created>2019-07-19</created><authors><author><keyname>Sun</keyname><forenames>Liting</forenames></author><author><keyname>Zhan</keyname><forenames>Wei</forenames></author><author><keyname>Hu</keyname><forenames>Yeping</forenames></author><author><keyname>Tomizuka</keyname><forenames>Masayoshi</forenames></author></authors><title>Interpretable Modelling of Driving Behaviors in Interactive Driving
  Scenarios based on Cumulative Prospect Theory</title><categories>cs.AI cs.RO cs.SY eess.SY</categories><comments>accepted to the 2019 IEEE Intelligent Transportation System
  Conference (ITSC2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding human driving behavior is important for autonomous vehicles. In
this paper, we propose an interpretable human behavior model in interactive
driving scenarios based on the cumulative prospect theory (CPT). As a
non-expected utility theory, CPT can well explain some systematically biased or
``irrational'' behavior/decisions of human that cannot be explained by the
expected utility theory. Hence, the goal of this work is to formulate the human
drivers' behavior generation model with CPT so that some ``irrational''
behavior or decisions of human can be better captured and predicted. Towards
such a goal, we first develop a CPT-driven decision-making model focusing on
driving scenarios with two interacting agents. A hierarchical learning
algorithm is proposed afterward to learn the utility function, the value
function, and the decision weighting function in the CPT model. A case study
for roundabout merging is also provided as verification. With real driving
data, the prediction performances of three different models are compared: a
predefined model based on time-to-collision (TTC), a learning-based model based
on neural networks, and the proposed CPT-based model. The results show that the
proposed model outperforms the TTC model and achieves similar performance as
the learning-based model with much less training data and better
interpretability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08720</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08720</id><created>2019-07-19</created><authors><author><keyname>Baranwal</keyname><forenames>Mayank</forenames></author><author><keyname>Srivastava</keyname><forenames>Amber</forenames></author><author><keyname>Salapaka</keyname><forenames>Srinivasa</forenames></author></authors><title>Multiway k-Cut in Static and Dynamic Graphs: A Maximum Entropy Principle
  Approach</title><categories>math.OC cs.SY eess.SY</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a maximum entropy principle based algorithm for solving
minimum multiway $k$-cut problem defined over static and dynamic {\em
digraphs}. A multiway $k$-cut problem requires partitioning the set of nodes in
a graph into $k$ subsets, such that each subset contains one prespecified node,
and the corresponding total cut weight is minimized. These problems arise in
many applications and are computationally complex (NP-hard). In the static
setting this article presents an approach that uses a relaxed multiway $k$-cut
cost function; we show that the resulting algorithm converges to a local
minimum. This iterative algorithm is designed to avoid poor local minima with
its run-time complexity as $\sim O(kIN^3)$, where $N$ is the number of vertices
and $I$ is the number of iterations. In the dynamic setting, the edge-weight
matrix has an associated dynamics with some of the edges in the graph capable
of being influenced by an external input. The objective is to design the
dynamics of the controllable edges so that multiway $k$-cut value remains small
(or decreases) as the graph evolves under the dynamics. Also it is required to
determine the time-varying partition that defines the minimum multiway $k$-cut
value. Our approach is to choose a relaxation of multiway $k$-cut value,
derived using maximum entropy principle, and treat it as a control Lyapunov
function to design control laws that affect the weight dynamics. Simulations on
practical examples of interactive foreground-background segmentation, minimum
multiway $k$-cut optimization for non-planar graphs and dynamically evolving
graphs that demonstrate the efficacy of the algorithm, are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08747</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08747</id><created>2019-07-19</created><authors><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Zhong</keyname><forenames>Yi</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chao</keyname><forenames>Han-Chieh</forenames></author></authors><title>Power-Consumption Outage Challenge in Next-Generation Cellular Networks</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conventional outage in wireless communication systems is caused by the
deterioration of the wireless communication link, i.e., the received signal
power is less than the minimum received signal power. Is there a possibility
that the outage occurs in wireless communication systems with a good channel
state? Based on both communication and heat transfer theories, a
power-consumption outage in the wireless communication between millimeter wave
(mmWave) massive multiple-input multiple-output (MIMO) base stations (BSs) and
smartphones has been modeled and analyzed. Moreover, the total transmission
time model with respect to the number of power-consumption outages is derived
for mmWave massive MIMO communication systems. Simulation results indicate that
the total transmission time is extended by the power-consumption outage, which
deteriorates the average transmission rate of mmWave massive MIMO BSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08750</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08750</id><created>2019-07-20</created><updated>2019-11-10</updated><authors><author><keyname>Ribeiro</keyname><forenames>Lucas N.</forenames></author><author><keyname>Schwarz</keyname><forenames>Stefan</forenames></author><author><keyname>de Almeida</keyname><forenames>Andr&#xe9; L. F.</forenames></author></authors><title>Double-Sided Massive MIMO Transceivers for MmWave Communications</title><categories>eess.SP</categories><journal-ref>IEEE Access, Issue Date: December 2019, Volume: 7, Issue:1, Pages
  157667-157679</journal-ref><doi>10.1109/ACCESS.2019.2949945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose practical transceiver structures for double-sided massive
multiple-input-multiple-output (MIMO) systems. Unlike standard massive MIMO,
both transmit and receive sides are equipped with high-dimensional antenna
arrays. We leverage the multi-layer filtering architecture and propose novel
layered transceiver schemes with practical channel state information
requirements to simplify the complexity of our double-sided massive MIMO
system. We conduct a comprehensive simulation campaign to investigate the
performance of the proposed transceivers under different channel propagation
conditions and to identify the most suitable strategy. Our results show that
the covariance matrix eigenfilter design at the outer transceiver layer
combined with maximum eigenmode transmission precoding/minimum mean square
error combining at the inner transceiver layer yields the best achievable sum
rate performance for different propagation conditions and multi-user
interference levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08753</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08753</id><created>2019-07-20</created><authors><author><keyname>Chung</keyname><forenames>Hyeonjin</forenames></author><author><keyname>Kim</keyname><forenames>Sunwoo</forenames></author></authors><title>Adaptive Beamwidth Control for mmWave Beam Tracking</title><categories>eess.SP</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional beam tracking methods have severe performance loss under the high
mobility and narrow beam scenario. To alleviate the tracking performance
degradation, we propose an adaptive beamwidth control for millimeter wave
(mmWave) beam tracking. The particle filter is applied to the beam tracking,
and the AoA estimation error is approximated with a posterior density function
constructed by the particles. The error approximation leads to the adaptive
beamwidth control which is implemented by the partial activation of the antenna
array. Simulation results show that the proposed algorithm aids the beam
tracking to yield a smaller AoA estimation error under the high mobility
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08756</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08756</id><created>2019-07-20</created><authors><author><keyname>Wu</keyname><forenames>Xiongwei</forenames></author><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author><author><keyname>Ching</keyname><forenames>P. C.</forenames></author></authors><title>Joint Fronthaul Multicast and Cooperative Beamforming for Cache-Enabled
  Cloud-Based Small Cell Networks: An MDS Codes-Aided Approach</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear in IEEE Trans. Wireless Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of cloud-based small cell networks (C-SCNs) relies highly on
a capacity-limited fronthaul, which degrade quality of service when it is
saturated. Coded caching is a promising approach to addressing these
challenges, as it provides abundant opportunities for fronthaul multicast and
cooperative transmissions. This paper investigates a cache-enabled C-SCNs, in
which small-cell base stations (SBSs) are connected to the central processor
via fronthaul, and can prefetch popular contents by applying maximum distance
separable (MDS) codes. To fully capture the benefits of fronthaul multicast and
cooperative transmissions, an MDS codes-aided transmission scheme is first
proposed. We formulate the problem to minimize the content delivery latency by
jointly optimizing fronthaul bandwidth allocation, SBS clustering, and
beamforming. To efficiently solve the resulting nonlinear integer programming
problem, we propose a penalty-based design by leveraging variational
reformulations of binary constraints. To improve the solution of the
penalty-based design, a greedy SBS clustering design is also developed.
Furthermore, closed-form characterization of the optimal solution is obtained,
through which the benefits of MDS codes can be quantified. Simulation results
are given to demonstrate the significant benefits of the proposed MDS
codes-aided transmission scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08759</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08759</id><created>2019-07-20</created><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Lei</keyname><forenames>Jin</forenames></author><author><keyname>Lin</keyname><forenames>Jingran</forenames></author><author><keyname>Wu</keyname><forenames>Xiaoxiao</forenames></author></authors><title>Latency Minimization for Multiuser Computation Offloading in Fog-Radio
  Access Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers computation offloading in fog-radio access networks
(F-RAN), where multiple user equipments (UEs) offload their computation tasks
to the F-RAN through a number of fog nodes. Each UE can choose one of the fog
nodes to offload its task, and each fog node may simultaneously serve multiple
UEs. Depending on the computation burden at the fog nodes, the tasks may be
computed by the fog nodes or further offloaded to the cloud via
capacity-limited fronthaul links. To compute all UEs tasks as fast as possible,
joint optimization of UE-Fog association, radio and computation resources of
F-RAN is proposed to minimize the maximum latency of all UEs. This min-max
problem is formulated as a mixed integer nonlinear program (MINP). We first
show that the MINP can be reformulated as a continuous optimization problem,
and then employ the majorization minimization (MM) approach to finding a
solution for it. The MM approach that we develop herein is unconventional in
that---each MM subproblem is inexactly solved with the same provable
convergence guarantee as the conventional exact MM. In addition, we also
consider a cooperative offloading model, where the fog nodes
compress-and-forward their received signals to the cloud. Under this model, a
similar min-max latency optimization problem is formulated and tackled again by
the inexact MM approach. Simulation results show that the proposed algorithms
outperform some heuristic offloading strategies, and that the cooperative
offloading is generally better than the non-cooperative one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08769</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08769</id><created>2019-07-20</created><authors><author><keyname>Zhu</keyname><forenames>Lin</forenames></author><author><keyname>Dong</keyname><forenames>Siwei</forenames></author><author><keyname>Huang</keyname><forenames>Tiejun</forenames></author><author><keyname>Tian</keyname><forenames>Yonghong</forenames></author></authors><title>A Retina-inspired Sampling Method for Visual Texture Reconstruction</title><categories>eess.IV cs.CV cs.MM</categories><comments>Published in ICME 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional frame-based camera is not able to meet the demand of rapid
reaction for real-time applications, while the emerging dynamic vision sensor
(DVS) can realize high speed capturing for moving objects. However, to achieve
visual texture reconstruction, DVS need extra information apart from the output
spikes. This paper introduces a fovea-like sampling method inspired by the
neuron signal processing in retina, which aims at visual texture reconstruction
only taking advantage of the properties of spikes. In the proposed method, the
pixels independently respond to the luminance changes with temporal
asynchronous spikes. Analyzing the arrivals of spikes makes it possible to
restore the luminance information, enabling reconstructing the natural scene
for visualization. Three decoding methods of spike stream for texture
reconstruction are proposed for high-speed motion and stationary scenes.
Compared to conventional frame-based camera and DVS, our model can achieve
better image quality and higher flexibility, which is capable of changing the
way that demanding machine vision applications are built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08778</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08778</id><created>2019-07-20</created><authors><author><keyname>Zhou</keyname><forenames>Meiling</forenames></author><author><keyname>Pan</keyname><forenames>An</forenames></author><author><keyname>Li</keyname><forenames>Runze</forenames></author><author><keyname>Liang</keyname><forenames>Yansheng</forenames></author><author><keyname>Min</keyname><forenames>Junwei</forenames></author><author><keyname>Peng</keyname><forenames>Tong</forenames></author><author><keyname>Bai</keyname><forenames>Chen</forenames></author><author><keyname>Yao</keyname><forenames>Baoli</forenames></author></authors><title>Retrieval of non-sparse object through scattering media beyond the
  memory effect</title><categories>eess.IV physics.comp-ph physics.optics</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical imaging through scattering media is a commonly confronted with the
problem of reconstruction of complex objects and optical memory effect. To
solve the problem, here, we propose a novel configuration based on the
combination of ptychography and shower-curtain effect, which enables the
retrieval of non-sparse samples through scattering media beyond the memory
effect. Furthermore, by virtue of the shower-curtain effect, the proposed
imaging system is insensitive to dynamic scattering media. Results from the
retrieval of hair follicle section demonstrate the effectiveness and
feasibility of the proposed method. The field of view is improved to 2.64mm.
This present technique will be a potential approach for imaging through deep
biological tissue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08790</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08790</id><created>2019-07-20</created><authors><author><keyname>Kautsk&#xfd;</keyname><forenames>V&#xe1;clav</forenames></author><author><keyname>Koldovsk&#xfd;</keyname><forenames>Zbyn&#x11b;k</forenames></author><author><keyname>Tichavsk&#xfd;</keyname><forenames>Petr</forenames></author><author><keyname>Zarzoso</keyname><forenames>Vicente</forenames></author></authors><title>Cram\'er-Rao Bounds for Complex-Valued Independent Component Extraction:
  Determined and Piecewise Determined Mixing Models</title><categories>math.ST eess.SP stat.TH</categories><comments>25 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents Cram\'er-Rao Lower Bound (CRLB) for the complex-valued
Blind Source Extraction (BSE) problem based on the assumption that the target
signal is independent of the other signals. Two instantaneous mixing models are
considered. First, we consider the standard determined mixing model used in
Independent Component Analysis (ICA) where the mixing matrix is square and
non-singular and the number of the latent sources is the same as that of the
observed signals. The CRLB for Independent Component Extraction (ICE) where the
mixing matrix is re-parameterized in order to extract only one independent
target source is computed. The target source is assumed to be non-Gaussian or
non-circular Gaussian while the other signals (background) are circular
Gaussian or non-Gaussian. The results confirm some previous observations known
for the real domain and bring new results for the complex domain. Also, the
CRLB for ICE is shown to coincide with that for ICA when the non-Gaussianity of
background is taken into account. %unless the assumed sources' distributions
are misspecified. Second, we extend the CRLB analysis to piecewise determined
mixing models. Here, the observed signals are assumed to obey the determined
mixing model within short blocks where the mixing matrices can be varying from
block to block. However, either the mixing vector or the separating vector
corresponding to the target source is assumed to be constant across the blocks.
The CRLBs for the parameters of these models bring new performance bounds for
the BSE problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08809</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08809</id><created>2019-07-20</created><authors><author><keyname>Yu</keyname><forenames>Jiabao</forenames></author><author><keyname>Hu</keyname><forenames>Aiqun</forenames></author><author><keyname>Zhou</keyname><forenames>Fen</forenames></author><author><keyname>Xing</keyname><forenames>Yuexiu</forenames></author><author><keyname>Yu</keyname><forenames>Yi</forenames></author><author><keyname>Li</keyname><forenames>Guyue</forenames></author><author><keyname>Peng</keyname><forenames>Linning</forenames></author></authors><title>Radio Frequency Fingerprint Identification Based on Denoising
  Autoencoders</title><categories>eess.SP cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio Frequency Fingerprinting (RFF) is one of the promising passive
authentication approaches for improving the security of the Internet of Things
(IoT). However, with the proliferation of low-power IoT devices, it becomes
imperative to improve the identification accuracy at low SNR scenarios. To
address this problem, this paper proposes a general Denoising AutoEncoder
(DAE)-based model for deep learning RFF techniques. Besides, a partially
stacking method is designed to appropriately combine the semi-steady and
steady-state RFFs of ZigBee devices. The proposed Partially Stacking-based
Convolutional DAE (PSC-DAE) aims at reconstructing a high-SNR signal as well as
device identification. Experimental results demonstrate that compared to
Convolutional Neural Network (CNN), PSCDAE can improve the identification
accuracy by 14% to 23.5% at low SNRs (from -10 dB to 5 dB) under Additive White
Gaussian Noise (AWGN) corrupted channels. Even at SNR = 10 dB, the
identification accuracy is as high as 97.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08821</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08821</id><created>2019-07-20</created><authors><author><keyname>Abbasi</keyname><forenames>M. Ali Babar</forenames></author><author><keyname>Fusco</keyname><forenames>Vincent F.</forenames></author></authors><title>Hardware Constraints in Compressive Sensing Based Antenna Array</title><categories>eess.SP physics.app-ph</categories><comments>3 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New constraints based on practical hardware are introduced in compressive
sensing (CS) based rectangular antenna array thinning technique. In a standard
CS array sparsity enforcement, antenna elements are considered as ideal point
sources which do not comply with the practical hardware. It also does not
consider the impact of mutual coupling of neighbouring antenna elements on the
impedance mismatch. In this work, we propose a combination of constraints based
on physical antenna array specifications, mutual coupling and practical antenna
element radiation performance in the CS-based array thinning enforcement.
Analytical modelling along with a design example is presented and discussed.
Array performance based on full-wave electromagnetic simulations shows the
reliability of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08823</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08823</id><created>2019-07-20</created><authors><author><keyname>Xiao</keyname><forenames>Baicen</forenames></author><author><keyname>Ramasubramanian</keyname><forenames>Bhaskar</forenames></author><author><keyname>Clark</keyname><forenames>Andrew</forenames></author><author><keyname>Hajishirzi</keyname><forenames>Hannaneh</forenames></author><author><keyname>Bushnell</keyname><forenames>Linda</forenames></author><author><keyname>Poovendran</keyname><forenames>Radha</forenames></author></authors><title>Potential-Based Advice for Stochastic Policy Learning</title><categories>cs.LG cs.AI cs.SY eess.SY stat.ML</categories><comments>Accepted to the IEEE Conference on Decision and Control, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper augments the reward received by a reinforcement learning agent
with potential functions in order to help the agent learn (possibly stochastic)
optimal policies. We show that a potential-based reward shaping scheme is able
to preserve optimality of stochastic policies, and demonstrate that the ability
of an agent to learn an optimal policy is not affected when this scheme is
augmented to soft Q-learning. We propose a method to impart potential based
advice schemes to policy gradient algorithms. An algorithm that considers an
advantage actor-critic architecture augmented with this scheme is proposed, and
we give guarantees on its convergence. Finally, we evaluate our approach on a
puddle-jump grid world with indistinguishable states, and the continuous state
and action mountain car environment from classical control. Our results
indicate that these schemes allow the agent to learn a stochastic optimal
policy faster and obtain a higher average reward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08831</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08831</id><created>2019-07-20</created><updated>2019-09-11</updated><authors><author><keyname>Ernst</keyname><forenames>Markus Roland</forenames></author><author><keyname>Triesch</keyname><forenames>Jochen</forenames></author><author><keyname>Burwick</keyname><forenames>Thomas</forenames></author></authors><title>Recurrent Connections Aid Occluded Object Recognition by Discounting
  Occluders</title><categories>cs.CV cs.LG eess.IV</categories><comments>13 pages, 5 figures, accepted at the 28th International Conference on
  Artificial Neural Networks, published in Springer Lecture Notes in Computer
  Science vol 11729</comments><journal-ref>In: Tetko, I. V. et al. (eds.) ICANN 2019. LNCS, vol 11729.
  Springer, Cham, pp 294-305</journal-ref><doi>10.1007/978-3-030-30508-6_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent connections in the visual cortex are thought to aid object
recognition when part of the stimulus is occluded. Here we investigate if and
how recurrent connections in artificial neural networks similarly aid object
recognition. We systematically test and compare architectures comprised of
bottom-up (B), lateral (L) and top-down (T) connections. Performance is
evaluated on a novel stereoscopic occluded object recognition dataset. The task
consists of recognizing one target digit occluded by multiple occluder digits
in a pseudo-3D environment. We find that recurrent models perform significantly
better than their feedforward counterparts, which were matched in parametric
complexity. Furthermore, we analyze how the network's representation of the
stimuli evolves over time due to recurrent connections. We show that the
recurrent connections tend to move the network's representation of an occluded
digit towards its un-occluded version. Our results suggest that both the brain
and artificial neural networks can exploit recurrent connectivity to aid
occluded object recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08859</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08859</id><created>2019-07-20</created><authors><author><keyname>Aky&#xfc;z</keyname><forenames>Erdi</forenames></author><author><keyname>Saikumar</keyname><forenames>Niranjan</forenames></author><author><keyname>HosseinNia</keyname><forenames>S. Hassan</forenames></author></authors><title>Reset Control for Vibration Disturbance Rejection</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high tech industry which requires fast stable motion with nanometer
precision continues to mainly use PID which is limited by fundamental linear
control limitations. Floor vibrations as disturbance significantly affect
performance and their rejection is particularly affected by these limitations.
Reset control has provided a promising alternative to surpass these, while
simultaneously allowing the use of industry standard loop-shaping during
design. However, the reset action introduced higher order harmonics can induce
unwanted dynamics and negatively influence performance. This paper investigates
two reset control strategies namely (1) band-pass phase lag reduction and (2)
phase compensation to reduce the negative effects of higher order harmonics.
The strategies are tested on a precision positioning stage for vibration
rejection and the results show that phase compensation provides better
performance compared to other tested strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08895</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08895</id><created>2019-07-20</created><authors><author><keyname>Hou</keyname><forenames>Rui</forenames></author><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Sukthankar</keyname><forenames>Rahul</forenames></author><author><keyname>Shah</keyname><forenames>Mubarak</forenames></author></authors><title>An Efficient 3D CNN for Action/Object Segmentation in Video</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Network (CNN) based image segmentation has made great
progress in recent years. However, video object segmentation remains a
challenging task due to its high computational complexity. Most of the previous
methods employ a two-stream CNN framework to handle spatial and motion features
separately. In this paper, we propose an end-to-end encoder-decoder style 3D
CNN to aggregate spatial and temporal information simultaneously for video
object segmentation. To efficiently process video, we propose 3D separable
convolution for the pyramid pooling module and decoder, which dramatically
reduces the number of operations while maintaining the performance. Moreover,
we also extend our framework to video action segmentation by adding an extra
classifier to predict the action label for actors in videos. Extensive
experiments on several video datasets demonstrate the superior performance of
the proposed approach for action and object segmentation compared to the
state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08915</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08915</id><created>2019-07-21</created><updated>2019-12-09</updated><authors><author><keyname>Hiasa</keyname><forenames>Yuta</forenames></author><author><keyname>Otake</keyname><forenames>Yoshito</forenames></author><author><keyname>Takao</keyname><forenames>Masaki</forenames></author><author><keyname>Ogawa</keyname><forenames>Takeshi</forenames></author><author><keyname>Sugano</keyname><forenames>Nobuhiko</forenames></author><author><keyname>Sato</keyname><forenames>Yoshinobu</forenames></author></authors><title>Automated Muscle Segmentation from Clinical CT using Bayesian U-Net for
  Personalized Musculoskeletal Modeling</title><categories>eess.IV cs.CV</categories><comments>11 pages, 10 figures, and supplementary materials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for automatic segmentation of individual muscles from a
clinical CT. The method uses Bayesian convolutional neural networks with the
U-Net architecture, using Monte Carlo dropout that infers an uncertainty metric
in addition to the segmentation label. We evaluated the performance of the
proposed method using two data sets: 20 fully annotated CTs of the hip and
thigh regions and 18 partially annotated CTs that are publicly available from
The Cancer Imaging Archive (TCIA) database. The experiments showed a Dice
coefficient (DC) of 0.891 +/- 0.016 (mean +/- std) and an average symmetric
surface distance (ASD) of 0.994 +/- 0.230 mm over 19 muscles in the set of 20
CTs. These results were statistically significant improvements compared to the
state-of-the-art hierarchical multi-atlas method which resulted in 0.845 +/-
0.031 DC and 1.556 +/- 0.444 mm ASD. We evaluated validity of the uncertainty
metric in the multi-class organ segmentation problem and demonstrated a
correlation between the pixels with high uncertainty and the segmentation
failure. One application of the uncertainty metric in active-learning is
demonstrated, and the proposed query pixel selection method considerably
reduced the manual annotation cost for expanding the training data set. The
proposed method allows an accurate patient-specific analysis of individual
muscle shapes in a clinical routine. This would open up various applications
including personalization of biomechanical simulation and quantitative
evaluation of muscle atrophy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08921</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08921</id><created>2019-07-21</created><updated>2019-07-29</updated><authors><author><keyname>Bu</keyname><forenames>Jingjing</forenames></author><author><keyname>Mesbahi</keyname><forenames>Afshin</forenames></author><author><keyname>Fazel</keyname><forenames>Maryam</forenames></author><author><keyname>Mesbahi</keyname><forenames>Mehran</forenames></author></authors><title>LQR through the Lens of First Order Methods: Discrete-time Case</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Linear-Quadratic-Regulator (LQR) problem in terms of
optimizing a real-valued matrix function over the set of feedback gains. Such a
setup facilitates examining the implications of a natural initial-state
independent formulation of LQR in designing first order algorithms. It is shown
that this cost function is smooth and coercive, and provide an alternate means
of noting its gradient dominated property. In the process, we provide a number
of analytic observations on the LQR cost when directly analyzed in terms of the
feedback gain. We then examine three types of well-posed flows for LQR:
gradient flow, natural gradient flow and the quasi-Newton flow. The coercive
property suggests that these flows admit unique solutions while gradient
dominated property indicates that the corresponding Lyapunov functionals decay
at an exponential rate; we also prove that these flows are exponentially stable
in the sense of Lyapunov. We then discuss the forward Euler discretization of
these flows, realized as gradient descent, natural gradient descent and the
quasi-Newton iteration. We present stepsize criteria for gradient descent and
natural gradient descent, guaranteeing that both algorithms converge linearly
to the global optima. An optimal stepsize for the quasi-Newton iteration is
also proposed, guaranteeing a $Q$-quadratic convergence rate--and in the
meantime--recovering the Hewer algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08924</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08924</id><created>2019-07-21</created><authors><author><keyname>Fry</keyname><forenames>Edward W. S.</forenames></author><author><keyname>Triantaphillidou</keyname><forenames>Sophie</forenames></author><author><keyname>Jenkin</keyname><forenames>Robin B.</forenames></author><author><keyname>Jarvis</keyname><forenames>John R.</forenames></author><author><keyname>Jacobson</keyname><forenames>Ralph E.</forenames></author></authors><title>Validation of Modulation Transfer Functions and Noise Power Spectra from
  Natural Scenes</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Modulation Transfer Function (MTF) and the Noise Power Spectrum (NPS)
characterize imaging system sharpness/resolution and noise, respectively. Both
measures are based on linear system theory but are applied routinely to systems
employing non-linear, content-aware image processing. For such systems,
MTFs/NPSs are derived inaccurately from traditional test charts containing
edges, sinusoids, noise or uniform tone signals, which are unrepresentative of
natural scene signals. The dead leaves test chart delivers improved
measurements, but still has limitations when describing the performance of
scene-dependent systems. In this paper, we validate several novel
scene-and-process-dependent MTF (SPD-MTF) and NPS (SPD-NPS) measures that
characterize, either: i) system performance concerning one scene, or ii)
average real-world performance concerning many scenes, or iii) the level of
system scene-dependency. We also derive novel SPD-NPS and SPD-MTF measures
using the dead leaves chart. We demonstrate that all the proposed measures are
robust and preferable for scene-dependent systems than current measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08926</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08926</id><created>2019-07-21</created><authors><author><keyname>Fry</keyname><forenames>Edward W. S.</forenames></author><author><keyname>Triantaphillidou</keyname><forenames>Sophie</forenames></author><author><keyname>Jenkin</keyname><forenames>Robin B.</forenames></author><author><keyname>Jacobson</keyname><forenames>Ralph E.</forenames></author><author><keyname>Jarvis</keyname><forenames>John R.</forenames></author></authors><title>Scene-and-Process-Dependent Spatial Image Quality Metrics</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial image quality metrics designed for camera systems generally employ
the Modulation Transfer Function (MTF), the Noise Power Spectrum (NPS), and a
visual contrast detection model. Prior art indicates that scene-dependent
characteristics of non-linear, content-aware image processing are unaccounted
for by MTFs and NPSs measured using traditional methods. We present two novel
metrics: the log Noise Equivalent Quanta (log NEQ) and Visual log NEQ. They
both employ scene-and-process-dependent MTF (SPD-MTF) and NPS (SPD-NPS)
measures, which account for signal-transfer and noise scene-dependency,
respectively. We also investigate implementing contrast detection and
discrimination models that account for scene-dependent visual masking. Also,
three leading camera metrics are revised that use the above scene-dependent
measures. All metrics are validated by examining correlations with the
perceived quality of images produced by simulated camera pipelines. Metric
accuracy improved consistently when the SPD-MTFs and SPD-NPSs were implemented.
The novel metrics outperformed existing metrics of the same genre.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08940</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08940</id><created>2019-07-21</created><authors><author><keyname>Wu</keyname><forenames>Yi-Chiao</forenames></author><author><keyname>Tobing</keyname><forenames>Patrick Lumban</forenames></author><author><keyname>Hayashi</keyname><forenames>Tomoki</forenames></author><author><keyname>Kobayashi</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author></authors><title>Statistical Voice Conversion with Quasi-Periodic WaveNet Vocoder</title><categories>eess.AS cs.SD</categories><comments>6pages, 7figures, Proc. SSW10, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the effectiveness of a quasi-periodic WaveNet
(QPNet) vocoder combined with a statistical spectral conversion technique for a
voice conversion task. The WaveNet (WN) vocoder has been applied as the
waveform generation module in many different voice conversion frameworks and
achieves significant improvement over conventional vocoders. However, because
of the fixed dilated convolution and generic network architecture, the WN
vocoder lacks robustness against unseen input features and often requires a
huge network size to achieve acceptable speech quality. Such limitations
usually lead to performance degradation in the voice conversion task. To
overcome this problem, the QPNet vocoder is applied, which includes a
pitch-dependent dilated convolution component to enhance the pitch
controllability and attain a more compact network than the WN vocoder. In the
proposed method, input spectral features are first converted using a framewise
deep neural network, and then the QPNet vocoder generates converted speech
conditioned on the linearly converted prosodic and transformed spectral
features. The experimental results confirm that the QPNet vocoder achieves
significantly better performance than the same-size WN vocoder while
maintaining comparable speech quality to the double-size WN vocoder. Index
Terms: WaveNet, vocoder, voice conversion, pitch-dependent dilated convolution,
pitch controllability
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08941</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08941</id><created>2019-07-21</created><authors><author><keyname>Shi</keyname><forenames>Xin</forenames></author></authors><title>Short-term Electric Load Forecasting Using TensorFlow and Deep
  Auto-Encoders</title><categories>eess.SP cs.SY eess.SY</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper conducts research on the short-term electric load forecast method
under the background of big data. It builds a new electric load forecast model
based on Deep Auto-Encoder Networks (DAENs), which takes into account
multidimensional load-related data sets including historical load value,
temperature, day type, etc. A new distributed short-term load forecast method
based on TensorFlow and DAENs is therefore proposed, with an algorithm
flowchart designed. This method overcomes the shortcomings of traditional
neural network methods, such as over-fitting, slow convergence and local
optimum, etc. Case study results show that the proposed method has obvious
advantages in prediction accuracy, stability, and expansibility compared with
those based on traditional neural networks. Thus, this model can better meet
the demands of short-term electric load forecasting under big data scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08951</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08951</id><created>2019-07-21</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Jing</forenames></author><author><keyname>Chen</keyname><forenames>Liang</forenames></author><author><keyname>Qi</keyname><forenames>Junjian</forenames></author><author><keyname>Li</keyname><forenames>Guoqing</forenames></author></authors><title>Dynamic State Estimation of Synchronous Machines Using Robust Cubature
  Kalman Filter Against Complex Measurement Noise Statistics</title><categories>eess.SY cs.SY eess.SP</categories><comments>Accepted by Transactions of China Electrotechnical Society, in
  Chinese</comments><journal-ref>Transactions of China Electrotechnical Society 34 (2019) 3651-3660</journal-ref><doi>10.19595/j.cnki.1000-6753.tces.181150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cubature Kalman Filter (CKF) has good performance when handling nonlinear
dynamic state estimations. However, it cannot work well in non-Gaussian noise
and bad data environment due to the lack of auto-adaptive ability to measure
noise statistics on line. In order to address the problem of behavioral decline
and divergence when measure noise statistics deviate prior noise statistics, a
new robust CKF (RCKF) algorithm is developed by combining the Huber's
M-estimation theory with the classical CKF, and thereby it is proposed to
coping with the dynamic state estimation of synchronous generators in this
study. The simulation results on the IEEE-9 bus system and New England
16-machine-68-bus system demonstrate that the estimation accuracy and
convergence of the proposed RCKF are superior to those of the classical CKF
under complex measurement noise environments including different measurement
noises and bad data, and that the RCKF is capable of effectively eliminating
the impact of bad data on the estimation effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08952</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08952</id><created>2019-07-21</created><authors><author><keyname>Tseng</keyname><forenames>Tzu-Wei</forenames><affiliation>Lawrence</affiliation></author><author><keyname>Yang</keyname><forenames>Kai-Jiun</forenames><affiliation>Lawrence</affiliation></author><author><keyname>Kuo</keyname><forenames>C. -C. Jay</forenames><affiliation>Lawrence</affiliation></author><author><keyname>Shang-Ho</keyname><affiliation>Lawrence</affiliation></author><author><keyname>Tsai</keyname></author></authors><title>An Interpretable Compression and Classification System: Theory and
  Applications</title><categories>cs.CV eess.SP</categories><comments>12 pages, 12 figures and 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a low-complexity interpretable classification system. The
proposed system contains three main modules including feature extraction,
feature reduction, and classification. All of them are linear. Thanks to the
linear property, the extracted and reduced features can be inversed to original
data, like a linear transform such as Fourier transform, so that one can
quantify and visualize the contribution of individual features towards the
original data. Also, the reduced features and reversibility naturally endure
the proposed system ability of data compression. This system can significantly
compress data with a small percent deviation between the compressed and the
original data. At the same time, when the compressed data is used for
classification, it still achieves high testing accuracy. Furthermore, we
observe that the extracted features of the proposed system can be approximated
to uncorrelated Gaussian random variables. Hence, classical theory in
estimation and detection can be applied for classification. This motivates us
to propose using a MAP (maximum a posteriori) based classification method. As a
result, the extracted features and the corresponding performance have
statistical meaning and mathematically interpretable. Simulation results show
that the proposed classification system not only enjoys significant reduced
training and testing time but also high testing accuracy compared to the
conventional schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08954</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08954</id><created>2019-07-21</created><authors><author><keyname>Baswade</keyname><forenames>Anand M.</forenames></author><author><keyname>Reddy</keyname><forenames>Mohith</forenames></author><author><keyname>A</keyname><forenames>Antony Franklin</forenames></author><author><keyname>Tamma</keyname><forenames>Bheemarjuna Reddy</forenames></author></authors><title>Modeling and Performance Analysis of Spatially Distributed LTE-U and
  Wi-Fi Networks</title><categories>cs.NI eess.SP</categories><comments>14 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To access an unlicensed channel Wi-Fi follows Listen Before Talk (LBT)
mechanism whereas LTE-U adopts ON-OFF duty cycled mechanism to fairly share the
channel with Wi-Fi. These contrasting mechanisms result in quite different
performance for Wi-Fi and LTE-U based on their relative deployment and density
in the environment. In this work, we present an analytical model for
characterization of achievable throughputs of Wi-Fi and LTE-U networks in
spatially distributed high-density scenarios. The proposed model is used to
study how LTE-U and Wi-Fi coexist with each other in different deployment
scenarios. Our extensive simulation results prove it to be a reliable model for
estimating throughput of both Wi-Fi and LTE-U. We record a very good accuracy
in throughput estimation and the mean normalized error is less than 1% for
40-node scenario in which 50% of nodes belong to each of Wi-Fi and LTE-U.
Finally, we use the analytical model to conduct coexistence studies of LTE-U
and Wi-Fi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08963</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08963</id><created>2019-07-21</created><authors><author><keyname>Zhou</keyname><forenames>Hongyi</forenames></author><author><keyname>Lv</keyname><forenames>Kefan</forenames></author><author><keyname>Huang</keyname><forenames>Longbo</forenames></author><author><keyname>Ma</keyname><forenames>Xiongfeng</forenames></author></authors><title>Security assessment and key management in a quantum network</title><categories>quant-ph cs.SY eess.SY</categories><comments>11 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum key distribution allows secure key distribution between remote
communication parties. In a quantum network, multiple users are connected by
quantum links for key distribution and classical links for encrypted data
transmission. When the quantum network structure becomes complicated with a
large number of users, it is important to investigate network issues, including
security, key management, latency, reliability, scalability, and cost. In this
work, we utilize the classical network theory and graph theory to establish a
framework for a quantum network, addressing two critical issues, security and
key management. First, we design a communication scheme with the highest
security level that trusts a minimum number of intermediate nodes. Second, when
the quantum key is a limited resource, we design key management and data
scheduling schemes to optimize the utility of data transmission. Our results
can be directly applied to the current metropolitan and free-space quantum
network implementations and can potentially be a standard approach for future
quantum network designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08965</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08965</id><created>2019-07-21</created><authors><author><keyname>Hussain</keyname><forenames>Fatima</forenames></author><author><keyname>Hassan</keyname><forenames>Syed Ali</forenames></author><author><keyname>Hussain</keyname><forenames>Rasheed</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>Machine Learning for Resource Management in Cellular and IoT Networks:
  Potentials, Current Solutions, and Open Challenges</title><categories>cs.NI eess.SP</categories><comments>21 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet-of-Things (IoT) refers to a massively heterogeneous network formed
through smart devices connected to the Internet. In the wake of disruptive IoT
with a huge amount and variety of data, Machine Learning (ML) and Deep Learning
(DL) mechanisms will play a pivotal role to bring intelligence to the IoT
networks. Among other aspects, ML and DL can play an essential role in
addressing the challenges of resource management in large-scale IoT networks.
In this article, we conduct a systematic and in-depth survey of the ML- and
DL-based resource management mechanisms in cellular wireless and IoT networks.
We start with the challenges of resource management in cellular IoT and
low-power IoT networks, review the traditional resource management mechanisms
for IoT networks, and motivate the use of ML and DL techniques for resource
management in these networks. Then, we provide a comprehensive survey of the
existing ML- and DL-based resource allocation techniques in wireless IoT
networks and also techniques specifically designed for HetNets, MIMO and D2D
communications, and NOMA networks. To this end, we also identify the future
research directions in using ML and DL for resource allocation and management
in IoT networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08981</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08981</id><created>2019-07-21</created><authors><author><keyname>Zhao</keyname><forenames>Zhanzhan</forenames></author><author><keyname>Sun</keyname><forenames>Haoran</forenames></author></authors><title>Alice's Adventures in the Markovian World</title><categories>eess.SY cs.LG cs.RO cs.SY</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an algorithm Alice having no access to the physics law of
the environment, which is actually linear with stochastic noise, and learns to
make decisions directly online without a training phase or a stable policy as
initial input. Neither estimating the system parameters nor the value functions
online, the proposed algorithm generalizes one of the most fundamental online
learning algorithms Follow-the-Leader into a linear Gauss-Markov process
setting, with a regularization term similar to the momentum method in the
gradient descent algorithm, and a feasible online constraint inspired by
Lyapunov's Second Theorem. The proposed algorithm is considered as a mirror
optimization to the model predictive control. Only knowing the state-action
alignment relationship, with the ability to observe every state exactly, a
no-regret proof of the algorithm without state noise is given. The analysis of
the general linear system with stochastic noise is shown with a sufficient
condition for the no-regret proof. The simulations compare the performance of
Alice with another recent work and verify the great flexibility of Alice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08983</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.08983</id><created>2019-07-21</created><updated>2019-07-23</updated><authors><author><keyname>Chen</keyname><forenames>Pingping</forenames></author><author><keyname>Xie</keyname><forenames>Zhaopeng</forenames></author><author><keyname>Fang</keyname><forenames>Yi</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Mumtaz</keyname><forenames>Shahid</forenames></author><author><keyname>Rodrigues</keyname><forenames>Joel J. P. C.</forenames></author></authors><title>Physical-Layer Network Coding: An Efficient Technique for Wireless
  Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a subfield of network coding, physical-layer network coding (PNC) can
effectively enhance the throughput of wireless networks by mapping superimposed
signals at receiver to other forms of user messages. Over the past twenty
years, PNC has received significant research attention and has been widely
studied in various communication scenarios, e.g., two-way relay communications
(TWRC), nonorthogonal multiple access (NOMA) in 5G networks, random access
networks, etc. To ensure network reliability, channel-coded PNC is proposed and
related communication techniques are investigated, such as the design of
channel code, low-complexity decoding, and cross-layer design. In this article,
we briefly review the variants of channel-coded PNC wireless communications
with the aim of inspiring future research activities in this area. We also put
forth open research problems along with a few selected research directions
under PNC-aided frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09006</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09006</id><created>2019-07-18</created><authors><author><keyname>Zheng</keyname><forenames>Yibin</forenames></author><author><keyname>Wang</keyname><forenames>Xi</forenames></author><author><keyname>He</keyname><forenames>Lei</forenames></author><author><keyname>Pan</keyname><forenames>Shifeng</forenames></author><author><keyname>Soong</keyname><forenames>Frank K.</forenames></author><author><keyname>Wen</keyname><forenames>Zhengqi</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author></authors><title>Forward-Backward Decoding for Regularizing End-to-End TTS</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted by INTERSPEECH2019. arXiv admin note: text overlap with
  arXiv:1808.04064, arXiv:1804.05374 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural end-to-end TTS can generate very high-quality synthesized speech, and
even close to human recording within similar domain text. However, it performs
unsatisfactory when scaling it to challenging test sets. One concern is that
the encoder-decoder with attention-based network adopts autoregressive
generative sequence model with the limitation of &quot;exposure bias&quot; To address
this issue, we propose two novel methods, which learn to predict future by
improving agreement between forward and backward decoding sequence. The first
one is achieved by introducing divergence regularization terms into model
training objective to reduce the mismatch between two directional models,
namely L2R and R2L (which generates targets from left-to-right and
right-to-left, respectively). While the second one operates on decoder-level
and exploits the future information during decoding. In addition, we employ a
joint training strategy to allow forward and backward decoding to improve each
other in an interactive process. Experimental results show our proposed methods
especially the second one (bidirectional decoder regularization), leads a
significantly improvement on both robustness and overall naturalness, as
outperforming baseline (the revised version of Tacotron2) with a MOS gap of
0.14 in a challenging test, and achieving close to human quality (4.42 vs. 4.49
in MOS) on general test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09019</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09019</id><created>2019-07-21</created><updated>2019-08-04</updated><authors><author><keyname>Sun</keyname><forenames>Eric D.</forenames></author><author><keyname>Dekel</keyname><forenames>Ron</forenames></author></authors><title>ImageNet-trained deep neural network exhibits illusion-like response to
  the Scintillating Grid</title><categories>cs.CV cs.LG eess.IV q-bio.NC</categories><comments>Supplementary material at end of document</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural network (DNN) models for computer vision are now capable of
human-level object recognition. Consequently, similarities in the performance
and vulnerabilities of DNN and human vision are of great interest. Here we
characterize the response of the VGG-19 DNN to images of the Scintillating Grid
visual illusion, in which white dots are perceived to be partially black. We
observed a significant deviation from the expected monotonic relation between
VGG-19 representational dissimilarity and dot whiteness in the Scintillating
Grid. That is, a linear increase in dot whiteness leads to a non-linear
increase and then, remarkably, a decrease (non-monotonicity) in
representational dissimilarity. In control images, mostly monotonic relations
between representational dissimilarity and dot whiteness were observed.
Furthermore, the dot whiteness level corresponding to the maximal
representational dissimilarity (i.e. onset of non-monotonic dissimilarity)
matched closely with that corresponding to the onset of illusion perception in
human observers. As such, the non-monotonic response in the DNN is a potential
model correlate for human illusion perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09028</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09028</id><created>2019-07-21</created><updated>2019-12-08</updated><authors><author><keyname>Krivulin</keyname><forenames>Nikolai</forenames></author></authors><title>Using tropical optimization techniques to solve time-constrained
  bi-objective project scheduling problems</title><categories>math.OC cs.SY eess.SY</categories><comments>29 pages, 2 figures</comments><msc-class>65K10 (Primary), 15A80, 90C29, 90C47, 90B50 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a project that consists of a set of activities performed in
parallel under constraints on their start and finish times, including
start-finish precedence relationships, release start times, release end times
and deadlines. The problems of interest are to schedule the activities to
minimize both the maximum flow-time over all activities and the project
makespan. We formulate and solve the problems in the framework of tropical
mathematics, which investigates the theory and applications of algebraic
systems with idempotent operations, as tropical bi-objective optimization
problems. As a result, we derive complete Pareto-optimal solutions in a direct
explicit form, ready for further analysis and straightforward computation. We
examine the computational complexity of the solution, and give illustrative
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09050</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09050</id><created>2019-07-21</created><updated>2019-10-30</updated><authors><author><keyname>Jiang</keyname><forenames>Richard</forenames></author><author><keyname>Crookes</keyname><forenames>Danny</forenames></author></authors><title>Shallow Unorganized Neural Networks using Smart Neuron Model for Visual
  Perception</title><categories>cs.CV cs.AI cs.LG cs.NE eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recent success of Deep Neural Networks (DNNs) has revealed the
significant capability of neural computing in many challenging applications.
Although DNNs are derived from emulating biological neurons, there still exist
doubts over whether or not DNNs are the final and best model to emulate the
mechanism of human intelligence. In particular, there are two discrepancies
between computational DNN models and the observed facts of biological neurons.
First, human neurons are interconnected randomly, while DNNs need
carefully-designed architectures to work properly. Second, human neurons
usually have a long spiking latency (~100ms) which implies that not many layers
can be involved in making a decision, while DNNs could have hundreds of layers
to guarantee high accuracy. In this paper, we propose a new computational
model, namely shallow unorganized neural networks (SUNNs), in contrast to
ANNs/DNNs. The proposed SUNNs differ from standard ANNs or DNNs in three
fundamental aspects: 1) SUNNs are based on an adaptive neuron cell model, Smart
Neurons, that allows each artificial neuron cell to adaptively respond to its
inputs rather than carrying out a fixed weighted-sum operation like the classic
neuron model in ANNs/DNNs; 2) SUNNs can cope with computational tasks with very
shallow architectures; 3) SUNNs have a natural topology with random
interconnections, as the human brain does, and as proposed by Turing's B-type
unorganized machines. We implemented the proposed SUNN architecture and tested
it on a number of unsupervised early stage visual perception tasks.
Surprisingly, such simple shallow architectures achieved very good results in
our experiments. The success of our new computational model makes it the first
workable example of Turing's B-Type unorganized machine that can achieve
comparable or better performance against the state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09063</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09063</id><created>2019-07-21</created><authors><author><keyname>Song</keyname><forenames>Andrew H.</forenames></author><author><keyname>Flores</keyname><forenames>Francisco J.</forenames></author><author><keyname>Ba</keyname><forenames>Demba</forenames></author></authors><title>Fast Convolutional Dictionary Learning off the Grid</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a continuous-time signal that can be modeled as the superposition of
localized, time-shifted events from multiple sources, the goal of Convolutional
Dictionary Learning (CDL) is to identify the location of the events--by
Convolutional Sparse Coding (CSC)--and learn the template for each source--by
Convolutional Dictionary Update (CDU). In practice, because we observe samples
of the continuous-time signal on a uniformly-sampled grid in discrete time,
classical CSC methods can only produce estimates of the times when the events
occur on this grid, which degrades the performance of the CDU. We introduce a
CDL framework that significantly reduces the errors arising from performing the
estimation in discrete time. Specifically, we construct an expanded dictionary
that comprises, not only discrete-time shifts of the templates, but also
interpolated variants, obtained by bandlimited interpolation, that account for
continuous-time shifts. For CSC, we develop a novel computationally efficient
CSC algorithm, termed Convolutional Orthogonal Matching Pursuit with
interpolated dictionary (COMP-INTERP). We benchmarked COMP-INTERP to
Contiunuous Basis Pursuit (CBP), the state-of-the-art CSC algorithm for
estimating off-the-grid events, and demonstrate, on simulated data, that 1)
COMP-INTERP achieves a similar level of accuracy, and 2) is two orders of
magnitude faster. For CDU, we derive a novel procedure to update the templates
given sparse codes that can occur both on and off the discrete-time grid. We
also show that 3) dictionary update with the overcomplete dictionary yields
more accurate templates. Finally, we apply the algorithms to the spike sorting
problem on electrophysiology recording and show their competitive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09077</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09077</id><created>2019-07-21</created><authors><author><keyname>Cai</keyname><forenames>Ruizhe</forenames></author><author><keyname>Ren</keyname><forenames>Ao</forenames></author><author><keyname>Chen</keyname><forenames>Olivia</forenames></author><author><keyname>Liu</keyname><forenames>Ning</forenames></author><author><keyname>Ding</keyname><forenames>Caiwen</forenames></author><author><keyname>Qian</keyname><forenames>Xuehai</forenames></author><author><keyname>Han</keyname><forenames>Jie</forenames></author><author><keyname>Luo</keyname><forenames>Wenhui</forenames></author><author><keyname>Yoshikawa</keyname><forenames>Nobuyuki</forenames></author><author><keyname>Wang</keyname><forenames>Yanzhi</forenames></author></authors><title>A Stochastic-Computing based Deep Learning Framework using Adiabatic
  Quantum-Flux-Parametron SuperconductingTechnology</title><categories>cs.NE cs.ET cs.LG eess.SP</categories><doi>10.1145/3307650.3322270</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Adiabatic Quantum-Flux-Parametron (AQFP) superconducting technology has
been recently developed, which achieves the highest energy efficiency among
superconducting logic families, potentially huge gain compared with
state-of-the-art CMOS. In 2016, the successful fabrication and testing of
AQFP-based circuits with the scale of 83,000 JJs have demonstrated the
scalability and potential of implementing large-scale systems using AQFP. As a
result, it will be promising for AQFP in high-performance computing and deep
space applications, with Deep Neural Network (DNN) inference acceleration as an
important example. Besides ultra-high energy efficiency, AQFP exhibits two
unique characteristics: the deep pipelining nature since each AQFP logic gate
is connected with an AC clock signal, which increases the difficulty to avoid
RAW hazards; the second is the unique opportunity of true random number
generation (RNG) using a single AQFP buffer, far more efficient than RNG in
CMOS. We point out that these two characteristics make AQFP especially
compatible with the \emph{stochastic computing} (SC) technique, which uses a
time-independent bit sequence for value representation, and is compatible with
the deep pipelining nature. Further, the application of SC has been
investigated in DNNs in prior work, and the suitability has been illustrated as
SC is more compatible with approximate computations. This work is the first to
develop an SC-based DNN acceleration framework using AQFP technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09085</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09085</id><created>2019-07-21</created><updated>2019-07-22</updated><authors><author><keyname>Yuan</keyname><forenames>Jianbo</forenames></author><author><keyname>Liao</keyname><forenames>Haofu</forenames></author><author><keyname>Luo</keyname><forenames>Rui</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author></authors><title>Automatic Radiology Report Generation based on Multi-view Image Fusion
  and Medical Concept Enrichment</title><categories>eess.IV cs.CV cs.MM</categories><journal-ref>MICCAI 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating radiology reports is time-consuming and requires extensive
expertise in practice. Therefore, reliable automatic radiology report
generation is highly desired to alleviate the workload. Although deep learning
techniques have been successfully applied to image classification and image
captioning tasks, radiology report generation remains challenging in regards to
understanding and linking complicated medical visual contents with accurate
natural language descriptions. In addition, the data scales of open-access
datasets that contain paired medical images and reports remain very limited. To
cope with these practical challenges, we propose a generative encoder-decoder
model and focus on chest x-ray images and reports with the following
improvements. First, we pretrain the encoder with a large number of chest x-ray
images to accurately recognize 14 common radiographic observations, while
taking advantage of the multi-view images by enforcing the cross-view
consistency. Second, we synthesize multi-view visual features based on a
sentence-level attention mechanism in a late fusion fashion. In addition, in
order to enrich the decoder with descriptive semantics and enforce the
correctness of the deterministic medical-related contents such as mentions of
organs or diagnoses, we extract medical concepts based on the radiology reports
in the training data and fine-tune the encoder to extract the most frequent
medical concepts from the x-ray images. Such concepts are fused with each
decoding step by a word-level attention model. The experimental results
conducted on the Indiana University Chest X-Ray dataset demonstrate that the
proposed model achieves the state-of-the-art performance compared with other
baseline approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09117</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09117</id><created>2019-07-21</created><authors><author><keyname>Huangfu</keyname><forenames>Yourui</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Xu</keyname><forenames>Chen</forenames></author><author><keyname>Li</keyname><forenames>Rong</forenames></author><author><keyname>Ge</keyname><forenames>Yiqun</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author><author><keyname>Zhang</keyname><forenames>Huazi</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author></authors><title>Realistic Channel Models Pre-training</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a neural-network-based realistic channel model with
both the similar accuracy as deterministic channel models and uniformity as
stochastic channel models. To facilitate this realistic channel modeling, a
multi-domain channel embedding method combined with self-attention mechanism is
proposed to extract channel features from multiple domains simultaneously. This
'one model to fit them all' solution employs available wireless channel data as
the only data set for self-supervised pre-training. With the permission of
users, network operators or other organizations can make use of some available
user specific data to fine-tune this pre-trained realistic channel model for
applications on channel-related downstream tasks. Moreover, even without
fine-tuning, we show that the pre-trained realistic channel model itself is a
great tool with its understanding of wireless channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09125</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09125</id><created>2019-07-16</created><authors><author><keyname>Fourer</keyname><forenames>Dominique</forenames></author><author><keyname>Auger</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Second-order Time-Reassigned Synchrosqueezing Transform: Application to
  Draupner Wave Analysis</title><categories>eess.SP cs.NA math.NA</categories><comments>Proc. EUSIPCO 2019. Matlab code available on IEEE Code Ocean:
  https://codeocean.com/capsule/2190725/</comments><doi>10.24433/CO.2190725.v1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of efficiently jointly representing a
non-stationary multicomponent signal in time and frequency. We introduce a
novel enhancement of the time-reassigned synchrosqueezing method designed to
compute sharpened and reversible representations of impulsive or strongly
modulated signals. After establishing theoretical relations of the new proposed
method with our previous results, we illustrate in numerical experiments the
improvement brought by our proposal when applied on both synthetic and
real-world signals. Our experiments deal with an analysis of the Draupner wave
record for which we provide pioneered time-frequency analysis results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09131</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09131</id><created>2019-07-22</created><authors><author><keyname>Piyathilaka</keyname><forenames>Lasitha</forenames></author><author><keyname>Sooriyaarachchi</keyname><forenames>Basura</forenames></author><author><keyname>Kodagoda</keyname><forenames>Sarath</forenames></author><author><keyname>Thiyagarajan</keyname><forenames>Karthick</forenames></author></authors><title>Capacitive Sensor Based 2D Subsurface Imaging Technology for Non
  Destructive Evaluation of Building Surfaces</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the underlying structure of building surfaces like walls and
floors is essential when carrying out building maintenance and modification
work. To facilitate such work, this paper introduces a capacitive sensor-based
technology which can conduct non-destructive evaluation of building surfaces.
The novelty of this sensor is that it can generate a real-time 2D subsurface
image which can be used to understand structure beneath the top surface. Finite
Element Analysis (FEA) simulations are done to understand the best sensor head
configuration that gives optimum results. Hardware and software components are
custom-built to facilitate real-time imaging capability. The sensor is
validated by laboratory tests, which revealed the ability of the proposed
capacitive sensing technology to see through common building materials like
wood and concrete. The 2D image generated by the sensor is found to be useful
in understanding the subsurface structure beneath the top surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09136</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09136</id><created>2019-07-18</created><authors><author><keyname>Sui</keyname><forenames>Wenbo</forenames></author><author><keyname>Hall</keyname><forenames>Carrie M.</forenames></author></authors><title>Combustion Phasing Modelling and Control for Compression Ignition
  Engines with High Dilution and Boost Levels</title><categories>eess.SY cs.SY</categories><comments>Journal of Automobile Engineering, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because fuel efficiency is significantly impacted by the timing of combustion
in internal combustion engines, accurate control of combustion phasing is
critical. In this paper, a nonlinear combustion phasing model is introduced and
calibrated, and both a feedforward model-based control strategy and an adaptive
model-based control strategy are investigated for combustion phasing control.
The combustion phasing model combines a knock integral model, burn duration
model and a Wiebe function to predict the combustion phasing of a diesel
engine. This model is simplified to be more suitable for combustion phasing
control and is calibrated and validated using simulations and experimental data
that include conditions with high exhaust gas recirculation fractions and high
boost levels. Based on this model, an adaptive nonlinear model-based controller
is designed for closed-loop control, and a feedforward model-based controller
is designed for open-loop control. These two control approaches were tested in
simulations. The simulation results show that during transient changes the CA50
(the crank angle at which 50% of the mass of fuel has burned) can reach steady
state in no more than 5 cycles and the steady state errors are less than +/-0.1
crank angle degree (CAD) for adaptive control, and less than +/-0.5 CAD for
feedforward model-based control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09138</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09138</id><created>2019-07-22</created><updated>2020-01-14</updated><authors><author><keyname>Hu</keyname><forenames>Wei</forenames></author><author><keyname>Gao</keyname><forenames>Xiang</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Guo</keyname><forenames>Zongming</forenames></author></authors><title>Feature Graph Learning for 3D Point Cloud Denoising</title><categories>cs.CV cs.LG eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying an appropriate underlying graph kernel that reflects pairwise
similarities is critical in many recent graph spectral signal restoration
schemes, including image denoising, dequantization, and contrast enhancement.
Existing graph learning algorithms compute the most likely entries of a
properly defined graph Laplacian matrix $\mathbf{L}$, but require a large
number of signal observations $\mathbf{z}$'s for a stable estimate. In this
work, we assume instead the availability of a relevant feature vector
$\mathbf{f}_i$ per node $i$, from which we compute an optimal feature graph via
optimization of a feature metric. Specifically, we alternately optimize the
diagonal and off-diagonal entries of a Mahalanobis distance matrix $\mathbf{M}$
by minimizing the graph Laplacian regularizer (GLR) $\mathbf{z}^{\top}
\mathbf{L} \mathbf{z}$, where edge weight is $w_{i,j} = \exp\{-(\mathbf{f}_i -
\mathbf{f}_j)^{\top} \mathbf{M} (\mathbf{f}_i - \mathbf{f}_j) \}$, given a
single observation $\mathbf{z}$. We optimize diagonal entries via proximal
gradient (PG), where we constrain $\mathbf{M}$ to be positive definite (PD) via
linear inequalities derived from the Gershgorin circle theorem. To optimize
off-diagonal entries, we design a block descent algorithm that iteratively
optimizes one row and column of $\mathbf{M}$. To keep $\mathbf{M}$ PD, we
constrain the Schur complement of sub-matrix $\mathbf{M}_{2,2}$ of $\mathbf{M}$
to be PD when optimizing via PG. Our algorithm mitigates full
eigen-decomposition of $\mathbf{M}$, thus ensuring fast computation speed even
when feature vector $\mathbf{f}_i$ has high dimension. To validate its
usefulness, we apply our feature graph learning algorithm to the problem of 3D
point cloud denoising, resulting in state-of-the-art performance compared to
competing schemes in extensive experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09163</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09163</id><created>2019-07-22</created><updated>2019-08-03</updated><authors><author><keyname>Faucher</keyname><forenames>Florian</forenames></author><author><keyname>Alessandrini</keyname><forenames>Giovanni</forenames></author><author><keyname>Barucq</keyname><forenames>H&#xe9;l&#xe8;ne</forenames></author><author><keyname>de Hoop</keyname><forenames>Maarten V.</forenames></author><author><keyname>Gaburro</keyname><forenames>Romina</forenames></author><author><keyname>Sincich</keyname><forenames>Eva</forenames></author></authors><title>Full Reciprocity-Gap Waveform Inversion in the frequency domain,
  enabling sparse-source acquisition</title><categories>physics.geo-ph eess.SP physics.comp-ph</categories><comments>28 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform quantitative sub-surface Earth-imaging by setting up the Full
Reciprocity-gap Waveform Inversion (FRgWI ) method. The reconstruction relies
on iterative minimization of a misfit functional which is specifically designed
for data obtained from dual-sensors devices. In addition to the pressure field,
the dual-sensors devices are able to measure the normal velocity of the waves
and have been deployed in exploration geophysics. The use of reciprocity-based
misfit functional provides additional features compared to the more traditional
least-squares approaches with, in particular, that the observational and
computational acquisitions can be different. Therefore, the source positions
and wavelets that generate the measurements are not needed for the
reconstruction procedure and, in fact, the numerical acquisition (for the
simulations) can be arbitrarily chosen. We illustrate our method with
three-dimensional experiments, where we first show that the reciprocity-gap
inversion behaves better than the Full Waveform Inversion (FWI) in the same
context. Next, we investigate arbitrary numerical acquisitions in two ways:
firstly, when few measurements are given, we use a dense numerical acquisition
(compared to the observational one). On the other hand, with a dense
observational acquisition, we employ a sparse computational acquisition, with
multiple-point sources, to reduce the numerical cost. We highlight that the
reciprocity-gap functional is efficient in both situations and is more robust
with respect to cross-talk than shot-stacking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09180</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09180</id><created>2019-07-22</created><authors><author><keyname>Qadir</keyname><forenames>Hemin Ali</forenames></author><author><keyname>Shin</keyname><forenames>Younghak</forenames></author><author><keyname>Solhusvik</keyname><forenames>Johannes</forenames></author><author><keyname>Bergsland</keyname><forenames>Jacob</forenames></author><author><keyname>Aabakken</keyname><forenames>Lars</forenames></author><author><keyname>Balasingham</keyname><forenames>Ilangko</forenames></author></authors><title>Polyp Detection and Segmentation using Mask R-CNN: Does a Deeper Feature
  Extractor CNN Always Perform Better?</title><categories>cs.CV cs.LG eess.IV</categories><comments>6</comments><journal-ref>2019 13th International Symposium on Medical Information and
  Communication Technology (ISMICT)</journal-ref><doi>10.1109/ISMICT.2019.8743694</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic polyp detection and segmentation are highly desirable for colon
screening due to polyp miss rate by physicians during colonoscopy, which is
about 25%. However, this computerization is still an unsolved problem due to
various polyp-like structures in the colon and high interclass polyp variations
in terms of size, color, shape, and texture. In this paper, we adapt Mask R-CNN
and evaluate its performance with different modern convolutional neural
networks (CNN) as its feature extractor for polyp detection and segmentation.
We investigate the performance improvement of each feature extractor by adding
extra polyp images to the training dataset to answer whether we need deeper and
more complex CNNs or better dataset for training in automatic polyp detection
and segmentation. Finally, we propose an ensemble method for further
performance improvement. We evaluate the performance on the 2015 MICCAI polyp
detection dataset. The best results achieved are 72.59% recall, 80% precision,
70.42% dice, and 61.24% Jaccard. The model achieved state-of-the-art
segmentation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09184</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09184</id><created>2019-07-22</created><updated>2019-08-27</updated><authors><author><keyname>Choi</keyname><forenames>Minjun J.</forenames><affiliation>National Fusion Research Institute</affiliation></author></authors><title>Spectral data analysis methods for the two-dimensional imaging
  diagnostics</title><categories>physics.data-an eess.IV physics.plasm-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some spectral data analysis methods that are useful for the two-dimensional
imaging diagnostics data are introduced. It is shown that the frequency
spectrum, the local dispersion relation, the flow shear, and the nonlinear
energy transfer rates can be estimated using the proper analysis methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09194</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09194</id><created>2019-07-22</created><authors><author><keyname>Yang</keyname><forenames>Binbin</forenames></author><author><keyname>Zhang</keyname><forenames>Weiwei</forenames></author></authors><title>FD-FCN: 3D Fully Dense and Fully Convolutional Network for Semantic
  Segmentation of Brain Anatomy</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a 3D patch-based fully dense and fully convolutional network
(FD-FCN) is proposed for fast and accurate segmentation of subcortical
structures in T1-weighted magnetic resonance images. Developed from the seminal
FCN with an end-to-end learning-based approach and constructed by newly
designed dense blocks including a dense fully-connected layer, the proposed
FD-FCN is different from other FCN-based methods and leads to an outperformance
in the perspective of both efficiency and accuracy. Compared with the U-shaped
architecture, FD-FCN discards the upsampling path for model fitness. To
alleviate the problem of parameter explosion, the inputs of dense blocks are no
longer directly passed to subsequent layers. This architecture of FD-FCN brings
a great reduction on both memory and time consumption in training process.
Although FD-FCN is slimmed down, in model competence it gains better capability
of dense inference than other conventional networks. This benefits from the
construction of network architecture and the incorporation of redesigned dense
blocks. The multi-scale FD-FCN models both local and global context by
embedding intermediate-layer outputs in the final prediction, which encourages
consistency between features extracted at different scales and embeds
fine-grained information directly in the segmentation process. In addition,
dense blocks are rebuilt to enlarge the receptive fields without significantly
increasing parameters, and spectral coordinates are exploited for spatial
context of the original input patch. The experiments were performed over the
IBSR dataset, and FD-FCN produced an accurate segmentation result of overall
Dice overlap value of 89.81% for 11 brain structures in 53 seconds, with at
least 3.66% absolute improvement of dice accuracy than state-of-the-art 3D
FCN-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09203</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09203</id><created>2019-07-22</created><updated>2019-12-16</updated><authors><author><keyname>Zhang</keyname><forenames>Songyang</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Introducing Hypergraph Signal Processing: Theoretical Foundation and
  Practical Applications</title><categories>eess.SP</categories><doi>10.1109/JIOT.2019.2950213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal processing over graphs has recently attracted significant attentions
for dealing with structured data. Normal graphs, however, only model pairwise
relationships between nodes and are not effective in representing and capturing
some high-order relationships of data samples, which are common in many
applications such as Internet of Things (IoT). In this work, we propose a new
framework of hypergraph signal processing (HGSP) based on tensor representation
to generalize the traditional graph signal processing (GSP) to tackle
high-order interactions. We introduce the core concepts of HGSP and define the
hypergraph Fourier space. We then study the spectrum properties of hypergraph
Fourier transform and explain its connection to mainstream digital signal
processing. We derive the novel hypergraph sampling theory and present the
fundamentals of hypergraph filter design based on the tensor framework. We
present HGSP-based methods for several signal processing and data analysis
applications. Our experimental results demonstrate significant performance
improvement using our HGSP framework over some traditional signal processing
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09217</identifier>
 <datestamp>2020-01-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09217</id><created>2019-07-22</created><updated>2020-01-03</updated><authors><author><keyname>Yuan</keyname><forenames>Hui</forenames></author><author><keyname>Li</keyname><forenames>Mengyu</forenames></author><author><keyname>Hou</keyname><forenames>Junhui</forenames></author><author><keyname>Xiao</keyname><forenames>Jimin</forenames></author></authors><title>Single Image based Head Pose Estimation with Spherical Parameterization
  and 3D Morphing</title><categories>cs.CV eess.IV</categories><comments>34pages, 5figures, Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Head pose estimation plays a vital role in various applications, e.g.,
driverassistance systems, human-computer interaction, virtual reality
technology, and so on. We propose a novel geometry based algorithm for
accurately estimating the head pose from a single 2D face image at a very low
computational cost. Specifically, the rectangular coordinates of only four
non-coplanar feature points from a predefined 3D facial model as well as the
corresponding ones automatically/ manually extracted from a 2D face image are
first normalized to exclude the effect of external factors (i.e., scale factor
and translation parameters). Then, the four normalized 3D feature points are
represented in spherical coordinates with reference to the uniquely determined
sphere by themselves. Due to the spherical parameterization, the coordinates of
feature points can then be morphed along all the three directions in the
rectangular coordinates effectively. Finally, the rotation matrix indicating
the head pose is obtained by minimizing the Euclidean distance between the
normalized 2D feature points and the 2D re-projections of morphed 3D feature
points. Comprehensive experimental results over two popular databases, i.e.,
Pointing'04 and Biwi Kinect, demonstrate that the proposed algorithm can
estimate head poses with higher accuracy and lower run time than
state-of-the-art geometry based methods. Even compared with start-of-the-art
learning based methods or geometry based methods with additional depth
information, our algorithm still produces comparable performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09225</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09225</id><created>2019-07-22</created><authors><author><keyname>Liu</keyname><forenames>Bryan</forenames></author><author><keyname>Li</keyname><forenames>Shuangyang</forenames></author><author><keyname>Xie</keyname><forenames>Yixuan</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Deep Learning Assisted Sum-Product Detection Algorithm for
  Faster-than-Nyquist Signaling</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 7 figures, accepted by IEEE ITW 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A deep learning assisted sum-product detection algorithm (DL-SPA) for
faster-than-Nyquist (FTN) signaling is proposed in this paper. The proposed
detection algorithm concatenates a neural network to the variable nodes of the
conventional factor graph of the FTN system to help the detector converge to
the a posterior probabilities based on the received sequence. More
specifically, the neural network performs as a function node in the modified
factor graph to deal with the residual intersymbol interference (ISI) that is
not modeled by the conventional detector with a limited number of ISI taps. We
modify the updating rule in the conventional sum-product algorithm so that the
neural network assisted detector can be complemented to a Turbo equalization.
Furthermore, a simplified convolutional neural network is employed as the
neural network function node to enhance the detector's performance and the
neural network needs a small number of batches to be trained. Simulation
results have shown that the proposed DL-SPA achieves a performance gain up to
2.5 dB with the same bit error rate compared to the conventional sum-product
detection algorithm under the same ISI responses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09234</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09234</id><created>2019-07-22</created><updated>2019-09-07</updated><authors><author><keyname>Joshi</keyname><forenames>Anant A.</forenames></author><author><keyname>Maithripala</keyname><forenames>D. H. S.</forenames></author><author><keyname>Banavar</keyname><forenames>Ravi N.</forenames></author></authors><title>A bundle framework for observer design on smooth manifolds with symmetry</title><categories>eess.SY cs.SY</categories><comments>Second version. Slightly modified a result, improved notation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents a bundle framework for nonlinear observer design on a
manifold having a Lie group action. The group action on the manifold decomposes
the manifold to a quotient structure and an orbit space, and the problem of
observer design for the entire system gets decomposed to a design over the
orbit (the group space) and a design over the quotient space. The emphasis
throughout is on studying and exploiting the created geometric structure.
Gradient based observer design on a Lie group falls out as a special case and
is given explicit attention. The concepts developed are illustrated by applying
them on well known examples, which include SLAM and rigid body observer design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09238</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09238</id><created>2019-07-22</created><authors><author><keyname>Lipping</keyname><forenames>Samuel</forenames></author><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Crowdsourcing a Dataset of Audio Captions</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio captioning is a novel field of multi-modal translation and it is the
task of creating a textual description of the content of an audio signal (e.g.
&quot;people talking in a big room&quot;). The creation of a dataset for this task
requires a considerable amount of work, rendering the crowdsourcing a very
attractive option. In this paper we present a three steps based framework for
crowdsourcing an audio captioning dataset, based on concepts and practises
followed for the creation of widely used image captioning and machine
translations datasets. During the first step initial captions are gathered. A
grammatically corrected and/or rephrased version of each initial caption is
obtained in second step. Finally, the initial and edited captions are rated,
keeping the top ones for the produced dataset. We objectively evaluate the
impact of our framework during the process of creating an audio captioning
dataset, in terms of diversity and amount of typographical errors in the
obtained captions. The obtained results show that the resulting dataset has
less typographical errors than the initial captions, and on average each sound
in the produced dataset has captions with a Jaccard similarity of 0.24, roughly
equivalent to two ten-word captions having in common four words with the same
root, indicating that the captions are dissimilar while they still contain some
of the same information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09249</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09249</id><created>2019-07-22</created><authors><author><keyname>Saikumar</keyname><forenames>Niranjan</forenames></author><author><keyname>Val&#xe9;rio</keyname><forenames>Duarte</forenames></author><author><keyname>HosseinNia</keyname><forenames>S. Hassan</forenames></author></authors><title>Complex order control for improved loop-shaping in precision positioning</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a complex order filter developed and subsequently
integrated into a PID-based controller design. The nonlinear filter is designed
with reset elements to have describing function based frequency response
similar to that of a linear (practically non-implementable) complex order
filter. This allows for a design which has a negative gain slope and a
corresponding positive phase slope as desired from a loop-shaping
controller-design perspective. This approach enables improvement in precision
tracking without compromising the bandwidth or stability requirements. The
proposed designs are tested on a planar precision positioning stage and
performance compared with PID and other state-of-the-art reset based
controllers to showcase the advantages of this filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09250</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09250</id><created>2019-07-22</created><updated>2020-01-27</updated><authors><author><keyname>Laufer</keyname><forenames>Yaron</forenames></author><author><keyname>Laufer-Goldshtein</keyname><forenames>Bracha</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author></authors><title>ML Estimation and CRBs for Reverberation, Speech and Noise PSDs in
  Rank-Deficient Noise-Field</title><categories>eess.AS cs.SD</categories><comments>Accepted for publication in IEEE/ACM Transactions on Audio, Speech,
  and Language Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech communication systems are prone to performance degradation in
reverberant and noisy acoustic environments. Dereverberation and noise
reduction algorithms typically require several model parameters, e.g. the
speech, reverberation and noise power spectral densities (PSDs). A commonly
used assumption is that the noise PSD matrix is known. However, in practical
acoustic scenarios, the noise PSD matrix is unknown and should be estimated
along with the speech and reverberation PSDs. In this paper, we consider the
case of rank-deficient noise PSD matrix, which arises when the noise signal
consists of multiple directional interference sources, whose number is less
than the number of microphones. We derive two closed-form maximum likelihood
estimators (MLEs). The first is a non-blocking-based estimator which jointly
estimates the speech, reverberation and noise PSDs, and the second is a
blocking-based estimator, which first blocks the speech signal and then jointly
estimates the reverberation and noise PSDs. Both estimators are analytically
compared and analyzed, and mean square errors (MSEs) expressions are derived.
Furthermore, Cramer-Rao Bounds (CRBs) on the estimated PSDs are derived. The
proposed estimators are examined using both simulation and real reverberant and
noisy signals, demonstrating the advantage of the proposed method compared to
competing estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09254</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09254</id><created>2019-07-22</created><updated>2019-08-02</updated><authors><author><keyname>Sekuboyina</keyname><forenames>Anjany</forenames></author><author><keyname>Rempfler</keyname><forenames>Markus</forenames></author><author><keyname>Valentinitsch</keyname><forenames>Alexander</forenames></author><author><keyname>Loeffler</keyname><forenames>Maximilian</forenames></author><author><keyname>Kirschke</keyname><forenames>Jan S.</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern H.</forenames></author></authors><title>Probabilistic Point Cloud Reconstructions for Vertebral Shape Analysis</title><categories>eess.IV cs.CV</categories><comments>Accepted at Medical Image Computing and Computer-Assisted
  Intervention (MICCAI), 2019; JSK and BHM are joint supervising authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an auto-encoding network architecture for point clouds (PC)
capable of extracting shape signatures without supervision. Building on this,
we (i) design a loss function capable of modelling data variance on PCs which
are unstructured, and (ii) regularise the latent space as in a variational
auto-encoder, both of which increase the auto-encoders' descriptive capacity
while making them probabilistic. Evaluating the reconstruction quality of our
architectures, we employ them for detecting vertebral fractures without any
supervision. By learning to efficiently reconstruct only healthy vertebrae,
fractures are detected as anomalous reconstructions. Evaluating on a dataset
containing $\sim$1500 vertebrae, we achieve area-under-ROC curve of $&gt;$75%,
without using intensity-based features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09275</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09275</id><created>2019-07-22</created><authors><author><keyname>Brehmer</keyname><forenames>Kai</forenames></author><author><keyname>Wacker</keyname><forenames>Benjamin</forenames></author><author><keyname>Modersitzki</keyname><forenames>Jan</forenames></author></authors><title>Simultaneous Registration of Image Sequences -- a novel singular value
  based images similarity measure</title><categories>eess.IV cs.NA math.NA</categories><comments>3 pages, 1 figure, presented at GAMM Annual Meeting in Munich, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The comparison of images is an important task in image processing. For a
comparison of two images, a variety of measures has been suggested. However,
applications such as dynamic imaging or serial sectioning provide a series of
many images to be compared. When these images are to be registered, the
standard approach is to sequentially align the j-th image with respect to its
neighbours and sweep with respect to j. One of the disadvantages is that
information is distributed only locally. We introduce an alternative so-called
SqN approach. SqN is based on the Schatten-q-norm of the image sequence
gradients, i.e. rank information of image gradients of the whole image
sequence. With this approach, information is transported globally. Our
experiments show that SqN gives at least comparable registration results to
standard distance measures but its computation is about six times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09296</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09296</id><created>2019-07-22</created><authors><author><keyname>Arce-Santana</keyname><forenames>Edgar R.</forenames></author><author><keyname>Alba</keyname><forenames>Alfonso</forenames></author><author><keyname>Mendez</keyname><forenames>Martin O.</forenames></author><author><keyname>Arce-Guevara</keyname><forenames>Valdemar</forenames></author></authors><title>A-Phase classification using convolutional neural networks</title><categories>eess.SP cs.CV eess.IV</categories><comments>19 pages, 5 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A series of short events, called A-phases, can be observed in the human
electroencephalogram during NREM sleep. These events can be classified in three
groups (A1, A2 and A3) according to their spectral contents, and are thought to
play a role in the transitions between the different sleep stages. A-phase
detection and classification is usually performed manually by a trained expert,
but it is a tedious and time-consuming task. In the past two decades, various
researchers have designed algorithms to automatically detect and classify the
A-phases with varying degrees of success, but the problem remains open. In this
paper, a different approach is proposed: instead of attempting to design a
general classifier for all subjects, we propose to train ad-hoc classifiers for
each subject using as little data as possible, in order to drastically reduce
the amount of time required from the expert. The proposed classifiers are based
on deep convolutional neural networks using the log-spectrogram of the EEG
signal as input data. Results are encouraging, achieving average accuracies of
80.31% when discriminating between A-phases and non A-phases, and 71.87% when
classifying among A-phase sub-types, with only 25% of the total A-phases used
for training. When additional expert-validated data is considered, the sub-type
classification accuracy increases to 78.92%. These results show that a
semi-automatic annotation system with assistance from an expert could provide a
better alternative to fully automatic classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09320</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09320</id><created>2019-07-22</created><authors><author><keyname>Wang</keyname><forenames>Hongyu</forenames></author><author><keyname>Liang</keyname><forenames>Wei</forenames></author><author><keyname>Shan</keyname><forenames>Guangcun</forenames></author></authors><title>An Efficient Method of Detection and Recognition in Remote Sensing Image
  Based on multi-angle Region of Interests</title><categories>cs.CV cs.NE eess.IV</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Presently, deep learning technology has been widely used in the field of
image recognition. However, it mainly aims at the recognition and detection of
ordinary pictures and common scenes. As special images, remote sensing images
have different shooting angles and shooting methods compared with ordinary
ones, which makes remote sensing images play an irreplaceable role in some
areas. In this paper, based on a deep convolution neural network for providing
multi-level information of images and combines RPN (Region Proposal Network)
for generating multi-angle ROIs (Region of Interest), a new model for object
detection and recognition in remote sensing images is proposed. In the
experiment, it achieves better results than traditional ways, which demonstrate
that the model proposed here would have a huge potential application in remote
sensing image recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09411</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09411</id><created>2019-07-13</created><authors><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Tian</keyname><forenames>Jing</forenames></author><author><keyname>Wen</keyname><forenames>Tao</forenames></author><author><keyname>Yang</keyname><forenames>Xiaohui</forenames></author><author><keyname>Rao</keyname><forenames>Yong</forenames></author><author><keyname>Xu</keyname><forenames>Xiaobin</forenames></author></authors><title>Deep Fault Diagnosis for Rotating Machinery with Scarce Labeled Samples</title><categories>eess.SP</categories><comments>To appear in Chinese Journal of Electronics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early and accurately detecting faults in rotating machinery is crucial for
operation safety of the modern manufacturing system. In this paper, we proposed
a novel Deep fault diagnosis (DFD) method for rotating machinery with scarce
labeled samples. DFD tackles the challenging problem by transferring knowledge
from shallow models, which is based on the idea that shallow models trained
with different hand-crafted features can reveal the latent prior knowledge and
diagnostic expertise and have good generalization ability even with scarce
labeled samples. DFD can be divided into three phases. First, a spectrogram of
the raw vibration signal is calculated by applying a Short-time Fourier
transform (STFT). From those spectrograms, discriminative time-frequency domain
features can be extracted and used to form a feature pool. Then, several
candidate Support vector machine (SVM) models are trained with different
combinations of features in the feature pool with scarce labeled samples. By
evaluating the pretrained SVM models on the validation set, the most
discriminative features and best-performed SVM models can be selected, which
are used to make predictions on the unlabeled samples. The predicted labels
reserve the expert knowledge originally carried by the SVM model. They are
combined together with the scarce fine labeled samples to form an Augmented
training set (ATS). Finally, a novel 2D deep Convolutional neural network (CNN)
model is trained on the ATS to learn more discriminative features and a better
classifier. Experimental results on two fault diagnosis datasets demonstrate
the effectiveness of the proposed DFD, which achieves better performance than
SVM models and the vanilla deep CNN model trained on scarce labeled samples.
Moreover, it is computationally efficient and is promising for real-time
rotating machinery fault diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09423</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09423</id><created>2019-07-22</created><authors><author><keyname>Bernasconi</keyname><forenames>Eleonora</forenames></author><author><keyname>Pugliese</keyname><forenames>Francesco</forenames></author><author><keyname>Zardetto</keyname><forenames>Diego</forenames></author><author><keyname>Scannapieco</keyname><forenames>Monica</forenames></author></authors><title>Satellite-Net: Automatic Extraction of Land Cover Indicators from
  Satellite Imagery by Deep Learning</title><categories>cs.CV cs.LG eess.IV</categories><comments>New Techniques and Technologies for Statistics 2019, Brussels</comments><msc-class>68T45</msc-class><acm-class>I.4.8; I.4.9; I.4.0</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we address the challenge of land cover classification for
satellite images via Deep Learning (DL). Land Cover aims to detect the physical
characteristics of the territory and estimate the percentage of land occupied
by a certain category of entities: vegetation, residential buildings,
industrial areas, forest areas, rivers, lakes, etc. DL is a new paradigm for
Big Data analytics and in particular for Computer Vision. The application of DL
in images classification for land cover purposes has a great potential owing to
the high degree of automation and computing performance. In particular, the
invention of Convolution Neural Networks (CNNs) was a fundament for the
advancements in this field. In [1], the Satellite Task Team of the UN Global
Working Group describes the results achieved so far with respect to the use of
earth observation for Official Statistics. However, in that study, CNNs have
not yet been explored for automatic classification of imagery. This work
investigates the usage of CNNs for the estimation of land cover indicators,
providing evidence of the first promising results. In particular, the paper
proposes a customized model, called Satellite-Net, able to reach an accuracy
level up to 98% on test sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09425</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09425</id><created>2019-07-22</created><authors><author><keyname>Qin</keyname><forenames>Chen</forenames></author><author><keyname>Schlemper</keyname><forenames>Jo</forenames></author><author><keyname>Duan</keyname><forenames>Jinming</forenames></author><author><keyname>Seegoolam</keyname><forenames>Gavin</forenames></author><author><keyname>Price</keyname><forenames>Anthony</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>k-t NEXT: Dynamic MR Image Reconstruction Exploiting Spatio-temporal
  Correlations</title><categories>eess.IV cs.CV</categories><comments>This paper is accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic magnetic resonance imaging (MRI) exhibits high correlations in
k-space and time. In order to accelerate the dynamic MR imaging and to exploit
k-t correlations from highly undersampled data, here we propose a novel deep
learning based approach for dynamic MR image reconstruction, termed k-t NEXT
(k-t NEtwork with X-f Transform). In particular, inspired by traditional
methods such as k-t BLAST and k-t FOCUSS, we propose to reconstruct the true
signals from aliased signals in x-f domain to exploit the spatio-temporal
redundancies. Building on that, the proposed method then learns to recover the
signals by alternating the reconstruction process between the x-f space and
image space in an iterative fashion. This enables the network to effectively
capture useful information and jointly exploit spatio-temporal correlations
from both complementary domains. Experiments conducted on highly undersampled
short-axis cardiac cine MRI scans demonstrate that our proposed method
outperforms the current state-of-the-art dynamic MR reconstruction approaches
both quantitatively and qualitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09439</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09439</id><created>2019-07-22</created><authors><author><keyname>He</keyname><forenames>Hengtao</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Model-Driven Deep Learning for Joint MIMO Channel Estimation and Signal
  Detection</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>27 Pages, 8 Figures, 1 Table. This paper has been submitted to the
  IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the model-driven deep learning (DL) for joint
MIMO channel estimation and signal detection (JCESD), where signal detection
considers channel estimation error and channel statistics while channel
estimation is refined by detected data and takes the signal detection error
into consideration. In particular, the MIMO signal detector is specially
designed by unfolding an iterative algorithm and adding some trainable
parameters. Since the number of trainable parameters is much fewer than the
data-driven DL based signal detector, the model-driven DL based MIMO signal
detector can be rapidly trained with a much smaller data set. Furthermore, the
proposed signal detector can be extended to soft-input soft-output detection
easily. Based on numerical results, the model-driven DL based JCESD scheme
significantly improves the performance of the corresponding traditional
iterative detector and the signal detector exhibits superior robustness to
signal-to-noise ratio (SNR) and channel correlation mismatches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09440</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09440</id><created>2019-07-22</created><updated>2019-08-18</updated><authors><author><keyname>Pothukuchi</keyname><forenames>Raghavendra Pradyumna</forenames></author><author><keyname>Pothukuchi</keyname><forenames>Sweta Yamini</forenames></author><author><keyname>Voulgaris</keyname><forenames>Petros</forenames></author><author><keyname>Schwing</keyname><forenames>Alexander</forenames></author><author><keyname>Torrellas</keyname><forenames>Josep</forenames></author></authors><title>Maya: Falsifying Power Sidechannels with Dynamic Control</title><categories>cs.CR cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of computers is at risk because of information leaking through
physical outputs such as power, temperature, or electromagnetic (EM) emissions.
Attackers can use advanced signal measurement and analysis to recover sensitive
data from these sidechannels. To address this problem, this paper presents
Maya, a simple and effective solution against power side-channels. The idea is
to re-shape the power dissipated by an application in an
application-transparent manner using control theory techniques - preventing
attackers from learning any information. With control theory, a controller can
reliably keep power close to a desired target value even when runtime
conditions change unpredictably. Then, by changing these targets intelligently,
power can be made to appear in any desired form, appearing to carry activity
information which, in reality, is unrelated to the application. Maya can be
implemented in privileged software or in simple hardware. In this paper, we
implement Maya on two multiprocessor machines using Operating System (OS)
threads, and show its effectiveness and ease of deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09450</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09450</id><created>2019-07-22</created><authors><author><keyname>Behvandi</keyname><forenames>Milad</forenames></author><author><keyname>Khosravi</keyname><forenames>Mohammad Azam</forenames></author><author><keyname>Suratgar</keyname><forenames>Amir Abolfazl</forenames></author></authors><title>A New computation reduction based nonlinear Kalman filter</title><categories>eess.SY cs.SY eess.SP</categories><comments>8 pages, 6 figures, 4 tables</comments><doi>10.5281/zenodo.3346568</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This article introduces a new algorithm for nonlinear state estimation based
on deterministic sigma point and EKF linearized framework for priori mean and
covariance respectively. This method reduces the computation cost of UKF about
50% and has better accuracy compared to EKF due to propagating mean and
Covariance of state to 3rd order Taylor series. Several types of Kalman filter
have been presented before to reduce the computation cost of UKF, however, this
new KF is a better choice because of its simplicity, numerical stability, and
accuracy for real-time implementation. Examples verify the effectiveness of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09453</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09453</id><created>2019-07-19</created><authors><author><keyname>Gelmini</keyname><forenames>Simone</forenames></author><author><keyname>Panzani</keyname><forenames>Giulio</forenames></author><author><keyname>Savaresi</keyname><forenames>Sergio</forenames></author></authors><title>Analysis and development of an automatic eCall for motorcycles: a
  one-class cepstrum approach</title><categories>eess.SP cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The automatic dial of an emergency call - eCall - in response to a road
accident is a feature that is gaining interest in the intelligent vehicle
community. It indirectly increases the driving safety of road vehicles, but
presents the technical challenge of developing an algorithm which triggers the
emergency call only when needed, a non-trivial task for two-wheeled vehicles
due to their complex dynamics. In the present work, we propose an eCall
algorithm that detects these anomalies in the data time series, thanks to the
cepstral analysis. The main advantage of the proposed approach is the direct
focus on the data dynamics, solving the limits of approaches based on the
analysis of the instantaneous value of some signals combination. The algorithm
is calibrated and tested against real driving data of ten different drivers,
including seven real crash events, and performance are compared with known
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09454</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09454</id><created>2019-07-16</created><authors><author><keyname>Maheswaran</keyname><forenames>Muthucumaru</forenames></author><author><keyname>Yang</keyname><forenames>Tianzi</forenames></author><author><keyname>Memon</keyname><forenames>Salman</forenames></author></authors><title>A Fog Computing Framework for Autonomous Driving Assist: Architecture,
  Experiments, and Challenges</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous driving is expected to provide a range of far-reaching economic,
environmental and safety benefits. In this study, we propose a fog computing
based framework to assist autonomous driving. Our framework relies on overhead
views from cameras and data streams from vehicle sensors to create a network of
distributed digital twins, called an edge twin, on fog machines. The edge twin
will be continuously updated with the locations of both autonomous and
human-piloted vehicles on the road segments. The vehicle locations will be
harvested from overhead cameras as well as location feeds from the vehicles
themselves. Although the edge twin can make fair road space allocations from a
global viewpoint, there is a communication cost (delay) in reaching it from the
cameras and vehicular sensors. To address this, we introduce a machine learning
forecaster as a part of the edge twin which is responsible for predicting the
future location of vehicles. Lastly, we introduce a box algorithm that will use
the forecasted values to create a hazard map for the road segment which would
be used by the framework to suggest safe manoeuvres for the autonomous vehicles
such as lane changes and accelerations. We present the complete fog computing
framework for autonomous driving assist and evaluate key portions of the
proposed framework using simulations based on a real-world dataset of vehicle
position traces on a highway
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09455</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09455</id><created>2019-07-19</created><authors><author><keyname>Chehade</keyname><forenames>Abdallah A.</forenames></author><author><keyname>Hussein</keyname><forenames>Ala A.</forenames></author></authors><title>Latent Function Decomposition for Forecasting Li-ion Battery Cells
  Capacity: A Multi-Output Convolved Gaussian Process Approach</title><categories>eess.SP cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A latent function decomposition method is proposed for forecasting the
capacity of lithium-ion battery cells. The method uses the Multi-Output
Gaussian Process, a generative machine learning framework for multi-task and
transfer learning. The MCGP decomposes the available capacity trends from
multiple battery cells into latent functions. The latent functions are then
convolved over kernel smoothers to reconstruct and/or forecast capacity trends
of the battery cells. Besides the high prediction accuracy the proposed method
possesses, it provides uncertainty information for the predictions and captures
nontrivial cross-correlations between capacity trends of different battery
cells. These two merits make the proposed MCGP a very reliable and practical
solution for applications that use battery cell packs. The MCGP is derived and
compared to benchmark methods on an experimental lithium-ion battery cells
data. The results show the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09456</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09456</id><created>2019-07-18</created><updated>2019-11-27</updated><authors><author><keyname>Meyers</keyname><forenames>Bennet</forenames></author><author><keyname>Deceglie</keyname><forenames>Michael</forenames></author><author><keyname>Deline</keyname><forenames>Chris</forenames></author><author><keyname>Jordan</keyname><forenames>Dirk</forenames></author></authors><title>Signal Processing on PV Time-Series Data: Robust Degradation Analysis
  without Physical Models</title><categories>eess.SP</categories><comments>Presented at 46th IEEE Photovoltaic Specialists Conference (2019),
  accepted with revisions to IEEE Journal of Photovoltaics, final proof
  submitted November 2019</comments><doi>10.1109/JPHOTOV.2019.2957646</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A novel unsupervised machine learning approach for analyzing time-series data
is applied to the topic of photovoltaic (PV) system degradation rate
estimation, sometimes referred to as energy-yield degradation analysis. This
approach only requires a measured power signal as an input--no irradiance data,
temperature data, or system configuration information. We present results on a
data set that was previously analyzed and presented by NREL using RdTools,
validating the accuracy of the new approach and showing increased robustness to
data anomalies while reducing the data requirements to carry out the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09457</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09457</id><created>2019-07-17</created><authors><author><keyname>Zefreh</keyname><forenames>Mahdi Ranjbar</forenames></author><author><keyname>Poggiolini</keyname><forenames>Pierluigi</forenames></author></authors><title>A GN-model closed-form formula considering coherency terms in the Link
  function and covering all possible islands in 2-D GN integration</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient evaluation of nonlinearity in modern coherent optical
telecommunication networks is necessary for design, optimization and
management. The original GN model formula can not be used in real time
applications due to long processing time needed for numerical 2-D integration,
particularly when facing with full C band or C+L band. There are closed form
approximations of the GN model which has been mathematically derived based on
some assumptions which fail in low dispersion regime. In this work, we derive a
GN closed form formula without any restrictive assumption capable of handling
arbitrary WDM combs and arbitrary link structures in closed form which can be
used with a very good accuracy with respect to original GN formula for networks
employing both high and low dispersion fibers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09458</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09458</id><created>2019-07-17</created><authors><author><keyname>Crozier</keyname><forenames>Constance</forenames></author><author><keyname>Morstyn</keyname><forenames>Thomas</forenames></author><author><keyname>McCulloch</keyname><forenames>Malcolm</forenames></author></authors><title>A Stochastic Model for Uncontrolled Charging of Electric Vehicles Using
  Cluster Analysis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a probabilistic model for uncontrolled charging of
electric vehicles (EVs). EV charging will add significant load to power systems
in the coming years and, due to the convenience of charging at home, this is
likely to occur in residential distribution systems. Estimating the size and
shape of the load will allow necessary reinforcements to be identified. Models
predicting EV charging are usually based on data from travel surveys, or from
small trials. Travel surveys are recorded by hand and typically describe
conventional vehicles, but represent a much larger and more diverse sample of
the population. The model here utilizes both sources: trial data to
parameterize the model, and survey data as the model input. Clustering is used
to identify modes of vehicle use, thus reducing vehicle use to a single
parameter -- which can be incorporated into the model without adding
significant computational burden. Two case studies are included: one
investigating the aggregated charging of 50 vehicles, and one predicting the
increase in after diversity maximum demand for different regions of the UK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09478</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09478</id><created>2019-07-22</created><authors><author><keyname>Shaban</keyname><forenames>Muhammad</forenames></author><author><keyname>Awan</keyname><forenames>Ruqayya</forenames></author><author><keyname>Fraz</keyname><forenames>Muhammad Moazam</forenames></author><author><keyname>Azam</keyname><forenames>Ayesha</forenames></author><author><keyname>Snead</keyname><forenames>David</forenames></author><author><keyname>Rajpoot</keyname><forenames>Nasir M.</forenames></author></authors><title>Context-Aware Convolutional Neural Network for Grading of Colorectal
  Cancer Histology Images</title><categories>eess.IV cs.LG stat.ML</categories><comments>10 pages, 4 figures, Supplementary Document</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Digital histology images are amenable to the application of convolutional
neural network (CNN) for analysis due to the sheer size of pixel data present
in them. CNNs are generally used for representation learning from small image
patches (e.g. 224x224) extracted from digital histology images due to
computational and memory constraints. However, this approach does not
incorporate high-resolution contextual information in histology images. We
propose a novel way to incorporate larger context by a context-aware neural
network based on images with a dimension of 1,792x1,792 pixels. The proposed
framework first encodes the local representation of a histology image into high
dimensional features then aggregates the features by considering their spatial
organization to make a final prediction. The proposed method is evaluated for
colorectal cancer grading and breast cancer classification. A comprehensive
analysis of some variants of the proposed method is presented. Our method
outperformed the traditional patch-based approaches, problem-specific methods,
and existing context-based methods quantitatively by a margin of 3.61%. Code
and dataset related information is available at this link:
https://tia-lab.github.io/Context-Aware-CNN
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09504</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09504</id><created>2019-07-22</created><authors><author><keyname>Hadaeghi</keyname><forenames>Fatemeh</forenames></author></authors><title>Reservoir Computing Models for Patient-Adaptable ECG Monitoring in
  Wearable Devices</title><categories>cs.LG eess.SP stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The reservoir computing paradigm is employed to classify heartbeat anomalies
online based on electrocardiogram signals. Inspired by the principles of
information processing in the brain, reservoir computing provides a framework
to design, train, and analyze recurrent neural networks (RNNs) for processing
time-dependent information. Due to its computational efficiency and the fact
that training amounts to a simple linear regression, this supervised learning
algorithm has been variously considered as a strategy to implement useful
computations not only on digital computers but also on emerging unconventional
hardware platforms such as neuromorphic microchips. Here, this
biological-inspired learning framework is exploited to devise an accurate
patient-adaptive model that has the potential to be integrated into wearable
cardiac events monitoring devices. The proposed patient-customized model was
trained and tested on ECG recordings selected from the MIT-BIH arrhythmia
database. Restrictive inclusion criteria were used to conduct the study only on
ECGs including, at least, two classes of heartbeats with highly unequal number
of instances. The results of extensive simulations showed this model not only
provides accurate, cheap and fast patient-customized heartbeat classifier but
also circumvents the problem of &quot;imbalanced classes&quot; when the readout weights
are trained using weighted ridge-regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09505</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09505</id><created>2019-07-22</created><authors><author><keyname>Javadpour</keyname><forenames>Amir</forenames></author><author><keyname>Mohammadi</keyname><forenames>Alireza</forenames></author></authors><title>Improving Brain Magnetic Resonance Image MRI Segmentation via a Novel
  Algorithm based on Genetic and Regional Growth</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Regarding the importance of right diagnosis in medical
applications, various methods have been exploited for processing medical images
solar. The method of segmentation is used to analyze anal to miscall structures
in medical imaging. Objective: This study describes a new method for brain
Magnetic Resonance Image (MRI) segmentation via a novel algorithm based on
genetic and regional growth. Methods: Among medical imaging methods, brains MRI
segmentation is important due to the high contrast of non-intrusive soft tissue
and high spatial resolution. Size variations of brain tissues are often
accompanied by various diseases such as Alzheimers disease. As our knowledge
about the relationship between various brain diseases and deviation of brain
anatomy increases, MRI segmentation is exploited as the first step in early
diagnosis. In this paper, the regional growth method and auto-mate selection of
initial points by genetic algorithm are used to introduce a new method for MRI
segmentation. Primary pixels and similarity criterion are automatically by
genetic algorithms to maximize the accuracy and validity in image segmentation.
Results: By using genetic algorithms and defining the fixed function of image
segmentation, the initial points for the algorithm were found. The proposed
algorithms are applied to the images and results are manually selected by
regional growth in which the initial points were compared. The results showed
that the proposed algorithm could reduce segmentation error effectively.
Conclusion: The study concluded that the proposed algorithm could reduce
segmentation error effectively and help us to diagnose brain diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09509</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09509</id><created>2019-07-22</created><authors><author><keyname>Bacharach</keyname><forenames>Lucien</forenames></author><author><keyname>Fritsche</keyname><forenames>Carsten</forenames></author><author><keyname>Orguner</keyname><forenames>Umut</forenames></author><author><keyname>Chaumette</keyname><forenames>Eric</forenames></author></authors><title>Some Results on Tighter Bayesian Lower Bounds on the Mean-Square Error</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In random parameter estimation, Bayesian lower bounds (BLBs) for the
mean-square error have been noticed to not be tight in a number of cases, even
when the sample size, or the signal-to-noise ratio, grow to infinity. In this
paper, we study alternative forms of BLBs obtained from a covariance
inequality, where the inner product is based on the \textit{a posteriori}
instead of the joint probability density function. We hence obtain a family of
BLBs, which is shown to form a counterpart at least as tight as the well-known
Weiss-Weinstein family of BLBs, and we extend it to the general case of vector
parameter estimation. Conditions for equality between these two families are
provided. Focusing on the Bayesian Cram\'er-Rao bound (BCRB), a definition of
efficiency is proposed relatively to its tighter form, and efficient estimators
are described for various types of common estimation problems, e.g., scalar,
exponential family model parameter estimation. Finally, an example is provided,
for which the classical BCRB is known to not be tight, while we show its
tighter form is, based on formal proofs of asymptotic efficiency of Bayesian
estimators. This analysis is finally corroborated by numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09517</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09517</id><created>2019-04-25</created><authors><author><keyname>Zhao</keyname><forenames>Weigang</forenames></author><author><keyname>Chen</keyname><forenames>Hui</forenames></author><author><keyname>Yuan</keyname><forenames>Yuan</forenames></author><author><keyname>Zheng</keyname><forenames>Huaibin</forenames></author><author><keyname>Liu</keyname><forenames>Jianbin</forenames></author><author><keyname>Zhou</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Jianbin</forenames></author><author><keyname>Xu</keyname><forenames>Zhuo</forenames></author></authors><title>Ultra-high-speed color imaging with single-pixel detectors under low
  light level</title><categories>physics.ins-det eess.IV physics.app-ph</categories><journal-ref>Phys. Rev. Applied 12, 034049 (2019)</journal-ref><doi>10.1103/PhysRevApplied.12.034049</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-pixel imaging is suitable for low light level scenarios because a
bucket detector is employed to maximally collect the light from an object.
However, one of the challenges is its slow imaging speed, mainly due to the
slow light modulation technique. We here demonstrate 1.4MHz video imaging based
on computational ghost imaging with a RGB LED array having a full-range frame
rate up to 100MHz. With this method, the motion of a high speed propeller is
observed. Moreover, by exploiting single-photon detectors to increase the
detection efficiency, this method is developed for ultra-high-speed imaging
under low light level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09523</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09523</id><created>2019-07-17</created><authors><author><keyname>Dargazany</keyname><forenames>Aras R.</forenames></author><author><keyname>Abtahi</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Mankodiya</keyname><forenames>Kunal</forenames></author></authors><title>An end-to-end (deep) neural network applied to raw EEG, fNIRs and body
  motion data for data fusion and BCI classification task without any
  pre-/post-processing</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain computer interfaces (BCI) using EEG, fNIRS and body motion (MoCap) data
are getting more attention due to the fact that fNIRS and MoCap are not prone
to movement artifacts similar to other brain imaging techniques such as EEG.
Advancements in deep learning (neural networks) would allow the use of raw data
for efficient feature extraction without any pre-/post-processing. In this
work, we are performing human activity recognition (BCI classification task)
for 5 activity classes using an end-to-end (deep) neural network (NN) (from
input all the way to the output) on raw fNIRS, EEG and MoCap data. Our core
contribution is focused on applying an end-to-end NN model without any
pre-/post-processing on the data. The entire NN model is being trained using
backpropagation algorithm. Our end-to-end model is composed of a four-layered
MLP: input layer, two hidden layers (using fully connected (dense) layer, batch
normalization and leaky-RELU as non-linearity and activation function), and
output layer using softmax. We have reached minimum 90\% accuracy on the test
dataset for the classification task on 10 subjects data and 5 classes of
activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09524</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09524</id><created>2019-07-16</created><authors><author><keyname>Thakallapelli</keyname><forenames>Abilash</forenames></author><author><keyname>Ghosh</keyname><forenames>Sudipta</forenames></author><author><keyname>Kamalasadan</keyname><forenames>Sukumar</forenames></author></authors><title>Development and Applicability of Online Passivity Enforced Wide-Band
  Multi-Port Equivalents For Hybrid Transient Simulation</title><categories>eess.SP cs.SY eess.SY</categories><journal-ref>IEEE Trans. on Power Syst., Volume: 34, No: 3, pp. 2302 - 2311,
  May. 2019</journal-ref><doi>10.1109/TPWRS.2018.2885240</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for developing single and multi-port frequency
dependent network equivalent (FDNE) based on a passivity enforced online
recursive least squares identification algorithm, which identifies the input
admittance matrix in z-domain. Furthermore, with the proposed architecture, a
real-time hybrid model of the reduced power system is developed that integrate
transient stability analysis and FDNE. Main advantages of the proposed
architecture are, it identifies the FDNE even with unknown network parameters
in the frequency range of interest, and yet can be implemented directly due to
discrete formulation while maintaining desired accuracy, stability, and
passivity conditions. The accuracy and characteristics of the proposed method
are verified by implementing on two-area, IEEE 39 and 68 bus power system
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09533</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09533</id><created>2019-07-22</created><authors><author><keyname>&#xd6;zdenizci</keyname><forenames>Ozan</forenames></author><author><keyname>Meyer</keyname><forenames>Timm</forenames></author><author><keyname>Wichmann</keyname><forenames>Felix</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author><author><keyname>&#xc7;etin</keyname><forenames>M&#xfc;jdat</forenames></author><author><keyname>Grosse-Wentrup</keyname><forenames>Moritz</forenames></author></authors><title>Neural Signatures of Motor Skill in the Resting Brain</title><categories>q-bio.NC eess.SP</categories><comments>2019 IEEE International Conference on Systems, Man, and Cybernetics
  (IEEE SMC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stroke-induced disturbances of large-scale cortical networks are known to be
associated with the extent of motor deficits. We argue that identifying brain
networks representative of motor behavior in the resting brain would provide
significant insights for current neurorehabilitation approaches. Particularly,
we aim to investigate the global configuration of brain rhythms and their
relation to motor skill, instead of learning performance as broadly studied. We
empirically approach this problem by conducting a three-dimensional physical
space visuomotor learning experiment during electroencephalographic (EEG) data
recordings with thirty-seven healthy participants. We demonstrate that
across-subjects variations in average movement smoothness as the quantified
measure of subjects' motor skills can be predicted from the global
configuration of resting-state EEG alpha-rhythms (8-14 Hz) recorded prior to
the experiment. Importantly, this neural signature of motor skill was found to
be orthogonal to (independent of) task -- as well as to learning-related
changes in alpha-rhythms, which we interpret as an organizing principle of the
brain. We argue that disturbances of such configurations in the brain may
contribute to motor deficits in stroke, and that reconfiguring stroke patients'
brain rhythms by neurofeedback may enhance post-stroke neurorehabilitation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09536</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09536</id><created>2019-07-22</created><authors><author><keyname>Rao</keyname><forenames>Raghunandan M.</forenames></author><author><keyname>Dhillon</keyname><forenames>Harpeet S.</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>Analysis of Worst-Case Interference in Underlay Radar-Massive MIMO
  Spectrum Sharing Scenarios</title><categories>cs.NI eess.SP</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider an underlay radar-massive MIMO spectrum sharing
scenario in which massive MIMO base stations (BSs) are allowed to operate
outside a circular exclusion zone centered at the radar. Modeling the locations
of the massive MIMO BSs as a homogeneous Poisson point process (PPP), we derive
an analytical expression for a tight upper bound on the average interference at
the radar due to cellular transmissions. The technical novelty is in bounding
the worst-case elevation angle for each massive MIMO BS for which we devise a
novel construction based on the circumradius distribution of a typical
Poisson-Voronoi (PV) cell. While these worst-case elevation angles are
correlated for neighboring BSs due to the structure of the PV tessellation, it
does not explicitly appear in our analysis because of our focus on the average
interference. We also provide an estimate of the nominal average interference
by approximating each cell as a circle with area equal to the average area of
the typical cell. Using these results, we demonstrate that the gap between the
two results remains approximately constant with respect to the exclusion zone
radius. Our analysis reveals useful trends in average interference power, as a
function of key deployment parameters such as radar/BS antenna heights, number
of antenna elements per radar/BS, BS density, and exclusion zone radius.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09544</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09544</id><created>2019-07-22</created><authors><author><keyname>Alsulami</keyname><forenames>Osama Zwaid</forenames></author><author><keyname>Alahmadi</keyname><forenames>Amal A.</forenames></author><author><keyname>Saeed</keyname><forenames>Sarah O. M.</forenames></author><author><keyname>Mohamed</keyname><forenames>Sanaa Hamid</forenames></author><author><keyname>El-Gorashi</keyname><forenames>T. E. H.</forenames></author><author><keyname>Alresheedi</keyname><forenames>Mohammed T.</forenames></author><author><keyname>Elmirghani</keyname><forenames>Jaafar M. H.</forenames></author></authors><title>Networking and processing in optical wireless</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Optical wireless communication (OWC) is a promising technology that can
provide high data rates while supporting multiple users. The Optical Wireless
(OW) physical layer has been researched extensively, however less work was
devoted to multiple access and how the OW front end is connected to the
network. In this paper, an OWC system which employs a wavelength division
multiple access (WDMA) scheme is studied, for the purpose of supporting
multiple users. In addition, a cloud/fog architecture is proposed for the first
time for OWC to provide processing capabilities. The cloud/fog-integrated
architecture uses visible indoor light to create high data rate connections
with potential mobile nodes. These optical wireless nodes are further clustered
and used as fog mini servers to provide processing services through the optical
wireless channel for other users. Additional fog processing units are located
in the room, the building, the campus and at the metro level. Further
processing capabilities are provided by remote cloud sites. A mixed-integer
linear programming (MILP) model was developed and utilised to optimise resource
allocation in the indoor OWC system. A second MILP model was developed to
optimise the placement of processing tasks in the different fog and cloud nodes
available. The optimisation of tasks placement in the cloud-/fog-integrated
architecture was analysed using the MILP models. Multiple scenarios were
considered where the mobile node locations were varied in the room and the
amount of processing and data rate requested by each optical wireless node is
varied. The results help identify the optimum colour and access point to use
for communication for a given mobile node location and OWC system
configuration, the optimum location to place processing and the impact of the
network architecture. Areas for future work are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09589</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09589</id><created>2019-07-22</created><authors><author><keyname>Wang</keyname><forenames>Chen</forenames></author><author><keyname>Mishra</keyname><forenames>Chetan</forenames></author></authors><title>Voltage Security Analysis of VSC-HVDC Transmission Lines</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to generation retirements and growth of renewable energy sources
integration, there will be widespread changes in the real and reactive power
flow in nowadays power systems. These changes also bring about challenges on
system operation and stability. High voltage direct current (HVDC) technology
seems to be a promising solution to these new challenges. A study on the impact
of the replacement of 500KV AC transmission lines by VSC-HVDC transmission line
on system voltage security is conducted. The analysis is based on reactive load
margin method and implemented on one of the Dominion Energy planning models.
Different control schemes of HVDC are considered. Using k-means clustering
method, three representative zones within the network are selected. The results
corresponding to them are demonstrated and discussed. It is shown that HVDC
lines with P-V control remarkably improve system voltage security, while those
with P-PF control scheme have negative effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09605</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09605</id><created>2019-07-22</created><authors><author><keyname>Antil</keyname><forenames>Harbir</forenames></author><author><keyname>Di</keyname><forenames>Zichao</forenames></author><author><keyname>Khatri</keyname><forenames>Ratna</forenames></author></authors><title>Bilevel Optimization, Deep Learning and Fractional Laplacian
  Regularization with Applications in Tomography</title><categories>eess.IV cs.LG cs.NA math.NA math.OC</categories><msc-class>65D18, 68U10, 62H35, 94A08, 35R11, 34K37, 65K10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we consider a generalized bilevel optimization framework for
solving inverse problems. We introduce fractional Laplacian as a regularizer to
improve the reconstruction quality, and compare it with the total variation
regularization. We emphasize that the key advantage of using fractional
Laplacian as a regularizer is that it leads to a linear operator, as opposed to
the total variation regularization which results in a nonlinear degenerate
operator. Inspired by residual neural networks, to learn the optimal strength
of regularization and the exponent of fractional Laplacian, we develop a
dedicated bilevel optimization neural network with a variable depth for a
general regularized inverse problem. We also draw some parallels between an
activation function in a neural network and regularization. We illustrate how
to incorporate various regularizer choices into our proposed network. As an
example, we consider tomographic reconstruction as a model problem and show an
improvement in reconstruction quality, especially for limited data, via
fractional Laplacian regularization. We successfully learn the regularization
strength and the fractional exponent via our proposed bilevel optimization
neural network. We observe that the fractional Laplacian regularization
outperforms total variation regularization. This is specially encouraging, and
important, in the case of limited and noisy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09636</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09636</id><created>2019-07-22</created><updated>2020-02-13</updated><authors><author><keyname>Jeon</keyname><forenames>Woojay</forenames></author><author><keyname>Jordan</keyname><forenames>Maxwell</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Mahesh</forenames></author></authors><title>On Modeling ASR Word Confidence</title><categories>cs.CL cs.SD eess.AS stat.ML</categories><comments>To appear in IEEE ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new method for computing ASR word confidences that effectively
mitigates the effect of ASR errors for diverse downstream applications,
improves the word error rate of the 1-best result, and allows better comparison
of scores across different models. We propose 1) a new method for modeling word
confidence using a Heterogeneous Word Confusion Network (HWCN) that addresses
some key flaws in conventional Word Confusion Networks, and 2) a new score
calibration method for facilitating direct comparison of scores from different
models. Using a bidirectional lattice recurrent neural network to compute the
confidence scores of each word in the HWCN, we show that the word sequence with
the best overall confidence is more accurate than the default 1-best result of
the recognizer, and that the calibration method can substantially improve the
reliability of recognizer combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09640</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09640</id><created>2019-07-22</created><authors><author><keyname>Jin</keyname><forenames>Jing</forenames></author><author><keyname>Hou</keyname><forenames>Junhui</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Kwong</keyname><forenames>Sam</forenames></author><author><keyname>Yu</keyname><forenames>Jingyi</forenames></author></authors><title>Learning High-fidelity Light Field Images From Hybrid Inputs</title><categories>cs.CV eess.IV</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the reconstruction of high-fidelity LF images (i.e., LF
images with both high spatial and angular resolution) from hybrid inputs,
including a high resolution RGB image and a low spatial but high angular
resolution LF image. To tackle this challenging problem, we propose a novel
end-to-end learning-based approach, which can comprehensively utilize the
specific characteristics of the input from two complementary and parallel
perspectives. Specifically, one module efficiently learns a deep
multi-dimensional and cross-domain feature representation to regress an
intermediate estimation; the other one propagates the information of the input,
which is challenging to predict, to construct another intermediate estimation.
We finally leverage the advantages of the two intermediate estimations via the
learned confidence maps, leading to the final high-fidelity LF image. Extensive
experiments demonstrate the significant superiority of our approach over the
state-of-the-art ones. That is, our method not only improves the PSNR more than
2 dB, but also preserves the LF structure much better. To the best of our
knowledge, this is the first end-to-end deep learning method for reconstructing
a high-fidelity LF image with a hybrid input. We believe our framework could
potentially decrease the cost of high-fidelity LF data acquisition and also be
beneficial to LF data storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09642</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09642</id><created>2019-07-22</created><updated>2019-11-26</updated><authors><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Pingping</forenames></author><author><keyname>Lei</keyname><forenames>Yinjie</forenames></author><author><keyname>Huang</keyname><forenames>Xiaolin</forenames></author><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Reid</keyname><forenames>Ian</forenames></author></authors><title>A Generalized Framework for Edge-preserving and Structure-preserving
  Image Smoothing</title><categories>cs.GR cs.CV eess.IV</categories><comments>Accepted by AAAI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image smoothing is a fundamental procedure in applications of both computer
vision and graphics. The required smoothing properties can be different or even
contradictive among different tasks. Nevertheless, the inherent smoothing
nature of one smoothing operator is usually fixed and thus cannot meet the
various requirements of different applications. In this paper, a non-convex
non-smooth optimization framework is proposed to achieve diverse smoothing
natures where even contradictive smoothing behaviors can be achieved. To this
end, we first introduce the truncated Huber penalty function which has seldom
been used in image smoothing. A robust framework is then proposed. When
combined with the strong flexibility of the truncated Huber penalty function,
our framework is capable of a range of applications and can outperform the
state-of-the-art approaches in several tasks. In addition, an efficient
numerical solution is provided and its convergence is theoretically guaranteed
even the optimization framework is non-convex and non-smooth. The effectiveness
and superior performance of our approach are validated through comprehensive
experimental results in a range of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09648</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09648</id><created>2019-07-22</created><updated>2019-11-12</updated><authors><author><keyname>Xin</keyname><forenames>Ran</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Khan</keyname><forenames>Usman A.</forenames></author></authors><title>An introduction to decentralized stochastic optimization with gradient
  tracking</title><categories>cs.LG cs.SY eess.SY math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralized solutions to finite-sum minimization are of significant
importance in many signal processing, control, and machine learning
applications. In such settings, the data is distributed over a network of
arbitrarily-connected nodes and raw data sharing is prohibitive often due to
communication or privacy constraints. In this article, we review decentralized
stochastic first-order optimization methods and illustrate some recent
improvements based on gradient tracking and variance reduction, focusing
particularly on smooth and strongly-convex objective functions. We provide
intuitive illustrations of the main technical ideas as well as applications of
the algorithms in the context of decentralized training of machine learning
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09655</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09655</id><created>2019-07-22</created><authors><author><keyname>Xue</keyname><forenames>Xuan</forenames></author><author><keyname>Wang</keyname><forenames>Yongchao</forenames></author><author><keyname>Yang</keyname><forenames>Long</forenames></author><author><keyname>Shi</keyname><forenames>Jia</forenames></author><author><keyname>Li</keyname><forenames>Zan</forenames></author></authors><title>Energy-Efficient Hybrid Precoding for Massive MIMO mmWave Systems With a
  Fully-Adaptive-Connected Structure</title><categories>eess.SP</categories><comments>26 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the hybrid precoding design in millimeter-wave
(mmWave) systems with a fully-adaptive-connected precoding structure, where a
switch-controlled connection is deployed between every antenna and every radio
frequency (RF) chain. To maximally enhance the energy efficiency (EE) of hybrid
precoding under this structure, the joint optimization of switch-controlled
connections and the hybrid precoders is formulated as a large-scale
mixed-integer non-convex problem with high-dimensional power constraints. To
efficiently solve such a challenging problem, we first decouple it into a
continuous hybrid precoding (CHP) subproblem. Then, with the hybrid precoder
obtained from the CHP subproblem, the original problem can be equivalently
reformulated as a discrete connection-state (DCS) problem with only 0-1 integer
variables. For the CHP subproblem, we propose an alternating hybrid precoding
(AHP) algorithm. Then, with the hybrid precoder provided by the AHP algorithm,
we develop a matching assisted fully-adaptive hybrid precoding (MA-FAHP)
algorithm to solve the DCS problem. It is theoretically shown that the proposed
MA-FAHP algorithm always converges to a stable solution with the polynomial
complexity. Finally, simulation results demonstrate that the superior
performance of the proposed MA-FAHP algorithm in terms of EE and beampattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09691</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09691</id><created>2019-07-23</created><updated>2019-12-09</updated><authors><author><keyname>Hu</keyname><forenames>Lan</forenames></author><author><keyname>Xu</keyname><forenames>Wanting</forenames></author><author><keyname>Huang</keyname><forenames>Kun</forenames></author><author><keyname>Kneip</keyname><forenames>Laurent</forenames></author></authors><title>Deep-SLAM++: Object-level RGBD SLAM based on class-specific deep shape
  priors</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an effort to increase the capabilities of SLAM systems and produce
object-level representations, the community increasingly investigates the
imposition of higher-level priors into the estimation process. One such example
is given by employing object detectors to load and register full CAD models.
Our work extends this idea to environments with unknown objects and imposes
object priors by employing modern class-specific neural networks to generate
complete model geometry proposals. The difficulty of using such predictions in
a real SLAM scenario is that the prediction performance depends on the
view-point and measurement quality, with even small changes of the input data
sometimes leading to a large variability in the network output. We propose a
discrete selection strategy that finds the best among multiple proposals from
different registered views by re-enforcing the agreement with the online depth
measurements. The result is an effective object-level RGBD SLAM system that
produces compact, high-fidelity, and dense 3D maps with semantic annotations.
It outperforms traditional fusion strategies in terms of map completeness and
resilience against degrading measurement quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09707</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09707</id><created>2019-07-23</created><updated>2019-07-31</updated><authors><author><keyname>Oh</keyname><forenames>Sangyun</forenames></author><author><keyname>Kim</keyname><forenames>Hye-Jin S.</forenames></author><author><keyname>Lee</keyname><forenames>Jongeun</forenames></author><author><keyname>Kim</keyname><forenames>Junmo</forenames></author></authors><title>RRNet: Repetition-Reduction Network for Energy Efficient Decoder of
  Depth Estimation</title><categories>cs.CV eess.IV</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Repetition-Reduction network (RRNet) for resource-constrained
depth estimation, offering significantly improved efficiency in terms of
computation, memory and energy consumption. The proposed method is based on
repetition-reduction (RR) blocks. The RR blocks consist of the set of repeated
convolutions and the residual connection layer that take place of the pointwise
reduction layer with linear connection to the decoder. The RRNet help reduce
memory usage and power consumption in the residual connections to the decoder
layers. RRNet consumes approximately 3.84 times less energy and 3.06 times less
meory and is approaximately 2.21 times faster, without increasing the demand on
hardware resource relative to the baseline network (Godard et al, CVPR'17),
outperforming current state-of-the-art lightweight architectures such as
SqueezeNet, ShuffleNet, MobileNet and PyDNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09732</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09732</id><created>2019-07-23</created><authors><author><keyname>Brehmer</keyname><forenames>Kai</forenames></author><author><keyname>Aggrawal</keyname><forenames>Hari Om</forenames></author><author><keyname>Heldmann</keyname><forenames>Stefan</forenames></author><author><keyname>Modersitzki</keyname><forenames>Jan</forenames></author></authors><title>Variational Registration of Multiple Images with the SVD based SqN
  Distance Measure</title><categories>eess.IV cs.CV cs.NA math.NA</categories><comments>12 pages, 5 figures, accepted at the conference &quot;Scale Space and
  Variational Methods&quot; in Hofgeismar, Germany 2019</comments><doi>10.1007/978-3-030-22368-7_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image registration, especially the quantification of image similarity, is an
important task in image processing. Various approaches for the comparison of
two images are discussed in the literature. However, although most of these
approaches perform very well in a two image scenario, an extension to a
multiple images scenario deserves attention. In this article, we discuss and
compare registration methods for multiple images. Our key assumption is, that
information about the singular values of a feature matrix of images can be used
for alignment. We introduce, discuss and relate three recent approaches from
the literature: the Schatten q-norm based SqN distance measure, a rank based
approach, and a feature volume based approach. We also present results for
typical applications such as dynamic image sequences or stacks of histological
sections. Our results indicate that the SqN approach is in fact a suitable
distance measure for image registration. Moreover, our examples also indicate
that the results obtained by SqN are superior to those obtained by its
competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09735</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09735</id><created>2019-07-23</created><authors><author><keyname>Liu</keyname><forenames>Bryan</forenames></author><author><keyname>Wei</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Pajovic</keyname><forenames>Milutin</forenames></author></authors><title>Deep Learning Assisted User Identification in Massive Machine-Type
  Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 4 figures, accepted by IEEE GLOBECOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a deep learning aided list approximate message
passing (AMP) algorithm to further improve the user identification performance
in massive machine type communications. A neural network is employed to
identify a suspicious device which is most likely to be falsely alarmed during
the first round of the AMP algorithm. The neural network returns the false
alarm likelihood and it is expected to learn the unknown features of the false
alarm event and the implicit correlation structure in the quantized pilot
matrix. Then, via employing the idea of list decoding in the field of error
control coding, we propose to enforce the suspicious device to be inactive in
every iteration of the AMP algorithm in the second round. The proposed scheme
can effectively combat the interference caused by the suspicious device and
thus improve the user identification performance. Simulations demonstrate that
the proposed algorithm improves the mean squared error performance of
recovering the sparse unknown signals in comparison to the conventional AMP
algorithm with the minimum mean squared error denoiser.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09741</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09741</id><created>2019-07-23</created><authors><author><keyname>Brehmer</keyname><forenames>Kai</forenames></author><author><keyname>Wacker</keyname><forenames>Benjamin</forenames></author><author><keyname>Modersitzki</keyname><forenames>Jan</forenames></author></authors><title>A Novel Similarity Measure for Image Sequences</title><categories>eess.IV cs.NA math.NA</categories><comments>10 pages, 5 figures, accepted at the &quot;International Workshop on
  Biomedical Image Registration&quot;</comments><doi>10.1007/978-3-319-92258-4_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantification of image similarity is a common problem in image processing.
For pairs of two images, a variety of options is available and well-understood.
However, some applications such as dynamic imaging or serial sectioning involve
the analysis of image sequences and thus require a simultaneous and unbiased
comparison of many images. This paper proposes a new similarity measure, that
takes a global perspective and involves all images at the same time. The key
idea is to look at Schatten-q-norms of a matrix assembled from normalized
gradient fields of the image sequence. In particular, for q = 0, the measure is
minimized if the gradient information from the image sequence has a low rank.
This global perspective of the novel SqN-measure does not only allow to
register sequences from dynamic imaging, e.g. DCE-MRI, but is also a new
opportunity to simultaneously register serial sections, e.g. in histology. In
this way, an accumulation of small, local registration errors may be avoided.
First numerical experiments show very promising results for a DCE-MRI sequence
of a human kidney as well as for a set of serial sections. The global structure
of the data used for registration with SqN is preserved in all cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09766</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09766</id><created>2019-07-23</created><authors><author><keyname>Grayver</keyname><forenames>Alexander V.</forenames></author><author><keyname>Noir</keyname><forenames>Jerome</forenames></author></authors><title>Particle streak velocimetry using Ensemble Convolutional Neural Networks</title><categories>eess.IV physics.flu-dyn</categories><doi>10.1007/s00348-019-2876-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study reports an approach and presents its open-source implementation
for quantitative analysis of experimental flows using streak images and
Convolutional Neural Networks (CNN). The latter are applied to retrieve a
length and an angle from streaks, which can be used to deduce kinetic energy
and directionality (up to 180$^{\circ}$ ambiguity) of an imaged flow. We
developed a quick method for generating essentially unlimited number of
training and validation images, which enabled efficient training. Additionally,
we show how to apply an ensemble of CNNs to derive a formal uncertainty on the
estimated quantities. The approach is validated on the numerical simulation of
a convenctive turbulent flow and applied to a longitutidal libration flow
experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09804</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09804</id><created>2019-07-23</created><updated>2019-08-01</updated><authors><author><keyname>Shanbhag</keyname><forenames>Soham</forenames></author><author><keyname>Banavar</keyname><forenames>Ravi</forenames></author></authors><title>Design of a Discrete Time Observer for the Continuous Time Rotation
  Kinematics on $\mathbb{S}\mathbb{O}(3)$</title><categories>eess.SY cs.SY</categories><comments>24 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report proposes a discrete time observer for the continuous time rigid
body kinematics on the rotation group $\mathbb{S}\mathbb{O}(3)$. The work draws
on two research schools - one by Chang based on feedback integrators for
systems evolving on manifolds,and the other by Mahony, who proposed an observer
for attitude dynamics. The discrete time observer is based on the modified
dynamics of the Mahony observer for attitude dynamics, where the modification
of the vector field enables numerical integration based on Euclidean schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09811</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09811</id><created>2019-07-23</created><authors><author><keyname>Geng</keyname><forenames>Xiurui</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>NPSA: Nonorthogonal Principal Skewness Analysis</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal skewness analysis (PSA) has been introduced for feature extraction
in hyperspectral imagery. As a third-order generalization of principal
component analysis (PCA), its solution of searching for the locally maximum
skewness direction is transformed into the problem of calculating the
eigenpairs (the eigenvalues and the corresponding eigenvectors) of a coskewness
tensor. By combining a fixed-point method with an orthogonal constraint, it can
prevent the new eigenpairs from converging to the same maxima that has been
determined before. However, the eigenvectors of the supersymmetric tensor are
not inherently orthogonal in general, which implies that the results obtained
by the search strategy used in PSA may unavoidably deviate from the actual
eigenpairs. In this paper, we propose a new nonorthogonal search strategy to
solve this problem and the new algorithm is named nonorthogonal principal
skewness analysis (NPSA). The contribution of NPSA lies in the finding that the
search space of the eigenvector to be determined can be enlarged by using the
orthogonal complement of the Kronecker product of the previous one, instead of
its orthogonal complement space. We give a detailed theoretical proof to
illustrate why the new strategy can result in the more accurate eigenpairs. In
addition, after some algebraic derivations, the complexity of the presented
algorithm is also greatly reduced. Experiments with both simulated data and
real multi/hyperspectral imagery demonstrate its validity in feature
extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09822</identifier>
 <datestamp>2020-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09822</id><created>2019-07-23</created><updated>2020-01-08</updated><authors><author><keyname>Picallo</keyname><forenames>Miguel</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author></authors><title>Sieving out Unnecessary Constraints in Scenario Optimization with an
  Application to Power Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many optimization problems incorporate uncertainty affecting their parameters
and thus their objective functions and constraints. As an example, in
chance-constrained optimization the constraints need to be satisfied with a
certain probability. To solve these problems, scenario optimization is a well
established methodology that ensures feasibility of the solution by enforcing
it to satisfy a given number of samples of the constraints. The main
theoretical results in scenario optimization provide the methods to determine
the necessary number of samples, or to compute the risk based on the number of
so-called support constraints. In this paper, we propose a methodology to
remove constraints after observing the number of support constraints and the
consequent risk. Additionally, we show the effectiveness of the approach with
an illustrative example and an application to power distribution grid
management when solving the optimal power flow problem. In this problem,
uncertainty in the loads converts the admissible voltage limits into
chance-constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09863</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09863</id><created>2019-07-23</created><authors><author><keyname>Jovicic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author></authors><title>Enhanced Modelling Framework for Equivalent Circuit-Based Power System
  State Estimation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The equivalent split-circuit formulation is a novel approach that has
recently been applied to a range of power system related problems. As a result,
a linear and a nonlinear method for power system state estimation with
simultaneous treatment of the conventional and synchrophasor measurements have
been proposed. In this paper, new circuit models are introduced for different
combinations of conventional measurements, thus providing a complete modelling
framework for these methods. Additionally, handling cases of null injections
and buses with no measurements are included. Simulations are performed on
several test systems in order to evaluate the performance of both methods with
the enhanced modelling framework and to compare them to a hybrid constrained
estimator based on the conventional WLS approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09884</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09884</id><created>2019-07-23</created><authors><author><keyname>Fan</keyname><forenames>Cunhang</forenames></author><author><keyname>Liu</keyname><forenames>Bin</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author><author><keyname>Yi</keyname><forenames>Jiangyan</forenames></author><author><keyname>Wen</keyname><forenames>Zhengqi</forenames></author></authors><title>Discriminative Learning for Monaural Speech Separation Using Deep
  Embedding Features</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages, 1 figure, accepted by INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep clustering (DC) and utterance-level permutation invariant training
(uPIT) have been demonstrated promising for speaker-independent speech
separation. DC is usually formulated as two-step processes: embedding learning
and embedding clustering, which results in complex separation pipelines and a
huge obstacle in directly optimizing the actual separation objectives. As for
uPIT, it only minimizes the chosen permutation with the lowest mean square
error, doesn't discriminate it with other permutations. In this paper, we
propose a discriminative learning method for speaker-independent speech
separation using deep embedding features. Firstly, a DC network is trained to
extract deep embedding features, which contain each source's information and
have an advantage in discriminating each target speakers. Then these features
are used as the input for uPIT to directly separate the different sources.
Finally, uPIT and DC are jointly trained, which directly optimizes the actual
separation objectives. Moreover, in order to maximize the distance of each
permutation, the discriminative learning is applied to fine tuning the whole
model. Our experiments are conducted on WSJ0-2mix dataset. Experimental results
show that the proposed models achieve better performances than DC and uPIT for
speaker-independent speech separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09890</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09890</id><created>2019-04-29</created><authors><author><keyname>Keskin</keyname><forenames>Ridvan</forenames></author><author><keyname>Aliskan</keyname><forenames>Ibrahim</forenames></author></authors><title>Design of Non-Inverting Buck-Boost Converter for Electronic Ballast
  Compatible with LED Drivers</title><categories>eess.SY cs.SY eess.SP</categories><journal-ref>published in 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents design and control of dual-switch non-inverting
buck-boost converter (CBB). This converter is designed to simplify the
compatibility of electronic ballast with simple and low cost LED drivers. The
converter provides starting voltage and current limitation of electronic
ballasts, which operates at continuous conduction mode (CCM). The voltage of
load terminal is controlled by adjusting the duty cycle of the PWM regulator.
Although both converter switches are controlled separately, one feedback
control loop is needed to obtain the desired compensator level. Appropriate
control requirements have been defined by analyzing open-loop characteristic of
converter transfer function through the small-signal model of CBB, which lets
decide about the control strategy and analyse the stability and performance of
the closed loop control system. In order to obtain the desired output voltage,
Type-III rational controller is preferred because of the non-minimum phase
feature in the converter boost mode. The performance of the synthesized voltage
controller is verified by comparing of the pre-determined performance
requirements and the obtained simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09916</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09916</id><created>2019-07-23</created><authors><author><keyname>Huang</keyname><forenames>Shuo-An</forenames></author><author><keyname>Yang</keyname><forenames>Chia-Hsiang</forenames></author></authors><title>A Hardware-Efficient ADMM-Based SVM Training Algorithm for Edge
  Computing</title><categories>eess.SP cs.LG</categories><comments>10 pages, 1 table, and 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work demonstrates a hardware-efficient support vector machine (SVM)
training algorithm via the alternative direction method of multipliers (ADMM)
optimizer. Low-rank approximation is exploited to reduce the dimension of the
kernel matrix by employing the Nystr\&quot;{o}m method. Verified in four datasets,
the proposed ADMM-based training algorithm with rank approximation reduces
32$\times$ of matrix dimension with only 2% drop in inference accuracy.
Compared to the conventional sequential minimal optimization (SMO) algorithm,
the ADMM-based training algorithm is able to achieve a 9.8$\times$10$^7$
shorter latency for training 2048 samples. Hardware design techniques,
including pre-computation and memory sharing, are proposed to reduce the
computational complexity by 62% and the memory usage by 60%. As a proof of
concept, an epileptic seizure detector chip is designed to demonstrate the
effectiveness of the proposed hardware-efficient training algorithm. The chip
achieves a 153,310$\times$ higher energy efficiency and a 364$\times$ higher
throughput-to-area ratio for SVM training than a high-end CPU. This work
provides a promising solution for edge devices which require low-power and
real-time training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09918</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09918</id><created>2019-07-16</created><updated>2019-07-24</updated><authors><author><keyname>Ding</keyname><forenames>Z.</forenames></author><author><keyname>Poor</keyname><forenames>H. V.</forenames></author></authors><title>A Simple Design of IRS-NOMA Transmission</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes a simple design of intelligent reflecting surface (IRS)
assisted non-orthogonal multiple access (NOMA) transmission, which can ensure
that more users are served on each orthogonal spatial direction than spatial
division multiple access (SDMA). In particular, by employing IRS, the
directions of users' channel vectors can be effectively aligned, which
facilitates the implementation of NOMA. Both analytical and simulation results
are provided to demonstrate the performance of the proposed IRS-NOMA scheme and
also study the impact of hardware impairments on IRS-NOMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09936</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09936</id><created>2019-07-23</created><authors><author><keyname>Wedekind</keyname><forenames>Stephen</forenames></author><author><keyname>Fraundorf</keyname><forenames>P.</forenames></author></authors><title>Log Complex Color for Visual Pattern Recognition of Total Sound</title><categories>cs.SD eess.AS</categories><comments>6 pages, 5 figures, 28 references, cf. http://tinyurl.com/color-rtsm</comments><journal-ref>Audio Engineering Society Convention 141 (2016) paper 9647;
  Subject of US patent 10,341,795</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  While traditional audio visualization methods depict amplitude intensities
vs. time, such as in a time-frequency spectrogram, and while some may use
complex phase information to augment the amplitude representation, such as in a
reassigned spectrogram, the phase data are not generally represented in their
own right. By plotting amplitude intensity as brightness/saturation and
phase-cycles as hue-variations, our complex spectrogram method displays both
amplitude and phase information simultaneously, making such images canonical
visual representations of the source wave. As a result, the original sound may
be precisely reconstructed (down to the original phases) from an image, simply
by reversing our process. This allows humans to apply our highly developed
visual pattern recognition skills to complete audio data in new way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09944</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09944</id><created>2019-07-23</created><updated>2019-08-10</updated><authors><author><keyname>Wang</keyname><forenames>Mingjin</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>An Overview of Enhanced Massive MIMO with Array Signal Processing
  Techniques</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/JSTSP.2019.2934931</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past ten years, there have been tremendous research progresses on
massive MIMO systems, most of which stand from the communications viewpoint. A
new trend of investigating massive MIMO, especially for the sparse scenario
like millimeter wave (mmWave) transmission, is to re-build the transceiver
design from array signal processing viewpoint that could deeply exploit the
half-wavelength array and provide enhanced performances in many aspects. For
example, the high dimensional channel could be decomposed into small amount of
physical parameters, e.g., angle of arrival (AoA), angle of departure (AoD),
multi-path delay, Doppler shift, etc. As a consequence, transceiver techniques
like synchronization, channel estimation, beamforming, precoding, multi-user
access, etc., can be re-shaped with these physical parameters, as opposed to
those designed directly with channel state information (CSI). Interestingly,
parameters like AoA/AoD and multi-path delay are frequency insensitive and thus
can be used to guide the down-link transmission from uplink training even for
FDD systems. Moreover, some phenomena of massive MIMO that were vaguely
revealed previously can be better explained now with array signal processing,
e.g., the beam squint effect. In all, the target of this paper is to present an
overview of recent progress on merging array signal processing into massive
MIMO communications as well as its promising future directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09949</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09949</id><created>2019-07-21</created><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cheng</keyname><forenames>Peng</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>A Learning-Based Two-Stage Spectrum Sharing Strategy with Multiple
  Primary Transmit Power Levels</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><comments>46 pages, 10 figures, accepted by IEEE Transactions on Signal
  Processing 2019</comments><doi>10.1109/TSP.2019.2932866</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-parameter cognition in a cognitive radio network (CRN) provides a more
thorough understanding of the radio environments, and could potentially lead to
far more intelligent and efficient spectrum usage for a secondary user. In this
paper, we investigate the multi-parameter cognition problem for a CRN where the
primary transmitter (PT) radiates multiple transmit power levels, and propose a
learning-based two-stage spectrum sharing strategy. We first propose a
data-driven/machine learning based multi-level spectrum sensing scheme,
including the spectrum learning (Stage I) and prediction (the first part in
Stage II). This fully blind sensing scheme does not require any prior knowledge
of the PT power characteristics. Then, based on a novel normalized power level
alignment metric, we propose two prediction-transmission structures, namely
periodic and non-periodic, for spectrum access (the second part in Stage II),
which enable the secondary transmitter (ST) to closely follow the PT power
level variation. The periodic structure features a fixed prediction interval,
while the non-periodic one dynamically determines the interval with a proposed
reinforcement learning algorithm to further improve the alignment metric.
Finally, we extend the prediction-transmission structure to an online scenario,
where the number of PT power levels might change as a consequence of PT
adapting to the environment fluctuation or quality of service variation. The
simulation results demonstrate the effectiveness of the proposed strategy in
various scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09951</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09951</id><created>2019-07-23</created><updated>2019-09-13</updated><authors><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Wiedeman</keyname><forenames>Christopher</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author><author><keyname>Yang</keyname><forenames>Yang</forenames></author></authors><title>Simultaneous reconstruction of the initial pressure and sound speed in
  photoacoustic tomography using a deep-learning approach</title><categories>eess.IV cs.LG</categories><doi>10.1117/12.2529984</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic tomography seeks to reconstruct an acoustic initial pressure
distribution from the measurement of the ultrasound waveforms. Conventional
methods assume a-prior knowledge of the sound speed distribution, which
practically is unknown. One way to circumvent the issue is to simultaneously
reconstruct both the acoustic initial pressure and speed. In this article, we
develop a novel data-driven method that integrates an advanced deep neural
network through model-based iteration. The image of the initial pressure is
significantly improved in our numerical simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09972</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09972</id><created>2019-07-23</created><updated>2020-01-16</updated><authors><author><keyname>Brendel</keyname><forenames>Andreas</forenames></author><author><keyname>Haubner</keyname><forenames>Thomas</forenames></author><author><keyname>Kellermann</keyname><forenames>Walter</forenames></author></authors><title>Spatially Informed Independent Vector Analysis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Maximum A Posteriori (MAP) derivation of the Independent Vector
Analysis (IVA) algorithm, a blind source separation algorithm, by incorporating
a prior over the demixing matrices, relying on a free-field model. In this way,
the outer permutation ambiguity of IVA is avoided. The resulting MAP
optimization problem is solved by deriving majorize-minimize update rules to
achieve convergence speed comparable to the well-known auxiliary function IVA
algorithm. The performance of the proposed algorithm is investigated and
compared to a benchmark algorithm using real measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09973</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09973</id><created>2019-07-23</created><authors><author><keyname>Cucuzzella</keyname><forenames>Michele</forenames></author><author><keyname>Kosaraju</keyname><forenames>Krishna Chaitanya</forenames></author><author><keyname>Scherpen</keyname><forenames>Jacquelien M. A.</forenames></author></authors><title>Voltage control of DC networks: robustness for unknown ZIP-loads</title><categories>eess.SY cs.SY</categories><comments>M. Cucuzzella and K. C. Kosaraju have given equivalent contribution</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we propose a new passivity-based control technique for DC power
networks comprising the so-called ZIP-loads, i.e., nonlinear loads with the
parallel combination of unknown constant impedance (Z), current (I) and power
(P) components. More precisely, we propose a novel passifying input and a
storage function based on the so-called mixed potential function introduced by
Brayton and Moser, leading to a novel passivity property with output
port-variable equal to the first time derivative of the voltage. Differently
from the existing results in the literature, where restrictive (sufficient)
conditions on Z, P and the voltage reference are assumed to be satisfied, we
establish a passivity property for every positive voltage reference and every
type of load. Consequently, we develop a new decentralized passivity-based
control scheme that is robust with respect to the uncertainty affecting the
ZIP-loads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09974</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09974</id><created>2019-07-23</created><authors><author><keyname>Neary-Zajiczek</keyname><forenames>Lydia</forenames></author><author><keyname>Essmann</keyname><forenames>Clara</forenames></author><author><keyname>Clancy</keyname><forenames>Neil</forenames></author><author><keyname>Haider</keyname><forenames>Aiman</forenames></author><author><keyname>Miranda</keyname><forenames>Elena</forenames></author><author><keyname>Shaw</keyname><forenames>Michael</forenames></author><author><keyname>Gander</keyname><forenames>Amir</forenames></author><author><keyname>Davidson</keyname><forenames>Brian</forenames></author><author><keyname>Fernandez-Reyes</keyname><forenames>Delmiro</forenames></author><author><keyname>Pawar</keyname><forenames>Vijay</forenames></author><author><keyname>Stoyanov</keyname><forenames>Danail</forenames></author></authors><title>Whole-Sample Mapping of Cancerous and Benign Tissue Properties</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted at MICCAI2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural and mechanical differences between cancerous and healthy tissue
give rise to variations in macroscopic properties such as visual appearance and
elastic modulus that show promise as signatures for early cancer detection.
Atomic force microscopy (AFM) has been used to measure significant differences
in stiffness between cancerous and healthy cells owing to its high force
sensitivity and spatial resolution, however due to absorption and scattering of
light, it is often challenging to accurately locate where AFM measurements have
been made on a bulk tissue sample. In this paper we describe an image
registration method that localizes AFM elastic stiffness measurements with
high-resolution images of haematoxylin and eosin (H\&amp;E)-stained tissue to
within 1.5 microns. Color RGB images are segmented into three structure types
(lumen, cells and stroma) by a neural network classifier trained on
ground-truth pixel data obtained through k-means clustering in HSV color space.
Using the localized stiffness maps and corresponding structural information, a
whole-sample stiffness map is generated with a region matching and
interpolation algorithm that associates similar structures with measured
stiffness values. We present results showing significant differences in
stiffness between healthy and cancerous liver tissue and discuss potential
applications of this technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09979</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09979</id><created>2019-07-23</created><authors><author><keyname>Suzuki</keyname><forenames>Atsushi</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Efficient PageRank Computation via Distributed Algorithms with Web
  Clustering</title><categories>eess.SY cs.SY</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PageRank is a well-known centrality measure for the web used in search
engines, representing the importance of each web page. In this paper, we follow
the line of recent research on the development of distributed algorithms for
computation of PageRank, where each page computes its own PageRank value by
interacting with pages connected over hyperlinks. Our approach is novel in that
it is based on a reinterpretation of PageRank, which leads us to a set of
algorithms with exponential convergence rates. We first employ gossip-type
randomization for the page selections in the update iterations. Then, the
algorithms are generalized to deterministic ones, allowing simultaneous updates
by multiple pages. Finally, based on these algorithms, we propose a
clustering-based scheme, in which groups of pages make updates by locally
interacting among themselves many times to expedite the convergence. In
comparison with other existing techniques, significant advantages can be
exhibited in their convergence performance, as demonstrated via numerical
examples using real web data, and also in the limited amount of communication
required among pages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09983</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09983</id><created>2019-07-23</created><updated>2019-12-17</updated><authors><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Biffi</keyname><forenames>Carlo</forenames></author><author><keyname>Tarroni</keyname><forenames>Giacomo</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Learning Shape Priors for Robust Cardiac MR Segmentation from Multi-view
  Images</title><categories>eess.IV cs.CV cs.LG</categories><comments>11 pages, 5 figures, accepted at MICCAI 2019, Camera-ready version</comments><doi>10.1007/978-3-030-32245-8_58</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cardiac MR image segmentation is essential for the morphological and
functional analysis of the heart. Inspired by how experienced clinicians assess
the cardiac morphology and function across multiple standard views (i.e. long-
and short-axis views), we propose a novel approach which learns anatomical
shape priors across different 2D standard views and leverages these priors to
segment the left ventricular (LV) myocardium from short-axis MR image stacks.
The proposed segmentation method has the advantage of being a 2D network but at
the same time incorporates spatial context from multiple, complementary views
that span a 3D space. Our method achieves accurate and robust segmentation of
the myocardium across different short-axis slices (from apex to base),
outperforming baseline models (e.g. 2D U-Net, 3D U-Net) while achieving higher
data efficiency. Compared to the 2D U-Net, the proposed method reduces the mean
Hausdorff distance (mm) from 3.24 to 2.49 on the apical slices, from 2.34 to
2.09 on the middle slices and from 3.62 to 2.76 on the basal slices on the test
set, when only 10% of the training data was used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09987</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.09987</id><created>2019-07-22</created><authors><author><keyname>Patel</keyname><forenames>Dhruv</forenames></author><author><keyname>Oberai</keyname><forenames>Assad A</forenames></author></authors><title>Bayesian Inference with Generative Adversarial Network Priors</title><categories>stat.ML cs.LG eess.IV physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian inference is used extensively to infer and to quantify the
uncertainty in a field of interest from a measurement of a related field when
the two are linked by a physical model. Despite its many applications, Bayesian
inference faces challenges when inferring fields that have discrete
representations of large dimension, and/or have prior distributions that are
difficult to represent mathematically. In this manuscript we consider the use
of Generative Adversarial Networks (GANs) in addressing these challenges. A GAN
is a type of deep neural network equipped with the ability to learn the
distribution implied by multiple samples of a given field. Once trained on
these samples, the generator component of a GAN maps the iid components of a
low-dimensional latent vector to an approximation of the distribution of the
field of interest. In this work we demonstrate how this approximate
distribution may be used as a prior in a Bayesian update, and how it addresses
the challenges associated with characterizing complex prior distributions and
the large dimension of the inferred field. We demonstrate the efficacy of this
approach by applying it to the problem of inferring and quantifying uncertainty
in the initial temperature field in a heat conduction problem from a noisy
measurement of the temperature at later time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10001</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10001</id><created>2019-07-23</created><authors><author><keyname>Islam</keyname><forenames>S. M. Riazul</forenames></author><author><keyname>Zeng</keyname><forenames>Ming</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung-Sup</forenames></author></authors><title>Non-Orthogonal Multiple Access (NOMA): How It Meets 5G and Beyond</title><categories>cs.IT eess.SP math.IT</categories><comments>38 pages, 9 figures, Wiley 5G Ref</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to massive connectivity and increasing demands of various services and
data-hungry applications, a full-scale implementation of the fifth generation
(5G) wireless systems requires more effective radio access techniques. In this
regard, non-orthogonal multiple access (NOMA) has recently gained ever-growing
attention from both academia and industry. Compared to orthogonal multiple
access (OMA) techniques, NOMA is superior in terms of spectral efficiency and
is thus appropriate for 5G and Beyond. In this article, we provide an overview
of NOMA principles and applications. Specifically, the article discusses the
fundamentals of power-domain NOMA with single and multiple antennas in both
uplink and downlink settings. In addition, the basic principles of code-domain
NOMA are elaborated. Further, the article explains various resource allocation
techniques such as user pairing and power allocation for NOMA systems;
discusses the basic form of cooperative NOMA and its variants; and addresses
several opportunities and challenges associated with the compatibility of NOMA
with other advanced communication paradigms such as heterogeneous networks and
millimeter wave communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10032</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10032</id><created>2019-07-20</created><updated>2019-08-02</updated><authors><author><keyname>Zhang</keyname><forenames>Dong</forenames></author><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Zhao</keyname><forenames>Shu</forenames></author><author><keyname>Zhang</keyname><forenames>Yanping</forenames></author><author><keyname>Zhang</keyname><forenames>Heye</forenames></author><author><keyname>Li</keyname><forenames>Shuo</forenames></author></authors><title>Direct Quantification for Coronary Artery Stenosis Using Multiview
  Learning</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quantification of the coronary artery stenosis is of significant clinical
importance in coronary artery disease diagnosis and intervention treatment. It
aims to quantify the morphological indices of the coronary artery lesions such
as minimum lumen diameter, reference vessel diameter, lesion length, and these
indices are the reference of the interventional stent placement. In this study,
we propose a direct multiview quantitative coronary angiography (DMQCA) model
as an automatic clinical tool to quantify the coronary artery stenosis from
X-ray coronary angiography images. The proposed DMQCA model consists of a
multiview module with two attention mechanisms, a key-frame module, and a
regression module, to achieve direct accurate multiple-index estimation. The
multi-view module comprehensively learns the Spatio-temporal features of
coronary arteries through a three-dimensional convolution. The attention
mechanisms of each view focus on the subtle feature of the lesion region and
capture the important context information. The key-frame module learns the
subtle features of the stenosis through successive dilated residual blocks. The
regression module finally generates the indices estimation from multiple
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10033</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10033</id><created>2019-07-19</created><authors><author><keyname>Duan</keyname><forenames>Jinming</forenames></author><author><keyname>Schlemper</keyname><forenames>Jo</forenames></author><author><keyname>Qin</keyname><forenames>Chen</forenames></author><author><keyname>Ouyang</keyname><forenames>Cheng</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author><author><keyname>Biffi</keyname><forenames>Carlo</forenames></author><author><keyname>Bello</keyname><forenames>Ghalib</forenames></author><author><keyname>Statton</keyname><forenames>Ben</forenames></author><author><keyname>O'Regan</keyname><forenames>Declan P</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>VS-Net: Variable splitting network for accelerated parallel MRI
  reconstruction</title><categories>eess.IV cs.CV</categories><comments>Accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a deep learning approach for parallel magnetic
resonance imaging (MRI) reconstruction, termed a variable splitting network
(VS-Net), for an efficient, high-quality reconstruction of undersampled
multi-coil MR data. We formulate the generalized parallel compressed sensing
reconstruction as an energy minimization problem, for which a variable
splitting optimization method is derived. Based on this formulation we propose
a novel, end-to-end trainable deep neural network architecture by unrolling the
resulting iterative process of such variable splitting scheme. VS-Net is
evaluated on complex valued multi-coil knee images for 4-fold and 6-fold
acceleration factors. We show that VS-Net outperforms state-of-the-art deep
learning reconstruction algorithms, in terms of reconstruction accuracy and
perceptual quality. Our code is publicly available at
https://github.com/j-duan/VS-Net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10085</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10085</id><created>2019-07-23</created><updated>2019-07-25</updated><authors><author><keyname>Aviles-Rivero</keyname><forenames>Angelica I.</forenames></author><author><keyname>Papadakis</keyname><forenames>Nicolas</forenames></author><author><keyname>Li</keyname><forenames>Ruoteng</forenames></author><author><keyname>Sellars</keyname><forenames>Philip</forenames></author><author><keyname>Fan</keyname><forenames>Qingnan</forenames></author><author><keyname>Tan</keyname><forenames>Robby T.</forenames></author><author><keyname>Sch&#xf6;nlieb</keyname><forenames>Carola-Bibiane</forenames></author></authors><title>GraphX$^{NET}-$ Chest X-Ray Classification Under Extreme Minimal
  Supervision</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of classifying X-ray data is a problem of both theoretical and
clinical interest. Whilst supervised deep learning methods rely upon huge
amounts of labelled data, the critical problem of achieving a good
classification accuracy when an extremely small amount of labelled data is
available has yet to be tackled. In this work, we introduce a novel
semi-supervised framework for X-ray classification which is based on a
graph-based optimisation model. To the best of our knowledge, this is the first
method that exploits graph-based semi-supervised learning for X-ray data
classification. Furthermore, we introduce a new multi-class classification
functional with carefully selected class priors which allows for a smooth
solution that strengthens the synergy between the limited number of labels and
the huge amount of unlabelled data. We demonstrate, through a set of numerical
and visual experiments, that our method produces highly competitive results on
the ChestX-ray14 data set whilst drastically reducing the need for annotated
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10086</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10086</id><created>2019-07-23</created><updated>2019-11-11</updated><authors><author><keyname>Savelli</keyname><forenames>Iacopo</forenames></author><author><keyname>De Paola</keyname><forenames>Antonio</forenames></author><author><keyname>Li</keyname><forenames>Furong</forenames></author></authors><title>Ex-ante dynamic network tariffs for transmission cost recovery</title><categories>eess.SY cs.SY</categories><doi>10.1016/j.apenergy.2019.113979</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper proposes a novel tariff scheme and a new optimization framework in
order to address the recovery of fixed investment costs in transmission network
planning, particularly against rising demand elasticity. At the moment, ex-post
network tariffs are utilized in addition to congestion revenues to fully
recover network costs, which often leads to over/under fixed cost recovery,
thus increasing the investment risk. Furthermore, in the case of agents with
elastic market curves, ex-post tariffs can cause several inefficiencies, such
as mistrustful bidding to exploit ex-post schemes, imperfect information in
applied costs and cleared quantities, and negative surplus for marginal
generators and consumers. These problems are exacerbated by the increasing
price-elasticity of demand, caused for example by the diffusion of demand
response technologies. To address these issues, we design a dynamic ex-ante
tariff scheme that explicitly accounts for the effect of tariffs in the
longterm network planning problem and in the underlying market clearing
process. Using linearization techniques and a novel reformulation of the
congestion rent, the long-term network planning problem is reformulated as a
single mixed-integer linear problem which returns the combined optimal values
of network expansion and associated tariffs, while accounting for price-elastic
agents and lumpy investments. The advantages of the proposed approach in terms
of cost recovery, market equilibrium and increased social welfare are discussed
qualitatively and are validated in numerical case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10102</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10102</id><created>2019-07-23</created><authors><author><keyname>Ho</keyname><forenames>Tai Manh</forenames></author><author><keyname>Tran</keyname><forenames>Thinh Duy</forenames></author><author><keyname>Nguyen</keyname><forenames>Ti Ti</forenames></author><author><keyname>Kazmi</keyname><forenames>S. M. Ahsan</forenames></author><author><keyname>Le</keyname><forenames>Long Bao</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Next-generation Wireless Solutions for the Smart Factory, Smart
  Vehicles, the Smart Grid and Smart Cities</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G wireless systems will extend mobile communication services beyond mobile
telephony, mobile broadband, and massive machine-type communication into new
application domains, namely the so-called vertical domains including the smart
factory, smart vehicles, smart grid, smart city, etc. Supporting these vertical
domains comes with demanding requirements: high-availability, high-reliability,
low-latency, and in some cases, high-accuracy positioning. In this survey, we
first identify the potential key performance requirements of 5G communication
in support of automation in the vertical domains and highlight the 5G enabling
technologies conceived for meeting these requirements. We then discuss the key
challenges faced both by industry and academia which have to be addressed in
order to support automation in the vertical domains. We also provide a survey
of the related research dedicated to automation in the vertical domains.
Finally, our vision of 6G wireless systems is discussed briefly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10105</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10105</id><created>2019-07-23</created><updated>2020-01-01</updated><authors><author><keyname>Qian</keyname><forenames>Yanjun</forenames></author><author><keyname>Xu</keyname><forenames>Jiaxi</forenames></author><author><keyname>Drummy</keyname><forenames>Lawrence F.</forenames></author><author><keyname>Ding</keyname><forenames>Yu</forenames></author></authors><title>Effective Super-Resolution Method for Paired Electron Microscopic Images</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with investigating super-resolution algorithms and
solutions for handling electron microscopic images. We note two main aspects
differentiating the problem discussed here from those considered in the
literature. The first difference is that in the electron imaging setting, we
have a pair of physical high-resolution and low-resolution images, rather than
a physical image with its downsampled counterpart. The high-resolution image
covers about 25% of the view field of the low-resolution image, and the
objective is to enhance the area of the low-resolution image where there is no
high-resolution counterpart. The second difference is that the physics behind
electron imaging is different from that of optical (visible light) photos. The
implication is that super-resolution models trained by optical photos are not
effective when applied to electron images. Focusing on the unique properties,
we devise a global and local registration method to match the high- and
low-resolution image patches and explore training strategies for applying deep
learning super-resolution methods to the paired electron images. We also
present a simple, non-local-mean approach as an alternative. This simple
alternative performs as a close runner-up to the deep learning approaches, but
it takes less time to train and entertains better interpretability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10126</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10126</id><created>2019-07-23</created><authors><author><keyname>Giordani</keyname><forenames>Marco</forenames></author><author><keyname>Shimizu</keyname><forenames>Takayuki</forenames></author><author><keyname>Zanella</keyname><forenames>Andrea</forenames></author><author><keyname>Higuchi</keyname><forenames>Takamasa</forenames></author><author><keyname>Altintas</keyname><forenames>Onur</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author></authors><title>Path Loss Models for V2V mmWave Communication: Performance Evaluation
  and Open Challenges</title><categories>cs.NI eess.SP</categories><comments>5 pages, 3 figures, 4 tables. Accepted to the IEEE 2nd Connected and
  Automated Vehicles Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, millimeter wave (mmWave) bands have been investigated as a means to
enhance automated driving and address the challenging data rate and latency
demands of emerging automotive applications. For the development of those
systems to operate in bands above 6 GHz, there is a need to have accurate
channel models able to predict the peculiarities of the vehicular propagation
at these bands, especially as far as Vehicle-to-Vehicle (V2V) communications
are concerned. In this paper, we validate the channel model that the 3GPP has
proposed for NR-V2X systems, which (i) supports deployment scenarios for
urban/highway propagation, and (ii) incorporates the effects of path loss,
shadowing, line of sight probability, and static/dynamic blockage attenuation.
We also exemplify the impact of several automotive-specific parameters on the
overall network performance considering realistic system-level simulation
assumptions for typical scenarios. Finally, we highlight potential
inconsistencies of the model and provide recommendations for future measurement
campaigns in vehicular environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10128</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10128</id><created>2019-07-23</created><authors><author><keyname>Sahu</keyname><forenames>Siddhant</forenames></author><author><keyname>Lenka</keyname><forenames>Manoj Kumar</forenames></author><author><keyname>Sa</keyname><forenames>Pankaj Kumar</forenames></author></authors><title>Blind Deblurring using Deep Learning: A Survey</title><categories>eess.IV cs.CV</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We inspect all the deep learning based solutions and provide holistic
understanding of various architectures that have evolved over the past few
years to solve blind deblurring. The introductory work used deep learning to
estimate some features of the blur kernel and then moved onto predicting the
blur kernel entirely, which converts the problem into non-blind deblurring. The
recent state of the art techniques are end to end, i.e., they don't estimate
the blur kernel rather try to estimate the latent sharp image directly from the
blurred image. The benchmarking PSNR and SSIM values on standard datasets of
GOPRO and Kohler using various architectures are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10132</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10132</id><created>2019-07-23</created><updated>2020-01-30</updated><authors><author><keyname>Kloenne</keyname><forenames>Marie</forenames></author><author><keyname>Niehaus</keyname><forenames>Sebastian</forenames></author><author><keyname>Lampe</keyname><forenames>Leonie</forenames></author><author><keyname>Merola</keyname><forenames>Alberto</forenames></author><author><keyname>Reinelt</keyname><forenames>Janis</forenames></author><author><keyname>Roeder</keyname><forenames>Ingo</forenames></author><author><keyname>Scherf</keyname><forenames>Nico</forenames></author></authors><title>Domain specific cues improve robustness of deep learning based
  segmentation of ct volumes</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Learning has considerably improved medical image analysis in the past
years. Although data-driven approaches are intrinsically adaptive and thus,
generic, they often do not perform the same way on data from different imaging
modalities. In particular Computed tomography (CT) data poses many challenges
to medical image segmentation based on convolutional neural networks (CNNs),
mostly due to the broad dynamic range of intensities and the varying number of
recorded slices of CT volumes. In this paper, we address these issues with a
framework that combines domain-specific data preprocessing and augmentation
with state-of-the-art CNN architectures. The focus is not limited to optimise
the score, but also to stabilise the prediction performance since this is a
mandatory requirement for use in automated and semi-automated workflows in the
clinical environment.
  The framework is validated with an architecture comparison to show CNN
architecture-independent effects of our framework functionality. We compare a
modified U-Net and a modified Mixed-Scale Dense Network (MS-D Net) to compare
dilated convolutions for parallel multi-scale processing to the U-Net approach
based on traditional scaling operations. Finally, we propose an ensemble model
combining the strengths of different individual methods. The framework performs
well on a range of tasks such as liver and kidney segmentation, without
significant differences in prediction performance on strongly differing volume
sizes and varying slice thickness. Thus our framework is an essential step
towards performing robust segmentation of unknown real-world samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10185</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10185</id><created>2019-07-23</created><authors><author><keyname>Tobing</keyname><forenames>Patrick Lumban</forenames></author><author><keyname>Wu</keyname><forenames>Yi-Chiao</forenames></author><author><keyname>Hayashi</keyname><forenames>Tomoki</forenames></author><author><keyname>Kobayashi</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author></authors><title>Non-Parallel Voice Conversion with Cyclic Variational Autoencoder</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel technique for a non-parallel voice
conversion (VC) with the use of cyclic variational autoencoder (CycleVAE)-based
spectral modeling. In a variational autoencoder(VAE) framework, a latent space,
usually with a Gaussian prior, is used to encode a set of input features. In a
VAE-based VC, the encoded latent features are fed into a decoder, along with
speaker-coding features, to generate estimated spectra with either the original
speaker identity (reconstructed) or another speaker identity (converted). Due
to the non-parallel modeling condition, the converted spectra can not be
directly optimized, which heavily degrades the performance of a VAE-based VC.
In this work, to overcome this problem, we propose to use CycleVAE-based
spectral model that indirectly optimizes the conversion flow by recycling the
converted features back into the system to obtain corresponding cyclic
reconstructed spectra that can be directly optimized. The cyclic flow can be
continued by using the cyclic reconstructed features as input for the next
cycle. The experimental results demonstrate the effectiveness of the proposed
CycleVAE-based VC, which yields higher accuracy of converted spectra, generates
latent features with higher correlation degree, and significantly improves the
quality and conversion accuracy of the converted speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10210</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10210</id><created>2019-07-23</created><authors><author><keyname>Zhu</keyname><forenames>Jian</forenames></author><author><keyname>Styler</keyname><forenames>Will</forenames></author><author><keyname>Calloway</keyname><forenames>Ian</forenames></author></authors><title>A CNN-based tool for automatic tongue contour tracking in ultrasound
  images</title><categories>eess.IV cs.CL cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  For speech research, ultrasound tongue imaging provides a non-invasive means
for visualizing tongue position and movement during articulation. Extracting
tongue contours from ultrasound images is a basic step in analyzing ultrasound
data but this task often requires non-trivial manual annotation. This study
presents an open source tool for fully automatic tracking of tongue contours in
ultrasound frames using neural network based methods. We have implemented and
systematically compared two convolutional neural networks, U-Net and
DenseU-Net, under different conditions. Though both models can perform
automatic contour tracking with comparable accuracy, Dense U-Net architecture
seems more generalizable across test datasets while U-Net has faster extraction
speed. Our comparison also shows that the choice of loss function and data
augmentation have a greater effect on tracking performance in this task. This
public available segmentation tool shows considerable promise for the automated
tongue contour annotation of ultrasound images in speech research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10211</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10211</id><created>2019-07-23</created><authors><author><keyname>Zhu</keyname><forenames>Yi</forenames></author><author><keyname>Newsam</keyname><forenames>Shawn</forenames></author></authors><title>Motion-Aware Feature for Improved Video Anomaly Detection</title><categories>cs.CV cs.LG eess.IV</categories><comments>BMVC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by our observation that motion information is the key to good
anomaly detection performance in video, we propose a temporal augmented network
to learn a motion-aware feature. This feature alone can achieve competitive
performance with previous state-of-the-art methods, and when combined with
them, can achieve significant performance improvements. Furthermore, we
incorporate temporal context into the Multiple Instance Learning (MIL) ranking
model by using an attention block. The learned attention weights can help to
differentiate between anomalous and normal video segments better. With the
proposed motion-aware feature and the temporal MIL ranking model, we outperform
previous approaches by a large margin on both anomaly detection and anomalous
action recognition tasks in the UCF Crime dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10213</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10213</id><created>2019-07-23</created><authors><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Wang</keyname><forenames>Huafeng</forenames></author><author><keyname>Yang</keyname><forenames>Sichen</forenames></author></authors><title>Image Super-Resolution Using a Wavelet-based Generative Adversarial
  Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of super-resolution recons-truction.
This is a hot topic because super-resolution reconstruction has a wide range of
applications in the medical field, remote sensing monitoring, and criminal
investigation. Compared with traditional algorithms, the current
super-resolution reconstruction algorithm based on deep learning greatly
improves the clarity of reconstructed pictures. Existing work like
Super-Resolution Using a Generative Adversarial Network (SRGAN) can effectively
restore the texture details of the image. However, experimentally verified that
the texture details of the image recovered by the SRGAN are not robust. In
order to get super-resolution reconstructed images with richer high-frequency
details, we improve the network structure and propose a super-resolution
reconstruction algorithm combining wavelet transform and Generative Adversarial
Network. The proposed algorithm can efficiently reconstruct high-resolution
images with rich global information and local texture details. We have trained
our model by PyTorch framework and VOC2012 dataset, and tested it by Set5,
Set14, BSD100 and Urban100 test datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10242</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10242</id><created>2019-07-24</created><authors><author><keyname>Zhang</keyname><forenames>Jingwei</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Receding Horizon Optimization for Energy-Efficient UAV Communication</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we study a wireless communication system with a fixed-wing
unmanned aerial vehicle (UAV) employed to collect information from a group of
ground nodes (GNs). Our objective is to maximize the UAV's energy efficiency
(EE), which is defined as the achievable rate among all GNs per unit propulsion
energy consumption of the UAV. To efficiently solve this problem with
continuous-time functions, we propose a new method based on receding horizon
optimization (RHO), which significantly reduces the computational complexity
compared to the conventional time discretization method. Specifically, we
sequentially solve the EE maximization problem over a moving time-window of
finite duration, for each of which the number of optimization variables is
greatly reduced. Simulation results are provided to show the effectiveness of
the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10257</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10257</id><created>2019-07-24</created><updated>2020-02-23</updated><authors><author><keyname>Khan</keyname><forenames>Shujaat</forenames></author><author><keyname>Huh</keyname><forenames>Jaeyoung</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Adaptive and Compressive Beamforming Using Deep Learning for Medical
  Ultrasound</title><categories>eess.IV cs.CV cs.LG</categories><comments>This is a significantly extended version of the original paper in
  arXiv:1901.01706. This paper is accepted for IEEE Transactions on
  Ultrasonics, Ferroelectrics, and Frequency Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ultrasound (US) imaging, various types of adaptive beamforming techniques
have been investigated to improve the resolution and contrast-to-noise ratio of
the delay and sum (DAS) beamformers. Unfortunately, the performance of these
adaptive beamforming approaches degrade when the underlying model is not
sufficiently accurate and the number of channels decreases. To address this
problem, here we propose a deep learning-based beamformer to generate
significantly improved images over widely varying measurement conditions and
channel subsampling patterns. In particular, our deep neural network is
designed to directly process full or sub-sampled radio-frequency (RF) data
acquired at various subsampling rates and detector configurations so that it
can generate high quality ultrasound images using a single beamformer. The
origin of such input-dependent adaptivity is also theoretically analyzed.
Experimental results using B-mode focused ultrasound confirm the efficacy of
the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10258</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10258</id><created>2019-07-24</created><updated>2019-07-29</updated><authors><author><keyname>Zhou</keyname><forenames>Qingyi</forenames></author><author><keyname>Yang</keyname><forenames>Chuanchuan</forenames></author></authors><title>AdaNN: Adaptive Neural Network-based Equalizer via Online
  Semi-supervised Learning</title><categories>eess.SP</categories><comments>12 pages, 15 figures, 2 tables</comments><msc-class>94</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The demand for high speed data transmission has increased rapidly over the
past few years, leading to the development of advanced optical communication
techniques. At this point, nonlinear effects caused by optical fiber
characteristics and non-ideal devices are becoming significant, limiting the
achievable transmission distance and channel capacity of high speed optical
communication systems. Such effects cannot be equalized efficiently using
conventional equalizers. In the past few years, multiple equalizers based on
neural network (NN) have been proposed to recover signal from nonlinear
distortions. However, previous experiments mainly focused on achieving low bit
error rate (BER) on certain dataset with an offline-trained NN, neglecting the
generalization ability of NN-based equalizer when the properties of optical
link change. Few people are committed to developing efficient online training
scheme, which hinders the application of NN-based equalizers. In this paper,
we've proposed an adaptive online training scheme, which can be used to
fine-tune parameters of NN-based equalizer without the help of training
sequence. The online training scheme originates from decision-directed adaptive
equalization. By combining it with data augmentation and virtual adversarial
training, we've successfully increased the convergence speed by 4.5 times. The
proposed adaptive NN-based equalizer is called &quot;AdaNN&quot;. Its BER has been
evaluated over a 56 Gb/s PAM4-modulated VCSEL-MMF optical link, showing
performance improvement compared with non-adaptive NN-based equalizer and
conventional MLSE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10267</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10267</id><created>2019-07-24</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Zhang</keyname><forenames>Heye</forenames></author><author><keyname>Zhang</keyname><forenames>Yanping</forenames></author><author><keyname>Zhao</keyname><forenames>Shu</forenames></author><author><keyname>Mohiaddin</keyname><forenames>Raad</forenames></author><author><keyname>Wong</keyname><forenames>Tom</forenames></author><author><keyname>Firmin</keyname><forenames>David</forenames></author><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Keegan</keyname><forenames>Jennifer</forenames></author></authors><title>Discriminative Consistent Domain Generation for Semi-supervised Learning</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning based task systems normally rely on a large amount of manually
labeled training data, which is expensive to obtain and subject to operator
variations. Moreover, it does not always hold that the manually labeled data
and the unlabeled data are sitting in the same distribution. In this paper, we
alleviate these problems by proposing a discriminative consistent domain
generation (DCDG) approach to achieve a semi-supervised learning. The
discriminative consistent domain is achieved by a double-sided domain
adaptation. The double-sided domain adaptation aims to make a fusion of the
feature spaces of labeled data and unlabeled data. In this way, we can fit the
differences of various distributions between labeled data and unlabeled data.
In order to keep the discriminativeness of generated consistent domain for the
task learning, we apply an indirect learning for the double-sided domain
adaptation. Based on the generated discriminative consistent domain, we can use
the unlabeled data to learn the task model along with the labeled data via a
consistent image generation. We demonstrate the performance of our proposed
DCDG on the late gadolinium enhancement cardiac MRI (LGE-CMRI) images acquired
from patients with atrial fibrillation in two clinical centers for the
segmentation of the left atrium anatomy (LA) and proximal pulmonary veins
(PVs). The experiments show that our semi-supervised approach achieves
compelling segmentation results, which can prove the robustness of DCDG for the
semi-supervised learning using the unlabeled data along with labeled data
acquired from a single center or multicenter studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10273</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10273</id><created>2019-07-24</created><authors><author><keyname>Thakallapelli</keyname><forenames>Abilash</forenames></author><author><keyname>Ghosh</keyname><forenames>Sudipta</forenames></author><author><keyname>Kamalasadan</keyname><forenames>Sukumar</forenames></author></authors><title>Real-time frequency based reduced order modeling of large power grid</title><categories>eess.SP cs.SY eess.SY</categories><comments>Real-time Simulator, Electromagnetic Simulation, Transient Stability
  Type Equivalent, Frequency Dependent Network Equivalent (FDNE), Recursive
  Least Square Identification (RLS)</comments><journal-ref>Power and Energy Society General Meeting, 2016, Boston, MA, USA</journal-ref><doi>10.1109/PESGM.2016.7741877</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large power systems are complex and real-time modeling of the grid for
electromagnetic simulation (EMT) studies is impractical. In general, there are
methods that reduce large power system into an equivalent network that requires
less computational resource, while preserving electromechanical (low frequency)
and high frequency behavior of the original system. This can be achieved by
modeling the area not of interest (external area) as a combination of Transient
Stability Analysis (TSA) type phasor model equivalent and Frequency Dependent
Network Equivalent (FDNE). TSA retains electromechanical behavior, whereas FDNE
retains high frequency behavior of the original power system. To this effect,
this paper introduces a method of developing FDNE based on an online recursive
least squares (RLS) identification algorithm in z-domain, and modeling of
reduced power systems as FDNE and as a combination of TSA and FDNE using
real-time digital simulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10275</identifier>
 <datestamp>2019-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10275</id><created>2019-07-24</created><updated>2019-11-06</updated><authors><author><keyname>Nambath</keyname><forenames>Nandakumar</forenames></author><author><keyname>Ashok</keyname><forenames>Rakesh</forenames></author><author><keyname>Manikandan</keyname><forenames>Sarath</forenames></author><author><keyname>Thaker</keyname><forenames>Nandish Bharat</forenames></author><author><keyname>Anghan</keyname><forenames>Mehul</forenames></author><author><keyname>Kamran</keyname><forenames>Rashmi</forenames></author><author><keyname>Anmadwar</keyname><forenames>Saurabh</forenames></author><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author></authors><title>All-Analog Adaptive Equalizer for Coherent Data Center Interconnects</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a high-speed coherent optical transmission system, typically the signals
obtained at the receiver front-end are digitized using very high-speed ADCs and
then processed in the digital domain to remove optical channel impairments. In
this work, we show that these signals can instead be processed in the analog
domain itself, which can significantly reduce the power consumption as well as
the complexity of the receiver. The first all-analog adaptive equalizer for
receivers of coherent dual-polarization optical links has been presented with
its detailed architecture and measurement results. The proof-of-concept
equalizer uses the constant modulus algorithm for blind adaptation of its
weight coefficients to implement a 4x4 2-tap FIR filter in 130 nm SiGe BiCMOS
technology. Its functionality is evaluated experimentally for 40 Gb /s data
rate and 10 km standard single-mode fiber channel. This demonstration shows
that the use of all-analog processing for short-reach data-center interconnects
is feasible and is a much simpler solution than the use of the high-speed
ADC+DSP based approach. Moreover, when implemented in advanced CMOS or FinFET
technologies, the power consumption of the equalizer is expected to be
significantly lower than the DSP based implementations in similar process
technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10283</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10283</id><created>2019-07-24</created><authors><author><keyname>Huang</keyname><forenames>Chia-Hung</forenames></author><author><keyname>Yin</keyname><forenames>Hang</forenames></author><author><keyname>Tai</keyname><forenames>Yu-Wing</forenames></author><author><keyname>Tang</keyname><forenames>Chi-Keung</forenames></author></authors><title>StableNet: Semi-Online, Multi-Scale Deep Video Stabilization</title><categories>cs.CV eess.IV</categories><comments>Chia-Hung and Hang have equal contribution</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video stabilization algorithms are of greater importance nowadays with the
prevalence of hand-held devices which unavoidably produce videos with
undesirable shaky motions. In this paper we propose a data-driven online video
stabilization method along with a paired dataset for deep learning. The network
processes each unsteady frame progressively in a multi-scale manner, from low
resolution to high resolution, and then outputs an affine transformation to
stabilize the frame. Different from conventional methods which require explicit
feature tracking or optical flow estimation, the underlying stabilization
process is learned implicitly from the training data, and the stabilization
process can be done online. Since there are limited public video stabilization
datasets available, we synthesized unstable videos with different extent of
shake that simulate real-life camera movement. Experiments show that our method
is able to outperform other stabilization methods in several unstable samples
while remaining comparable in general. Also, our method is tested on complex
contents and found robust enough to dampen these samples to some extent even it
was not explicitly trained in the contents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10293</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10293</id><created>2019-07-24</created><authors><author><keyname>Picallo</keyname><forenames>Miguel</forenames></author><author><keyname>Anta</keyname><forenames>Adolfo</forenames></author><author><keyname>De Schutter</keyname><forenames>Bart</forenames></author></authors><title>Stochastic Optimal Power Flow in Distribution Grids under Uncertainty
  from State Estimation</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing amount of controllable generation and consumption in
distribution grids poses a severe challenge in keeping voltage values within
admissible ranges. Existing approaches have considered different optimal power
flow formulations to regulate distributed generation and other controllable
elements. Nevertheless, distribution grids are characterized by an insufficient
number of sensors, and state estimation algorithms are required to monitor the
grid status. We consider in this paper the combined problem of optimal power
flow under state estimation, where the estimation uncertainty results into
stochastic constraints for the voltage magnitude levels instead of
deterministic ones. To solve the given problem efficiently and to bypass the
lack of load measurements, we use a linear approximation of the power flow
equations. Moreover, we derive a transformation of the stochastic constraints
to make them tractable without being too conservative. A case study shows the
success of our approach at keeping voltage within limits, and also shows how
ignoring the uncertainty in the estimation can lead to voltage level
violations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10310</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10310</id><created>2019-07-24</created><authors><author><keyname>Zhang</keyname><forenames>Haichao</forenames></author><author><keyname>Wang</keyname><forenames>Jianyu</forenames></author></authors><title>Towards Adversarially Robust Object Detection</title><categories>cs.CV cs.LG eess.IV</categories><comments>ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object detection is an important vision task and has emerged as an
indispensable component in many vision system, rendering its robustness as an
increasingly important performance factor for practical applications. While
object detection models have been demonstrated to be vulnerable against
adversarial attacks by many recent works, very few efforts have been devoted to
improving their robustness. In this work, we take an initial attempt towards
this direction. We first revisit and systematically analyze object detectors
and many recently developed attacks from the perspective of model robustness.
We then present a multi-task learning perspective of object detection and
identify an asymmetric role of task losses. We further develop an adversarial
training approach which can leverage the multiple sources of attacks for
improving the robustness of detection models. Extensive experiments on
PASCAL-VOC and MS-COCO verified the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10354</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10354</id><created>2019-07-24</created><authors><author><keyname>Ara&#xfa;jo</keyname><forenames>Ricardo J.</forenames></author><author><keyname>Garrido</keyname><forenames>Vera</forenames></author><author><keyname>Bara&#xe7;as</keyname><forenames>Catarina A.</forenames></author><author><keyname>Vasconcelos</keyname><forenames>Maria A.</forenames></author><author><keyname>Mavioso</keyname><forenames>Carlos</forenames></author><author><keyname>Anacleto</keyname><forenames>Jo&#xe3;o C.</forenames></author><author><keyname>Cardoso</keyname><forenames>Maria J.</forenames></author><author><keyname>Oliveira</keyname><forenames>H&#xe9;lder P.</forenames></author></authors><title>Computer Aided Detection of Deep Inferior Epigastric Perforators in
  Computed Tomography Angiography scans</title><categories>eess.IV cs.CV</categories><comments>26 pages, 2 tables, 9 figures, submitted to Computerized Medical
  Imaging and Graphics journal</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deep inferior epigastric artery perforator (DIEAP) flap is the most
common free flap used for breast reconstruction after a mastectomy. It makes
use of the skin and fat of the lower abdomen to build a new breast mound either
at the same time of the mastectomy or in a second surgery. This operation
requires preoperative imaging studies to evaluate the branches - the
perforators - that irrigate the tissue that will be used to reconstruct the
breast mound. These branches will support tissue viability after the
microsurgical ligation of the inferior epigastric vessels to the receptor
vessels in the thorax. Usually through a Computed Tomography Angiography (CTA),
each perforator, diameter and direction is manually identified by the imaging
team, who will subsequently draw a map for the identification of the best
vascular support for the reconstruction. In the current work we propose a
semi-automatic methodology that aims at reducing the time and subjectivity
inherent to the manual annotation. In 21 CTAs from patients proposed for breast
reconstruction with DIEAP flaps, the subcutaneous region of each perforator was
extracted, by means of a tracking procedure, whereas the intramuscular portion
was detected through a minimum cost approach. Both were subsequently compared
with the radiologist manual annotation. Results showed that the semi-automatic
procedure was able to correctly detect the course of the DIEAPs with a minimum
error (average error of 0.64 mm and 0.50 mm regarding the extraction of
subcutaneous and intramuscular paths, respectively). The objective methodology
is a promising tool in the automatic detection of perforators in CTA and can
contribute to spare human resources and reduce subjectivity in the
aforementioned task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10370</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10370</id><created>2019-07-24</created><updated>2019-07-29</updated><authors><author><keyname>Dubey</keyname><forenames>Kavita</forenames></author><author><keyname>Agarwal</keyname><forenames>Anant</forenames></author><author><keyname>Lathe</keyname><forenames>Astitwa Sarthak</forenames></author><author><keyname>Kumar</keyname><forenames>Ranjeet</forenames></author><author><keyname>Srivastava</keyname><forenames>Vishal</forenames></author></authors><title>Self-attention based BiLSTM-CNN classifier for the prediction of
  ischemic and non-ischemic cardiomyopathy</title><categories>cs.LG cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heart Failure is a major component of healthcare expenditure and a leading
cause of mortality worldwide. Despite higher inter-rater variability,
endomyocardial biopsy (EMB) is still regarded as the standard technique, used
to identify the cause (e.g. ischemic or non-ischemic cardiomyopathy, coronary
artery disease, myocardial infarction etc.) of unexplained heart failure. In
this paper, we focus on identifying cardiomyopathy as ischemic or non-ischemic.
For this, we propose and implement a new unified architecture comprising CNN
(inception-V3 model) and bidirectional LSTM (BiLSTM) with self-attention
mechanism to predict the ischemic or non-ischemic to classify cardiomyopathy
using histopathological images. The proposed model is based on self-attention
that implicitly focuses on the information outputted from the hidden layers of
BiLSTM. Through our results we demonstrate that this framework carries a high
learning capacity and is able to improve the classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10380</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10380</id><created>2019-07-23</created><authors><author><keyname>Bazin</keyname><forenames>Th&#xe9;is</forenames></author><author><keyname>Hadjeres</keyname><forenames>Ga&#xeb;tan</forenames></author></authors><title>NONOTO: A Model-agnostic Web Interface for Interactive Music Composition
  by Inpainting</title><categories>cs.HC cs.LG cs.SD eess.AS</categories><comments>3 pages, 1 figure. Published as a conference paper at the 10th
  International Conference on Computational Creativity (ICCC 2019), UNC
  Charlotte, North Carolina</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inpainting-based generative modeling allows for stimulating human-machine
interactions by letting users perform stylistically coherent local editions to
an object using a statistical model. We present NONOTO, a new interface for
interactive music generation based on inpainting models. It is aimed both at
researchers, by offering a simple and flexible API allowing them to connect
their own models with the interface, and at musicians by providing
industry-standard features such as audio playback, real-time MIDI output and
straightforward synchronization with DAWs using Ableton Link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10383</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10383</id><created>2019-07-24</created><authors><author><keyname>Marco</keyname><forenames>Alonso</forenames></author><author><keyname>Baumann</keyname><forenames>Dominik</forenames></author><author><keyname>Hennig</keyname><forenames>Philipp</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Classified Regression for Bayesian Optimization: Robot Learning with
  Unknown Penalties</title><categories>cs.LG cs.RO cs.SY eess.SY stat.ML</categories><comments>Submitted to Journal (under review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning robot controllers by minimizing a black-box objective cost using
Bayesian optimization (BO) can be time-consuming and challenging. It is very
often the case that some roll-outs result in failure behaviors, causing
premature experiment detention. In such cases, the designer is forced to decide
on heuristic cost penalties because the acquired data is often scarce, or not
comparable with that of the stable policies. To overcome this, we propose a
Bayesian model that captures exactly what we know about the cost of unstable
controllers prior to data collection: Nothing, except that it should be a
somewhat large number. The resulting Bayesian model, approximated with a
Gaussian process, predicts high cost values in regions where failures are
likely to occur. In this way, the model guides the BO exploration toward
regions of stability. We demonstrate the benefits of the proposed model in
several illustrative and statistical synthetic benchmarks, and also in
experiments on a real robotic platform. In addition, we propose and
experimentally validate a new BO method to account for unknown constraints.
Such method is an extension of Max-Value Entropy Search, a recent
information-theoretic method, to solve unconstrained global optimization
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10393</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10393</id><created>2019-07-23</created><authors><author><keyname>Lin</keyname><forenames>Qingjian</forenames></author><author><keyname>Yin</keyname><forenames>Ruiqing</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Bredin</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Barras</keyname><forenames>Claude</forenames></author></authors><title>LSTM based Similarity Measurement with Spectral Clustering for Speaker
  Diarization</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted for INTERSPEECH 2019</comments><doi>10.21437/Interspeech.2019-1388</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More and more neural network approaches have achieved considerable
improvement upon submodules of speaker diarization system, including speaker
change detection and segment-wise speaker embedding extraction. Still, in the
clustering stage, traditional algorithms like probabilistic linear discriminant
analysis (PLDA) are widely used for scoring the similarity between two speech
segments. In this paper, we propose a supervised method to measure the
similarity matrix between all segments of an audio recording with sequential
bidirectional long short-term memory networks (Bi-LSTM). Spectral clustering is
applied on top of the similarity matrix to further improve the performance.
Experimental results show that our system significantly outperforms the
state-of-the-art methods and achieves a diarization error rate of 6.63% on the
NIST SRE 2000 CALLHOME database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10399</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10399</id><created>2019-07-24</created><authors><author><keyname>Hui</keyname><forenames>Zheng</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Gao</keyname><forenames>Xinbo</forenames></author><author><keyname>Wang</keyname><forenames>Xiumei</forenames></author></authors><title>Progressive Perception-Oriented Network for Single Image
  Super-Resolution</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that deep neural networks can significantly
improve the performance of single image super-resolution (SISR). Numerous
studies have focused on raising the quantitative quality of super-resolved (SR)
images. However, these methods that target PSNR maximization usually produce
smooth images at large upscaling factor. The introduction of generative
adversarial networks (GANs) can mitigate this issue and show impressive results
with synthetic high-frequency textures. Nevertheless, these GAN-based
approaches always tend to add fake textures and even artifacts to make the SR
image of visually higher-resolution. In this paper, we propose a novel
perceptual image super-resolution method that progressively generates visually
high-quality results by constructing a stage-wise network. Specifically, the
first phase concentrates on minimizing pixel-wise error and the second stage
utilizes the features extracted by the previous stage to pursue results with
better structural retention. The final stage employs fine structure features
distilled by the second phase to produce more realistic results. In this way,
we can maintain the pixel and structure level information in the perceptual
image as much as possible. It is worth note that the proposed method can build
three types of images in a feed-forward process. Also, we explore a new
generator that adopts multi-scale hierarchical features fusion. Extensive
experiments on benchmark datasets show that our approach is superior to the
state-of-the-art methods. Code is available at
https://github.com/Zheng222/PPON.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10418</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10418</id><created>2019-07-23</created><authors><author><keyname>Rahman</keyname><forenames>Aimon</forenames></author><author><keyname>Zunair</keyname><forenames>Hasib</forenames></author><author><keyname>Rahman</keyname><forenames>M Sohel</forenames></author><author><keyname>Yuki</keyname><forenames>Jesia Quader</forenames></author><author><keyname>Biswas</keyname><forenames>Sabyasachi</forenames></author><author><keyname>Alam</keyname><forenames>Md Ashraful</forenames></author><author><keyname>Alam</keyname><forenames>Nabila Binte</forenames></author><author><keyname>Mahdy</keyname><forenames>M. R. C.</forenames></author></authors><title>Improving Malaria Parasite Detection from Red Blood Cell using Deep
  Convolutional Neural Networks</title><categories>eess.IV cs.LG stat.ML</categories><comments>Application of deep learning in biological science for the early
  detection of disease</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malaria is a female anopheles mosquito-bite inflicted life-threatening
disease which is considered endemic in many parts of the world. This article
focuses on improving malaria detection from patches segmented from microscopic
images of red blood cell smears by introducing a deep convolutional neural
network. Compared to the traditional methods that use tedious hand engineering
feature extraction, the proposed method uses deep learning in an end-to-end
arrangement that performs both feature extraction and classification directly
from the raw segmented patches of the red blood smears. The dataset used in
this study was taken from National Institute of Health named NIH Malaria
Dataset. The evaluation metric accuracy and loss along with 5-fold cross
validation was used to compare and select the best performing architecture. To
maximize the performance, existing standard pre-processing techniques from the
literature has also been experimented. In addition, several other complex
architectures have been implemented and tested to pick the best performing
model. A holdout test has also been conducted to verify how well the proposed
model generalizes on unseen data. Our best model achieves an accuracy of almost
97.77%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10419</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10419</id><created>2019-07-22</created><updated>2019-09-19</updated><authors><author><keyname>Kao</keyname><forenames>Po-Yu</forenames></author><author><keyname>Chen</keyname><forenames>Jefferson W.</forenames></author><author><keyname>Manjunath</keyname><forenames>B. S.</forenames></author></authors><title>Predicting Clinical Outcome of Stroke Patients with Tractographic
  Feature</title><categories>eess.IV cs.LG q-bio.QM stat.ML</categories><comments>12 pages, 4 figures, 3 tables. Accepted by MICCAI-BrainLesion 2019 as
  an oral presentation</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The volume of stroke lesion is the gold standard for predicting the clinical
outcome of stroke patients. However, the presence of stroke lesion may cause
neural disruptions to other brain regions, and these potentially damaged
regions may affect the clinical outcome of stroke patients. In this paper, we
introduce the tractographic feature to capture these potentially damaged
regions and predict the modified Rankin Scale (mRS), which is a widely used
outcome measure in stroke clinical trials. The tractographic feature is built
from the stroke lesion and average connectome information from a group of
normal subjects. The tractographic feature takes into account different
functional regions that may be affected by the stroke, thus complementing the
commonly used stroke volume features. The proposed tractographic feature is
tested on a public stroke benchmark Ischemic Stroke Lesion Segmentation 2017
and achieves higher accuracy than the stroke volume and the state-of-the-art
feature on predicting the mRS grades of stroke patients. In addition, the
tractographic feature also yields a lower average absolute error than the
commonly used stroke volume feature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10420</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10420</id><created>2019-07-22</created><authors><author><keyname>Hajavi</keyname><forenames>Amirhossein</forenames></author><author><keyname>Etemad</keyname><forenames>Ali</forenames></author></authors><title>A Deep Neural Network for Short-Segment Speaker Recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted in Interspeech 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Todays interactive devices such as smart-phone assistants and smart speakers
often deal with short-duration speech segments. As a result, speaker
recognition systems integrated into such devices will be much better suited
with models capable of performing the recognition task with short-duration
utterances. In this paper, a new deep neural network, UtterIdNet, capable of
performing speaker recognition with short speech segments is proposed. Our
proposed model utilizes a novel architecture that makes it suitable for
short-segment speaker recognition through an efficiently increased use of
information in short speech segments. UtterIdNet has been trained and tested on
the VoxCeleb datasets, the latest benchmarks in speaker recognition.
Evaluations for different segment durations show consistent and stable
performance for short segments, with significant improvement over the previous
models for segments of 2 seconds, 1 second, and especially sub-second durations
(250 ms and 500 ms).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10428</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10428</id><created>2019-07-23</created><authors><author><keyname>Han</keyname><forenames>Jing</forenames></author><author><keyname>Zhang</keyname><forenames>Zixing</forenames></author><author><keyname>Ren</keyname><forenames>Zhao</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>EmoBed: Strengthening Monomodal Emotion Recognition via Training with
  Crossmodal Emotion Embeddings</title><categories>cs.LG cs.HC cs.SD eess.AS</categories><doi>10.1109/TAFFC.2019.2928297</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite remarkable advances in emotion recognition, they are severely
restrained from either the essentially limited property of the employed single
modality, or the synchronous presence of all involved multiple modalities.
Motivated by this, we propose a novel crossmodal emotion embedding framework
called EmoBed, which aims to leverage the knowledge from other auxiliary
modalities to improve the performance of an emotion recognition system at hand.
The framework generally includes two main learning components, i. e., joint
multimodal training and crossmodal training. Both of them tend to explore the
underlying semantic emotion information but with a shared recognition network
or with a shared emotion embedding space, respectively. In doing this, the
enhanced system trained with this approach can efficiently make use of the
complementary information from other modalities. Nevertheless, the presence of
these auxiliary modalities is not demanded during inference. To empirically
investigate the effectiveness and robustness of the proposed framework, we
perform extensive experiments on the two benchmark databases RECOLA and
OMG-Emotion for the tasks of dimensional emotion regression and categorical
emotion classification, respectively. The obtained results show that the
proposed framework significantly outperforms related baselines in monomodal
inference, and are also competitive or superior to the recently reported
systems, which emphasises the importance of the proposed crossmodal learning
for emotion recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10456</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10456</id><created>2019-07-24</created><authors><author><keyname>Ma</keyname><forenames>Xingjun</forenames></author><author><keyname>Niu</keyname><forenames>Yuhao</forenames></author><author><keyname>Gu</keyname><forenames>Lin</forenames></author><author><keyname>Wang</keyname><forenames>Yisen</forenames></author><author><keyname>Zhao</keyname><forenames>Yitian</forenames></author><author><keyname>Bailey</keyname><forenames>James</forenames></author><author><keyname>Lu</keyname><forenames>Feng</forenames></author></authors><title>Understanding Adversarial Attacks on Deep Learning Based Medical Image
  Analysis Systems</title><categories>cs.CV cs.LG eess.IV</categories><comments>15 pages, 10 figures</comments><acm-class>I.4.9; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs) have become popular for medical image analysis
tasks like cancer diagnosis and lesion detection. However, a recent study
demonstrates that medical deep learning systems can be compromised by
carefully-engineered adversarial examples/attacks, i.e., small imperceptible
perturbations can fool DNNs to predict incorrectly. This raises safety concerns
about the deployment of deep learning systems in clinical settings. In this
paper, we provide a deeper understanding of adversarial examples in the context
of medical images. We find that medical DNN models can be more vulnerable to
adversarial attacks compared to natural ones from three different viewpoints:
1) medical image DNNs that have only a few classes are generally easier to be
attacked; 2) the complex biological textures of medical images may lead to more
vulnerable regions; and most importantly, 3) state-of-the-art deep networks
designed for large-scale natural image processing can be overparameterized for
medical imaging tasks and result in high vulnerability to adversarial attacks.
Surprisingly, we also find that medical adversarial attacks can be easily
detected, i.e., simple detectors can achieve over 98% detection AUCs against
state-of-the-art attacks, due to their fundamental feature difference from
normal examples. We show this is because adversarial attacks tend to attack a
wide spread area outside the pathological regions, which results in deep
features that are fundamentally different and easily separable from normal
features. We believe these findings may be a useful basis to approach the
design of secure medical deep learning systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10461</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10461</id><created>2019-07-24</created><authors><author><keyname>Deplano</keyname><forenames>Diego</forenames></author><author><keyname>Franceschelli</keyname><forenames>Mauro</forenames></author><author><keyname>Giua</keyname><forenames>Alessandro</forenames></author></authors><title>A Nonlinear Perron-Frobenius Approach for Stability and Consensus of
  Discrete-Time Multi-Agent Systems</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel method to establish stability and, in
addition, convergence to a consensus state for a class of discrete-time
Multi-Agent System (MAS) evolving according to nonlinear heterogeneous local
interaction rules which is not based on Lyapunov function arguments. In
particular, we focus on a class of discrete-time MASs whose global dynamics can
be represented by sub-homogeneous and order-preserving nonlinear maps. This
paper directly generalizes results for sub-homogeneous and order-preserving
linear maps which are shown to be the counterpart to stochastic matrices thanks
to nonlinear Perron-Frobenius theory. We provide sufficient conditions on the
structure of local interaction rules among agents to establish convergence to a
fixed point and study the consensus problem in this generalized framework as a
particular case. Examples to show the effectiveness of the method are provided
to corroborate the theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10462</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10462</id><created>2019-07-24</created><authors><author><keyname>Giannetti</keyname><forenames>Filippo</forenames></author><author><keyname>Moretti</keyname><forenames>Marco</forenames></author><author><keyname>Reggiannini</keyname><forenames>Ruggero</forenames></author><author><keyname>Vaccaro</keyname><forenames>Attilio</forenames></author></authors><title>The NEFOCAST System for Detection and Estimation of Rainfall Fields by
  the Opportunistic Use of Broadcast Satellite Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present results from the NEFOCAST project, funded by the
Tuscany Region, aiming at detecting and estimating rainfall fields from the
opportunistic use of the rain-induced excess attenuation incurred in the
downlink channel by a commercial DVB satellite signal. The attenuation is
estimated by reverse-engineering the effects of the various propagation
phenomena affecting the received signal, among which, in first place, the
perturbations factors affecting geostationary orbits, such as the gravitational
attraction from the moon and the sun and the inhomogeneity in Earth mass
distribution and, secondly, the small-scale irregularities in the atmospheric
refractive index, causing rapid fluctuations in signal amplitude. The latter
impairments, in particular, even if periodically counteracted by correction
maneuvers, may give rise to significant departures of the actual satellite
position from the nominal orbit. A further problem to deal with is the daily
and seasonal random fluctuation of the rain height and altitude/size of the
associated melting layer. All of the above issues lead to non-negligible random
deviations from the dry nominal downlink attenuation, that can be
misinterpreted as rain events. In this paper we show how to counteract these
issues by employing two differentially-configured Kalman filters designed to
track slow and fast changes of the received signal-to-noise ratio, so that the
rain events can be reliably detected and the relevant rainfall rate estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10465</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10465</id><created>2019-07-24</created><authors><author><keyname>Kordon</keyname><forenames>Florian</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation><affiliation>Advanced Therapies, Siemens Healthcare GmbH, Forchheim, Germany</affiliation><affiliation>Faculty of Digital Media, Hochschule Furtwangen, Furtwangen, Germany</affiliation></author><author><keyname>Fischer</keyname><forenames>Peter</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation><affiliation>Advanced Therapies, Siemens Healthcare GmbH, Forchheim, Germany</affiliation></author><author><keyname>Privalov</keyname><forenames>Maxim</forenames><affiliation>Department for Trauma and Orthopaedic Surgery, BG Trauma Center Ludwigshafen, Ludwigshafen, Germany</affiliation></author><author><keyname>Swartman</keyname><forenames>Benedict</forenames><affiliation>Department for Trauma and Orthopaedic Surgery, BG Trauma Center Ludwigshafen, Ludwigshafen, Germany</affiliation></author><author><keyname>Schnetzke</keyname><forenames>Marc</forenames><affiliation>Department for Trauma and Orthopaedic Surgery, BG Trauma Center Ludwigshafen, Ludwigshafen, Germany</affiliation></author><author><keyname>Franke</keyname><forenames>Jochen</forenames><affiliation>Department for Trauma and Orthopaedic Surgery, BG Trauma Center Ludwigshafen, Ludwigshafen, Germany</affiliation></author><author><keyname>Lasowski</keyname><forenames>Ruxandra</forenames><affiliation>Faculty of Digital Media, Hochschule Furtwangen, Furtwangen, Germany</affiliation></author><author><keyname>Maier</keyname><forenames>Andreas</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation></author><author><keyname>Kunze</keyname><forenames>Holger</forenames><affiliation>Advanced Therapies, Siemens Healthcare GmbH, Forchheim, Germany</affiliation></author></authors><title>Multi-task Localization and Segmentation for X-ray Guided Planning in
  Knee Surgery</title><categories>eess.IV cs.CV</categories><comments>Accepted for MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray based measurement and guidance are commonly used tools in orthopaedic
surgery to facilitate a minimally invasive workflow. Typically, a surgical
planning is first performed using knowledge of bone morphology and anatomical
landmarks. Information about bone location then serves as a prior for
registration during overlay of the planning on intra-operative X-ray images.
Performing these steps manually however is prone to intra-rater/inter-rater
variability and increases task complexity for the surgeon. To remedy these
issues, we propose an automatic framework for planning and subsequent overlay.
We evaluate it on the example of femoral drill site planning for medial
patellofemoral ligament reconstruction surgery. A deep multi-task stacked
hourglass network is trained on 149 conventional lateral X-ray images to
jointly localize two femoral landmarks, to predict a region of interest for the
posterior femoral cortex tangent line, and to perform semantic segmentation of
the femur, patella, tibia, and fibula with adaptive task complexity weighting.
On 38 clinical test images the framework achieves a median localization error
of 1.50 mm for the femoral drill site and mean IOU scores of 0.99, 0.97, 0.98,
and 0.96 for the femur, patella, tibia, and fibula respectively. The
demonstrated approach consistently performs surgical planning at expert-level
precision without the need for manual correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10478</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10478</id><created>2019-07-24</created><updated>2019-09-18</updated><authors><author><keyname>Guo</keyname><forenames>Zongyu</forenames></author><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author><author><keyname>Yu</keyname><forenames>Tao</forenames></author><author><keyname>Chen</keyname><forenames>Jiale</forenames></author><author><keyname>Liu</keyname><forenames>Sen</forenames></author></authors><title>Progressive Image Inpainting with Full-Resolution Residual Network</title><categories>eess.IV</categories><comments>Accepted to ACM Multimedia 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, learning-based algorithms for image inpainting achieve remarkable
progress dealing with squared or irregular holes. However, they fail to
generate plausible textures inside damaged area because there lacks surrounding
information. A progressive inpainting approach would be advantageous for
eliminating central blurriness, i.e., restoring well and then updating masks.
In this paper, we propose full-resolution residual network (FRRN) to fill
irregular holes, which is proved to be effective for progressive image
inpainting. We show that well-designed residual architecture facilitates
feature integration and texture prediction. Additionally, to guarantee
completion quality during progressive inpainting, we adopt N Blocks, One
Dilation strategy, which assigns several residual blocks for one dilation step.
Correspondingly, a step loss function is applied to improve the performance of
intermediate restorations. The experimental results demonstrate that the
proposed FRRN framework for image inpainting is much better than previous
methods both quantitatively and qualitatively. Our codes are released at:
\url{https://github.com/ZongyuGuo/Inpainting_FRRN}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10485</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10485</id><created>2019-07-21</created><authors><author><keyname>Shi</keyname><forenames>Xin</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>Early Anomaly Detection in Power Systems Based on Random Matrix Theory</title><categories>eess.SP stat.AP</categories><comments>8 pages, IEEE Trans on Smart Grid, submitted. arXiv admin note:
  substantial text overlap with arXiv:1801.01669; text overlap with
  arXiv:1810.08962</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is important for detecting the anomaly in power systems before it expands
and causes serious faults such as power failures or system blackout. With the
deployments of phasor measurement units (PMUs), massive amounts of
synchrophasor measurements are collected, which makes it possible for the
real-time situation awareness of the entire system. In this paper, based on
random matrix theory (RMT), a data-driven approach is proposed for anomaly
detection in power systems. First, spatio-temporal data set is formulated by
arranging high-dimensional synchrophasor measurements in chronological order.
Based on the Ring Law in RMT for the empirical spectral analysis of
`signal+noise' matrix, the mean spectral radius (MSR) is introduced to indicate
the system states from the macroscopic perspective. In order to realize anomaly
declare automatically, an anomaly indicator based on the MSR is designed and
the corresponding confidence level $1-\alpha$ is calculated. The proposed
approach is capable of detecting the anomaly in an early phase and robust
against random fluctuations and measuring errors. Cases on the synthetic data
generated from IEEE 300-bus, 118-bus and 57-bus test systems validate the
effectiveness and advantages of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10491</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10491</id><created>2019-07-21</created><authors><author><keyname>Zhong</keyname><forenames>Zijia</forenames></author><author><keyname>Lee</keyname><forenames>Earl E.</forenames></author></authors><title>Alternative Intersection Designs with Connected and Automated Vehicle</title><categories>cs.MA eess.SP</categories><comments>6 pages, 6 figures, 2019 IEEE 2nd Connected and Automated Vehicles
  Symposium. arXiv admin note: text overlap with arXiv:1811.03074</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alternative intersection designs (AIDs) can improve the performance of an
intersection by not only reducing the number of signal phases but also change
the configuration of the conflicting points by re-routing traffic. However the
AID studies have rarely been extended to Connected and Automated Vehicle (CAV)
which is expected to revolutionize our transportation system. In this study, we
investigate the potential benefits of CAV to two AIDs: the diverging diamond
interchange (DDI) and the restricted crossing U-turn intersection. The
potential enhancements of AID, CAV, and the combination of both are quantified
via microscopic traffic simulation. We found that CAV is able to positively
contribute to the performance of an intersection. However, converting an
existing conventional diamond interchange (CDI) to a diverging one is a more
effective way according to the simulation results. DDI improves the throughput
of a CDI by 950 vehicles per hour, a near 20% improvement; whereas with full
penetration of CAV, the throughput of a CDI is increased only by 300 vehicles
per hour. A similar trend is observed in the average delay per vehicle as well.
Furthermore, we assess the impact for the driver's confusion, a concern for
deploying AIDs, on the traffic flow. According to the ANOVA test, the negative
impacts of driver's confusion are of statistical significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10507</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10507</id><created>2019-07-19</created><authors><author><keyname>Al-Nahhal</keyname><forenames>Ibrahim</forenames></author><author><keyname>Alghoniemy</keyname><forenames>Masoud</forenames></author><author><keyname>El-Rahman</keyname><forenames>Adel B. Abd</forenames></author><author><keyname>Kawasaki</keyname><forenames>Zen</forenames></author></authors><title>Modified zero forcing decoder for ill-conditioned channels</title><categories>cs.IT eess.SP math.IT</categories><comments>9 pages, 7 figures. Published in 2013 IFIP Wireless Days (WD)</comments><journal-ref>2013 IFIP Wireless Days (WD)</journal-ref><doi>10.1109/WD.2013.6686453</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A modified zero-forcing (MZF) decoder for ill-conditioned Multi-Input
Multi-Output (MIMO) channels is proposed. The proposed decoder provides
significant performance improvement compared to the traditional zero-forcing
decoder by only considering the well-conditioned elements of the channel
matrix. This is achieved by reformulating the QR decomposition of the channel
matrix by neglecting the elements which are responsible for the correlation. By
combining the traditional ZF with the MZF decoders, a hybrid decoder can be
formed that alternates between the traditional ZF and the proposed MZF
according to the channel condition. We will illustrate through simulations the
significant improvement in performance with little change in complexity over
the traditional implementation of the zero forcing decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10509</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10509</id><created>2019-07-19</created><authors><author><keyname>Ingel</keyname><forenames>Anti</forenames></author><author><keyname>Kuzovkin</keyname><forenames>Ilya</forenames></author><author><keyname>Vicente</keyname><forenames>Raul</forenames></author></authors><title>Direct information transfer rate optimisation for SSVEP-based BCI</title><categories>eess.SP cs.LG stat.ML</categories><journal-ref>Journal of neural engineering, 16(1), 016016 (2018)</journal-ref><doi>10.1088/1741-2552/aae8c7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a classification method for SSVEP-based BCI is proposed. The
classification method uses features extracted by traditional SSVEP-based BCI
methods and finds optimal discrimination thresholds for each feature to
classify the targets. Optimising the thresholds is formalised as a maximisation
task of a performance measure of BCIs called information transfer rate (ITR).
However, instead of the standard method of calculating ITR, which makes certain
assumptions about the data, a more general formula is derived to avoid
incorrect ITR calculation when the standard assumptions are not met. This
allows the optimal discrimination thresholds to be automatically calculated and
thus eliminates the need for manual parameter selection or performing
computationally expensive grid searches. The proposed method shows good
performance in classifying targets of a BCI, outperforming previously reported
results on the same dataset by a factor of 2 in terms of ITR. The highest
achieved ITR on the used dataset was 62 bit/min. The proposed method also
provides a way to reduce false classifications, which is important in
real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10515</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10515</id><created>2019-07-23</created><authors><author><keyname>Hakhamaneshi</keyname><forenames>Kourosh</forenames></author><author><keyname>Werblun</keyname><forenames>Nick</forenames></author><author><keyname>Abbeel</keyname><forenames>Pieter</forenames></author><author><keyname>Stojanovic</keyname><forenames>Vladimir</forenames></author></authors><title>BagNet: Berkeley Analog Generator with Layout Optimizer Boosted with
  Deep Neural Networks</title><categories>eess.SP cs.LG cs.NE</categories><comments>Accepted on ICCAD 2019 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrepancy between post-layout and schematic simulation results
continues to widen in analog design due in part to the domination of layout
parasitics. This paradigm shift is forcing designers to adopt design
methodologies that seamlessly integrate layout effects into the standard design
flow. Hence, any simulation-based optimization framework should take into
account time-consuming post-layout simulation results. This work presents a
learning framework that learns to reduce the number of simulations of
evolutionary-based combinatorial optimizers, using a DNN that discriminates
against generated samples, before running simulations. Using this approach, the
discriminator achieves at least two orders of magnitude improvement on sample
efficiency for several large circuit examples including an optical link
receiver layout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10518</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10518</id><created>2019-07-22</created><updated>2019-11-12</updated><authors><author><keyname>Pascual</keyname><forenames>Damian</forenames></author><author><keyname>Aminifar</keyname><forenames>Amir</forenames></author><author><keyname>Atienza</keyname><forenames>David</forenames></author><author><keyname>Ryvlin</keyname><forenames>Philippe</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>Synthetic Epileptic Brain Activities Using Generative Adversarial
  Networks</title><categories>eess.SP cs.LG</categories><comments>Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended
  Abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epilepsy is a chronic neurological disorder affecting more than 65 million
people worldwide and manifested by recurrent unprovoked seizures. The
unpredictability of seizures not only degrades the quality of life of the
patients, but it can also be life-threatening. Modern systems monitoring
electroencephalography (EEG) signals are being currently developed with the
view to detect epileptic seizures in order to alert caregivers and reduce the
impact of seizures on patients' quality of life. Such seizure detection systems
employ state-of-the-art machine learning algorithms that require a considerably
large amount of labeled personal data for training. However, acquiring EEG
signals of epileptic seizures is a costly and time-consuming process for
medical experts and patients, currently requiring in-hospital recordings in
specialized units. In this work, we generate synthetic seizure-like brain
electrical activities, i.e., EEG signals, that can be used to train seizure
detection algorithms, alleviating the need for recorded data. First, we train a
Generative Adversarial Network (GAN) with data from 30 epilepsy patients. Then,
we generate synthetic personalized training sets for new, unseen patients,
which overall yield higher detection performance than the real-data training
sets. We demonstrate our results using the datasets from the EPILEPSIAE
Project, one of the world's largest public databases for seizure detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10519</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10519</id><created>2019-07-22</created><authors><author><keyname>Cox</keyname><forenames>Mitchell A.</forenames></author><author><keyname>Gailele</keyname><forenames>Lucas</forenames></author><author><keyname>Cheng</keyname><forenames>Ling</forenames></author><author><keyname>Forbes</keyname><forenames>Andrew</forenames></author></authors><title>Modelling the Memory of Turbulence-Induced Beam Wander</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges for long range, high speed Free-Space Optical
(FSO) communication is turbulence induced beam wander. Beam wander causes
fluctuations in the received intensity as well as crosstalk in mode division
multiplexed systems. Existing models for beam wander make use of probability
distributions and long term averages and are not able to accurately model
time-dependent intensity fluctuations such as deep fading, where the received
intensity is too low to maintain reliable communication for an extended period
of time. In this work we present an elegant new memory model which models the
behaviour of beam wander induced intensity fluctuations with the unique
capability to accurately simulate deep fading. This is invaluable for the
development of optimised error correction coding and digital signal processing
in order to improve the throughput and reliability of FSO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10526</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10526</id><created>2019-07-24</created><authors><author><keyname>Zhang</keyname><forenames>Kai</forenames></author><author><keyname>Entezari</keyname><forenames>Alireza</forenames></author></authors><title>A Convolutional Forward and Back-Projection Model for Fan-Beam Geometry</title><categories>eess.IV cs.CV cs.DC</categories><comments>This paper was submitted to IEEE-TMI, and it's an extension of our
  ISBI paper (https://ieeexplore.ieee.org/abstract/document/8759285)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Iterative methods for tomographic image reconstruction have great potential
for enabling high quality imaging from low-dose projection data. The
computational burden of iterative reconstruction algorithms, however, has been
an impediment in their adoption in practical CT reconstruction problems. We
present an approach for highly efficient and accurate computation of forward
model for image reconstruction in fan-beam geometry in X-ray CT. The efficiency
of computations makes this approach suitable for large-scale optimization
algorithms with on-the-fly, memory-less, computations of the forward and
back-projection. Our experiments demonstrate the improvements in accuracy as
well as efficiency of our model, specifically for first-order box splines
(i.e., pixel-basis) compared to recently developed methods for this purpose,
namely Look-up Table-based Ray Integration (LTRI) and Separable Footprints (SF)
in 2-D.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10554</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10554</id><created>2019-07-24</created><authors><author><keyname>Tang</keyname><forenames>Guanglin</forenames></author><author><keyname>Yan</keyname><forenames>Yulong</forenames></author><author><keyname>Shen</keyname><forenames>Chenyang</forenames></author><author><keyname>Jia</keyname><forenames>Xun</forenames></author><author><keyname>Zinn</keyname><forenames>Meyer</forenames></author><author><keyname>Trivedi</keyname><forenames>Zipalkumar</forenames></author><author><keyname>Yingling</keyname><forenames>Alicia</forenames></author><author><keyname>Westover</keyname><forenames>Kenneth</forenames></author><author><keyname>Jiang</keyname><forenames>Steve</forenames></author></authors><title>Balancing Robustness and Responsiveness in a Real-time Indoor Location
  System using Bluetooth Low Energy Technology and Deep Learning to Facilitate
  Clinical Applications</title><categories>eess.SP cs.CY</categories><comments>20 pages, 6 figures, submitted to Physics in Medicine &amp; Biology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An indoor, real-time location system (RTLS) can benefit both hospitals and
patients by improving clinical efficiency through data-driven optimization of
procedures. Bluetooth-based RTLS systems are cost-effective but lack accuracy
and robustness because Bluetooth signal strength is subject to fluctuation. We
developed a machine learning-based solution using a Long Short-Term Memory
(LSTM) network followed by a Multilayer Perceptron classifier and a posterior
constraint algorithm to improve RTLS performance. Training and validation
datasets showed that most machine learning models perform well in classifying
individual location zones, although LSTM was most reliable. However, when faced
with data indicating cross-zone trajectories, all models showed erratic zone
switching. Thus, we implemented a history-based posterior constraint algorithm
to reduce the variability in exchange for a slight decrease in responsiveness.
This network increases robustness at the expense of latency. When latency is
less of a concern, we computed the latency-corrected accuracy which is 100% for
our testing data, significantly improved from LSTM without constraint which is
96.2%. The balance between robustness and responsiveness can be considered and
adjusted on a case-by-case basis, according to the specific needs of downstream
clinical applications. This system was deployed and validated in an academic
medical center. Industry best practices enabled system scaling without
substantial compromises to performance or cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10557</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10557</id><created>2019-07-24</created><authors><author><keyname>Kornilov</keyname><forenames>Matwey V.</forenames></author></authors><title>Maximum likelihood estimation for disk image parameters</title><categories>eess.IV astro-ph.IM cs.CV</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel technique for estimating disc parameters from its 2D
image. It is based on the maximal likelihood approach utilising both edge
coordinates and the image intensity gradients. We emphasise the following
advantages of our likelihood model. It has closed-form formulae for parameter
estimating, therefore requiring less computational resources than iterative
algorithms. The likelihood model naturally distinguishes the outer and inner
annulus edges. The proposed technique was evaluated on both synthetic and real
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10560</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10560</id><created>2019-07-24</created><authors><author><keyname>Ding</keyname><forenames>Haichuan</forenames></author><author><keyname>Shin</keyname><forenames>Kang G.</forenames></author></authors><title>Accurate Angular Inference for 802.11ad Devices Using Beam-Specific
  Measurements</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to their sparsity, 60GHz channels are characterized by a few dominant
paths. Knowing the angular information of their dominant paths, we can develop
various applications, such as the prediction of link performance and the
tracking of an 802.11ad device. Although they are equipped with phased arrays,
the angular inference for 802.11ad devices is still challenging due to their
limited number of RF chains and limited phase control capabilities. Considering
the beam sweeping operation and the high communication bandwidth of 802.11ad
devices, we propose variation-based angle estimation (VAE), called VAE-CIR, by
utilizing beam-specific channel impulse responses (CIRs) measured under
different beams and the directional gains of the corresponding beams to infer
the angular information of dominant paths. Unlike state-of-the-arts, VAE-CIR
exploits the variations between different beam-specific CIRs, instead of their
absolute values, for angular inference. To evaluate the performance of VAE-CIR,
we generate the beam-specific CIRs by simulating the beam sweeping of 802.11ad
devices with the beam patterns measured on off-the-shelf 802.11ad devices. The
60GHz channel is generated via a ray-tracing simulator and the CIRs are
extracted via channel estimation based on Golay sequences. Through experiments
in various scenarios, we demonstrate the effectiveness of VAE-CIR and its
superiority to existing angular inference schemes for 802.11ad devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10562</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10562</id><created>2019-07-24</created><authors><author><keyname>Laas</keyname><forenames>Tobias</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author><author><keyname>Bazzi</keyname><forenames>Samer</forenames></author><author><keyname>Xu</keyname><forenames>Wen</forenames></author></authors><title>On Reciprocity in Physically Consistent TDD Systems with Coupled
  Antennas</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted for publication in an IEEE journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the reciprocity of the information theoretic channel of Time
Division Duplex (TDD) Multi User-Multiple Input Multiple Output (MU-MIMO)
systems in the up- and downlink. Specifically, we assume that the transmit and
receive chains are reciprocal. We take the mutual coupling between the antenna
elements at the base station and at the mobiles into account. Mutual coupling
influences how to calculate transmit power and noise covariance. The analysis
is based on the Multiport Communication Theory, which ensures that the
information theoretic model is consistent with physics. It also includes a
detailed noise model. We show that due to the coupling, the information
theoretic up- and downlink channels do not fulfill the ordinary reciprocity
relation, even if the input-output relation of the transmit voltage sources and
the receive load voltages, i.e., the channel which is estimated with the help
of pilot signals in the uplink, is reciprocal. This is a fundamental effect
that is not considered otherwise. We show via Monte Carlo simulations that
both, using the ordinary reciprocity relation, and not taking the coupling into
account, significantly decreases the ergodic rates in single-user and the
ergodic sum rates in multi-user systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10585</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10585</id><created>2019-07-24</created><updated>2019-07-24</updated><authors><author><keyname>Lu</keyname><forenames>JinHong</forenames></author><author><keyname>Shimodaira</keyname><forenames>Hiroshi</forenames></author></authors><title>A neural network based post-filter for speech-driven head motion
  synthesis</title><categories>eess.SP cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the fact that neural networks are widely used for speech-driven head
motion synthesis, it is well-known that the output of neural networks is noisy
or discontinuous due to the limited capability of deep neural networks in
predicting human motion. Thus, post-processing is required to obtain smooth
head motion trajectories for animation. It is common to apply a linear filter
or consider keyframes as post-processing. However, neither approach is optimal
as there is always a trade-off between smoothness and accuracy. We propose to
employ a neural network trained in a way that it is capable of reconstructing
the head motions, in order to overcome this limitation. In the objective
evaluation, this filter is proved to be good at de-noising data involving types
of noise (dropout or Gaussian noise). Objective metrics also demonstrate the
improvement of the joined head motion's smoothness after being processed by our
proposed filter. A detailed analysis reveals that our proposed filter learns
the characteristic of head motions. The subjective evaluation shows that
participants were unable to distinguish the synthesised head motions with our
proposed filter from ground truth, which was preferred over the Gaussian filter
and moving average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10634</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10634</id><created>2019-07-24</created><updated>2019-11-11</updated><authors><author><keyname>Palazzi</keyname><forenames>Andrea</forenames></author><author><keyname>Bergamini</keyname><forenames>Luca</forenames></author><author><keyname>Calderara</keyname><forenames>Simone</forenames></author><author><keyname>Cucchiara</keyname><forenames>Rita</forenames></author></authors><title>Warp and Learn: Novel Views Generation for Vehicles and Other Objects</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce a new self-supervised, semi-parametric approach for
synthesizing novel views of a vehicle starting from a single monocular image.
Differently from parametric (i.e. entirely learning-based) methods, we show how
a-priori geometric knowledge about the object and the 3D world can be
successfully integrated into a deep learning based image generation framework.
As this geometric component is not learnt, we call our approach
semi-parametric.
  In particular, we exploit man-made object symmetry and piece-wise planarity
to integrate rich a-priori visual information into the novel viewpoint
synthesis process. An Image Completion Network (ICN) is then trained to
generate a realistic image starting from this geometric guidance.
  This careful blend between parametric and non-parametric components allows us
to i) operate in a real-world scenario, ii) preserve high-frequency visual
information such as textures, iii) handle truly arbitrary 3D roto-translations
of the input and iv) perform shape transfer to completely different 3D models.
Eventually, we show that our approach can be easily complemented with synthetic
data and extended to other rigid objects with completely different topology,
even in presence of concave structures and holes (e.g. chairs).
  A comprehensive experimental analysis against state-of-the-art competitors
shows the efficacy of our method both from a quantitative and a perceptive
point of view.
  Supplementary material, animated results, code and data are available at:
https://github.com/ndrplz/semiparametric
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10648</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10648</id><created>2019-07-24</created><authors><author><keyname>Camponogara</keyname><forenames>&#xc2;ndrei</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Ribeiro</keyname><forenames>Mois&#xe9;s V.</forenames></author></authors><title>In-Home Broadband PLC Systems Under the Presence of a Malicious Wireless
  Device: Physical Layer Security Analysis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the physical layer security (PLS) of a broadband
in-home power line communication (PLC) system when a malicious wireless device
tries to eavesdrop private messages exchanged between two PLC devices. Such a
security issue arises when electric power circuits, which are used for data
communication, are constituted by unshielded power cables. In this regard, the
hybrid wiretap channel model for formulating achievable secrecy rate and
secrecy outage probability is considered. Additionally, a data set of channel
estimates and measured additive noises obtained from a measurement campaign
carried out in several in-home facilities is used for providing practical
results, which can offer direction for dealing with the security aspects of
broadband in-home PLC systems in the physical layer perspective. The attained
results show high values of secrecy outage probability for all chosen values of
target secrecy rate and total power transmission (practical and theoretical)
when the PLC devices are far from each other and the eavesdropper is close to
the PLC transmitter (i.e., the distance is shorter than 2 meters). Overall, the
numerical results show that the vulnerability of broadband in-home PLC systems,
in terms of PLS, is relevant when practical values of total transmission power
apply. Therefore, a rethinking of the use of unshielded power cables or new
designs of the broadband in-home PLC system deserves special attention for
ensuring security at the physical layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10655</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10655</id><created>2019-07-24</created><authors><author><keyname>Xue</keyname><forenames>Yuan</forenames></author><author><keyname>Zhou</keyname><forenames>Qianying</forenames></author><author><keyname>Ye</keyname><forenames>Jiarong</forenames></author><author><keyname>Long</keyname><forenames>L. Rodney</forenames></author><author><keyname>Antani</keyname><forenames>Sameer</forenames></author><author><keyname>Cornwell</keyname><forenames>Carl</forenames></author><author><keyname>Xue</keyname><forenames>Zhiyun</forenames></author><author><keyname>Huang</keyname><forenames>Xiaolei</forenames></author></authors><title>Synthetic Augmentation and Feature-based Filtering for Improved Cervical
  Histopathology Image Classification</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cervical intraepithelial neoplasia (CIN) grade of histopathology images is a
crucial indicator in cervical biopsy results. Accurate CIN grading of
epithelium regions helps pathologists with precancerous lesion diagnosis and
treatment planning. Although an automated CIN grading system has been desired,
supervised training of such a system would require a large amount of expert
annotations, which are expensive and time-consuming to collect. In this paper,
we investigate the CIN grade classification problem on segmented epithelium
patches. We propose to use conditional Generative Adversarial Networks (cGANs)
to expand the limited training dataset, by synthesizing realistic cervical
histopathology images. While the synthetic images are visually appealing, they
are not guaranteed to contain meaningful features for data augmentation. To
tackle this issue, we propose a synthetic-image filtering mechanism based on
the divergence in feature space between generated images and class centroids in
order to control the feature quality of selected synthetic images for data
augmentation. Our models are evaluated on a cervical histopathology image
dataset with a limited number of patch-level CIN grade annotations. Extensive
experimental results show a significant improvement of classification accuracy
from 66.3% to 71.7% using the same ResNet18 baseline classifier after
leveraging our cGAN generated images with feature-based filtering, which
demonstrates the effectiveness of our models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10671</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10671</id><created>2019-07-23</created><authors><author><keyname>Rikos</keyname><forenames>Apostolos I.</forenames></author><author><keyname>Hadjicostis</keyname><forenames>Christoforos N.</forenames></author></authors><title>Distributed Average Consensus under Quantized Communication via
  Event-Triggered Mass Splitting</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1806.08535</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the distributed average consensus problem in multi-agent systems
with directed communication links that are subject to quantized information
flow. The goal of distributed average consensus is for the nodes, each
associated with some initial value, to obtain the average (or some value close
to the average) of these initial values. In this paper, we present and analyze
a distributed averaging algorithm which operates exclusively with quantized
values (specifically, the information stored, processed and exchanged between
neighboring agents is subject to deterministic uniform quantization) and rely
on event-driven updates (e.g., to reduce energy consumption, communication
bandwidth, network congestion, and/or processor usage). We characterize the
properties of the proposed distributed averaging protocol, illustrate its
operation with an example, and show that its execution, on any timeinvariant
and strongly connected digraph, will allow all agents to reach, in finite time,
a common consensus value that is equal to the quantized average. We conclude
with comparisons against existing quantized average consensus algorithms that
illustrate the performance and potential advantages of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10682</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10682</id><created>2019-07-24</created><authors><author><keyname>Naghnaeian</keyname><forenames>Mohammad</forenames></author></authors><title>Optimal State Estimation Synthesis over Unreliable Network in Presence
  of Denial-of-Service Attack: an Operator Framework Approach</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of state-estimation in the presence of
Denial-of-Service (DoS) attack. We formulate this problem as an state
estimation problem for a plant with switching measured outputs. In the absence
of attack, the state-estimator has access to all measured outputs, however, in
the presence of attack, only a subset of all measurements are made available to
the state-estimator. We seek to find an state-estimator that results in the
minimum estimation error for the worst-case attack strategy. First, we
parameterize the set of all state-estimators that result in stable estimation
error for the worst-case attack scenario. Then, we will show that any
state-estimator in this set can be written as a generalized Luenberger observer
with an appropriately defined observer-gain. This observer-gain, in general,
can be an operator and possibly unbounded as opposed to the classical static
observer-gain. Furthermore, we will show that finding the optimal
state-estimator that results in the minimum estimation error can be cast as a
convex program over the set of stable factors of the observer operator-gain.
This optimization in, in fact, linear programming and tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10709</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10709</id><created>2019-07-24</created><authors><author><keyname>Siracusano</keyname><forenames>Giulio</forenames></author><author><keyname>La Corte</keyname><forenames>Aurelio</forenames></author><author><keyname>Tomasello</keyname><forenames>Riccardo</forenames></author><author><keyname>Lamonaca</keyname><forenames>Francesco</forenames></author><author><keyname>Scuro</keyname><forenames>Carmelo</forenames></author><author><keyname>Garesc&#xec;</keyname><forenames>Francesca</forenames></author><author><keyname>Carpentieri</keyname><forenames>Mario</forenames></author><author><keyname>Finocchio</keyname><forenames>Giovanni</forenames></author></authors><title>Automatic crack detection and classification by exploiting statistical
  event descriptors for Deep Learning</title><categories>cs.LG eess.SP stat.ML</categories><comments>34 pages, 2 tables, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern building infrastructures, the chance to devise adaptive and
unsupervised data-driven health monitoring systems is gaining in popularity due
to the large availability of data from low-cost sensors with internetworking
capabilities. In particular, deep learning provides the tools for processing
and analyzing this unprecedented amount of data efficiently. The main purpose
of this paper is to combine the recent advances of Deep Learning (DL) and
statistical analysis on structural health monitoring (SHM) to develop an
accurate classification tool able to discriminate among different acoustic
emission events (cracks) by means of the identification of tensile, shear and
mixed modes. The applications of DL in SHM systems is described by using the
concept of Bidirectional Long Short Term Memory. We investigated on effective
event descriptors to capture the unique characteristics from the different
types of modes. Among them, Spectral Kurtosis and Spectral L2/L1 Norm exhibit
distinctive behavior and effectively contributed to the learning process. This
classification will contribute to unambiguously detect incipient damages, which
is advantageous to realize predictive maintenance. Tests on experimental
results confirm that this method achieves accurate classification (92%)
capabilities of crack events and can impact on the design of future SHM
technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10714</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10714</id><created>2019-05-26</created><authors><author><keyname>Bahadori</keyname><forenames>Meisam</forenames></author><author><keyname>Yang</keyname><forenames>Yansong</forenames></author><author><keyname>Goddard</keyname><forenames>Lynford L.</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>High performance fully etched isotropic microring resonators in
  thin-film lithium niobate on insulator platform</title><categories>physics.app-ph eess.SP</categories><doi>10.1364/OE.27.022025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present our design, fabrication, and experimental results for very
high-performance isotropic microring resonators with small radii (~ 30 {\mu}m)
based on single-mode strip waveguides and transverse magnetic (TM) polarization
in a fully etched lithium niobate (Z-cut) thin-film on insulator. The loss of
the devices is predicted to be &lt; 10 dB/cm, and is measured to be ~ 7 dB/cm. The
measured optical responses of microring resonators exhibit an extinction of ~
25 dB (close to critical coupling), a 3 dB optical bandwidth of 49 pm (~ 6 GHz)
for all-pass structures, an extinction of ~ 10 dB for add-drop structures, and
a free spectral range of ~ 5.26 nm, all of which are in excellent agreement
with the design. This work is the first step towards ultra-compact and fully
isotropic optical modulators in thin-film lithium niobate on insulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10726</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10726</id><created>2019-07-24</created><authors><author><keyname>Kim</keyname><forenames>Suyoun</forenames></author><author><keyname>Dalmia</keyname><forenames>Siddharth</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Cross-Attention End-to-End ASR for Two-Party Conversations</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an end-to-end speech recognition model that learns interaction
between two speakers based on the turn-changing information. Unlike
conventional speech recognition models, our model exploits two speakers'
history of conversational-context information that spans across multiple turns
within an end-to-end framework. Specifically, we propose a speaker-specific
cross-attention mechanism that can look at the output of the other speaker side
as well as the one of the current speaker for better at recognizing long
conversations. We evaluated the models on the Switchboard conversational speech
corpus and show that our model outperforms standard end-to-end speech
recognition models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10737</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10737</id><created>2019-07-24</created><updated>2019-07-31</updated><authors><author><keyname>Zhang</keyname><forenames>Haichao</forenames></author><author><keyname>Wang</keyname><forenames>Jianyu</forenames></author></authors><title>Joint Adversarial Training: Incorporating both Spatial and Pixel Attacks</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional adversarial training methods using attacks that manipulate the
pixel value directly and individually, leading to models that are less robust
in face of spatial transformation-based attacks. In this paper, we propose a
joint adversarial training method that incorporates both spatial
transformation-based and pixel-value based attacks for improving model
robustness. We introduce a spatial transformation-based attack with an explicit
notion of budget and develop an algorithm for spatial attack generation. We
further integrate both pixel and spatial attacks into one generation model and
show how to leverage the complementary strengths of each other in training for
improving the overall model robustness. Extensive experimental results on
different benchmark datasets compared with state-of-the-art methods verified
the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10742</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10742</id><created>2019-07-24</created><authors><author><keyname>Ghawash</keyname><forenames>Faiq</forenames></author><author><keyname>Abbas</keyname><forenames>Waseem</forenames></author></authors><title>Leveraging Diversity for Achieving Resilient Consensus in Sparse
  Networks</title><categories>eess.SY cs.CR cs.SY</categories><comments>8th IFAC Workshop on Distributed Estimation and Control in Networked
  Systems (NecSys) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A networked system can be made resilient against adversaries and attacks if
the underlying network graph is structurally robust. For instance, to achieve
distributed consensus in the presence of adversaries, the underlying network
graph needs to satisfy certain robustness conditions. A typical approach to
making networks structurally robust is to strategically add extra links between
nodes, which might be prohibitively expensive. In this paper, we propose an
alternative way of improving network's robustness, that is by considering
heterogeneity of nodes. Nodes in a network can be of different types and can
have multiple variants. As a result, different nodes can have disjoint sets of
vulnerabilities, which means that an attacker can only compromise a particular
type of nodes by exploiting a particular vulnerability. We show that, by such a
diversification of nodes, attacker's ability to change the underlying network
structure is significantly reduced. Consequently, even a sparse network with
heterogeneous nodes can exhibit the properties of a structurally robust
network. Using these ideas, we propose a distributed control policy that
utilizes heterogeneity in the network to achieve resilient consensus in
adversarial environment. We extend the notion of $(r,s)$-robustness to
incorporate the diversity of nodes and provide necessary and sufficient
conditions to guarantee resilient distributed consensus in heterogeneous
networks. Finally we study the properties and construction of robust graphs
with heterogeneous nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10749</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10749</id><created>2019-07-24</created><authors><author><keyname>Gupta</keyname><forenames>Anant</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author><author><keyname>Arbabian</keyname><forenames>Amin</forenames></author><author><keyname>Sadri</keyname><forenames>Ali</forenames></author></authors><title>Design of Large Effective Apertures for Millimeter Wave Systems using a
  Sparse Array of Subarrays</title><categories>eess.SP</categories><comments>submitted for publication</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 67, no. 24, pp.
  6483-6497, 15 Dec.15, 2019</journal-ref><doi>10.1109/TSP.2019.2955828</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate synthesis of a large effective aperture using a sparse array
of subarrays. We employ a multi-objective optimization framework for placement
of subarrays within a prescribed area dictated by form factor constraints,
trading off the smaller beam width obtained by spacing out the subarrays
against the grating and side lobes created by sparse placement. We assess the
performance of our designs for the fundamental problem of bearing estimation
for one or more sources, comparing performance against estimation-theoretic
bounds. Our tiled architecture is motivated by recent progress in low-cost
hardware realizations of moderately sized antenna arrays (which play the role
of subarrays) in the millimeter wave band, and our numerical examples are based
on 16-element (4x4) subarrays in the 60 GHz unlicensed band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10794</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10794</id><created>2019-07-24</created><updated>2019-09-02</updated><authors><author><keyname>Ban</keyname><forenames>Byunghyun</forenames></author><author><keyname>Ryu</keyname><forenames>Donghun</forenames></author><author><keyname>Lee</keyname><forenames>Minwoo</forenames></author></authors><title>Machine learning approach to remove ion interference effect in
  agricultural nutrient solutions</title><categories>cs.LG eess.SP stat.ML</categories><comments>6 pages, 5 figures, 5 tables. Accepted to 2019 International
  Conference on Information and Communication Technology Convergence (ICTC) -
  ICTC2019</comments><journal-ref>2019 International Conference on Information and Communication
  Technology Convergence (ICTC)</journal-ref><doi>10.1109/ICTC46691.2019.8939812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High concentration agricultural facilities such as vertical farms or plant
factories consider hydroponic techniques as optimal solutions. Although
closed-system dramatically reduces water consumption and pollution issues, it
has ion-ratio related problem. As the root absorbs individual ions with
different rate, ion rate in a nutrient solution should be adjusted
periodically. But traditional method only considers pH and electrical
conductivity to adjust the nutrient solution, leading to ion imbalance and
accumulation of excessive salts. To avoid those problems, some researchers have
proposed ion-balancing methods which measure and control each ion
concentration. However, those approaches do not overcome the innate limitations
of ISEs, especially ion interference effect. An anion sensor is affected by
other anions, and the error grows larger in higher concentration solution. A
machine learning approach to modify ISE data distorted by ion interference
effect is proposed in this paper. As measurement of TDS value is relatively
robust than any other signals, we applied TDS as key parameter to build a
readjustment function to remove the artifact. Once a readjustment model is
established, application on ISE data can be done in real time. Readjusted data
with proposed model showed about 91.6 ~ 98.3% accuracies. This method will
enable the fields to apply recent methods in feasible status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10800</identifier>
 <datestamp>2020-01-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10800</id><created>2019-07-24</created><updated>2019-09-02</updated><authors><author><keyname>Ban</keyname><forenames>Byunghyun</forenames></author><author><keyname>Lee</keyname><forenames>Minwoo</forenames></author><author><keyname>Ryu</keyname><forenames>Donghun</forenames></author></authors><title>ODE network model for nonlinear and complex agricultural nutrient
  solution system</title><categories>eess.SY cs.SY</categories><comments>6 pages, 1 figure, 2 tables. Accepted to 2019 International
  Conference on Information and Communication Technology Convergence (ICTC) -
  ICTC2019</comments><journal-ref>2019 International Conference on Information and Communication
  Technology Convergence (ICTC)</journal-ref><doi>10.1109/ICTC46691.2019.8939946</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In closed hydroponic systems, periodic readjustment of nutrient solution is
necessary to continuously provide stable environment to plant roots because the
interaction between plant and nutrient solution changes the rate of ions in it.
The traditional method is to repeat supplying small amount of premade
concentrated nutrient solution, measuring total electric conductivity and pH of
the tank only. As it cannot control the collapse of ion rates, recent
researches try to measure the concentration of individual components to provide
insufficient ions only. However, those approaches use titrationlike heuristic
approaches, which repeat adding small amount of components and measuring ion
density a lot of times for a single control input. Both traditional and recent
methods are not only time-consuming, but also cannot predict chemical reactions
related with control inputs because the nutrient solution is a nonlinear
complex system, including many precipitation reactions and complicated
interactions. We present a continuous network model of the nutrient solution
system, whose reactions are described as differential equations. The model
predicts molar concentration of each chemical components and total dissolved
solids with low error. This model also can calculate the amount of chemical
compounds needed to produce a desired nutrient solution, by reverse calculation
from dissolved ion concentrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10804</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10804</id><created>2019-07-24</created><authors><author><keyname>Shu</keyname><forenames>Han</forenames></author><author><keyname>Wang</keyname><forenames>Yunhe</forenames></author><author><keyname>Jia</keyname><forenames>Xu</forenames></author><author><keyname>Han</keyname><forenames>Kai</forenames></author><author><keyname>Chen</keyname><forenames>Hanting</forenames></author><author><keyname>Xu</keyname><forenames>Chunjing</forenames></author><author><keyname>Tian</keyname><forenames>Qi</forenames></author><author><keyname>Xu</keyname><forenames>Chang</forenames></author></authors><title>Co-Evolutionary Compression for Unpaired Image Translation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks (GANs) have been successfully used for
considerable computer vision tasks, especially the image-to-image translation.
However, generators in these networks are of complicated architectures with
large number of parameters and huge computational complexities. Existing
methods are mainly designed for compressing and speeding-up deep neural
networks in the classification task, and cannot be directly applied on GANs for
image translation, due to their different objectives and training procedures.
To this end, we develop a novel co-evolutionary approach for reducing their
memory usage and FLOPs simultaneously. In practice, generators for two image
domains are encoded as two populations and synergistically optimized for
investigating the most important convolution filters iteratively. Fitness of
each individual is calculated using the number of parameters, a
discriminator-aware regularization, and the cycle consistency. Extensive
experiments conducted on benchmark datasets demonstrate the effectiveness of
the proposed method for obtaining compact and effective generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10818</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10818</id><created>2019-06-20</created><authors><author><keyname>Zhu</keyname><forenames>Na</forenames></author><author><keyname>Anagnostopoulos</keyname><forenames>Aris</forenames></author><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author></authors><title>On Mining IoT Data for Evaluating the Operation of Public Educational
  Buildings</title><categories>eess.SP cs.LG</categories><comments>13 pages, 7 figures. arXiv admin note: substantial text overlap with
  arXiv:1805.09561</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Public educational systems operate thousands of buildings with vastly
different characteristics in terms of size, age, location, construction,
thermal behavior and user communities. Their strategic planning and sustainable
operation is an extremely complex and requires quantitative evidence on the
performance of buildings such as the interaction of indoor-outdoor environment.
Internet of Things (IoT) deployments can provide the necessary data to
evaluate, redesign and eventually improve the organizational and managerial
measures. In this work a data mining approach is presented to analyze the
sensor data collected over a period of 2 years from an IoT infrastructure
deployed over 18 school buildings spread in Greece, Italy and Sweden. The
real-world evaluation indicates that data mining on sensor data can provide
critical insights to building managers and custodial staff about ways to lower
a building's energy footprint through effectively managing building operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10822</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10822</id><created>2019-07-23</created><authors><author><keyname>Kofidis</keyname><forenames>Eleftherios</forenames></author></authors><title>A Tensor-based Approach to Joint Channel Estimation / Data Detection in
  Flexible Multicarrier MIMO Systems</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1609.09661</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filter bank-based multicarrier (FBMC) systems have attracted increasing
attention recently in view of their many advantages over the classical cyclic
prefix (CP)-based orthogonal frequency division multiplexing (CP-OFDM)
modulation. However, their more advanced structure (resulting in, for example,
self interference) complicates signal processing tasks at the receiver,
including synchronization, channel estimation and equalization. In a
multiple-input multiple-output (MIMO) configuration, the multi-antenna
interference has also to be taken into account. (Semi-) blind receivers, of
increasing interest in (massive) MIMO systems, have been little studied so far
for FBMC and mainly for the single-antenna case only. The design of such
receivers for flexible MIMO FBMC systems, unifying a number of existing FBMC
schemes, is considered in this paper through a tensor-based approach, which is
shown to encompass existing joint channel estimation and data detection
approaches as special cases, adding to their understanding and paving the way
to further developments. Simulation-based results are included, for realistic
transmission models, demonstrating the estimation and detection performance
gains from the adoption of these receivers over their training only-based
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10830</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10830</id><created>2019-07-25</created><updated>2020-01-16</updated><authors><author><keyname>Kim</keyname><forenames>Junho</forenames></author><author><keyname>Kim</keyname><forenames>Minjae</forenames></author><author><keyname>Kang</keyname><forenames>Hyeonwoo</forenames></author><author><keyname>Lee</keyname><forenames>Kwanghee</forenames></author></authors><title>U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive
  Layer-Instance Normalization for Image-to-Image Translation</title><categories>cs.CV eess.IV</categories><comments>Accepted to ICLR 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method for unsupervised image-to-image translation, which
incorporates a new attention module and a new learnable normalization function
in an end-to-end manner. The attention module guides our model to focus on more
important regions distinguishing between source and target domains based on the
attention map obtained by the auxiliary classifier. Unlike previous
attention-based method which cannot handle the geometric changes between
domains, our model can translate both images requiring holistic changes and
images requiring large shape changes. Moreover, our new AdaLIN (Adaptive
Layer-Instance Normalization) function helps our attention-guided model to
flexibly control the amount of change in shape and texture by learned
parameters depending on datasets. Experimental results show the superiority of
the proposed method compared to the existing state-of-the-art models with a
fixed network architecture and hyper-parameters. Our code and datasets are
available at https://github.com/taki0112/UGATIT or
https://github.com/znxlwm/UGATIT-pytorch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10834</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10834</id><created>2019-07-25</created><authors><author><keyname>Hyun</keyname><forenames>Chang Min</forenames></author><author><keyname>Kim</keyname><forenames>Kang Cheol</forenames></author><author><keyname>Cho</keyname><forenames>Hyun Cheol</forenames></author><author><keyname>Choi</keyname><forenames>Jae Kyu</forenames></author><author><keyname>Seo</keyname><forenames>Jin Keun</forenames></author></authors><title>Framelet Pooling Aided Deep Learning Network : The Method to Process
  High Dimensional Medical Data</title><categories>cs.LG cs.NA eess.IV math.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning-based analysis of medical images often faces several
hurdles, such as the lack of training data, the curse of dimensionality
problem, and the generalization issues. One of the main difficulties is that
there exists computational cost problem in dealing with input data of large
size matrices which represent medical images. The purpose of this paper is to
introduce a framelet-pooling aided deep learning method for mitigating
computational bundle, caused by large dimensionality. By transforming high
dimensional data into low dimensional components by filter banks with
preserving detailed information, the proposed method aims to reduce the
complexity of the neural network and computational costs significantly during
the learning process. Various experiments show that our method is comparable to
the standard unreduced learning method, while reducing computational burdens by
decomposing large-sized learning tasks into several small-scale learning tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10840</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10840</id><created>2019-07-25</created><updated>2019-08-11</updated><authors><author><keyname>Sanyal</keyname><forenames>Amit K.</forenames></author></authors><title>Nonlinearly Stable Real-Time Learning and Model-Free Control</title><categories>eess.SY cs.SY</categories><comments>29 pages, 5 figures, unpublished</comments><msc-class>93-XX</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work provides a framework for nonlinear model-free control of systems
with unknown input-output dynamics, but outputs that can be controlled by the
inputs. This framework leads to real-time control of the system such that a
feasible output trajectory can be tracked by the inputs. Unlike existing
model-free or data-driven control approaches, this framework guarantees
nonlinear stability. The controller and observer designs in the proposed
framework are nonlinearly stable and robust to the unknown dynamics as well as
unknown measurement noise. For ease of computer implementation, the framework
is developed in discrete time. Nonlinear stability analyses of the
discrete-time observers and controllers are carried out using discrete Lyapunov
analysis. The unknown input-output dynamics is learnt in real time using a
nonlinearly stable observer from prior input-output history. This observer
ensures finite-time stable convergence of model estimation errors to zero if
the unknown model is constant, and model estimation errors converge to a
bounded neighborhood of the zero vector if the model has bounded change in
discrete time. Measured outputs are filtered by a finite-time stable observer
before use in feedback tracking of a desired output trajectory. Finite-time
stable observer design in this framework also ensures that a nonlinear
separation principle is in effect for separate controller and observer design.
A model-free nonlinearly stable control scheme is then designed to ensure
convergence of observed outputs to a desired output trajectory. This control
scheme ensures nonlinear finite-time stable convergence of tracking errors to a
manifold where the tracking errors decay asymptotically. A numerical experiment
on a nonlinear second-order system demonstrates the performance of this
nonlinear model-free control framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10860</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10860</id><created>2019-07-25</created><authors><author><keyname>Falsone</keyname><forenames>Alessandro</forenames></author><author><keyname>Notarnicola</keyname><forenames>Ivano</forenames></author><author><keyname>Notarstefano</keyname><forenames>Giuseppe</forenames></author><author><keyname>Prandini</keyname><forenames>Maria</forenames></author></authors><title>Tracking-ADMM for Distributed Constraint-Coupled Optimization</title><categories>math.OC cs.SY eess.SY</categories><comments>14 pages, 2 figures, submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider constraint-coupled optimization problems in which agents of a
network aim to cooperatively minimize the sum of local objective functions
subject to individual constraints and a common linear coupling constraint. We
propose a novel optimization algorithm that embeds a dynamic average consensus
protocol in the parallel Alternating Direction Method of Multipliers (ADMM) to
design a fully distributed scheme for the considered set-up. The dynamic
average mechanism allows agents to track the time-varying coupling constraint
violation (at the current solution estimates). The tracked version of the
constraint violation is then used to update local dual variables in a
consensus-based scheme mimicking a parallel ADMM step. Under convexity, we
prove that all limit points of the agents' primal solution estimates form an
optimal solution of the constraint-coupled (primal) problem. The result is
proved by means of a Lyapunov-based analysis simultaneously showing consensus
of the dual estimates to a dual optimal solution, convergence of the tracking
scheme and asymptotic optimality of primal iterates. A numerical study on
optimal charging schedule of plug-in electric vehicles corroborates the
theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10864</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10864</id><created>2019-07-25</created><updated>2019-08-28</updated><authors><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Ren</keyname><forenames>Hong</forenames></author><author><keyname>Wang</keyname><forenames>Kezhi</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Multicell MIMO Communications Relying on Intelligent Reflecting Surface</title><categories>eess.SP</categories><comments>Submit to one journal for possible publication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Intelligent reflecting surfaces (IRSs) constitute a disruptive wireless
communication technique capable of creating a controllable propagation
environment. This is achieved by constructing a large number of passive
reflection elements that impose controllable phase shifts on the impinging
electromagnetic waves so that the reflected signal can be constructively added
for the desired user or destructively at the unintended users to mitigate the
interference. In this paper, we propose to invoke an IRS at the cell boundary
of multiple cells to assist the downlink transmission to cell-edge users,
whilst mitigating the inter-cell interference, which is a crucial issue in
multicell communication systems. We aim for maximizing the weighted sum rate
(WSR) of all users through jointly optimizing the active precoding matrices at
the base stations (BSs) and the phase shifts at the IRS subject to each BS's
power constraint and unit modulus constraint. Both the BSs and the users are
equipped with multiple antennas, which enhances the spectral efficiency by
exploiting the spatial multiplexing gain. Due to the non-convexity of the
problem, we first reformulate it into an equivalent one, which is solved by
using the block coordinate descent (BCD) algorithm, where the precoding
matrices and phase shifts are alternately optimized. The optimal precoding
matrices can be obtained in closed form, when fixing the phase shifts. A pair
of efficient algorithms are proposed for solving the phase shift optimization
problem, namely the Majorization-Minimization (MM) Algorithm and the Complex
Circle Manifold (CCM) Method. Both algorithms are guaranteed to converge to at
least locally optimal solutions. Finally, our simulation results confirm the
advantages of introducing IRSs in enhancing the cell-edge user performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10865</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10865</id><created>2019-07-25</created><authors><author><keyname>Siracusano</keyname><forenames>Giulio</forenames></author><author><keyname>La Corte</keyname><forenames>Aurelio</forenames></author></authors><title>Forecasting Mobile Traffic with Spatiotemporal correlation using Deep
  Regression</title><categories>eess.SP cs.LG cs.NI</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of mobility prediction represents one of the key enablers for an
efficient management of future cellular networks, which tend to be
progressively more elaborate and dense due to the aggregation of multiple
technologies. In this letter we aim to investigate the problem of cellular
traffic prediction over a metropolitan area and propose a deep regression (DR)
approach to model its complex spatio-temporal dynamics. DR is instrumental in
capturing multi-scale and multi-domain dependences of mobile data by solving an
image-to-image regression problem. A parametric relationship between input and
expected output is defined and grid search is put in place to isolate and
optimize performance. Experimental results confirm that the proposed method
achieves a lower prediction error against stateof-the-art algorithms. We
validate forecasting performance and stability by using a large public dataset
of a European Provider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10889</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10889</id><created>2019-07-25</created><authors><author><keyname>Kobayashi</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Performance Evaluation of Two-layer lossless HDR Coding using Histogram
  Packing Technique under Various Tone-mapping Operators</title><categories>eess.IV cs.CV</categories><comments>to appear in 2019 IEEE 8th Global Conference on Consumer Electronics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a lossless two-layer HDR coding method using a histogram packing
technique. The proposed method was demonstrated to outperform the normative
JPEG XT encoder, under the use of the default tone-mapping operator. However,
the performance under various tone-mapping operators has not been discussed. In
this paper, we aim to compare the performance of the proposed method with that
of the JPEG XT encoder under the use of various tone-mapping operators to
clearly show the characteristic difference between them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10897</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10897</id><created>2019-07-25</created><authors><author><keyname>Mei</keyname><forenames>Jie</forenames></author></authors><title>Distributed Consensus for Multiple Lagrangian Systems with Parametric
  Uncertainties and External Disturbances Under Directed Graphs</title><categories>eess.SY cs.SY</categories><comments>15 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the leaderless consensus problem for multiple
Lagrangian systems in the presence of parametric uncertainties and external
disturbances under directed graphs. For achieving asymptotic behavior, a robust
continuous term with adaptive varying gains is added to alleviate the effects
of the external disturbances with unknown bounds. In the case of a fixed
directed graph, by introducing an integrate term in the auxiliary variable
design, the final consensus equilibrium can be explicitly derived. We show that
the agents achieve weighted average consensus, where the final equilibrium is
dependent on three factors, namely, the interactive topology, the initial
positions of the agents, and the control gains of the proposed control
algorithm. In the case of switching directed graphs, a model reference adaptive
consensus based algorithm is proposed such that the agents achieve leaderless
consensus if the infinite sequence of switching graphs is uniformly jointly
connected. Motivated by the fact that the relative velocity information is
difficult to obtain accurately, we further propose a leaderless consensus
algorithm with gain adaptation for multiple Lagrangian systems without using
neighbors' velocity information. We also propose a model reference adaptive
consensus based algorithm without using neighbors' velocity information for
switching directed graphs. The proposed algorithms are distributed in the sense
of using local information from its neighbors and using no comment control
gains. Numerical simulations are performed to show the effectiveness of the
proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10929</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10929</id><created>2019-07-25</created><updated>2019-12-16</updated><authors><author><keyname>Jany</keyname><forenames>Benedykt R.</forenames></author><author><keyname>Janas</keyname><forenames>Arkadiusz</forenames></author><author><keyname>Krok</keyname><forenames>Franciszek</forenames></author></authors><title>Automatic microscopic image analysis by moving window local Fourier
  Transform and Machine Learning</title><categories>eess.IV cond-mat.mes-hall physics.app-ph</categories><journal-ref>Micron 130 (2020) 102800</journal-ref><doi>10.1016/j.micron.2019.102800</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Analysis of microscope images is a tedious work which requires patience and
time, usually done manually by the microscopist after data collection. Here we
introduce an approach of automatic image analysis, which is based on locally
applied Fourier Transform and Machine Learning methods. In this approach, a
whole image is scanned by a local moving window with defined size and the 2D
Fourier Transform is calculated for each window. Then, all the Local Fourier
Transforms are fed into Machine Learning processing. Firstly, a number of
components in the data is estimated from Principal Component Analysis (PCA)
Scree Plot performed on the data. Secondly, the data are decomposed blindly by
Non-Negative Matrix Factorization (NMF) into interpretable spatial maps
(loadings) and corresponding Fourier Transforms (factors). The microscopic
image is analyzed and the features on the image are automatically discovered,
based on the local changes in Fourier Transform. The user selects only a size
and movement of the scanning local window which defines the final analysis
resolution. This automatic approach was successfully applied to analysis of
various microscopic images with and without local periodicity i.e. atomically
resolved High Angle Annular Dark Field (HAADF) Scanning Transmission Electron
Microscopy (STEM) image of Au nanoisland of fcc and Au hcp phases, Scanning
Tunneling Microscopy (STM) image of Au-induced reconstruction on Ge(001)
surface, Scanning Electron Microscopy (SEM) image of metallic nanoclusters
grown on GaSb surface, and Fluorescence microscopy image of HeLa cell line of
cervical cancer. The proposed approach could be used to automatically analyze
the local structure of microscopic images within a time of about a minute for a
single image on a modern desktop/notebook computer and it is freely available
as a Python analysis notebook and Python program for batch processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10956</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10956</id><created>2019-07-25</created><authors><author><keyname>Vuillemin</keyname><forenames>Pierre</forenames></author><author><keyname>Poussot-Vassal</keyname><forenames>Charles</forenames></author></authors><title>Discretisation of continuous-time linear dynamical model with the
  Loewner interpolation framework</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An interpolation method for discretising continuous-time Linear Time
Invariant (LTI) models is proposed in this paper. It consists first in using
the Loewner interpolation framework on a specific set of frequency data and
secondly to project the resulting model onto a stable subspace. The order of
the discretised model may be chosen larger than the initial one thus allowing
for trading complexity for accuracy if needed. Numerical examples highlight the
efficiency of the method at preserving a satisfactory matching both in
magnitude and phase in comparison to standard discretisation methods like ZOH
or Tustin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10961</identifier>
 <datestamp>2019-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10961</id><created>2019-07-25</created><authors><author><keyname>Pawlowski</keyname><forenames>Nick</forenames></author><author><keyname>Glocker</keyname><forenames>Ben</forenames></author></authors><title>Is Texture Predictive for Age and Sex in Brain MRI?</title><categories>eess.IV cs.CV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BJxgXfab94</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Deep learning builds the foundation for many medical image analysis tasks
where neuralnetworks are often designed to have a large receptive field to
incorporate long spatialdependencies. Recent work has shown that large
receptive fields are not always necessaryfor computer vision tasks on natural
images. We explore whether this translates to certainmedical imaging tasks such
as age and sex prediction from a T1-weighted brain MRI scans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10978</identifier>
 <datestamp>2019-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10978</id><created>2019-07-25</created><authors><author><keyname>Lessmann</keyname><forenames>Nikolas</forenames></author><author><keyname>Wolterink</keyname><forenames>Jelmer M.</forenames></author><author><keyname>Zreik</keyname><forenames>Majd</forenames></author><author><keyname>Viergever</keyname><forenames>Max A.</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author><author><keyname>I&#x161;gum</keyname><forenames>Ivana</forenames></author></authors><title>Vertebra partitioning with thin-plate spline surfaces steered by a
  convolutional neural network</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/B1eQv5INqV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Thin-plate splines can be used for interpolation of image values, but can
also be used to represent a smooth surface, such as the boundary between two
structures. We present a method for partitioning vertebra segmentation masks
into two substructures, the vertebral body and the posterior elements, using a
convolutional neural network that predicts the boundary between the two
structures. This boundary is modeled as a thin-plate spline surface defined by
a set of control points predicted by the network. The neural network is trained
using the reconstruction error of a convolutional autoencoder to enable the use
of unpaired data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.10993</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.10993</id><created>2019-07-25</created><authors><author><keyname>van Amsterdam</keyname><forenames>Beatrice</forenames></author><author><keyname>Nakawala</keyname><forenames>Hirenkumar</forenames></author><author><keyname>De Momi</keyname><forenames>Elena</forenames></author><author><keyname>Stoyanov</keyname><forenames>Danail</forenames></author></authors><title>Weakly Supervised Recognition of Surgical Gestures</title><categories>cs.RO cs.CV eess.IV</categories><comments>2019 IEEE International Conference on Robotics and Automation (ICRA)</comments><msc-class>68 Computer science</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kinematic trajectories recorded from surgical robots contain information
about surgical gestures and potentially encode cues about surgeon's skill
levels. Automatic segmentation of these trajectories into meaningful action
units could help to develop new metrics for surgical skill assessment as well
as to simplify surgical automation. State-of-the-art methods for action
recognition relied on manual labelling of large datasets, which is time
consuming and error prone. Unsupervised methods have been developed to overcome
these limitations. However, they often rely on tedious parameter tuning and
perform less well than supervised approaches, especially on data with high
variability such as surgical trajectories. Hence, the potential of weak
supervision could be to improve unsupervised learning while avoiding manual
annotation of large datasets. In this paper, we used at a minimum one expert
demonstration and its ground truth annotations to generate an appropriate
initialization for a GMM-based algorithm for gesture recognition. We showed on
real surgical demonstrations that the latter significantly outperforms standard
task-agnostic initialization methods. We also demonstrated how to improve the
recognition accuracy further by redefining the actions and optimising the
inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11048</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11048</id><created>2019-07-25</created><updated>2019-11-24</updated><authors><author><keyname>Aghamiry</keyname><forenames>Hossein S.</forenames></author><author><keyname>Gholami</keyname><forenames>Ali</forenames></author><author><keyname>Operto</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Robust Wavefield Inversion via Phase Retrieval</title><categories>math.OC eess.SP</categories><doi>10.1093/gji/ggaa035</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extended formulation of Full Waveform Inversion (FWI), called Wavefield
Reconstruction Inversion (WRI), offers potential benefits of decreasing the
nonlinearity of the inverse problem by replacing the explicit inverse of the
ill-conditioned wave-equation operator of classical FWI (the oscillating Green
functions) with a suitably defined data-driven regularized inverse. This
regularization relaxes the wave-equation constraint to reconstruct wavefields
that match the data, hence mitigating the risk of cycle skipping. The
subsurface model parameters are then updated in a direction that reduces these
constraint violations. However, in the case of a rough initial model, the phase
errors in the reconstructed wavefields may trap the waveform inversion in a
local minimum leading to inaccurate subsurface models. In this paper, in order
to avoid matching such incorrect phase information during the early WRI
iterations, we design a new cost function based upon phase retrieval, namely a
process which seeks to reconstruct a signal from the amplitude of linear
measurements. This new formulation, called Wavefield Inversion with Phase
Retrieval (WIPR), further improves the robustness of the parameter estimation
subproblem by a suitable phase correction. We implement the resulting WIPR
problem with an alternating-direction approach, which combines the
Majorization-Minimization (MM) algorithm to linearise the phase-retrieval term
and a variable splitting technique based upon the alternating direction method
of multipliers (ADMM). This new workflow equipped with Tikhonov-total variation
(TT) regularization, which is the combination of second-order Tikhonov and
total variation regularizations and bound constraints, successfully
reconstructs the 2004 BP salt model from a sparse fixed-spread acquisition
using a 3~Hz starting frequency and a homogeneous initial velocity model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11064</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11064</id><created>2019-07-25</created><authors><author><keyname>Jiang</keyname><forenames>Nan</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Online Supervised Learning for Traffic Load Prediction in Framed-ALOHA
  Networks</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the current backlog, or traffic load, in framed-ALOHA networks
enables the optimization of resource allocation, e.g., of the frame size.
However, this prediction is made difficult by the lack of information about the
cardinality of collisions and by possibly complex packet generation statistics.
Assuming no prior information about the traffic model, apart from a bound on
its temporal memory, this paper develops an online learning-based adaptive
traffic load prediction method that is based on Recurrent Neural Networks (RNN)
and specifically on the Long Short-Term Memory (LSTM) architecture. In order to
enable online training in the absence of feedback on the exact cardinality of
collisions, the proposed strategy leverages a novel approximate labeling
technique that is inspired by Method of Moments (MOM) estimators. Numerical
results show that the proposed online predictor considerably outperforms
conventional methods and is able to adapt to changing traffic statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11136</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11136</id><created>2019-06-20</created><authors><author><keyname>Kossifos</keyname><forenames>K. M.</forenames></author><author><keyname>Jaafar</keyname><forenames>A. H.</forenames></author><author><keyname>Kemp</keyname><forenames>N. T.</forenames></author><author><keyname>Antoniades</keyname><forenames>M. A.</forenames></author><author><keyname>Georgiou</keyname><forenames>J.</forenames></author></authors><title>An Optically-Programmable Absorbing Metasurface</title><categories>physics.app-ph eess.SP</categories><comments>5 pages, 8 figures, Published in 2018 IEEE International Symposium on
  Circuits and Systems (ISCAS)</comments><doi>10.1109/ISCAS.2018.8351874</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A tunable metasurface absorber is presented in this work using an
optically-programmable capacitor as the tuning element. The tuning element does
not employ conventional semiconductor technologies to operate but rather a
bases its tuning by changing the optomechanical properties of its dielectric,
poly disperse red 1 acrylate (PDR1A). Doing so there are no conventional
semiconductor devices in the RF signal path. The metasurface operates at a
design frequency of 5.5 GHz and it achieves an optically-tuned bandwidth of 150
MHz, from 5.50 GHz to 5.65 GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11137</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11137</id><created>2019-06-20</created><authors><author><keyname>Georgiou</keyname><forenames>J.</forenames></author><author><keyname>Kossifos</keyname><forenames>K. M.</forenames></author><author><keyname>Jaafar</keyname><forenames>A. H.</forenames></author><author><keyname>Kemp</keyname><forenames>N. T.</forenames></author><author><keyname>Antoniades</keyname><forenames>M. A.</forenames></author></authors><title>Chua Mem-Components for Adaptive RF Metamaterials</title><categories>physics.app-ph eess.SP</categories><comments>5 pages, 7 figures, Published in 2018 IEEE International Symposium on
  Circuits and Systems (ISCAS)</comments><doi>10.1109/ISCAS.2018.8351852</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Chua's mem-components are ideal for creating adaptive metasurfaces for
manipulating EM waves given that they hold their state without external biases.
In this paper, we propose a generic adaptive reactive element that is in fact a
memcapacitor/meminductor. This element makes use of a polymer that demonstrates
reversible trans-cis photochemical isomerization, thus making it possible to
change the distance between two conductive plates by up to 25%. Furthermore, a
design methodology for utilizing these devices is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11138</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11138</id><created>2019-06-07</created><authors><author><keyname>Zhu</keyname><forenames>Qi</forenames></author><author><keyname>Zou</keyname><forenames>Lixiang Jackie</forenames></author><author><keyname>Zang</keyname><forenames>Shaoge</forenames></author><author><keyname>Su</keyname><forenames>Mei</forenames></author><author><keyname>Hu</keyname><forenames>Aiguo Patrick</forenames></author></authors><title>Effect of Surrounding Conductive Object on Four-Plate Capacitive Power
  Transfer System</title><categories>physics.app-ph eess.SP</categories><comments>9 pages, 15 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the effect of a surrounding conductive object on a typical
capacitive power transfer (CPT) system with two pairs of parallel plates is
studied by considering the mutual coupling between the conductive object and
the plates. A mathematical model is established based on a 5*5 mutual
capacitance matrix by using a larger additional conductive plate to represent
the surrounding conductive object. Based on the proposed model, the effect of
the additional conductive plate on the CPT system is analyzed in detail. The
electric field distribution of the CPT system including the additional plate is
simulated by ANSYS Maxwell. A practical CPT system consisting of four
100mm*100mm square aluminum plates and one 300mm*300mm square aluminum plate is
built to verify the modeling and analysis. Both theoretical and experimental
results show that the output voltage of the CPT system decreases when the
additional conductive plate is placed closer to the CPT system. It has found
that the additional plate can effectively shield the electric field outside the
plate, and it attracts the electric field in-between the four plates of the CPT
system and the additional plate. It has also found that the voltage potential
difference between the additional plate and the reference plate of the CPT
system remains almost constant even when the distance between them changes. The
findings are useful for guiding the design of CPT systems, particularly the
electric field shielding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11150</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11150</id><created>2019-07-25</created><authors><author><keyname>Dorent</keyname><forenames>Reuben</forenames></author><author><keyname>Joutard</keyname><forenames>Samuel</forenames></author><author><keyname>Modat</keyname><forenames>Marc</forenames></author><author><keyname>Ourselin</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author></authors><title>Hetero-Modal Variational Encoder-Decoder for Joint Modality Completion
  and Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted at MICCAI 2019</comments><doi>10.1007/978-3-030-32245-8_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new deep learning method for tumour segmentation when dealing
with missing imaging modalities. Instead of producing one network for each
possible subset of observed modalities or using arithmetic operations to
combine feature maps, our hetero-modal variational 3D encoder-decoder
independently embeds all observed modalities into a shared latent
representation. Missing data and tumour segmentation can be then generated from
this embedding. In our scenario, the input is a random subset of modalities. We
demonstrate that the optimisation problem can be seen as a mixture sampling. In
addition to this, we introduce a new network architecture building upon both
the 3D U-Net and the Multi-Modal Variational Auto-Encoder (MVAE). Finally, we
evaluate our method on BraTS2018 using subsets of the imaging modalities as
input. Our model outperforms the current state-of-the-art method for dealing
with missing modalities and achieves similar performance to the subset-specific
equivalent networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11198</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11198</id><created>2019-07-24</created><authors><author><keyname>Luo</keyname><forenames>Xihaier</forenames></author><author><keyname>Kareem</keyname><forenames>Ahsan</forenames></author></authors><title>Deep convolutional neural networks for uncertainty propagation in random
  fields</title><categories>eess.IV cs.SY eess.SY</categories><comments>25 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of a reliable and robust surrogate model is often constrained
by the dimensionality of the problem. For a system with high-dimensional
inputs/outputs (I/O), conventional approaches usually use a low-dimensional
manifold to describe the high-dimensional system, where the I/O data is first
reduced to more manageable dimensions and then the condensed representation is
used for surrogate modeling. In this study, we present a new solution scheme
for this type of problems based on a deep learning approach. The proposed
surrogate is based on a particular network architecture, i.e. the convolutional
neural networks. The surrogate architecture is designed in a hierarchical style
containing three different levels of model structures, advancing the efficiency
and effectiveness of the model in the aspect of training and deploying. To
assess the model performance, we carry out uncertainty quantification in a
continuum mechanics benchmark problem. Numerical results suggest the proposed
model is capable of directly inferring a wide variety of I/O mapping
relationships. Uncertainty analysis results obtained via the proposed surrogate
have successfully characterized the statistical properties of the output fields
compared to the Monte Carlo estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11210</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11210</id><created>2019-07-25</created><authors><author><keyname>Shi</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Ziheng</forenames></author><author><keyname>Yuan</keyname><forenames>Tao</forenames></author><author><keyname>Zhu</keyname><forenames>Song-Chun</forenames></author></authors><title>HUGE2: a Highly Untangled Generative-model Engine for Edge-computing</title><categories>cs.LG cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a type of prominent studies in deep learning, generative models have been
widely investigated in research recently. Two research branches of the deep
learning models, the Generative Networks (GANs, VAE) and the Semantic
Segmentation, rely highly on the upsampling operations, especially the
transposed convolution and the dilated convolution. However, these two types of
convolutions are intrinsically different from standard convolution regarding
the insertion of zeros in input feature maps or in kernels respectively. This
distinct nature severely degrades the performance of the existing deep learning
engine or frameworks, such as Darknet, Tensorflow, and PyTorch, which are
mainly developed for the standard convolution. Another trend in deep learning
realm is to deploy the model onto edge/ embedded devices, in which the memory
resource is scarce. In this work, we propose a Highly Untangled
Generative-model Engine for Edge-computing or HUGE2 for accelerating these two
special convolutions on the edge-computing platform by decomposing the kernels
and untangling these smaller convolutions by performing basic matrix
multiplications. The methods we propose use much smaller memory footprint,
hence much fewer memory accesses, and the data access patterns also
dramatically increase the reusability of the data already fetched in caches,
hence increasing the localities of caches. Our engine achieves a speedup of
nearly 5x on embedded CPUs, and around 10x on embedded GPUs, and more than 50%
reduction of memory access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11238</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11238</id><created>2019-07-25</created><authors><author><keyname>Grzywalski</keyname><forenames>Tomasz</forenames></author><author><keyname>Belluzzo</keyname><forenames>Riccardo</forenames></author><author><keyname>Drgas</keyname><forenames>Szymon</forenames></author><author><keyname>Cwalinska</keyname><forenames>Agnieszka</forenames></author><author><keyname>Hafke-Dys</keyname><forenames>Honorata</forenames></author></authors><title>Interactive Lungs Auscultation with Reinforcement Learning Agent</title><categories>cs.SD cs.AI cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To perform a precise auscultation for the purposes of examination of
respiratory system normally requires the presence of an experienced doctor.
With most recent advances in machine learning and artificial intelligence,
automatic detection of pathological breath phenomena in sounds recorded with
stethoscope becomes a reality. But to perform a full auscultation in home
environment by layman is another matter, especially if the patient is a child.
In this paper we propose a unique application of Reinforcement Learning for
training an agent that interactively guides the end user throughout the
auscultation procedure. We show that \textit{intelligent} selection of
auscultation points by the agent reduces time of the examination fourfold
without significant decrease in diagnosis accuracy compared to exhaustive
auscultation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11276</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11276</id><created>2019-07-25</created><updated>2019-08-05</updated><authors><author><keyname>Aichele</keyname><forenames>Johannes</forenames></author><author><keyname>Giammarinaro</keyname><forenames>Bruno</forenames></author><author><keyname>Reinwald</keyname><forenames>Michael</forenames></author><author><keyname>Moign</keyname><forenames>Goulven Le</forenames></author><author><keyname>Catheline</keyname><forenames>Stefan</forenames></author></authors><title>Capturing the shear and secondary compression wave: High frame rate
  ultrasound imaging in saturated foams</title><categories>physics.med-ph cond-mat.soft eess.IV</categories><comments>6 pages, 4 figures, has additional supplementary material, accepted
  in Physical Review Letters (PRL) on 25 July 2019:
  https://journals.aps.org/prl/accepted/d8073Yb2Q561ed74b02b45f3f2ce801db54da98ac</comments><doi>10.1103/PhysRevLett.123.148001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We experimentally observe the shear and secondary compression wave inside
soft porous water-saturated melamine foams by high frame rate ultrasound
imaging. Both wave speeds are supported by the weak frame of the foam. The
first and second compression waves show opposite polarity, as predicted by Biot
theory. Our experiments have direct implications for medical imaging: Melamine
foams exhibit a similar microstructure as lung tissue. In the future, combined
shear wave and slow compression wave imaging might provide new means of
distinguishing malignant and healthy pulmonary tissue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11292</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11292</id><created>2019-07-24</created><authors><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Zhang</keyname><forenames>Weiwei</forenames></author><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Wang</keyname><forenames>Chengjia</forenames></author><author><keyname>Zhang</keyname><forenames>Heye</forenames></author><author><keyname>Liu</keyname><forenames>Huafeng</forenames></author><author><keyname>Zheng</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Shuo</forenames></author></authors><title>Recurrent Aggregation Learning for Multi-View Echocardiographic
  Sequences Segmentation</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-view echocardiographic sequences segmentation is crucial for clinical
diagnosis. However, this task is challenging due to limited labeled data, huge
noise, and large gaps across views. Here we propose a recurrent aggregation
learning method to tackle this challenging task. By pyramid ConvBlocks,
multi-level and multi-scale features are extracted efficiently. Hierarchical
ConvLSTMs next fuse these features and capture spatial-temporal information in
multi-level and multi-scale space. We further introduce a double-branch
aggregation mechanism for segmentation and classification which are mutually
promoted by deep aggregation of multi-level and multi-scale features. The
segmentation branch provides information to guide the classification while the
classification branch affords multi-view regularization to refine segmentations
and further lessen gaps across views. Our method is built as an end-to-end
framework for segmentation and classification. Adequate experiments on our
multi-view dataset (9000 labeled images) and the CAMUS dataset (1800 labeled
images) corroborate that our method achieves not only superior segmentation and
classification accuracy but also prominent temporal stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11294</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11294</id><created>2019-07-25</created><authors><author><keyname>Liao</keyname><forenames>Yun</forenames></author><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Shlezinger</keyname><forenames>Nir</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>Deep Neural Network Symbol Detection for Millimeter Wave Communications</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes to use a deep neural network (DNN)-based symbol detector
for mmWave systems such that CSI acquisition can be bypassed. In particular, we
consider a sliding bidirectional recurrent neural network (BRNN) architecture
that is suitable for the long memory length of typical mmWave channels. The
performance of the DNN detector is evaluated in comparison to that of the
Viterbi detector. The results show that the performance of the DNN detector is
close to that of the optimal Viterbi detector with perfect CSI, and that it
outperforms the Viterbi algorithm with CSI estimation error. Further
experiments show that the DNN detector is robust to a wide range of noise
levels and varying channel conditions, and that a pretrained detector can be
reliably applied to different mmWave channel realizations with minimal
overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11341</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11341</id><created>2019-07-25</created><authors><author><keyname>Park</keyname><forenames>Saem</forenames></author><author><keyname>Kwak</keyname><forenames>Nojun</forenames></author></authors><title>Image Enhancement by Recurrently-trained Super-resolution Network</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new learning strategy for image enhancement by recurrently
training the same simple superresolution (SR) network multiple times. After
initially training an SR network by using pairs of a corrupted low resolution
(LR) image and an original image, the proposed method makes use of the trained
SR network to generate new high resolution (HR) images with a doubled
resolution from the original uncorrupted images. Then, the new HR images are
downscaled to the original resolution, which work as target images for the SR
network in the next stage. The newly generated HR images by the repeatedly
trained SR network show better image quality and this strategy of training LR
to mimic new HR can lead to a more efficient SR network. Up to a certain point,
by repeating this process multiple times, better and better images are
obtained. This recurrent leaning strategy for SR can be a good solution for
downsizing convolution networks and making a more efficient SR network. To
measure the enhanced image quality, for the first time in this area of
super-resolution and image enhancement, we use VIQET MOS score which reflects
human visual quality more accurately than the conventional MSE measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11353</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11353</id><created>2019-07-25</created><updated>2019-09-21</updated><authors><author><keyname>Chen</keyname><forenames>Shuxiao</forenames></author><author><keyname>Rogers</keyname><forenames>Jonathan</forenames></author><author><keyname>Zhang</keyname><forenames>Bike</forenames></author><author><keyname>Sreenath</keyname><forenames>Koushil</forenames></author></authors><title>Feedback Control for Autonomous Riding of Hovershoes by a Cassie Bipedal
  Robot</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated towards achieving multi-modal locomotion, in this paper, we develop
a framework for a bipedal robot to dynamically ride a pair of Hovershoes over
various terrain. Our developed control strategy enables the Cassie bipedal
robot to interact with the Hovershoes to balance, regulate forward and
rotational velocities, achieve fast turns, and move over flat terrain, slopes,
stairs, and rough outdoor terrain. Our sensor suite comprising of tracking and
depth cameras for visual SLAM as well as our Dijkstra-based global planner and
timed elastic band-based local planning framework enables us to achieve
autonomous riding on the Hovershoes while navigating an obstacle course. We
present numerical and experimental validations of our work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11361</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11361</id><created>2019-07-25</created><authors><author><keyname>Badi</keyname><forenames>Alzahra</forenames></author><author><keyname>Park</keyname><forenames>Sangwook</forenames></author><author><keyname>Han</keyname><forenames>David K.</forenames></author><author><keyname>Ko</keyname><forenames>Hanseok</forenames></author></authors><title>Correlation Distance Skip Connection Denoising Autoencoder (CDSK-DAE)
  for Speech Feature Enhancement</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance of learning based Automatic Speech Recognition (ASR) is
susceptible to noise, especially when it is introduced in the testing data
while not presented in the training data. This work focuses on a feature
enhancement for noise robust end-to-end ASR system by introducing a novel
variant of denoising autoencoder (DAE). The proposed method uses skip
connections in both encoder and decoder sides by passing speech information of
the target frame from input to the model. It also uses a new objective function
in training model that uses a correlation distance measure in penalty terms by
measuring dependency of the latent target features and the model (latent
features and enhanced features obtained from the DAE). Performance of the
proposed method was compared against a conventional model and a state of the
art model under both seen and unseen noisy environments of 7 different types of
background noise with different SNR levels (0, 5, 10 and 20 dB). The proposed
method also is tested using linear and non-linear penalty terms as well, where,
they both show an improvement on the overall average WER under noisy conditions
both seen and unseen in comparison to the state-of-the-art model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11374</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11374</id><created>2019-07-25</created><authors><author><keyname>Bahadir</keyname><forenames>Cagla D.</forenames></author><author><keyname>Dalca</keyname><forenames>Adrian V.</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author></authors><title>Adaptive Compressed Sensing MRI with Unsupervised Learning</title><categories>eess.IV cs.LG stat.ML</categories><comments>10 pages, 5 figures</comments><msc-class>68T01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In compressed sensing MRI, k-space measurements are under-sampled to achieve
accelerated scan times. There are two fundamental problems in compressed
sensing MRI: (1) where to sample and (2) how to reconstruct. In this paper, we
tackle both problems simultaneously, using a novel unsupervised, end-to-end
learning framework, called LOUPE. Our method trains a neural network model on a
set of full-resolution MRI scans, which are retrospectively under-sampled and
forwarded to an anti-aliasing model that computes a reconstruction, which is in
turn compared with the input. In our experiments, we demonstrate that
LOUPE-optimized under-sampling masks are data-dependent, varying significantly
with the imaged anatomy, and perform well with different reconstruction
methods. We present empirical results obtained with a large-scale, publicly
available knee MRI dataset, where LOUPE offered the most superior
reconstruction quality across different conditions. Even with an aggressive
8-fold acceleration rate, LOUPE's reconstructions contained much of the
anatomical detail that was missed by alternative masks and reconstruction
methods. Our experiments also show how LOUPE yielded optimal under-sampling
patterns that were significantly different for brain vs knee MRI scans. Our
code is made freely available at https://github.com/cagladbahadir/LOUPE/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11377</identifier>
 <datestamp>2019-11-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11377</id><created>2019-07-26</created><updated>2019-09-22</updated><authors><author><keyname>Liu</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Dongpeng</forenames></author><author><keyname>Sun</keyname><forenames>Guangyu</forenames></author><author><keyname>Zhao</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Duolin</forenames></author><author><keyname>Liu</keyname><forenames>Fangxing</forenames></author><author><keyname>Fang</keyname><forenames>Xiang</forenames></author><author><keyname>He</keyname><forenames>Qing</forenames></author><author><keyname>Xu</keyname><forenames>Dong</forenames></author></authors><title>Detection of Malfunctioning Smart Electricity Meter</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting malfunctional smart meters based on electricity usage and targeting
them for replacement can save significant resources. For this purpose, we
developed a novel deep-learning method for malfunctional smart meter detection
based on long short-term memory (LSTM) and a modified convolutional neural
network (CNN). Our method uses LSTM to predict the reading of a master meter
based on data collected from submeters. If the predicted value is significantly
different from master meter reading data over a period of time, the diagnosis
part will be activated, classifying every submeter to identify the
malfunctional submeter based on CNN. We propose a time series-recurrence plot
(TS-RP) CNN, by combining the sequential raw data of electricity and its
recurrence plots in the phase space as dual input branches of CNN. By combining
this time sequential (TS) raw data with the recurrence plots (RP), we found
that the classification performance was much better than when using the
sequential raw data only. We compared our method with several classical
methods, including the elastic net and gradient boosting regression methods,
which show that our method performs better. To the best of our knowledge, our
TS-RP CNN is the first method to apply deep learning in malfunctional meter
detection. It is also relatively unique in the way it combines sequential data
and its phase-space transformation as the dual input for general sequential
data classification. This method is not only useful for increasing the service
life span of smart meters, preventing unnecessary replacement, but it also
provides a general method for managing other instruments of sequential data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11379</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11379</id><created>2019-07-26</created><authors><author><keyname>Visavakitcharoen</keyname><forenames>Artit</forenames></author><author><keyname>Kinoshita</keyname><forenames>Yuma</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>A Color Compensation Method Using Inverse Camera Response Function for
  Multi-exposure Image Fusion</title><categories>eess.IV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-exposure image fusion is a method for producing an image with a wide
dynamic range by fusing multiple images taken under various exposure values. In
this paper, we discuss color distortion included in fused images, and propose a
novel color compensation method for multi-exposure image fusion. In the
proposed method, an inverse camera response function (CRF) is estimated by
using multi-exposure images, and then a high dynamic range (HDR) radiance map
is recovered. The color information of the radiance map is applied to images
fused by conventional multi-exposure imaging to correct the color distortion.
The proposed method can be applied to any existing fusion approaches for
improving the quality of the fused images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11392</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11392</id><created>2019-07-26</created><authors><author><keyname>Ma</keyname><forenames>Jiechao</forenames></author><author><keyname>Zhang</keyname><forenames>Rongguo</forenames></author></authors><title>Automatic Calcium Scoring in Cardiac and Chest CT Using DenseRAUnet</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiovascular disease (CVD) is a common and strong threat to human beings,
featuring high prevalence, disability and mortality. The amount of coronary
artery calcification (CAC) is an effective factor for CVD risk evaluation.
Conventionally, CAC is quantified using ECG-synchronized cardiac CT but rarely
from general chest CT scans. However, compared with ECG-synchronized cardiac
CT, chest CT is more prevalent and economical in clinical practice. To address
this, we propose an automatic method based on Dense U-Net to segment coronary
calcium pixels on both types of CT scans. Our contribution is two-fold. First,
we propose a novel network called DenseRAUnet, which takes advantage of Dense
U-net, ResNet and atrous convolutions. We prove the robustness and
generalizability of our model by training it exclusively on chest CT while test
on both types of CT scans. Second, we design a loss function combining
bootstrap with IoU function to balance foreground and background classes.
DenseRAUnet is trained in a 2.5D fashion and tested on a private dataset
consisting of 144 scans. Results show an F1-score of 0.75, with 0.83 accuracy
of predicting cardiovascular disease risk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11401</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11401</id><created>2019-07-26</created><authors><author><keyname>Choi</keyname><forenames>Thomas</forenames></author><author><keyname>Rottenberg</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Gomez-Ponce</keyname><forenames>Jorge</forenames></author><author><keyname>Ramesh</keyname><forenames>Akshay</forenames></author><author><keyname>Luo</keyname><forenames>Peng</forenames></author><author><keyname>Zhang</keyname><forenames>Jianzhong</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Channel Extrapolation for FDD Massive MIMO: Procedure and Experimental
  Results</title><categories>eess.SP cs.SY eess.SY</categories><comments>6 pages, 6 figures, 2019 IEEE VTC (Fall) Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Application of massive multiple-input multiple-output (MIMO) systems to
frequency division duplex (FDD) is challenging mainly due to the considerable
overhead required for downlink training and feedback. Channel extrapolation,
i.e., estimating the channel response at the downlink frequency band based on
measurements in the disjoint uplink band, is a promising solution to overcome
this bottleneck. This paper presents measurement campaigns obtained by using a
wideband (350 MHz) channel sounder at 3.5 GHz composed of a calibrated 64
element antenna array, in both an anechoic chamber and outdoor environment. The
Space Alternating Generalized Expectation-Maximization (SAGE) algorithm was
used to extract the parameters (amplitude, delay, and angular information) of
the multipath components from the attained channel data within the training
(uplink) band. The channel in the downlink band is then reconstructed based on
these path parameters. The performance of the extrapolated channel is evaluated
in terms of mean squared error (MSE) and reduction of beamforming gain (RBG) in
comparison to the ground truth, i.e., the measured channel at the downlink
frequency. We find strong sensitivity to calibration errors and model mismatch,
and also find that performance depends on propagation conditions: LOS performs
significantly better than NLOS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11406</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11406</id><created>2019-07-26</created><authors><author><keyname>Qasim</keyname><forenames>Nameer Hashim</forenames></author><author><keyname>Pyliavskyi</keyname><forenames>Volodymyr</forenames></author><author><keyname>Solodka</keyname><forenames>Valentina</forenames></author></authors><title>Development of test materials for assessment broadcasting video path</title><categories>eess.IV</categories><comments>16 pages, 13 figure, 2 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of metrological agents for the estimation of the quality of
telecommunication path treatments is carried out. Analysis of subjective and
objective estimation methods is presented. The justification for choosing an
objective method of measuring is presented. Are reported a list of existing
goals and objectives, which face the current progress of the implementation of
promising systems for broadcasting and improvement of existing ones. The latter
include the absence of normative documents and recommendations for optical
specimens of testing tables, etc. Researches related to the choice of optical
samples from existing sets of colors from a number of international documents
and recommendations are presented. Deficiency of these sets is substantiated,
as some of the colors necessary for evaluation of telecommunication paths
cannot be provided with no color of sets. Provides recommendations and
refinements about which colors from existing sets should be used and what
constraints exist when used and how to solve. It is shown, that saturated
colors of green and red colors are not provided with spectral from the existing
sets, therefore, it is proposed to expand the traditional understanding of
metrological means by using atlases of colors. Satin colors In contrast to
existing ones have a number of advantages and can be used for evaluation in
advanced conditions, rather than in the studio that is rigidly defined by the
regulations. It is noted that for different brightness values there are a
different number of testing points. The number of testing points directly
depends on the evaluation criteria, is driven by several possible sets of
colors for evaluation. Recommendations for other evaluation conditions are
provided. Use satin colors to construct testing tables
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11414</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11414</id><created>2019-07-26</created><authors><author><keyname>Satouri</keyname><forenames>Mohammad reza</forenames></author><author><keyname>Kebriaei</keyname><forenames>Hamed</forenames></author><author><keyname>Razminia</keyname><forenames>Abolhassan</forenames></author><author><keyname>Yazdanpanah</keyname><forenames>Mohammad javad</forenames></author></authors><title>Robust On-Line ADP-based Solution of a Class of Hierarchical Nonlinear
  Differential Game</title><categories>eess.SY cs.SY</categories><msc-class>91A65, 49N70, 68T05,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a hierarchical one-leader-multi-followers game for a class of
continuous-time nonlinear systems with disturbance is investigated by a novel
policy iteration reinforcement learning technique in which, the game model
consists both of the zero-sum and nonzero-sum games, simultaneously. An
adaptive dynamic programming (ADP), method is developed to achieve optimal
control strategy under the worst case of disturbance. This algorithm reduces
the number of neural networks which are used for estimation for about thirty
percent. The proposed algorithm uses neural networks to estimate value
functions, control policies and disturbances. Convergence analysis of the
estimations is investigated using Lyapunov theory and exploiting properties of
the Nemytskii operator. Finally, the simulation results will show effectiveness
of the developed ADP method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11425</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11425</id><created>2019-07-26</created><authors><author><keyname>De Sena</keyname><forenames>Enzo</forenames></author><author><keyname>Cvetkovic</keyname><forenames>Zoran</forenames></author><author><keyname>Hacihabiboglu</keyname><forenames>Huseyin</forenames></author><author><keyname>Moonen</keyname><forenames>Marc</forenames></author><author><keyname>van Waterschoot</keyname><forenames>Toon</forenames></author></authors><title>Localization Uncertainty in Time-Intensity Stereophonic Reproduction</title><categories>eess.AS</categories><comments>Paper has been submitted for publication to IEEE/ACM Transactions on
  Audio, Speech, and Language Processing, and is currently under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the effects of inter-channel time and level differences in
stereophonic reproduction on perceived localization uncertainty. Towards this
end, a computational model of localization uncertainty is proposed first. The
model calculates inter-aural time and level difference cues, and compares them
to those associated to free-field point-like sources. The comparison is carried
out using a particular distance functional that replicates the increased
uncertainty observed experimentally with inconsistent inter-aural time and
level difference cues. The model is validated by subjective listening tests,
achieving a Pearson correlation of 0.95. The model is then used to predict
localization uncertainty for stereophonic setups and a listener in central and
off-central positions. Results show that intensity methods achieve a slightly
lower localization uncertainty for a listener positioned exactly in the center
of the sweet spot. As soon as the listener moves away from that position, the
situation reverses, with time-intensity methods achieving a lower localization
uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11436</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11436</id><created>2019-07-26</created><authors><author><keyname>Kleinschmidt</keyname><forenames>Sebastian P.</forenames></author><author><keyname>Wagner</keyname><forenames>Bernardo</forenames></author></authors><title>Semantic Deep Intermodal Feature Transfer: Transferring Feature
  Descriptors Between Imaging Modalities</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under difficult environmental conditions, the view of RGB cameras may be
restricted by fog, dust or difficult lighting situations. Because thermal
cameras visualize thermal radiation, they are not subject to the same
limitations as RGB cameras. However, because RGB and thermal imaging differ
significantly in appearance, common, state-of-the-art feature descriptors are
unsuitable for intermodal feature matching between these imaging modalities. As
a consequence, visual maps created with an RGB camera can currently not be used
for localization using a thermal camera. In this paper, we introduce the
Semantic Deep Intermodal Feature Transfer (Se-DIFT), an approach for
transferring image feature descriptors from the visual to the thermal spectrum
and vice versa. For this purpose, we predict potential feature appearance in
varying imaging modalities using a deep convolutional encoder-decoder
architecture in combination with a global feature vector. Since the
representation of a thermal image is not only affected by features which can be
extracted from an RGB image, we introduce the global feature vector which
augments the auto encoder's coding. The global feature vector contains
additional information about the thermal history of a scene which is
automatically extracted from external data sources. By augmenting the encoder's
coding, we decrease the L1 error of the prediction by more than 7% compared to
the prediction of a traditional U-Net architecture. To evaluate our approach,
we match image feature descriptors detected in RGB and thermal images using
Se-DIFT. Subsequently, we make a competitive comparison on the intermodal
transferability of SIFT, SURF, and ORB features using our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11458</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11458</id><created>2019-07-26</created><authors><author><keyname>Han</keyname><forenames>Ruize</forenames></author><author><keyname>Zhang</keyname><forenames>Yujun</forenames></author><author><keyname>Feng</keyname><forenames>Wei</forenames></author><author><keyname>Gong</keyname><forenames>Chenxing</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Zhao</keyname><forenames>Jiewen</forenames></author><author><keyname>Wan</keyname><forenames>Liang</forenames></author><author><keyname>Wang</keyname><forenames>Song</forenames></author></authors><title>Multiple Human Association between Top and Horizontal Views by Matching
  Subjects' Spatial Distributions</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video surveillance can be significantly enhanced by using both top-view data,
e.g., those from drone-mounted cameras in the air, and horizontal-view data,
e.g., those from wearable cameras on the ground. Collaborative analysis of
different-view data can facilitate various kinds of applications, such as human
tracking, person identification, and human activity recognition. However, for
such collaborative analysis, the first step is to associate people, referred to
as subjects in this paper, across these two views. This is a very challenging
problem due to large human-appearance difference between top and horizontal
views. In this paper, we present a new approach to address this problem by
exploring and matching the subjects' spatial distributions between the two
views. More specifically, on the top-view image, we model and match subjects'
relative positions to the horizontal-view camera in both views and define a
matching cost to decide the actual location of horizontal-view camera and its
view angle in the top-view image. We collect a new dataset consisting of
top-view and horizontal-view image pairs for performance evaluation and the
experimental results show the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11477</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11477</id><created>2019-07-26</created><authors><author><keyname>Khan</keyname><forenames>Farhan</forenames></author></authors><title>Online Subspace Tracking for Damage Propagation Modeling and Predictive
  Analytics: Big Data Perspective</title><categories>eess.SP cs.LG cs.SY eess.SY</categories><comments>14 pages, 5 figures, two tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze damage propagation modeling of turbo-engines in a data-driven
approach. We investigate subspace tracking assuming a low dimensional manifold
structure and a static behavior during the healthy state of the machines. Our
damage propagation model is based on the deviation of the data from the static
behavior and uses the notion of health index as a measure of the condition.
Hence, we incorporate condition-based maintenance and estimate the remaining
useful life based on the current and previous health indexes. This paper
proposes an algorithm that adapts well to the dynamics of the data and
underlying system, and reduces the computational complexity by utilizing the
low dimensional manifold structure of the data. A significant performance
improvement is demonstrated over existing methods by using the proposed
algorithm on CMAPSS Turbo-engine datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11483</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11483</id><created>2019-07-26</created><authors><author><keyname>Yu</keyname><forenames>Fei</forenames></author><author><keyname>Zhao</keyname><forenames>Jie</forenames></author><author><keyname>Gong</keyname><forenames>Yanjun</forenames></author><author><keyname>Wang</keyname><forenames>Zhi</forenames></author><author><keyname>Li</keyname><forenames>Yuxi</forenames></author><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Dong</keyname><forenames>Bin</forenames></author><author><keyname>Li</keyname><forenames>Quanzheng</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>Annotation-Free Cardiac Vessel Segmentation via Knowledge Transfer from
  Retinal Images</title><categories>eess.IV cs.CV</categories><comments>Accepted at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmenting coronary arteries is challenging, as classic unsupervised methods
fail to produce satisfactory results and modern supervised learning (deep
learning) requires manual annotation which is often time-consuming and can some
time be infeasible. To solve this problem, we propose a knowledge transfer
based shape-consistent generative adversarial network (SC-GAN), which is an
annotation-free approach that uses the knowledge from publicly available
annotated fundus dataset to segment coronary arteries. The proposed network is
trained in an end-to-end fashion, generating and segmenting synthetic images
that maintain the background of coronary angiography and preserve the vascular
structures of retinal vessels and coronary arteries. We train and evaluate the
proposed model on a dataset of 1092 digital subtraction angiography images, and
experiments demonstrate the supreme accuracy of the proposed method on coronary
arteries segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11514</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11514</id><created>2019-07-25</created><authors><author><keyname>Kong</keyname><forenames>Hui</forenames></author><author><keyname>Bartocci</keyname><forenames>Ezio</forenames></author><author><keyname>Jiang</keyname><forenames>Yu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Piecewise Robust Barrier Tubes for Nonlinear Hybrid Systems with
  Uncertainty</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Piecewise Barrier Tubes (PBT) is a new technique for flowpipe
overapproximation for nonlinear systems with polynomial dynamics, which
leverages a combination of barrier certificates. PBT has advantages over
traditional time-step based methods in dealing with those nonlinear dynamical
systems in which there is a large difference in speed between trajectories,
producing an overapproximation that is time independent. However, the existing
approach for PBT is not efficient due to the application of interval methods
for enclosure-box computation, and it can only deal with continuous dynamical
systems without uncertainty. In this paper, we extend the approach with the
ability to handle both continuous and hybrid dynamical systems with uncertainty
that can reside in parameters and/or noise. We also improve the efficiency of
the method significantly, by avoiding the use of interval-based methods for the
enclosure-box computation without loosing soundness. We have developed a C++
prototype implementing the proposed approach and we evaluate it on several
benchmarks. The experiments show that our approach is more efficient and
precise than other methods in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11542</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11542</id><created>2019-07-26</created><authors><author><keyname>Costantini</keyname><forenames>Giovanni</forenames></author><author><keyname>Casali</keyname><forenames>Daniele</forenames></author><author><keyname>Paolizzo</keyname><forenames>Fabio</forenames></author><author><keyname>Alessandrini</keyname><forenames>Marco</forenames></author><author><keyname>Micarelli</keyname><forenames>Alessandro</forenames></author><author><keyname>Viziano</keyname><forenames>Andrea</forenames></author><author><keyname>Saggio</keyname><forenames>Giovanni</forenames></author></authors><title>Towards the Enhancement of Body Standing Balance Recovery by Means of a
  Wireless Audio-Biofeedback System</title><categories>eess.SP cs.IR physics.med-ph</categories><comments>8 pages, 7 figures, 2 tables</comments><journal-ref>Medical engineering &amp; physics, 54, 74-81, 2019</journal-ref><doi>10.1016/j.medengphy.2018.01.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human maintain their body balance by sensorimotor controls mainly based on
information gathered from vision, proprioception and vestibular systems. When
there is a lack of information, caused by pathologies, diseases or aging, the
subject may fall. In this context, we developed a system to augment information
gathering, providing the subject with warning audio-feedback signals related to
his/her equilibrium. The system comprises an inertial measurement unit (IMU), a
data processing unit, a headphone audio device and a software application. The
IMU is a low-weight, small-size wireless instrument that, body-back located
between the L2 and L5 lumbar vertebrae, measures the subject's trunk
kinematics. The application drives the data processing unit to feeding the
headphone with electric signals related to the kinematic measures.
Consequently, the user is audio-alerted, via headphone, of his/her own
equilibrium, hearing a pleasant sound when in a stable equilibrium, or an
increasing bothering sound when in an increasing unstable condition. Tests were
conducted on a group of six older subjects (59y-61y, SD = 2.09y) and a group of
four young subjects (21y-26y, SD = 2.88y) to underline difference in
effectiveness of the system, if any, related to the age of the users. For each
subject, standing balance tests were performed in normal or altered conditions,
such as, open or closed eyes, and on a solid or foam surface The system was
evaluated in terms of usability, reliability, and effectiveness in improving
the subject's balance in all conditions. As a result, the system successfully
helped the subjects in reducing the body swaying within 10.65%-65.90%,
differences depending on subjects' age and test conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11544</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11544</id><created>2019-07-25</created><authors><author><keyname>Chen</keyname><forenames>Guanying</forenames></author><author><keyname>Han</keyname><forenames>Kai</forenames></author><author><keyname>Wong</keyname><forenames>Kwan-Yee K.</forenames></author></authors><title>Learning Transparent Object Matting</title><categories>cs.CV eess.IV</categories><comments>To appear in International Journal of Computer Vision, Project Page:
  https://guanyingc.github.io/TOM-Net. arXiv admin note: substantial text
  overlap with arXiv:1803.04636</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of image matting for transparent objects.
Existing approaches often require tedious capturing procedures and long
processing time, which limit their practical use. In this paper, we formulate
transparent object matting as a refractive flow estimation problem, and propose
a deep learning framework, called TOM-Net, for learning the refractive flow.
Our framework comprises two parts, namely a multi-scale encoder-decoder network
for producing a coarse prediction, and a residual network for refinement. At
test time, TOM-Net takes a single image as input, and outputs a matte
(consisting of an object mask, an attenuation mask and a refractive flow field)
in a fast feed-forward pass. As no off-the-shelf dataset is available for
transparent object matting, we create a large-scale synthetic dataset
consisting of $178K$ images of transparent objects rendered in front of images
sampled from the Microsoft COCO dataset. We also capture a real dataset
consisting of $876$ samples using $14$ transparent objects and $60$ background
images. Besides, we show that our method can be easily extended to handle the
cases where a trimap or a background image is available.Promising experimental
results have been achieved on both synthetic and real data, which clearly
demonstrate the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11555</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11555</id><created>2019-07-25</created><authors><author><keyname>Eaton-Rosen</keyname><forenames>Zach</forenames></author><author><keyname>Varsavsky</keyname><forenames>Thomas</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author><author><keyname>Cardoso</keyname><forenames>M. Jorge</forenames></author></authors><title>As easy as 1, 2... 4? Uncertainty in counting tasks for medical imaging</title><categories>eess.IV cs.LG stat.ML</categories><comments>Early Accept to MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Counting is a fundamental task in biomedical imaging and count is an
important biomarker in a number of conditions. Estimating the uncertainty in
the measurement is thus vital to making definite, informed conclusions. In this
paper, we first compare a range of existing methods to perform counting in
medical imaging and suggest ways of deriving predictive intervals from these.
We then propose and test a method for calculating intervals as an output of a
multi-task network. These predictive intervals are optimised to be as narrow as
possible, while also enclosing a desired percentage of the data. We demonstrate
the effectiveness of this technique on histopathological cell counting and
white matter hyperintensity counting. Finally, we offer insight into other
areas where this technique may apply.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11559</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11559</id><created>2019-07-26</created><authors><author><keyname>Pombo</keyname><forenames>Guilherme</forenames></author><author><keyname>Gray</keyname><forenames>Robert</forenames></author><author><keyname>Varsavsky</keyname><forenames>Tom</forenames></author><author><keyname>Ashburner</keyname><forenames>John</forenames></author><author><keyname>Nachev</keyname><forenames>Parashkev</forenames></author></authors><title>Bayesian Volumetric Autoregressive generative models for better
  semisupervised learning</title><categories>cs.LG cs.CV eess.IV stat.CO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep generative models are rapidly gaining traction in medical imaging.
Nonetheless, most generative architectures struggle to capture the underlying
probability distributions of volumetric data, exhibit convergence problems, and
offer no robust indices of model uncertainty. By comparison, the autoregressive
generative model PixelCNN can be extended to volumetric data with relative
ease, it readily attempts to learn the true underlying probability distribution
and it still admits a Bayesian reformulation that provides a principled
framework for reasoning about model uncertainty. Our contributions in this
paper are two fold: first, we extend PixelCNN to work with volumetric brain
magnetic resonance imaging data. Second, we show that reformulating this model
to approximate a deep Gaussian process yields a measure of uncertainty that
improves the performance of semi-supervised learning, in particular
classification performance in settings where the proportion of labelled data is
low. We quantify this improvement across classification, regression, and
semantic segmentation tasks, training and testing on clinical magnetic
resonance brain imaging data comprising T1-weighted and diffusion-weighted
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11563</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11563</id><created>2019-07-26</created><authors><author><keyname>Doan</keyname><forenames>Nghia</forenames></author><author><keyname>Hashemi</keyname><forenames>Seyyed Ali</forenames></author><author><keyname>Ercan</keyname><forenames>Furkan</forenames></author><author><keyname>Tonnellier</keyname><forenames>Thibaud</forenames></author><author><keyname>Gross</keyname><forenames>Warren</forenames></author></authors><title>Neural Dynamic Successive Cancellation Flip Decoding of Polar Codes</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic successive cancellation flip (DSCF) decoding of polar codes is a
powerful algorithm that can achieve the error correction performance of
successive cancellation list (SCL) decoding, with a complexity that is close to
that of successive cancellation (SC) decoding at practical signal-to-noise
ratio (SNR) regimes. However, DSCF decoding requires costly transcendental
computations which adversely affect its implementation complexity. In this
paper, we first show that a direct application of common approximation schemes
on the conventional DSCF decoding results in significant error-correction
performance loss. We then introduce a training parameter and propose an
approximation scheme which completely removes the need to perform
transcendental computations in DSCF decoding, with almost no error-correction
performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11577</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11577</id><created>2019-07-26</created><authors><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author><author><keyname>Sardellitti</keyname><forenames>Stefania</forenames></author></authors><title>Topological Signal Processing over Simplicial Complexes</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Signal Processing, July 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to establish the fundamental tools to analyze
signals defined over a topological space, i.e. a set of points along with a set
of neighborhood relations. This setup does not require the definition of a
metric and then it is especially useful to deal with signals defined over
non-metric spaces. We focus on signals defined over simplicial complexes. Graph
Signal Processing (GSP) represents a very simple case of Topological Signal
Processing (TSP), referring to the situation where the signals are associated
only with the vertices of a graph. We are interested in the most general case,
where the signals are associated with vertices, edges and higher order
complexes. After reviewing the basic principles of algebraic topology, we show
how to build unitary bases to represent signals defined over sets of increasing
order, giving rise to a spectral simplicial complex theory. Then we derive a
sampling theory for signals of any order and emphasize the interplay between
signals of different order. After having established the analysis tools, we
propose a method to infer the topology of a simplicial complex from data. We
conclude with applications to real edge signals to illustrate the benefits of
the proposed methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11587</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11587</id><created>2019-07-26</created><authors><author><keyname>Calisto</keyname><forenames>Maria G. Baldeon</forenames></author><author><keyname>Lai-Yuen</keyname><forenames>Susana K.</forenames></author></authors><title>Self-Adaptive 2D-3D Ensemble of Fully Convolutional Networks for Medical
  Image Segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation is a critical step in medical image analysis. Fully
Convolutional Networks (FCNs) have emerged as powerful segmentation models
achieving state-of-the-art results in various medical image datasets. Network
architectures are usually designed manually for a specific segmentation task so
applying them to other medical datasets requires extensive experience and time.
Moreover, the segmentation requires handling large volumetric data that results
in big and complex architectures. Recently, methods that automatically design
neural networks for medical image segmentation have been presented; however,
most approaches either do not fully consider volumetric information or do not
optimize the size of the network. In this paper, we propose a novel
self-adaptive 2D-3D ensemble of FCNs for medical image segmentation that
incorporates volumetric information and optimizes both the model's performance
and size. The model is composed of an ensemble of a 2D FCN that extracts
intra-slice information, and a 3D FCN that exploits inter-slice information.
The architectures of the 2D and 3D FCNs are automatically adapted to a medical
image dataset using a multiobjective evolutionary based algorithm that
minimizes both the segmentation error and number of parameters in the network.
The proposed 2D-3D FCN ensemble was tested on the task of prostate segmentation
on the image dataset from the PROMISE12 Grand Challenge. The resulting network
is ranked in the top 10 submissions, surpassing the performance of other
automatically-designed architectures while being considerably smaller in size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11637</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11637</id><created>2019-07-26</created><updated>2019-07-29</updated><authors><author><keyname>Ma</keyname><forenames>Sizhuo</forenames></author><author><keyname>Smith</keyname><forenames>Brandon M.</forenames></author><author><keyname>Gupta</keyname><forenames>Mohit</forenames></author></authors><title>Differential Scene Flow from Light Field Gradients</title><categories>cs.CV eess.IV</categories><acm-class>I.4.8</acm-class><doi>10.1007/s11263-019-01230-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents novel techniques for recovering 3D dense scene flow,
based on differential analysis of 4D light fields. The key enabling result is a
per-ray linear equation, called the ray flow equation, that relates 3D scene
flow to 4D light field gradients. The ray flow equation is invariant to 3D
scene structure and applicable to a general class of scenes, but is
under-constrained (3 unknowns per equation). Thus, additional constraints must
be imposed to recover motion. We develop two families of scene flow algorithms
by leveraging the structural similarity between ray flow and optical flow
equations: local 'Lucas-Kanade' ray flow and global 'Horn-Schunck' ray flow,
inspired by corresponding optical flow methods. We also develop a combined
local-global method by utilizing the correspondence structure in the light
fields. We demonstrate high precision 3D scene flow recovery for a wide range
of scenarios, including rotation and non-rigid motion. We analyze the
theoretical and practical performance limits of the proposed techniques via the
light field structure tensor, a 3x3 matrix that encodes the local structure of
light fields. We envision that the proposed analysis and algorithms will lead
to design of future light-field cameras that are optimized for motion sensing,
in addition to depth sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11640</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11640</id><created>2019-07-26</created><authors><author><keyname>Moore</keyname><forenames>Roger K.</forenames></author><author><keyname>Skidmore</keyname><forenames>Lucy</forenames></author></authors><title>On the Use/Misuse of the Term 'Phoneme'</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted at INTERSPEECH-2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The term 'phoneme' lies at the heart of speech science and technology, and
yet it is not clear that the research community fully appreciates its meaning
and implications. In particular, it is suspected that many researchers use the
term in a casual sense to refer to the sounds of speech, rather than as a well
defined abstract concept. If true, this means that some sections of the
community may be missing an opportunity to understand and exploit the
implications of this important psychological phenomenon. Here we review the
correct meaning of the term 'phoneme' and report the results of an
investigation into its use/misuse in the accepted papers at INTERSPEECH-2018.
It is confirmed that a significant proportion of the community (i) may not be
aware of the critical difference between `phonetic' and 'phonemic' levels of
description, (ii) may not fully understand the significance of 'phonemic
contrast', and as a consequence, (iii) consistently misuse the term 'phoneme'.
These findings are discussed, and recommendations are made as to how this
situation might be mitigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11646</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11646</id><created>2019-07-26</created><authors><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author><author><keyname>Hafermann</keyname><forenames>Hartmut</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Four-dimensional polarization-ring-switching for dispersion-managed
  optical fibre systems</title><categories>eess.SP</categories><comments>4pages, 5 figures, ECOC2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recently introduced 4D 64-ary polarisation-ring-switching format is
investigated in dispersion-managed systems. Numerical simulations show a reach
increase of $25\%$ with respect to PM-8QAM. This gain is achieved from the
nonlinear tolerance of the format and a 4D demapper using correlated noise
assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11647</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11647</id><created>2019-07-25</created><authors><author><keyname>Ni</keyname><forenames>Zhou</forenames></author><author><keyname>Chen</keyname><forenames>Ziru</forenames></author><author><keyname>Zhang</keyname><forenames>Qinbo</forenames></author><author><keyname>Zhou</keyname><forenames>Chi</forenames></author></authors><title>Analysis of RF Energy Harvesting in Uplink-NOMA IoT-based Network</title><categories>eess.SP cs.SY eess.SY</categories><comments>Accepted by vtc 2019 fall workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things (IoT) systems in general consist of a lot of devices with
massive connectivity. Those devices are usually constrained with limited energy
supply and can only operate at low power and low rate. In this paper, we
investigate a cellular-based IoT system combined with energy harvesting and
NOMA. We consider all base stations (BS) and IoT devices follow the Poisson
Point Process (PPP) distribution in a given area. The unit time slot is divided
into two phases, energy harvesting phase in downlink (DL) and data transmission
phase in uplink (uplink). That is, IoT devices will first harvest energy from
all BS transmissions and then use the harvested energy to do the NOMA
information transmission. We define an energy harvesting circle within which
all IoT devices can harvest enough energy for NOMA transmission. The design
objective is to maximize the total throughput in uplink within the circle by
varying the duration T of energy harvesting phase. In our work, we also
consider the inter-cell interference in the throughput calculation. The
analysis of Probability Mass Function (PMF) for IoT devices in the energy
harvesting circle is also compared with simulation results. It is shown that
the BS density needs to be carefully set so that the IoT devices in the energy
harvesting circle receive relatively smaller interference and energy circles
overlap only with a small probability. Our simulations show that there exists
an optimal T to achieve the maximum throughput. When the BSs are densely
deployed consequently the total throughput will decrease because of the
interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11648</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11648</id><created>2019-07-24</created><updated>2019-08-13</updated><authors><author><keyname>Avr</keyname><forenames>Azhagan</forenames></author><author><keyname>Tanvir</keyname><forenames>Shams</forenames></author><author><keyname>Rouphail</keyname><forenames>Nagui M.</forenames></author><author><keyname>Gupta</keyname><forenames>Rachana</forenames></author></authors><title>Capturing vehicular space headway using low-cost LIDAR and processing
  through ARIMA prediction modeling</title><categories>eess.SP</categories><comments>16 pages, 9 figures, and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a low-cost system to capture spatial vehicle headway data
and process the raw data by filtering outliers using a novel filtering process.
Multiple sensors and modules are integrated to form the system. The sensors
used are compact, lightweight, low-cost and have low power consumption. A
single beam 1-Dimensional Light Detection and Ranging (LIDAR) was used for
capturing the space headway data, a Global Positioning System (GPS) to map each
data point with a timestamp and position and also a camera to capture video
data with an overlay of date, time, distance and speed in real-time. The
filtering technique utilizes the Autoregressive Integrated Moving Average
(ARIMA) prediction modeling and mean-filtering. The data captured is stored in
a Raspberry Pi module. The data is later processed by using the filtering
technique to obtain the least outliers. The overall system has enabled to
capture spatial headway data and speed of the vehicle at a very low cost and
the data obtained can be used for car-following model analysis and
speed-density analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11649</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11649</id><created>2019-07-24</created><authors><author><keyname>Gupta</keyname><forenames>Ankit</forenames></author><author><keyname>Tang</keyname><forenames>George</forenames></author><author><keyname>Suresh</keyname><forenames>Sylesh</forenames></author></authors><title>HeartFit: An Accurate Platform for Heart Murmur Diagnosis Utilizing Deep
  Learning</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiovascular disease (CD) is the number one leading cause of death
worldwide, accounting for more than 17 million deaths in 2015. Critical
indicators of CD include heart murmurs, intense sounds emitted by the heart
during periods of irregular blood flow. Current diagnosis of heart murmurs
relies on echocardiography (ECHO), which costs thousands of dollars and medical
professionals to analyze the results, making it very unsuitable for areas with
inadequate medical facilities. Thus, there is a need for an accessible
alternative. Based on a simple interface and deep learning, HeartFit allows
users to administer diagnoses themselves. An inexpensive, custom designed
stethoscope in conjunction with a mobile application allows users to record and
upload audio of their heart to a database. Using a deep learning network
architecture, the database classifies the audio and returns the diagnosis to
the user. The model consists of a deep recurrent convolutional neural network
trained on 300 prelabeled heartbeat audio samples. After the model was
validated on a previously unseen set of 100 heartbeat audio samples, it
achieved a f beta score of 0.9545 and an accuracy of 95.5 percent. This value
exceeds that of clinical examination accuracy, which is around 83 percent to 91
percent and costs orders of magnitude less than ECHO, demonstrating the
effectiveness of the HeartFit platform. Through the platform, users can obtain
immediate, accurate diagnosis of heart murmurs without any professional medical
assistance, revolutionizing how we combat CD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11651</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11651</id><created>2019-07-23</created><updated>2019-09-29</updated><authors><author><keyname>Rakhshandehroo</keyname><forenames>Mohsen</forenames></author><author><keyname>Rajabdorri</keyname><forenames>Mohammad</forenames></author></authors><title>Time Series Analysis of Electricity Price and Demand to Find
  Cyber-attacks using Stationary Analysis</title><categories>eess.SP cs.CR cs.DB cs.SY eess.SY stat.ML</categories><comments>9pages, 13 figs, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With developing of computation tools in the last years, data analysis methods
to find insightful information are becoming more common among industries and
researchers. This paper is the first part of the times series analysis of New
England electricity price and demand to find anomaly in the data. In this paper
time-series stationary criteria to prepare data for further times-series
related analysis is investigated. Three main analysis are conducted in this
paper, including moving average, moving standard deviation and augmented
Dickey-Fuller test. The data used in this paper is New England big data from 9
different operational zones. For each zone, 4 different variables including
day-ahead (DA) electricity demand, price and real-time (RT) electricity demand
price are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11652</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11652</id><created>2019-07-23</created><authors><author><keyname>Filho</keyname><forenames>Jose Ilton de Oliveira</forenames></author><author><keyname>Trichili</keyname><forenames>Abderrahmen</forenames></author><author><keyname>Ooi</keyname><forenames>Boon S.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Salama</keyname><forenames>Khaled Nabil</forenames></author></authors><title>Towards Self-Powered Internet of Underwater Things Devices</title><categories>eess.SP</categories><comments>6 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Exploiting light beams to carry information and deliver power is mooted as a
potential technology to recharge batteries of future generation Internet of
things (IoT) and Internet of underwater things (IoUT) devices while providing
optical connectivity. Simultaneous lightwave information and power transfer
(SLIPT) has been recently proposed as an efficient way for wireless power
transfer between communicating terminals. In this article, we provide an
overview of the various SLIPT techniques in time, power, and space domains. We
additionally demonstrate two SLPIT scenarios through underwater channels.
Moreover, we discuss the open issues related to the hardware as well as system
deployment in harsh environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11653</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11653</id><created>2019-07-22</created><authors><author><keyname>Lobo</keyname><forenames>Jesus L.</forenames></author><author><keyname>Ballesteros</keyname><forenames>Igor</forenames></author><author><keyname>Oregi</keyname><forenames>Izaskun</forenames></author><author><keyname>Del Ser</keyname><forenames>Javier</forenames></author></authors><title>Real-time Electrical Power Prediction in a Combined Cycle Power Plant</title><categories>eess.SP cs.SY eess.SY</categories><journal-ref>Till under revision in Engineering Applications of Artificial
  Intelligence journal un 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prediction of electrical power in combined cycle power plants is a key
challenge in the electrical power and energy systems field. This power output
can vary depending on environmental variables, such as temperature, pressure,
and humidity. Thus, the business problem is how to predict the power output as
a function of these environmental conditions in order to maximize the profit.
The research community has solved this problem by applying machine learning
techniques and has managed to reduce the computational and time costs in
comparison with the traditional thermodynamical analysis. Until now, this
challenge has been tackled from a batch learning perspective in which data is
assumed to be at rest, and where models do not continuously integrate new
information into already constructed models. We present an approach closer to
the Big Data and Internet of Things paradigms in which data is arriving
continuously and where models learn incrementally, achieving significant
enhancements in terms of data processing (time, memory and computational
costs), and obtaining competitive performances. This work compares and examines
the hourly electrical power prediction of several streaming regressors, and
discusses about the best technique in terms of time processing and performance
to be applied on this streaming scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11654</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11654</id><created>2019-06-27</created><authors><author><keyname>Cui</keyname><forenames>Wen</forenames></author><author><keyname>Liu</keyname><forenames>Chen</forenames></author><author><keyname>Cai</keyname><forenames>Lin</forenames></author><author><keyname>Pan</keyname><forenames>Jianping</forenames></author></authors><title>PhyCode: A Practical Wireless Communication System Exploiting
  Superimposed Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superimposed signals are anticipated to improve wireless spectrum efficiency
to support the ever-growing IoT applications. Implementing the superimposed
signal demands on ideally aligned signals in both the time and frequency
domains. Prior work applied an average carrier-frequency offset compensation to
the superimposed signal under the assumptions of homogeneous devices and static
environments. However, this will cause a significant signal distortion in
practice when heterogeneous IoT devices are involved in a dynamic environment.
This paper presents PhyCode, which exploits the nature of varying offsets
across devices, and designs a dynamic decoding scheme which can react to the
exact offsets from different signal sources simultaneously. We implement
PhyCode via a software-defined radio platform and demonstrate that PhyCode
achieves a lower raw BER compared with the existing state-of-the-art method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11673</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11673</id><created>2019-07-26</created><authors><author><keyname>Haimovich</keyname><forenames>Hernan</forenames></author><author><keyname>Mancilla-Aguilar</keyname><forenames>Jose L.</forenames></author><author><keyname>Cardone</keyname><forenames>Paula</forenames></author></authors><title>A characterization of strong iISS for time-varying impulsive systems</title><categories>eess.SY cs.SY math.OC</categories><comments>Accepted at XVIII Workshop on Information Processing and Control
  (RPIC'19), Bahia Blanca, Argentina</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For general time-varying or switched (nonlinear) systems, converse Lyapunov
theorems for stability are not available. In these cases, the integral
input-to-state stability (iISS) property is not equivalent to the existence of
an iISS-Lyapunov function but can still be characterized as the combination of
global uniform asymptotic stability under zero input (0-GUAS) and uniformly
bounded energy input-bounded state (UBEBS). For impulsive systems, asymptotic
stability can be weak (when the asymptotic decay depends only on elapsed time)
or strong (when such a decay depends also on the number of impulses that
occurred). This paper shows that the mentioned characterization of iISS remains
valid for time-varying impulsive systems, provided that stability is understood
in the strong sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11683</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11683</id><created>2019-07-26</created><updated>2019-07-29</updated><authors><author><keyname>Loghmannia</keyname><forenames>Pedram</forenames></author><author><keyname>Manteghi</keyname><forenames>Majid</forenames></author></authors><title>Broadband Parametric Impedance Matching for Small Antennas Beyond the
  Bode-Fano Limit</title><categories>physics.app-ph eess.SP</categories><comments>Submitted to IEEE AWPL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, a parametric up-converter is introduced as a wideband
impedance matching network for electrically small antennas. The proposed
technique can also be applied to any narrowband load. Narrowband loads have a
high-quality factor because they store a large amount of energy throughout each
cycle while dissipating a limited amount of power. We propose lowering a
narrowband load's quality factor by increasing its dissipated power while
maintaining the general noise figure of the system. The idea is to use a
reactive network that emulates a positive resistor to drain power from the
narrowband load. The suggested matching network includes a time-varying reactor
(capacitor) which is not only a parametric amplifier but also a low noise
element.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11704</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11704</id><created>2019-07-25</created><authors><author><keyname>Liu</keyname><forenames>Jingya</forenames></author><author><keyname>Cao</keyname><forenames>Liangliang</forenames></author><author><keyname>Akin</keyname><forenames>Oguz</forenames></author><author><keyname>Tian</keyname><forenames>Yingli</forenames></author></authors><title>Accurate and Robust Pulmonary Nodule Detection by 3D Feature Pyramid
  Network with Self-supervised Feature Learning</title><categories>eess.IV cs.CV</categories><comments>15 pages, 8 figures, 5 tables, under review by Medical Image
  Analysis. arXiv admin note: substantial text overlap with arXiv:1906.03467</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate detection of pulmonary nodules with high sensitivity and specificity
is essential for automatic lung cancer diagnosis from CT scans. Although many
deep learning-based algorithms make great progress for improving the accuracy
of nodule detection, the high false positive rate is still a challenging
problem which limits the automatic diagnosis in routine clinical practice.
Moreover, the CT scans collected from multiple manufacturers may affect the
robustness of Computer-aided diagnosis (CAD) due to the differences in
intensity scales and machine noises. In this paper, we propose a novel
self-supervised learning assisted pulmonary nodule detection framework based on
a 3D Feature Pyramid Network (3DFPN) to improve the sensitivity of nodule
detection by employing multi-scale features to increase the resolution of
nodules, as well as a parallel top-down path to transit the high-level semantic
features to complement low-level general features. Furthermore, a High
Sensitivity and Specificity (HS2) network is introduced to eliminate the false
positive nodule candidates by tracking the appearance changes in continuous CT
slices of each nodule candidate on Location History Images (LHI). In addition,
in order to improve the performance consistency of the proposed framework
across data captured by different CT scanners without using additional
annotations, an effective self-supervised learning schema is applied to learn
spatiotemporal features of CT scans from large-scale unlabeled data. The
performance and robustness of our method are evaluated on several publicly
available datasets with significant performance improvements. The proposed
framework is able to accurately detect pulmonary nodules with high sensitivity
and specificity and achieves 90.6% sensitivity with 1/8 false positive per scan
which outperforms the state-of-the-art results 15.8% on LUNA16 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11711</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11711</id><created>2019-07-26</created><authors><author><keyname>Liang</keyname><forenames>Dong</forenames></author><author><keyname>Cheng</keyname><forenames>Jing</forenames></author><author><keyname>Ke</keyname><forenames>Ziwen</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author></authors><title>Deep MRI Reconstruction: Unrolled Optimization Algorithms Meet Neural
  Networks</title><categories>eess.IV cs.CV cs.LG eess.SP physics.med-ph stat.ML</categories><comments>a review paper on deep learning MR reconstruction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image reconstruction from undersampled k-space data has been playing an
important role for fast MRI. Recently, deep learning has demonstrated
tremendous success in various fields and also shown potential to significantly
speed up MR reconstruction with reduced measurements. This article gives an
overview of deep learning-based image reconstruction methods for MRI. Three
types of deep learning-based approaches are reviewed, the data-driven,
model-driven and integrated approaches. The main structure of each network in
three approaches is explained and the analysis of common parts of reviewed
networks and differences in-between are highlighted. Based on the review, a
number of signal processing issues are discussed for maximizing the potential
of deep reconstruction for fast MRI. the discussion may facilitate further
development of &quot;optimal&quot; network and performance analysis from a theoretical
point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11713</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11713</id><created>2019-07-26</created><authors><author><keyname>Deng</keyname><forenames>Mo</forenames></author><author><keyname>Li</keyname><forenames>Shuai</forenames></author><author><keyname>Goy</keyname><forenames>Alexandre</forenames></author><author><keyname>Kang</keyname><forenames>Iksung</forenames></author><author><keyname>Barbastathis</keyname><forenames>George</forenames></author></authors><title>Learning to Synthesize: Robust Phase Retrieval at Low Photon counts</title><categories>eess.IV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quality of inverse problem solutions obtained through deep learning
[Barbastathis et al, 2019] is limited by the nature of the priors learned from
examples presented during the training phase. In the case of quantitative phase
retrieval [Sinha et al, 2017, Goy et al, 2019], in particular, spatial
frequencies that are underrepresented in the training database, most often at
the high band, tend to be suppressed in the reconstruction. Ad hoc solutions
have been proposed, such as pre-amplifying the high spatial frequencies in the
examples [Li et al, 2018]; however, while that strategy improves resolution, it
also leads to high-frequency artifacts as well as low-frequency distortions in
the reconstructions. Here, we present a new approach that learns separately how
to handle the two frequency bands, low and high; and also learns how to
synthesize these two bands into the full-band reconstructions. We show that
this &quot;learning to synthesize&quot; (LS) method yields phase reconstructions of high
spatial resolution and artifact-free; and it is also resilient to high-noise
conditions, e.g. in the case of very low photon flux. In addition to the
problem of quantitative phase retrieval, the LS method is applicable, in
principle, to any inverse problem where the forward operator treats different
frequency bands unevenly, i.e. is ill-posed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11737</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11737</id><created>2019-07-26</created><authors><author><keyname>Patel</keyname><forenames>Sandeep</forenames></author><author><keyname>Dhuli</keyname><forenames>Ravindra</forenames></author><author><keyname>Lall</keyname><forenames>Brejesh</forenames></author></authors><title>Analysis of Signals via Non-Maximally Decimated Non-Uniform Filter Banks</title><categories>eess.SP</categories><comments>14 pages, accepted for publication in IEEE Transactions on Circuit
  and Systems I: Regular Papers</comments><doi>10.1109/TCSI.2019.2914302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the important problem of reconstructing a signal from
multiple multirate observations. The observations are modeled as the output of
an analysis bank, and time-domain analysis is carried out to design an optimal
FIR synthesis bank. We pose this as a minimizing the mean-square problem and
prove that at least one optimal solution is always possible. A parametric form
for all optimal solutions is obtained for a non-maximally decimated filter
bank. The necessary and sufficient conditions for an optimal solution, that
results in perfect reconstruction (PR), are derived as time-domain
pseudocirculant conditions. This represents a novel theoretical contribution in
multirate filter bank theory. We explore PR in a more general setting. This
results in the ability to design a synthesis bank with a particular delay in
the reconstruction. Using this delay, one can achieve PR in cases where it
might not have been possible otherwise. Further, we extend the design and
analysis to non-uniform filter banks and carry out simulations to verify the
derived results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11738</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11738</id><created>2019-07-26</created><authors><author><keyname>Lin</keyname><forenames>You</forenames></author><author><keyname>Wang</keyname><forenames>Jianhui</forenames></author><author><keyname>Cui</keyname><forenames>Mingjian</forenames></author></authors><title>Reconstruction of Power System Measurements Based on Enhanced Denoising
  Autoencoder</title><categories>eess.SP</categories><comments>This paper is accepted by the conference 2019 IEEE PES General
  Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new solution for reconstructing missing data in power
system measurements. An Enhanced Denoising Autoencoder (EDAE) is proposed to
reconstruct the missing data through the input vector space reconstruction
based on the neighbor values correlation and Long Short-Term Memory (LSTM)
networks. The proposed LSTM-EDAE is able to remove the noise, extract principle
features of the dataset, and reconstruct the missing information for new
inputs. The paper shows that the utilization of neighbor correlation can
perform better in missing data reconstruction. Trained with LSTM networks, the
EDAE is more effective in coping with big data in power systems and obtains a
better performance than the neural network in conventional Denoising
Autoencoder. A random data sequence and the simulated Phasor Measurement Unit
(PMU) data of power system are utilized to verify the effectiveness of the
proposed LSTM-EDAE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11773</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11773</id><created>2019-07-26</created><authors><author><keyname>Chlebus</keyname><forenames>Grzegorz</forenames></author><author><keyname>Abolmaali</keyname><forenames>Nasreddin</forenames></author><author><keyname>Schenk</keyname><forenames>Andrea</forenames></author><author><keyname>Meine</keyname><forenames>Hans</forenames></author></authors><title>Relevance analysis of MRI sequences for automatic liver tumor
  segmentation</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/B1lRBjMAYN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Explainability of decisions made by deep neural networks is of high value as
it allows for validation and improvement of models. This work proposes an
approach to explain semantic segmentation networks by means of layer-wise
relevance propagation. As an exemplary application, we investigate which MRI
sequences are most relevant for liver tumor segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11793</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11793</id><created>2019-07-26</created><authors><author><keyname>Song</keyname><forenames>Guangxiao</forenames></author><author><keyname>Sun</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Jiaming</forenames></author><author><keyname>Wang</keyname><forenames>Zhijie</forenames></author><author><keyname>Kamilov</keyname><forenames>Ulugbek S.</forenames></author></authors><title>A New Recurrent Plug-and-Play Prior Based on the Multiple
  Self-Similarity Network</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown the effectiveness of the plug-and-play priors (PnP)
framework for regularized image reconstruction. However, the performance of PnP
depends on the quality of the denoisers used as priors. In this letter, we
design a novel PnP denoising prior, called multiple self-similarity net (MSSN),
based on the recurrent neural network (RNN) with self-similarity matching using
multi-head attention mechanism. Unlike traditional neural net denoisers, MSSN
exploits different types of relationships among non-local and repeating
features to remove the noise in the input image. We numerically evaluate the
performance of MSSN as a module within PnP for solving magnetic resonance (MR)
image reconstruction. Experimental results show the stable convergence and
excellent performance of MSSN for reconstructing images from highly compressive
Fourier measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11818</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11818</id><created>2019-07-26</created><updated>2019-09-10</updated><authors><author><keyname>Chun</keyname><forenames>Il Yong</forenames></author><author><keyname>Huang</keyname><forenames>Zhengyu</forenames></author><author><keyname>Lim</keyname><forenames>Hongki</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>Momentum-Net: Fast and convergent iterative neural network for inverse
  problems</title><categories>eess.IV cs.CV cs.LG math.OC</categories><comments>26 pages, 7 figures, 3 algorithms, 3 tables, fixed incorrect ref</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative neural networks (INN) are rapidly gaining attention for solving
inverse problems in imaging, image processing, and computer vision. INNs
combine regression NNs and an iterative model-based image reconstruction (MBIR)
algorithm, leading to both good generalization capability and outperforming
reconstruction quality over existing MBIR optimization models. This paper
proposes the first fast and convergent INN architecture, Momentum-Net, by
generalizing a block-wise MBIR algorithm that uses momentums and majorizers
with regression NNs. For fast MBIR, Momentum-Net uses momentum terms in
extrapolation modules, and noniterative MBIR modules at each layer by using
majorizers, where each layer of Momentum-Net consists of three core modules:
image refining, extrapolation, and MBIR. Momentum-Net guarantees convergence to
a fixed-point for general differentiable (non)convex MBIR functions (or
data-fit terms) and convex feasible sets, under two asymptomatic conditions. To
consider data-fit variations across training and testing samples, we also
propose a regularization parameter selection scheme based on the spectral
radius of majorization matrices. Numerical experiments for light-field
photography using a focal stack and sparse-view computational tomography
demonstrate that given identical regression NN architectures, Momentum-Net
significantly improves MBIR speed and accuracy over several existing INNs; it
significantly improves reconstruction quality compared to a state-of-the-art
MBIR method in each application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11835</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11835</id><created>2019-07-26</created><authors><author><keyname>Zhu</keyname><forenames>Haidong</forenames></author><author><keyname>Shi</keyname><forenames>Jialin</forenames></author><author><keyname>Wu</keyname><forenames>Ji</forenames></author></authors><title>Pick-and-Learn: Automatic Quality Evaluation for Noisy-Labeled Image
  Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted for MICCAI2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning methods have achieved promising performance in many areas, but
they are still struggling with noisy-labeled images during the training
process. Considering that the annotation quality indispensably relies on great
expertise, the problem is even more crucial in the medical image domain. How to
eliminate the disturbance from noisy labels for segmentation tasks without
further annotations is still a significant challenge. In this paper, we
introduce our label quality evaluation strategy for deep neural networks
automatically assessing the quality of each label, which is not explicitly
provided, and training on clean-annotated ones. We propose a solution for
network automatically evaluating the relative quality of the labels in the
training set and using good ones to tune the network parameters. We also design
an overfitting control module to let the network maximally learn from the
precise annotations during the training process. Experiments on the public
biomedical image segmentation dataset have proved the method outperforms
baseline methods and retains both high accuracy and good generalization at
different noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11837</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11837</id><created>2019-07-26</created><authors><author><keyname>Han</keyname><forenames>Kai</forenames></author><author><keyname>Wang</keyname><forenames>Yunhe</forenames></author><author><keyname>Shu</keyname><forenames>Han</forenames></author><author><keyname>Liu</keyname><forenames>Chuanjian</forenames></author><author><keyname>Xu</keyname><forenames>Chunjing</forenames></author><author><keyname>Xu</keyname><forenames>Chang</forenames></author></authors><title>Attribute Aware Pooling for Pedestrian Attribute Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by IJCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper expands the strength of deep convolutional neural networks (CNNs)
to the pedestrian attribute recognition problem by devising a novel attribute
aware pooling algorithm. Existing vanilla CNNs cannot be straightforwardly
applied to handle multi-attribute data because of the larger label space as
well as the attribute entanglement and correlations. We tackle these challenges
that hampers the development of CNNs for multi-attribute classification by
fully exploiting the correlation between different attributes. The multi-branch
architecture is adopted for fucusing on attributes at different regions.
Besides the prediction based on each branch itself, context information of each
branch are employed for decision as well. The attribute aware pooling is
developed to integrate both kinds of information. Therefore, attributes which
are indistinct or tangled with others can be accurately recognized by
exploiting the context information. Experiments on benchmark datasets
demonstrate that the proposed pooling method appropriately explores and
exploits the correlations between attributes for the pedestrian attribute
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11848</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11848</id><created>2019-07-27</created><authors><author><keyname>Zhang</keyname><forenames>Jianlei</forenames></author><author><keyname>Starly</keyname><forenames>Binil</forenames></author></authors><title>Recurrent Neural Networks with Long Term Temporal Dependencies in
  Machine Tool Wear Diagnosis and Prognosis</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven approaches to automated machine condition monitoring are gaining
popularity due to advancements made in sensing technologies and computing
algorithms. This paper proposes the use of a deep learning model, based on Long
Short-Term Memory (LSTM) architecture for a recurrent neural network (RNN)
which captures long term dependencies for modeling sequential data. In the
context of estimating cutting tool wear amounts, this LSTM based RNN approach
utilizes a system transition and system observation function based on a
minimally intrusive vibration sensor signal located near the workpiece
fixtures. By applying an LSTM based RNN, the method helps to avoid building an
analytic model for specific tool wear machine degradation, overcoming the
assumptions made by Hidden Markov Models, Kalman filter, and Particle filter
based approaches. The proposed approach is tested using experiments performed
on a milling machine. We have demonstrated one-step and two-step look ahead
cutting tool state prediction using online indirect measurements obtained from
vibration signals. Additionally, the study also estimates remaining useful life
(RUL) of a machine cutting tool insert through generative RNN. The experimental
results show that our approach, applying the LSTM to model system observation
and transition function is able to outperform the functions modeled with a
simple RNN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11860</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11860</id><created>2019-07-27</created><authors><author><keyname>Tardy</keyname><forenames>Mickael</forenames></author><author><keyname>Scheffer</keyname><forenames>Bruno</forenames></author><author><keyname>Mateus</keyname><forenames>Diana</forenames></author></authors><title>A closer look onto breast density with weakly supervised dense-tissue
  masks</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SkgCGCBEqN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This work focuses on the automatic quantification of the breast density from
digital mammography imaging. Using only categorical image-wise labels we train
a model capable of predicting continuous density percentage as well as
providing a pixel wise support frit for the dense region. In particular we
propose a weakly supervised loss linking the density percentage to the mask
size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11861</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11861</id><created>2019-07-27</created><authors><author><keyname>Du</keyname><forenames>Richard</forenames></author><author><keyname>Cao</keyname><forenames>Peng</forenames></author><author><keyname>Han</keyname><forenames>Lujun</forenames></author><author><keyname>Ai</keyname><forenames>Qiyong</forenames></author><author><keyname>King</keyname><forenames>Ann D.</forenames></author><author><keyname>Vardhanabhuti</keyname><forenames>Varut</forenames></author></authors><title>Deep convolution neural network model for automatic risk assessment of
  patients with non-metastatic nasopharyngeal carcinoma</title><categories>eess.IV</categories><comments>Medical Imaging with Deep Learning 2019 - Extended Abstract. MIDL
  2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/S1xEkdTpYN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Nasopharyngeal Carcinoma (NPC) is endemic cancer in the south-east Asia. With
the advent of intensity-modulated radiotherapy excellent locoregional control
are being achieved. Consequently, this had led to pretreatment clinical staging
classification to be less prognostic of outcomes such as recurrence after
treatment. Alternative pretreatment strategies for prognosis of NPC after
treatment are needed to provide better risk stratification for NPC. In this
study we proposed a deep convolution neural network model based on
contrast-enhanced T1 (T1C) and T2 weighted (T2) MRI scan to predict 3-year
disease progression of NPC patient after primary treatment. We retrospective
obtained 596 non-metastatic NPC patients from four independent centres in Hong
Kong and China. Our model first performs a segmentation of the primary NPC
tumour to localise the tumour, and then uses the segmentation mask as prior
knowledge along with the T1C and T2 scan to classify 3-year disease
progression. For segmentation, we adapted and modified a VNet to encode both
T1C and T2 scan and also encoding to classify T and overall stage
classification. Our modified network performed better than baseline VNet with
T1C and network with no T and overall classification. The classification result
for 3-year disease progression achieved an AUC of 0.828 in the validation set
but did not generalised well for the test set which consist of 146 patients
from a different centre to the training data (AUC = 0.69). Our preliminary
results show that deep learning may offer prognostication of disease
progression of NPC patients after treatment. One advantage of our model is that
it does not require manual segmentation of the region of interest, hence
reducing clinician's burden. Further development in generalising multicentre
data set are needed before clinical application of deep learning models in
assessment of NPC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11880</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11880</id><created>2019-07-27</created><authors><author><keyname>Lenka</keyname><forenames>Manoj Kumar</forenames></author><author><keyname>Pandey</keyname><forenames>Anubha</forenames></author><author><keyname>Mittal</keyname><forenames>Anurag</forenames></author></authors><title>Blind Deblurring Using GANs</title><categories>eess.IV cs.CV</categories><comments>15 Pages (including reference and appendices). 6 Figures. 5 Tables
  (including appendices). Work done as a part of the Summer Research Fellowship
  Program by the Indian Academy of Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deblurring is the task of restoring a blurred image to a sharp one,
retrieving the information lost due to the blur. In blind deblurring we have no
information regarding the blur kernel. As deblurring can be considered as an
image to image translation task, deep learning based solutions, including the
ones which use GAN (Generative Adversarial Network), have been proven effective
for deblurring. Most of them have an encoder-decoder structure. Our objective
is to try different GAN structures and improve its performance through various
modifications to the existing structure for supervised deblurring. In
supervised deblurring we have pairs of blurred and their corresponding sharp
images, while in the unsupervised case we have a set of blurred and sharp
images but their is no correspondence between them. Modifications to the
structures is done to improve the global perception of the model. As blur is
non-uniform in nature, for deblurring we require global information of the
entire image, whereas convolution used in CNN is able to provide only local
perception. Deep models can be used to improve global perception but due to
large number of parameters it becomes difficult for it to converge and
inference time increases, to solve this we propose the use of attention module
(non-local block) which was previously used in language translation and other
image to image translation tasks in deblurring. Use of residual connection also
improves the performance of deblurring as features from the lower layers are
added to the upper layers of the model. It has been found that classical losses
like L1, L2, and perceptual loss also help in training of GANs when added
together with adversarial loss. We also concatenate edge information of the
image to observe its effects on deblurring. We also use feedback modules to
retain long term dependencies
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11881</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11881</id><created>2019-07-27</created><updated>2019-12-24</updated><authors><author><keyname>Neogi</keyname><forenames>Satyajit</forenames></author><author><keyname>Hoy</keyname><forenames>Michael</forenames></author><author><keyname>Dang</keyname><forenames>Kang</forenames></author><author><keyname>Yu</keyname><forenames>Hang</forenames></author><author><keyname>Dauwels</keyname><forenames>Justin</forenames></author></authors><title>Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields</title><categories>cs.CV cs.RO eess.IV stat.ML</categories><comments>Submitted to IEEE Transactions on Intelligent Transportation Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smooth handling of pedestrian interactions is a key requirement for
Autonomous Vehicles (AV) and Advanced Driver Assistance Systems (ADAS). Such
systems call for early and accurate prediction of a pedestrian's
crossing/not-crossing behaviour in front of the vehicle. Existing approaches to
pedestrian behaviour prediction make use of pedestrian motion, his/her location
in a scene and static context variables such as traffic lights, zebra crossings
etc. We stress on the necessity of early prediction for smooth operation of
such systems. We introduce the influence of vehicle interactions on pedestrian
intention for this purpose. In this paper, we show a discernible advance in
prediction time aided by the inclusion of such vehicle interaction context. We
apply our methods to two different datasets, one in-house collected - NTU
dataset and another public real-life benchmark - JAAD dataset. We also propose
a generic graphical model Factored Latent-Dynamic Conditional Random Fields
(FLDCRF) for single and multi-label sequence prediction as well as joint
interaction modeling tasks. FLDCRF outperforms Long Short-Term Memory (LSTM)
networks across the datasets ($\sim$100 sequences per dataset) over identical
time-series features. While the existing best system predicts pedestrian
stopping behaviour with 70\% accuracy 0.38 seconds before the actual events,
our system achieves such accuracy at least 0.9 seconds on an average before the
actual events across datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11898</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11898</id><created>2019-07-27</created><authors><author><keyname>Huang</keyname><forenames>Wen-Chin</forenames></author><author><keyname>Wu</keyname><forenames>Yi-Chiao</forenames></author><author><keyname>Kobayashi</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Peng</keyname><forenames>Yu-Huai</forenames></author><author><keyname>Hwang</keyname><forenames>Hsin-Te</forenames></author><author><keyname>Tobing</keyname><forenames>Patrick Lumban</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author></authors><title>Generalization of Spectrum Differential based Direct Waveform
  Modification for Voice Conversion</title><categories>eess.AS eess.SP</categories><comments>6 pages, 4 figures, 1 table; accepted to the 10th ISCA speech
  synthesis workshop (SSW10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a modification to the spectrum differential based direct waveform
modification for voice conversion (DIFFVC) so that it can be directly applied
as a waveform generation module to voice conversion models. The recently
proposed DIFFVC avoids the use of a vocoder, meanwhile preserves rich spectral
details hence capable of generating high quality converted voice. To apply the
DIFFVC framework, a model that can estimate the spectral differential from the
F0 transformed input speech needs to be trained beforehand. This requirement
imposes several constraints, including a limitation on the estimation model to
parallel training and the need of extra training on each conversion pair, which
make DIFFVC inflexible. Based on the above motivations, we propose a new DIFFVC
framework based on an F0 transformation in the residual domain. By performing
inverse filtering on the input signal followed by synthesis filtering on the F0
transformed residual signal using the converted spectral features directly, the
spectral conversion model does not need to be retrained or capable of
predicting the spectral differential. We describe several details that need to
be taken care of under this modification, and by applying our proposed method
to a non-parallel, variational autoencoder (VAE)-based spectral conversion
model, we demonstrate that this framework can be generalized to any spectral
conversion model, and experimental evaluations show that it can outperform a
baseline framework whose waveform generation process is carried out by a
vocoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11899</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11899</id><created>2019-07-27</created><authors><author><keyname>Scannell</keyname><forenames>Cian M.</forenames></author><author><keyname>Bosch</keyname><forenames>Piet van den</forenames></author><author><keyname>Chiribiri</keyname><forenames>Amedeo</forenames></author><author><keyname>Lee</keyname><forenames>Jack</forenames></author><author><keyname>Breeuwer</keyname><forenames>Marcel</forenames></author><author><keyname>Veta</keyname><forenames>Mitko</forenames></author></authors><title>Deep learning-based prediction of kinetic parameters from myocardial
  perfusion MRI</title><categories>eess.IV cs.CV physics.med-ph q-bio.QM</categories><comments>Medical Imaging with Deep Learning: MIDL 2019 Extended Abstract
  Track. MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/HyxyNmQAF4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The quantification of myocardial perfusion MRI has the potential to provide a
fast, automated and user-independent assessment of myocardial ischaemia.
However, due to the relatively high noise level and low temporal resolution of
the acquired data and the complexity of the tracer-kinetic models, the model
fitting can yield unreliable parameter estimates. A solution to this problem is
the use of Bayesian inference which can incorporate prior knowledge and improve
the reliability of the parameter estimation. This, however, uses Markov chain
Monte Carlo sampling to approximate the posterior distribution of the kinetic
parameters which is extremely time intensive. This work proposes training
convolutional networks to directly predict the kinetic parameters from the
signal-intensity curves that are trained using estimates obtained from the
Bayesian inference. This allows fast estimation of the kinetic parameters with
a similar performance to the Bayesian inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11901</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11901</id><created>2019-07-27</created><authors><author><keyname>Nurdin</keyname><forenames>Hendra I.</forenames></author></authors><title>Quantum Stochastic Processes and the Modelling of Quantum Noise</title><categories>quant-ph cs.SY eess.SY</categories><comments>14 pages, invited article for the second edition of Springer's
  Encyclopedia of Systems and Control (to appear). Comments welcome</comments><journal-ref>Encyclopedia of Systems and Control, Living Edition (Eds. J.
  Baillieul and T. Samad), 2020</journal-ref><doi>10.1007/978-1-4471-5102-9_100160-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This brief article gives an overview of quantum mechanics as a {\em quantum
probability theory}. It begins with a review of the basic operator-algebraic
elements that connect probability theory with quantum probability theory. Then
quantum stochastic processes is formulated as a generalization of stochastic
processes within the framework of quantum probability theory. Quantum Markov
models from quantum optics are used to explicitly illustrate the underlying
abstract concepts and their connections to the quantum regression theorem from
quantum optics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11904</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11904</id><created>2019-07-27</created><authors><author><keyname>Qian</keyname><forenames>Cheng</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author></authors><title>Amplitude Retrieval for Channel Estimation of MIMO Systems with One-Bit
  ADCs</title><categories>eess.SP</categories><doi>10.1109/LSP.2019.2945490</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter revisits the channel estimation problem for MIMO systems with
one-bit analog-to-digital converters (ADCs) through a novel
algorithm--Amplitude Retrieval (AR). Unlike the state-of-the-art methods such
as those based on one-bit compressive sensing, AR takes a different approach.
It accounts for the lost amplitudes of the one-bit quantized measurements, and
performs channel estimation and amplitude completion jointly. This way, the
direction information of the propagation paths can be estimated via accurate
direction finding algorithms in array processing, e.g., maximum likelihood. The
upsot is that AR is able to handle off-grid angles and provide more accurate
channel estimates. Simulation results are included to showcase the advantages
of AR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11913</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11913</id><created>2019-07-27</created><authors><author><keyname>Gaudio</keyname><forenames>Joseph E.</forenames></author><author><keyname>Annaswamy</keyname><forenames>Anuradha M.</forenames></author><author><keyname>Bolender</keyname><forenames>Michael A.</forenames></author><author><keyname>Lavretsky</keyname><forenames>Eugene</forenames></author></authors><title>Adaptive Flight Control in the Presence of Limits on Magnitude and Rate</title><categories>math.OC cs.SY eess.SY</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Input constraints as well as parametric uncertainties must be accounted for
in the design of safe control systems. This paper presents an adaptive
controller for multiple-input-multiple-output (MIMO) plants with input
magnitude and rate saturation in the presence of parametric uncertainties. A
filter is introduced in the control path to accommodate the presence of rate
limits. An output feedback adaptive controller is designed to stabilize the
closed loop system even in the presence of this filter. The overall control
architecture includes adaptive laws that are modified to account for the
magnitude and rate limits. Analytical guarantees of bounded solutions and
satisfactory tracking are provided. Three flight control simulations with
nonlinear models of the aircraft dynamics are provided to demonstrate the
efficacy of the proposed adaptive controller for open loop stable and unstable
systems in the presence of uncertainties in the dynamics as well as input
magnitude and rate saturation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11921</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11921</id><created>2019-07-27</created><authors><author><keyname>Yu</keyname><forenames>Zitong</forenames></author><author><keyname>Peng</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Xiaobai</forenames></author><author><keyname>Hong</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Zhao</keyname><forenames>Guoying</forenames></author></authors><title>Remote Heart Rate Measurement from Highly Compressed Facial Videos: an
  End-to-end Deep Learning Solution with Video Enhancement</title><categories>eess.IV cs.CV</categories><comments>IEEE ICCV2019, accepted</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Remote photoplethysmography (rPPG), which aims at measuring heart activities
without any contact, has great potential in many applications (e.g., remote
healthcare). Existing rPPG approaches rely on analyzing very fine details of
facial videos, which are prone to be affected by video compression. Here we
propose a two-stage, end-to-end method using hidden rPPG information
enhancement and attention networks, which is the first attempt to counter video
compression loss and recover rPPG signals from highly compressed videos. The
method includes two parts: 1) a Spatio-Temporal Video Enhancement Network
(STVEN) for video enhancement, and 2) an rPPG network (rPPGNet) for rPPG signal
recovery. The rPPGNet can work on its own for robust rPPG measurement, and the
STVEN network can be added and jointly trained to further boost the performance
especially on highly compressed videos. Comprehensive experiments are performed
on two benchmark datasets to show that, 1) the proposed method not only
achieves superior performance on compressed videos with high-quality videos
pair, 2) it also generalizes well on novel data with only compressed videos
available, which implies the promising potential for real world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11944</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11944</id><created>2019-07-27</created><authors><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Sun</keyname><forenames>Jingzhang</forenames></author><author><keyname>Mok</keyname><forenames>Greta S. P.</forenames></author></authors><title>Low dose SPECT image denoising using a generative adversarial network</title><categories>eess.IV</categories><comments>International Conference on Medical Imaging with Deep Learning 2019.
  MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/Skxgj3SntN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The image noise level and resolution of SPECT images are relatively poor
attributed to the limited number of detected counts and various physical
degradation factors during acquisitions. This study aims to apply and evaluate
the use of generative adversarial network (GAN) method in static SPECT image
denoising. A population of 4D extended cardiac-torso (XCAT) phantoms were used
to simulate 10 male and female patients with different organ sizes and activity
uptakes. An analytical projector was applied to simulate 120 projections from
right anterior oblique to left posterior oblique positions with two noise
levels. The first noise level was based on a standard clinical count rate of
987 MBq injection and 16 min acquisition (low noise) while the other was 1/8 of
the previous count rate (high noise). The high noise and low noise SPECT
reconstructed images of 9 patients, i.e., 1026 images (9*114 axial slices)
respectively, were paired for training. High noise SPECT images of 1 patient
were tested using the trained GAN. The noise level is substantially reduced in
high noise SPECT reconstructed images after using the GAN. Our method has the
potential to decrease the noise level of SPECT images, which could be traded
for a reduced injection dose or acquisition time while still maintaining the
similar image quality as compared to the original low noise images for clinical
diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11953</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11953</id><created>2019-07-27</created><authors><author><keyname>Hamidinekoo</keyname><forenames>Azam</forenames></author><author><keyname>Denton</keyname><forenames>Erika</forenames></author><author><keyname>Zwiggelaar</keyname><forenames>Reyer</forenames></author></authors><title>Automated Mammogram Analysis with a Deep Learning Pipeline</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BJeZW6GXqN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Current deep learning based detection models tackle detection and
segmentation tasks by casting them to pixel or patch-wise classification. To
automate the initial mass lesion detection and segmentation on the whole
mammographic images and avoid the computational redundancy of patch-based and
sliding window approaches, the conditional generative adversarial network
(cGAN) was used in this study. Subsequently, feeding the detected regions to
the trained densely connected network (DenseNet), the binary classification of
benign versus malignant was predicted. We used a combination of publicly
available mammographic data repositories to train the pipeline, while
evaluating the model's robustness toward our clinically collected repository,
which was unseen to the pipeline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11956</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11956</id><created>2019-07-27</created><authors><author><keyname>Gong</keyname><forenames>Shuyu</forenames></author><author><keyname>Wang</keyname><forenames>Zhewei</forenames></author><author><keyname>Sun</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Yuanhang</forenames></author><author><keyname>Smith</keyname><forenames>Charles D.</forenames></author><author><keyname>Xu</keyname><forenames>Li</forenames></author><author><keyname>Liu</keyname><forenames>Jundong</forenames></author></authors><title>Dilated FCN: Listening Longer to Hear Better</title><categories>cs.SD eess.AS</categories><comments>5 pages; will appear in WASPAA conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural network solutions have emerged as a new and powerful paradigm for
speech enhancement (SE). The capabilities to capture long context and extract
multi-scale patterns are crucial to design effective SE networks. Such
capabilities, however, are often in conflict with the goal of maintaining
compact networks to ensure good system generalization. In this paper, we
explore dilation operations and apply them to fully convolutional networks
(FCNs) to address this issue. Dilations equip the networks with greatly
expanded receptive fields, without increasing the number of parameters.
Different strategies to fuse multi-scale dilations, as well as to install the
dilation modules are explored in this work. Using Noisy VCTK and AzBio
sentences datasets, we demonstrate that the proposed dilation models
significantly improve over the baseline FCN and outperform the state-of-the-art
SE solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11972</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11972</id><created>2019-07-27</created><authors><author><keyname>Cheng</keyname><forenames>Qian</forenames></author><author><keyname>Fusco</keyname><forenames>Vincent</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Wang</keyname><forenames>Shilian</forenames></author><author><keyname>Gu</keyname><forenames>Chao</forenames></author></authors><title>SVD-Aided Multi-Beam Directional Modulation Scheme Based on Frequency
  Diverse Array</title><categories>eess.SP</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the assistance of singular value decomposition (SVD), a multi-beam
directional modulation (DM) scheme based on symmetrical multi-carrier frequency
diverse array (FDA) is proposed. The proposed DM scheme is capable of achieving
range-angle dependent physical layer secure (PLS) transmissions in free space
with much lower complexity than the conventional zero-forcing (ZF) method.
Theoretical and simulated results about secrecy rate and complexity verify the
improved computational efficiency and considerable memory savings despite a
very small penalty of secrecy rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11989</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11989</id><created>2019-07-27</created><authors><author><keyname>Amiri</keyname><forenames>Delaram</forenames></author><author><keyname>Anzanpour</keyname><forenames>Arman</forenames></author><author><keyname>Azimi</keyname><forenames>Iman</forenames></author><author><keyname>Rahmani</keyname><forenames>Amir M.</forenames></author><author><keyname>Liljeberg</keyname><forenames>Pasi</forenames></author><author><keyname>Dutt</keyname><forenames>Nikil</forenames></author><author><keyname>Levorato</keyname><forenames>Marco</forenames></author></authors><title>Optimizing Energy Efficiency of Wearable Sensors Using Fog-assisted
  Control</title><categories>eess.SP cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in the Internet of Things (IoT) technologies have enabled the
use of wearables for remote patient monitoring. Wearable sensors capture the
patient's vital signs, and provide alerts or diagnosis based on the collected
data. Unfortunately, wearables typically have limited energy and computational
capacity, making their use challenging for healthcare applications where
monitoring must continue uninterrupted long time, without the need to charge or
change the battery. Fog computing can alleviate this problem by offloading
computationally intensive tasks from the sensor layer to higher layers, thereby
not only meeting the sensors' limited computational capacity but also enabling
the use of local closed-loop energy optimization algorithms to increase the
battery life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11990</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11990</id><created>2019-07-27</created><authors><author><keyname>Sardarmehni</keyname><forenames>Tohid</forenames></author><author><keyname>Song</keyname><forenames>Xingyong</forenames></author></authors><title>Sub-optimal Tracking in Switched Systems with Controlled Subsystems and
  Fixed-mode Sequence using Approximate Dynamic Programming</title><categories>eess.SY cs.SY</categories><comments>6 pages, 2 figures, This article has been accepted for oral
  presentation at 2019 Dynamic System and Control Conference. The content is
  the same as the final edition of the accepted paper. However, the
  presentation might be different</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal tracking in switched systems with controlled subsystem and
Discrete-time (DT) dynamics is investigated. A feedback control policy is
generated such that a) the system tracks the desired reference signal, and b)
the optimal switching time instants are sought. For finding the optimal
solution, approximate dynamic programming is used. Simulation results are
provided to illustrate the effectiveness of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.11993</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.11993</id><created>2019-07-27</created><authors><author><keyname>Sardarmehni</keyname><forenames>Tohid</forenames></author><author><keyname>Song</keyname><forenames>Xingyong</forenames></author></authors><title>Sub-optimal Control of Autonomous Wheel loader with Approximate Dynamic
  Programming</title><categories>eess.SY cs.SY</categories><comments>This article has been accepted for oral presentation at 2019 Dynamic
  System and Control Conference. The content might NOT be the same as the final
  edition of the accepted paper for the DSCC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal control of wheel loaders in short loading cycles is studied in this
paper. For modeling the wheel loader, the data from a validated diesel engine
model is used to find a control oriented mean value engine model. The driveline
is modeled as a switched system with three constant gear ratios (modes) of
$-60$ for backwarding, $60$ for forwarding, and zero for stopping. With these
three modes, the sequence of active modes in a short loading cycle is fixed as
backwarding, stopping, forwarding, and stopping. For the control part, it is
assumed that the optimal path is known a priori. Given the mode sequence, the
control objective is finding the optimal switching time instants between the
modes while the wheel loader tracks the optimal path. To solve the optimal
control problem, approximate dynamic programming is used. Simulation results
are provided to show the effectiveness of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12023</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12023</id><created>2019-07-28</created><authors><author><keyname>Wang</keyname><forenames>Weisen</forenames></author><author><keyname>Xu</keyname><forenames>Zhiyan</forenames></author><author><keyname>Yu</keyname><forenames>Weihong</forenames></author><author><keyname>Zhao</keyname><forenames>Jianchun</forenames></author><author><keyname>Yang</keyname><forenames>Jingyuan</forenames></author><author><keyname>He</keyname><forenames>Feng</forenames></author><author><keyname>Yang</keyname><forenames>Zhikun</forenames></author><author><keyname>Chen</keyname><forenames>Di</forenames></author><author><keyname>Ding</keyname><forenames>Dayong</forenames></author><author><keyname>Chen</keyname><forenames>Youxin</forenames></author><author><keyname>Li</keyname><forenames>Xirong</forenames></author></authors><title>Two-Stream CNN with Loose Pair Training for Multi-modal AMD
  Categorization</title><categories>eess.IV cs.CV</categories><comments>accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies automated categorization of age-related macular
degeneration (AMD) given a multi-modal input, which consists of a color fundus
image and an optical coherence tomography (OCT) image from a specific eye.
Previous work uses a traditional method, comprised of feature extraction and
classifier training that cannot be optimized jointly. By contrast, we propose a
two-stream convolutional neural network (CNN) that is end-to-end. The CNN's
fusion layer is tailored to the need of fusing information from the fundus and
OCT streams. For generating more multi-modal training instances, we introduce
Loose Pair training, where a fundus image and an OCT image are paired based on
class labels rather than eyes. Moreover, for a visual interpretation of how the
individual modalities make contributions, we extend the class activation
mapping technique to the multi-modal scenario. Experiments on a real-world
dataset collected from an outpatient clinic justify the viability of our
proposal for multi-modal AMD categorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12042</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12042</id><created>2019-07-28</created><updated>2019-09-05</updated><authors><author><keyname>Yang</keyname><forenames>Linfu</forenames></author><author><keyname>Liu</keyname><forenames>Bin</forenames></author></authors><title>Temporal Data Fusion at the Edge</title><categories>cs.DC eess.SP</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an enabler technique, data fusion has gained great attention in the
context of Internet of things (IoT). In traditional settings, data fusion is
done at the cloud server. So the data to be fused should be transferred from
the sensor nodes to the cloud server before data fusion. Such an application
mode of data fusion inherits disturbing concerns from the cloud computing
framework, e.g., privacy-leaking, large latency between data capture and
computation, excessive ingress bandwidth consumption. We take into account how
to do temporal data fusion at the edge to bypass the above issues. We present a
Gaussian process based temporal data fusion (GPTDF) method targeted for the
problem of sequential online prediction at the edge. The GPTDF method fits the
edge computing framework and thus inherits desirable properties from edge
computing, such as privacy-preserving, low latency between data capture and
computation, and tiny bandwidth consumption. Through a real-data experiment
using archived traffic datasets from the Caltrans Performance Measurement
System (PeMS), we demonstrate that the application of GPTDF can provide more
timely and accurate real-time predictions at the network edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12054</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12054</id><created>2019-07-28</created><authors><author><keyname>Yang</keyname><forenames>Peng</forenames></author><author><keyname>Liu</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Zhaojian</forenames></author><author><keyname>Ma</keyname><forenames>Shicong</forenames></author></authors><title>Towards Distributed Stability Analytics of Dynamic Power Systems: A
  Phasor-Circuit Theory Perspective</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of renewable and distributed energies, the
underlying dynamics of power systems are no longer dominated by large
synchronous generators, but by numerous dynamic components with heterogeneous
characteristics. In such a situation, the traditional stability analysis method
may fail due to the challenges of heterogeneity and scalability. In this paper,
we handle this issue by fundamental circuit theory. Inspired by the work of
Brayton and Moser in the nonlinear RLC circuit, we extend the concept of the
voltage potential to phasor circuits and offer new results into the distributed
stability analytics in power systems. We show that under certain distributed
passivity-like conditions the system-wide stability can be ensured. The
simulation of a 3-bus system is also provided to verify our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12056</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12056</id><created>2019-07-28</created><authors><author><keyname>Gao</keyname><forenames>Yunhe</forenames></author><author><keyname>Huang</keyname><forenames>Rui</forenames></author><author><keyname>Chen</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Zhe</forenames></author><author><keyname>Deng</keyname><forenames>Jincheng</forenames></author><author><keyname>Chen</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Yang</keyname><forenames>Yiwei</forenames></author><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Tao</keyname><forenames>Chanjuan</forenames></author><author><keyname>Li</keyname><forenames>Hongsheng</forenames></author></authors><title>FocusNet: Imbalanced Large and Small Organ Segmentation with an
  End-to-End Deep Neural Network for Head and Neck CT Images</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an end-to-end deep neural network for solving the
problem of imbalanced large and small organ segmentation in head and neck (HaN)
CT images. To conduct radiotherapy planning for nasopharyngeal cancer, more
than 10 organs-at-risk (normal organs) need to be precisely segmented in
advance. However, the size ratio between large and small organs in the head
could reach hundreds. Directly using such imbalanced organ annotations to train
deep neural networks generally leads to inaccurate small-organ label maps. We
propose a novel end-to-end deep neural network to solve this challenging
problem by automatically locating, ROI-pooling, and segmenting small organs
with specifically designed small-organ sub-networks while maintaining the
accuracy of large organ segmentation. A strong main network with densely
connected atrous spatial pyramid pooling and squeeze-and-excitation modules is
used for segmenting large organs, where large organs' label maps are directly
output. For small organs, their probabilistic locations instead of label maps
are estimated by the main network. High-resolution and multi-scale feature
volumes for each small organ are ROI-pooled according to their locations and
are fed into small-organ networks for accurate segmenting small organs. Our
proposed network is extensively tested on both collected real data and the
\emph{MICCAI Head and Neck Auto Segmentation Challenge 2015} dataset, and shows
superior performance compared with state-of-the-art segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12070</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12070</id><created>2019-07-28</created><updated>2019-07-31</updated><authors><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Zhu</keyname><forenames>Lingling</forenames></author><author><keyname>Cai</keyname><forenames>Wenlong</forenames></author><author><keyname>Shen</keyname><forenames>Tong</forenames></author><author><keyname>Lin</keyname><forenames>Jinyong</forenames></author><author><keyname>Zhang</keyname><forenames>Shuo</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author></authors><title>Two Efficient Beamformers for Secure Precise Jamming and Communication
  with Phase Alignment</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To achieve a better effect of interference on eavesdropper with an enhanced
security, a secure precise jamming (PJ) and communication (SPJC) is proposed
and its basic idea is to force the transmit energy of artificial noise (AN) and
confidential message into the neighborhoods of Eve and Bob by using random
subcarrier selection (RSS), directional modulation, and beamforming under phase
alignment (PA) constraint (PAC). Here, we propose two high-performance
beamforming schemes: minimum transmit power (Min-TP) and minimum regularized
transmit power (Min-RTP) to achieve SPJC under PAC and orthogonal constraint
(OC), where OC means that AN and CM are projected onto the null-spaces of the
desired and eavesdropping channels, respectively. Simulation results show that
the proposed Min-TP and Min-RTP methods perform much better than existing equal
amplitude (EA) method in terms of both bit-error-rate (BER) and secrecy rate
(SR) at medium and high signal-to-noise ratio regions. The SR performance
difference between the proposed two methods becomes trivial as the number of
transmit antennas approaches large-scale. More importantly, we also find the
fact that all three schemes including EA, Min-TP, and Min-RTP can form two main
peaks of AN and CM around Eve and Bob, respectively. This achieves both PJ and
secure precise wireless transmission (SPWT), called SPJC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12075</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12075</id><created>2019-07-28</created><updated>2019-12-13</updated><authors><author><keyname>Wang</keyname><forenames>Zheming</forenames></author><author><keyname>Jungers</keyname><forenames>Rapha&#xeb;l M.</forenames></author></authors><title>Data-driven computation of invariant sets of discrete time-invariant
  black-box systems</title><categories>eess.SY cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing the maximal invariant set of
discrete-time black-box nonlinear systems without analytic dynamical models.
Under the assumption that the system is asymptotically stable, the maximal
invariant set coincides with the domain of attraction. A data-driven framework
relying on the observation of trajectories is proposed to compute
almost-invariant sets, which are invariant almost everywhere except a small
subset. Based on these observations, scenario optimization problems are
formulated and solved. We show that probabilistic invariance guarantees on the
almost-invariant sets can be established. To get explicit expressions of such
sets, a set identification procedure is designed with a verification step that
provides inner and outer approximations in a probabilistic sense. The proposed
data-driven framework is illustrated by several numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12109</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12109</id><created>2019-07-28</created><authors><author><keyname>Thomson</keyname><forenames>Bart R.</forenames></author><author><keyname>Nijkamp</keyname><forenames>Jasper</forenames></author><author><keyname>Ivashchenko</keyname><forenames>Oleksandra</forenames></author><author><keyname>van der Heijden</keyname><forenames>Ferdinand</forenames></author><author><keyname>Smit</keyname><forenames>Jasper N.</forenames></author><author><keyname>Kok</keyname><forenames>Niels F. M.</forenames></author><author><keyname>Kuhlmann</keyname><forenames>Koert F. D.</forenames></author><author><keyname>Ruers</keyname><forenames>Theo J. M.</forenames></author><author><keyname>Fusaglia</keyname><forenames>Matteo</forenames></author></authors><title>Hepatic vessel segmentation using a reduced filter 3D U-Net in
  ultrasound imaging</title><categories>eess.IV</categories><comments>3 pages, conference extended abstract. MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BklfuXG0KV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Accurate hepatic vessel segmentation on ultrasound (US) images can be an
important tool in the planning and execution of surgery, however proves to be a
challenging task due to noise and speckle. Our method comprises a reduced
filter 3D U-Net implementation to automatically detect hepatic vasculature in
3D US volumes. A comparison is made between volumes acquired with a 3D probe
and stacked 2D US images based on electromagnetic tracking. Experiments are
conducted on 67 scans, where 45 are used in training, 12 in validation and 10
in testing. This network architecture yields Dice scores of 0.740 and 0.781 for
3D and stacked 2D volumes respectively, comparing promising to literature and
inter-observer performance (Dice = 0.879).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12120</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12120</id><created>2019-07-28</created><authors><author><keyname>Guiomar</keyname><forenames>F. P.</forenames></author><author><keyname>Lorences-Riesgo</keyname><forenames>A.</forenames></author><author><keyname>Ranzal</keyname><forenames>D.</forenames></author><author><keyname>Rocco</keyname><forenames>F.</forenames></author><author><keyname>Sousa</keyname><forenames>A. N.</forenames></author><author><keyname>Carena</keyname><forenames>A.</forenames></author><author><keyname>Teixeira</keyname><forenames>A. L.</forenames></author><author><keyname>Medeiros</keyname><forenames>M. C. R.</forenames></author><author><keyname>Monteiro</keyname><forenames>P. P.</forenames></author></authors><title>High-Capacity and Rain-Resilient Free-Space Optics Link Enabled by
  Time-Adaptive Probabilistic Shaping</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using time-adaptive probabilistic shaped 64QAM driven by a simple SNR
prediction algorithm, we demonstrate $&gt;$450 Gbps transmission over a 55-m
free-space optics link with enhanced resilience towards rainy weather
conditions. Through continuous measurement over 3-hours, we demonstrate
$\sim$40~Gbps average bit-rate gain over unsupervised fixed modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12127</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12127</id><created>2019-07-28</created><authors><author><keyname>Ghosal</keyname><forenames>Sandip</forenames></author><author><keyname>De</keyname><forenames>Arijit</forenames></author><author><keyname>Shubair</keyname><forenames>Raed M.</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Ajay</forenames></author></authors><title>Near-Field Radiation Exposure Control in Slot-Loaded Microstrip Antenna:
  A Characteristic Mode Approach</title><categories>eess.SP</categories><comments>21 Pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Microstip antenna topology is commonly loaded with a narrow slot to
manipulate the resonance frequency or impedance bandwidth. However, the tuning
of the resonance frequency or impedance bandwidth results in the variation of
the current and field distributions. In this regard, this work adopts the
concept of characteristic modes to gain an initial understanding of the
perturbation mechanism of the rectangular patch when loaded with a slot. The
performance of microstrip antennas with finite ground plane is then studied
using full-wave simulation. It has been found that the distribution of the
induced current density is highly dependent on the orientation of the slot The
incorporation of a narrow slot suppresses the nearby orthogonal eigen mode and,
as a consequence, the radiation behavior is affected. Specifically, in the
presence of biological tissues in the near-field region, both antenna input
impedance properties and the realized gain are dependent on the slot
orientation. Different examples are included for understanding the impact of
slot loading on the energy absorption by biological tissues, by calculating the
the specific absorption rate (SAR). The proposed analysis facilitates the
design of miniaturized antenna geometries for biomedical applications via
systematic loading of narrow slots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12146</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12146</id><created>2019-07-28</created><authors><author><keyname>Scholl</keyname><forenames>Tessina H.</forenames></author><author><keyname>Hagenmeyer</keyname><forenames>Veit</forenames></author><author><keyname>Gr&#xf6;ll</keyname><forenames>Lutz</forenames></author></authors><title>On Norm-Based Estimations for Domains of Attraction in Nonlinear Time
  Delay Systems</title><categories>eess.SY cs.SY nlin.CD</categories><comments>8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For nonlinear time delay systems, domains of attraction are rarely studied
despite their importance for technological applications. The present paper
introduces a novel method to determine an upper bound on the radius of
attraction by a numerical approach. Thereby, the respective Banach space for
initial functions has to be selected and primary initial functions have to be
chosen. The latter are used in time forward simulations to determine a first
upper bound on the radius of attraction. Thereafter, this upper bound is
refined by secondary initial functions which result a posteriori from the
preceding simulations. Additionally, a bifurcation analysis is undertaken with
the time delay as bifurcation parameter. This analysis results in a possible
improvement of the previous estimation. An example of a time-delayed swing
equation demonstrates the overall methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12155</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12155</id><created>2019-07-25</created><updated>2019-12-11</updated><authors><author><keyname>Co&#xeb;nt</keyname><forenames>Adrien Le</forenames><affiliation>LSV, ENS Paris Saclay, CNRS</affiliation></author><author><keyname>Fribourg</keyname><forenames>Laurent</forenames><affiliation>LSV, ENS Paris Saclay, CNRS</affiliation></author></authors><title>Guaranteed optimal reachability control of reaction-diffusion equations
  using one-sided Lipschitz constants and model reduction</title><categories>math.OC cs.SY eess.SY</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that, for any spatially discretized system of reaction-diffusion, the
approximate solution given by the explicit Euler time-discretization scheme
converges to the exact time-continuous solution, provided that diffusion
coefficient be sufficiently large. By &quot;sufficiently large&quot;, we mean that the
diffusion coefficient value makes the one-sided Lipschitz constant of the
reaction-diffusion system negative. We apply this result to solve a finite
horizon control problem for a 1D reaction-diffusion example. We also explain
how to perform model reduction in order to improve the efficiency of the
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12157</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12157</id><created>2019-07-22</created><authors><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author><author><keyname>Manta</keyname><forenames>Alexander</forenames></author><author><keyname>Meggendorfer</keyname><forenames>Tobias</forenames></author></authors><title>Semantic Labelling and Learning for Parity Game Solving in LTL Synthesis</title><categories>cs.LO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose &quot;semantic labelling&quot; as a novel ingredient for solving games in
the context of LTL synthesis. It exploits recent advances in the automata-based
approach, yielding more information for each state of the generated parity game
than the game graph can capture. We utilize this extra information to improve
standard approaches as follows. (i) Compared to strategy improvement (SI) with
random initial strategy, a more informed initialization often yields a winning
strategy directly without any computation. (ii) This initialization makes SI
also yield smaller solutions. (iii) While Q-learning on the game graph turns
out not too efficient, Q-learning with the semantic information becomes
competitive to SI. Since already the simplest heuristics achieve significant
improvements the experimental results demonstrate the utility of semantic
labelling. This extra information opens the door to more advanced learning
approaches both for initialization and improvement of strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12165</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12165</id><created>2019-07-28</created><updated>2020-01-10</updated><authors><author><keyname>Kennedy</keyname><forenames>Hugh L</forenames></author></authors><title>On the Realization and Analysis of Circular Harmonic Transforms for
  Feature Detection</title><categories>cs.CV eess.IV</categories><comments>Fixed some subscript (x,y) typos, e.g. in Eqn (4) and elsewhere in
  text</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circular-harmonic spectra are a compact representation of local image
features in two dimensions. It is well known that the computational complexity
of such transforms is greatly reduced when polar separability is exploited in
steerable filter-banks. Further simplifications are possible when Cartesian
separability is incorporated using the radial apodization (i.e. weight, window,
or taper) described here, as a consequence of the Laguerre/Hermite
correspondence over polar/Cartesian coordinates. The chosen form also mitigates
undesirable discretization artefacts due to angular aliasing. The possible
utility of circular-harmonic spectra for the description of simple features is
illustrated using real data from an airborne electro-optic sensor. The spectrum
is deployed in a test-statistic to detect and characterize corners of arbitrary
angle and orientation (i.e. wedges). The test-statistic considers uncertainty
due to finite sampling and clutter/noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12175</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12175</id><created>2019-07-28</created><authors><author><keyname>Ramazi</keyname><forenames>Ramin</forenames></author><author><keyname>Perndorfer</keyname><forenames>Christine</forenames></author><author><keyname>Soriano</keyname><forenames>Emily</forenames></author><author><keyname>Laurenceau</keyname><forenames>Jean-Philippe</forenames></author><author><keyname>Beheshti</keyname><forenames>Rahmatollah</forenames></author></authors><title>Multi-modal Predictive Models of Diabetes Progression</title><categories>cs.LG eess.SP stat.ML</categories><doi>10.1145/3307339.3342177</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing availability of wearable devices, continuous monitoring
of individuals' physiological and behavioral patterns has become significantly
more accessible. Access to these continuous patterns about individuals'
statuses offers an unprecedented opportunity for studying complex diseases and
health conditions such as type 2 diabetes (T2D). T2D is a widely common chronic
disease that its roots and progression patterns are not fully understood.
Predicting the progression of T2D can inform timely and more effective
interventions to prevent or manage the disease. In this study, we have used a
dataset related to 63 patients with T2D that includes the data from two
different types of wearable devices worn by the patients: continuous glucose
monitoring (CGM) devices and activity trackers (ActiGraphs). Using this
dataset, we created a model for predicting the levels of four major biomarkers
related to T2D after a one-year period. We developed a wide and deep neural
network and used the data from the demographic information, lab tests, and
wearable sensors to create the model. The deep part of our method was developed
based on the long short-term memory (LSTM) structure to process the time-series
dataset collected by the wearables. In predicting the patterns of the four
biomarkers, we have obtained a root mean square error of 1.67% for HBA1c, 6.22
mg/dl for HDL cholesterol, 10.46 mg/dl for LDL cholesterol, and 18.38 mg/dl for
Triglyceride. Compared to existing models for studying T2D, our model offers a
more comprehensive tool for combining a large variety of factors that
contribute to the disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12178</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12178</id><created>2019-07-28</created><updated>2019-08-24</updated><authors><author><keyname>Lane</keyname><forenames>Thomas J.</forenames></author><author><keyname>Ratner</keyname><forenames>Daniel</forenames></author></authors><title>What are the advantages of ghost imaging? Multiplexing for x-ray and
  electron imaging</title><categories>physics.app-ph eess.IV</categories><comments>13 pages, 4 figures, preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ghost imaging, Fourier transform spectroscopy, and the newly developed
Hadamard transform crystallography are all examples of multiplexing measurement
strategies. Multiplexed experiments are performed by measuring multiple points
in space, time, or energy simultaneously. This contrasts to the usual method of
systematically scanning single points. How do multiplexed measurements work and
when they are advantageous? Here we address these questions with a focus on
applications involving x-rays or electrons. We present a quantitative framework
for analyzing the expected error and radiation dose of different measurement
scheme that enables comparison. We conclude that in very specific situations,
multiplexing can offer improvements in resolution and signal-to-noise. If the
signal has a sparse representation, these advantages become more general and
dramatic, and further less radiation can be used to complete a measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12219</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12219</id><created>2019-07-29</created><authors><author><keyname>Rajesh</keyname><forenames>Bulla</forenames></author><author><keyname>Javed</keyname><forenames>Mohammed</forenames></author><author><keyname>Nagabhushan</keyname><forenames>P</forenames></author></authors><title>Automatic Text Line Segmentation Directly in JPEG Compressed Document
  Images</title><categories>cs.CV eess.IV</categories><comments>Accepted in GCCE2019, Okinawa, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  JPEG is one of the popular image compression algorithms that provide
efficient storage and transmission capabilities in consumer electronics, and
hence it is the most preferred image format over the internet world. In the
present digital and Big-data era, a huge volume of JPEG compressed document
images are being archived and communicated through consumer electronics on
daily basis. Though it is advantageous to have data in the compressed form on
one side, however, on the other side processing with off-the-shelf methods
becomes computationally expensive because it requires decompression and
recompression operations. Therefore, it would be novel and efficient, if the
compressed data are processed directly in their respective compressed domains
of consumer electronics. In the present research paper, we propose to
demonstrate this idea taking the case study of printed text line segmentation.
Since, JPEG achieves compression by dividing the image into non overlapping 8x8
blocks in the pixel domain and using Discrete Cosine Transform (DCT); it is
very likely that the partitioned 8x8 DCT blocks overlap the contents of two
adjacent text-lines without leaving any clue for the line separator, thus
making text-line segmentation a challenging problem. Two approaches of
segmentation have been proposed here using the DC projection profile and AC
coefficients of each 8x8 DCT block. The first approach is based on the strategy
of partial decompression of selected DCT blocks, and the second approach is
with intelligent analysis of F10 and F11 AC coefficients and without using any
type of decompression. The proposed methods have been tested with variable font
sizes, font style and spacing between lines, and a good performance is
reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12234</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12234</id><created>2019-07-29</created><authors><author><keyname>Zhang</keyname><forenames>Haiyang</forenames></author><author><keyname>Duan</keyname><forenames>Lingjie</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Jamming-assisted Proactive Eavesdropping over Two Suspicious
  Communication Links</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a new and challenging wireless surveillance problem where
a legitimate monitor attempts to eavesdrop two suspicious communication links
simultaneously. To facilitate concurrent eavesdropping, our multi-antenna
legitimate monitor employs a proactive eavesdropping via jamming approach, by
selectively jamming suspicious receivers to lower the transmission rates of the
target links. In particular, we are interested in characterizing the achievable
eavesdropping rate region for the minimum-mean-squared-error (MMSE) receiver
case, by optimizing the legitimate monitor's jamming transmit covariance matrix
subject to its power budget. As the monitor cannot hear more than what
suspicious links transmit, the achievable eavesdropping rate region is
essentially the intersection of the achievable rate region for the two
suspicious links and that for the two eavesdropping links. The former region
can be purposely altered by the monitor's jamming transmit covariance matrix,
whereas the latter region is fixed when the MMSE receiver is employed.
Therefore, we first analytically characterize the achievable rate region for
the two suspicious links via optimizing the jamming transmit covariance matrix
and then obtain the achievable eavesdropping rate region for the MMSE receiver
case. Furthermore, we also extend our study to the MMSE with successive
interference cancellation (MMSE-SIC) receiver case and characterize the
corresponding achievable eavesdropping rate region by jointly optimizing the
time-sharing factor between different decoding orders. Finally, numerical
results are provided to corroborate our analysis and examine the eavesdropping
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12246</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12246</id><created>2019-07-29</created><authors><author><keyname>Chen</keyname><forenames>Yo-Chuan</forenames></author><author><keyname>Lin</keyname><forenames>Yi-Chen</forenames></author><author><keyname>Wang</keyname><forenames>Ching-Ping</forenames></author><author><keyname>Lee</keyname><forenames>Chia-Yen</forenames></author><author><keyname>Lee</keyname><forenames>Wen-Jeng</forenames></author><author><keyname>Wang</keyname><forenames>Tzung-Dau</forenames></author><author><keyname>Chen</keyname><forenames>Chung-Ming</forenames></author></authors><title>Coronary Artery Segmentation in Cardiac CT Angiography Using 3D
  Multi-Channel U-net</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/r1g1GbCV54</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Vessel stenosis is a major risk factor in cardiovascular diseases (CVD). To
analyze the degree of vessel stenosis for supporting the treatment management,
extraction of coronary artery area from Computed Tomographic Angiography (CTA)
is regarded as a key procedure. However, manual segmentation by cardiologists
may be a time-consuming task, and present a significant inter-observer
variation. Although various computer-aided approaches have been developed to
support segmentation of coronary arteries in CTA, the results remain unreliable
due to complex attenuation appearance of plaques, which are the cause of the
stenosis. To overcome the difficulties caused by attenuation ambiguity, in this
paper, a 3D multi-channel U-Net architecture is proposed for fully automatic 3D
coronary artery reconstruction from CTA. Other than using the original CTA
image, the main idea of the proposed approach is to incorporate the vesselness
map into the input of the U-Net, which serves as the reinforcing information to
highlight the tubular structure of coronary arteries. The experimental results
show that the proposed approach could achieve a Dice Similarity Coefficient
(DSC) of 0.8 in comparison to around 0.6 attained by previous CNN approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12253</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12253</id><created>2019-07-29</created><authors><author><keyname>Zou</keyname><forenames>Chuhang</forenames></author><author><keyname>Hoiem</keyname><forenames>Derek</forenames></author></authors><title>Silhouette Guided Point Cloud Reconstruction beyond Occlusion</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One major challenge in 3D reconstruction is to infer the complete shape
geometry from partial foreground occlusions. In this paper, we propose a method
to reconstruct the complete 3D shape of an object from a single RGB image, with
robustness to occlusion. Given the image and a silhouette of the visible
region, our approach completes the silhouette of the occluded region and then
generates a point cloud. We show improvements for reconstruction of
non-occluded and partially occluded objects by providing the predicted complete
silhouette as guidance. We also improve state-of-the-art for 3D shape
prediction with a 2D reprojection loss from multiple synthetic views and a
surface-based smoothing and refinement step. Experiments demonstrate the
efficacy of our approach both quantitatively and qualitatively on synthetic and
real scene datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12255</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12255</id><created>2019-07-29</created><authors><author><keyname>Du</keyname><forenames>Jingbo</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Zhao</keyname><forenames>Chunming</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Weighted Spectral Efficiency Optimization for Hybrid Beamforming in
  Multiuser Massive MIMO-OFDM Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>34 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider hybrid beamforming designs for multiuser massive
multiple-input multiple-output (MIMO)-orthogonal frequency division
multiplexing (OFDM) systems. Aiming at maximizing the weighted spectral
efficiency, we propose one alternating maximization framework where the analog
precoding is optimized by Riemannian manifold optimization. If the digital
precoding is optimized by a locally optimal algorithm, we obtain a locally
optimal alternating maximization algorithm. In contrast, if we use a weighted
minimum mean square error (MMSE)-based iterative algorithm for digital
precoding, we obtain a suboptimal alternating maximization algorithm with
reduced complexity in each iteration. By characterizing the upper bound of the
weighted arithmetic and geometric means of mean square errors (MSEs), it is
shown that the two alternating maximization algorithms have similar performance
when the user specific weights do not have big differences. Verified by
numerical results, the performance gap between the two alternating maximization
algorithms becomes large when the ratio of the maximal and minimal weights
among users is very large. Moreover, we also propose a low-complexity
closed-form method without iterations. It employs matrix decomposition for the
analog beamforming and weighted MMSE for the digital beamforming. Although it
is not supposed to maximize the weighted spectral efficiency, it exhibits small
performance deterioration compared to the two iterative alternating
maximization algorithms and it qualifies as a good initialization for iterative
algorithms, saving thereby iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12258</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12258</id><created>2019-07-29</created><updated>2020-01-01</updated><authors><author><keyname>Zimmerer</keyname><forenames>David</forenames></author><author><keyname>Kohl</keyname><forenames>Simon</forenames></author><author><keyname>Petersen</keyname><forenames>Jens</forenames></author><author><keyname>Isensee</keyname><forenames>Fabian</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Klaus</forenames></author></authors><title>Context-encoding Variational Autoencoder for Unsupervised Anomaly
  Detection -- Short Paper</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BylLiVXptV</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised learning can leverage large-scale data sources without the need
for annotations. In this context, deep learning-based autoencoders have shown
great potential in detecting anomalies in medical images. However, especially
Variational Autoencoders (VAEs)often fail to capture the high-level structure
in the data. We address these shortcomings by proposing the context-encoding
Variational Autoencoder (ceVAE), which improves both, the sample, as well as
pixelwise results. In our experiments on the BraTS-2017 and ISLES-2015
segmentation benchmarks the ceVAE achieves unsupervised AUROCs of 0.95 and
0.89, respectively, thus outperforming other reported deep-learning based
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12279</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12279</id><created>2019-07-29</created><updated>2019-08-07</updated><authors><author><keyname>Kaneko</keyname><forenames>Takuhiro</forenames></author><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author><author><keyname>Tanaka</keyname><forenames>Kou</forenames></author><author><keyname>Hojo</keyname><forenames>Nobukatsu</forenames></author></authors><title>StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice
  Conversion</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Accepted to Interspeech 2019. Project page:
  http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-parallel multi-domain voice conversion (VC) is a technique for learning
mappings among multiple domains without relying on parallel data. This is
important but challenging owing to the requirement of learning multiple
mappings and the non-availability of explicit supervision. Recently, StarGAN-VC
has garnered attention owing to its ability to solve this problem only using a
single generator. However, there is still a gap between real and converted
speech. To bridge this gap, we rethink conditional methods of StarGAN-VC, which
are key components for achieving non-parallel multi-domain VC in a single
model, and propose an improved variant called StarGAN-VC2. Particularly, we
rethink conditional methods in two aspects: training objectives and network
architectures. For the former, we propose a source-and-target conditional
adversarial loss that allows all source domain data to be convertible to the
target domain data. For the latter, we introduce a modulation-based conditional
method that can transform the modulation of the acoustic feature in a
domain-specific manner. We evaluated our methods on non-parallel multi-speaker
VC. An objective evaluation demonstrates that our proposed methods improve
speech quality in terms of both global and local structure measures.
Furthermore, a subjective evaluation shows that StarGAN-VC2 outperforms
StarGAN-VC in terms of naturalness and speaker similarity. The converted speech
samples are provided at
http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12296</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12296</id><created>2019-07-29</created><authors><author><keyname>Andreini</keyname><forenames>Paolo</forenames></author><author><keyname>Bonechi</keyname><forenames>Simone</forenames></author><author><keyname>Bianchini</keyname><forenames>Monica</forenames></author><author><keyname>Mecocci</keyname><forenames>Alessandro</forenames></author><author><keyname>Scarselli</keyname><forenames>Franco</forenames></author><author><keyname>Sodi</keyname><forenames>Andrea</forenames></author></authors><title>A Two Stage GAN for High Resolution Retinal Image Generation and
  Segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the use of deep learning is becoming increasingly popular in
computer vision. However, the effective training of deep architectures usually
relies on huge sets of annotated data. This is critical in the medical field
where it is difficult and expensive to obtain annotated images. In this paper,
we use Generative Adversarial Networks (GANs) for synthesizing high quality
retinal images, along with the corresponding semantic label-maps, to be used
instead of real images during the training process. Differently from other
previous proposals, we suggest a two step approach: first, a progressively
growing GAN is trained to generate the semantic label-maps, which describe the
blood vessel structure (i.e. vasculature); second, an image-to-image
translation approach is used to obtain realistic retinal images from the
generated vasculature. By using only a handful of training samples, our
approach generates realistic high resolution images, that can be effectively
used to enlarge small available datasets. Comparable results have been obtained
employing the generated images in place of real data during training. The
practical viability of the proposed approach has been demonstrated by applying
it on two well established benchmark sets for retinal vessel segmentation, both
containing a very small number of training samples. Our method obtained better
performances with respect to state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12300</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12300</id><created>2019-07-29</created><authors><author><keyname>Mastrangelo</keyname><forenames>Jos&#xe9; Mario</forenames></author><author><keyname>Baumann</keyname><forenames>Dominik</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Predictive Triggering for Distributed Control of Resource Constrained
  Multi-agent Systems</title><categories>eess.SY cs.SY</categories><comments>6 pages, 3 figures, to appear in Proc. of the 8th IFAC Workshop on
  Distributed Estimation and Control in Networked Systems, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A predictive triggering (PT) framework for the distributed control of
resource constrained multi-agent systems is proposed. By predicting future
communication demands and deriving a probabilistic priority measure, the PT
framework is able to allocate limited communication resources in advance. The
framework is evaluated through simulations of a cooperative adaptive cruise
control system and experiments on multi-agent cart-pole systems. The results of
these studies show its effectiveness over other event-triggered designs at
reducing network utilization, while also improving the control error of the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12314</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12314</id><created>2019-07-29</created><authors><author><keyname>Heuvel</keyname><forenames>Thomas L. A. van den</forenames></author><author><keyname>de Korte</keyname><forenames>Chris L.</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author></authors><title>Automated interpretation of prenatal ultrasound using a predefined
  acquisition protocol in resource-limited countries</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/H1eUCb6at4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In this study, we combine a standardized acquisition protocol with image
analysis algorithms to investigate if it is possible to automatically detect
maternal risk factors without a trained sonographer. The standardized
acquisition protocol can be taught to any health care worker within two hours.
This protocol was acquired from 280 pregnant women at St.\ Luke's Catholic
Hospital, Wolisso, Ethiopia. A VGG-like network was used to perform a frame
classification for each frame within the acquired ultrasound data. This frame
classification was used to automatically determine the number of fetuses and
the fetal presentation. A U-net was trained to measure the fetal head
circumference in all frames in which the VGG-like network detected a fetal
head. This head circumference was used to estimate the gestational age. The
results show that it possible automatically determine gestational age and
determine fetal presentation and the potential to detect twin pregnancies using
the standardized acquisition protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12330</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12330</id><created>2019-07-29</created><authors><author><keyname>Jacenk&#xf3;w</keyname><forenames>Grzegorz</forenames></author><author><keyname>Chartsias</keyname><forenames>Agisilaos</forenames></author><author><keyname>Mohr</keyname><forenames>Brian</forenames></author><author><keyname>Tsaftaris</keyname><forenames>Sotirios A.</forenames></author></authors><title>Conditioning Convolutional Segmentation Architectures with Non-Imaging
  Data</title><categories>eess.IV</categories><comments>Accepted as an extended abstract at MIDL 2019 conference. MIDL 2019
  [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BklGUoAEcE</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We compare two conditioning mechanisms based on concatenation and
feature-wise modulation to integrate non-imaging information into convolutional
neural networks for segmentation of anatomical structures. As a
proof-of-concept we provide the distribution of class labels obtained from
ground truth masks to ensure strong correlation between the conditioning data
and the segmentation maps. We evaluate the methods on the ACDC dataset, and
show that conditioning with non-imaging data improves performance of the
segmentation networks. We observed conditioning the U-Net architectures was
challenging, where no method gave significant improvement. However, the same
architecture without skip connections outperforms the baseline with
feature-wise modulation, and the relative performance increases as the training
size decreases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12331</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12331</id><created>2019-07-29</created><authors><author><keyname>Gordaliza</keyname><forenames>Pedro M.</forenames></author><author><keyname>Vaquero</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>Sharpe</keyname><forenames>Sally</forenames></author><author><keyname>Gleeson</keyname><forenames>Fergus</forenames></author><author><keyname>Mu&#xf1;oz-Barrutia</keyname><forenames>Arrate</forenames></author></authors><title>A Multi-Task Self-Normalizing 3D-CNN to Infer Tuberculosis Radiological
  Manifestations</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/Hyxndu1pKE</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We propose a learning method well-suited to infer the presence of
Tuberculosis (TB) manifestations on Computer Tomography (CT) scans mimicking
the radiologist reports. Latent features are extracted from the CT volumes
employing the V-Net encoder and those are the input to a Feed-Forward Neural
Network (FNN) for multi-class classification. To overtake the issues (e.g.,
exploding/vanishing gradients, lack of sensibility) that normally appear when
training deep 3D models with datasets of limited size and composed of large
volumes, our proposal employs: 1) At the network architecture level, the scaled
exponential linear unit (SELU) activation which allows the network
self-normalization, and 2) at the learning phase, multi-task learning with a
loss function weighted by the task homoscedastic uncertainty. The results
achieve F1-scores close to or above 0.9 for the detection of TB lesions and a
Root Mean Square Error of 1.16 for the number of nodules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12354</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12354</id><created>2019-07-29</created><authors><author><keyname>Kobler</keyname><forenames>Reinmar J.</forenames></author><author><keyname>Sburlea</keyname><forenames>Andreea I.</forenames></author><author><keyname>Mondini</keyname><forenames>Valeria</forenames></author><author><keyname>M&#xfc;ller-Putz</keyname><forenames>Gernot R.</forenames></author></authors><title>HEAR to remove pops and drifts: the high-variance electrode artifact
  removal (HEAR) algorithm</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A high fraction of artifact-free signals is highly desirable in functional
neuroimaging and brain-computer interfacing (BCI). We present the high-variance
electrode artifact removal (HEAR) algorithm to remove transient electrode pop
and drift (PD) artifacts from electroencephalographic (EEG) signals. Transient
PD artifacts reflect impedance variations at the electrode scalp interface that
are caused by ion concentration changes. HEAR and its online version (oHEAR)
are open-source and publicly available. Both outperformed state of the art
offline and online transient, high-variance artifact correction algorithms for
simulated EEG signals. (o)HEAR attenuated PD artifacts by approx. 25 dB, and at
the same time maintained a high SNR during PD artifact-free periods. For
real-world EEG data, (o)HEAR reduced the fraction of outlier trials by half and
maintained the waveform of a movement related cortical potential during a
center-out reaching task. In the case of BCI training, using oHEAR can improve
the reliability of the feedback a user receives through reducing a potential
negative impact of PD artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12370</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12370</id><created>2019-07-20</created><authors><author><keyname>Saxena</keyname><forenames>Shivam</forenames></author><author><keyname>Farag</keyname><forenames>Hany</forenames></author><author><keyname>Brookson</keyname><forenames>Aidan</forenames></author><author><keyname>Turesson</keyname><forenames>Hjalmar</forenames></author><author><keyname>Kim</keyname><forenames>Henry M.</forenames></author></authors><title>Design and Field Implementation of Blockchain Based Renewable Energy
  Trading in Residential Communities</title><categories>eess.SY cs.CY cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a peer to peer (P2P), blockchain based energy trading
market platform for residential communities with the objective of reducing
overall community peak demand and household electricity bills. Smart homes
within the community place energy bids for its available distributed energy
resources (DERs) for each discrete trading period during a day, and a double
auction mechanism is used to clear the market and compute the market clearing
price (MCP). The marketplace is implemented on a permissioned blockchain
infrastructure, where bids are stored to the immutable ledger and smart
contracts are used to implement the MCP calculation and award service contracts
to all winning bids. Utilizing the blockchain obviates the need for a trusted,
centralized auctioneer, and eliminates vulnerability to a single point of
failure. Simulation results show that the platform enables a community peak
demand reduction of 46%, as well as a weekly savings of 6%. The platform is
also tested at a real-world Canadian microgrid using the Hyperledger Fabric
blockchain framework, to show the end to end connectivity of smart home DERs to
the platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12371</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12371</id><created>2019-07-19</created><updated>2019-10-30</updated><authors><author><keyname>Shen</keyname><forenames>Zhihao</forenames></author><author><keyname>Du</keyname><forenames>Wan</forenames></author><author><keyname>Zhao</keyname><forenames>Xi</forenames></author><author><keyname>Zou</keyname><forenames>Jianhua</forenames></author></authors><title>Retrieving Similar Trajectories from Cellular Data at City Scale</title><categories>eess.SP cs.IR</categories><comments>This paper has been submitted to IEEE Transactions on Mobile
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retrieving similar trajectories from a large trajectory dataset is important
for a variety of applications, like transportation planning and mobility
analysis. Unlike previous works based on fine-grained GPS trajectories, this
paper investigates the feasibility of identifying similar trajectories from
cellular data observed by mobile infrastructure, which provide more
comprehensive coverage. To handle the large localization errors and low sample
rates of cellular data, we develop a holistic system, cellSim, which seamlessly
integrates map matching and similar trajectory search. A set of map matching
techniques are proposed to transform cell tower sequences into moving
trajectories on a road map by considering the unique features of cellular data,
like the dynamic density of cell towers and bidirectional roads. To further
improve the accuracy of similarity search, map matching outputs M trajectory
candidates of different confidence, and a new similarity measure scheme is
developed to process the map matching results. Meanwhile, M is dynamically
adapted to maintain a low false positive rate of the similarity search, and two
pruning schemes are proposed to minimize the computation overhead. Extensive
experiments on a large-scale dataset and real-world trajectories of 1701 km
reveal that cellSim provides high accuracy (precision 62.4% and recall of
89.8%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12382</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12382</id><created>2019-07-29</created><authors><author><keyname>Hosseinzadeh</keyname><forenames>Matin</forenames></author><author><keyname>Brand</keyname><forenames>Patrick</forenames></author><author><keyname>Huisman</keyname><forenames>Henkjan</forenames></author></authors><title>Effect of Adding Probabilistic Zonal Prior in Deep Learning-based
  Prostate Cancer Detection</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SkxAwFtEqV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We propose and evaluate a novel method for automatically detecting clinically
significant prostate cancer (csPCa) in bi-parametric magnetic resonance imaging
(bpMRI). Prostate zones play an important role in the assessment of prostate
cancer on MRI. We hypothesize that the inclusion of zonal information can
improve the performance of a deep learning based csPCa lesion detection model.
However, segmentation of prostate zones is challenging and therefore
deterministic models are inaccurate. Hence, we investigated probabilistic zonal
segmentation. Our baseline detection model is a 2DUNet trained to produce a
csPCa heatmap followed by a 3D detector. We experimented with the integration
of zonal prior information by fusing the output of an anisotropic 3DUNet
trained to produce either a deterministic or probabilistic map for each
prostate zone. We also investigate the effect of early or late fusion on csPCa
detection. All methods were trained and tested on 848 bpMRI. The results show
that fusing zonal prior knowledge improves the baseline detection model with a
preference for probabilistic over deterministic zonal segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12403</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12403</id><created>2019-07-29</created><updated>2019-09-04</updated><authors><author><keyname>Lun</keyname><forenames>Yuriy Zacchia</forenames></author><author><keyname>D'Innocenzo</keyname><forenames>Alessandro</forenames></author></authors><title>Stabilizability of Markov jump linear systems modeling wireless
  networked control scenarios (extended version)</title><categories>eess.SY cs.SY</categories><comments>Extended version of the paper accepted for the presentation at the
  58th IEEE Conference on Decision and Control (CDC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communication channels used to convey information between the components
of wireless networked control systems (WNCSs) are subject to packet losses due
to time-varying fading and interference. The WNCSs with missing packets can be
modeled as Markov jump linear systems with one time-step delayed mode
observations. While the problem of the optimal linear quadratic regulation for
such systems has been already solved, we derive the necessary and sufficient
conditions for stabilizability. We also show, with an example considering a
communication channel model based on WirelessHART (a on-the-market wireless
communication standard specifically designed for process automation), that such
conditions are essential to the analysis of WNCSs where packet losses are
modeled with Bernoulli random variables representing the expected value of the
real random process governing the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12407</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12407</id><created>2019-07-01</created><authors><author><keyname>Mohamad</keyname><forenames>Yazan</forenames><affiliation>American University of Kuwait</affiliation></author><author><keyname>Makdessi</keyname><forenames>Majd</forenames><affiliation>American University of Kuwait</affiliation></author><author><keyname>Raad</keyname><forenames>Omar</forenames><affiliation>American University of Kuwait</affiliation></author><author><keyname>Damaj</keyname><forenames>Issam</forenames><affiliation>American University of Kuwait</affiliation></author></authors><title>SysMART Outdoor Services: A System of Connected and Smart Supermarkets</title><categories>cs.OH eess.SP</categories><comments>5 pages, 6 figures, 3 tables</comments><acm-class>B.4.1; H.4.3; K.8.1</acm-class><journal-ref>The 9th IEEE-GCC Conference and Exhibition, Manama, Bahrain, May
  8-11, (2017) 98-102</journal-ref><doi>10.1109/IEEEGCC.2017.8448000</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart cities are today's modern trend. Many high-tech industrial firms are
exploring different approaches to implement smart cities. Various projects aim
at internet-of-things and smart solutions. Current implementations are mostly
localized to a specific building or area; however, the growth is crossing space
and geographic location limits. Shopping is a central activity that is frequent
and typically a time-consuming task. SysMART is system of connected and smart
supermarkets. SysMART enables a plausible shopping experience for customers.
The aim of SysMART is to provide an advanced lifestyle with its ease of use
functionality. SysMART outdoor services support distant parking availability,
traffic status, and remote inventory checks for supermarkets in a chain.
SysMART implementation relies on cutting edge technologies that support rapid
prototyping and precision data acquisition, such as, National Instrument
devices. The selected development environment is LabView with its world-class
interfacing libraries. The paper comprises a detailed system description,
development strategy, interface design, software engineering, and a thorough
analysis and evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12421</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12421</id><created>2019-07-29</created><authors><author><keyname>&#x10c;mejla</keyname><forenames>Jaroslav</forenames></author><author><keyname>Kounovsk&#xfd;</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author><author><keyname>Koldovsk&#xfd;</keyname><forenames>Zbyn&#x11b;k</forenames></author><author><keyname>Tandeitnik</keyname><forenames>Pinchas</forenames></author></authors><title>MIRaGe: Multichannel Database Of Room Impulse Responses Measured On
  High-Resolution Cube-Shaped Grid In Multiple Acoustic Conditions</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a database of multi-channel recordings performed in an acoustic
lab with adjustable reverberation time. The recordings provide information
about room impulse responses (RIR) for various positions of a loudspeaker. In
particular, the main positions correspond to 4104 vertices of a cube-shaped
dense grid within a 46x36x32 cm volume. The database thus provides a tool for
detailed analyses of beampatterns of spatial processing methods as well as for
training and testing of mathematical models of the acoustic field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12436</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12436</id><created>2019-07-29</created><updated>2019-12-28</updated><authors><author><keyname>Frank</keyname><forenames>Steven J.</forenames></author><author><keyname>Frank</keyname><forenames>Andrea M.</forenames></author></authors><title>Salient Slices: Improved Neural Network Training and Performance with
  Image Entropy</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a training and analysis strategy for convolutional neural networks (CNNs),
we slice images into tiled segments and use, for training and prediction,
segments that both satisfy a criterion of information diversity and contain
sufficient content to support classification. In particular, we utilize image
entropy as the diversity criterion. This ensures that each tile carries as much
information diversity as the original image, and for many applications serves
as an indicator of usefulness in classification. To make predictions, a
probability aggregation framework is applied to probabilities assigned by the
CNN to the input image tiles. This technique facilitates the use of large,
high-resolution images that would be impractical to analyze unmodified;
provides data augmentation for training, which is particularly valuable when
image availability is limited; and the ensemble nature of the input for
prediction enhances its accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12452</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12452</id><created>2019-07-29</created><authors><author><keyname>van Wijnen</keyname><forenames>Kimberlin M. H.</forenames></author><author><keyname>Dubost</keyname><forenames>Florian</forenames></author><author><keyname>Yilmaz</keyname><forenames>Pinar</forenames></author><author><keyname>Ikram</keyname><forenames>M. Arfan</forenames></author><author><keyname>Niessen</keyname><forenames>Wiro J.</forenames></author><author><keyname>Adams</keyname><forenames>Hieab</forenames></author><author><keyname>Vernooij</keyname><forenames>Meike W.</forenames></author><author><keyname>de Bruijne</keyname><forenames>Marleen</forenames></author></authors><title>Automated Lesion Detection by Regressing Intensity-Based Distance with a
  Neural Network</title><categories>eess.IV cs.CV cs.LG</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization of focal vascular lesions on brain MRI is an important component
of research on the etiology of neurological disorders. However, manual
annotation of lesions can be challenging, time-consuming and subject to
observer bias. Automated detection methods often need voxel-wise annotations
for training. We propose a novel approach for automated lesion detection that
can be trained on scans only annotated with a dot per lesion instead of a full
segmentation. From the dot annotations and their corresponding intensity images
we compute various distance maps (DMs), indicating the distance to a lesion
based on spatial distance, intensity distance, or both. We train a fully
convolutional neural network (FCN) to predict these DMs for unseen intensity
images. The local optima in the predicted DMs are expected to correspond to
lesion locations. We show the potential of this approach to detect enlarged
perivascular spaces in white matter on a large brain MRI dataset with an
independent test set of 1000 scans. Our method matches the intra-rater
performance of the expert rater that was computed on an independent set. We
compare the different types of distance maps, showing that incorporating
intensity information in the distance maps used to train an FCN greatly
improves performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12454</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12454</id><created>2019-07-29</created><authors><author><keyname>Martini</keyname><forenames>Nicola</forenames></author><author><keyname>Vatti</keyname><forenames>Alessio</forenames></author><author><keyname>Ripoli</keyname><forenames>Andrea</forenames></author><author><keyname>Salaris</keyname><forenames>Sara</forenames></author><author><keyname>Santini</keyname><forenames>Gianmarco</forenames></author><author><keyname>Santarelli</keyname><forenames>Maria Filomena</forenames></author><author><keyname>Chiappino</keyname><forenames>Dante</forenames></author><author><keyname>Della Latta</keyname><forenames>Daniele</forenames></author></authors><title>Robust reconstruction of cardiac T1 maps using RNNs</title><categories>eess.IV</categories><comments>4 pages, 1 figure, Medical Imaging with Deep Learning: MIDL 2019 -
  Extended Abstract Track [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BJlMeAnEqN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Cardiac magnetic resonance parametric T1 maps are typically reconstructed
using non-linear fitting. However this method has limitations due to the high
computational cost and robustness. In this study, a recurrent neural network
(RNN) is proposed for the robust and fast reconstruction of cardiac T1 maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12475</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12475</id><created>2019-07-29</created><authors><author><keyname>Yang</keyname><forenames>Kai</forenames></author><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author></authors><title>Energy-Efficient Processing and Robust Wireless Cooperative Transmission
  for Edge Inference</title><categories>cs.IT cs.LG eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edge machine learning can deliver low-latency and private artificial
intelligent (AI) services for mobile devices by leveraging computation and
storage resources at the network edge. This paper presents an energy-efficient
edge processing framework to execute deep learning inference tasks at the edge
computing nodes whose wireless connections to mobile devices are prone to
channel uncertainties. Aimed at minimizing the sum of computation and
transmission power consumption with probabilistic quality-of-service (QoS)
constraints, we formulate a joint inference tasking and downlink beamforming
problem that is characterized by a group sparse objective function. We provide
a statistical learning based robust optimization approach to approximate the
highly intractable probabilistic-QoS constraints by nonconvex quadratic
constraints, which are further reformulated as matrix inequalities with a
rank-one constraint via matrix lifting. We design a reweighted power
minimization approach by iteratively reweighted $\ell_1$ minimization with
difference-of-convex-functions (DC) regularization and updating weights, where
the reweighted approach is adopted for enhancing group sparsity whereas the DC
regularization is designed for inducing rank-one solutions. Numerical results
demonstrate that the proposed approach outperforms other state-of-the-art
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12499</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12499</id><created>2019-07-29</created><authors><author><keyname>Palmer</keyname><forenames>David M.</forenames></author><author><keyname>Holmes</keyname><forenames>Rebecca M.</forenames></author><author><keyname>Weaver</keyname><forenames>Charles T.</forenames></author></authors><title>The First Orbital Flight of the ELROI Optical Satellite License Plate</title><categories>astro-ph.IM eess.SP</categories><comments>SmallSat 2019 (The 33rd Annual AIAA/USU Conference on Small
  Satellites)</comments><report-no>LA-UR-19-25352</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space Object Identification is one of the cornerstones of Space Traffic
Control and a requirement for successful operation of a spacecraft.
  ELROI, the Extremely Low Resource Optical Identifier, is a new concept that
can provide a self-powered satellite identification beacon in a package the
size of a thick postage stamp. Its small size, low cost, and fully autonomous
operation make it usable by all space objects, including CubeSats and inert
debris objects.
  The beacon's signal is received on the ground using a small telescope
equipped with a photon-counting detector which can unambiguously determine the
satellite identification number during a single pass overhead. Additional
information can be included in the signal to aid in anomaly diagnosis and
resolution, further improving spaceflight reliability and safety.
  The first ELROI unit in orbit was launched December, 2018 as a payload on the
student CubeSat NMTSat. We are now searching for the identification signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12610</identifier>
 <datestamp>2019-11-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12610</id><created>2019-07-29</created><updated>2019-10-12</updated><authors><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Yang</keyname><forenames>Yansong</forenames></author><author><keyname>Li</keyname><forenames>Ming-Huang</forenames></author><author><keyname>Breen</keyname><forenames>Michael</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>5-GHz Antisymmetric Mode Acoustic Delay Lines in Lithium Niobate Thin
  Film</title><categories>eess.SP physics.app-ph</categories><comments>16 pages, 27 figures</comments><doi>10.1109/TMTT.2019.2949808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first group of acoustic delay lines (ADLs) at 5 GHz, using the
first-order antisymmetric (A1) mode in Z-cut lithium niobate thin films. The
demonstrated ADLs significantly surpass the operation frequency of the previous
works with similar feature sizes, because of its simultaneously fast phase
velocity, large coupling coefficient, and low-loss. In this work, the
propagation characteristics of the A1 mode in lithium niobate is analytically
modeled and validated with finite element analysis. The design space of A1 ADLs
is then investigated, including both the fundamental design parameters and
those introduced from the practical implementation. The implemented ADLs at 5
GHz show a minimum insertion loss of 7.94 dB, an average IL of 9.1 dB, and a
fractional bandwidth around 4%, with delays ranging between 15 ns to 109 ns and
the center frequencies between 4.5 GHz and 5.25 GHz. The propagation
characteristics of A1 mode acoustic waves have also been extracted for the
first time. The A1 ADL platform can potentially enable wide-band high-frequency
passive signal processing functions for future 5G applications in the sub-6 GHz
spectrum bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12613</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12613</id><created>2019-07-29</created><updated>2019-09-18</updated><authors><author><keyname>Ouameur</keyname><forenames>Messaoud Ahmed</forenames></author><author><keyname>Massicotte</keyname><forenames>Daniel</forenames></author></authors><title>Autoencoder for Interconnect's Bandwidth Relaxation in Large Scale
  MIMO-OFDM Processing</title><categories>eess.SP</categories><comments>4 pages, 5 figures, extended version to be sumbitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is playing an instrumental role in the design of the next
generation of communication systems. In this letter, we address the massive
MIMO interconnect's bandwidth constraint relaxation using autoencoders. The
autoencoder is trained to learn the received signal structure so that a low
dimension latent variable is transferred as opposed to the original high
dimension signal. For an efficient implementation, the approach suggests to
separately deploy the autoencoder components, namely the encoder and the
decoder, in massive MIMO radio head and central processing units respectively.
The simulation results show that one can relax the interconnect's bandwidth by
a factor of up to 16 with non-substantial performance degradation of the
centralized and the decentralized processing. Fortunately, such a loss can be
compensated by running few extra iterations in the detection process which
renders the autoencoder-iterative detection an interconnect's bandwidth and
computational complexity design trade-off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12616</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12616</id><created>2019-07-29</created><authors><author><keyname>Dimas</keyname><forenames>Anastasios</forenames></author><author><keyname>Kalogerias</keyname><forenames>Dionysios S.</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author></authors><title>Cooperative Beamforming with Predictive Relay Selection for Urban mmWave
  Communications</title><categories>eess.SP cs.IT cs.LG cs.NI math.IT</categories><journal-ref>10.1109/ACCESS.2019.2950274</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While millimeter wave (mmWave) communications promise high data rates, their
sensitivity to blockage and severe signal attenuation presents challenges in
their deployment in urban settings. To overcome these effects, we consider a
distributed cooperative beamforming system, which relies on static relays
deployed in clusters with similar channel characteristics, and where, at every
time instance, only one relay from each cluster is selected to participate in
beamforming to the destination. To meet the quality-of-service guarantees of
the network, a key prerequisite for beamforming is relay selection. However, as
the channels change with time, relay selection becomes a resource demanding
task. Indeed, estimation of channel state information for all candidate relays,
essential for relay selection, is a process that takes up bandwidth, wastes
power and introduces latency and interference in the network. We instead
propose a unique, predictive scheme for resource efficient relay selection,
which exploits the special propagation patterns of the mmWave medium, and can
be executed distributively across clusters, and in parallel to optimal
beamforming-based communication. The proposed predictive scheme efficiently
exploits spatiotemporal channel correlations with current and past networkwide
Received Signal Strength (RSS), the latter being invariant to relay cluster
size, measured sequentially during the operation of the system. Our numerical
results confirm that our proposed relay selection strategy outperforms any
randomized selection policy that does not exploit channel correlations,
whereas, at the same time, it performs very close to an ideal scheme that uses
complete, cluster size dependent RSS, and offers significant savings in terms
of channel estimation overhead, providing substantially better network
utilization, especially in dense topologies, typical in mmWave networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12621</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12621</id><created>2019-07-29</created><authors><author><keyname>Grondin</keyname><forenames>Francois</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Fast and Robust 3-D Sound Source Localization with DSVD-PHAT</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a variant of the Singular Value Decomposition with
Phase Transform (SVD-PHAT), named Difference SVD-PHAT (DSVD-PHAT), to achieve
robust Sound Source Localization (SSL) in noisy conditions. Experiments are
performed on a Baxter robot with a four-microphone planar array mounted on its
head. Results show that this method offers similar robustness to noise as the
state-of-the-art Multiple Signal Classification based on Generalized Singular
Value Decomposition (GSVD-MUSIC) method, and considerably reduces the
computational load by a factor of 250. This performance gain thus makes
DSVD-PHAT appealing for real-time application on robots with limited on-board
computing power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12640</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12640</id><created>2019-07-29</created><authors><author><keyname>Sivaranjani</keyname><forenames>S.</forenames></author><author><keyname>Agarwal</keyname><forenames>Etika</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author></authors><title>Data-driven identification of dissipative linear models for nonlinear
  systems</title><categories>eess.SY cs.SY math.OC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of identifying a dissipative linear model of an
unknown nonlinear system that is known to be dissipative, from time domain
input-output data. We first learn an approximate linear model of the nonlinear
system using standard system identification techniques and then perturb the
system matrices of the linear model to enforce dissipativity, while closely
approximating the dynamical behavior of the nonlinear system. Further, we
provide an analytical relationship between the size of the perturbation and the
radius in which the dissipativity of the linear model guarantees local
dissipativity of the unknown nonlinear system. We demonstrate the application
of this identification technique to the problem of learning a dissipative model
of a microgrid with high penetration of variable renewable energy sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12672</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12672</id><created>2019-07-29</created><authors><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Correction of Channel Sounding Clock Drift and Antenna Rotation Effects
  for mmWave Angular Profile Measurements</title><categories>eess.SP cs.SY eess.SY</categories><comments>15 pages. Submitted to IEEE Transactions on Antennas and Propagation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) bands will be used for the fifth generation
communication systems to support high data rates. For the proper
characterization of the mmWave propagation channel, it is essential to measure
the power angular-delay profile (PADP) of the channel which includes
angle-of-departure (AoD) and angle-of-arrival (AoA) of the multipath components
(MPCs). In this paper, we first describe in detail our 28 GHz channel sounder
where directional horn antennas are placed on rotating gimbals. Then, for this
specific sounder class, we describe and address the following two problems in
extracting the MPCs from the measurements: 1) For the channel measurements at
large distances between the transmitter (TX) and the receiver (RX), it is not
possible to generate the triggering signal for the TX and the RX using a single
clock (SICL). This necessitates the use of separate clocks (SECLs) which
introduces a random timing drift between the clocks. 2) As the positions of the
antennas change during the scanning process, total distance traveled by the
same MPC differs at each measurement. These two errors together cause missing
some of the MPCs and detecting MPCs that do not exist in reality. We propose an
algorithm to correct the clock drift and the errors in the MPC delays due to
the rotation of the antennas. We compare the MPCs from the SICL measurement and
the corrected SECL measurements using a Hungarian algorithm based MPC matching
method. We show that the percentage of the matched MPCs increases from 28.36%
to 74.13% after the correction process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12681</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12681</id><created>2019-07-29</created><authors><author><keyname>Jia</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Li</forenames></author><author><keyname>Li</keyname><forenames>Zhu</forenames></author><author><keyname>Liu</keyname><forenames>Shan</forenames></author></authors><title>Residue guided loop filter for HEVC post processing</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The block-based coding structure in the hybrid coding framework gives rise to
the obvious artifacts such as blocking, ringing .etc. Recently, some
Convolutional Neural Network (CNN) based works apply reconstruction as the only
input to reduce the artifacts. Though the performance of these works relying on
powerful learning ability surpasses traditional loop-filter based methods in
the High Efficiency Video Coding (HEVC) standard, how to enhance the high
frequency signal is still not addressed. In addition to reconstruction, we
first propose using the residue as the other input of our CNN-based loop
filter. In essence, the residual signal as a high frequency indicator guides
the CNN to augment the high frequency signal such as sharp shape and edge
information. Second, we find out that the reconstruction and residue signals
have different characteristics and should be handled with different network
structures. For the reconstruction, we develop an All Frequency
(reconstruction) CNN (AF-CNN) adopting the down sampling and up sampling pairs
to learn all frequency signal with the global information. For the residue, we
devise a High Frequency (residual) CNN (HF-CNN) customizing the Residual Blocks
to adapt to the high frequency signal information. To the best of our
knowledge, this is the first work that employs residual signal as a vital
independent high frequency input to direct the learning of CNN- based loop
filtering. We implement the proposed algorithms in the HEVC reference software.
The experimental results show that our proposed approach of dual inputs of
Residual and Reconstruction with HF-CNN and AF-CNN respectively (RRHA) presents
significant BD-rate savings compared with the current CNN-based scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12690</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12690</id><created>2019-07-29</created><authors><author><keyname>Ban</keyname><forenames>Byunghyun</forenames></author><author><keyname>Kim</keyname><forenames>Soobin</forenames></author></authors><title>Control of nonlinear, complex and black-boxed greenhouse system with
  reinforcement learning</title><categories>cs.LG cs.AI cs.SY eess.SY stat.ML</categories><comments>4 pages, 2 figures, 1 table. 2 pages of supplementary information.
  Published on ICTC 2017</comments><journal-ref>2017 International Conference on Information and Communication
  Technology Convergence (ICTC)</journal-ref><doi>10.1109/ICTC.2017.8190813</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern control theories such as systems engineering approaches try to solve
nonlinear system problems by revelation of causal relationship or
co-relationship among the components; most of those approaches focus on control
of sophisticatedly modeled white-boxed systems. We suggest an application of
actor-critic reinforcement learning approach to control a nonlinear, complex
and black-boxed system. We demonstrated this approach on artificial green-house
environment simulator all of whose control inputs have several side effects so
human cannot figure out how to control this system easily. Our approach
succeeded to maintain the circumstance at least 20 times longer than PID and
Deep Q Learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12706</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12706</id><created>2019-07-29</created><authors><author><keyname>Sun</keyname><forenames>Chengjian</forenames></author><author><keyname>Liu</keyname><forenames>Dong</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author></authors><title>Model-Free Unsupervised Learning for Optimization Problems with
  Constraints</title><categories>cs.LG eess.SP stat.ML</categories><comments>Submitted to Asia-Pacific Conference on Communications (APCC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many optimization problems in wireless communications, the expressions of
objective function or constraints are hard or even impossible to derive, which
makes the solutions difficult to find. In this paper, we propose a model-free
learning framework to solve constrained optimization problems without the
supervision of the optimal solution. Neural networks are used respectively for
parameterizing the function to be optimized, parameterizing the Lagrange
multiplier associated with instantaneous constraints, and approximating the
unknown objective function or constraints. We provide learning algorithms to
train all the neural networks simultaneously, and reveal the connections of the
proposed framework with reinforcement learning. Numerical and simulation
results validate the proposed framework and demonstrate the efficiency of
model-free learning by taking power control problem as an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12707</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12707</id><created>2019-07-29</created><updated>2019-12-22</updated><authors><author><keyname>Niu</keyname><forenames>Zhiang</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author></authors><title>Spatial Modulation for Ambient Backscatter Communications: Modeling and
  Analysis</title><categories>eess.SP cs.IT math.IT</categories><comments>The system model and some simulation parameters of this article need
  to be reconsidered and improved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-antenna backscatter is emerging as a promising approach to offer
high communication performance for the data-intensive applications of ambient
backscatter communications (AmBC). Although much has been understood about
multiple-antenna backscatter in conventional backscatter communications (CoBC),
existing analytical models cannot be directly applied to AmBC due to the
structural differences in RF source and tag circuit designs. This paper takes
the first step to fill the gap, by exploring the use of spatial modulation (SM)
in AmBC whenever tags are equipped with multiple antennas. Specifically, we
present a practical multiple-antenna backscatter design for AmBC that exempts
tags from the inter-antenna synchronization and mutual coupling problems while
ensuring high spectral efficiency and ultra-low power consumption. We obtain an
optimal detector for the joint detection of both backscatter signal and source
signal based on the maximum likelihood principle. We also design a two-step
algorithm to derive bounds on the bit error rate (BER) of both signals.
Simulation results validate the analysis and show that the proposed scheme can
significantly improve the throughput compared with traditional systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12708</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12708</id><created>2019-07-29</created><authors><author><keyname>Zhu</keyname><forenames>Lipeng</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Xiao</keyname><forenames>Zhenyu</forenames></author><author><keyname>Cao</keyname><forenames>Xianbin</forenames></author><author><keyname>Wu</keyname><forenames>Dapeng Oliver</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>Millimeter-Wave NOMA with User Grouping, Power Allocation and Hybrid
  Beamforming</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Trans. Wireless Comm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the application of non-orthogonal multiple access in
millimeter-Wave communications (mmWave-NOMA). Particularly, we consider
downlink transmission with a hybrid beamforming structure. A user grouping
algorithm is first proposed according to the channel correlations of the users.
Whereafter, a joint hybrid beamforming and power allocation problem is
formulated to maximize the achievable sum rate, subject to a minimum rate
constraint for each user. To solve this non-convex problem with
high-dimensional variables, we first obtain the solution of power allocation
under arbitrary fixed hybrid beamforming, which is divided into intra-group
power allocation and inter-group power allocation. Then, given arbitrary fixed
analog beamforming, we utilize the approximate zero-forcing method to design
the digital beamforming to minimize the inter-group interference. Finally, the
analog beamforming problem with the constant-modulus constraint is solved with
a proposed boundary-compressed particle swarm optimization algorithm.
Simulation results show that the proposed joint approach, including user
grouping, hybrid beamforming and power allocation, outperforms the
state-of-the-art schemes and the conventional mmWave orthogonal multiple access
system in terms of achievable sum rate and energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12717</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12717</id><created>2019-07-29</created><authors><author><keyname>Wang</keyname><forenames>Yu</forenames></author><author><keyname>Sheng</keyname><forenames>Min</forenames></author><author><keyname>Ye</keyname><forenames>Qiang</forenames></author><author><keyname>Zhang</keyname><forenames>Shan</forenames></author><author><keyname>Zhuang</keyname><forenames>Weihua</forenames></author><author><keyname>Li</keyname><forenames>Jiandong</forenames></author></authors><title>Optimal Dynamic Multi-Resource Management in Earth Observation Oriented
  Space Information Networks</title><categories>eess.SY cs.NI cs.SY</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space information network (SIN) is an innovative networking architecture to
achieve near-real-time mass data observation, processing and transmission over
the globe. In the SIN environment, it is essential to coordinate
multi-dimensional heterogeneous resources (i.e., observation resource,
computation resource and transmission resource) to improve network performance.
However, the time varying property of both the observation resource and
transmission resource is not fully exploited in existing studies. Dynamic
resource management according to instantaneous channel conditions has a
potential to enhance network performance. To this end, in this paper, we study
the multi-resource dynamic management problem, considering stochastic
observation and transmission channel conditions in SINs. Specifically, we
develop an aggregate optimization framework for observation scheduling,
compression ratio selection and transmission scheduling, and formulate a flow
optimization problem based on extended time expanded graph (ETEG) to maximize
the sum network utility. Then, we equivalently transform the flow optimization
problem on ETEG as a queue stability-related stochastic optimization problem.
An online algorithm is proposed to solve the problem in a slot-by-slot manner
by exploiting the Lyapunov optimization technique. Performance analysis shows
that the proposed algorithm achieves close-to-optimal network utility while
guaranteeing bounded queue occupancy. Extensive simulation results further
validate the efficiency of the proposed algorithm and evaluate the impacts of
various network parameters on the algorithm performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12720</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12720</id><created>2019-07-29</created><authors><author><keyname>Oakden-Rayner</keyname><forenames>Luke</forenames></author></authors><title>Exploring large scale public medical image datasets</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rationale and Objectives: Medical artificial intelligence systems are
dependent on well characterised large scale datasets. Recently released public
datasets have been of great interest to the field, but pose specific challenges
due to the disconnect they cause between data generation and data usage,
potentially limiting the utility of these datasets.
  Materials and Methods: We visually explore two large public datasets, to
determine how accurate the provided labels are and whether other subtle
problems exist. The ChestXray14 dataset contains 112,120 frontal chest films,
and the MURA dataset contains 40,561 upper limb radiographs. A subset of around
700 images from both datasets was reviewed by a board-certified radiologist,
and the quality of the original labels was determined.
  Results: The ChestXray14 labels did not accurately reflect the visual content
of the images, with positive predictive values mostly between 10% and 30% lower
than the values presented in the original documentation. There were other
significant problems, with examples of hidden stratification and label
disambiguation failure. The MURA labels were more accurate, but the original
normal/abnormal labels were inaccurate for the subset of cases with
degenerative joint disease, with a sensitivity of 60% and a specificity of 82%.
  Conclusion: Visual inspection of images is a necessary component of
understanding large image datasets. We recommend that teams producing public
datasets should perform this important quality control procedure and include a
thorough description of their findings, along with an explanation of the data
generating procedures and labelling rules, in the documentation for their
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12725</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12725</id><created>2019-07-29</created><authors><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Steady-State Simulation for Combined Transmission and Distribution
  Systems</title><categories>eess.SY cs.SY</categories><comments>To appear in IEEE Transactions on Smart Grid</comments><doi>10.1109/TSG.2019.2932403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future electric grid will consist of significant penetration of renewable
and distributed generation that is likely to create a homogenous transmission
and distribution (T&amp;D) system, requiring tools that can model and robustly
simulate the combined T&amp;D networks. Existing tools use disparate models and
formulations for simulation of transmission versus distribution grids and
solving for the steady-state solution of the combined T&amp;D networks often lacks
convergence robustness and scalability to large systems. In this paper, we show
that modeling both the T&amp;D grid elements in terms of currents and voltages
using an equivalent circuit framework enables simulation of combined positive
sequence networks of the transmission grids with three-phase networks of the
distribution grids without loss of generality. We further demonstrate that we
can ensure robust convergence for these resulting large-scale complex T&amp;D
systems when the circuit simulation methods are applied to them. Our results
illustrate robust convergence of combined T&amp;D networks using a direct
Newton-Raphson solver on a single machine for smaller sized systems and using a
parallel Gauss-Seidel-Newton solver on multiple machines for larger sized
systems with greater than million nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12727</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12727</id><created>2019-07-29</created><authors><author><keyname>Zhao</keyname><forenames>Qingyu</forenames></author><author><keyname>Adeli</keyname><forenames>Ehsan</forenames></author><author><keyname>Pfefferbaum</keyname><forenames>Adolf</forenames></author><author><keyname>Sullivan</keyname><forenames>Edith V.</forenames></author><author><keyname>Pohl</keyname><forenames>Kilian M.</forenames></author></authors><title>Confounder-Aware Visualization of ConvNets</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With recent advances in deep learning, neuroimaging studies increasingly rely
on convolutional networks (ConvNets) to predict diagnosis based on MR images.
To gain a better understanding of how a disease impacts the brain, the studies
visualize the salience maps of the ConvNet highlighting voxels within the brain
majorly contributing to the prediction. However, these salience maps are
generally confounded, i.e., some salient regions are more predictive of
confounding variables (such as age) than the diagnosis. To avoid such
misinterpretation, we propose in this paper an approach that aims to visualize
confounder-free saliency maps that only highlight voxels predictive of the
diagnosis. The approach incorporates univariate statistical tests to identify
confounding effects within the intermediate features learned by ConvNet. The
influence from the subset of confounded features is then removed by a novel
partial back-propagation procedure. We use this two-step approach to visualize
confounder-free saliency maps extracted from synthetic and two real datasets.
These experiments reveal the potential of our visualization in producing
unbiased model-interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12728</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12728</id><created>2019-07-29</created><authors><author><keyname>Liu</keyname><forenames>Huikang</forenames></author><author><keyname>Wu</keyname><forenames>Ruiyuan</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>Is There Any Recovery Guarantee with Coupled Structured Matrix
  Factorization for Hyperspectral Super-Resolution?</title><categories>eess.SP</categories><comments>submitted to CAMSAP 2019, extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coupled structured matrix factorization (CoSMF) for hyperspectral
super-resolution (HSR) has recently drawn significant interest in hyperspectral
imaging for remote sensing. Presently there is very few work that studies the
theoretical recovery guarantees of CoSMF. This paper makes one such endeavor by
considering the CoSMF formulation by Wei et al., which, simply speaking, is
similar to coupled non-negative matrix factorization. Assuming no noise, we
show sufficient conditions under which the globably optimal solution to the
CoSMF problem is guaranteed to deliver certain recovery accuracies. Our
analysis suggests that sparsity and the pure-pixel (or separability) condition
play a hidden role in enabling CoSMF to achieve some good recovery
characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12736</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12736</id><created>2019-07-30</created><authors><author><keyname>Jang</keyname><forenames>Ho-Deok</forenames></author><author><keyname>Woo</keyname><forenames>Sanghyun</forenames></author><author><keyname>Benz</keyname><forenames>Philipp</forenames></author><author><keyname>Park</keyname><forenames>Jinsun</forenames></author><author><keyname>Kweon</keyname><forenames>In So</forenames></author></authors><title>Propose-and-Attend Single Shot Detector</title><categories>cs.CV cs.LG eess.IV</categories><comments>8 pages, 2 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple yet effective prediction module for a one-stage detector.
The main process is conducted in a coarse-to-fine manner. First, the module
roughly adjusts the default boxes to well capture the extent of target objects
in an image. Second, given the adjusted boxes, the module aligns the receptive
field of the convolution filters accordingly, not requiring any embedding
layers. Both steps build a propose-and-attend mechanism, mimicking two-stage
detectors in a highly efficient manner. To verify its effectiveness, we apply
the proposed module to a basic one-stage detector SSD. Our final model achieves
an accuracy comparable to that of state-of-the-art detectors while using a
fraction of their model parameters and computational overheads. Moreover, we
found that the proposed module has two strong applications. 1) The module can
be successfully integrated into a lightweight backbone, further pushing the
efficiency of the one-stage detector. 2) The module also allows
train-from-scratch without relying on any sophisticated base networks as
previous methods do.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12741</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12741</id><created>2019-07-18</created><authors><author><keyname>Jan</keyname><forenames>Hamid</forenames></author><author><keyname>Ali</keyname><forenames>Amjad</forenames></author><author><keyname>Mahmood</keyname><forenames>Shahid</forenames></author><author><keyname>Srivastava</keyname><forenames>Gautam</forenames></author></authors><title>Statistical Descriptors-based Automatic Fingerprint Identification:
  Machine Learning Approaches</title><categories>cs.CV eess.IV</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of a person from fingerprints of good quality has been used by
commercial applications and law enforcement agencies for many years, however
identification of a person from latent fingerprints is very difficult and
challenging. A latent fingerprint is a fingerprint left on a surface by
deposits of oils and/or perspiration from the finger. It is not usually visible
to the naked eye but may be detected with special techniques such as dusting
with fine powder and then lifting the pattern of powder with transparent tape.
We have evaluated the quality of machine learning techniques that has been
implemented in automatic fingerprint identification. In this paper, we use
fingerprints of low quality from database DB1 of Fingerprint Verification
Competition (FVC 2002) to conduct our experiments. Fingerprints are processed
to find its core point using Poincare index and carry out enhancement using
Diffusion coherence filter whose performance is known to be good in the high
curvature regions of fingerprints. Grey-level Co-Occurrence Matrix (GLCM) based
seven statistical descriptors with four different inter pixel distances are
then extracted as features and put forward to train and test REPTree,
RandomTree, J48, Decision Stump and Random Forest Machine Learning techniques
for personal identification. Experiments are conducted on 80 instances and 28
attributes. Our experiments proved that Random Forests and J48 give good
results for latent fingerprints as compared to other machine learning
techniques and can help improve the identification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12743</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12743</id><created>2019-07-30</created><updated>2019-09-14</updated><authors><author><keyname>Chen</keyname><forenames>Min-Hung</forenames></author><author><keyname>Kira</keyname><forenames>Zsolt</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author><author><keyname>Yoo</keyname><forenames>Jaekwon</forenames></author><author><keyname>Chen</keyname><forenames>Ruxin</forenames></author><author><keyname>Zheng</keyname><forenames>Jian</forenames></author></authors><title>Temporal Attentive Alignment for Large-Scale Video Domain Adaptation</title><categories>cs.CV cs.LG cs.MM eess.IV</categories><comments>ICCV 2019 (Oral) camera-ready + supplementary. Code and data:
  http://github.com/cmhungsteve/TA3N</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although various image-based domain adaptation (DA) techniques have been
proposed in recent years, domain shift in videos is still not well-explored.
Most previous works only evaluate performance on small-scale datasets which are
saturated. Therefore, we first propose two large-scale video DA datasets with
much larger domain discrepancy: UCF-HMDB_full and Kinetics-Gameplay. Second, we
investigate different DA integration methods for videos, and show that
simultaneously aligning and learning temporal dynamics achieves effective
alignment even without sophisticated DA methods. Finally, we propose Temporal
Attentive Adversarial Adaptation Network (TA3N), which explicitly attends to
the temporal dynamics using domain discrepancy for more effective domain
alignment, achieving state-of-the-art performance on four video DA datasets
(e.g. 7.9% accuracy gain over &quot;Source only&quot; from 73.9% to 81.8% on &quot;HMDB --&gt;
UCF&quot;, and 10.3% gain on &quot;Kinetics --&gt; Gameplay&quot;). The code and data are
released at http://github.com/cmhungsteve/TA3N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12802</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12802</id><created>2019-07-30</created><updated>2020-02-18</updated><authors><author><keyname>Giaquinto</keyname><forenames>Nicola</forenames></author><author><keyname>Scarpetta</keyname><forenames>Marco</forenames></author><author><keyname>Spadavecchia</keyname><forenames>Maurizio</forenames></author></authors><title>Algorithms for Locating and Characterizing Cable Faults via
  Stepped-Frequency Waveform Reflectometry</title><categories>eess.SP</categories><comments>10 pages, 13 figures. Accepted for publication on IEEE Transactions
  on Instrumentation and Measurement</comments><doi>10.1109/TIM.2020.2974110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents algorithms to realize effectively and accurately the
stepped-frequency waveform reflectometry (SFWR), i.e. the reflectometric
technique based on the use of sinusoidal bursts. This technique is useful for
monitoring the health status of connection cables, but has many other
applications, like other reflectometric techniques. The paper outlines the
theory of SFWR, highlighting the problems associated to the transient
components in the reflected signals; presents a method to minimize the effect
of the transients, estimating the frequency response function (FRF) of interest
with very low systematic error; shows how to use the FRF to locate and
characterize faults in cables; evaluates accurately, using simulated cables
with exactly known characteristics, the errors associated to the proposed
methods. Overall, the paper demonstrates how the SFWR technique can be
effectively used for testing cables, and in general determine, via
reflectometry, parameters of interest of transmission lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12827</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12827</id><created>2019-07-30</created><authors><author><keyname>Wang</keyname><forenames>Tian</forenames></author><author><keyname>Bezerianos</keyname><forenames>Anastasios</forenames></author><author><keyname>Cichocki</keyname><forenames>Andrzej</forenames></author><author><keyname>Li</keyname><forenames>Junhua</forenames></author></authors><title>Multi-Kernel Capsule Network for Schizophrenia Identification</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Schizophrenia seriously affects the quality of life. To date, both
simple (linear discriminant analysis) and complex (deep neural network) machine
learning methods have been utilized to identify schizophrenia based on
functional connectivity features. The existing simple methods need two separate
steps (i.e., feature extraction and classification) to achieve the
identification, which disables simultaneous tuning for the best feature
extraction and classifier training. The complex methods integrate two steps and
can be simultaneously tuned to achieve optimal performance, but these methods
require a much larger amount of data for model training. Methods: To overcome
the aforementioned drawbacks, we proposed a multi-kernel capsule network
(MKCapsnet), which was developed by considering the brain anatomical structure.
Kernels were set to match with partition sizes of brain anatomical structure in
order to capture interregional connectivities at the varying scales. With the
inspiration of widely-used dropout strategy in deep learning, we developed
vector dropout in the capsule layer to prevent overfitting of the model.
Results: The comparison results showed that the proposed method outperformed
the state-of-the-art methods. Besides, we compared performances using different
parameters and illustrated the routing process to reveal characteristics of the
proposed method. Conclusion: MKCapsnet is promising for schizophrenia
identification. Significance: Our study not only proposed a multi-kernel
capsule network but also provided useful information in the parameter setting,
which is informative for further studies using a capsule network for
neurophysiological signal classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12830</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12830</id><created>2019-07-30</created><authors><author><keyname>Lopez-Martinez</keyname><forenames>Daniel</forenames></author><author><keyname>Peng</keyname><forenames>Ke</forenames></author><author><keyname>Lee</keyname><forenames>Arielle</forenames></author><author><keyname>Borsook</keyname><forenames>David</forenames></author><author><keyname>Picard</keyname><forenames>Rosalind</forenames></author></authors><title>Pain Detection with fNIRS-Measured Brain Signals: A Personalized Machine
  Learning Approach Using the Wavelet Transform and Bayesian Hierarchical
  Modeling with Dirichlet Process Priors</title><categories>eess.IV cs.LG q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently self-report pain ratings are the gold standard in clinical pain
assessment. However, the development of objective automatic measures of pain
could substantially aid pain diagnosis and therapy. Recent neuroimaging studies
have shown the potential of functional near-infrared spectroscopy (fNIRS) for
pain detection. This is a brain-imaging technique that provides non-invasive,
long-term measurements of cortical hemoglobin concentration changes. In this
study, we focused on fNIRS signals acquired exclusively from the prefrontal
cortex, which can be accessed unobtrusively, and derived an algorithm for the
detection of the presence of pain using Bayesian hierarchical modelling with
wavelet features. This approach allows personalization of the inference process
by accounting for inter-participant variability in pain responses. Our work
highlights the importance of adopting a personalized approach and supports the
use of fNIRS for pain assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12839</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12839</id><created>2019-07-30</created><updated>2019-12-14</updated><authors><author><keyname>Guan</keyname><forenames>Xinrong</forenames></author><author><keyname>Wu</keyname><forenames>Qingqing</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Intelligent Reflecting Surface Assisted Secrecy Communication: Is
  Artificial Noise Helpful or Not?</title><categories>cs.IT eess.SP math.IT</categories><comments>We show the necessity of using AN in the IRS-assisted secrecy
  communication system. It is observed that: (a) as the number of Eves, K,
  increases, transmit beamforming lacks sufficient DoF and it becomes more
  beneficial to send AN; (b) in the setup with both Bob and Eves are near IRS,
  the AN-aided No-IRS design even outperforms the No-AN IRS-aided design when K
  increases to large enough</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we investigate whether the use of artificial noise (AN) is
helpful to enhance the secrecy rate of an intelligent reflecting surface (IRS)
assisted wireless communication system. Specifically, an IRS is deployed nearby
a single-antenna receiver to assist in the transmission from a multi-antenna
transmitter, in the presence of multiple single-antenna eavesdroppers. Aiming
to maximize the achievable secrecy rate, a design problem for jointly
optimizing transmit beamforming with AN or jamming and IRS reflect beamforming
is formulated, which is however difficult to solve due to its non-convexity and
coupled variables. We thus propose an efficient algorithm based on alternating
optimization to solve the problem sub-optimally. Simulation results show that
incorporating AN in transmit beamforming is beneficial under the new setup with
IRS reflect beamforming. In particular, it is unveiled that the IRS-aided
design without AN even performs worse than the AN-aided design without IRS as
the number of eavesdroppers near the IRS increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12848</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12848</id><created>2019-07-30</created><updated>2019-08-07</updated><authors><author><keyname>Bourne</keyname><forenames>Jonathan</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Aidan</forenames></author><author><keyname>Arcaute</keyname><forenames>Elsa</forenames></author></authors><title>Don't go chasing artificial waterfalls: Simulating cascading failures in
  the power grid and the impact of artificial line-limit methods on results</title><categories>eess.SY cs.SY</categories><comments>13 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Research into cascading failures in power-transmission networks requires
detailed data on the capacity of individual transmission lines. However, these
data are often unavailable to researchers. As a result, line limits are often
modelled by assuming they are proportional to some average load. Little
research exists, however, to support this assumption as being realistic. In
this paper, we analyse the proportional-loading (PL) approach and compare it to
two linear models that use voltage and initial power flow as variables. In
conducting this modelling, we test the ability of artificial line limits to
model true line limits, the damage done during an attack and the order in which
edges are lost. we also test how accurately these methods rank the relative
performance of different attack strategies. We find that the linear models are
the top-performing method or close to the top in all tests. In comparison, the
tolerance value that produces the best PL limits changes depending on the test.
The PL approach was a particularly poor fit when the line tolerance was less
than two, which is the most commonly used value range in cascading-failure
research. We also find indications that the accuracy of modelling line limits
does not indicate how well a model will represent grid collapse. In addition,
we find evidence that the network's topology can be used to estimate the
system's true mean loading. The findings of this paper provide an understanding
of the weaknesses of the PL approach and offer an alternative method of
line-limit modelling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12891</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12891</id><created>2019-07-30</created><authors><author><keyname>Rukundo</keyname><forenames>Olivier</forenames></author></authors><title>4X4 Census Transform</title><categories>cs.CV eess.IV</categories><comments>3 pages, 9 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a 4X4 Census Transform (4X4CT) to encourage further
research in computer vision and visual computing. Unlike the traditional 3X3 CT
which uses a nine pixels kernel, the proposed 4X4CT uses a sixteen pixels
kernel with four overlapped groups of 3X3 kernel size. In each overlapping
group, a reference input pixel profits from its nearest eight pixels to produce
an eight bits binary string convertible to a grayscale integer of the 4X4CT's
output pixel. Preliminary experiments demonstrated more image textural
crispness and contrast than the CT as well as alternativeness to enable
meaningful solutions to be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12898</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12898</id><created>2019-07-19</created><updated>2019-10-08</updated><authors><author><keyname>Jiang</keyname><forenames>Ling</forenames></author><author><keyname>Hu</keyname><forenames>Yang</forenames></author><author><keyname>Xia</keyname><forenames>Xilin</forenames></author><author><keyname>Liang</keyname><forenames>Qiuhua</forenames></author><author><keyname>Soltoggio</keyname><forenames>Andrea</forenames></author></authors><title>A Multi-Scale Mapping Approach Based on a Deep Learning CNN Model for
  Reconstructing High-Resolution Urban DEMs</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The shortage of high-resolution urban digital elevation model (DEM) datasets
has been a challenge for modelling urban flood and managing its risk. A
solution is to develop effective approaches to reconstruct high-resolution DEMs
from their low-resolution equivalents that are more widely available. However,
the current high-resolution DEM reconstruction approaches mainly focus on
natural topography. Few attempts have been made for urban topography which is
typically an integration of complex man-made and natural features. This study
proposes a novel multi-scale mapping approach based on convolutional neural
network (CNN) to deal with the complex characteristics of urban topography and
reconstruct high-resolution urban DEMs. The proposed multi-scale CNN model is
firstly trained using urban DEMs that contain topographic features at different
resolutions, and then used to reconstruct the urban DEM at a specified (high)
resolution from a low-resolution equivalent. A two-level accuracy assessment
approach is also designed to evaluate the performance of the proposed urban DEM
reconstruction method, in terms of numerical accuracy and morphological
accuracy. The proposed DEM reconstruction approach is applied to a 121 km2
urbanized area in London, UK. Compared with other commonly used methods, the
current CNN based approach produces superior results, providing a
cost-effective innovative method to acquire high-resolution DEMs in other
data-scarce environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12900</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12900</id><created>2019-07-19</created><authors><author><keyname>Zhou</keyname><forenames>Yingwei</forenames></author></authors><title>Slot Based Image Augmentation System for Object Detection</title><categories>cs.CV cs.LG eess.IV</categories><comments>preprint draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object Detection has been a significant topic in computer vision. As the
continuous development of Deep Learning, many advanced academic and industrial
outcomes are established on localising and classifying the target objects, such
as instance segmentation, video tracking and robotic vision. As the core
concept of Deep Learning, Deep Neural Networks (DNNs) and associated training
are highly integrated with task-driven modelling, having great effects on
accurate detection. The main focus of improving detection performance is
proposing DNNs with extra layers and novel topological connections to extract
the desired features from input data. However, training these models can be
computationally expensive and laborious progress as the complicated model
architecture and enormous parameters. Besides, the dataset is another reason
causing this issue and low detection accuracy, because of insufficient data
samples or difficult instances. To address these training difficulties, this
thesis presents two different approaches to improve the detection performance
in the relatively light-weight way. As the intrinsic feature of data-driven in
deep learning, the first approach is &quot;slot-based image augmentation&quot; to enrich
the dataset with extra foreground and background combinations. Instead of the
commonly used image flipping method, the proposed system achieved similar mAP
improvement with less extra images which decrease training time. This proposed
augmentation system has extra flexibility adapting to various scenarios and the
performance-driven analysis provides an alternative aspect of conducting image
augmentation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12904</identifier>
 <datestamp>2019-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12904</id><created>2019-07-22</created><updated>2019-11-05</updated><authors><author><keyname>Sun</keyname><forenames>Wanjie</forenames></author><author><keyname>Chen</keyname><forenames>Zhenzhong</forenames></author></authors><title>Learned Image Downscaling for Upscaling using Content Adaptive Resampler</title><categories>cs.CV cs.MM eess.IV</categories><comments>15 pages; not the final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep convolutional neural network based image super-resolution (SR) models
have shown superior performance in recovering the underlying high resolution
(HR) images from low resolution (LR) images obtained from the predefined
downscaling methods. In this paper we propose a learned image downscaling
method based on content adaptive resampler (CAR) with consideration on the
upscaling process. The proposed resampler network generates content adaptive
image resampling kernels that are applied to the original HR input to generate
pixels on the downscaled image. Moreover, a differentiable upscaling (SR)
module is employed to upscale the LR result into its underlying HR counterpart.
By back-propagating the reconstruction error down to the original HR input
across the entire framework to adjust model parameters, the proposed framework
achieves a new state-of-the-art SR performance through upscaling guided image
resamplers which adaptively preserve detailed information that is essential to
the upscaling. Experimental results indicate that the quality of the generated
LR image is comparable to that of the traditional interpolation based method,
but the significant SR performance gain is achieved by deep SR models trained
jointly with the CAR model. The code is publicly available on: URL
https://github.com/sunwj/CAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12913</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12913</id><created>2019-07-26</created><authors><author><keyname>Rastgoftar</keyname><forenames>Hossein</forenames></author><author><keyname>Jeannin</keyname><forenames>Jean-Baptiste</forenames></author><author><keyname>Atkins</keyname><forenames>Ella</forenames></author></authors><title>Formal Specification of Continuum Deformation Coordination</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuum deformation is a leader-follower multiagent cooperative control
approach. Previous work showed a desired continuum deformation can be uniquely
defined based on trajectories of d +1 leaders in a d-dimensional motion space
and acquired by followers through local inter-agent communication. This paper
formally specifies continuum deformation coordination in an obstacle-laden
environment. Using linear temporal logic (LTL), continuum deformation liveness
and safety requirements are defined. Safety is prescribed by providing
conditions on (i) agent deviation bound, (ii) inter-agent collision avoidance,
(iii) agent containment, (iv) motion space containment, and (v) obstacle
collision avoidance. Liveness specifies a reachability condition on the desired
final formation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12921</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12921</id><created>2019-07-20</created><authors><author><keyname>Kavitha</keyname><forenames>K.</forenames></author><author><keyname>Rao</keyname><forenames>B. Thirumala</forenames></author></authors><title>Evaluation of Distance Measures for Feature based Image Registration
  using AlexNet</title><categories>cs.CV cs.DC eess.IV</categories><doi>10.14569/IJACSA.2018.091034</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Image registration is a classic problem of computer vision with several
applications across areas like defence, remote sensing, medicine etc. Feature
based image registration methods traditionally used hand-crafted feature
extraction algorithms, which detect key points in an image and describe them
using a region around the point. Such features are matched using a threshold
either on distances or ratio of distances computed between the feature
descriptors. Evolution of deep learning, in particular convolution neural
networks, has enabled researchers to address several problems of vision such as
recognition, tracking, localization etc. Outputs of convolution layers or fully
connected layers of CNN which has been trained for applications like visual
recognition are proved to be effective when used as features in other
applications such as retrieval. In this work, a deep CNN, AlexNet, is used in
the place of handcrafted features for feature extraction in the first stage of
image registration. However, there is a need to identify a suitable distance
measure and a matching method for effective results. Several distance metrics
have been evaluated in the framework of nearest neighbour and nearest neighbour
ratio matching methods using benchmark dataset. Evaluation is done by comparing
matching and registration performance using metrics computed from ground truth.
  Keywords: Distance measures; deep learning; feature detection; feature
descriptor; image matching
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12928</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12928</id><created>2019-07-25</created><authors><author><keyname>Junyu</keyname><affiliation>Jason</affiliation></author><author><keyname>Wang</keyname></author><author><keyname>Song</keyname><forenames>Rong</forenames></author></authors><title>Improved Super-Resolution Convolution Neural Network for Large Images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single image super-resolution (SISR) is a very popular topic nowadays, which
has both research value and practical value. In daily life, we crop a large
image into sub-images to do super-resolution and then merge them together.
Although convolution neural network performs very well in the research field,
if we use it to do super-resolution, we can easily observe cutting lines from
merged pictures. To address these problems, in this paper, we propose a refined
architecture of SRCNN with 'Symmetric padding', 'Random learning' and 'Residual
learning'. Moreover, we have done a lot of experiments to prove our model
performs best among a lot of the state-of-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12929</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12929</id><created>2019-07-25</created><authors><author><keyname>Ding</keyname><forenames>Li</forenames></author><author><keyname>Fridman</keyname><forenames>Lex</forenames></author></authors><title>Object as Distribution</title><categories>cs.CV cs.LG eess.IV</categories><comments>NeurIPS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object detection is a critical part of visual scene understanding. The
representation of the object in the detection task has important implications
on the efficiency and feasibility of annotation, robustness to occlusion, pose,
lighting, and other visual sources of semantic uncertainty, and effectiveness
in real-world applications (e.g., autonomous driving). Popular object
representations include 2D and 3D bounding boxes, polygons, splines, pixels,
and voxels. Each have their strengths and weakness. In this work, we propose a
new representation of objects based on the bivariate normal distribution. This
distribution-based representation has the benefit of robust detection of
highly-overlapping objects and the potential for improved downstream tracking
and instance segmentation tasks due to the statistical representation of object
edges. We provide qualitative evaluation of this representation for the object
detection task and quantitative evaluation of its use in a baseline algorithm
for the instance segmentation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12930</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12930</id><created>2019-07-25</created><updated>2019-10-23</updated><authors><author><keyname>Zhang</keyname><forenames>Shihao</forenames></author><author><keyname>Fu</keyname><forenames>Huazhu</forenames></author><author><keyname>Yan</keyname><forenames>Yuguang</forenames></author><author><keyname>Zhang</keyname><forenames>Yubing</forenames></author><author><keyname>Wu</keyname><forenames>Qingyao</forenames></author><author><keyname>Yang</keyname><forenames>Ming</forenames></author><author><keyname>Tan</keyname><forenames>Mingkui</forenames></author><author><keyname>Xu</keyname><forenames>Yanwu</forenames></author></authors><title>Attention Guided Network for Retinal Image Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted to MICCAI 2019. Project page:
  (https://github.com/HzFu/AGNet)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning structural information is critical for producing an ideal result in
retinal image segmentation. Recently, convolutional neural networks have shown
a powerful ability to extract effective representations. However, convolutional
and pooling operations filter out some useful structural information. In this
paper, we propose an Attention Guided Network (AG-Net) to preserve the
structural information and guide the expanding operation. In our AG-Net, the
guided filter is exploited as a structure sensitive expanding path to transfer
structural information from previous feature maps, and an attention block is
introduced to exclude the noise and reduce the negative influence of background
further. The extensive experiments on two retinal image segmentation tasks
(i.e., blood vessel segmentation, optic disc and cup segmentation) demonstrate
the effectiveness of our proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12941</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12941</id><created>2019-07-30</created><authors><author><keyname>Meier</keyname><forenames>Raphael</forenames></author><author><keyname>Rebsamen</keyname><forenames>Michael</forenames></author><author><keyname>Knecht</keyname><forenames>Urspeter</forenames></author><author><keyname>Reyes</keyname><forenames>Mauricio</forenames></author><author><keyname>Wiest</keyname><forenames>Roland</forenames></author><author><keyname>McKinley</keyname><forenames>Richard</forenames></author></authors><title>Stratify or Inject: Two Simple Training Strategies to Improve Brain
  Tumor Segmentation</title><categories>eess.IV</categories><comments>Accepted as extended abstract for MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/r1gjGAroFN</report-no><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep learning methods for brain tumor segmentation are typically trained in
an ad hoc fashion on all available data. Brain tumors are tremendously
heterogeneous in image appearance and labeled training data is limited. We
argue that incorporation of additional prior information, specifically tumor
grade, associated with tumor imaging phenotypes during model training can
significantly improve segmentation performance. Two strategies for
incorporation of tumor grade during model training are proposed and their
impact on segmentation performance is demonstrated on the BRATS 2018 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12945</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12945</id><created>2019-07-26</created><authors><author><keyname>Sun</keyname><forenames>Tao</forenames></author><author><keyname>Barrio</keyname><forenames>Roberto</forenames></author><author><keyname>Rodriguez</keyname><forenames>Marcos</forenames></author><author><keyname>Jiang</keyname><forenames>Hao</forenames></author></authors><title>Inertial nonconvex alternating minimizations for the image deblurring</title><categories>math.OC cs.CV cs.MM eess.IV</categories><comments>Transactions on Image Processing</comments><doi>10.1109/TIP.2019.2924339</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In image processing, Total Variation (TV) regularization models are commonly
used to recover blurred images. One of the most efficient and popular methods
to solve the convex TV problem is the Alternating Direction Method of
Multipliers (ADMM) algorithm, recently extended using the inertial proximal
point method. Although all the classical studies focus on only a convex
formulation, recent articles are paying increasing attention to the nonconvex
methodology due to its good numerical performance and properties. In this
paper, we propose to extend the classical formulation with a novel nonconvex
Alternating Direction Method of Multipliers with the Inertial technique
(IADMM). Under certain assumptions on the parameters, we prove the convergence
of the algorithm with the help of the Kurdyka-{\L}ojasiewicz property. We also
present numerical simulations on classical TV image reconstruction problems to
illustrate the efficiency of the new algorithm and its behavior compared with
the well established ADMM method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12965</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12965</id><created>2019-07-30</created><authors><author><keyname>Huang</keyname><forenames>Yubo</forenames></author><author><keyname>Lu</keyname><forenames>Junguo</forenames></author><author><keyname>Zhang</keyname><forenames>Weidong</forenames></author></authors><title>Small disturbances can trigger cascading failures in power grids</title><categories>eess.SY cs.SY</categories><comments>9 pages. 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the sharp increase of power demand, large-scale blackouts in power grids
occur frequently around the world. Cascading failures are the main causes of
network outages. Therefore, revealing the complicated cascade mechanism in
grids is conducive to design the efficient policy to restrain the failures and
further ensure a stable supply of power to users. Motivated by the recent
advances of network dynamics, we proposed a framework based Lyapunov stability
to analyze the dynamically induced cascading failures in complex networks. We
abandoned the assumption that the network is stable in traditional static
failure models and then detected that small disturbances actually can trigger
cascading failures in unstable networks. What's worse, such failure usually
accompanied the overload failure of lines during the equilibriums conversion
process. Through the simulation analysis of the Spanish grid, we summarized
that the features of this new failure mode include low incidence, large
destructiveness, and fast propagation speed. And it usually tends to occur
first in edge nodes and subsequently propagate to the central nodes. These
features are consistent with the empirical observation of outages in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12988</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.12988</id><created>2019-07-30</created><authors><author><keyname>Su</keyname><forenames>Lanlan</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author><author><keyname>Antsaklis</keyname><forenames>Panos</forenames></author></authors><title>Feedback Passivation of Linear Systems with Fixed-Structured Controllers</title><categories>eess.SY cs.SY math.OC</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of designing an optimal output feedback
controller with a specified controller structure for linear time-invariant
(LTI) systems to maximize the passivity level for the closed-loop system, in
both continuous-time (CT) and discrete-time (DT). Specifically, the set of
controllers under consideration is linearly parameterized with constrained
parameters. Both input feedforward passivity (IFP) and output feedback
passivity (OFP) indices are used to capture the level of passivity. Given a set
of stabilizing controllers, a necessary and sufficient condition is proposed
for the existence of such fixed-structured output feedback controllers that can
passivate the closed-loop system. Moreover, it is shown that the condition can
be used to obtain the controller that maximizes the IFP or the OFP index by
solving a convex optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13003</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13003</id><created>2019-07-30</created><authors><author><keyname>Su</keyname><forenames>Lanlan</forenames></author><author><keyname>Li</keyname><forenames>Mengmou</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author><author><keyname>Chesi</keyname><forenames>Graziano</forenames></author></authors><title>Distributed Resource Allocation over Time-varying Balanced Digraphs with
  Discrete-time Communication</title><categories>cs.MA cs.SY eess.SY math.OC</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a group of nodes aiming to solve a resource allocation problem
cooperatively and distributedly. Specifically, each node has access to its own
local cost function and local network resource, and the goal is to minimize the
sum of the local cost functions subject to a global network resource
constraint. The communication among the nodes occurs at discrete-time steps and
the communication topology is described by a strongly connected and
weight-balanced digraph that may be time-varying. We propose a continuous-time
algorithm that solves this problem. Particularly, a novel passivity-based
perspective of the proposed algorithmic dynamic at each individual node is
provided, which enables us to analyze the convergence of the overall
distributed algorithm over time-varying digraphs. To exempt from the
difficult-to-satisfy assumption of continuous-time communication among nodes,
we also develop an asynchronous distributed event-triggered scheme building on
the passivity-based notion. Additionally, a synchronous periodic communication
strategy is also derived through analyzing the passivity degradation over
sampling of the distributed dynamic at each node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13016</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13016</id><created>2019-07-30</created><authors><author><keyname>Rakhshandehroo</keyname><forenames>Mohsen</forenames></author><author><keyname>Rajabdorri</keyname><forenames>Mohammad</forenames></author></authors><title>Time Series Analysis of Big Data for Electricity Price and Demand to
  Find Cyber-Attacks part 2: Decomposition Analysis</title><categories>eess.SP stat.ML</categories><comments>7pages, 8 tables, 17 figs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, in following of the first part (which ADF tests using ACI
evaluation) has conducted, Time Series (TSs) are analyzed using decomposition
analysis. In fact, TSs are composed of four components including trend (long
term behavior or progression of series), cyclic component (non-periodic
fluctuation behavior which are usually long term), seasonal component (periodic
fluctuations due to seasonal variations like temperature, weather condition and
etc.) and error term. For our case of cyber-attack detection, in this paper,
two common ways of TS decomposition are investigated. The first method is
additive decomposition and the second is multiplicative method to decompose a
TS into its components. After decomposition, the error term is tested using
Durbin-Watson and Breusch-Godfrey test to see whether the error follows any
predictable pattern, it can be concluded that there is a chance of cyber-attack
to the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13020</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13020</id><created>2019-07-30</created><authors><author><keyname>Wei</keyname><forenames>Dongming</forenames></author><author><keyname>Ahmad</keyname><forenames>Sahar</forenames></author><author><keyname>Huo</keyname><forenames>Jiayu</forenames></author><author><keyname>Peng</keyname><forenames>Wen</forenames></author><author><keyname>Ge</keyname><forenames>Yunhao</forenames></author><author><keyname>Xue</keyname><forenames>Zhong</forenames></author><author><keyname>Yap</keyname><forenames>Pew-Thian</forenames></author><author><keyname>Li</keyname><forenames>Wentao</forenames></author><author><keyname>Shen</keyname><forenames>Dinggang</forenames></author><author><keyname>Wang</keyname><forenames>Qian</forenames></author></authors><title>Synthesis and Inpainting-Based MR-CT Registration for Image-Guided
  Thermal Ablation of Liver Tumors</title><categories>eess.IV cs.CV</categories><comments>Accepted in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thermal ablation is a minimally invasive procedure for treat-ing small or
unresectable tumors. Although CT is widely used for guiding ablation
procedures, the contrast of tumors against surrounding normal tissues in CT
images is often poor, aggravating the difficulty in accurate thermal ablation.
In this paper, we propose a fast MR-CT image registration method to overlay a
pre-procedural MR (pMR) image onto an intra-procedural CT (iCT) image for
guiding the thermal ablation of liver tumors. By first using a Cycle-GAN model
with mutual information constraint to generate synthesized CT (sCT) image from
the cor-responding pMR, pre-procedural MR-CT image registration is carried out
through traditional mono-modality CT-CT image registration. At the
intra-procedural stage, a partial-convolution-based network is first used to
inpaint the probe and its artifacts in the iCT image. Then, an unsupervised
registration network is used to efficiently align the pre-procedural CT (pCT)
with the inpainted iCT (inpCT) image. The final transformation from pMR to iCT
is obtained by combining the two estimated transformations,i.e., (1) from the
pMR image space to the pCT image space (through sCT) and (2) from the pCT image
space to the iCT image space (through inpCT). Experimental results confirm that
the proposed method achieves high registration accuracy with a very fast
computational speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13024</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13024</id><created>2019-07-30</created><updated>2019-07-31</updated><authors><author><keyname>Su</keyname><forenames>Lanlan</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author><author><keyname>Chesi</keyname><forenames>Graziano</forenames></author></authors><title>Stabilization of Linear Systems Across a Time-Varying AWGN Fading
  Channel</title><categories>eess.SY cs.IT cs.SY math.IT math.OC</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical note investigates the minimum average transmit power required
for mean-square stabilization of a discrete-time linear process across a
time-varying additive white Gaussian noise (AWGN) fading channel that is
presented between the sensor and the controller. We assume channel state
information at both the transmitter and the receiver, and allow the transmit
power to vary with the channel state to obtain the minimum required average
transmit power via optimal power adaptation. We consider both the case of
independent and identically distributed fading and fading subject to a Markov
chain. Based on the proposed necessary and sufficient conditions for
mean-square stabilization, we show that the minimum average transmit power to
ensure stabilizability can be obtained by solving a geometric program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13025</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13025</id><created>2019-07-30</created><authors><author><keyname>Caetano</keyname><forenames>Carlos</forenames></author><author><keyname>Sena</keyname><forenames>Jessica</forenames></author><author><keyname>Br&#xe9;mond</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Santos</keyname><forenames>Jefersson A. dos</forenames></author><author><keyname>Schwartz</keyname><forenames>William Robson</forenames></author></authors><title>SkeleMotion: A New Representation of Skeleton Joint Sequences Based on
  Motion Information for 3D Action Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>16-th IEEE International Conference on Advanced Video and
  Signal-based Surveillance (AVSS2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the availability of large-scale skeleton datasets, 3D human action
recognition has recently called the attention of computer vision community.
Many works have focused on encoding skeleton data as skeleton image
representations based on spatial structure of the skeleton joints, in which the
temporal dynamics of the sequence is encoded as variations in columns and the
spatial structure of each frame is represented as rows of a matrix. To further
improve such representations, we introduce a novel skeleton image
representation to be used as input of Convolutional Neural Networks (CNNs),
named SkeleMotion. The proposed approach encodes the temporal dynamics by
explicitly computing the magnitude and orientation values of the skeleton
joints. Different temporal scales are employed to compute motion values to
aggregate more temporal dynamics to the representation making it able to
capture longrange joint interactions involved in actions as well as filtering
noisy motion values. Experimental results demonstrate the effectiveness of the
proposed representation on 3D action recognition outperforming the
state-of-the-art on NTU RGB+D 120 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13033</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13033</id><created>2019-07-30</created><authors><author><keyname>Cai</keyname><forenames>Jiaxin</forenames></author><author><keyname>Zhu</keyname><forenames>Hongfeng</forenames></author></authors><title>Lung image segmentation by generative adversarial networks</title><categories>eess.IV cs.CV</categories><report-no>2019 International Conference on Image and Video Processing, and
  Artificial Intelligence. Shanghai, China, Aug, 2019</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung image segmentation plays an important role in computer-aid pulmonary
diseases diagnosis and treatment. This paper proposed a lung image segmentation
method by generative adversarial networks. We employed a variety of generative
adversarial networks and use its capability of image translation to perform
image segmentation. The generative adversarial networks was employed to
translate the original lung image to the segmented image. The generative
adversarial networks based segmentation method was test on real lung image data
set. Experimental results shows that the proposed method is effective and
outperform state-of-the art method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13049</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13049</id><created>2019-07-30</created><authors><author><keyname>&#x10c;i&#x10d;i&#x107;</keyname><forenames>Mladen</forenames></author><author><keyname>Jin</keyname><forenames>Li</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>Coordinating Vehicle Platoons for Highway Bottleneck Decongestion and
  Throughput Improvement</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Truck platooning is a technology that is expected to become widespread in the
coming years. Apart from the numerous benefits that it brings, its potential
effects on the overall traffic situation needs to be studied further,
especially at bottlenecks and ramps. However, assuming we can control the truck
platoons from the infrastructure, they can be used as controlled moving
bottlenecks, actuating control actions on the rest of the traffic. Thus
properly controlled platoons can possibly improve the efficiency and throughput
of the whole system. In this paper, we use a multi-class cell transmission
model to capture the interaction between truck platoons and background traffic,
and propose a corresponding queuing model, which we use for control design. As
control inputs, we use platoon speeds, and the number of lanes platoons occupy,
and we devise a control strategy for throughput improvement. This control law
is applied on a highway section upstream of a bottleneck, with one on-ramp and
one off-ramp. By postponing and shaping the inflow to the bottleneck, we are
able to keep it in free flow, avoiding traffic breakdown and capacity drop,
leading to significant reduction of total time spent of all vehicles. We tested
the proposed control in a simulation study and found that by applying, we
reduce the median delay of all vehicles by 75.6%. Notably, although they are
slowed down while actuating control actions, platoons experience less delay
compared to the case without control, since they avoid going through congestion
at the bottleneck.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13057</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13057</id><created>2019-07-30</created><authors><author><keyname>Park</keyname><forenames>Jungkyu</forenames></author><author><keyname>Phang</keyname><forenames>Jason</forenames></author><author><keyname>Shen</keyname><forenames>Yiqiu</forenames></author><author><keyname>Wu</keyname><forenames>Nan</forenames></author><author><keyname>Kim</keyname><forenames>S. Gene</forenames></author><author><keyname>Moy</keyname><forenames>Linda</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Geras</keyname><forenames>Krzysztof J.</forenames></author></authors><title>Screening Mammogram Classification with Prior Exams</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/HkgCdUaMq4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Radiologists typically compare a patient's most recent breast cancer
screening exam to their previous ones in making informed diagnoses. To reflect
this practice, we propose new neural network models that compare pairs of
screening mammograms from the same patient. We train and evaluate our proposed
models on over 665,000 pairs of images (over 166,000 pairs of exams). Our best
model achieves an AUC of 0.866 in predicting malignancy in patients who
underwent breast cancer screening, reducing the error rate of the corresponding
baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13075</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13075</id><created>2019-07-30</created><authors><author><keyname>L&#xf3;pez</keyname><forenames>Pau Rodr&#xed;guez</forenames></author><author><keyname>Dorta</keyname><forenames>Diego Velazquez</forenames></author><author><keyname>Preixens</keyname><forenames>Guillem Cucurull</forenames></author><author><keyname>Gonfaus</keyname><forenames>Josep M.</forenames></author><author><keyname>Marva</keyname><forenames>F. Xavier Roca</forenames></author><author><keyname>Sabat&#xe9;</keyname><forenames>Jordi Gonz&#xe0;lez</forenames></author></authors><title>Pay attention to the activations: a modular attention mechanism for
  fine-grained image recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>IEEE Transactions on Multimedia, ECCV extension</comments><doi>10.1109/TMM.2019.2928494</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fine-grained image recognition is central to many multimedia tasks such as
search, retrieval and captioning. Unfortunately, these tasks are still
challenging since the appearance of samples of the same class can be more
different than those from different classes. Attention has been typically
implemented in neural networks by selecting the most informative regions of the
image that improve classification. In contrast, in this paper, attention is not
applied at the image level but to the convolutional feature activations. In
essence, with our approach, the neural model learns to attend to lower-level
feature activations without requiring part annotations and uses those
activations to update and rectify the output likelihood distribution. The
proposed mechanism is modular, architecture-independent and efficient in terms
of both parameters and computation required. Experiments demonstrate that
well-known networks such as Wide Residual Networks and ResNeXt, when augmented
with our approach, systematically improve their classification accuracy and
become more robust to changes in deformation and pose and to the presence of
clutter. As a result, our proposal reaches state-of-the-art classification
accuracies in CIFAR-10, the Adience gender recognition task, Stanford Dogs, and
UEC-Food100 while obtaining competitive performance in ImageNet, CIFAR-100,
CUB200 Birds, and Stanford Cars. In addition, we analyze the different
components of our model, showing that the proposed attention modules succeed in
finding the most discriminative regions of the image. Finally, as a proof of
concept, we demonstrate that with only local predictions, an augmented neural
network can successfully classify an image before reaching any fully connected
layer, thus reducing the computational amount up to 10%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13091</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13091</id><created>2019-07-30</created><authors><author><keyname>Chen</keyname><forenames>Tan</forenames></author><author><keyname>Goodwine</keyname><forenames>Bill</forenames></author></authors><title>Controllability and Accessibility Results for N-Link Horizontal Planar
  Manipulators with One Unactuated Joint</title><categories>eess.SY cs.RO cs.SY</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper presents the accessibility and small-time local controllability
(STLC) results for $N$-link horizontal planar manipulators with only one
unactuated joint. STLC is important in controls, both for design considerations
and because large and swinging maneuvers may be avoided for close
reconfiguration if a system is STLC. Despite the fact that controllability of
underactuated horizontal planar manipulators has been extensively studied, most
work focused only on three-link and global controllability. This paper thus has
two contributions: 1) using Lie brackets to study the accessibility and STLC
for underactuated two-link manipulators with different actuator configurations,
and illustrating the results from a perspective of system dynamics, 2)
obtaining the accessibility and STLC results for $N$-link manipulators with one
unactuated joint by considering realistic models and different actuator
configurations. It is found that an $N$-link ($N\geq 3$) with the first joint
actuated is STLC for a subset of equilibrium points based on Sussmann's general
theorem for STLC. Moreover, with the dynamics of $N$-link considered in the
controllability analysis, it gives relatively simple forms for the nontrivial
vector fields, which make it easy to determine at which configurations a model
loses full rank condition for accessibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13121</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13121</id><created>2019-07-29</created><authors><author><keyname>Sercu</keyname><forenames>Tom</forenames></author><author><keyname>Mallinar</keyname><forenames>Neil</forenames></author></authors><title>Multi-Frame Cross-Entropy Training for Convolutional Neural Networks in
  Speech Recognition</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Multi-Frame Cross-Entropy training (MFCE) for convolutional
neural network acoustic models. Recognizing that similar to RNNs, CNNs are in
nature sequence models that take variable length inputs, we propose to take as
input to the CNN a part of an utterance long enough that multiple labels are
predicted at once, therefore getting cross-entropy loss signal from multiple
adjacent frames. This increases the amount of label information drastically for
small marginal computational cost. We show large WER improvements on hub5 and
rt02 after training on the 2000-hour Switchboard benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13122</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13122</id><created>2019-07-29</created><authors><author><keyname>Singh</keyname><forenames>Sumeet</forenames></author><author><keyname>Richards</keyname><forenames>Spencer M.</forenames></author><author><keyname>Sindhwani</keyname><forenames>Vikas</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques E.</forenames></author><author><keyname>Pavone</keyname><forenames>Marco</forenames></author></authors><title>Learning Stabilizable Nonlinear Dynamics with Contraction-Based
  Regularization</title><categories>math.OC cs.LG cs.RO cs.SY eess.SY</categories><comments>Invited submission for IJRR; under review. arXiv admin note: text
  overlap with arXiv:1808.00113</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel framework for learning stabilizable nonlinear dynamical
systems for continuous control tasks in robotics. The key contribution is a
control-theoretic regularizer for dynamics fitting rooted in the notion of
stabilizability, a constraint which guarantees the existence of robust tracking
controllers for arbitrary open-loop trajectories generated with the learned
system. Leveraging tools from contraction theory and statistical learning in
Reproducing Kernel Hilbert Spaces, we formulate stabilizable dynamics learning
as a functional optimization with convex objective and bi-convex functional
constraints. Under a mild structural assumption and relaxation of the
functional constraints to sampling-based constraints, we derive the optimal
solution with a modified Representer theorem. Finally, we utilize random matrix
feature approximations to reduce the dimensionality of the search parameters
and formulate an iterative convex optimization algorithm that jointly fits the
dynamics functions and searches for a certificate of stabilizability. We
validate the proposed algorithm in simulation for a planar quadrotor, and on a
quadrotor hardware testbed emulating planar dynamics. We verify, both in
simulation and on hardware, significantly improved trajectory generation and
tracking performance with the control-theoretic regularized model over models
learned using traditional regression techniques, especially when learning from
small supervised datasets. The results support the conjecture that the use of
stabilizability constraints as a form of regularization can help prune the
hypothesis space in a manner that is tailored to the downstream task of
trajectory generation and feedback control, resulting in models that are not
only dramatically better conditioned, but also data efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13124</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13124</id><created>2019-07-30</created><authors><author><keyname>Ozbulak</keyname><forenames>Utku</forenames></author><author><keyname>Van Messem</keyname><forenames>Arnout</forenames></author><author><keyname>De Neve</keyname><forenames>Wesley</forenames></author></authors><title>Impact of Adversarial Examples on Deep Learning Models for Biomedical
  Image Segmentation</title><categories>eess.IV cs.CR cs.CV cs.LG stat.ML</categories><comments>Accepted for the 22nd International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI-19)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models, which are increasingly being used in the field of
medical image analysis, come with a major security risk, namely, their
vulnerability to adversarial examples. Adversarial examples are carefully
crafted samples that force machine learning models to make mistakes during
testing time. These malicious samples have been shown to be highly effective in
misguiding classification tasks. However, research on the influence of
adversarial examples on segmentation is significantly lacking. Given that a
large portion of medical imaging problems are effectively segmentation
problems, we analyze the impact of adversarial examples on deep learning-based
image segmentation models. Specifically, we expose the vulnerability of these
models to adversarial examples by proposing the Adaptive Segmentation Mask
Attack (ASMA). This novel algorithm makes it possible to craft targeted
adversarial examples that come with (1) high intersection-over-union rates
between the target adversarial mask and the prediction and (2) with
perturbation that is, for the most part, invisible to the bare eye. We lay out
experimental and visual evidence by showing results obtained for the ISIC skin
lesion segmentation challenge and the problem of glaucoma optic disc
segmentation. An implementation of this algorithm and additional examples can
be found at https://github.com/utkuozbulak/adaptive-segmentation-mask-attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13177</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13177</id><created>2019-07-30</created><authors><author><keyname>Phan</keyname><forenames>Huy</forenames></author><author><keyname>Ch&#xe9;n</keyname><forenames>Oliver Y.</forenames></author><author><keyname>Koch</keyname><forenames>Philipp</forenames></author><author><keyname>Lu</keyname><forenames>Zongqing</forenames></author><author><keyname>McLoughlin</keyname><forenames>Ian</forenames></author><author><keyname>Mertins</keyname><forenames>Alfred</forenames></author><author><keyname>De Vos</keyname><forenames>Maarten</forenames></author></authors><title>Towards More Accurate Automatic Sleep Staging via Deep Transfer Learning</title><categories>cs.LG eess.SP stat.ML</categories><comments>Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although large annotated sleep databases are publicly available, and might be
used to train automated scoring algorithms, it might still be a challenge to
develop an optimal algorithm for your personal sleep study, which might have
few subjects or rely on a different recording setup. Both directly applying a
learned algorithm or retraining the algorithm on your rather small database is
suboptimal. And definitely state-of-the-art sleep staging algorithms based on
deep neural networks demand a large amount of data to be trained. This work
presents a deep transfer learning approach to overcome the channel mismatch
problem and enable transferring knowledge from a large dataset to a small
cohort for automatic sleep staging. We start from a generic end-to-end deep
learning framework for sequence-to-sequence sleep staging and derive two
networks adhering to this framework as a device for transfer learning. The
networks are first trained in the source domain (i.e. the large database). The
pretrained networks are then finetuned in the target domain, i.e. the small
cohort, to complete knowledge transfer. We employ the Montreal Archive of Sleep
Studies (MASS) database consisting of 200 subjects as the source domain and
study deep transfer learning on four different target domains: the Sleep
Cassette subset and the Sleep Telemetry subset of the Sleep-EDF Expanded
database, the Surrey-cEEGGrid database, and the Surrey-PSG database. The target
domains are purposely adopted to cover different degrees of channel mismatch to
the source domain. Our experimental results show significant performance
improvement on automatic sleep staging on the target domains achieved with the
proposed deep transfer learning approach and we discuss the impact of various
fine tuning approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13188</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13188</id><created>2019-07-30</created><authors><author><keyname>Thomas</keyname><forenames>Mark</forenames></author><author><keyname>Martin</keyname><forenames>Bruce</forenames></author><author><keyname>Kowarski</keyname><forenames>Katie</forenames></author><author><keyname>Gaudet</keyname><forenames>Briand</forenames></author><author><keyname>Matwin</keyname><forenames>Stan</forenames></author></authors><title>Marine Mammal Species Classification using Convolutional Neural Networks
  and a Novel Acoustic Representation</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>16 pages, To appear in ECML-PKDD 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research into automated systems for detecting and classifying marine mammals
in acoustic recordings is expanding internationally due to the necessity to
analyze large collections of data for conservation purposes. In this work, we
present a Convolutional Neural Network that is capable of classifying the
vocalizations of three species of whales, non-biological sources of noise, and
a fifth class pertaining to ambient noise. In this way, the classifier is
capable of detecting the presence and absence of whale vocalizations in an
acoustic recording. Through transfer learning, we show that the classifier is
capable of learning high-level representations and can generalize to additional
species. We also propose a novel representation of acoustic signals that builds
upon the commonly used spectrogram representation by way of interpolating and
stacking multiple spectrograms produced using different Short-time Fourier
Transform (STFT) parameters. The proposed representation is particularly
effective for the task of marine mammal species classification where the
acoustic events we are attempting to classify are sensitive to the parameters
of the STFT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13248</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13248</id><created>2019-07-30</created><authors><author><keyname>Di Renna</keyname><forenames>R. B.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Study of Adaptive Activity-Aware Iterative Detection Techniques for
  Massive Machine-Type Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>9 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the uplink of grant-free low data-rate massive
machine-to-machine communications (mMTC) where devices are only active
sporadically, which requires a joint activity and data detection at the
receiver. We develop an adaptive decision feedback detector along with an
$l_0$-norm regularized activity-aware recursive least-squares algorithm that
only require pilot symbols. An iterative detection and decoding scheme based on
low-density parity-check (LDPC) is also devised for signal detection in mMTC.
Simulations show the performance of the proposed approaches against existing
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13261</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13261</id><created>2019-07-30</created><authors><author><keyname>Lobos</keyname><forenames>Rodrigo A.</forenames></author><author><keyname>Hoge</keyname><forenames>W. Scott</forenames></author><author><keyname>Javed</keyname><forenames>Ahsan</forenames></author><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Nayak</keyname><forenames>Krishna S.</forenames></author><author><keyname>Haldar</keyname><forenames>Justin P.</forenames></author></authors><title>Robust Autocalibrated Structured Low-Rank EPI Ghost Correction</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: We propose and evaluate a new structured low-rank method for EPI
ghost correction called Robust Autocalibrated LORAKS (RAC-LORAKS). The method
can be used to suppress EPI ghosts arising from the differences between
different readout gradient polarities and/or the differences between different
shots. It does not require conventional EPI navigator signals, and is robust to
imperfect autocalibration data.
  Methods: Autocalibrated LORAKS is a previous structured low-rank method for
EPI ghost correction that uses GRAPPA-type autocalibration data to enable
high-quality ghost correction. This method works well when the autocalibration
data is pristine, but performance degrades substantially when the
autocalibration information is imperfect. RAC-LORAKS generalizes Autocalibrated
LORAKS in two ways. First, it does not completely trust the information from
autocalibration data, and instead considers the autocalibration and EPI data
simultaneously when estimating low-rank matrix structure. And second, it uses
complementary information from the autocalibration data to improve EPI
reconstruction in a multi-contrast joint reconstruction framework. RAC-LORAKS
is evaluated using simulations and in vivo data, and compared to
state-of-the-art methods.
  Results: RAC-LORAKS is demonstrated to have good ghost elimination
performance compared to state-of-the-art methods in several complicated
acquisition scenarios (including gradient-echo brain imaging, diffusion-encoded
brain imaging, and cardiac imaging).
  Conclusion: RAC-LORAKS provides effective suppression of EPI ghosts and is
robust to imperfect autocalibration data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13262</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13262</id><created>2019-07-30</created><authors><author><keyname>Hilbert</keyname><forenames>Tom</forenames></author><author><keyname>Xia</keyname><forenames>Ding</forenames></author><author><keyname>Block</keyname><forenames>Kai Tobias</forenames></author><author><keyname>Yu</keyname><forenames>Zidan</forenames></author><author><keyname>Lattanzi</keyname><forenames>Riccardo</forenames></author><author><keyname>Sodickson</keyname><forenames>Daniel K.</forenames></author><author><keyname>Kober</keyname><forenames>Tobias</forenames></author><author><keyname>Cloos</keyname><forenames>Martijn A.</forenames></author></authors><title>Magnetization Transfer in Magnetic Resonance Fingerprinting</title><categories>eess.IV physics.bio-ph physics.med-ph</categories><comments>11 pages, 5 figures, 2 tables, 2 supplements</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To study the effects of magnetization transfer (MT, in which a
semisolid spin pool interacts with the free pool), in the context of magnetic
resonance fingerprinting (MRF).
  Methods: Simulations and phantom experiments were performed to study the
impact of MT on the MRF signal and its potential influence on T1 and T2
estimation. Subsequently, an MRF sequence implementing off-resonance MT pulses
and a dictionary with an MT dimension by incorporating a two-pool model were
used to estimate the fractional pool size in addition to the B1+, T1, and T2
values. The proposed method was evaluated in the human brain.
  Results: Simulations and phantom experiments showed that an MRF signal
obtained from a cross-linked bovine serum sample is influenced by MT. Using a
dictionary based on an MT model, a better match between simulations and
acquired MR signals can be obtained (NRMSE 1.3% versus 4.7%). Adding
off-resonance MT pulses can improve the differentiation of MT from T1 and T2.
In-vivo results showed that MT affects the MRF signals from white matter
(fractional pool-size ~16%) and gray matter (fractional pool-size ~10%).
Furthermore, longer T1 (~1060 ms versus ~860 ms) and T2 values (~47 ms versus
~35 ms) can be observed in white matter if MT is accounted for.
  Conclusion: Our experiments demonstrated a potential influence of MT on the
quantification of T1 and T2 with MRF. A model that encompasses MT effects can
improve the accuracy of estimated relaxation parameters and allows
quantification of the fractional pool size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13266</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13266</id><created>2019-07-30</created><authors><author><keyname>Wang</keyname><forenames>Qisheng</forenames></author><author><keyname>Feng</keyname><forenames>Keming</forenames></author></authors><title>PrecoderNet: Hybrid Beamforming for Millimeter Wave Systems Using Deep
  Reinforcement Learning</title><categories>eess.SP cs.LG</categories><comments>7 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) with large-scale antenna arrays is a promising
solution to resolve the frequency resource shortage in next generation wireless
communication. However, fully digital beamforming structure becomes infeasible
due to its prohibitively high hardware cost and unacceptable energy consumption
while traditional hybrid beamforming algorithms have unnegligible gap to the
optimal up bound. In this paper, we consider a mmWave point-to-point massive
multiple-input-multiple-output (MIMO) system and propose a new hybrid analog
and digital beamforming (HBF) scheme based on deep reinforcement learning (DRL)
to improve the spectral efficiency and reduce system bit error rate (BER). At
the base station (BS) side, we propose a novel DRL-based HBF design method
called PrecoderNet to design the hybrid precoding matrix. The DRL agent denotes
the system sum rate as state and the real /imaginary part of the digital
beamformer as actions. For the user side, the minimum mean-square-error (MMSE)
criterion is used to design the receiving hybrid precoders which minimizes the
distance between the processed signals and the transmitted signals.
Furthermore, HBF design algorithm such as weighted MMSE and orthogonal matching
pursuit (OMP) are regarded as benchmarks to verify the performance of our
algorithm. Finally, simulation results demonstrate that our proposed
PrecoderNet outperforms the benchmarks in terms of spectral efficiency and BER
while is more tractable in practical implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13269</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13269</id><created>2019-07-30</created><authors><author><keyname>Guo</keyname><forenames>Jiajia</forenames></author><author><keyname>Wang</keyname><forenames>Jinghe</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Compression and Acceleration of Neural Networks for Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 4 figures, 2 tables. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning (DL) has achieved great success in signal processing and
communications and has become a promising technology for future wireless
communications. Existing works mainly focus on exploiting DL to improve the
performance of communication systems. However, the high memory requirement and
computational complexity constitute a major hurdle for the practical deployment
of DL-based communications. In this article, we investigate how to compress and
accelerate the neural networks (NNs) in communication systems. After
introducing the deployment challenges for DL-based communication algorithms, we
discuss some representative NN compression and acceleration techniques.
Afterwards, two case studies for multiple-input-multiple-output (MIMO)
communications, including DL-based channel state information feedback and
signal detection, are presented to show the feasibility and potential of these
techniques. We finally identify some challenges on NN compression and
acceleration in DL-based communications and provide a guideline for subsequent
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13294</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13294</id><created>2019-07-30</created><authors><author><keyname>Kaviani</keyname><forenames>Ramin</forenames></author><author><keyname>Hedman</keyname><forenames>Kory W.</forenames></author></authors><title>A Detection Mechanism Against Load-Redistribution Attacks in Smart Grids</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a real-time non-probabilistic detection mechanism to
detect load-redistribution (LR) attacks against energy management systems
(EMSs). Prior studies have shown that certain LR attacks can bypass
conventional bad data detectors (BDDs) and remain undetectable, which implies
that presence of a reliable and intelligent detection mechanism to flag LR
attacks, is imperative. Therefore, in this study a detection mechanism to
enhance the existing BDDs is proposed based on the fundamental knowledge of the
physics laws in the electric grid. A greedy algorithm, which can optimize the
core LR attack problems, is presented to enable a fast mechanism to identify
the most sensitive locations for critical assets. The main contribution of this
detection mechanism is leveraging of power systems domain insight to identify
an underlying exploitable structure for the core problem of LR attack problems,
which enables the prediction of the attackers' behavior. Additional
contribution includes the ability to combine this approach with other detection
mechanisms to increase their likelihood of detection. The proposed approach is
applied to 2383-bus Polish test system to demonstrate the scalability of the
greedy algorithm, and it solved the attacker's problem more than 10x faster
than a traditional linear optimization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13297</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13297</id><created>2019-07-30</created><updated>2019-11-29</updated><authors><author><keyname>Liu</keyname><forenames>Wanchun</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Wireless Networked Control Systems with Coding-Free Data Transmission
  for Industrial IoT</title><categories>cs.IT cs.SY eess.SY math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networked control systems for the Industrial Internet of Things
(IIoT) require low latency communication techniques that are very reliable and
resilient. In this paper, we investigate a coding-free control method to
achieve ultra-low latency communications in single-controller-multi-plant
networked control systems for both slow and fast fading channels. We formulate
a power allocation problem to optimize the sum cost functions of multiple
plants, subject to the plant stabilization condition and the controller's power
limit. Although the optimization problem is a non-convex one, we derive a
closed-form solution, which indicates that the optimal power allocation policy
for stabilizing the plants with different channel conditions is reminiscent of
the channel-inversion policy. We numerically compare the performance of the
proposed coding-free control method and the conventional coding-based control
methods in terms of the control performance (i.e., the cost function) of a
plant, which shows that the coding-free method is superior in a practical range
of SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13306</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13306</id><created>2019-07-31</created><authors><author><keyname>Lin</keyname><forenames>Bin</forenames></author><author><keyname>Huang</keyname><forenames>Yinhao</forenames></author><author><keyname>Zhang</keyname><forenames>Jianshan</forenames></author><author><keyname>Hu</keyname><forenames>Junqin</forenames></author><author><keyname>Chen</keyname><forenames>Xing</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author></authors><title>Cost-Driven Offloading for DNN-based Applications over Cloud, Edge and
  End Devices</title><categories>cs.DC eess.SP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Currently, deep neural networks (DNNs) have achieved a great success in
various applications. Traditional deployment for DNNs in the cloud may incur a
prohibitively serious delay in transferring input data from the end devices to
the cloud. To address this problem, the hybrid computing environments,
consisting of the cloud, edge and end devices, are adopted to offload DNN
layers by combining the larger layers (more amount of data) in the cloud and
the smaller layers (less amount of data) at the edge and end devices. A key
issue in hybrid computing environments is how to minimize the system cost while
accomplishing the offloaded layers with their deadline constraints. In this
paper, a self-adaptive discrete particle swarm optimization (PSO) algorithm
using the genetic algorithm (GA) operators was proposed to reduce the system
cost caused by data transmission and layer execution. This approach considers
the characteristics of DNNs partitioning and layers offloading over the cloud,
edge and end devices. The mutation operator and crossover operator of GA were
adopted to avert the premature convergence of PSO, which distinctly reduces the
system cost through enhanced population diversity of PSO. The proposed
offloading strategy is compared with benchmark solutions, and the results show
that our strategy can effectively reduce the cost of offloading for DNN-based
applications over the cloud, edge and end devices relative to the benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13342</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13342</id><created>2019-07-31</created><authors><author><keyname>AprilPyone</keyname><forenames>MaungMaung</forenames></author><author><keyname>Sirichotedumrong</keyname><forenames>Warit</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Adversarial Test on Learnable Image Encryption</title><categories>eess.IV cs.CV</categories><comments>To be appeared in 2019 IEEE 8th Global Conference on Consumer
  Electronics (GCCE 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data for deep learning should be protected for privacy preserving.
Researchers have come up with the notion of learnable image encryption to
satisfy the requirement. However, existing privacy preserving approaches have
never considered the threat of adversarial attacks. In this paper, we ran an
adversarial test on learnable image encryption in five different scenarios. The
results show different behaviors of the network in the variable key scenarios
and suggest learnable image encryption provides certain level of adversarial
robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13351</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13351</id><created>2019-07-31</created><authors><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Chen</keyname><forenames>Xiaocong</forenames></author><author><keyname>Dong</keyname><forenames>Manqing</forenames></author><author><keyname>Liu</keyname><forenames>Huan</forenames></author><author><keyname>Ge</keyname><forenames>Chang</forenames></author><author><keyname>Yao</keyname><forenames>Lina</forenames></author></authors><title>Multi-task Generative Adversarial Learning on Geometrical Shape
  Reconstruction from EEG Brain Signals</title><categories>eess.SP cs.LG</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthesizing geometrical shapes from human brain activities is an interesting
and meaningful but very challenging topic. Recently, the advancements of deep
generative models like Generative Adversarial Networks (GANs) have supported
the object generation from neurological signals. However, the
Electroencephalograph (EEG)-based shape generation still suffer from the low
realism problem. In particular, the generated geometrical shapes lack clear
edges and fail to contain necessary details. In light of this, we propose a
novel multi-task generative adversarial network to convert the individual's EEG
signals evoked by geometrical shapes to the original geometry. First, we adopt
a Convolutional Neural Network (CNN) to learn highly informative latent
representation for the raw EEG signals, which is vital for the subsequent shape
reconstruction. Next, we build the discriminator based on multi-task learning
to distinguish and classify fake samples simultaneously, where the mutual
promotion between different tasks improves the quality of the recovered shapes.
Then, we propose a semantic alignment constraint in order to force the
synthesized samples to approach the real ones in pixel-level, thus producing
more compelling shapes. The proposed approach is evaluated over a local dataset
and the results show that our model outperforms the competitive
state-of-the-art baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13357</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13357</id><created>2019-07-31</created><updated>2020-01-24</updated><authors><author><keyname>Takeyama</keyname><forenames>Saori</forenames></author><author><keyname>Ono</keyname><forenames>Shunsuke</forenames></author><author><keyname>Kumazawa</keyname><forenames>Itsuo</forenames></author></authors><title>Hybrid Spatio-Spectral Total Variation: A Regularization Technique for
  Hyperspectral Image Denoising and Compressed Sensing</title><categories>eess.SP math.OC</categories><comments>11 pages, 3 tables, 8 figures, submitted to IEEE Trans. Geosci.
  Remote Sens</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new regularization technique, named Hybrid Spatio-Spectral Total
Variation (HSSTV), for hyperspectral (HS) image denoising and compressed
sensing. Regularization techniques based on total variation (TV) focus on local
differences of an HS image to model its underlying smoothness and have been
recognized as a popular approach to HS image restoration. However, existing TVs
do not fully exploit underlying spectral correlation in their designs and/or
require a high computational cost in optimization. Our HSSTV is designed to
simultaneously evaluates two types of local differences: direct local spatial
differences and local spatio-spectral differences in a unified manner with a
balancing weight. This design resolves the said drawbacks of existing TVs.
Then, we formulate HS image restoration as a constrained convex optimization
problem involving HSSTV and develop an efficient algorithm based on the
alternating direction method of multipliers (ADMM) for solving it. In the
experiments, we illustrate the advantages of HSSTV over several
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13372</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13372</id><created>2019-07-31</created><updated>2019-09-17</updated><authors><author><keyname>Michieli</keyname><forenames>Umberto</forenames></author><author><keyname>Zanuttigh</keyname><forenames>Pietro</forenames></author></authors><title>Incremental Learning Techniques for Semantic Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>8 pages, 3 figures, 4 tables</comments><journal-ref>International Conference on Computer Vision (ICCV), Workshop on
  Transferring and Adapting Source Knowledge in Computer Vision (TASK-CV) 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning architectures exhibit a critical drop of performance due to
catastrophic forgetting when they are required to incrementally learn new
tasks. Contemporary incremental learning frameworks focus on image
classification and object detection while in this work we formally introduce
the incremental learning problem for semantic segmentation in which a
pixel-wise labeling is considered. To tackle this task we propose to distill
the knowledge of the previous model to retain the information about previously
learned classes, whilst updating the current model to learn the new ones. We
propose various approaches working both on the output logits and on
intermediate features. In opposition to some recent frameworks, we do not store
any image from previously learned classes and only the last model is needed to
preserve high accuracy on these classes. The experimental evaluation on the
Pascal VOC2012 dataset shows the effectiveness of the proposed approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13381</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13381</id><created>2019-07-31</created><authors><author><keyname>Radhakrishnan</keyname><forenames>Vimal</forenames></author><author><keyname>Taghizadeh</keyname><forenames>Omid</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Rate Splitting for Massive MIMO Multi-carrier system using Full Duplex
  Decode and Forward Relay with Hardware Impairments</title><categories>cs.IT cs.SY eess.SP eess.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the power allocation problem for a decode and
forward (DF) relay system, where a massive multiple-input-multiple-output
(mMIMO) multi-carrier (MC) base station (BS) node communicates with a MC single
antenna node directly and also through the single antenna full duplex (FD) MC
relay, using rate splitting (RS) approach. Successive interference cancellation
approach is adopted at the destination. We consider orthogonal frequency
division multiplexing (OFDM) as our MC strategy. We take into account the
impact of hardware distortions resulting in residual self-interference and
inter-carrier leakage (ICL), and also imperfect channel state information
(CSI). We formulate a joint sub-carrier and power allocation problem to
maximize the total sum rate. An iterative optimization method is proposed,
which follows successive inner approximation (SIA) framework to reach the
convergence point that satisfies the Karush-Kuhn-Tucker (KKT) conditions.
Numerical results show the significance of distortion-aware design for such
systems, and also the significant gain in terms of sum rate compared to its
half duplex (HD) and also non-rate splitting scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13401</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13401</id><created>2019-07-31</created><authors><author><keyname>Gordon</keyname><forenames>O.</forenames></author><author><keyname>Junqueira</keyname><forenames>F.</forenames></author><author><keyname>Moriarty</keyname><forenames>P.</forenames></author></authors><title>Embedding Human Heuristics in Machine-Learning-Enabled Probe Microscopy</title><categories>physics.atm-clus cs.LG eess.IV physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scanning probe microscopists generally do not rely on complete images to
assess the quality of data acquired during a scan. Instead, assessments of the
state of the tip apex, which not only determines the resolution in any scanning
probe technique but can also generate a wide array of frustrating artefacts,
are carried out in real time on the basis of a few lines of an image (and,
typically, their associated line profiles.) The very small number of machine
learning approaches to probe microscopy published to date, however, involve
classifications based on full images. Given that data acquisition is the most
time-consuming task during routine tip conditioning, automated methods are thus
currently extremely slow in comparison to the tried-and-trusted strategies and
heuristics used routinely by probe microscopists. Here, we explore various
strategies by which different STM image classes (arising from changes in the
tip state) can be correctly identified from partial scans. By employing a
secondary temporal network and a rolling window of a small group of individual
scanlines, we find that tip assessment is possible with a small fraction of a
complete image. We achieve this with little-to-no performance penalty -- or,
indeed, markedly improved performance in some cases -- and introduce a protocol
to detect the state of the tip apex in real time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13409</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13409</id><created>2019-07-31</created><authors><author><keyname>Heker</keyname><forenames>Michal</forenames></author><author><keyname>Ben-Cohen</keyname><forenames>Avi</forenames></author><author><keyname>Greenspan</keyname><forenames>Hayit</forenames></author></authors><title>Hierarchical Fine-Tuning for joint Liver Lesion Segmentation and Lesion
  Classification in CT</title><categories>eess.IV</categories><comments>Accepted to IEEE EMBC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an automatic method for joint liver lesion segmentation and
classification using a hierarchical fine-tuning framework. Our dataset is
small, containing 332 2-D CT examinations with lesion annotated into 3 lesion
types: cysts, hemangiomas, and metastases. Using a cascaded U-net that performs
segmentation and classification simultaneously, we trained a strong lesion
segmentation model on the dataset of MICCAI 2017 Liver Tumor Segmentation
(LiTS) Challenge. We used the trained weights to fine-tune a slightly modified
model to obtain improved lesion segmentation and classification, on the smaller
dataset. Since pre-training was done with similar data on a related task, we
were able to learn more representative features (especially higher-level
features in the U-Net's encoder), and improve pixel-wise classification
results. We show an improvement of over 10\% in Dice score and classification
accuracy, compared to a baseline model. We further improve the classification
performance by hierarchically freezing the encoder part of the network and
achieve an improvement of over 15\% in Dice score and classification accuracy.
We compare our results with an existing method and show an improvement of 14\%
in the success rate and 12\% in the classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13418</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13418</id><created>2019-07-31</created><authors><author><keyname>Tanno</keyname><forenames>Ryutaro</forenames></author><author><keyname>Worrall</keyname><forenames>Daniel</forenames></author><author><keyname>Kaden</keyname><forenames>Enrico</forenames></author><author><keyname>Ghosh</keyname><forenames>Aurobrata</forenames></author><author><keyname>Grussu</keyname><forenames>Francesco</forenames></author><author><keyname>Bizzi</keyname><forenames>Alberto</forenames></author><author><keyname>Sotiropoulos</keyname><forenames>Stamatios N.</forenames></author><author><keyname>Criminisi</keyname><forenames>Antonio</forenames></author><author><keyname>Alexander</keyname><forenames>Daniel C.</forenames></author></authors><title>Uncertainty Quantification in Deep Learning for Safer Neuroimage
  Enhancement</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning (DL) has shown great potential in medical image enhancement
problems, such as super-resolution or image synthesis. However, to date, little
consideration has been given to uncertainty quantification over the output
image. Here we introduce methods to characterise different components of
uncertainty in such problems and demonstrate the ideas using diffusion MRI
super-resolution. Specifically, we propose to account for $intrinsic$
uncertainty through a heteroscedastic noise model and for $parameter$
uncertainty through approximate Bayesian inference, and integrate the two to
quantify $predictive$ uncertainty over the output image. Moreover, we introduce
a method to propagate the predictive uncertainty on a multi-channelled image to
derived scalar parameters, and separately quantify the effects of intrinsic and
parameter uncertainty therein. The methods are evaluated for super-resolution
of two different signal representations of diffusion MR images---DTIs and Mean
Apparent Propagator MRI---and their derived quantities such as MD and FA, on
multiple datasets of both healthy and pathological human brains. Results
highlight three key benefits of uncertainty modelling for improving the safety
of DL-based image enhancement systems. Firstly, incorporating uncertainty
improves the predictive performance even when test data departs from training
data. Secondly, the predictive uncertainty highly correlates with errors, and
is therefore capable of detecting predictive &quot;failures&quot;. Results demonstrate
that such an uncertainty measure enables subject-specific and voxel-wise risk
assessment of the output images. Thirdly, we show that the method for
decomposing predictive uncertainty into its independent sources provides
high-level &quot;explanations&quot; for the performance by quantifying how much
uncertainty arises from the inherent difficulty of the task or the limited
training examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13445</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13445</id><created>2019-07-31</created><authors><author><keyname>Tirupachuri</keyname><forenames>Yeshasvi</forenames></author><author><keyname>Nava</keyname><forenames>Gabriele</forenames></author><author><keyname>Rapetti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Latella</keyname><forenames>Claudia</forenames></author><author><keyname>Pucci</keyname><forenames>Daniele</forenames></author></authors><title>Trajectory Advancement during Human-Robot Collaboration</title><categories>cs.RO cs.SY eess.SY</categories><comments>Accepted to the 28th IEEE International Conference on Robot &amp; Human
  Interactive Communication (IEEE RO-MAN 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As technology advances, the barriers between the co-existence of humans and
robots are slowly coming down. The prominence of physical interactions for
collaboration and cooperation between humans and robots will be an undeniable
fact. Rather than exhibiting simple reactive behaviors to human interactions,
it is desirable to endow robots with augmented capabilities of exploiting human
interactions for successful task completion. Towards that goal, in this paper,
we propose a trajectory advancement approach in which we mathematically derive
the conditions that facilitate advancing along a reference trajectory by
leveraging assistance from helpful interaction wrench present during
human-robot collaboration. We validate our approach through experiments
conducted with the iCub humanoid robot both in simulation and on the real
robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13452</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13452</id><created>2019-07-31</created><updated>2019-07-31</updated><authors><author><keyname>Zhai</keyname><forenames>Chao</forenames></author></authors><title>A Robust Optimization Approach for Terminating the Cascading Failure of
  Power Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to uncertainties and the complicated intrinsic dynamics of power systems,
it is difficult to predict the cascading failure paths once the cascades occur.
This makes it challenging to achieve the effective power system protection
against cascading blackouts. By incorporating uncertainties and stochastic
factors of the cascades, a Markov chain model is developed in this paper to
predict the cascading failure paths of power systems. The transition matrix of
Markov chain is dependent on the probability of branch outage caused by
overloads or stochastic factors. Moreover, a robust optimization formulation is
proposed to deal with the cascading blackouts by shedding load optimally for
multiple cascading failure paths with relatively high probabilities.
Essentially, it can be converted to the best approximation problem. Thus, an
efficient numerical solver based on Dykstra's algorithm is employed to deal
with the robust optimization problem. In theory, we provide a lower bound for
the probability of preventing the cascading blackouts of power systems.
Finally, the proposed approach for power system protection is verified by a
case study of IEEE 118 bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13505</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13505</id><created>2019-07-31</created><authors><author><keyname>Mariani</keyname><forenames>Andrea</forenames></author><author><keyname>Giorgetti</keyname><forenames>Andrea</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>On Oversampling-Based Signal Detection</title><categories>eess.SP</categories><comments>This is a pre-print of an article published in International Journal
  of Wireless Information Networks. The final authenticated version is
  available online at: https://doi.org/10.1007/s10776-019-00444-9</comments><journal-ref>International Journal of Wireless Information Networks, July, 2019</journal-ref><doi>10.1007/s10776-019-00444-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability of inexpensive devices allows nowadays to implement
cognitive radio functionalities in large-scale networks such as the
internet-of-things and future mobile cellular systems. In this paper, we focus
on wideband spectrum sensing in the presence of oversampling, i.e., the
sampling frequency of a digital receiver is larger than the signal bandwidth,
where signal detection must take into account the front-end impairments of
low-cost devices. Based on the noise model of a software-defined radio dongle,
we address the problem of robust signal detection in the presence of noise
power uncertainty and non-flat noise power spectral density (PSD). In
particular, we analyze the receiver operating characteristic of several
detectors in the presence of such front-end impairments, to assess the
performance attainable in a real-world scenario. We propose new
frequency-domain detectors, some of which are proven to outperform previously
proposed spectrum sensing techniques such as, e.g., eigenvalue-based tests. The
study shows that the best performance is provided by a noise-uncertainty immune
energy detector (ED) and, for the colored noise case, by tests that match the
PSD of the receiver noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13511</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13511</id><created>2019-07-31</created><authors><author><keyname>Shor</keyname><forenames>Joel</forenames></author><author><keyname>Emanuel</keyname><forenames>Dotan</forenames></author><author><keyname>Lang</keyname><forenames>Oran</forenames></author><author><keyname>Tuval</keyname><forenames>Omry</forenames></author><author><keyname>Brenner</keyname><forenames>Michael</forenames></author><author><keyname>Cattiau</keyname><forenames>Julie</forenames></author><author><keyname>Vieira</keyname><forenames>Fernando</forenames></author><author><keyname>McNally</keyname><forenames>Maeve</forenames></author><author><keyname>Charbonneau</keyname><forenames>Taylor</forenames></author><author><keyname>Nollstadt</keyname><forenames>Melissa</forenames></author><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author><author><keyname>Matias</keyname><forenames>Yossi</forenames></author></authors><title>Personalizing ASR for Dysarthric and Accented Speech with Limited Data</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic speech recognition (ASR) systems have dramatically improved over
the last few years. ASR systems are most often trained from 'typical' speech,
which means that underrepresented groups don't experience the same level of
improvement. In this paper, we present and evaluate finetuning techniques to
improve ASR for users with non-standard speech. We focus on two types of
non-standard speech: speech from people with amyotrophic lateral sclerosis
(ALS) and accented speech. We train personalized models that achieve 62% and
35% relative WER improvement on these two groups, bringing the absolute WER for
ALS speakers, on a test set of message bank phrases, down to 10% for mild
dysarthria and 20% for more serious dysarthria. We show that 71% of the
improvement comes from only 5 minutes of training data. Finetuning a particular
subset of layers (with many fewer parameters) often gives better results than
finetuning the entire model. This is the first step towards building state of
the art ASR models for dysarthric speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13512</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13512</id><created>2019-07-31</created><updated>2019-08-15</updated><authors><author><keyname>Tavakolpour-Saleh</keyname><forenames>A. R.</forenames></author></authors><title>General theorem of equilibrium status</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determination of stability and instability of singular points in nonlinear
dynamical systems is an important issue that has attracted considerable
attention in different fields of engineering and science. So far, different
well-defined theories have been presented to study the stability of singular
points among which the Lyapunov theory is well-known. However, the instability
problem of singular points has been neglected to some extent in spite of its
application in oscillator design. Besides, it is often difficult to achieve a
proper Lyapunov function for a given complex system. This work presents a more
general theorem based on defining two distinct functionals and some
straightforward criteria that significantly facilitate the determination of
equilibrium status at singular points without the requirement to analytical
solution. Indeed, this method is applicable to both instability and stability
problems of linear and nonlinear systems. In addition, the presented theorem is
further generalized for linearization of dynamical systems based on averaging
technique. The obtained results clearly show the effectiveness and generality
of the proposed theorem for linear and nonlinear dynamic problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13517</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13517</id><created>2019-07-27</created><updated>2019-11-30</updated><authors><author><keyname>Kim</keyname><forenames>Amang Song-Kyoo</forenames></author><author><keyname>Yeun</keyname><forenames>Chan Yeob</forenames></author><author><keyname>Yoo</keyname><forenames>Paul D.</forenames></author></authors><title>An Enhanced Machine Learning-based Biometric Authentication System Using
  RR-Interval Framed Electrocardiograms</title><categories>cs.CR cs.LG eess.SP</categories><comments>The paper has been accepted and published in the IEEE Access</comments><journal-ref>IEEE Access 7 (2019), pp. 168669-168674</journal-ref><doi>10.1109/ACCESS.2019.2954576</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is targeted in the area of biometric data enabled security system
based on the machine learning for the digital health. The disadvantages of
traditional authentication systems include the risks of forgetfulness, loss,
and theft. Biometric authentication is therefore rapidly replacing traditional
authentication methods and is becoming an everyday part of life. The
electrocardiogram (ECG) was recently introduced as a biometric authentication
system suitable for security checks. The proposed authentication system helps
investigators studying ECG-based biometric authentication techniques to reshape
input data by slicing based on the RR-interval, and defines the Overall
Performance (OP), which is the combined performance metric of multiple
authentication measures. We evaluated the performance of the proposed system
using a confusion matrix and achieved up to 95% accuracy by compact data
analysis. We also used the Amang ECG (amgecg) toolbox in MATLAB to investigate
the upper-range control limit (UCL) based on the mean square error, which
directly affects three authentication performance metrics: the accuracy, the
number of accepted samples, and the OP. Using this approach, we found that the
OP can be optimized by using a UCL of 0.0028, which indicates 61 accepted
samples out of 70 and ensures that the proposed authentication system achieves
an accuracy of 95%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13539</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13539</id><created>2019-07-31</created><authors><author><keyname>Licandro</keyname><forenames>Roxane</forenames></author><author><keyname>Hofmanninger</keyname><forenames>Johannes</forenames></author><author><keyname>Perkonigg</keyname><forenames>Matthias</forenames></author><author><keyname>R&#xf6;hrich</keyname><forenames>Sebastian</forenames></author><author><keyname>Weber</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Wennmann</keyname><forenames>Markus</forenames></author><author><keyname>Kintzele</keyname><forenames>Laurent</forenames></author><author><keyname>Piraud</keyname><forenames>Marie</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern</forenames></author><author><keyname>Langs</keyname><forenames>Georg</forenames></author></authors><title>Asymmetric Cascade Networks for Focal Bone Lesion Prediction in Multiple
  Myeloma</title><categories>eess.IV</categories><comments>5 pages, 2 figures, International Conference on Medical Imaging with
  Deep Learning, MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/H1xLm6fQ5E</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The reliable and timely stratification of bone lesion evolution risk in
smoldering Multiple Myeloma plays an important role in identifying prime
markers of the disease's advance and in improving the patients' outcome. In
this work we provide an asymmetric cascade network for the longitudinal
prediction of future bone lesions for T1 weighted whole body MR images. The
proposed cascaded architecture, consisting of two distinct configured U-Nets,
first detects the bone regions and subsequently predicts lesions within bones
in a patch based way. The algorithm provides a full volumetric risk score map
for the identification of early signatures of emerging lesions and for
visualising high risk locations. The prediction accuracy is evaluated on a
longitudinal dataset of 63 multiple myeloma patients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13590</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13590</id><created>2019-07-31</created><updated>2019-08-28</updated><authors><author><keyname>Yang</keyname><forenames>Junlin</forenames></author><author><keyname>Dvornek</keyname><forenames>Nicha C.</forenames></author><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Chapiro</keyname><forenames>Julius</forenames></author><author><keyname>Lin</keyname><forenames>MingDe</forenames></author><author><keyname>Duncan</keyname><forenames>James S.</forenames></author></authors><title>Unsupervised Domain Adaptation via Disentangled Representations:
  Application to Cross-Modality Liver Segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A deep learning model trained on some labeled data from a certain source
domain generally performs poorly on data from different target domains due to
domain shifts. Unsupervised domain adaptation methods address this problem by
alleviating the domain shift between the labeled source data and the unlabeled
target data. In this work, we achieve cross-modality domain adaptation, i.e.
between CT and MRI images, via disentangled representations. Compared to
learning a one-to-one mapping as the state-of-art CycleGAN, our model recovers
a many-to-many mapping between domains to capture the complex cross-domain
relations. It preserves semantic feature-level information by finding a shared
content space instead of a direct pixelwise style transfer. Domain adaptation
is achieved in two steps. First, images from each domain are embedded into two
spaces, a shared domain-invariant content space and a domain-specific style
space. Next, the representation in the content space is extracted to perform a
task. We validated our method on a cross-modality liver segmentation task, to
train a liver segmentation model on CT images that also performs well on MRI.
Our method achieved Dice Similarity Coefficient (DSC) of 0.81, outperforming a
CycleGAN-based method of 0.72. Moreover, our model achieved good generalization
to joint-domain learning, in which unpaired data from different modalities are
jointly learned to improve the segmentation performance on each individual
modality. Lastly, under a multi-modal target domain with significant diversity,
our approach exhibited the potential for diverse image generation and remained
effective with DSC of 0.74 on multi-phasic MRI while the CycleGAN-based method
performed poorly with a DSC of only 0.52.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.13594</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.13594</id><created>2019-07-31</created><authors><author><keyname>Kocer</keyname><forenames>Basaran Bahadir</forenames></author><author><keyname>Tiryaki</keyname><forenames>Mehmet Efe</forenames></author><author><keyname>Pratama</keyname><forenames>Mahardhika</forenames></author><author><keyname>Tjahjowidodo</keyname><forenames>Tegoeh</forenames></author><author><keyname>Seet</keyname><forenames>Gerald Gim Lee</forenames></author></authors><title>Aerial Robot Control in Close Proximity to Ceiling: A Force
  Estimation-based Nonlinear MPC</title><categories>cs.RO cs.SY eess.SY</categories><comments>Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being motivated by ceiling inspection applications via unmanned aerial
vehicles (UAVs) which require close proximity flight to surfaces, a systematic
control approach enabling safe and accurate close proximity flight is proposed
in this work. There are two main challenges for close proximity flights: (i)
the trust characteristics varies drastically for the different distance from
the ceiling which results in a complex nonlinear dynamics; (ii) the system
needs to consider physical and environmental constraints to safely fly in close
proximity. To address these challenges, a novel framework consisting of a
constrained optimization-based force estimation and an optimization-based
nonlinear controller is proposed. Experimental results illustrate that the
performance of the proposed control approach can stabilize UAV down to 1 cm
distance to the ceiling. Furthermore, we report that the UAV consumes up to
12.5% less power when it is operated 1 cm distance to ceiling, which is
promising potential for more battery-efficient inspection flights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00003</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00003</id><created>2019-07-31</created><authors><author><keyname>Miller</keyname><forenames>Matthias</forenames></author><author><keyname>Bonnici</keyname><forenames>Alexandra</forenames></author><author><keyname>El-Assady</keyname><forenames>Mennatallah</forenames></author></authors><title>Augmenting Music Sheets with Harmonic Fingerprints</title><categories>cs.HC cs.SD eess.AS</categories><comments>(9+1) pages; 5 figures; User Study</comments><acm-class>H.5.0; I.7.2; H.1.1</acm-class><doi>10.1145/3342558.3345395</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conventional Music Notation (CMN) is the well-established foundation for the
written communication of musical information, such as rhythm, harmony, or
timbre. However, CMN suffers from the complexity of its visual encoding and the
need for extensive training to acquire proficiency and legibility. While
alternative notations using additional visual variables (such as color to
improve pitch identification) have been proposed, the music community does not
readily accept notation systems that vary widely from the CMN. Therefore, to
support student musicians in understanding the harmonic relationship of notes,
instead of replacing the CMN, we present a visualization technique that
augments a digital music sheet with a harmonic fingerprint glyph. Our design
exploits the circle of fifths - a fundamental concept in music theory, as a
visual metaphor. By attaching these visual glyphs to each bar of a selected
composition we provide additional information about the salient harmonic
features available in a musical piece. We conducted a user study to analyze the
performance of experts and non-experts in an identification and comparison task
of recurring patterns. The evaluation shows that the harmonic fingerprint
supports these tasks without the need for close-reading, as when compared to a
not-annotated music sheet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00031</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00031</id><created>2019-07-31</created><authors><author><keyname>Mamun</keyname><forenames>Nursadul</forenames></author><author><keyname>Ghosh</keyname><forenames>Ria</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Quantifying Cochlear Implant Users' Ability for Speaker Identification
  using CI Auditory Stimuli</title><categories>cs.SD eess.AS</categories><comments>Interspeech 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Speaker recognition is a biometric modality that uses underlying speech
information to determine the identity of the speaker. Speaker Identification
(SID) under noisy conditions is one of the challenging topics in the field of
speech processing, specifically when it comes to individuals with cochlear
implants (CI). This study analyzes and quantifies the ability of CI-users to
perform speaker identification based on direct electric auditory stimuli. CI
users employ a limited number of frequency bands (8 to 22) and use electrodes
to directly stimulate the Basilar Membrane/Cochlear in order to recognize the
speech signal. The sparsity of electric stimulation within the CI frequency
range is a prime reason for loss in human speech recognition, as well as SID
performance. Therefore, it is assumed that CI-users might be unable to
recognize and distinguish a speaker given dependent information such as formant
frequencies, pitch etc. which are lost to un-simulated electrodes. To quantify
this assumption, the input speech signal is processed using a CI Advanced
Combined Encoder (ACE) signal processing strategy to construct the CI auditory
electrodogram. The proposed study uses 50 speakers from each of three different
databases for training the system using two different classifiers under quiet,
and tested under both quiet and noisy conditions. The objective result shows
that, the CI users can effectively identify a limited number of speakers.
However, their performance decreases when more speakers are added in the
system, as well as when noisy conditions are introduced. This information could
therefore be used for improving CI-user signal processing techniques to improve
human SID.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00090</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00090</id><created>2019-07-31</created><authors><author><keyname>Khazraei</keyname><forenames>Amir</forenames></author><author><keyname>Kebriaei</keyname><forenames>Hamed</forenames></author><author><keyname>Salmasi</keyname><forenames>Farzad Rajaei</forenames></author></authors><title>An Optimal Linear Dynamic Detection Method for Replay Attack in
  Cyber-Physical Systems</title><categories>eess.SY cs.SY</categories><comments>8 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The problem of detecting replay attack to the linear stochastic system with
Kalman filer state estimator and LQG controller is addressed. To this end, a
dynamic attack detector method is proposed which is coupled with the dynamics
of the system. While preserving stability of the main system, conditions on
parameters of the attack detector dynamics are obtained such that the attack
can be revealed by destabilization of a residual trajectory which is the
difference between the estimated and measured output of the system. Using this
method, system operator can adjust the detection rate based on the proposed
scheme by changing the design parameters. Nevertheless, since the exogenous
attack detector signal affects the performance of the closed loop control
system, we propose an optimization problem to determine such a detector with
minimum loss effect. In the simulation results, the proposed dynamical attack
detector approach is compared with the well-known additive white noise
watermarking method and the results confirm the superiority of the new scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00130</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00130</id><created>2019-07-31</created><updated>2019-08-01</updated><authors><author><keyname>Dallas</keyname><forenames>James</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Jain</keyname><forenames>Kshitij</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Dong</keyname><forenames>Zheng</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Cole</keyname><forenames>Michael P.</forenames><affiliation>U.S. Army Ground Vehicle Systems Center</affiliation></author><author><keyname>Jayakumar</keyname><forenames>Paramsothy</forenames><affiliation>U.S. Army Ground Vehicle Systems Center</affiliation></author><author><keyname>Ersal</keyname><forenames>Tulga</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Online terrain estimation for autonomous vehicles on deformable terrains</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this work, a terrain estimation framework is developed for autonomous
vehicles operating on deformable terrains. Previous work in this area usually
relies on steady state tire operation, linearized classical terramechanics
models, or on computationally expensive algorithms that are not suitable for
real-time estimation. To address these shortcomings, this work develops a
reduced-order nonlinear terramechanics model as a surrogate of the Soil Contact
Model (SCM) through extending a state-of-the-art Bekker model to account for
additional dynamic effects. It is shown that this reduced-order surrogate model
is able to accurately replicate the forces predicted by the SCM while reducing
the computation cost by an order of magnitude. This surrogate model is then
utilized in a unscented Kalman filter to estimate the sinkage exponent.
Simulations suggest this parameter can be estimated within 4% of its true value
for clay and sandy loam terrains. It is also shown that utilizing this
estimated parameter can reduce the prediction errors of the future vehicle
states by orders of magnitude, which could assist with achieving more robust
model-predictive autonomous navigation strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00142</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00142</id><created>2019-07-31</created><authors><author><keyname>Zarabie</keyname><forenames>Ahmad Khaled</forenames></author><author><keyname>Das</keyname><forenames>Sanjoy</forenames></author></authors><title>An L0-Norm Constrained Non-Negative Matrix Factorization Algorithm for
  the Simultaneous Disaggregation of Fixed and Shiftable Loads</title><categories>eess.SY cs.DS cs.SY</categories><comments>8 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy disaggregation refers to the decomposition of energy use time series
data into its constituent loads. This paper decomposes daily use data of a
household unit into fixed loads and one or more classes of shiftable loads. The
latter is characterized by ON OFF duty cycles. A novel algorithm based on
nonnegative matrix factorization NMF for energy disaggregation is proposed,
where fixed loads are represented in terms of real-valued basis vectors,
whereas shiftable loads are divided into binary signals. This binary
decomposition approach directly applies L0 norm constraints on individual
shiftable loads. The new approach obviates the need for more computationally
intensive methods e.g. spectral decomposition or mean field annealing that have
been used in earlier research for these constraints. A probabilistic framework
for the proposed approach has been addressed. The proposed approach s
effectiveness has been demonstrated with real consumer energy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00144</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00144</id><created>2019-07-31</created><authors><author><keyname>Balevi</keyname><forenames>Eren</forenames></author><author><keyname>Doshi</keyname><forenames>Akash</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Massive MIMO Channel Estimation with an Untrained Deep Neural Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a deep learning-based channel estimation method for
multi-cell interference-limited massive MIMO systems, in which base stations
equipped with a large number of antennas serve multiple single-antenna users.
The proposed estimator employs a specially designed deep neural network (DNN)
to first denoise the received signal, followed by a conventional least-squares
(LS) estimation. We analytically prove that our LS-type deep channel estimator
can approach minimum mean square error (MMSE) estimator performance for
high-dimensional signals, while avoiding MMSE's requirement for complex channel
inversions and knowledge of the channel covariance matrix. This analytical
result, while asymptotic, is observed in simulations to be operational for just
64 antennas and 64 subcarriers per OFDM symbol. The proposed method also does
not require any training and utilizes several orders of magnitude fewer
parameters than conventional DNNs. The proposed deep channel estimator is also
robust to pilot contamination and can even completely eliminate it under
certain conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00160</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00160</id><created>2019-07-31</created><updated>2019-08-02</updated><authors><author><keyname>Naghsh</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Masjedi</keyname><forenames>Maryam</forenames></author><author><keyname>Adibi</keyname><forenames>Arman</forenames></author><author><keyname>Stoica</keyname><forenames>Petre</forenames></author></authors><title>Max-Min Fairness Design for MIMO Interference Channels: a
  Minorization-Maximization Approach</title><categories>eess.SP cs.SI cs.SY eess.SY math.OC stat.AP</categories><doi>10.1109/TSP.2019.2929470</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address the problem of linear precoder (beamformer) design in a
multiple-input multiple-output interference channel (MIMO-IC). The aim is to
design the transmit covariance matrices in order to achieve max-min utility
fairness for all users. The corresponding optimization problem is non-convex
and NP-hard in general. We devise an efficient algorithm based on the
minorization-maximization (MM) technique to obtain quality solutions to this
problem. The proposed method solves a second-order cone convex program (SOCP)
at each iteration. We prove that the devised method converges to stationary
points of the problem. We also extend our algorithm to the case where there are
uncertainties in the noise covariance matrices or channel state information
(CSI). Simulation results show the effectiveness of the proposed method
compared with its main competitor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00166</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00166</id><created>2019-07-31</created><authors><author><keyname>Khatun</keyname><forenames>Mahfuza</forenames></author><author><keyname>Guo</keyname><forenames>Changyu</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author></authors><title>Indoor and Outdoor Penetration Loss Measurements at 73 and 81 GHz</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present millimeter-wave (mmWave) penetration loss
measurements and analysis at E-bands-73 GHz and 81 GHz. Penetration loss was
measured for common building materials such as clear glass, metal, tinted
glass, wood, and drywall on the campus of Boise State University in the city of
Boise. A horn antenna with a gain of 24 dBi was used at the transmitter and
receiver at both bands, and both antennas were boresight-aligned with respect
to the test material. A total of twelve locations were selected to test five
materials. We tested two indoor materials (clear glass and wood) in at least
two locations to determine the effect of penetration loss of materials in
similar compositions. The average penetration loss and standard deviation were
estimated for these indoor materials. We measured an average penetration loss
of 2 to 9 dB for wood and glass, respectively. Furthermore, we measured the
penetration loss of common indoor and outdoor building materials. We studied
that outdoor materials had larger penetration losses, e.g., we obtained a
penetration loss of 22.69 dB for outdoor metal, where this value dropped to
16.04 dB for indoor metal at 73 GHz. Similar results were also obtained for the
81 GHz channel, where the largest penetration loss was measured to be 26.5 dB
through a tinted glass door in an outdoor setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00168</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00168</id><created>2019-07-31</created><updated>2019-08-09</updated><authors><author><keyname>Zhang</keyname><forenames>Runfan</forenames></author><author><keyname>Hredzak</keyname><forenames>Branislav</forenames></author></authors><title>Remote-Strong-Grid-Point-Based Synchronization Strategy with Fault
  Ride-Through Capability for Distributed Energy Resources Connected to Weak
  Grids</title><categories>eess.SY cs.SY</categories><comments>5 pages, and 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel strategy for the current injection based control
for distributed energy resources connected to weak grids through a voltage
source converter experiencing faults. The current injection controller is no
longer synchronized with the point of common coupling at which the measured
voltage signal can be severely affected by faults in the weak grid, but with
the strong grid point at which the voltage is rigid. It is shown that the phase
difference between the voltage source converter and the strong grid voltages
caused by the long power lines does not affect the power control. Furthermore,
a time delay compensation method which tolerates communication time delay
introduced by the transmission of the synchronization signal from the strong
grid point is proposed. The performance of the proposed control strategy is
verified with an RTDS Technologies real-time digital simulator using switching
converter models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00175</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00175</id><created>2019-07-31</created><authors><author><keyname>Bocchieri</keyname><forenames>Alex E.</forenames></author><author><keyname>Parekh</keyname><forenames>Vishwa S.</forenames></author><author><keyname>Ahlawat</keyname><forenames>Kathryn R. Wagner. Shivani</forenames></author><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Leung</keyname><forenames>Doris G.</forenames></author><author><keyname>Jacobs</keyname><forenames>Michael A.</forenames></author></authors><title>Multiparametric Deep Learning Tissue Signatures for Muscular Dystrophy:
  Preliminary Results</title><categories>eess.IV cs.LG physics.med-ph</categories><comments>6 pages, 3 figures. MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/H1g3ICh4cV</report-no><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A current clinical challenge is identifying limb girdle muscular dystrophy
2I(LGMD2I)tissue changes in the thighs, in particular, separating fat,
fat-infiltrated muscle, and muscle tissue. Deep learning algorithms have the
ability to learn different features by using the inherent tissue contrasts from
multiparametric magnetic resonance imaging (mpMRI). To that end, we developed a
novel multiparametric deep learning network (MPDL) tissue signature model based
on mpMRI and applied it to LGMD2I. We demonstrate a new tissue signature model
of muscular dystrophy with the MPDL algorithm segments different tissue types
with excellent results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00177</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00177</id><created>2019-07-31</created><authors><author><keyname>Tram</keyname><forenames>Tommy</forenames></author><author><keyname>Batkovic</keyname><forenames>Ivo</forenames></author><author><keyname>Ali</keyname><forenames>Mohammad</forenames></author><author><keyname>Sj&#xf6;berg</keyname><forenames>Jonas</forenames></author></authors><title>Learning When to Drive in Intersections by Combining Reinforcement
  Learning and Model Predictive Control</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML</categories><comments>6 pages, 5 figures, 1 table, Accepted to IEEE Intelligent Transport
  Systems Conference 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a decision making algorithm intended for automated
vehicles that negotiate with other possibly non-automated vehicles in
intersections. The decision algorithm is separated into two parts: a high-level
decision module based on reinforcement learning, and a low-level planning
module based on model predictive control. Traffic is simulated with numerous
predefined driver behaviors and intentions, and the performance of the proposed
decision algorithm was evaluated against another controller. The results show
that the proposed decision algorithm yields shorter training episodes and an
increased performance in success rate compared to the other controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00186</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00186</id><created>2019-07-31</created><authors><author><keyname>Go</keyname><forenames>Chihiro</forenames></author><author><keyname>Kinoshita</keyname><forenames>Yuma</forenames></author><author><keyname>Shiota</keyname><forenames>Sayaka</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Single-Shot High Dynamic Range Imaging with Spatially Varying Exposures
  Considering Hue Distortion</title><categories>eess.IV cs.CV</categories><comments>To appear in 2019 IEEE 8th Global Conference on Consumer Electronics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposes a novel single-shot high dynamic range imaging scheme with
spatially varying exposures (SVE) considering hue distortion. Single-shot
imaging with SVE enables us to capture multi-exposure images from a single-shot
image, so high dynamic range images can be produced without ghost artifacts.
However, SVE images have some pixels at which a range supported by camera
sensors is exceeded. Therefore, generated images have some color distortion, so
that conventional imaging with SVE has never considered the influence of this
range limitation. To overcome this issue, we consider estimating the correct
hue of a scene from raw images, and propose a method with the estimated hue
information for correcting the hue of SVE images on the constant hue plain in
the RGB color space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00195</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00195</id><created>2019-07-31</created><authors><author><keyname>Nooraiepour</keyname><forenames>Alireza</forenames></author><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan B.</forenames></author></authors><title>Learning-Aided Physical Layer Attacks Against Multicarrier
  Communications in IoT</title><categories>cs.LG cs.CR eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet-of-Things (IoT) devices that are limited in power and processing
capabilities are susceptible to physical layer (PHY) spoofing attacks owing to
their inability to implement a full-blown protocol stack for security. The
overwhelming adoption of multicarrier communications for the PHY layer makes
IoT devices further vulnerable to PHY spoofing attacks. These attacks which aim
at injecting bogus data into the receiver, involve inferring transmission
parameters and finding PHY characteristics of the transmitted signals so as to
spoof the received signal. Non-contiguous orthogonal frequency division
multiplexing (NC-OFDM) systems have been argued to have low probability of
exploitation (LPE) characteristics against classic attacks based on
cyclostationary analysis. However, with the advent of machine learning (ML)
algorithms, adversaries can devise data-driven attacks to compromise such
systems. It is in this vein that PHY spoofing performance of adversaries
equipped with supervised and unsupervised ML tools are investigated in this
paper. The supervised ML approach is based on estimation/classification
utilizing deep neural networks (DNN) while the unsupervised one employs
variational autoencoders (VAEs). In particular, VAEs are shown to be capable of
learning representations from NC-OFDM signals related to their PHY
characteristics such as frequency pattern and modulation scheme, which are
useful for PHY spoofing. In addition, a new metric based on the disentanglement
principle is proposed to measure the quality of such learned representations.
Simulation results demonstrate that the performance of the spoofing adversaries
highly depends on the subcarriers' allocation patterns used at the transmitter.
Particularly, it is shown that utilizing a random subcarrier occupancy pattern
precludes the adversary from spoofing and secures NC-OFDM systems against
ML-based attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00206</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00206</id><created>2019-08-01</created><authors><author><keyname>Liu</keyname><forenames>Juan</forenames></author><author><keyname>Koch</keyname><forenames>Kevin M.</forenames></author></authors><title>Meta-QSM: An Image-Resolution-Arbitrary Network for QSM Reconstruction</title><categories>physics.med-ph eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Quantitative Susceptibility Mapping (QSM) can estimate the underlying tissue
magnetic susceptibility and reveal pathology. Current deep-learning-based
approaches to solve the QSM inverse problem are restricted on fixed image
resolution. They trained a specific model for each image resolution which is
inefficient in computing. In this work, we proposed a novel method called
Meta-QSM to firstly solve QSM reconstruction of arbitrary image resolution with
a single model. In Meta-QSM, weight prediction was used to predict the weights
of kernels by taking the image resolution as input. The proposed method was
evaluated on synthetic data and clinical data with comparison to existing QSM
reconstruction methods. The experimental results showed the Meta-QSM can
effectively reconstruct susceptibility maps with different image resolution
using one neural network training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00248</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00248</id><created>2019-08-01</created><authors><author><keyname>Xin</keyname><forenames>Qu</forenames></author><author><keyname>Kang</keyname><forenames>Chung G.</forenames></author></authors><title>Achievable Degrees of Freedom for Closed-form Solution to Interference
  Alignment and Cancellation in Gaussian Interference Multiple Access Channel</title><categories>eess.SP cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A combined technique of interference alignment (IA) and interference
cancellation (IC), known as interference alignment and cancellation (IAC)
scheme, has been proposed to improve the total achievable degrees of freedom
(DoFs) over IA. Since it is NP-hard to solve the transceiver under a given
tuple of DoFs or to maximize the total achievable DoFs in the general system
configuration by IA (or IAC), the optimal transceiver cannot be obtained in
polynomial time. Meanwhile, it has been known that a closed-form yet suboptimal
transceiver can be designed for IAC by employing a symbol-to-symbol (STS)
alignment structure. As its performance has not been known yet, we aim to
derive the total DoFs that can be achieved by such suboptimal but closed-form
IAC transceivers for Gaussian interference multiple access channels with K
receivers and J users (transmitters), each with M antennas. Our analysis shows
that the closed-form IAC transceivers under consideration can achieve a maximum
total achievable DoFs of 2M, which turns out to be larger than those achieved
in classical IA, e.g., 2MK/(K+1) DoFs by a specific configuration where each
link has the same target DoFs. Moreover, considering the NP-hardness of
deriving the maximum total achievable DoFs with the optimal IAC transceiver,
its upper bound has been derived for comparison with the results of our
closed-form IAC transceiver. Numerical results illustrate that its performance
can be guaranteed within 20% of the upper bound when the number of multiple
access channels are relatively small, e.g., K &lt;=4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00260</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00260</id><created>2019-08-01</created><authors><author><keyname>Ghodrat</keyname><forenames>Mohsen</forenames></author><author><keyname>Marquez</keyname><forenames>Horacio J.</forenames></author></authors><title>Event-Triggered Design with Guaranteed Minimum Inter-Event Times and Lp
  Performance</title><categories>eess.SY cs.SY</categories><comments>20 pages, 2 figures</comments><doi>10.1109/TAC.2019.2930223</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an event-based scenario, the system decides when to update the actuators
based on a real time triggering condition on the measured signals. This
condition can be defined in various forms and varies depending on the system
properties and design problem. This paper proposes a framework to design the
triggering condition while keeping Lp performance within desired limits. Our
general framework captures several existing state-based triggering rules as a
special case, and can achieve the performance objectives while reducing
transmissions. Indeed, this general structure is shown to enlarge the minimum
inter-event time by a specified amount, for a desired period of time. Numerical
examples suggest that the proposed mechanism effectively enlarges the average
sampling time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00273</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00273</id><created>2019-08-01</created><updated>2019-10-21</updated><authors><author><keyname>Zhao</keyname><forenames>Yiyun</forenames></author><author><keyname>Jiang</keyname><forenames>Zhuqing</forenames></author><author><keyname>Men</keyname><forenames>Aidong</forenames></author><author><keyname>Ju</keyname><forenames>Guodong</forenames></author></authors><title>Pyramid Real Image Denoising Network</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While deep Convolutional Neural Networks (CNNs) have shown extraordinary
capability of modelling specific noise and denoising, they still perform poorly
on real-world noisy images. The main reason is that the real-world noise is
more sophisticated and diverse. To tackle the issue of blind denoising, in this
paper, we propose a novel pyramid real image denoising network (PRIDNet), which
contains three stages. First, the noise estimation stage uses channel attention
mechanism to recalibrate the channel importance of input noise. Second, at the
multi-scale denoising stage, pyramid pooling is utilized to extract multi-scale
features. Third, the stage of feature fusion adopts a kernel selecting
operation to adaptively fuse multi-scale features. Experiments on two datasets
of real noisy photographs demonstrate that our approach can achieve competitive
performance in comparison with state-of-the-art denoisers in terms of both
quantitative measure and visual perception quality. Code is available at
https://github.com/491506870/PRIDNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00274</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00274</id><created>2019-08-01</created><authors><author><keyname>Sarfraz</keyname><forenames>M. Saquib</forenames></author><author><keyname>Seibold</keyname><forenames>Constantin</forenames></author><author><keyname>Khalid</keyname><forenames>Haroon</forenames></author><author><keyname>Stiefelhagen</keyname><forenames>Rainer</forenames></author></authors><title>Content and Colour Distillation for Learning Image Translations with the
  Spatial Profile Loss</title><categories>cs.CV cs.LG eess.IV</categories><comments>BMVC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks has emerged as a defacto standard for image
translation problems. To successfully drive such models, one has to rely on
additional networks e.g., discriminators and/or perceptual networks. Training
these networks with pixel based losses alone are generally not sufficient to
learn the target distribution. In this paper, we propose a novel method of
computing the loss directly between the source and target images that enable
proper distillation of shape/content and colour/style. We show that this is
useful in typical image-to-image translations allowing us to successfully drive
the generator without relying on additional networks. We demonstrate this on
many difficult image translation problems such as image-to-image domain
mapping, single image super-resolution and photo realistic makeup transfer. Our
extensive evaluation shows the effectiveness of the proposed formulation and
its ability to synthesize realistic images. [Code release:
https://github.com/ssarfraz/SPL]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00295</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00295</id><created>2019-08-01</created><authors><author><keyname>van der Ouderaa</keyname><forenames>Tycho F. A.</forenames></author><author><keyname>Worrall</keyname><forenames>Daniel E.</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author></authors><title>Chest CT Super-resolution and Domain-adaptation using Memory-efficient
  3D Reversible GANs</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SkxueFsiFV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Recently, paired (e.g. Pix2pix) and unpaired (e.g. CycleGAN) image-to-image
translation methods have shown effective in medical imaging tasks. In practice,
however, it can be difficult to apply these deep models on medical data
volumes, such as from MR and CT scans, since such data volumes tend to be
3-dimensional and of a high spatial resolution pushing the limits of the memory
constraints of GPU hardware that is typically used to train these models.
Recent studies in the field of invertible neural networks have shown that
reversible neural networks do not require to store intermediate activations for
training. We use the RevGAN model that makes use of this property to perform
memory-efficient partially-reversible image-to-image translation. We
demonstrate this by performing a 3D super-resolution and a 3D domain-adaptation
task on chest CT data volumes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00298</identifier>
 <datestamp>2019-12-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00298</id><created>2019-08-01</created><updated>2019-12-19</updated><authors><author><keyname>Huang</keyname><forenames>Yunyou</forenames></author><author><keyname>Wang</keyname><forenames>Nana</forenames></author><author><keyname>Gao</keyname><forenames>Wanling</forenames></author><author><keyname>Guo</keyname><forenames>Xiaoxu</forenames></author><author><keyname>Huang</keyname><forenames>Cheng</forenames></author><author><keyname>Hao</keyname><forenames>Tianshu</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author></authors><title>LoadCNN: A Low Training Cost Deep Learning Model for Day-Ahead
  Individual Residential Load Forecasting</title><categories>eess.SP cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate day-ahead individual residential load forecasting is of great
importance to various applications of smart grid on day-ahead market. Deep
learning, as a powerful machine learning technology, has shown great advantages
and promising application in load forecasting tasks. However, deep learning is
a computationally-hungry method, and requires high costs (e.g., time, energy
and CO2 emission) to train a deep learning model, which aggravates the energy
crisis and incurs a substantial burden to the environment. As a consequence,
the deep learning methods are difficult to be popularized and applied in the
real smart grid environment. In this paper, we propose a low training cost
model based on convolutional neural network, namely LoadCNN, for next-day load
forecasting of individual resident with reduced training cost. The experiments
show that the training time of LoadCNN is only approximately 1/54 of the one of
other state-of-the-art models, and energy consumption and CO2 emissions are
only approximate 1/45 of those of other state-of-the-art models based on the
same indicators. Meanwhile, the prediction accuracy of our model is equal to
that of current state-of-the-art models, making LoadCNN the first load
forecasting model simultaneously achieving high prediction accuracy and low
training costs. LoadCNN is an efficient green model that is able to be quickly,
cost-effectively and environmentally-friendly deployed in a realistic smart
grid environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00375</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00375</id><created>2019-08-01</created><updated>2019-10-05</updated><authors><author><keyname>Li</keyname><forenames>Dingquan</forenames></author><author><keyname>Jiang</keyname><forenames>Tingting</forenames></author><author><keyname>Jiang</keyname><forenames>Ming</forenames></author></authors><title>Quality Assessment of In-the-Wild Videos</title><categories>cs.MM cs.CV eess.IV</categories><comments>9 pages, 7 figures, 4 tables. ACM Multimedia 2019 camera ready. -&gt;
  Update alignment formatting of Table 1</comments><doi>10.1145/3343031.3351028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality assessment of in-the-wild videos is a challenging problem because of
the absence of reference videos and shooting distortions. Knowledge of the
human visual system can help establish methods for objective quality assessment
of in-the-wild videos. In this work, we show two eminent effects of the human
visual system, namely, content-dependency and temporal-memory effects, could be
used for this purpose. We propose an objective no-reference video quality
assessment method by integrating both effects into a deep neural network. For
content-dependency, we extract features from a pre-trained image classification
neural network for its inherent content-aware property. For temporal-memory
effects, long-term dependencies, especially the temporal hysteresis, are
integrated into the network with a gated recurrent unit and a
subjectively-inspired temporal pooling layer. To validate the performance of
our method, experiments are conducted on three publicly available in-the-wild
video quality assessment databases: KoNViD-1k, CVD2014, and LIVE-Qualcomm,
respectively. Experimental results demonstrate that our proposed method
outperforms five state-of-the-art methods by a large margin, specifically,
12.39%, 15.71%, 15.45%, and 18.09% overall performance improvements over the
second-best method VBLIINDS, in terms of SROCC, KROCC, PLCC and RMSE,
respectively. Moreover, the ablation study verifies the crucial role of both
the content-aware features and the modeling of temporal-memory effects. The
PyTorch implementation of our method is released at
https://github.com/lidq92/VSFA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00380</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00380</id><created>2019-08-01</created><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>You</keyname><forenames>Keyou</forenames></author><author><keyname>Song</keyname><forenames>Shiji</forenames></author><author><keyname>Xue</keyname><forenames>Anke</forenames></author></authors><title>Optimization-based Control for Bearing-only Target Search with a Mobile
  Vehicle</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work aims to design an optimization-based controller for a discrete-time
Dubins vehicle to approach a target with unknown position as fast as possible
by only using bearing measurements. To this end, we propose a bi-objective
optimization problem, which jointly considers the performance of estimating the
unknown target position and controlling the mobile vehicle to a known position,
and then adopt a weighted sum method with normalization to solve it. The
controller is given based on the solution of the optimization problem in ties
with a least-square estimate of the target position. Moreover, the controller
does not need the vehicle's global position information. Finally, simulation
results are included to validate the effectiveness of the proposed controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00399</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00399</id><created>2019-08-01</created><updated>2020-02-14</updated><authors><author><keyname>Fern&#xe1;ndez-Blanco</keyname><forenames>Ricardo</forenames></author><author><keyname>Morales</keyname><forenames>Juan Miguel</forenames></author><author><keyname>Pineda</keyname><forenames>Salvador</forenames></author><author><keyname>Porras</keyname><forenames>&#xc1;lvaro</forenames></author></authors><title>Kernel-Based Inverse Optimization: Application to the Power Forecasting
  and Bidding of a Fleet of Electric Vehicles</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers an aggregator of Electric Vehicles (EVs) who aims to
learn the aggregate power of his/her fleet while also participating in the
electricity market. The proposed approach is based on a data-driven inverse
optimization (IO) method, which is highly nonlinear. To overcome such a caveat,
we use a two-step estimation procedure which requires solving two convex
programs. Both programs depend on penalty parameters that can be adjusted by
using grid search. In addition, we propose the use of kernel regression to
account for the nonlinear relationship between the behaviour of the pool of EVs
and the explanatory variables, i.e., the past electricity prices and EV fleet's
driving patterns. Unlike any other forecasting method, the proposed IO
framework also allows the aggregator to derive a bid/offer curve, i.e. the
tuple of price-quantity to be submitted to the electricity market, according to
the market rules. We show the benefits of the proposed method against the
machine-learning techniques that are reported to exhibit the best forecasting
performance for this application in the technical literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00404</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00404</id><created>2019-08-01</created><authors><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author></authors><title>Complex-BP-Neural-Network-based Hybrid Precoding for Millimeter Wave
  Multiuser Massive MIMO Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high energy consumption of massive multi-input multi-out (MIMO) system
has become a prominent problem in the millimeter wave(mm-Wave) communication
scenario. The hybrid precoding technology greatly reduces the number of radio
frequency(RF) chains by handing over part of the coding work to the phase
shifting network, which can effectively improve energy efficiency. However,
conventional hybrid precoding algorithms based on mathematical means often
suffer from performance loss and high computational complexity. In this paper,
a novel BP-neural-network-enabled hybrid precoding algorithm is proposed, in
which the full-digital zero-forcing(ZF) precoding is set as the training
target. Considering that signals at the base station are complex, we choose the
complex neural network that has a richer representational capacity. Besides, we
present the activation function of the complex neural network and the gradient
derivation of the back propagation process. Simulation results demonstrate that
the performance of the proposed hybrid precoding algorithm can optimally
approximate the ZF precoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00407</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00407</id><created>2019-08-01</created><updated>2019-10-16</updated><authors><author><keyname>He</keyname><forenames>Wenbin</forenames></author><author><keyname>Wang</keyname><forenames>Junpeng</forenames></author><author><keyname>Guo</keyname><forenames>Hanqi</forenames></author><author><keyname>Wang</keyname><forenames>Ko-Chih</forenames></author><author><keyname>Shen</keyname><forenames>Han-Wei</forenames></author><author><keyname>Raj</keyname><forenames>Mukund</forenames></author><author><keyname>Nashed</keyname><forenames>Youssef S. G.</forenames></author><author><keyname>Peterka</keyname><forenames>Tom</forenames></author></authors><title>InSituNet: Deep Image Synthesis for Parameter Space Exploration of
  Ensemble Simulations</title><categories>eess.IV cs.CV cs.GR</categories><doi>10.1109/TVCG.2019.2934312</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose InSituNet, a deep learning based surrogate model to support
parameter space exploration for ensemble simulations that are visualized in
situ. In situ visualization, generating visualizations at simulation time, is
becoming prevalent in handling large-scale simulations because of the I/O and
storage constraints. However, in situ visualization approaches limit the
flexibility of post-hoc exploration because the raw simulation data are no
longer available. Although multiple image-based approaches have been proposed
to mitigate this limitation, those approaches lack the ability to explore the
simulation parameters. Our approach allows flexible exploration of parameter
space for large-scale ensemble simulations by taking advantage of the recent
advances in deep learning. Specifically, we design InSituNet as a convolutional
regression model to learn the mapping from the simulation and visualization
parameters to the visualization results. With the trained model, users can
generate new images for different simulation parameters under various
visualization settings, which enables in-depth analysis of the underlying
ensemble simulations. We demonstrate the effectiveness of InSituNet in
combustion, cosmology, and ocean simulations through quantitative and
qualitative evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00410</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00410</id><created>2019-07-31</created><authors><author><keyname>Xie</keyname><forenames>Ruitao</forenames></author><author><keyname>Liu</keyname><forenames>Libo</forenames></author><author><keyname>Liu</keyname><forenames>Jingxin</forenames></author><author><keyname>Qiu</keyname><forenames>Connor S</forenames></author></authors><title>Pathological Myopic Image Analysis with Transfer Learning</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/BkeLp6mTFE</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present a summary of transfer learning based methods for several
challenging myopic fundus image analysis tasks including classification of
pathological and non-pathological myopia,localisation of fovea,and segmentation
of optic disc.By adapting existing popular deep learning architectures,our
proposed methods have achieved 1st and 2nd place in several tasks at the
Pathologic Myopia Challenge held at ISBI2019.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00433</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00433</id><created>2019-08-01</created><authors><author><keyname>Malygina</keyname><forenames>Tatiana</forenames></author><author><keyname>Ericheva</keyname><forenames>Elena</forenames></author><author><keyname>Drokin</keyname><forenames>Ivan</forenames></author></authors><title>GANs 'N Lungs: improving pneumonia prediction</title><categories>eess.IV cs.CV</categories><comments>Accepted as an extended abstract for MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/rkexLAH0FE</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We propose a novel method to improve deep learning model performance on
highly-imbalanced tasks. The proposed method is based on CycleGAN to achieve
balanced dataset. We show that data augmentation with GAN helps to improve
accuracy of pneumonia binary classification task even if the generative network
was trained on the same training dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00452</identifier>
 <datestamp>2019-11-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00452</id><created>2019-08-01</created><updated>2019-11-14</updated><authors><author><keyname>Ribeiro</keyname><forenames>Alexandre M.</forenames></author><author><keyname>Moutinho</keyname><forenames>Alexandra</forenames></author><author><keyname>Fioravanti</keyname><forenames>Andr&#xe9; R.</forenames></author><author><keyname>de Paiva</keyname><forenames>Ely C.</forenames></author></authors><title>Estimation of Tire-Road Friction for Road Vehicles: a Time Delay Neural
  Network Approach</title><categories>cs.NE cs.SY eess.SY</categories><comments>13 pages, 15 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The performance of vehicle active safety systems is dependent on the friction
force arising from the contact of tires and the road surface. Therefore, an
adequate knowledge of the tire-road friction coefficient is of great importance
to achieve a good performance of different vehicle control systems. This paper
deals with the tire-road friction coefficient estimation problem through the
knowledge of lateral tire force. A time delay neural network (TDNN) is adopted
for the proposed estimation design. The TDNN aims at detecting road friction
coefficient under lateral force excitations avoiding the use of standard
mathematical tire models, which may provide a more efficient method with robust
results. Moreover, the approach is able to estimate the road friction at each
wheel independently, instead of using lumped axle models simplifications.
Simulations based on a realistic vehicle model are carried out on different
road surfaces and driving maneuvers to verify the effectiveness of the proposed
estimation method. The results are compared with a classical approach, a
model-based method modeled as a nonlinear regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00453</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00453</id><created>2019-08-01</created><updated>2019-08-19</updated><authors><author><keyname>Goossens</keyname><forenames>Sebastiaan</forenames></author><author><keyname>van der Heide</keyname><forenames>Sjoerd</forenames></author><author><keyname>Hout</keyname><forenames>Menno van den</forenames></author><author><keyname>Amari</keyname><forenames>Abdelkerim</forenames></author><author><keyname>G&#xfc;ltekin</keyname><forenames>Yunus Can</forenames></author><author><keyname>Vassilieva</keyname><forenames>Olga</forenames></author><author><keyname>Kim</keyname><forenames>Inwoong</forenames></author><author><keyname>Ikeuchi</keyname><forenames>Tadashi</forenames></author><author><keyname>Willems</keyname><forenames>Frans M. J.</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author></authors><title>First Experimental Demonstration of Probabilistic Enumerative Sphere
  Shaping in Optical Fiber Communications</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We transmit probabilistic enumerative sphere shaped dual-polarization 64-QAM
at 350Gbit/s/channel over 1610km SSMF using a short blocklength of 200. A reach
increase of 15% over constant composition distribution matching with identical
blocklength is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00460</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00460</id><created>2019-08-01</created><authors><author><keyname>Cao</keyname><forenames>Zhiwei</forenames></author><author><keyname>Zhu</keyname><forenames>Hongfei</forenames></author><author><keyname>Zhao</keyname><forenames>Yuping</forenames></author><author><keyname>Li</keyname><forenames>Dou</forenames></author></authors><title>Learning to Denoise and Decode: A Novel Residual Neural Network Decoder
  for Polar Codes</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes have been adopted as the control channel coding scheme in the
fifth generation new radio (5G NR) standard due to its capacity-achievable
property. Traditional polar decoding algorithms such as successive cancellation
(SC) suffer from high latency problem because of their sequential decoding
nature. Neural network decoder (NND) has been proved to be a candidate for
polar decoder since it is capable of oneshot decoding and parallel computing.
Whereas, the bit-errorrate (BER) performance of NND is still inferior to that
of SC algorithm. In this paper, we propose a residual neural network decoder
(RNND) for polar codes. Different from previous works which directly use neural
network for decoding symbols received from the channel, the proposed RNND
introduces a denoising module based on residual learning before NND. The
proposed residual learning denoiser is able to remove remarkable amount of
noise from received signals. Numerical results show that our proposed RNND
outperforms traditional NND with regard to the BER performance under comparable
latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00481</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00481</id><created>2019-08-01</created><authors><author><keyname>Fern&#xe1;ndez-Blanco</keyname><forenames>Ricardo</forenames></author><author><keyname>Morales</keyname><forenames>Juan Miguel</forenames></author><author><keyname>Pineda</keyname><forenames>Salvador</forenames></author></authors><title>How Can Smart Buildings Be Price-Responsive?</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prospective participation of smart buildings in the electricity system is
strongly related to the increasing active role of demand-side resources in the
electrical grid. In addition, the growing penetration of smart meters and
recent advances on home automation technologies will spur the development of
new mathematical tools to help optimize the local resources of these buildings.
Within this context, this paper first provides a comprehensive model to
determine the electrical consumption of a single-zone household based on
economic model predictive control. The goal of this problem is to minimize the
electricity consumption cost while accounting for the heating dynamics of the
building, smart home appliances, and comfort constraints. This paper then
identifies and analyzes the key parameters responsible for the price-responsive
behaviour of smart households.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00482</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00482</id><created>2019-08-01</created><authors><author><keyname>Shen</keyname><forenames>Haojing</forenames></author><author><keyname>Lee</keyname><forenames>Haksu</forenames></author><author><keyname>Seo</keyname><forenames>Dong-Jun</forenames></author></authors><title>Adaptive Conditional Bias-Penalized Kalman Filter for Improved
  Estimation of Extremes and its Approximation for Reduced Computation</title><categories>eess.SP</categories><comments>9 pages, 5 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many signal processing applications of Kalman filter (KF) and its variants
and extensions, accurate estimation of extreme states is often of great
importance. When the observations used are uncertain, however, KF suffers from
conditional bias (CB) which results in consistent under- and overestimation of
extremes in the right and left tails, respectively. Recently, CB-penalized KF,
or CBPKF, has been developed to address CB. In this paper, we present an
alternative formulation based on variance-inflated KF to reduce computation and
algorithmic complexity, and describe adaptive implementation to improve
unconditional performance. For theoretical basis and context, we also provide a
complete self-contained description of CB-penalized Fisher-like estimation and
CBPKF. The results from 1-dimensional synthetic experiments for a linear system
with varying degrees of nonstationarity show that adaptive CBPKF reduces root
mean square error at the extreme tail ends by 20 to 30% over KF while
performing comparably to KF in the unconditional sense. The alternative
formulation is found to approximate the original formulation very closely while
reducing computing time to 1.5 to 3.5 times of that for KF depending on the
dimensionality of the problem. Adaptive CBPKF hence offers a significant
addition to the dynamic filtering methods for general application in signal
processing when accurate estimation of extremes is of importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00492</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00492</id><created>2019-08-01</created><authors><author><keyname>Boonyakitanont</keyname><forenames>Poomipat</forenames></author><author><keyname>Lek-uthai</keyname><forenames>Apiwat</forenames></author><author><keyname>Chomtho</keyname><forenames>Krisnachai</forenames></author><author><keyname>Songsiri</keyname><forenames>Jitkomut</forenames></author></authors><title>A review of feature extraction and performance evaluation in epileptic
  seizure detection using EEG</title><categories>eess.SP</categories><comments>28 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the manual detection of electrographic seizures in continuous
electroencephalogram (EEG) monitoring is very time-consuming and requires a
trained expert, attempts to develop automatic seizure detection are diverse and
ongoing. Machine learning approaches are intensely being applied to this
problem due to their ability to classify seizure conditions from a large amount
of data, and provide pre-screened results for neurologists. Several features,
data transformations, and classifiers have been explored to analyze and
classify seizures via EEG signals. In the literature, some jointly-applied
features used in the classification may have shared similar contributions,
making them redundant in the learning process. Therefore, this paper aims to
comprehensively summarize feature descriptions and their interpretations in
characterizing epileptic seizures using EEG signals, as well as to review
classification performance metrics. To provide meaningful information of
feature selection, we conducted an experiment to examine the quality of each
feature independently. The Bayesian error and non-parametric probability
distribution estimation were employed to determine the significance of the
individual features. Moreover, a redundancy analysis using a correlation-based
feature selection was applied. The results showed that the following features
--variance, energy, nonlinear energy, and Shannon entropy computed on a raw EEG
signal, as well as variance, energy, kurtosis, and line length calculated on
wavelet coefficients-- were able to significantly capture the seizures. An
improvement of 4.77--13.51% in the Bayesian error from the baseline was
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00493</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00493</id><created>2019-08-01</created><authors><author><keyname>El-Geish</keyname><forenames>Mohamed</forenames></author></authors><title>Learning Joint Acoustic-Phonetic Word Embeddings</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most speech recognition tasks pertain to mapping words across two modalities:
acoustic and orthographic. In this work, we suggest learning encoders that map
variable-length, acoustic or phonetic, sequences that represent words into
fixed-dimensional vectors in a shared latent space; such that the distance
between two word vectors represents how closely the two words sound. Instead of
directly learning the distances between word vectors, we employ weak
supervision and model a binary classification task to predict whether two
inputs, one of each modality, represent the same word given a distance
threshold. We explore various deep-learning models, bimodal contrastive losses,
and techniques for mining hard negative examples such as the semi-supervised
technique of self-labeling. Our best model achieves an $F_1$ score of 0.95 for
the binary classification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00508</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00508</id><created>2019-08-01</created><authors><author><keyname>Kim</keyname><forenames>In-soo</forenames></author><author><keyname>Choi</keyname><forenames>Junil</forenames></author></authors><title>Gradient Pursuit-Based Channel Estimation for MmWave Massive MIMO
  Systems with One-Bit ADCs</title><categories>eess.SP cs.IT math.IT</categories><comments>to appear in PIMRC 2019, Istanbul, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, channel estimation for millimeter wave (mmWave) massive
multiple-input multiple-output (MIMO) systems with one-bit analog-to-digital
converters (ADCs) is considered. In the mmWave band, the number of propagation
paths is small, which results in sparse virtual channels. To estimate sparse
virtual channels based on the maximum a posteriori (MAP) criterion,
sparsity-constrained optimization comes into play. In general, optimizing
objective functions with sparsity constraints is NP-hard because of their
combinatorial complexity. Furthermore, the coarse quantization of one-bit ADCs
makes channel estimation a challenging task. In the field of compressed sensing
(CS), the gradient support pursuit (GraSP) and gradient hard thresholding
pursuit (GraHTP) algorithms were proposed to approximately solve
sparsity-constrained optimization problems iteratively by pursuing the gradient
of the objective function via hard thresholding. The accuracy guarantee of
these algorithms, however, breaks down when the objective function is
ill-conditioned, which frequently occurs in the mmWave band. To prevent the
breakdown of gradient pursuit-based algorithms, the band maximum selecting
(BMS) technique, which is a hard thresholder selecting only the &quot;band maxima,&quot;
is applied to GraSP and GraHTP to propose the BMSGraSP and BMSGraHTP algorithms
in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00510</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00510</id><created>2019-08-01</created><authors><author><keyname>Pradhan</keyname><forenames>Hrusikesha</forenames></author><author><keyname>Bedi</keyname><forenames>Amrit Singh</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Rajawat</keyname><forenames>Ketan</forenames></author></authors><title>Adaptive Kernel Learning in Heterogeneous Networks</title><categories>math.OC eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the framework of learning over decentralized networks, where
nodes observe unique, possibly correlated, observation streams. We focus on the
case where agents learn a regression \emph{function} that belongs to a
reproducing kernel Hilbert space (RKHS). In this setting, a decentralized
network aims to learn nonlinear statistical models that are optimal in terms of
a global stochastic convex functional that aggregates data across the network,
with only access to a local data stream. We incentivize coordination while
respecting network heterogeneity through the introduction of nonlinear
proximity constraints. To solve it, we propose applying a functional variant of
stochastic primal-dual (Arrow-Hurwicz) method which yields a decentralized
algorithm. To handle the fact that the RKHS parameterization has complexity
proportionate with the iteration index, we project the primal iterates onto
Hilbert subspaces that are greedily constructed from the observation sequence
of each node. The resulting proximal stochastic variant of Arrow-Hurwicz,
dubbed Heterogeneous Adaptive Learning with Kernels (HALK), is shown to
converge in expectation, both in terms of primal sub-optimality and constraint
violation to a neighborhood that depends on a given constant step-size
selection. Simulations on a correlated spatio-temporal random field estimation
problem validate our theoretical results, which are born out in practice for
networked oceanic sensing buoys estimating temperature and salinity from depth
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00512</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00512</id><created>2019-08-01</created><updated>2019-08-02</updated><authors><author><keyname>Du</keyname><forenames>Jinfeng</forenames></author><author><keyname>Chizhik</keyname><forenames>Dmitry</forenames></author><author><keyname>Valenzuela</keyname><forenames>Reinaldo A.</forenames></author><author><keyname>Feick</keyname><forenames>Rodolfo</forenames></author><author><keyname>Castro</keyname><forenames>Guillermo</forenames></author><author><keyname>Rodriguez</keyname><forenames>Mauricio</forenames></author><author><keyname>Chen</keyname><forenames>Tingjun</forenames></author><author><keyname>Kohli</keyname><forenames>Manav</forenames></author><author><keyname>Zussman</keyname><forenames>Gil</forenames></author></authors><title>Directional Measurements in Urban Street Canyons from Macro Rooftop
  Sites at 28 GHz for 90% Outdoor Coverage</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Path gain and effective directional gain in urban canyons from actual rooftop
base station sites are characterized based on a massive data set of 3000 links
on 12 streets in two cities, with over 21 million individual measurements.
Large street-to-street path gain variation is found, with median street path
gain varying over 35 dB at similar distances. Coverage in the street directly
illuminated by a roof edge antenna is found to suffer an average excess loss of
11 dB relative to free space at 200 m, with empirical slope-intercept fit model
representing the data with 7.1 dB standard deviation. Offsetting the base
antenna 5 m away from roof edge, as is common in macro cellular deployments,
introduces an additional average loss of 15 dB at 100 m, but this additional
loss reduces with distance. Around the corner loss is well modeled by a
diffraction formula with an empirically obtained diffraction coefficient.
Effective azimuthal gain degradation due to scatter is limited to 2 dB for 90%
of data, supporting effective use of high gain antennas in urban street
canyons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00528</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00528</id><created>2019-08-01</created><authors><author><keyname>Phan</keyname><forenames>Dung</forenames></author><author><keyname>Paoletti</keyname><forenames>Nicola</forenames></author><author><keyname>Grosu</keyname><forenames>Radu</forenames></author><author><keyname>Jansen</keyname><forenames>Nils</forenames></author><author><keyname>Smolka</keyname><forenames>Scott A.</forenames></author><author><keyname>Stoller</keyname><forenames>Scott D.</forenames></author></authors><title>Neural Simplex Architecture</title><categories>cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the Neural Simplex Architecture (NSA), a new approach to runtime
assurance that provides safety guarantees for neural controllers (obtained e.g.
using reinforcement learning) of complex autonomous and other cyber-physical
systems without unduly sacrificing performance. NSA is inspired by the Simplex
control architecture of Sha et al., but with some significant differences. In
the traditional Simplex approach, the advanced controller (AC) is treated as a
black box; there are no techniques for correcting the AC after it generates a
potentially unsafe control input that causes a failover to the BC. Our NSA
addresses this limitation. NSA not only provides safety assurances for CPSs in
the presence of a possibly faulty neural controller, but can also improve the
safety of such a controller in an online setting via retraining, without
degrading its performance. NSA also offers reverse switching strategies, which
allow the AC to resume control of the system under reasonable conditions,
allowing the mission to continue unabated. Our experimental results on several
significant case studies, including a target-seeking ground rover navigating an
obstacle field and a neural controller for an artificial pancreas system,
demonstrate NSA's benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00532</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00532</id><created>2019-08-01</created><authors><author><keyname>Kim</keyname><forenames>In-soo</forenames></author><author><keyname>Choi</keyname><forenames>Junil</forenames></author></authors><title>FCFGS-CV-Based Channel Estimation for Wideband MmWave Massive MIMO
  Systems with Low-Resolution ADCs</title><categories>eess.SP cs.IT math.IT</categories><comments>to appear in IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the fully corrective forward greedy selection-cross
validation-based (FCFGS-CV-based) channel estimator is proposed for wideband
millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems
with low-resolution analog-to-digital converters (ADCs). The sparse nature of
the mmWave virtual channel in the angular and delay domains is exploited to
convert the maximum a posteriori (MAP) channel estimation problem to an
optimization problem with a concave objective function and sparsity constraint.
The FCFGS algorithm, which is the generalized orthogonal matching pursuit (OMP)
algorithm, is used to solve the sparsity-constrained optimization problem.
Furthermore, the CV technique is adopted to determine the proper termination
condition by detecting overfitting when the sparsity level is unknown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00533</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00533</id><created>2019-08-01</created><updated>2019-08-06</updated><authors><author><keyname>Caluya</keyname><forenames>Kenneth F.</forenames></author><author><keyname>Halder</keyname><forenames>Abhishek</forenames></author></authors><title>Gradient Flow Algorithms for Density Propagation in Stochastic Systems</title><categories>math.OC cs.LG cs.SY eess.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1809.10844</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new computational framework to solve the partial differential
equations (PDEs) governing the flow of the joint probability density functions
(PDFs) in continuous-time stochastic nonlinear systems. The need for computing
the transient joint PDFs subject to prior dynamics arises in uncertainty
propagation, nonlinear filtering and stochastic control. Our methodology breaks
away from the traditional approach of spatial discretization or function
approximation -- both of which, in general, suffer from the
&quot;curse-of-dimensionality&quot;. In the proposed framework, we discretize time but
not the state space. We solve infinite dimensional proximal recursions in the
manifold of joint PDFs, which in the small time-step limit, is theoretically
equivalent to solving the underlying transport PDEs. The resulting computation
has the geometric interpretation of gradient flow of certain free energy
functional with respect to the Wasserstein metric arising from the theory of
optimal mass transport. We show that dualization along with an entropic
regularization, leads to a cone-preserving fixed point recursion that is proved
to be contractive in Thompson metric. A block co-ordinate iteration scheme is
proposed to solve the resulting nonlinear recursions with guaranteed
convergence. This approach enables remarkably fast computation for
non-parametric transient joint PDF propagation. Numerical examples and various
extensions are provided to illustrate the scope and efficacy of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00541</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00541</id><created>2019-07-31</created><authors><author><keyname>Wang</keyname><forenames>Ziran</forenames></author><author><keyname>Hsu</keyname><forenames>Yuan-Pu</forenames></author><author><keyname>Vu</keyname><forenames>Alexander</forenames></author><author><keyname>Caballero</keyname><forenames>Francisco</forenames></author><author><keyname>Hao</keyname><forenames>Peng</forenames></author><author><keyname>Wu</keyname><forenames>Guoyuan</forenames></author><author><keyname>Boriboonsomsin</keyname><forenames>Kanok</forenames></author><author><keyname>Barth</keyname><forenames>Matthew J.</forenames></author><author><keyname>Kailas</keyname><forenames>Aravind</forenames></author><author><keyname>Amar</keyname><forenames>Pascal</forenames></author><author><keyname>Garmon</keyname><forenames>Eddie</forenames></author><author><keyname>Tanugula</keyname><forenames>Sandeep</forenames></author></authors><title>Early Findings from Field Trials of Heavy-Duty Truck Connected
  Eco-Driving System</title><categories>eess.SY cs.SY</categories><comments>Earlier incorrectly submitted as a replacement of arXiv:1902.07747
  (which has been reverted). To appear in 2019 IEEE International Intelligent
  Transportation Systems Conference (ITSC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the development of connected and automated vehicle (CAV)
technology has inspired numerous advanced applications targeted at improving
existing transportation systems. As one of the widely studied applications of
CAV technology, connected eco-driving takes advantage of Signal Phase and
Timing (SPaT) information from traffic signals to enable CAVs to approach and
depart from signalized intersections in an energy-efficient manner. However the
majority of the connected eco-driving studies have been numerical or
microscopic traffic simulations. Only few studies have implemented the
application on real vehicles, and even fewer have been focused on heavy-duty
trucks. In this study, we developed a connected eco-driving system and equipped
it on a heavy-duty diesel truck using cellular-based wireless communications.
Field trials were conducted in the City ofCarson, California, along two
corridors with six connected signalized intersections capable of communicating
their SPaT information. Early results showed the benefits of the system in
smoothing the speed profiles of the equipped truck when approaching the
connected signalized intersections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00573</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00573</id><created>2019-08-01</created><authors><author><keyname>Zhao</keyname><forenames>Zhouqiao</forenames></author><author><keyname>Wang</keyname><forenames>Ziran</forenames></author><author><keyname>Wu</keyname><forenames>Guoyuan</forenames></author><author><keyname>Ye</keyname><forenames>Fei</forenames></author><author><keyname>Barth</keyname><forenames>Matthew J.</forenames></author></authors><title>The State-of-the-Art of Coordinated Ramp Control with Mixed Traffic
  Conditions</title><categories>eess.SY cs.SY</categories><comments>8 pages, 1 figure, IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE
  - ITSC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ramp metering, a traditional traffic control strategy for conventional
vehicles, has been widely deployed around the world since the 1960s. On the
other hand, the last decade has witnessed significant advances in connected and
automated vehicle (CAV) technology and its great potential for improving
safety, mobility and environmental sustainability. Therefore, a large amount of
research has been conducted on cooperative ramp merging for CAVs only. However,
it is expected that the phase of mixed traffic, namely the coexistence of both
human-driven vehicles and CAVs, would last for a long time. Since there is
little research on the system-wide ramp control with mixed traffic conditions,
the paper aims to close this gap by proposing an innovative system architecture
and reviewing the state-of-the-art studies on the key components of the
proposed system. These components include traffic state estimation, ramp
metering, driving behavior modeling, and coordination of CAVs. All reviewed
literature plot an extensive landscape for the proposed system-wide coordinated
ramp control with mixed traffic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00593</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00593</id><created>2019-08-01</created><authors><author><keyname>Schwab</keyname><forenames>Johannes</forenames></author><author><keyname>Antholzer</keyname><forenames>Stephan</forenames></author><author><keyname>Haltmeier</keyname><forenames>Markus</forenames></author></authors><title>Learned backprojection for sparse and limited view photoacoustic
  tomography</title><categories>eess.IV</categories><comments>This paper is a proceedings to our presentation (Paper 1087837) at
  the Photons Plus Ultrasound: Imaging and Sensing, (within the SPIE Photonics
  West), Poster Sunday, February 03, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filtered backprojection (FBP) is an efficient and popular class of
tomographic image reconstruction methods. In photoacoustic tomography, these
algorithms are based on theoretically exact analytic inversion formulas which
results in accurate reconstructions. However, photoacoustic measurement data
are often incomplete (limited detection view and sparse sampling), which
results in artefacts in the images reconstructed with FBP. In addition to that,
properties such as directivity of the acoustic detectors are not accounted for
in standard FBP, which affects the reconstruction quality, too. To account for
these issues, in this papers we propose to improve FBP algorithms based on
machine learning techniques. In the proposed method, we include additional
weight factors in the FBP, that are optimized on a set of incomplete data and
the corresponding ground truth photoacoustic source. Numerical tests show that
the learned FBP improves the reconstruction quality compared to the standard
FBP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00600</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00600</id><created>2019-08-01</created><authors><author><keyname>Khobahi</keyname><forenames>Shahin</forenames></author><author><keyname>Soltanalian</keyname><forenames>Mojtaba</forenames></author><author><keyname>Jiang</keyname><forenames>Feng</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Optimized Transmission for Parameter Estimation in Wireless Sensor
  Networks</title><categories>eess.SP cs.DC cs.MA cs.SY eess.SY</categories><comments>Accepted for publication in IEEE Transactions on Signal and
  Information Processing over Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in analog wireless sensor networks is to design the gain or
phase-shifts of the sensor nodes (i.e. the relaying configuration) in order to
achieve an accurate estimation of some parameter of interest at a fusion
center, or more generally, at each node by employing a distributed parameter
estimation scheme. In this paper, by using an over-parametrization of the
original design problem, we devise a cyclic optimization approach that can
handle tuning both gains and phase-shifts of the sensor nodes, even in
intricate scenarios involving sensor selection or discrete phase-shifts. Each
iteration of the proposed design framework consists of a combination of the
Gram-Schmidt process and power method-like iterations, and as a result, enjoys
a low computational cost. Along with formulating the design problem for a
fusion center, we further present a consensus-based framework for decentralized
estimation of deterministic parameters in a distributed network, which results
in a similar sensor gain design problem. The numerical results confirm the
computational advantage of the suggested approach in comparison with the
state-of-the-art methods---an advantage that becomes more pronounced when the
sensor network grows large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00615</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00615</id><created>2019-08-01</created><authors><author><keyname>F&#xe9;vry</keyname><forenames>Thibault</forenames></author><author><keyname>Phang</keyname><forenames>Jason</forenames></author><author><keyname>Wu</keyname><forenames>Nan</forenames></author><author><keyname>Kim</keyname><forenames>S. Gene</forenames></author><author><keyname>Moy</keyname><forenames>Linda</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Geras</keyname><forenames>Krzysztof J.</forenames></author></authors><title>Improving localization-based approaches for breast cancer screening exam
  classification</title><categories>eess.IV cs.CV stat.ML</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/HyxoAR_AK4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We trained and evaluated a localization-based deep CNN for breast cancer
screening exam classification on over 200,000 exams (over 1,000,000 images).
Our model achieves an AUC of 0.919 in predicting malignancy in patients
undergoing breast cancer screening, reducing the error rate of the baseline (Wu
et al., 2019a) by 23%. In addition, the models generates bounding boxes for
benign and malignant findings, providing interpretable predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00620</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00620</id><created>2019-08-01</created><authors><author><keyname>Metzler</keyname><forenames>Christopher A.</forenames></author><author><keyname>Ikoma</keyname><forenames>Hayato</forenames></author><author><keyname>Peng</keyname><forenames>Yifan</forenames></author><author><keyname>Wetzstein</keyname><forenames>Gordon</forenames></author></authors><title>Deep Optics for Single-shot High-dynamic-range Imaging</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-dynamic-range (HDR) imaging is crucial for many computer graphics and
vision applications. Yet, acquiring HDR images with a single shot remains a
challenging problem. Whereas modern deep learning approaches are successful at
hallucinating plausible HDR content from a single low-dynamic-range (LDR)
image, saturated scene details often cannot be faithfully recovered. Inspired
by recent deep optical imaging approaches, we interpret this problem as jointly
training an optical encoder and electronic decoder where the encoder is
parameterized by the point spread function (PSF) of the lens, the bottleneck is
the sensor with a limited dynamic range, and the decoder is a convolutional
neural network (CNN). The lens surface is then jointly optimized with the CNN
in a training phase; we fabricate this optimized optical element and attach it
as a hardware add-on to a conventional camera during inference. In extensive
simulations and with a physical prototype, we demonstrate that this end-to-end
deep optical imaging approach to single-shot HDR imaging outperforms both
purely CNN-based approaches and other PSF engineering approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00631</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00631</id><created>2019-08-01</created><authors><author><keyname>Ghaderi</keyname><forenames>Erfan</forenames></author><author><keyname>Ramani</keyname><forenames>Ajith</forenames></author><author><keyname>Rahimi</keyname><forenames>Arya</forenames></author><author><keyname>Shekhar</keyname><forenames>Sudip</forenames></author><author><keyname>Gupta</keyname><forenames>Subhanshu</forenames></author></authors><title>A 4-Element MIMO Baseband Receiver with &gt;35dB 80MHz Spatial Interference
  Cancellation</title><categories>eess.SP</categories><comments>under review at IEEE Trans. of Circuits and Systems - 1: Reg. Pap</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next-generation communication systems with wide bandwidths need to operate in
interference-limited networks. A discrete-time delay (TD) technique in a
baseband receiver array is proposed for canceling wide modulated bandwidth
spatial interference and reducing the ADC dynamic range requirements. The
proposed discrete TD technique first aligns the interference using non-uniform
sampled phases followed by uniform cancellation using a Truncated Hadamard
Transform implemented with antipodal binary coefficients. A digital
timeinterleaver with 5 ps resolution spanning 15 ns implements a scalable
discrete TD to compensate the inter-element delay, while the
multiply-accumulate in the signal path is simplified by implementing a 1-bit
differential truncated Hadamard matrix. Measured results demonstrate greater
than 35 dB cancellation over 80 MHz modulated bandwidth in 65 nm CMOS with a
592x improvement over prior-art demonstration of wide modulated bandwidth
interference cancellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00642</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00642</id><created>2019-08-01</created><authors><author><keyname>Dunham</keyname><forenames>Hallie</forenames></author><author><keyname>Cutler</keyname><forenames>Dylan</forenames></author><author><keyname>Mishra</keyname><forenames>Sakshi</forenames></author><author><keyname>Li</keyname><forenames>Xiangkun</forenames></author></authors><title>Evaluation of Centralized and Distributed Microgrid Topologies
  Considering Power Quality Constraints</title><categories>eess.SY cs.SY</categories><comments>under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integration of renewable generation and energy storage technologies with
conventional generation supports increased resilience, lower-costs, and clean
energy goals. Traditionally, energy supply needs of rural off-grid communities
have been addressed with diesel-generation. But with rapidly falling renewable
generation costs, mini-grids are transforming into hybrid systems with a mix of
renewables, energy storage, and diesel-generation. Optimal design of hybrid
mini-grid requires an understanding of both the economic and power quality
impacts of different designs. Existing approaches to modeling distributed
energy resources address the economic viability and power quality impacts via
separate/loosely coupled models. Here, we extend REopt - a techno-economic
optimization model developed at National Renewable Energy Laboratory - to
consider both within a single model. REopt formulates the design problem as a
mixed-integer linear program that solves a deterministic optimization problem
for a site's optimal technology mix, sizing, and operation to minimize life
cycle cost. REopt has traditionally not constrained the power injection based
on power quality. In the work presented here, we expand the REopt platform to
consider multiple connected nodes. In order to do this, we model power flow
using a fixed-point linear approximation method. Resulting system sizes and
voltage magnitudes are validated against the base REopt model, and solutions of
established power flow models respectively. We then use the model to explore
design considerations of mini-grids in Sub-Saharan Africa. Specifically, we
evaluate under what combinations of line length and line capacity it is
economically beneficial (or technically required based on voltage limits) to
build isolated mini-grids versus an interconnected system that benefits from
the economies of scale associated with a single, centralized generation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00656</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00656</id><created>2019-08-01</created><authors><author><keyname>Liu</keyname><forenames>Zheng</forenames></author><author><keyname>Zhang</keyname><forenames>Jinnian</forenames></author><author><keyname>Jog</keyname><forenames>Varun</forenames></author><author><keyname>Loh</keyname><forenames>Po-Ling</forenames></author><author><keyname>McMillan</keyname><forenames>Alan B</forenames></author></authors><title>Robustifying deep networks for image segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: The purpose of this study is to investigate the robustness of a
commonly-used convolutional neural network for image segmentation with respect
to visually-subtle adversarial perturbations, and suggest new methods to make
these networks more robust to such perturbations. Materials and Methods: In
this retrospective study, the accuracy of brain tumor segmentation was studied
in subjects with low- and high-grade gliomas. A three-dimensional UNet model
was implemented to segment four different MR series (T1-weighted, post-contrast
T1-weighted, T2- weighted, and T2-weighted FLAIR) into four pixelwise labels
(Gd-enhancing tumor, peritumoral edema, necrotic and non-enhancing tumor, and
background). We developed attack strategies based on the Fast Gradient Sign
Method (FGSM), iterative FGSM (i-FGSM), and targeted iterative FGSM (ti-FGSM)
to produce effective attacks. Additionally, we explored the effectiveness of
distillation and adversarial training via data augmentation to counteract
adversarial attacks. Robustness was measured by comparing the Dice coefficient
for each attack method using Wilcoxon signed-rank tests. Results: Attacks based
on FGSM, i-FGSM, and ti-FGSM were effective in significantly reducing the
quality of image segmentation with reductions in Dice coefficient by up to 65%.
For attack defenses, distillation performed significantly better than
adversarial training approaches. However, all defense approaches performed
worse compared to unperturbed test images. Conclusion: Segmentation networks
can be adversely affected by targeted attacks that introduce visually minor
(and potentially undetectable) modifications to existing images. With an
increasing interest in applying deep learning techniques to medical imaging
data, it is important to quantify the ramifications of adversarial inputs
(either intentional or unintentional).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00658</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00658</id><created>2019-08-01</created><authors><author><keyname>Peng</keyname><forenames>Qihang</forenames></author><author><keyname>Gilman</keyname><forenames>Andrew</forenames></author><author><keyname>Vasconcelos</keyname><forenames>Nuno</forenames></author><author><keyname>Cosman</keyname><forenames>Pamela C.</forenames></author><author><keyname>Milstein</keyname><forenames>Laurence B.</forenames></author></authors><title>Robust Deep Sensing Through Transfer Learning in Cognitive Radio</title><categories>cs.IT cs.LG eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a robust spectrum sensing framework based on deep learning. The
received signals at the secondary user's receiver are filtered, sampled and
then directly fed into a convolutional neural network. Although this deep
sensing is effective when operating in the same scenario as the collected
training data, the sensing performance is degraded when it is applied in a
different scenario with different wireless signals and propagation. We
incorporate transfer learning into the framework to improve the robustness.
Results validate the effectiveness as well as the robustness of the proposed
deep spectrum sensing framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00659</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00659</id><created>2019-08-01</created><updated>2019-08-26</updated><authors><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Dyck</keyname><forenames>Ondrej</forenames></author><author><keyname>Jesse</keyname><forenames>Stephen</forenames></author><author><keyname>Lupini</keyname><forenames>Andrew R.</forenames></author><author><keyname>Kalinin</keyname><forenames>Sergei V.</forenames></author><author><keyname>Oxley</keyname><forenames>Mark P.</forenames></author></authors><title>Structure retrieval from 4D-STEM: statistical analysis of potential
  pitfalls in high-dimensional data</title><categories>stat.AP eess.IV physics.data-an</categories><journal-ref>Phys. Rev. E 100, 023308, 2019</journal-ref><doi>10.1103/PhysRevE.100.023308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Four-dimensional scanning transmission electron microscopy (4D-STEM) is one
of the most rapidly growing modes of electron microscopy imaging. The advent of
fast pixelated cameras and the associated data infrastructure have greatly
accelerated this process. Yet conversion of the 4D datasets into physically
meaningful structure images in real-space remains an open issue. In this work,
we demonstrate that, it is possible to systematically create filters that will
affect the apparent resolution or even qualitative features of the real-space
structure image, reconstructing artificially generated patterns. As initial
efforts, we explore statistical model selection algorithms, aiming for
robustness and reliability of estimated filters. This statistical model
selection analysis demonstrates the need for regularization and
cross-validation of inversion methods to robustly recover structure from
high-dimensional diffraction datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00682</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00682</id><created>2019-08-01</created><updated>2019-11-19</updated><authors><author><keyname>Lv</keyname><forenames>Feifan</forenames></author><author><keyname>Li</keyname><forenames>Yu</forenames></author><author><keyname>Lu</keyname><forenames>Feng</forenames></author></authors><title>Attention-guided Low-light Image Enhancement</title><categories>eess.IV cs.CV</categories><comments>12 pages, 15 figures, 4 tables, supplementary materials and project
  page: http://phi-ai.org/project/AgLLNet/default.htm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-light image enhancement is a challenging task as multiple factors,
including color, brightness, contrast, artifacts, and noise, etc. need to be
simultaneously and effectively handled. To address such a complex problem
containing multiple issues, this paper proposes a novel attention-guided
enhancement solution based on which an end-to-end multi-branch CNN is built.
The key of our method is the computation of two attention maps to guide the
exposure enhancement and denoising tasks respectively. In particular, the first
attention map distinguishes underexposed regions from well lit regions, while
the second attention map distinguishes noises from real textures. Under their
guidance, the proposed multi-branch enhancement network can work in an input
adaptive way. Other contributions of this paper include a
decomposition-and-fusion design of the enhancement network and the
reinforcement-net for further contrast enhancement. In addition, we have
proposed a large dataset for low-light enhancement. We evaluate the proposed
method with extensive experiments, and the results demonstrate that our
solution outperforms state-of-the-art methods by a large margin both
quantitatively and visually. We additionally show that our method is flexible
and effective for other image processing tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00697</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00697</id><created>2019-08-02</created><updated>2020-02-22</updated><authors><author><keyname>Thorpe</keyname><forenames>Adam J.</forenames></author><author><keyname>Oishi</keyname><forenames>Meeko M. K.</forenames></author></authors><title>Model-Free Stochastic Reachability Using Kernel Distribution Embeddings</title><categories>math.OC cs.SY eess.SY</categories><journal-ref>in IEEE Control Systems Letters, vol. 4, no. 2, pp. 512-517, April
  2020</journal-ref><doi>10.1109/LCSYS.2019.2954102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a solution to the terminal-hitting stochastic reach-avoid problem
for a Markov control process. This solution takes advantage of a nonparametric
representation of the stochastic kernel as a conditional distribution embedding
within a reproducing kernel Hilbert space (RKHS). Because the disturbance is
modeled as a data-driven stochastic process, this representation avoids
intractable integrals in the dynamic recursion of the reach-avoid problem since
the expectations can be calculated as an inner product within the RKHS. We
demonstrate this approach on a high-dimensional chain of integrators and on
Clohessy-Wiltshire-Hill dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00699</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00699</id><created>2019-08-02</created><authors><author><keyname>Chadha</keyname><forenames>Karan N.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Ankur A.</forenames></author><author><keyname>Nair</keyname><forenames>Jayakrishnan</forenames></author></authors><title>Efficiency Fairness Tradeoff in Battery Sharing</title><categories>math.OC cs.SY eess.SY</categories><msc-class>60J27, 90B22, 60F10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing presence of decentralized renewable generation in the power
grid has motivated consumers to install batteries to save excess energy for
future use. The high price of energy storage calls for a shared storage system,
but careful battery management is required so that the battery is operated in a
manner that is fair to all and as efficiently as possible. In this paper, we
study the tradeoffs between efficiency and fairness in operating a shared
battery. We develop a framework based on constrained Markov decision processes
to study both regimes, namely, optimizing efficiency under a hard fairness
constraint and optimizing fairness under hard efficiency constraint. Our
results show that there are fundamental limits to efficiency under fairness and
vice-versa, and, in general, the two cannot be achieved simultaneously. We
characterize these fundamental limits via absolute bounds on these quantities,
and via the notion of price of fairness that we introduce in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00702</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00702</id><created>2019-08-02</created><authors><author><keyname>Kulkarni</keyname><forenames>Ankur A.</forenames></author></authors><title>The Efficiency of Generalized Nash and Variational Equilibria</title><categories>cs.GT cs.SY eess.SY math.OC</categories><msc-class>91A99,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shared-constraint games are noncooperative $N$-player games where players are
coupled through a common coupling constraint. It is known that such games admit
two kinds of equilibria -- generalized Nash equilibria (GNE) and variational
equilibria (VE) -- with two different economic interpretations. We consider
such games in the context of resource allocation, where players move
simultaneously to decide portions of the resource they can consume under a
coupling constraint that the sum of the portions they demand be no more than
the capacity of the resource. We clarify the worst case and best case
efficiency of these kinds of equilibria over all games in a class. We find that
the worst case efficiency of both solution concepts in zero and the best case
efficiency is unity. Moreover, we characterize the subclass of games where all
VE are efficient and show that even in this subclass but the worst case
efficiency of GNE is zero. We finally discuss means by which zero worst case
efficiency can be remedied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00748</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00748</id><created>2019-08-02</created><authors><author><keyname>Payer</keyname><forenames>Christian</forenames></author><author><keyname>&#x160;tern</keyname><forenames>Darko</forenames></author><author><keyname>Bischof</keyname><forenames>Horst</forenames></author><author><keyname>Urschler</keyname><forenames>Martin</forenames></author></authors><title>Integrating Spatial Configuration into Heatmap Regression Based CNNs for
  Landmark Localization</title><categories>eess.IV cs.CV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/r1xGxWJ0t4</report-no><doi>10.1016/j.media.2019.03.007</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In many medical image analysis applications, often only a limited amount of
training data is available, which makes training of convolutional neural
networks (CNNs) challenging. In this work on anatomical landmark localization,
we propose a CNN architecture that learns to split the localization task into
two simpler sub-problems, reducing the need for large training datasets. Our
fully convolutional SpatialConfiguration-Net (SCN) dedicates one component to
locally accurate but ambiguous candidate predictions, while the other component
improves robustness to ambiguities by incorporating the spatial configuration
of landmarks. In our experimental evaluation, we show that the proposed SCN
outperforms related methods in terms of landmark localization error on
size-limited datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00752</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00752</id><created>2019-08-02</created><authors><author><keyname>Yang</keyname><forenames>Peng</forenames></author><author><keyname>Liu</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Zhaojian</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author><author><keyname>Yi</keyname><forenames>Jun</forenames></author><author><keyname>Lin</keyname><forenames>Weifang</forenames></author></authors><title>Toward Distributed Stability Analytics for Power Systems with
  Heterogeneous Bus Dynamics</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stability issue emerges as a growing number of diverse power apparatus
connecting to the power system. The stability analysis for such power systems
is required to adapt to heterogeneity and scalability. This paper derives a
local passivity index condition that guarantees the system-wide stability for
lossless power systems with interconnected, nonlinear, heterogeneous bus
dynamics. Our condition requires each bus dynamics to be output feedback
passive with a large enough index w.r.t. a special supply rate. This condition
fits for numerous existing models since it only constrains the input-output
property rather than the detailed dynamics. Furthermore, for three typical
examples of bus dynamics in power systems, we show that this condition can be
reached via proper control designs. Simulations on a 3-bus heterogeneous power
system verify our results in both lossless and lossy cases. The
conservativeness of our condition is also demonstrated, as well as the impact
on transient stability. It shows that our condition is quite tight and a larger
index benefits transient stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00758</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00758</id><created>2019-08-02</created><authors><author><keyname>Shtar</keyname><forenames>Guy</forenames></author><author><keyname>Shapira</keyname><forenames>Bracha</forenames></author><author><keyname>Rokach</keyname><forenames>Lior</forenames></author></authors><title>Clustering Wi-Fi Fingerprints for Indoor-Outdoor Detection</title><categories>eess.SP cs.HC</categories><doi>10.1007/s11276-018-1753-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for continuous indoor-outdoor environment
detection on mobile devices based solely on WiFi fingerprints. Detection of
indoor outdoor switching is an important part of identifying a user's context,
and it provides important information for upper layer context aware mobile
applications such as recommender systems, navigation tools, etc. Moreover,
future indoor positioning systems are likely to use Wi-Fi fingerprints, and
therefore Wi-Fi receivers will be on most of the time. In contrast to existing
research, we believe that these fingerprints should be leveraged, and they
serve as the basis of the proposed method. Using various machine learning
algorithms, we train a supervised classifier based on features extracted from
the raw fingerprints, clusters, and cluster transition graph. The contribution
of each of the features to the method is assessed. Our method assumes no prior
knowledge of the environment, and a training set consisting of the data
collected for just a few hours on a single device is sufficient in order to
provide indoor-outdoor classification, even in an unknown location or when
using new devices. We evaluate our method in an experiment involving 12
participants during their daily routine, with a total of 828 hours' worth of
data collected by the participants. We report a predictive performance of the
AUC (area under the curve) of 0.94 using the gradient boosting machine ensemble
learning method. We show that our method can be used for other context
detection tasks such as learning and recognizing a given building or room.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00764</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00764</id><created>2019-08-02</created><updated>2019-10-21</updated><authors><author><keyname>Orlando</keyname><forenames>Jos&#xe9; Ignacio</forenames></author><author><keyname>Breger</keyname><forenames>Anna</forenames></author><author><keyname>Bogunovi&#x107;</keyname><forenames>Hrvoje</forenames></author><author><keyname>Riedl</keyname><forenames>Sophie</forenames></author><author><keyname>Gerendas</keyname><forenames>Bianca S.</forenames></author><author><keyname>Ehler</keyname><forenames>Martin</forenames></author><author><keyname>Schmidt-Erfurth</keyname><forenames>Ursula</forenames></author></authors><title>An amplified-target loss approach for photoreceptor layer segmentation
  in pathological OCT scans</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication at MICCAI-OMIA 2019</comments><doi>10.1007/978-3-030-32956-3_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmenting anatomical structures such as the photoreceptor layer in retinal
optical coherence tomography (OCT) scans is challenging in pathological
scenarios. Supervised deep learning models trained with standard loss functions
are usually able to characterize only the most common disease appeareance from
a training set, resulting in suboptimal performance and poor generalization
when dealing with unseen lesions. In this paper we propose to overcome this
limitation by means of an augmented target loss function framework. We
introduce a novel amplified-target loss that explicitly penalizes errors within
the central area of the input images, based on the observation that most of the
challenging disease appeareance is usually located in this area. We
experimentally validated our approach using a data set with OCT scans of
patients with macular diseases. We observe increased performance compared to
the models that use only the standard losses. Our proposed loss function
strongly supports the segmentation model to better distinguish photoreceptors
in highly pathological scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00766</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00766</id><created>2019-08-02</created><updated>2019-09-05</updated><authors><author><keyname>Kapka</keyname><forenames>S&#x142;awomir</forenames></author><author><keyname>Lewandowski</keyname><forenames>Mateusz</forenames></author></authors><title>Sound source detection, localization and classification using
  consecutive ensemble of CRNN models</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>5 pages, 3 figures, conference</comments><journal-ref>Proceedings of the Detection and Classification of Acoustic Scenes
  and Events 2019 Workshop (DCASE2019), New York University, NY, USA, October
  2019</journal-ref><doi>10.33682/1syg-dy60</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe our method for DCASE2019 task3: Sound Event
Localization and Detection (SELD). We use four CRNN SELDnet-like single output
models which run in a consecutive manner to recover all possible information of
occurring events. We decompose the SELD task into estimating number of active
sources, estimating direction of arrival of a single source, estimating
direction of arrival of the second source where the direction of the first one
is known and a multi-label classification task. We use custom consecutive
ensemble to predict events' onset, offset, direction of arrival and class. The
proposed approach is evaluated on the TAU Spatial Sound Events 2019 - Ambisonic
and it is compared with other participants' submissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00786</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00786</id><created>2019-08-02</created><authors><author><keyname>Pan</keyname><forenames>Yijin</forenames></author><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Yang</keyname><forenames>Zhaohui</forenames></author><author><keyname>Chen</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author></authors><title>A Caching Strategy Towards Maximal D2D Assisted Offloading Gain</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted in IEEE Transactions on Mobile Computing</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Device-to-Device (D2D) communications incorporated with content caching have
been regarded as a promising way to offload the cellular traffic data. In this
paper, the caching strategy is investigated to maximize the D2D offloading gain
with the comprehensive consideration of user collaborative characteristics as
well as the physical transmission conditions. Specifically, for a given
content, the number of interested users in different groups is different, and
users always ask the most trustworthy user in proximity for D2D transmissions.
An analytical expression of the D2D success probability is first derived, which
represents the probability that the received signal to interference ratio is no
less than a given threshold. As the formulated problem is non-convex, the
optimal caching strategy for the special unbiased case is derived in a closed
form, and a numerical searching algorithm is proposed to obtain the globally
optimal solution for the general case. To reduce the computational complexity,
an iterative algorithm based on the asymptotic approximation of the D2D success
probability is proposed to obtain the solution that satisfies the
Karush-Kuhn-Tucker conditions. The simulation results verify the effectiveness
of the analytical results and show that the proposed algorithm outperforms the
existing schemes in terms of offloading gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00787</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00787</id><created>2019-08-02</created><authors><author><keyname>Porras</keyname><forenames>&#xc1;lvaro</forenames></author><author><keyname>Fern&#xe1;ndez-Blanco</keyname><forenames>Ricardo</forenames></author><author><keyname>Morales</keyname><forenames>Juan Miguel</forenames></author><author><keyname>Pineda</keyname><forenames>Salvador</forenames></author></authors><title>Day-ahead Operation of an Aggregator of Electric Vehicles via
  Optimization under Uncertainty</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We pose the aggregator's problem as a bilevel model, where the upper level
minimizes the total operation costs of the fleet of EVs, while each lower level
minimizes the energy available to each vehicle for transportation given a
certain charging plan. Thanks to the totally unimodular character of the
constraint matrix in the lower-level problems, the model can be mathematically
recast as a computationally efficient mixed-integer program that delivers
charging schedules that are robust against the uncertain availability of the
EVs. Finally, we use synthetic data from the National Household Travel Survey
2017 to analyze the behavior of the EV aggregator from both economic and
technical viewpoints and compare it with the results from a deterministic
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00788</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00788</id><created>2019-08-02</created><authors><author><keyname>Laves</keyname><forenames>Max-Heinrich</forenames></author><author><keyname>Ihler</keyname><forenames>Sontje</forenames></author><author><keyname>Ortmaier</keyname><forenames>Tobias</forenames></author></authors><title>Deformable Medical Image Registration Using a Randomly-Initialized CNN
  as Regularization Prior</title><categories>eess.IV cs.CV</categories><comments>Accepted at MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/S1ehZFQ15E</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present deformable unsupervised medical image registration using a
randomly-initialized deep convolutional neural network (CNN) as regularization
prior. Conventional registration methods predict a transformation by minimizing
dissimilarities between an image pair. The minimization is usually regularized
with manually engineered priors, which limits the potential of the
registration. By learning transformation priors from a large dataset, CNNs have
achieved great success in deformable registration. However, learned methods are
restricted to domain-specific data and the required amounts of medical data are
difficult to obtain. Our approach uses the idea of deep image priors to combine
convolutional networks with conventional registration methods based on manually
engineered priors. The proposed method is applied to brain MRI scans. We show
that our approach registers image pairs with state-of-the-art accuracy by
providing dense, pixel-wise correspondence maps. It does not rely on prior
training and is therefore not limited to a specific image domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00792</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00792</id><created>2019-08-02</created><authors><author><keyname>Laves</keyname><forenames>Max-Heinrich</forenames></author><author><keyname>Ihler</keyname><forenames>Sontje</forenames></author><author><keyname>Ortmaier</keyname><forenames>Tobias</forenames></author></authors><title>Uncertainty Quantification in Computer-Aided Diagnosis: Make Your Model
  say &quot;I don't know&quot; for Ambiguous Cases</title><categories>eess.IV cs.CV</categories><comments>Accepted at MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/rJevPsX854</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We evaluate two different methods for the integration of prediction
uncertainty into diagnostic image classifiers to increase patient safety in
deep learning. In the first method, Monte Carlo sampling is applied with
dropout at test time to get a posterior distribution of the class labels
(Bayesian ResNet). The second method extends ResNet to a probabilistic approach
by predicting the parameters of the posterior distribution and sampling the
final result from it (Variational ResNet).The variance of the posterior is used
as metric for uncertainty.Both methods are trained on a data set of optical
coherence tomography scans showing four different retinal conditions. Our
results shown that cases in which the classifier predicts incorrectly correlate
with a higher uncertainty. Mean uncertainty of incorrectly diagnosed cases was
between 4.6 and 8.1 times higher than mean uncertainty of correctly diagnosed
cases. Modeling of the prediction uncertainty in computer-aided diagnosis with
deep learning yields more reliable results and is anticipated to increase
patient safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00801</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00801</id><created>2019-08-02</created><authors><author><keyname>Calatroni</keyname><forenames>Luca</forenames></author><author><keyname>Lanza</keyname><forenames>Alessandro</forenames></author><author><keyname>Pragliola</keyname><forenames>Monica</forenames></author><author><keyname>Sgallari</keyname><forenames>Fiorella</forenames></author></authors><title>Space-adaptive anisotropic bivariate Laplacian regularization for image
  restoration</title><categories>eess.IV cs.CV cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new regularization term for variational image
restoration which can be regarded as a space-variant anisotropic extension of
the classical isotropic Total Variation (TV) regularizer. The proposed
regularizer comes from the statistical assumption that the gradients of the
target image distribute locally according to space-variant bivariate Laplacian
distributions. The highly flexible variational structure of the corresponding
regularizer encodes several free parameters which hold the potential for
faithfully modelling the local geometry in the image and describing local
orientation preferences. For an automatic estimation of such parameters, we
design a robust maximum likelihood approach and report results on its
reliability on synthetic data and natural images. A minimization algorithm
based on the Alternating Direction Method of Multipliers (ADMM) is presented
for the efficient numerical solution of the proposed variational model. Some
experimental results are reported which demonstrate the high-quality of
restorations achievable by the proposed model, in particular with respect to
classical Total Variation regularization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00812</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00812</id><created>2019-08-02</created><updated>2019-12-13</updated><authors><author><keyname>Bourtsoulatze</keyname><forenames>Eirina</forenames></author><author><keyname>Chadha</keyname><forenames>Aaron</forenames></author><author><keyname>Fadeev</keyname><forenames>Ilya</forenames></author><author><keyname>Giotsas</keyname><forenames>Vasileios</forenames></author><author><keyname>Andreopoulos</keyname><forenames>Yiannis</forenames></author></authors><title>Deep Video Precoding</title><categories>eess.IV cs.LG cs.MM stat.ML</categories><comments>16 pages, 14 figures, 11 tables, to appear in IEEE Trans. Circ. Syst.
  for Video Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several groups are currently investigating how deep learning may advance the
state-of-the-art in image and video coding. An open question is how to make
deep neural networks work in conjunction with existing (and upcoming) video
codecs, such as MPEG AVC, HEVC, VVC, Google VP9 and AOM AV1, as well as
existing container and transport formats, without imposing any changes at the
client side. Such compatibility is a crucial aspect when it comes to practical
deployment, especially due to the fact that the video content industry and
hardware manufacturers are expected to remain committed to these standards for
the foreseeable future. We propose to use deep neural networks as precoders for
current and future video codecs and adaptive video streaming systems. In our
current design, the core precoding component comprises a cascaded structure of
downscaling neural networks that operates during video encoding, prior to
transmission. This is coupled with a precoding mode selection algorithm for
each independently-decodable stream segment, which adjusts the downscaling
factor according to scene characteristics, the utilized encoder, and the
desired bitrate and encoding configuration. Our framework is compatible with
all current and future codec and transport standards, as our deep precoding
network structure is trained in conjunction with linear upscaling filters
(e.g., the bilinear filter), which are supported by all web video players.
Results with FHD and UHD content and widely-used AVC, HEVC and VP9 encoders
show that coupling such standards with the proposed deep video precoding allows
for 15% to 45% rate reduction under encoding configurations and bitrates
suitable for video-on-demand adaptive streaming systems. The use of precoding
can also lead to encoding complexity reduction, which is essential for
cost-effective cloud deployment of complex encoders like H.265/HEVC and VP9.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00822</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00822</id><created>2019-08-02</created><authors><author><keyname>Sundaran</keyname><forenames>Deepthi</forenames></author><author><keyname>Kulkarni</keyname><forenames>Dheeraj</forenames></author><author><keyname>Dholakia</keyname><forenames>Jignesh</forenames></author></authors><title>Optimal Windowing of MR Images using Deep Learning: An Enabler for
  Enhanced Visualization</title><categories>eess.IV</categories><comments>The paper has 4 pages and includes 1 figure. It was presented as an
  Extended abstract poster at MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/B1xu1a1RtV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Window width (WW) and window level (WL) adjustments aid in visualizing
anatomies with a suitable contrast. However, the presence of background noise
in MR images biases the calculation of default WW/WL values since it
necessitates a trade-off between enhancing contrast of foreground/anatomy of
interest vs suppressing background/ outside the anatomy of interest. This paper
proposes an intelligent algorithm to improve the automatic computation of WW/WL
and provide better control for user defined windowing.This is achieved by first
eliminating the background pixels using a Deep Neural network and then
computing WW/WL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00833</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00833</id><created>2019-08-02</created><authors><author><keyname>Nguyen</keyname><forenames>Hieu V.</forenames></author><author><keyname>Nguyen</keyname><forenames>Van-Dinh</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Nguyen</keyname><forenames>Diep N.</forenames></author><author><keyname>Dutkiewicz</keyname><forenames>Eryk</forenames></author><author><keyname>Shin</keyname><forenames>Oh-Soon</forenames></author></authors><title>Joint Power Control and User Association for NOMA-Based Full-Duplex
  Systems</title><categories>eess.SP</categories><comments>This work has been accepted for publication in IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the coexistence of non-orthogonal multiple access
(NOMA) and full-duplex (FD) to improve both spectral efficiency (SE) and user
fairness. In such a scenario, NOMA based on the successive interference
cancellation technique is simultaneously applied to both uplink (UL) and
downlink (DL) transmissions in an FD system. We consider the problem of jointly
optimizing user association (UA) and power control to maximize the overall SE,
subject to user-specific quality-of-service and total transmit power
constraints. To be spectrally-efficient, we introduce the tensor model to
optimize UL users' decoding order and DL users' clustering, which results in a
mixed-integer non-convex problem. For practically appealing applications, we
first relax the binary variables and then propose two low-complexity designs.
In the first design, the continuous relaxation problem is solved using the
inner convex approximation framework. Next, we additionally introduce the
penalty method to further accelerate the performance of the former design. For
a benchmark, we develop an optimal solution based on brute-force search (BFS)
over all possible cases of UAs. It is demonstrated in numerical results that
the proposed algorithms outperform the conventional FD-based schemes and its
half-duplex counterpart, as well as yield data rates close to those obtained by
BFS-based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00841</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00841</id><created>2019-08-02</created><authors><author><keyname>Moe</keyname><forenames>Yngve Mardal</forenames></author><author><keyname>Groendahl</keyname><forenames>Aurora Rosvoll</forenames></author><author><keyname>Mulstad</keyname><forenames>Martine</forenames></author><author><keyname>Tomic</keyname><forenames>Oliver</forenames></author><author><keyname>Indahl</keyname><forenames>Ulf</forenames></author><author><keyname>Dale</keyname><forenames>Einar</forenames></author><author><keyname>Malinen</keyname><forenames>Eirik</forenames></author><author><keyname>Futsaether</keyname><forenames>Cecilia Marie</forenames></author></authors><title>Deep learning for automatic tumour segmentation in PET/CT images of
  patients with head and neck cancers</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/Ske75hkfqN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  An automatic segmentation algorithm for delineation of the gross tumour
volume and pathologic lymph nodes of head and neck cancers in PET/CT images is
described. The proposed algorithm is based on a convolutional neural network
using the U-Net architecture. Several model hyperparameters were explored and
the model performance in terms of the Dice similarity coefficient was validated
on images from 15 patients. A separate test set consisting of images from 40
patients was used to assess the generalisability of the algorithm. The
performance on the test set showed close-to-oncologist level delineations as
measured by the Dice coefficient (CT: $0.65 \pm 0.17$, PET: $0.71 \pm 0.12$,
PET/CT: $0.75 \pm 0.12$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00870</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00870</id><created>2019-08-02</created><authors><author><keyname>Coluccia</keyname><forenames>Angelo</forenames></author><author><keyname>Fascista</keyname><forenames>Alessio</forenames></author><author><keyname>Ricci</keyname><forenames>Giuseppe</forenames></author></authors><title>A k-nearest neighbors approach to the design of radar detectors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A k-nearest neighbors (KNN) approach to the design of radar detectors is
investigated. The idea is to start with either raw data or well-known radar
receiver statistics as feature vector to be fed to the KNN decision rule. In
the latter case, the probability of false alarm and probability of detection
are characterized in closed-form; moreover, it is proved that the detector
possesses the constant false alarm rate (CFAR) property and the relevant
performance parameters are identified. Simulation examples are provided to
illustrate the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00876</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00876</id><created>2019-08-02</created><authors><author><keyname>Skibbe</keyname><forenames>Henrik</forenames></author><author><keyname>Watakabe</keyname><forenames>Akiya</forenames></author><author><keyname>Nakae</keyname><forenames>Ken</forenames></author><author><keyname>Gutierrez</keyname><forenames>Carlos Enrique</forenames></author><author><keyname>Tsukada</keyname><forenames>Hiromichi</forenames></author><author><keyname>Hata</keyname><forenames>Junichi</forenames></author><author><keyname>Kawase</keyname><forenames>Takashi</forenames></author><author><keyname>Gong</keyname><forenames>Rui</forenames></author><author><keyname>Woodward</keyname><forenames>Alexander</forenames></author><author><keyname>Doya</keyname><forenames>Kenji</forenames></author><author><keyname>Okano</keyname><forenames>Hideyuki</forenames></author><author><keyname>Yamamori</keyname><forenames>Tetsuo</forenames></author><author><keyname>Ishii</keyname><forenames>Shin</forenames></author></authors><title>MarmoNet: a pipeline for automated projection mapping of the common
  marmoset brain from whole-brain serial two-photon tomography</title><categories>eess.IV cs.LG q-bio.NC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the connectivity in the brain is an important prerequisite for
understanding how the brain processes information. In the Brain/MINDS project,
a connectivity study on marmoset brains uses two-photon microscopy fluorescence
images of axonal projections to collect the neuron connectivity from defined
brain regions at the mesoscopic scale. The processing of the images requires
the detection and segmentation of the axonal tracer signal. The objective is to
detect as much tracer signal as possible while not misclassifying other
background structures as the signal. This can be challenging because of imaging
noise, a cluttered image background, distortions or varying image contrast
cause problems.
  We are developing MarmoNet, a pipeline that processes and analyzes tracer
image data of the common marmoset brain. The pipeline incorporates
state-of-the-art machine learning techniques based on artificial convolutional
neural networks (CNN) and image registration techniques to extract and map all
relevant information in a robust manner. The pipeline processes new images in a
fully automated way.
  This report introduces the current state of the tracer signal analysis part
of the pipeline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00878</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00878</id><created>2019-08-02</created><updated>2020-01-14</updated><authors><author><keyname>Rey</keyname><forenames>Samuel</forenames></author><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Segarra</keyname><forenames>Santiago</forenames></author></authors><title>An Underparametrized Deep Decoder Architecture for Graph Signals</title><categories>eess.SP cs.LG</categories><comments>This paper has already been accepted on 2019 IEEE International
  Workshop on Computational Advances in Multi-Sensor Adaptive Processing
  (CAMSAP) and it is going to be published in its proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While deep convolutional architectures have achieved remarkable results in a
gamut of supervised applications dealing with images and speech, recent works
show that deep untrained non-convolutional architectures can also outperform
state-of-the-art methods in several tasks such as image compression and
denoising. Motivated by the fact that many contemporary datasets have an
irregular structure different from a 1D/2D grid, this paper generalizes
untrained and underparametrized non-convolutional architectures to signals
defined over irregular domains represented by graphs. The proposed architecture
consists of a succession of layers, each of them implementing an upsampling
operator, a linear feature combination, and a scalar nonlinearity. A novel
element is the incorporation of upsampling operators accounting for the
structure of the supporting graph, which is achieved by considering a
systematic graph coarsening approach based on hierarchical clustering. The
numerical results carried out in synthetic and real-world datasets showcase
that the reconstruction performance can improve drastically if the information
of the supporting graph topology is taken into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00894</identifier>
 <datestamp>2019-11-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00894</id><created>2019-08-02</created><updated>2019-11-22</updated><authors><author><keyname>Fan</keyname><forenames>Rui</forenames></author><author><keyname>Ozgunalp</keyname><forenames>Umar</forenames></author><author><keyname>Hosking</keyname><forenames>Brett</forenames></author><author><keyname>Liu</keyname><forenames>Ming</forenames></author><author><keyname>Pitas</keyname><forenames>Ioannis</forenames></author></authors><title>Pothole Detection Based on Disparity Transformation and Road Surface
  Modeling</title><categories>cs.CV eess.IV</categories><comments>12 pages, 15 figures, IEEE Transactions on Image Processing</comments><doi>10.1109/TIP.2019.2933750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pothole detection is one of the most important tasks for road maintenance.
Computer vision approaches are generally based on either 2D road image analysis
or 3D road surface modeling. However, these two categories are always used
independently. Furthermore, the pothole detection accuracy is still far from
satisfactory. Therefore, in this paper, we present a robust pothole detection
algorithm that is both accurate and computationally efficient. A dense
disparity map is first transformed to better distinguish between damaged and
undamaged road areas. To achieve greater disparity transformation efficiency,
golden section search and dynamic programming are utilized to estimate the
transformation parameters. Otsu's thresholding method is then used to extract
potential undamaged road areas from the transformed disparity map. The
disparities in the extracted areas are modeled by a quadratic surface using
least squares fitting. To improve disparity map modeling robustness, the
surface normal is also integrated into the surface modeling process.
Furthermore, random sample consensus is utilized to reduce the effects caused
by outliers. By comparing the difference between the actual and modeled
disparity maps, the potholes can be detected accurately. Finally, the point
clouds of the detected potholes are extracted from the reconstructed 3D road
surface. The experimental results show that the successful detection accuracy
of the proposed system is around 98.7% and the overall pixel-level accuracy is
approximately 99.6%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00907</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00907</id><created>2019-08-01</created><authors><author><keyname>Hagos</keyname><forenames>Yeman Brhane</forenames></author><author><keyname>Narayanan</keyname><forenames>Priya Lakshmi</forenames></author><author><keyname>Akarca</keyname><forenames>Ayse U.</forenames></author><author><keyname>Marafioti</keyname><forenames>Teresa</forenames></author><author><keyname>Yuan</keyname><forenames>Yinyin</forenames></author></authors><title>ConCORDe-Net: Cell Count Regularized Convolutional Neural Network for
  Cell Detection in Multiplex Immunohistochemistry Images</title><categories>eess.IV cs.CV cs.LG</categories><comments>MICCAI2019 accepted, 3 figures,8.5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In digital pathology, cell detection and classification are often
prerequisites to quantify cell abundance and explore tissue spatial
heterogeneity. However, these tasks are particularly challenging for multiplex
immunohistochemistry (mIHC) images due to high levels of variability in
staining, expression intensity, and inherent noise as a result of preprocessing
artefacts. We proposed a deep learning method to detect and classify cells in
mIHC whole-tumour slide images of breast cancer. Inspired by inception-v3, we
developed Cell COunt RegularizeD Convolutional neural Network (ConCORDe-Net)
which integrates conventional dice overlap and a new cell count loss function
for optimizing cell detection, followed by a multi-stage convolutional neural
network for cell classification. In total, 20447 cells, belonging to five cell
classes were annotated by experts from 175 patches extracted from 6
whole-tumour mIHC images. These patches were randomly split into training,
validation and testing sets. Using ConCORDe-Net, we obtained a cell detection
F1 score of 0.873, which is the best score compared to three state of the art
methods. In particular, ConCORDe-Net excels at detecting closely located and
weakly stained cells compared to other methods. Incorporating cell count loss
in the objective function regularizes the network to learn weak gradient
boundaries and separate weakly stained cells from background artefacts.
Moreover, cell classification accuracy of 96.5% was achieved. These results
support that incorporating problem-specific knowledge such as cell count into
deep learning-based cell detection architectures improve the robustness of the
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00919</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00919</id><created>2019-07-30</created><authors><author><keyname>Krpan</keyname><forenames>Matej</forenames></author><author><keyname>Kuzle</keyname><forenames>Igor</forenames></author></authors><title>Accurate Model of a Supercapacitor Bank for Power System Dynamics
  Studies</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an accurate and simple dynamic model of a supercapacitor bank
system for power system dynamics studies is presented. It is shown through
comprehensive simulations in MATLAB-Simulink that an ideal capacitor
representation is not always adequate. The proposed model is derived from a
detailed RC circuit representation. Furthermore, a complete control system of
the supercapacitor bank is also presented. The proposed model is easy to
integrate in any power system simulation software and consists of maximally 4
easy-to-obtain parameters. The performance of the proposed model in grid
frequency control and low-voltage ride through was tested in an IEEE 14-bus
test system in DIgSILENT PowerFactory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00936</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00936</id><created>2019-08-01</created><updated>2019-12-11</updated><authors><author><keyname>Hauptmann</keyname><forenames>Andreas</forenames></author><author><keyname>Adler</keyname><forenames>Jonas</forenames></author><author><keyname>Arridge</keyname><forenames>Simon</forenames></author><author><keyname>&#xd6;ktem</keyname><forenames>Ozan</forenames></author></authors><title>Multi-Scale Learned Iterative Reconstruction</title><categories>eess.IV cs.CV cs.NA cs.NE math.NA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based learned iterative reconstruction methods have recently been shown
to outperform classical reconstruction algorithms. Applicability of these
methods to large scale inverse problems is however limited by the available
memory for training and extensive training times due to computationally
expensive forward models. As a possible solution to these restrictions we
propose a multi-scale learned iterative reconstruction scheme that computes
iterates on discretisations of increasing resolution. This procedure does not
only reduce memory requirements, it also considerably speeds up reconstruction
and training times, but most importantly is scalable to large scale inverse
problems with non-trivial forward operators, such as those that arise in many
3D tomographic applications. In particular, we propose a hybrid network that
combines the multi-scale iterative approach with a particularly expressive
network architecture which in combination exhibits excellent scalability in 3D.
  Applicability of the algorithm is demonstrated for 3D cone beam computed
tomography from real measurement data of an organic phantom. Additionally, we
examine scalability and reconstruction quality in comparison to established
learned reconstruction methods in two dimensions for low dose computed
tomography on human phantoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00941</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00941</id><created>2019-07-02</created><updated>2019-08-05</updated><authors><author><keyname>Jiang</keyname><forenames>Jie</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark</forenames></author><author><keyname>Gilbert</keyname><forenames>Nigel</forenames></author></authors><title>Deep Learning Based Energy Disaggregation and On/Off Detection of
  Household Appliances</title><categories>cs.LG cs.MM eess.SP</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy disaggregation, a.k.a. Non-Intrusive Load Monitoring, aims to separate
the energy consumption of individual appliances from the readings of a mains
power meter measuring the total energy consumption of, e.g. a whole house.
Energy consumption of individual appliances can be useful in many applications,
e.g., providing appliance-level feedback to the end users to help them
understand their energy consumption and ultimately save energy. Recently, with
the availability of large-scale energy consumption datasets, various neural
network models such as convolutional neural networks and recurrent neural
networks have been investigated to solve the energy disaggregation problem.
Neural network models can learn complex patterns from large amounts of data and
have been shown to outperform the traditional machine learning methods such as
variants of hidden Markov models. However, current neural network methods for
energy disaggregation are either computational expensive or are not capable of
handling long-term dependencies. In this paper, we investigate the application
of the recently developed WaveNet models for the task of energy disaggregation.
Based on a real-world energy dataset collected from 20 households over two
years, we show that WaveNet models outperforms the state-of-the-art deep
learning methods proposed in the literature for energy disaggregation in terms
of both error measures and computational cost. On the basis of energy
disaggregation, we then investigate the performance of two deep-learning based
frameworks for the task of on/off detection which aims at estimating whether an
appliance is in operation or not. Based on the same dataset, we show that for
the task of on/off detection the second framework, i.e., directly training a
binary classifier, achieves better performance in terms of F1 score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00948</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00948</id><created>2019-08-02</created><authors><author><keyname>Lattner</keyname><forenames>Stefan</forenames></author><author><keyname>Grachten</keyname><forenames>Maarten</forenames></author></authors><title>High-Level Control of Drum Track Generation Using Learned Patterns of
  Rhythmic Interaction</title><categories>cs.SD cs.HC cs.LG eess.AS</categories><comments>Paper accepted at the IEEE Workshop on Applications of Signal
  Processing to Audio and Acoustics (WASPAA 2019), New Paltz, New York, U.S.A.,
  October 20-23; 6 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spurred by the potential of deep learning, computational music generation has
gained renewed academic interest. A crucial issue in music generation is that
of user control, especially in scenarios where the music generation process is
conditioned on existing musical material. Here we propose a model for
conditional kick drum track generation that takes existing musical material as
input, in addition to a low-dimensional code that encodes the desired relation
between the existing material and the new material to be generated. These
relational codes are learned in an unsupervised manner from a music dataset. We
show that codes can be sampled to create a variety of musically plausible kick
drum tracks and that the model can be used to transfer kick drum patterns from
one song to another. Lastly, we demonstrate that the learned codes are largely
invariant to tempo and time-shift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00968</identifier>
 <datestamp>2019-08-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00968</id><created>2019-08-02</created><authors><author><keyname>Ferrante</keyname><forenames>Francesco</forenames></author><author><keyname>Wang</keyname><forenames>Yongqiang</forenames></author></authors><title>Robust Almost Global Splay State Stabilization of Pulse Coupled
  Oscillators</title><categories>eess.SY cs.SY</categories><comments>This version corrects some typos in the proof of Proposition 3</comments><journal-ref>IEEE Transactions on Automatic Control 2017</journal-ref><doi>10.1109/TAC.2017.2677740</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical note deals with the problem of asymptotically stabilizing the
splay state configuration of a network of identical pulse coupled oscillators
through the design of the their phase response function. The network of pulse
coupled oscillators is modeled as a hybrid system. The design of the phase
response function is performed to achieve almost global asymptotic stability of
a set wherein oscillators' phases are evenly distributed on the unit circle. To
establish such a result, a novel Lyapunov function is proposed. Robustness with
respect to frequency perturbation is assessed. Finally, the effectiveness of
the proposed methodology is shown in an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00975</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00975</id><created>2019-08-02</created><authors><author><keyname>Lan</keyname><forenames>Hengrong</forenames></author><author><keyname>Jiang</keyname><forenames>Daohuai</forenames></author><author><keyname>Yang</keyname><forenames>Changchun</forenames></author><author><keyname>Gao</keyname><forenames>Fei</forenames></author></authors><title>Y-Net: A Hybrid Deep Learning Reconstruction Framework for Photoacoustic
  Imaging in vivo</title><categories>eess.IV cs.CV cs.LG</categories><comments>submitted the journal version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic imaging (PAI) is an emerging non-invasive imaging modality
combining the advantages of deep ultrasound penetration and high optical
contrast. Image reconstruction is an essential topic in PAI, which is
unfortunately an ill-posed problem due to the complex and unknown
optical/acoustic parameters in tissue. Conventional algorithms used in PAI
(e.g., delay-and-sum) provide a fast solution while many artifacts remain,
especially for linear array probe with limited-view issue. Convolutional neural
network (CNN) has shown state-of-the-art results in computer vision, and more
and more work based on CNN has been studied in medical image processing
recently. In this paper, we present a non-iterative scheme filling the gap
between existing direct-processing and post-processing methods, and propose a
new framework Y-Net: a CNN architecture to reconstruct the PA image by
optimizing both raw data and beamformed images once. The network connected two
encoders with one decoder path, which optimally utilizes more information from
raw data and beamformed image. The results of the test set showed good
performance compared with conventional reconstruction algorithms and other deep
learning methods. Our method is also validated with experiments both in-vitro
and in vivo, which still performs better than other existing methods. The
proposed Y-Net architecture also has high potential in medical image
reconstruction for other imaging modalities beyond PAI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00976</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00976</id><created>2019-08-02</created><updated>2020-01-16</updated><authors><author><keyname>Ramaswamy</keyname><forenames>Karthik R.</forenames></author><author><keyname>Hof</keyname><forenames>Paul M. J. Van den</forenames></author></authors><title>A local direct method for module identification in dynamic networks with
  correlated noise</title><categories>eess.SY cs.SY</categories><comments>Submitted for publication in IEEE Transactions on Automatic Control,
  2 August 2019. arXiv admin note: text overlap with arXiv:1809.07502.
  Provisionally accepted for publication in IEEE Transactions on Automatic
  Control</comments><msc-class>93A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The identification of local modules in dynamic networks with known topology
has recently been addressed by formulating conditions for arriving at
consistent estimates of the module dynamics, under the assumption of having
disturbances that are uncorrelated over the different nodes. The conditions
typically reflect the selection of a set of node signals that are taken as
predictor inputs in a MISO identification setup. In this paper an extension is
made to arrive at an identification setup for the situation that process noises
on the different node signals can be correlated with each other. In this
situation the local module may need to be embedded in a MIMO identification
setup for arriving at a consistent estimate with maximum likelihood properties.
This requires the proper treatment of confounding variables. The result is a
set of algorithms that, based on the given network topology and disturbance
correlation structure, selects an appropriate set of node signals as predictor
inputs and outputs in a MISO or MIMO identification setup. Three algorithms are
presented that differ in their approach of selecting measured node signals.
Either a maximum or a minimum number of measured node signals can be
considered, as well as a preselected set of measured nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00983</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00983</id><created>2019-08-02</created><authors><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>Cao</keyname><forenames>Xiaozhi</forenames></author><author><keyname>Cho</keyname><forenames>Jaejin</forenames></author><author><keyname>Zhang</keyname><forenames>Zijing</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Bilgic</keyname><forenames>Berkin</forenames></author></authors><title>Highly efficient MRI through multi-shot echo planar imaging</title><categories>eess.IV physics.med-ph</categories><comments>13 pages, 10 figures</comments><journal-ref>Proceedings Volume 11138, Wavelets and Sparsity XVIII; 1113818
  (2019)</journal-ref><doi>10.1117/12.2527183</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-shot echo planar imaging (msEPI) is a promising approach to achieve
high in-plane resolution with high sampling efficiency and low T2* blurring.
However, due to the geometric distortion, shot-to-shot phase variations and
potential subject motion, msEPI continues to be a challenge in MRI. In this
work, we introduce acquisition and reconstruction strategies for robust,
high-quality msEPI without phase navigators. We propose Blip Up-Down
Acquisition (BUDA) using interleaved blip-up and -down phase encoding, and
incorporate B0 forward-modeling into Hankel structured low-rank model to enable
distortion- and navigator-free msEPI. We improve the acquisition efficiency and
reconstruction quality by incorporating simultaneous multi-slice acquisition
and virtual-coil reconstruction into the BUDA technique. We further combine
BUDA with the novel RF-encoded gSlider acquisition, dubbed BUDA-gSlider, to
achieve rapid high isotropic-resolution MRI. Deploying BUDA-gSlider with
model-based reconstruction allows for distortion-free whole-brain 1mm isotropic
T2 mapping in about 1 minute. It also provides whole-brain 1mm isotropic
diffusion imaging with high geometric fidelity and SNR efficiency. We finally
incorporate sinusoidal wave gradients during the EPI readout to better use coil
sensitivity encoding with controlled aliasing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00999</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.00999</id><created>2019-08-02</created><updated>2019-09-14</updated><authors><author><keyname>Tang</keyname><forenames>Hao</forenames></author><author><keyname>Xu</keyname><forenames>Dan</forenames></author><author><keyname>Liu</keyname><forenames>Gaowen</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Sebe</keyname><forenames>Nicu</forenames></author><author><keyname>Yan</keyname><forenames>Yan</forenames></author></authors><title>Cycle In Cycle Generative Adversarial Networks for Keypoint-Guided Image
  Generation</title><categories>cs.CV cs.LG eess.IV</categories><comments>9 pages, 8 figures, accepted to ACM MM 2019</comments><journal-ref>ACM MM 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a novel Cycle In Cycle Generative Adversarial
Network (C$^2$GAN) for the task of keypoint-guided image generation. The
proposed C$^2$GAN is a cross-modal framework exploring a joint exploitation of
the keypoint and the image data in an interactive manner. C$^2$GAN contains two
different types of generators, i.e., keypoint-oriented generator and
image-oriented generator. Both of them are mutually connected in an end-to-end
learnable fashion and explicitly form three cycled sub-networks, i.e., one
image generation cycle and two keypoint generation cycles. Each cycle not only
aims at reconstructing the input domain, and also produces useful output
involving in the generation of another cycle. By so doing, the cycles constrain
each other implicitly, which provides complementary information from the two
different modalities and brings extra supervision across cycles, thus
facilitating more robust optimization of the whole network. Extensive
experimental results on two publicly available datasets, i.e., Radboud Faces
and Market-1501, demonstrate that our approach is effective to generate more
photo-realistic images compared with state-of-the-art models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01010</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01010</id><created>2019-08-01</created><updated>2020-01-15</updated><authors><author><keyname>Zhang</keyname><forenames>Chen</forenames></author><author><keyname>Jin</keyname><forenames>Bangti</forenames></author></authors><title>Probabilistic Residual Learning for Aleatoric Uncertainty in Image
  Restoration</title><categories>eess.IV cs.LG stat.ML</categories><comments>this version is outdated, and we are completely reorganizing the
  paper and split it into several different pieces of work. Thus, we prefer to
  withdraw it from arxiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aleatoric uncertainty is an intrinsic property of ill-posed inverse and
imaging problems. Its quantification is vital for assessing the reliability of
relevant point estimates. In this paper, we propose an efficient framework for
quantifying aleatoric uncertainty for deep residual learning and showcase its
significant potential on image restoration. In the framework, we divide the
conditional probability modeling for the residual variable into a deterministic
homo-dimensional level, a stochastic low-dimensional level and a merging level.
The low-dimensionality is especially suitable for sparse correlation between
image pixels, enables efficient sampling for high dimensional problems and acts
as a regularizer for the distribution. Preliminary numerical experiments show
that the proposed method can give not only state-of-the-art point estimates of
image restoration but also useful associated uncertainty information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01046</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01046</id><created>2019-08-02</created><updated>2019-08-06</updated><authors><author><keyname>Corso</keyname><forenames>Anthony</forenames></author><author><keyname>Du</keyname><forenames>Peter</forenames></author><author><keyname>Driggs-Campbell</keyname><forenames>Katherine</forenames></author><author><keyname>Kochenderfer</keyname><forenames>Mykel J.</forenames></author></authors><title>Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle
  Validation</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML</categories><comments>Appears in IEEE ITSC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining possible failure scenarios is a critical step in the evaluation
of autonomous vehicle systems. Real-world vehicle testing is commonly employed
for autonomous vehicle validation, but the costs and time requirements are
high. Consequently, simulation-driven methods such as Adaptive Stress Testing
(AST) have been proposed to aid in validation. AST formulates the problem of
finding the most likely failure scenarios as a Markov decision process, which
can be solved using reinforcement learning. In practice, AST tends to find
scenarios where failure is unavoidable and tends to repeatedly discover the
same types of failures of a system. This work addresses these issues by
encoding domain relevant information into the search procedure. With this
modification, the AST method discovers a larger and more expressive subset of
the failure space when compared to the original AST formulation. We show that
our approach is able to identify useful failure scenarios of an autonomous
vehicle policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01047</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01047</id><created>2019-08-02</created><updated>2019-08-22</updated><authors><author><keyname>Alfatlawi</keyname><forenames>Mustaffa</forenames></author><author><keyname>Srivastava</keyname><forenames>Vaibhav</forenames></author></authors><title>An Incremental Approach to Online Dynamic Mode Decomposition for
  Time-Varying Systems with Applications to EEG Data Modeling</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic Mode Decomposition (DMD) is a data-driven technique to identify a low
dimensional linear time invariant dynamics underlying high-dimensional data.
For systems in which such underlying low-dimensional dynamics is time-varying,
a time-invariant approximation of such dynamics computed through standard DMD
techniques may not be appropriate. We focus on DMD techniques for such
time-varying systems and develop incremental algorithms for systems without and
with exogenous control inputs. We consider two classes of algorithms that rely
on (i) a discount factor on previous observations, and (ii) a sliding window of
observations. Our algorithms leverage existing techniques for incremental
singular value decomposition and allow us to determine an appropriately reduced
model at each time and are applicable even if data matrix is singular. We apply
the developed algorithms for autonomous systems to Electroencephalographic
(EEG) data and demonstrate their effectiveness in terms reconstruction and
prediction. Our algorithms for non-autonomous systems are illustrated using
randomly generated linear time-varying systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01059</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01059</id><created>2019-07-30</created><updated>2019-09-09</updated><authors><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author><author><keyname>Du</keyname><forenames>Linkang</forenames></author><author><keyname>Cheng</keyname><forenames>Peng</forenames></author><author><keyname>Chen</keyname><forenames>Jiming</forenames></author></authors><title>Privacy-preserving Distributed Machine Learning via Local Randomization
  and ADMM Perturbation</title><categories>cs.LG cs.CR cs.DC cs.MA cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the proliferation of training data, distributed machine learning (DML)
is becoming more competent for large-scale learning tasks. However, privacy
concerns have to be given priority in DML, since training data may contain
sensitive information of users. In this paper, we propose a privacy-preserving
ADMM-based DML framework with two novel features: First, we remove the
assumption commonly made in the literature that the users trust the server
collecting their data. Second, the framework provides heterogeneous privacy for
users depending on data's sensitive levels and servers' trust degrees. The
challenging issue is to keep the accumulation of privacy losses over ADMM
iterations minimal. In the proposed framework, a local randomization approach,
which is differentially private, is adopted to provide users with
self-controlled privacy guarantee for the most sensitive information. Further,
the ADMM algorithm is perturbed through a combined noise-adding method, which
simultaneously preserves privacy for users' less sensitive information and
strengthens the privacy protection of the most sensitive information. We
provide detailed analyses on the performance of the trained model according to
its generalization error. Finally, we conduct extensive experiments using
real-world datasets to validate the theoretical results and evaluate the
classification performance of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01060</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01060</id><created>2019-08-02</created><authors><author><keyname>Li</keyname><forenames>Xinjian</forenames></author><author><keyname>Dalmia</keyname><forenames>Siddharth</forenames></author><author><keyname>Black</keyname><forenames>Alan W.</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Multilingual Speech Recognition with Corpus Relatedness Sampling</title><categories>cs.CL cs.SD eess.AS</categories><comments>Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilingual acoustic models have been successfully applied to low-resource
speech recognition. Most existing works have combined many small corpora
together and pretrained a multilingual model by sampling from each corpus
uniformly. The model is eventually fine-tuned on each target corpus. This
approach, however, fails to exploit the relatedness and similarity among
corpora in the training set. For example, the target corpus might benefit more
from a corpus in the same domain or a corpus from a close language. In this
work, we propose a simple but useful sampling strategy to take advantage of
this relatedness. We first compute the corpus-level embeddings and estimate the
similarity between each corpus. Next, we start training the multilingual model
with uniform-sampling from each corpus at first, then we gradually increase the
probability to sample from related corpora based on its similarity with the
target corpus. Finally, the model would be fine-tuned automatically on the
target corpus. Our sampling strategy outperforms the baseline multilingual
model on 16 low-resource tasks. Additionally, we demonstrate that our corpus
embeddings capture the language and domain information of each corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01067</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01067</id><created>2019-08-02</created><authors><author><keyname>Li</keyname><forenames>Xinjian</forenames></author><author><keyname>Zhou</keyname><forenames>Zhong</forenames></author><author><keyname>Dalmia</keyname><forenames>Siddharth</forenames></author><author><keyname>Black</keyname><forenames>Alan W.</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>SANTLR: Speech Annotation Toolkit for Low Resource Languages</title><categories>cs.CL cs.SD eess.AS</categories><comments>Interspeech 2019 (Show and Tell)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While low resource speech recognition has attracted a lot of attention from
the speech community, there are a few tools available to facilitate low
resource speech collection. In this work, we present SANTLR: Speech Annotation
Toolkit for Low Resource Languages. It is a web-based toolkit which allows
researchers to easily collect and annotate a corpus of speech in a low resource
language. Annotators may use this toolkit for two purposes: transcription or
recording. In transcription, annotators would transcribe audio files provided
by the researchers; in recording, annotators would record their voice by
reading provided texts. We highlight two properties of this toolkit. First,
SANTLR has a very user-friendly User Interface (UI). Both researchers and
annotators may use this simple web interface to interact. There is no
requirement for the annotators to have any expertise in audio or text
processing. The toolkit would handle all preprocessing and postprocessing
steps. Second, we employ a multi-step ranking mechanism facilitate the
annotation process. In particular, the toolkit would give higher priority to
utterances which are easier to annotate and are more beneficial to achieving
the goal of the annotation, e.g. quickly training an acoustic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01073</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01073</id><created>2019-08-02</created><updated>2019-09-09</updated><authors><author><keyname>AskariHemmat</keyname><forenames>MohammadHossein</forenames></author><author><keyname>Honari</keyname><forenames>Sina</forenames></author><author><keyname>Rouhier</keyname><forenames>Lucas</forenames></author><author><keyname>Perone</keyname><forenames>Christian S.</forenames></author><author><keyname>Cohen-Adad</keyname><forenames>Julien</forenames></author><author><keyname>Savaria</keyname><forenames>Yvon</forenames></author><author><keyname>David</keyname><forenames>Jean-Pierre</forenames></author></authors><title>U-Net Fixed-Point Quantization for Medical Image Segmentation</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted to MICCAI 2019's Hardware Aware Learning for Medical Imaging
  and Computer Assisted Intervention</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model quantization is leveraged to reduce the memory consumption and the
computation time of deep neural networks. This is achieved by representing
weights and activations with a lower bit resolution when compared to their high
precision floating point counterparts. The suitable level of quantization is
directly related to the model performance. Lowering the quantization precision
(e.g. 2 bits), reduces the amount of memory required to store model parameters
and the amount of logic required to implement computational blocks, which
contributes to reducing the power consumption of the entire system. These
benefits typically come at the cost of reduced accuracy. The main challenge is
to quantize a network as much as possible, while maintaining the performance
accuracy. In this work, we present a quantization method for the U-Net
architecture, a popular model in medical image segmentation. We then apply our
quantization algorithm to three datasets: (1) the Spinal Cord Gray Matter
Segmentation (GM), (2) the ISBI challenge for segmentation of neuronal
structures in Electron Microscopic (EM), and (3) the public National Institute
of Health (NIH) dataset for pancreas segmentation in abdominal CT scans. The
reported results demonstrate that with only 4 bits for weights and 6 bits for
activations, we obtain 8 fold reduction in memory requirements while loosing
only 2.21%, 0.57% and 2.09% dice overlap score for EM, GM and NIH datasets
respectively. Our fixed point quantization provides a flexible trade off
between accuracy and memory requirement which is not provided by previous
quantization methods for U-Net such as TernaryNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01078</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01078</id><created>2019-08-02</created><authors><author><keyname>Dineva</keyname><forenames>Adrienn</forenames></author><author><keyname>Mosavi</keyname><forenames>Amir</forenames></author><author><keyname>Gyimesi</keyname><forenames>Mate</forenames></author><author><keyname>Vajda</keyname><forenames>Istvan</forenames></author></authors><title>Multi-label Classification for Fault Diagnosis of Rotating Electrical
  Machines</title><categories>cs.LG eess.SP</categories><comments>30 pages, 6 figures</comments><msc-class>68T01</msc-class><doi>10.20944/preprints201908.0029.v1</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Primary importance is devoted to Fault Detection and Diagnosis (FDI) of
electrical machine and drive systems in modern industrial automation. The
widespread use of Machine Learning techniques has made it possible to replace
traditional motor fault detection techniques with more efficient solutions that
are capable of early fault recognition by using large amounts of sensory data.
However, the detection of concurrent failures is still a challenge in the
presence of disturbing noises or when the multiple faults cause overlapping
features. The contribution of this work is to propose a novel methodology using
multi-label classification method for simultaneously diagnosing multiple faults
and evaluating the fault severity under noisy conditions. Performance of
various multi-label classification models are compared. Current and vibration
signals are acquired under normal and fault conditions. The applicability of
the proposed method is experimentally validated under diverse fault conditions
such as unbalance and misalignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01080</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01080</id><created>2019-08-02</created><authors><author><keyname>Mangal</keyname><forenames>Sanidhya</forenames></author><author><keyname>Modak</keyname><forenames>Rahul</forenames></author><author><keyname>Joshi</keyname><forenames>Poorva</forenames></author></authors><title>LSTM Based Music Generation System</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>6 pages, 11 figures</comments><journal-ref>IARJSET: Vol. 6, Issue 5 (2019) 47-54</journal-ref><doi>10.17148/IARJSET.2019.6508</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, music was treated as an analogue signal and was generated
manually. In recent years, music is conspicuous to technology which can
generate a suite of music automatically without any human intervention. To
accomplish this task, we need to overcome some technical challenges which are
discussed descriptively in this paper. A brief introduction about music and its
components is provided in the paper along with the citation and analysis of
related work accomplished by different authors in this domain. Main objective
of this paper is to propose an algorithm which can be used to generate musical
notes using Recurrent Neural Networks (RNN), principally Long Short-Term Memory
(LSTM) networks. A model is designed to execute this algorithm where data is
represented with the help of musical instrument digital interface (MIDI) file
format for easier access and better understanding. Preprocessing of data before
feeding it into the model, revealing methods to read, process and prepare MIDI
files for input are also discussed. The model used in this paper is used to
learn the sequences of polyphonic musical notes over a single-layered LSTM
network. The model must have the potential to recall past details of a musical
sequence and its structure for better learning. Description of layered
architecture used in LSTM model and its intertwining connections to develop a
neural network is presented in this work. This paper imparts a peek view of
distributions of weights and biases in every layer of the model along with a
precise representation of losses and accuracy at each step and batches. When
the model was thoroughly analyzed, it produced stellar results in composing new
melodies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01104</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01104</id><created>2019-08-02</created><updated>2019-11-27</updated><authors><author><keyname>Liao</keyname><forenames>Haofu</forenames></author><author><keyname>Lin</keyname><forenames>Wei-An</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author></authors><title>ADN: Artifact Disentanglement Network for Unsupervised Metal Artifact
  Reduction</title><categories>eess.IV cs.CV</categories><comments>This is the extended version of arXiv:1906.01806. This paper is
  accepted to IEEE Transactions on Medical Imaging</comments><doi>10.1109/TMI.2019.2933425</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Current deep neural network based approaches to computed tomography (CT)
metal artifact reduction (MAR) are supervised methods that rely on synthesized
metal artifacts for training. However, as synthesized data may not accurately
simulate the underlying physical mechanisms of CT imaging, the supervised
methods often generalize poorly to clinical applications. To address this
problem, we propose, to the best of our knowledge, the first unsupervised
learning approach to MAR. Specifically, we introduce a novel artifact
disentanglement network that disentangles the metal artifacts from CT images in
the latent space. It supports different forms of generations (artifact
reduction, artifact transfer, and self-reconstruction, etc.) with specialized
loss functions to obviate the need for supervision with synthesized data.
Extensive experiments show that when applied to a synthesized dataset, our
method addresses metal artifacts significantly better than the existing
unsupervised models designed for natural image-to-image translation problems,
and achieves comparable performance to existing supervised models for MAR. When
applied to clinical datasets, our method demonstrates better generalization
ability over the supervised models. The source code of this paper is publicly
available at https://github.com/liaohaofu/adn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01111</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01111</id><created>2019-08-02</created><authors><author><keyname>Wu</keyname><forenames>Dan</forenames></author><author><keyname>Wang</keyname><forenames>Bin</forenames></author></authors><title>Influence of Load Models on Equilibria, Stability and Algebraic
  Manifolds of Power System Differential-Algebraic System</title><categories>eess.SY cs.SY</categories><comments>This manuscript has been accepted by 57th Annual Allerton Conference
  on Communication, Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Load models have a great impact on voltage behaviors as well as power system
transient dynamics. Extensive work has been done on this topic, proposing
appropriate load models and capturing better load behaviors during transient.
This paper presents a comprehensive study to investigate the geometric and
topological changes induced by different load models for the traditional power
system differential-algebraic equations. Specifically, we attempt to reveal the
deformation of equilibria, stability regions, and algebraic manifolds during a
continuous evolution of load model. Several findings are presented in the
paper, some of which countering traditional recognitions and intuitions. A
major discovery is that the load model with a large proportion of constant
impedance and a small proportion of constant power exhibits much more complex
features than the load model with the reversed proportions of impedance and
power. The increase of complexity is thoroughly recorded and investigated by
the changes of geometric properties and mutations of topological invariants in
the sense of equilibria, stability regions, and algebraic manifolds for the DAE
system. However, most of the changes seem to occur on unstable components of
algebraic manifolds or near the singular boundary surfaces, suggesting a
limited variation of dynamical behaviors on the stable component.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01129</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01129</id><created>2019-08-03</created><updated>2020-01-27</updated><authors><author><keyname>Dehghanpour</keyname><forenames>Kaveh</forenames></author><author><keyname>Yuan</keyname><forenames>Yuxuan</forenames></author><author><keyname>Bu</keyname><forenames>Fankun</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author></authors><title>Statistical Modeling of Networked Solar Resources for Assessing and
  Mitigating Risk of Interdependent Inverter Tripping Events in Distribution
  Grids</title><categories>eess.SY cs.SY</categories><doi>10.1109/TPWRS.2020.2973380</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is speculated that higher penetration of inverter-based distributed
photo-voltaic (PV) power generators can increase the risk of tripping events
due to voltage fluctuations. To quantify this risk utilities need to solve the
interactive equations of tripping events for networked PVs in real-time.
However, these equations are non-differentiable, nonlinear, and exponentially
complex, and thus, cannot be used as a tractable basis for solar curtailment
prediction and mitigation. Furthermore, load/PV power values might not be
available in real-time due to limited grid observability, which further
complicates tripping event prediction. To address these challenges, we have
employed Chebyshev's inequality to obtain an alternative probabilistic model
for quantifying the risk of tripping for networked PVs. The proposed model
enables operators to estimate the probability of interdependent inverter
tripping events using only PV/load statistics and in a scalable manner.
Furthermore, by integrating this probabilistic model into an optimization
framework, countermeasures are designed to mitigate massive interdependent
tripping events. Since the proposed model is parameterized using only the
statistical characteristics of nodal active/reactive powers, it is especially
beneficial in practical systems, which have limited real-time observability.
Numerical experiments have been performed employing real data and feeder models
to verify the performance of the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01134</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01134</id><created>2019-08-03</created><updated>2019-08-05</updated><authors><author><keyname>Majee</keyname><forenames>Sudeb</forenames></author><author><keyname>Jain</keyname><forenames>Subit K</forenames></author><author><keyname>Ray</keyname><forenames>Rajendra K</forenames></author><author><keyname>Majee</keyname><forenames>Ananta K</forenames></author></authors><title>A Fuzzy Edge Detector Driven Telegraph Total Variation Model For Image
  Despeckling</title><categories>eess.IV cs.NA math.AP math.NA</categories><comments>19 pages, 4 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speckle noise suppression is a challenging and crucial pre-processing stage
for higher-level image analysis. In this work, a new attempt has been made
using telegraph total variation equation and fuzzy set theory for speckle noise
suppression. The intuitionistic fuzzy divergence (IFD) function has been used
to distinguish between edges and noise. To the best of the author's knowledge,
most of the studies on multiplicative speckle noise removal process focus on
only diffusion-based filters, and little attention has been paid to the study
of fuzzy set theory. The proposed approach enjoy the benefits of both telegraph
total variation equation and fuzzy edge detector, which is not only robust to
noise but also preserves image structural details. Moreover, we establish the
existence and uniqueness of a weak solution of the regularized version of the
proposed model using Schauder fixed point theorem. With the proposed model,
despeckling is carried out on natural and Synthetic Aperture Radar (SAR)
images. The experimental results of the proposed model are reported, which
found better in terms of noise suppression and detail/edge preservation, with
respect to the existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01146</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01146</id><created>2019-08-03</created><authors><author><keyname>Wu</keyname><forenames>Wentai</forenames></author><author><keyname>He</keyname><forenames>Ligang</forenames></author><author><keyname>Lin</keyname><forenames>Weiwei</forenames></author></authors><title>Local Trend Inconsistency: A Prediction-driven Approach to Unsupervised
  Anomaly Detection in Multi-seasonal Time Series</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>10 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On-line detection of anomalies in time series is a key technique in various
event-sensitive scenarios such as robotic system monitoring, smart sensor
networks and data center security. However, the increasing diversity of data
sources and demands are making this task more challenging than ever. First, the
rapid increase of unlabeled data makes supervised learning no longer suitable
in many cases. Second, a great portion of time series have complex seasonality
features. Third, on-line anomaly detection needs to be fast and reliable. In
view of this, we in this paper adopt an unsupervised prediction-driven approach
on the basis of a backbone model combining a series decomposition part and an
inference part. We then propose a novel metric, Local Trend Inconsistency
(LTI), along with a detection algorithm that efficiently computes LTI
chronologically along the series and marks each data point with a score
indicating its probability of being anomalous. We experimentally evaluated our
algorithm on datasets from UCI public repository and a production environment.
The result shows that our scheme outperforms several representative anomaly
detection algorithms in Area Under Curve (AUC) metric with decent time
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01161</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01161</id><created>2019-08-03</created><authors><author><keyname>Razak</keyname><forenames>Rihab Abdul</forenames></author><author><keyname>Sukumar</keyname><forenames>Srikant</forenames></author><author><keyname>Chung</keyname><forenames>Hoam</forenames></author></authors><title>Distributed Adaptive Coverage Control of Differential Drive Robotic
  Sensors</title><categories>eess.SY cs.MA cs.RO cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the deployment of multiple mobile robots in
order to autonomously cover a region Q. The region to be covered is described
using a density function which may not be apriori known. In this paper, we pose
the coverage problem as an optimization problem over some space of functions on
Q. In particular, we look at L 2 -distance based coverage algorithm and derive
adaptive control laws for the same. We also propose a modified adaptive control
law incorporating consensus for better parameter convergence. We implement the
algorithms on real differential drive robots with both simulated density
function as well as density function implemented using light sources. We also
compare the L 2 -distance based method with the locational optimization method
using experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01166</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01166</id><created>2019-08-03</created><authors><author><keyname>Zhang</keyname><forenames>Menglei</forenames></author><author><keyname>Liu</keyname><forenames>Zhou</forenames></author><author><keyname>Yu</keyname><forenames>Lei</forenames></author></authors><title>CRNet: Image Super-Resolution Using A Convolutional Sparse Coding
  Inspired Network</title><categories>eess.IV cs.CV</categories><comments>10 pages, 12 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Sparse Coding (CSC) has been attracting more and more attention
in recent years, for making full use of image global correlation to improve
performance on various computer vision applications. However, very few studies
focus on solving CSC based image Super-Resolution (SR) problem. As a
consequence, there is no significant progress in this area over a period of
time. In this paper, we exploit the natural connection between CSC and
Convolutional Neural Networks (CNN) to address CSC based image SR.
Specifically, Convolutional Iterative Soft Thresholding Algorithm (CISTA) is
introduced to solve CSC problem and it can be implemented using CNN
architectures. Then we develop a novel CSC based SR framework analogy to the
traditional SC based SR methods. Two models inspired by this framework are
proposed for pre-/post-upsampling SR, respectively. Compared with recent
state-of-the-art SR methods, both of our proposed models show superior
performance in terms of both quantitative and qualitative measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01174</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01174</id><created>2019-08-03</created><authors><author><keyname>Liu</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Guo</keyname><forenames>Zhenhua</forenames></author><author><keyname>Li</keyname><forenames>Site</forenames></author><author><keyname>Kong</keyname><forenames>Lingsheng</forenames></author><author><keyname>Jia</keyname><forenames>Ping</forenames></author><author><keyname>You</keyname><forenames>Jane</forenames></author><author><keyname>Kumar</keyname><forenames>B. V. K.</forenames></author></authors><title>Permutation-invariant Feature Restructuring for Correlation-aware Image
  Set-based Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted to ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of comparing the similarity of image sets with
variable-quantity, quality and un-ordered heterogeneous images. We use feature
restructuring to exploit the correlations of both inner$\&amp;$inter-set images.
Specifically, the residual self-attention can effectively restructure the
features using the other features within a set to emphasize the discriminative
images and eliminate the redundancy. Then, a sparse/collaborative
learning-based dependency-guided representation scheme reconstructs the probe
features conditional to the gallery features in order to adaptively align the
two sets. This enables our framework to be compatible with both verification
and open-set identification. We show that the parametric self-attention network
and non-parametric dictionary learning can be trained end-to-end by a unified
alternative optimization scheme, and that the full framework is
permutation-invariant. In the numerical experiments we conducted, our method
achieves top performance on competitive image set/video-based face recognition
and person re-identification benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01176</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01176</id><created>2019-08-03</created><authors><author><keyname>Sathish</keyname><forenames>Rachana</forenames></author><author><keyname>Rajan</keyname><forenames>Ronnie</forenames></author><author><keyname>Vupputuri</keyname><forenames>Anusha</forenames></author><author><keyname>Ghosh</keyname><forenames>Nirmalya</forenames></author><author><keyname>Sheet</keyname><forenames>Debdoot</forenames></author></authors><title>Adversarially Trained Convolutional Neural Networks for Semantic
  Segmentation of Ischaemic Stroke Lesion using Multisequence Magnetic
  Resonance Imaging</title><categories>eess.IV cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Ischaemic stroke is a medical condition caused by occlusion of blood supply
to the brain tissue thus forming a lesion. A lesion is zoned into a core
associated with irreversible necrosis typically located at the center of the
lesion, while reversible hypoxic changes in the outer regions of the lesion are
termed as the penumbra. Early estimation of core and penumbra in ischaemic
stroke is crucial for timely intervention with thrombolytic therapy to reverse
the damage and restore normalcy. Multisequence magnetic resonance imaging (MRI)
is commonly employed for clinical diagnosis. However, a sequence singly has not
been found to be sufficiently able to differentiate between core and penumbra,
while a combination of sequences is required to determine the extent of the
damage. The challenge, however, is that with an increase in the number of
sequences, it cognitively taxes the clinician to discover symptomatic
biomarkers in these images. In this paper, we present a data-driven fully
automated method for estimation of core and penumbra in ischaemic lesions using
diffusion-weighted imaging (DWI) and perfusion-weighted imaging (PWI) sequence
maps of MRI. The method employs recent developments in convolutional neural
networks (CNN) for semantic segmentation in medical images. In the absence of
availability of a large amount of labeled data, the CNN is trained using an
adversarial approach employing cross-entropy as a segmentation loss along with
losses aggregated from three discriminators of which two employ relativistic
visual Turing test. This method is experimentally validated on the ISLES-2015
dataset through three-fold cross-validation to obtain with an average Dice
score of 0.82 and 0.73 for segmentation of penumbra and core respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01182</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01182</id><created>2019-08-03</created><authors><author><keyname>Zeng</keyname><forenames>Tengchan</forenames></author><author><keyname>Semiari</keyname><forenames>Omid</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>Dependence Control for Reliability Optimization in Vehicular Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular networks will play an important role in enhancing road safety,
improving transportation efficiency, and providing seamless Internet service
for users on the road. Reaping the benefit of vehicular networks is contingent
upon meeting stringent wireless communication performance requirements,
particularly in terms of delay and reliability. In this paper, a dependence
control mechanism is proposed to improve the overall reliability of vehicular
networks. In particular, the dependence between the communication delays of
different vehicle-to-vehicle (V2V) links is first modeled. Then, the concept of
a concordance order, stemming from stochastic ordering theory, is introduced to
show that a higher dependence can lead to a better reliability. Using this
insight, a power allocation problem is formulated to maximize the concordance,
thereby optimizing the overall communication reliability of the V2V system. To
obtain an efficient solution to the power allocation problem, a dual update
method is introduced. Simulation results verify the effectiveness of performing
dependence control for reliability optimization in a vehicular network, and
show that the proposed mechanism can achieve up to 25% reliability gain
compared to a baseline system that uses a random power allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01244</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01244</id><created>2019-08-03</created><authors><author><keyname>Baharani</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Biglarbegian</keyname><forenames>Mehrdad</forenames></author><author><keyname>Parkhideh</keyname><forenames>Babak</forenames></author><author><keyname>Tabkhi</keyname><forenames>Hamed</forenames></author></authors><title>Real-time Deep Learning at the Edge for Scalable Reliability Modeling of
  Si-MOSFET Power Electronics Converters</title><categories>cs.LG eess.SP</categories><comments>2019 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</comments><journal-ref>IEEE Internet of Things Journal, 2019</journal-ref><doi>10.1109/JIOT.2019.2896174</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the significant growth of advanced high-frequency power converters,
on-line monitoring and active reliability assessment of power electronic
devices are extremely crucial. This article presents a transformative approach,
named Deep Learning Reliability Awareness of Converters at the Edge (Deep
RACE), for real-time reliability modeling and prediction of high-frequency
MOSFET power electronic converters. Deep RACE offers a holistic solution which
comprises algorithm advances, and full system integration (from the cloud down
to the edge node) to create a near real-time reliability awareness. On the
algorithm side, this paper proposes a deep learning algorithmic solution based
on stacked LSTM for collective reliability training and inference across
collective MOSFET converters based on device resistance changes. Deep RACE also
proposes an integrative edge-to-cloud solution to offer a scalable
decentralized devices-specific reliability monitoring, awareness, and modeling.
The MOSFET convertors are IoT devices which have been empowered with edge
real-time deep learning processing capabilities. The proposed Deep RACE
solution has been prototyped and implemented through learning from MOSFET data
set provided by NASA. Our experimental results show an average miss prediction
of $8.9\%$ over five different devices which is a much higher accuracy compared
to well-known classical approaches (Kalman Filter, and Particle Filter). Deep
RACE only requires $26ms$ processing time and $1.87W$ computing power on Edge
IoT device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01275</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01275</id><created>2019-08-04</created><updated>2019-09-04</updated><authors><author><keyname>Haj-Ali</keyname><forenames>Ameer</forenames></author><author><keyname>Ahmed</keyname><forenames>Nesreen K.</forenames></author><author><keyname>Willke</keyname><forenames>Ted</forenames></author><author><keyname>Gonzalez</keyname><forenames>Joseph</forenames></author><author><keyname>Asanovic</keyname><forenames>Krste</forenames></author><author><keyname>Stoica</keyname><forenames>Ion</forenames></author></authors><title>A View on Deep Reinforcement Learning in System Optimization</title><categories>cs.LG cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world systems problems require reasoning about the long term
consequences of actions taken to configure and manage the system. These
problems with delayed and often sequentially aggregated reward, are often
inherently reinforcement learning problems and present the opportunity to
leverage the recent substantial advances in deep reinforcement learning.
However, in some cases, it is not clear why deep reinforcement learning is a
good fit for the problem. Sometimes, it does not perform better than the
state-of-the-art solutions. And in other cases, random search or greedy
algorithms could outperform deep reinforcement learning. In this paper, we
review, discuss, and evaluate the recent trends of using deep reinforcement
learning in system optimization. We propose a set of essential metrics to guide
future works in evaluating the efficacy of using deep reinforcement learning in
system optimization. Our evaluation includes challenges, the types of problems,
their formulation in the deep reinforcement learning setting, embedding, the
model used, efficiency, and robustness. We conclude with a discussion on open
challenges and potential directions for pushing further the integration of
reinforcement learning in system optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01279</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01279</id><created>2019-08-04</created><updated>2019-09-16</updated><authors><author><keyname>Efremova</keyname><forenames>Dina B.</forenames></author><author><keyname>Konovalov</keyname><forenames>Dmitry A.</forenames></author><author><keyname>Siriapisith</keyname><forenames>Thanongchai</forenames></author><author><keyname>Kusakunniran</keyname><forenames>Worapan</forenames></author><author><keyname>Haddawy</keyname><forenames>Peter</forenames></author></authors><title>Automatic segmentation of kidney and liver tumors in CT images</title><categories>eess.IV cs.CV</categories><comments>Method description manuscript for our test predictions for the 2019
  Kidney Tumor Segmentation Challenge, https://kits19.grand-challenge.org/home/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic segmentation of hepatic lesions in computed tomography (CT) images
is a challenging task to perform due to heterogeneous, diffusive shape of
tumors and complex background. To address the problem more and more researchers
rely on assistance of deep convolutional neural networks (CNN) with 2D or 3D
type architecture that have proven to be effective in a wide range of computer
vision tasks, including medical image processing. In this technical report, we
carry out research focused on more careful approach to the process of learning
rather than on complex architecture of the CNN. We have chosen MICCAI 2017 LiTS
dataset for training process and the public 3DIRCADb dataset for validation of
our method. The proposed algorithm reached DICE score 78.8% on the 3DIRCADb
dataset. The described method was then applied to the 2019 Kidney Tumor
Segmentation (KiTS-2019) challenge, where our single submission achieved 96.38%
for kidney and 67.38% for tumor Dice scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01284</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01284</id><created>2019-08-04</created><updated>2019-11-18</updated><authors><author><keyname>Xie</keyname><forenames>Yaohua</forenames></author></authors><title>Solving equations after dense scan to improve the resolutions of
  microscopes</title><categories>eess.IV</categories><comments>This work has been patented, thereby is not open-source</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Super-resolution techniques overcome the diffraction-limit and get very high
resolutions. A category of these techniques, e.g., STED achieves this by
creating an illumination spot smaller than the Airy Disk. As a result, points
are distinguishable even if they are as small as the spot. In order to further
observe structures smaller than the spot itself, a technique called DDS scans
the sample more densely, and recovers the expected image by deconvolution. In
that technique, the deconvolution is achieved by filtering which requires some
peripheral areas to be scanned together with the region of interest. In this
study, an approach is proposed which has the same preprocessing stage as DDS.
But it requires to scan only the region of interest. After that, an equation
system is got from the scanned data. Finally, the expected image is recovered
by solving the equation system. Experiments are performed on simulated data,
and the results demonstrate the effectiveness of the proposed approach. The
experiments also suggest that the proposed approach is more efficient than the
existing one especially when the expected resolution is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01287</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01287</id><created>2019-08-04</created><authors><author><keyname>Chun</keyname><forenames>Il Yong</forenames></author><author><keyname>Zheng</keyname><forenames>Xuehang</forenames></author><author><keyname>Long</keyname><forenames>Yong</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>BCD-Net for Low-dose CT Reconstruction: Acceleration, Convergence, and
  Generalization</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted to MICCAI 2019, and the authors indicated by asterisks (*)
  equally contributed to this work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obtaining accurate and reliable images from low-dose computed tomography (CT)
is challenging. Regression convolutional neural network (CNN) models that are
learned from training data are increasingly gaining attention in low-dose CT
reconstruction. This paper modifies the architecture of an iterative regression
CNN, BCD-Net, for fast, stable, and accurate low-dose CT reconstruction, and
presents the convergence property of the modified BCD-Net. Numerical results
with phantom data show that applying faster numerical solvers to model-based
image reconstruction (MBIR) modules of BCD-Net leads to faster and more
accurate BCD-Net; BCD-Net significantly improves the reconstruction accuracy,
compared to the state-of-the-art MBIR method using learned transforms; BCD-Net
achieves better image quality, compared to a state-of-the-art iterative NN
architecture, ADMM-Net. Numerical results with clinical data show that BCD-Net
generalizes significantly better than a state-of-the-art deep (non-iterative)
regression NN, FBPConvNet, that lacks MBIR modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01301</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01301</id><created>2019-08-04</created><authors><author><keyname>Liu</keyname><forenames>Yixuan</forenames></author><author><keyname>Wang</keyname><forenames>Yuwang</forenames></author><author><keyname>Wang</keyname><forenames>Shengjin</forenames></author></authors><title>Adversarial View-Consistent Learning for Monocular Depth Estimation</title><categories>cs.CV cs.LG eess.IV</categories><comments>BMVC 2019 Spotlight</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of Monocular Depth Estimation (MDE).
Existing approaches on MDE usually model it as a pixel-level regression
problem, ignoring the underlying geometry property. We empirically find this
may result in sub-optimal solution: while the predicted depth map presents
small loss value in one specific view, it may exhibit large loss if viewed in
different directions. In this paper, inspired by multi-view stereo (MVS), we
propose an Adversarial View-Consistent Learning (AVCL) framework to force the
estimated depth map to be all reasonable viewed from multiple views. To this
end, we first design a differentiable depth map warping operation, which is
end-to-end trainable, and then propose a pose generator to generate novel views
for a given image in an adversarial manner. Collaborating with the
differentiable depth map warping operation, the pose generator encourages the
depth estimation network to learn from hard views, hence produce
view-consistent depth maps . We evaluate our method on NYU Depth V2 dataset and
the experimental results show promising performance gain upon state-of-the-art
MDE approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01339</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01339</id><created>2019-08-04</created><authors><author><keyname>Yang</keyname><forenames>Shengzhi</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Tang</keyname><forenames>Xuanxuan</forenames></author><author><keyname>Ding</keyname><forenames>Yuan</forenames></author><author><keyname>Zhou</keyname><forenames>Jianming</forenames></author></authors><title>Energy Efficiency Optimization for UAV-assisted Backscatter
  Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future Internet-of-Things (IoT) has high demand for energy-saving
communications, especially in remote areas and smart cities. To meet this
demand, we propose novel Unmanned Aerial Vehicle-assisted backscatter
communications, where a UAV first collects data from multiple terrestrial
backscattering tags via time division multiple access, and then flies into the
coverage region of a terrestrial base station to upload its collected data to
its associated base station. To determine the optimal UAV data collection
location, we first analyze the system average outage probability, and then
optimize the energy efficiency with the optimal backscattering location through
Golden Section method under UAV energy constraint. Our analytical and
simulation results illustrate that there is a trade-off between UAV data
collection location and the outage probability, and the optimal UAV data
collection location to achieve maximum energy efficiency needs to be closer to
the tags for lower UAV transmit power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01367</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01367</id><created>2019-08-04</created><authors><author><keyname>Yin</keyname><forenames>Xiaochuan</forenames></author><author><keyname>Liu</keyname><forenames>Chengju</forenames></author></authors><title>Unsupervised Learning of Depth and Deep Representation for Visual
  Odometry from Monocular Videos in a Metric Space</title><categories>cs.CV cs.RO eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For ego-motion estimation, the feature representation of the scenes is
crucial. Previous methods indicate that both the low-level and semantic
feature-based methods can achieve promising results. Therefore, the
incorporation of hierarchical feature representation may benefit from both
methods. From this perspective, we propose a novel direct feature odometry
framework, named DFO, for depth estimation and hierarchical feature
representation learning from monocular videos. By exploiting the metric
distance, our framework is able to learn the hierarchical feature
representation without supervision. The pose is obtained with a coarse-to-fine
approach from high-level to low-level features in enlarged feature maps. The
pixel-level attention mask can be self-learned to provide the prior
information. In contrast to the previous methods, our proposed method
calculates the camera motion with a direct method rather than regressing the
ego-motion from the pose network. With this approach, the consistency of the
scale factor of translation can be constrained. Additionally, the proposed
method is thus compatible with the traditional SLAM pipeline. Experiments on
the KITTI dataset demonstrate the effectiveness of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01373</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01373</id><created>2019-08-04</created><updated>2019-08-16</updated><authors><author><keyname>Gur</keyname><forenames>Shir</forenames></author><author><keyname>Wolf</keyname><forenames>Lior</forenames></author><author><keyname>Golgher</keyname><forenames>Lior</forenames></author><author><keyname>Blinder</keyname><forenames>Pablo</forenames></author></authors><title>Unsupervised Microvascular Image Segmentation Using an Active Contours
  Mimicking Neural Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of blood vessel segmentation in microscopy images is crucial for
many diagnostic and research applications. However, vessels can look vastly
different, depending on the transient imaging conditions, and collecting data
for supervised training is laborious. We present a novel deep learning method
for unsupervised segmentation of blood vessels. The method is inspired by the
field of active contours and we introduce a new loss term, which is based on
the morphological Active Contours Without Edges (ACWE) optimization method. The
role of the morphological operators is played by novel pooling layers that are
incorporated to the network's architecture. We demonstrate the challenges that
are faced by previous supervised learning solutions, when the imaging
conditions shift. Our unsupervised method is able to outperform such previous
methods in both the labeled dataset, and when applied to similar but different
datasets. Our code, as well as efficient PyTorch reimplementations of the
baseline methods VesselNN and DeepVess is available on GitHub -
https://github.com/shirgur/UMIS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01379</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01379</id><created>2019-08-04</created><authors><author><keyname>Wolff</keyname><forenames>Adam</forenames></author><author><keyname>Praisler</keyname><forenames>Shachar</forenames></author><author><keyname>Tcenov</keyname><forenames>Ilya</forenames></author><author><keyname>Gilboa</keyname><forenames>Guy</forenames></author></authors><title>Image-Guided Depth Sampling and Reconstruction</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depth acquisition, based on active illumination, is essential for autonomous
and robotic navigation. LiDARs (Light Detection And Ranging) with mechanical,
fixed, sampling templates are commonly used in today's autonomous vehicles. An
emerging technology, based on solid-state depth sensors, with no mechanical
parts, allows fast, adaptive, programmable scans.
  In this paper, we investigate the topic of adaptive, image-driven, sampling
and reconstruction strategies. First, we formulate a piece-wise linear depth
model with several tolerance parameters and estimate its validity for indoor
and outdoor scenes. Our model and experiments predict that, in the optimal
case, about 20-60 piece-wise linear structures can approximate well a depth
map. This translates to a depth-to-image sampling ratio of about 1/1200. We
propose a simple, generic, sampling and reconstruction algorithm, based on
super-pixels. We reach a sampling rate which is still far from the optimal
case. However, our sampling improves grid and random sampling, consistently,
for a wide variety of reconstruction methods. Moreover, our proposed
reconstruction achieves state-of-the-art results, compared to image-guided
depth completion algorithms, reducing the required sampling rate by a factor of
3-4. A single-pixel depth camera built in our lab illustrates the concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01393</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01393</id><created>2019-08-04</created><authors><author><keyname>Zhu</keyname><forenames>Yu</forenames></author><author><keyname>Schaub</keyname><forenames>Michael T.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author><author><keyname>Segarra</keyname><forenames>Santiago</forenames></author></authors><title>Network Inference from Consensus Dynamics with Unknown Parameters</title><categories>cs.SI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the problem of inferring the graph Laplacian of a weighted,
undirected network from snapshots of a single or multiple discrete-time
consensus dynamics, subject to parameter uncertainty, taking place on the
network. Specifically, we consider three problems in which we assume different
levels of knowledge about the diffusion rates, observation times, and the input
signal power of the dynamics. To solve these underdetermined problems, we
propose a set of algorithms that leverage the spectral properties of the
observed data and tools from convex optimization. Furthermore, we provide
theoretical performance guarantees associated with these algorithms. We
complement our theoretical work with numerical experiments, that demonstrate
how our proposed methods outperform current state-of-the-art algorithms and
showcase their effectiveness in recovering both synthetic and real-world
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01399</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01399</id><created>2019-08-04</created><authors><author><keyname>Xia</keyname><forenames>Wei</forenames></author><author><keyname>Koishida</keyname><forenames>Kazuhito</forenames></author></authors><title>Sound Event Detection in Multichannel Audio using Convolutional
  Time-Frequency-Channel Squeeze and Excitation</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted by Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we introduce a convolutional time-frequency-channel &quot;Squeeze
and Excitation&quot; (tfc-SE) module to explicitly model inter-dependencies between
the time-frequency domain and multiple channels. The tfc-SE module consists of
two parts: tf-SE block and c-SE block which are designed to provide attention
on time-frequency and channel domain, respectively, for adaptively
recalibrating the input feature map. The proposed tfc-SE module, together with
a popular Convolutional Recurrent Neural Network (CRNN) model, are evaluated on
a multi-channel sound event detection task with overlapping audio sources: the
training and test data are synthesized TUT Sound Events 2018 datasets, recorded
with microphone arrays. We show that the tfc-SE module can be incorporated into
the CRNN model at a small additional computational cost and bring significant
improvements on sound event detection accuracy. We also perform detailed
ablation studies by analyzing various factors that may influence the
performance of the SE blocks. We show that with the best tfc-SE block, error
rate (ER) decreases from 0.2538 to 0.2026, relative 20.17\% reduction of ER,
and 5.72\% improvement of F1 score. The results indicate that the learned
acoustic embeddings with the tfc-SE module efficiently strengthen
time-frequency and channel-wise feature representations to improve the
discriminative performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01404</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01404</id><created>2019-08-04</created><authors><author><keyname>Granzotto</keyname><forenames>Mathieu</forenames></author><author><keyname>Postoyan</keyname><forenames>Romain</forenames></author><author><keyname>Bu&#x15f;oniu</keyname><forenames>Lucian</forenames></author><author><keyname>Ne&#x161;i&#x107;</keyname><forenames>Dragan</forenames></author><author><keyname>Daafouz</keyname><forenames>Jamal</forenames></author></authors><title>Optimistic planning for the near-optimal control of nonlinear switched
  discrete-time systems with stability guarantees</title><categories>math.OC cs.SY eess.SY</categories><comments>8 pages, 2019 conference in decision and control, longer version
  submitted for reviewers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Originating in the artificial intelligence literature, optimistic planning
(OP) is an algorithm that generates near-optimal control inputs for generic
nonlinear discrete-time systems whose input set is finite. This technique is
therefore relevant for the near-optimal control of nonlinear switched systems,
for which the switching signal is the control. However, OP exhibits several
limitations, which prevent its application in a standard control context.
First, it requires the stage cost to take values in [0,1], an unnatural
prerequisite as it excludes, for instance, quadratic stage costs. Second, it
requires the cost function to be discounted. Third, it applies for reward
maximization, and not cost minimization. In this paper, we modify OP to
overcome these limitations, and we call the new algorithm OPmin. We then make
stabilizability and detectability assumptions, under which we derive
near-optimality guarantees for OPmin and we show that the obtained bound has
major advantages compared to the bound originally given by OP. In addition, we
prove that a system whose inputs are generated by OPmin in a receding-horizon
fashion exhibits stability properties. As a result, OPmin provides a new tool
for the near-optimal, stable control of nonlinear switched discrete-time
systems for generic cost functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01421</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01421</id><created>2019-08-04</created><authors><author><keyname>Mousavi</keyname><forenames>Hossein K.</forenames></author><author><keyname>Motee</keyname><forenames>Nader</forenames></author></authors><title>Explicit Characterization of Performance of a Class of Networked Linear
  Control Systems</title><categories>eess.SY cs.MA cs.SY</categories><comments>detailed version of a paper of the same name to be submitted to IEEE
  TCNS</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We show that the steady-state variance as a performance measure for a class
of networked linear control systems is expressible as the summation of a
rational function over the Laplacian eigenvalues of the network graph.
Moreover, we characterize the role of connectivity thresholds for the feedback
(and observer) gain design of these networks. We use our framework to derive
bounds and scaling laws for the performance of the dynamical network. Our
approach generalizes and unifies the previous results on the performance
measure of these networks for the case of arbitrary nodal dynamics. We bring
extensions of our methodology for the case of decentralized observer-based
output feedback as well as a class of composite networks. Numerous examples
support our theoretical contributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01429</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01429</id><created>2019-08-04</created><authors><author><keyname>Zhang</keyname><forenames>Yinghui</forenames></author><author><keyname>Deng</keyname><forenames>Xiaojuan</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Hongwei</forenames></author></authors><title>Restricted Linearized Augmented Lagrangian Method for Euler's Elastica
  Model</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Euler's elastica model has been extensively studied and applied to image
processing tasks. However, due to the high nonlinearity and nonconvexity of the
involved curvature term, conventional algorithms suffer from slow convergence
and high computational cost. Various fast algorithms have been proposed, among
which, the augmented Lagrangian based ones are very popular in the community.
However, parameter tuning might be very challenging for these methods. In this
paper, a simple cutting-off strategy is introduced into the augmented
Lagrangian based algorithms for minimizing the Euler's elastica energy, which
leads to easy parameter tuning and fast convergence. The cutting-off strategy
is based on an observation of inconsistency inside the augmented Lagrangian
based algorithms. When the weighting parameter of the curvature term goes to
zero, the energy functional boils down to the ROF model. So, a natural
requirement is that its augmented Lagrangian based algorithms should also
approach the augmented Lagrangian based algorithms formulated directly for
solving the ROF model from the very beginning. Unfortunately, this is not the
case for certain existing augmented Lagrangian based algorithms. The proposed
cutting-off strategy helps to decouple the tricky dependence between the
auxiliary splitting variables, so as to remove the observed inconsistency.
Numerical experiments suggest that the proposed algorithm enjoys easier
parameter-tuning, faster convergence and even higher quality of image
restorations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01439</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01439</id><created>2019-08-04</created><authors><author><keyname>Yasutomi</keyname><forenames>Suguru</forenames></author><author><keyname>Arakaki</keyname><forenames>Tatsuya</forenames></author><author><keyname>Hamamoto</keyname><forenames>Ryuji</forenames></author></authors><title>Shadow Detection for Ultrasound Images Using Unlabeled Data and
  Synthetic Shadows</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/rJl0fYG2KN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Medical ultrasound is widely used technique for diagnosing internal organs.
As common artifacts, shadows often appear in ultrasound images. Detecting such
shadows is curious because they prevent accurate diagnosis. In this paper, we
propose a novel shadow detection method based on auto-encoding structure. It
once separates an input image into a shadow image and a content image using two
decoders and combines them to reconstruct the input. To lead the network into
separating the input, we inject synthetic shadows into the input and make the
network to predict them as the shadow image. Since we know the rough shape of
shadows as basic domain knowledge, we can generate plausible shadows. These
processes are achieved by using only unlabeled data. Experiments on ultrasound
images for fetal heart diagnosis shows the effectiveness of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01447</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01447</id><created>2019-08-04</created><authors><author><keyname>Xia</keyname><forenames>Wei</forenames></author><author><keyname>Huang</keyname><forenames>Jing</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Cross-lingual Text-independent Speaker Verification using Unsupervised
  Adversarial Discriminative Domain Adaptation</title><categories>eess.AS cs.SD</categories><comments>Published in ICASSP2019</comments><doi>10.1109/ICASSP.2019.8682259</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker verification systems often degrade significantly when there is a
language mismatch between training and testing data. Being able to improve
cross-lingual speaker verification system using unlabeled data can greatly
increase the robustness of the system and reduce human labeling costs. In this
study, we introduce an unsupervised Adversarial Discriminative Domain
Adaptation (ADDA) method to effectively learn an asymmetric mapping that adapts
the target domain encoder to the source domain, where the target domain and
source domain are speech data from different languages. ADDA, together with a
popular Domain Adversarial Training (DAT) approach, are evaluated on a
cross-lingual speaker verification task: the training data is in English from
NIST SRE04-08, Mixer 6 and Switchboard, and the test data is in Chinese from
AISHELL-I. We show that with the ADDA adaptation, Equal Error Rate (EER) of the
x-vector system decreases from 9.331\% to 7.645\%, relatively 18.07\% reduction
of EER, and 6.32\% reduction from DAT as well. Further data analysis of ADDA
adapted speaker embedding shows that the learned speaker embeddings can perform
well on speaker classification for the target domain data, and are less
dependent with respect to the shift in language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01454</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01454</id><created>2019-08-04</created><authors><author><keyname>Nakamura</keyname><forenames>Taiki</forenames></author><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Ijima</keyname><forenames>Yusuke</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>V2S attack: building DNN-based voice conversion from automatic speaker
  verification</title><categories>cs.SD cs.CR cs.LG eess.AS</categories><comments>5 pages, 2 figures, accepted for The 10th ISCA Speech Synthesis
  Workshop (SSW10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new voice impersonation attack using voice conversion
(VC). Enrolling personal voices for automatic speaker verification (ASV) offers
natural and flexible biometric authentication systems. Basically, the ASV
systems do not include the users' voice data. However, if the ASV system is
unexpectedly exposed and hacked by a malicious attacker, there is a risk that
the attacker will use VC techniques to reproduce the enrolled user's voices. We
name this the ``verification-to-synthesis (V2S) attack'' and propose VC
training with the ASV and pre-trained automatic speech recognition (ASR) models
and without the targeted speaker's voice data. The VC model reproduces the
targeted speaker's individuality by deceiving the ASV model and restores
phonetic property of an input voice by matching phonetic posteriorgrams
predicted by the ASR model. The experimental evaluation compares converted
voices between the proposed method that does not use the targeted speaker's
voice data and the standard VC that uses the data. The experimental results
demonstrate that the proposed method performs comparably to the existing VC
methods that trained using a very small amount of parallel voice data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01469</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01469</id><created>2019-08-05</created><authors><author><keyname>Thang</keyname><forenames>Dang Duy</forenames></author><author><keyname>Matsui</keyname><forenames>Toshihiro</forenames></author></authors><title>Automated Detection System for Adversarial Examples with High-Frequency
  Noises Sieve</title><categories>cs.CV cs.LG eess.IV</categories><comments>Appear to 11th International Symposium on Cyberspace Safety and
  Security CSS 2019, Guangzhou, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks are being applied in many tasks with encouraging
results, and have often reached human-level performance. However, deep neural
networks are vulnerable to well-designed input samples called adversarial
examples. In particular, neural networks tend to misclassify adversarial
examples that are imperceptible to humans. This paper introduces a new
detection system that automatically detects adversarial examples on deep neural
networks. Our proposed system can mostly distinguish adversarial samples and
benign images in an end-to-end manner without human intervention. We exploit
the important role of the frequency domain in adversarial samples and propose a
method that detects malicious samples in observations. When evaluated on two
standard benchmark datasets (MNIST and ImageNet), our method achieved an
out-detection rate of 99.7 - 100% in many settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01477</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01477</id><created>2019-08-05</created><authors><author><keyname>Yu</keyname><forenames>Haibao</forenames></author><author><keyname>Wen</keyname><forenames>Tuopu</forenames></author><author><keyname>Cheng</keyname><forenames>Guangliang</forenames></author><author><keyname>Sun</keyname><forenames>Jiankai</forenames></author><author><keyname>Han</keyname><forenames>Qi</forenames></author><author><keyname>Shi</keyname><forenames>Jianping</forenames></author></authors><title>GDRQ: Group-based Distribution Reshaping for Quantization</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-bit quantization is challenging to maintain high performance with limited
model capacity (e.g., 4-bit for both weights and activations). Naturally, the
distribution of both weights and activations in deep neural network are
Gaussian-like. Nevertheless, due to the limited bitwidth of low-bit model,
uniform-like distributed weights and activations have been proved to be more
friendly to quantization while preserving accuracy~\cite{Han2015Learning}.
Motivated by this, we propose Scale-Clip, a Distribution Reshaping technique
that can reshape weights or activations into a uniform-like distribution in a
dynamic manner. Furthermore, to increase the model capability for a low-bit
model, a novel Group-based Quantization algorithm is proposed to split the
filters into several groups. Different groups can learn different quantization
parameters, which can be elegantly merged in to batch normalization layer
without extra computational cost in the inference stage. Finally, we integrate
Scale-Clip technique with Group-based Quantization algorithm and propose the
Group-based Distribution Reshaping Quantization (GDQR) framework to further
improve the quantization performance. Experiments on various networks (e.g.
VGGNet and ResNet) and vision tasks (e.g. classification, detection and
segmentation) demonstrate that our framework achieves good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01479</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01479</id><created>2019-08-05</created><authors><author><keyname>Moscoso</keyname><forenames>Miguel</forenames></author><author><keyname>Novikov</keyname><forenames>Alexei</forenames></author><author><keyname>Papanicolaou</keyname><forenames>George</forenames></author><author><keyname>Tsogka</keyname><forenames>Chrysoula</forenames></author></authors><title>Imaging with highly incomplete and corrupted data</title><categories>eess.IV cs.LG cs.NA math.NA physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of imaging sparse scenes from a few noisy data using
an $l_1$-minimization approach. This problem can be cast as a linear system of
the form $A \, \rho =b$, where $A$ is an $N\times K$ measurement matrix. We
assume that the dimension of the unknown sparse vector $\rho \in
{\mathbb{C}}^K$ is much larger than the dimension of the data vector $b \in
{\mathbb{C}}^N$, i.e, $K \gg N$. We provide a theoretical framework that allows
us to examine under what conditions the $\ell_1$-minimization problem admits a
solution that is close to the exact one in the presence of noise. Our analysis
shows that $l_1$-minimization is not robust for imaging with noisy data when
high resolution is required. To improve the performance of $l_1$-minimization
we propose to solve instead the augmented linear system $ [A \, | \, C] \rho
=b$, where the $N \times \Sigma$ matrix $C$ is a noise collector. It is
constructed so as its column vectors provide a frame on which the noise of the
data, a vector of dimension $N$, can be well approximated. Theoretically, the
dimension $\Sigma$ of the noise collector should be $e^N$ which would make its
use not practical. However, our numerical results illustrate that robust
results in the presence of noise can be obtained with a large enough number of
columns $\Sigma \approx 10 K$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01481</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01481</id><created>2019-08-05</created><updated>2019-08-07</updated><authors><author><keyname>Liang</keyname><forenames>Zhetong</forenames></author><author><keyname>Cai</keyname><forenames>Jianrui</forenames></author><author><keyname>Cao</keyname><forenames>Zisheng</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author></authors><title>CameraNet: A Two-Stage Framework for Effective Camera ISP Learning</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional image signal processing (ISP) pipeline consists of a set of
individual image processing components onboard a camera to reconstruct a
high-quality sRGB image from the sensor raw data. Due to the hand-crafted
nature of the ISP components, traditional ISP pipeline has limited
reconstruction quality under challenging scenes. Recently, the convolutional
neural networks (CNNs) have demonstrated their competitiveness in solving many
individual image processing problems, such as image denoising, demosaicking,
white balance and contrast enhancement. However, it remains a question whether
a CNN model can address the multiple tasks inside an ISP pipeline
simultaneously. We make a good attempt along this line and propose a novel
framework, which we call CameraNet, for effective and general ISP pipeline
learning. The CameraNet is composed of two CNN modules to account for two sets
of relatively uncorrelated subtasks in an ISP pipeline: restoration and
enhancement. To train the two-stage CameraNet model, we specify two
groundtruths that can be easily created in the common workflow of photography.
CameraNet is trained to progressively address the restoration and the
enhancement subtasks with its two modules. Experiments show that the proposed
CameraNet achieves consistently compelling reconstruction quality on three
benchmark datasets and outperforms traditional ISP pipelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01486</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01486</id><created>2019-08-05</created><authors><author><keyname>Chen</keyname><forenames>Lian-Kuan</forenames></author><author><keyname>Shao</keyname><forenames>Yingjie</forenames></author><author><keyname>Deng</keyname><forenames>Rui</forenames></author></authors><title>Robust UOWC systems against bubble-induced impairments via
  transmit/receive diversities</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We systematically investigate the bubble-induced performance degradation for
underwater wireless optical communication (UOWC) with different bubble sizes
and positions. By using different transmit and receive diversities, we
investigate the effectiveness of transmit/receive diversity on the mitigation
of the bubble-induced impairment to the UOWC link. With the help of a 2 by 2
MIMO using repetition coding (RC) and maximum ratio combining (MRC), a robust
780-Mbit/s UOWC transmission is achieved. The corresponding outage probability
can be significantly reduced from 34.6% for the system without diversity to
less than 1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01506</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01506</id><created>2019-08-05</created><authors><author><keyname>Decuyper</keyname><forenames>Milan</forenames></author><author><keyname>Van Holen</keyname><forenames>Roel</forenames></author></authors><title>Fully Automatic Binary Glioma Grading based on Pre-Therapy MRI using 3D
  Convolutional Neural Networks</title><categories>eess.IV</categories><comments>Presented at the International Conference on Medical Imaging with
  Deep Learning, MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/H1eBD0pTY4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The optimal treatment strategy of newly diagnosed glioma is strongly
influenced by tumour malignancy. Manual non-invasive grading based on MRI is
not always accurate and biopsies to verify diagnosis negatively impact overall
survival. In this paper, we propose a fully automatic 3D computer-aided
diagnosis (CAD) system to non-invasively differentiate high-grade glioblastoma
from lower-grade glioma. The approach consists of an automatic segmentation
step to extract the tumour ROI followed by classification using a 3D
convolutional neural network. Segmentation was performed using a 3D U-Net
achieving a dice score of 88.53% which matches top performing algorithms in the
BraTS 2018 challenge. The classification network was trained and evaluated on a
large heterogeneous dataset of 549 patients reaching an accuracy of 91%.
Additionally, the CAD system was evaluated on data from the Ghent University
Hospital and achieved an accuracy of 92% which shows that the algorithm is
robust to data from different centres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01517</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01517</id><created>2019-08-05</created><authors><author><keyname>Bashkirova</keyname><forenames>Dina</forenames></author><author><keyname>Usman</keyname><forenames>Ben</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author></authors><title>Adversarial Self-Defense for Cycle-Consistent GANs</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of unsupervised image-to-image translation is to map images from one
domain to another without the ground truth correspondence between the two
domains. State-of-art methods learn the correspondence using large numbers of
unpaired examples from both domains and are based on generative adversarial
networks. In order to preserve the semantics of the input image, the
adversarial objective is usually combined with a cycle-consistency loss that
penalizes incorrect reconstruction of the input image from the translated one.
However, if the target mapping is many-to-one, e.g. aerial photos to maps, such
a restriction forces the generator to hide information in low-amplitude
structured noise that is undetectable by human eye or by the discriminator. In
this paper, we show how such self-attacking behavior of unsupervised
translation methods affects their performance and provide two defense
techniques. We perform a quantitative evaluation of the proposed techniques and
show that making the translation model more robust to the self-adversarial
attack increases its generation quality and reconstruction reliability and
makes the model less sensitive to low-amplitude perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01529</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01529</id><created>2019-08-05</created><updated>2019-12-28</updated><authors><author><keyname>Chao</keyname><forenames>Manuel Arias</forenames></author><author><keyname>Kulkarni</keyname><forenames>Chetan</forenames></author><author><keyname>Goebel</keyname><forenames>Kai</forenames></author><author><keyname>Fink</keyname><forenames>Olga</forenames></author></authors><title>Hybrid deep fault detection and isolation: Combining deep neural
  networks and system performance models</title><categories>eess.SY cs.SY</categories><comments>25 pages, 19 figures, submitted to the International Journal of
  Prognostics and Health Management (IJPHM), July 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increased availability of condition monitoring data and the
increased complexity of explicit system physics-based models, the application
of data-driven approaches for fault detection and isolation has recently grown.
While detection accuracy of such approaches is generally good, their
performance on fault isolation often suffers from the fact that fault
conditions affect a large portion of the measured signals thereby masking the
fault source. To overcome this limitation and enable a more accurate fault
detection, we propose a hybrid approach combining physical performance models
with deep learning algorithms. Unobserved process variables are inferred with a
physics-based performance model to enhance the input space of a data-driven
diagnostics model. To validate the effectiveness of the proposed method, we
generate a condition monitoring dataset of an advanced gas turbine during
flight conditions under healthy and four faulty operative conditions based on
the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dynamical
model. We evaluate the performance of the proposed method in combination with
two different deep learning algorithms: feed forward neural networks and
Variational Autoencoders, both of which demonstrate a significant improvement
when applied within the hybrid fault detection and diagnostics framework. The
proposed method is able to outperform pure data-driven solutions, particularly
for systems with a high variability of operating conditions. It provides
superior results both for fault detection as well as for fault isolation. For
fault isolation, it overcomes the smearing effect that is observed in pure
data-driven approaches and enables a precise isolation of the affected signal.
We also demonstrate that deep learning algorithms provide a better performance
on fault detection compared to the traditional machine learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01542</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01542</id><created>2019-08-05</created><authors><author><keyname>Chen</keyname><forenames>Liangming</forenames></author><author><keyname>Cao</keyname><forenames>Ming</forenames></author><author><keyname>Li</keyname><forenames>Chuanjiang</forenames></author></authors><title>Angle rigidity and its usage to stabilize planar formations</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the challenging formation stabilization problem for mobile
robotic teams when no distance or relative displacement measurements are
available and each robot can only measure some of those angles formed by rays
towards its neighbors, we develop the notion of ``angle rigidity&quot; for a
multi-point framework, named ``angularity&quot;, consisting of a set of nodes
embedded in a Euclidean space and a set of angle constraints among them.
Different from bearings or angles defined with respect to a global axis, the
angles we use do not rely on the knowledge of a global coordinate system and
are signed according to the counter-clockwise direction. Here \emph{angle
rigidity} refers to the property specifying that under proper angle
constraints, the angularity can only translate, rotate or scale as a whole when
one or more of its nodes are perturbed locally. We first demonstrate that this
angle rigidity property, in sharp comparison to bearing rigidity or other
reported rigidity related to angles of frameworks in the literature, is
\emph{not} a global property since an angle rigid angularity may allow flex
ambiguity. We then construct necessary and sufficient conditions for
\emph{infinitesimal} angle rigidity by checking the rank of an angularity's
rigidity matrix. We develop a combinatorial necessary condition for
infinitesimal minimal angle rigidity. Using the developed theories, a formation
stabilization algorithm is designed for a robotic team to achieve a globally
angle rigid formation, in which only angle measurements are needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01543</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01543</id><created>2019-08-05</created><authors><author><keyname>Wang</keyname><forenames>Chenglong</forenames></author><author><keyname>Roth</keyname><forenames>Holger R.</forenames></author><author><keyname>Kitasaka</keyname><forenames>Takayuki</forenames></author><author><keyname>Oda</keyname><forenames>Masahiro</forenames></author><author><keyname>Hayashi</keyname><forenames>Yuichiro</forenames></author><author><keyname>Yoshino</keyname><forenames>Yasushi</forenames></author><author><keyname>Yamamoto</keyname><forenames>Tokunori</forenames></author><author><keyname>Sassa</keyname><forenames>Naoto</forenames></author><author><keyname>Goto</keyname><forenames>Momokazu</forenames></author><author><keyname>Mori</keyname><forenames>Kensaku</forenames></author></authors><title>Precise Estimation of Renal Vascular Dominant Regions Using Spatially
  Aware Fully Convolutional Networks, Tensor-Cut and Voronoi Diagrams</title><categories>eess.IV cs.CV</categories><journal-ref>Computerized Medical Imaging and Graphics 77 (2019): 101642</journal-ref><doi>10.1016/j.compmedimag.2019.101642</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for precisely estimating the renal
vascular dominant region using a Voronoi diagram. To provide computer-assisted
diagnostics for the pre-surgical simulation of partial nephrectomy surgery, we
must obtain information on the renal arteries and the renal vascular dominant
regions. We propose a fully automatic segmentation method that combines a
neural network and tensor-based graph-cut methods to precisely extract the
kidney and renal arteries. First, we use a convolutional neural network to
localize the kidney regions and extract tiny renal arteries with a tensor-based
graph-cut method. Then we generate a Voronoi diagram to estimate the renal
vascular dominant regions based on the segmented kidney and renal arteries. The
accuracy of kidney segmentation in 27 cases with 8-fold cross validation
reached a Dice score of 95%. The accuracy of renal artery segmentation in 8
cases obtained a centerline overlap ratio of 80%. Each partition region
corresponds to a renal vascular dominant region. The final dominant-region
estimation accuracy achieved a Dice coefficient of 80%. A clinical application
showed the potential of our proposed estimation approach in a real clinical
surgical environment. Further validation using large-scale database is our
future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01551</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01551</id><created>2019-08-05</created><updated>2019-11-12</updated><authors><author><keyname>Sch&#xf6;nherr</keyname><forenames>Lea</forenames></author><author><keyname>Zeiler</keyname><forenames>Steffen</forenames></author><author><keyname>Holz</keyname><forenames>Thorsten</forenames></author><author><keyname>Kolossa</keyname><forenames>Dorothea</forenames></author></authors><title>Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech
  Recognition Systems</title><categories>cs.CR cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous research showed that automatic speech recognition (ASR) systems can
be fooled via adversarial examples. These can induce the ASR system to produce
an arbitrary transcription in response to any type of audio signal.
Unfortunately, the adversarial examples introduced in prior work did not work
in a real-world setup, where the attack is played over the air. Instead, most
examples rather have to be fed directly into the ASR system, ignoring practical
side-effects such as reflections. In the few cases where the adversarial
examples have been successfully demonstrated over the air, the attacks were not
transferable between environments, but instead required precise information
about the room where the attack was to take place. The remaining over-the-air
attacks in the literature are either handcrafted examples or human listeners
can easily recognize the target transcription once they have been alerted to
its content. We demonstrate the first algorithm that produces generic
adversarial examples, which remain robust in an over-the-air attack that is not
adapted to the specific environment. Hence, no prior knowledge of the room
characteristics is required. Instead, we use room impulse responses to compute
robust adversarial examples for arbitrary room characteristics and employ the
open-source ASR system Kaldi to demonstrate a full end-to-end attack. Further,
we utilize psychoacoustic masking to hide the changes of the original audio
signal below the human thresholds of hearing. We show that the adversarial
examples work for varying room setups and that no line-of-sight between speaker
and microphone is necessary. As a result, an attacker can optimize adversarial
examples for any kind of target transcription, based on any kind of audio
content, for arbitrary room setups without any prior knowledge. Additionally,
the adversarial examples remain transferable across a wide range of rooms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01576</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01576</id><created>2019-07-03</created><authors><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Michetti</keyname><forenames>Giuseppe</forenames></author><author><keyname>Kord</keyname><forenames>Ahmed</forenames></author><author><keyname>Pirro</keyname><forenames>Michele</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios</forenames></author><author><keyname>Xiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Cassella</keyname><forenames>Cristian</forenames></author><author><keyname>Alu</keyname><forenames>Andrea</forenames></author><author><keyname>Rinaldi</keyname><forenames>Matteo</forenames></author></authors><title>Highly-Linear Magnet-Free Microelectromechanical Circulators</title><categories>physics.app-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the first demonstration of a magnet-free, high performance
microelectromechanical system (MEMS) based circulator. An innovative circuit
based on the commutation of MEMS resonators with high quality (Q) factor using
RF switches is designed and implemented. Thanks to the high Q factor, a much
smaller modulation frequency can be achieved compared to the previous
demonstrations, reducing the power consumption and enabling the use of high
power-handling switches. Furthermore, the MEMS resonators greatly reduce the
required inductance value, guaranteeing much smaller form factor compared to
the previous LC demonstrations. The demonstrated circulator shows broad BW (15
dB-IX BW=34.7 MHz for an operational frequency around 2.5 GHz), low IL (4 dB),
high IX (30 dB), high linearity (P1dB=28 dBm; IIP3=40 dBm) and at the same time
low power consumption, addressing several of the current limitations hindering
the full development of magnet-free circulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01590</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01590</id><created>2019-08-02</created><authors><author><keyname>Xi</keyname><forenames>Mengjia</forenames></author><author><keyname>Chen</keyname><forenames>Hui</forenames></author><author><keyname>Yuan</keyname><forenames>Yuan</forenames></author><author><keyname>Wang</keyname><forenames>Gao</forenames></author><author><keyname>He</keyname><forenames>Yuchen</forenames></author><author><keyname>Liang</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>Jianbin</forenames></author><author><keyname>Zheng</keyname><forenames>Huaibin</forenames></author><author><keyname>Xu</keyname><forenames>Zhuo</forenames></author></authors><title>Bifrequency 3D Ghost Imaging with Haar Wavelet Transform</title><categories>eess.IV</categories><comments>8 pages and 6 figures</comments><doi>10.1364/OE.27.032349</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, ghost imaging has been attracting attentions because its mechanism
would lead to many applications inaccessible to conventional imaging methods.
However, it is challenging for high contrast and high resolution imaging, due
to its low signal-to-noise ratio (SNR) and the demand of high sampling rate in
detection. To circumvent these challenges, we here propose a ghost imaging
scheme that exploits Haar wavelets as illuminating patterns with a bi-frequency
light projecting system and frequency-selecting single-pixel detectors. This
method provides a theoretically 100% image contrast and high detection SNR,
which reduces the requirement of high dynamic range of detectors, enabling high
resolution ghost imaging. Moreover, it can highly reduce the sampling rate (far
below Nyquist limit) for a sparse object by adaptively abandoning unnecessary
patterns during the measurement. These characteristics are experimentally
verified with a resolution of 512 times 512 and a sampling rate lower than 5%.
A high-resolution (1000 times 1000 times 1000) 3D reconstruction of an object
is also achieved from multi-angle images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01593</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01593</id><created>2019-08-02</created><authors><author><keyname>Rana</keyname><forenames>Aman</forenames></author><author><keyname>Lowe</keyname><forenames>Alarice</forenames></author><author><keyname>Lithgow</keyname><forenames>Marie</forenames></author><author><keyname>Horback</keyname><forenames>Katharine</forenames></author><author><keyname>Janovitz</keyname><forenames>Tyler</forenames></author><author><keyname>Da Silva</keyname><forenames>Annacarolina</forenames></author><author><keyname>Tsai</keyname><forenames>Harrison</forenames></author><author><keyname>Shanmugam</keyname><forenames>Vignesh</forenames></author><author><keyname>Yoon</keyname><forenames>Hyung-Jin</forenames></author><author><keyname>Shah</keyname><forenames>Pratik</forenames></author></authors><title>High Accuracy Tumor Diagnoses and Benchmarking of Hematoxylin and Eosin
  Stained Prostate Core Biopsy Images Generated by Explainable Deep Neural
  Networks</title><categories>q-bio.QM cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histopathological diagnoses of tumors in tissue biopsy after Hematoxylin and
Eosin (H&amp;E) staining is the gold standard for oncology care. H&amp;E staining is
slow and uses dyes, reagents and precious tissue samples that cannot be reused.
Thousands of native nonstained RGB Whole Slide Image (RWSI) patches of prostate
core tissue biopsies were registered with their H&amp;E stained versions.
Conditional Generative Adversarial Neural Networks (cGANs) that automate
conversion of native nonstained RWSI to computational H&amp;E stained images were
then trained. High similarities between computational and H&amp;E dye stained
images with Structural Similarity Index (SSIM) 0.902, Pearsons Correlation
Coefficient (CC) 0.962 and Peak Signal to Noise Ratio (PSNR) 22.821 dB were
calculated. A second cGAN performed accurate computational destaining of H&amp;E
dye stained images back to their native nonstained form with SSIM 0.9, CC 0.963
and PSNR 25.646 dB. A single-blind study computed more than 95% pixel-by-pixel
overlap between prostate tumor annotations on computationally stained images,
provided by five-board certified MD pathologists, with those on H&amp;E dye stained
counterparts. We report the first visualization and explanation of neural
network kernel activation maps during H&amp;E staining and destaining of RGB images
by cGANs. High similarities between kernel activation maps of computational and
H&amp;E stained images (Mean-Squared Errors &lt;0.0005) provide additional
mathematical and mechanistic validation of the staining system. Our neural
network framework thus is automated, explainable and performs high precision
H&amp;E staining and destaining of low cost native RGB images, and is computer
vision and physician authenticated for rapid and accurate tumor diagnoses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01594</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01594</id><created>2019-08-05</created><authors><author><keyname>Byra</keyname><forenames>Michal</forenames></author><author><keyname>Wu</keyname><forenames>Mei</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaodong</forenames></author><author><keyname>Jang</keyname><forenames>Hyungseok</forenames></author><author><keyname>Ma</keyname><forenames>Ya-Jun</forenames></author><author><keyname>Chang</keyname><forenames>Eric Y</forenames></author><author><keyname>Shah</keyname><forenames>Sameer</forenames></author><author><keyname>Du</keyname><forenames>Jiang</forenames></author></authors><title>Knee menisci segmentation and relaxometry of 3D ultrashort echo time
  (UTE) cones MR imaging using attention U-Net with transfer learning</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>30 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this work is to develop a deep learning-based method for knee
menisci segmentation in 3D ultrashort echo time (UTE) cones magnetic resonance
(MR) imaging, and to automatically determine MR relaxation times, namely the
T1, T1$\rho$, and T2* parameters, which can be used to assess knee
osteoarthritis (OA). Whole knee joint imaging was performed using 3D UTE cones
sequences to collect data from 61 human subjects. Regions of interest (ROIs)
were outlined by two experienced radiologists based on subtracted
T1$\rho$-weighted MR images. Transfer learning was applied to develop 2D
attention U-Net convolutional neural networks for the menisci segmentation
based on each radiologist's ROIs separately. Dice scores were calculated to
assess segmentation performance. Next, the T1, T1$\rho$, T2* relaxations, and
ROI areas were determined for the manual and automatic segmentations, then
compared.The models developed using ROIs provided by two radiologists achieved
high Dice scores of 0.860 and 0.833, while the radiologists' manual
segmentations achieved a Dice score of 0.820. Linear correlation coefficients
for the T1, T1$\rho$, and T2* relaxations calculated using the automatic and
manual segmentations ranged between 0.90 and 0.97, and there were no associated
differences between the estimated average meniscal relaxation parameters. The
deep learning models achieved segmentation performance equivalent to the
inter-observer variability of two radiologists. The proposed deep
learning-based approach can be used to efficiently generate automatic
segmentations and determine meniscal relaxations times. The method has the
potential to help radiologists with the assessment of meniscal diseases, such
as OA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01596</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01596</id><created>2019-08-05</created><updated>2020-02-07</updated><authors><author><keyname>Dees</keyname><forenames>Bruno Scalzo</forenames></author><author><keyname>Stankovic</keyname><forenames>Ljubisa</forenames></author><author><keyname>Dakovic</keyname><forenames>Milos</forenames></author><author><keyname>Constantinides</keyname><forenames>Anthony G.</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>A Class of Doubly Stochastic Shift Operators for Random Graph Signals
  and their Boundedness</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of doubly stochastic graph shift operators (GSO) is proposed, which
is shown to exhibit: (i) lower and upper $L_{2}$-boundedness for locally
stationary random graph signals; (ii) $L_{2}$-isometry for \textit{i.i.d.}
random graph signals with the asymptotic increase in the incoming neighbourhood
size of vertices; and (iii) preservation of the mean of any graph signal. These
properties are obtained through a statistical consistency analysis of the graph
shift, and by exploiting the dual role of the doubly stochastic GSO as a Markov
(diffusion) matrix and as an unbiased expectation operator. Practical utility
of the class of doubly stochastic GSOs is demonstrated in a real-world
multi-sensor signal filtering setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01608</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01608</id><created>2019-08-05</created><updated>2019-08-12</updated><authors><author><keyname>Yuan</keyname><forenames>Ye</forenames></author><author><keyname>Guan</keyname><forenames>Jian</forenames></author><author><keyname>Sun</keyname><forenames>Jianguo</forenames></author></authors><title>Blind SAR Image Despeckling Using Self-Supervised Dense Dilated
  Convolutional Neural Network</title><categories>eess.IV cs.GR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despeckling is a key and indispensable step in SAR image preprocessing,
existing deep learning-based methods achieve SAR despeckling by learning some
mappings between speckled (different looks) and clean images. However, there
exist no clean SAR image in the real world. To this end, in this paper, we
propose a self-supervised dense dilated convolutional neural network (BDSS) for
blind SAR image despeckling. Proposed BDSS can still learn to suppress speckle
noise without clean ground truth by optimized for L2 loss. Besides, three
enhanced dense blocks with dilated convolution are employed to improve network
performance. The synthetic and real-data experiments demonstrate that proposed
BDSS can achieve despeckling effectively while maintaining well features such
as edges, point targets, and radiometric. At last, we demonstrate that our
proposed BDSS can achieve blind despeckling excellently, i.e., do not need to
care about the number of looks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01612</identifier>
 <datestamp>2020-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01612</id><created>2019-08-05</created><updated>2019-08-06</updated><authors><author><keyname>Lyu</keyname><forenames>Qing</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>Multi-Contrast Super-Resolution MRI Through a Progressive Network</title><categories>eess.IV cs.LG physics.med-ph</categories><comments>10 figures, 5 tables, 11 pages</comments><journal-ref>IEEE Transactions on Medical Imaging, early access, 2020</journal-ref><doi>10.1109/TMI.2020.2974858</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) is widely used for screening, diagnosis,
image-guided therapy, and scientific research. A significant advantage of MRI
over other imaging modalities such as computed tomography (CT) and nuclear
imaging is that it clearly shows soft tissues in multi-contrasts. Compared with
other medical image super-resolution (SR) methods that are in a single
contrast, multi-contrast super-resolution studies can synergize multiple
contrast images to achieve better super-resolution results. In this paper, we
propose a one-level non-progressive neural network for low up-sampling
multi-contrast super-resolution and a two-level progressive network for high
up-sampling multi-contrast super-resolution. Multi-contrast information is
combined in high-level feature space. Our experimental results demonstrate that
the proposed networks can produce MRI super-resolution images with good image
quality and outperform other multi-contrast super-resolution methods in terms
of structural similarity and peak signal-to-noise ratio. Also, the progressive
network produces a better SR image quality than the non-progressive network,
even if the original low-resolution images were highly down-sampled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01642</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01642</id><created>2019-08-05</created><authors><author><keyname>Sher</keyname><forenames>Yoni</forenames></author></authors><title>Review of Algorithms for Compressive Sensing of Images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>14 pages, 8 figures, all data available in appendix</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We provide a comprehensive review of classical algorithms for compressive
sensing of images, focused on Total variation methods, with a view to
application in LiDAR systems. Our primary focus is providing a full review for
beginners in the field, as well as simulating the kind of noise found in real
LiDAR systems. To this end, we provide an overview of the theoretical
background, a brief discussion of various considerations that come in to play
in compressive sensing, and a standardized comparison of off-the-shelf methods,
intended as a quick-start guide to choosing algorithms for compressive sensing
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01654</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01654</id><created>2019-08-05</created><authors><author><keyname>Yan</keyname><forenames>Yang</forenames></author><author><keyname>Su</keyname><forenames>Lanlan</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author><author><keyname>Antsaklis</keyname><forenames>Panos</forenames></author></authors><title>Analysis of Two-Dimensional Feedback Systems over Networks Using
  Dissipativity</title><categories>eess.SY cs.SY</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the closed-loop $\mathcal{L}_2$ stability of
two-dimensional (2-D) feedback systems across a digital communication network
by introducing the tool of dissipativity. First, sampling of a continuous 2-D
system is considered and an analytical characterization of the
$QSR$-dissipativity of the sampled system is presented. Next, the
input-feedforward output-feedback passivity (IF-OFP), a simplified form of
$QSR$-dissipativity, is utilized to study the framework of feedback
interconnection of two 2-D systems over networks. Then, the effects of signal
quantization in communication links on dissipativity degradation of the 2-D
feedback quantized system is analyzed. Additionally, an event-triggered
mechanism is developed for 2-D networked control systems while maintaining
$\mathcal{L}_2$ stability of the closed-loop system. In the end, an
illustrative example is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01671</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01671</id><created>2019-08-05</created><updated>2019-10-21</updated><authors><author><keyname>Baird</keyname><forenames>Alice</forenames></author><author><keyname>Schuller</keyname><forenames>Bjoern</forenames></author></authors><title>Acoustic Sounds for Wellbeing: A Novel Dataset and Baseline Results</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of sound healing includes ancient practices coming from a broad
range of cultures. Across such practices there is a variety of acoustic
instrumentation utilised. Practitioners suggest that sound has the ability to
target both mental and even physical health issues, e.g., chronic-stress, or
joint-pain. Instruments including the Tibetan singing bowl and vocal chanting,
are still widely used today. With the noise-floor of modern urban soundscapes
continually increasing and known to impact wellbeing, methods to improve this
are needed. With that in mind, this study presents the Acoustic Sounds for
Wellbeing (ASW) dataset. The ASW dataset is a dataset gathered from YouTube
including 88\,+ hrs of audio from 5-classes of acoustic instrumentation (Gongs,
Drumming, Singing Bowls, and Chanting). We additionally present initial
baseline classification results on the dataset, finding that conventional
Mel-Frequency Cepstra coefficient features achieve at best an unweighted
average recalled of 57.4 % for a 5-class support vector machine classification
paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01678</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01678</id><created>2019-08-05</created><authors><author><keyname>Yesilli</keyname><forenames>Melih C.</forenames></author><author><keyname>Khasawneh</keyname><forenames>Firas A.</forenames></author><author><keyname>Otto</keyname><forenames>Andreas</forenames></author></authors><title>Chatter Detection in Turning Using Machine Learning and Similarity
  Measures of Time Series via Dynamic Time Warping</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chatter detection from sensor signals has been an active field of research.
While some success has been reported using several featurization tools and
machine learning algorithms, existing methods have several drawbacks such as
manual preprocessing and requiring a large data set. In this paper, we present
an alternative approach for chatter detection based on K-Nearest Neighbor (kNN)
algorithm for classification and the Dynamic Time Warping (DTW) as a time
series similarity measure. The used time series are the acceleration signals
acquired from the tool holder in a series of turning experiments. Our results,
show that this approach achieves detection accuracies that in most cases
outperform existing methods. We compare our results to the traditional methods
based on Wavelet Packet Transform (WPT) and the Ensemble Empirical Mode
Decomposition (EEMD), as well as to the more recent Topological Data Analysis
(TDA) based approach. We show that in three out of four cutting configurations
our DTW-based approach attains the highest average classification rate reaching
in one case as high as 99% accuracy. Our approach does not require feature
extraction, is capable of reusing a classifier across different cutting
configurations, and it uses reasonably sized training sets. Although the
resulting high accuracy in our approach is associated with high computational
cost, this is specific to the DTW implementation that we used. Specifically, we
highlight available, very fast DTW implementations that can even be implemented
on small consumer electronics. Therefore, further code optimization and the
significantly reduced computational effort during the implementation phase make
our approach a viable option for in-process chatter detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01743</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01743</id><created>2019-08-05</created><updated>2020-02-22</updated><authors><author><keyname>Chen</keyname><forenames>Lingji</forenames></author></authors><title>A Merge/Split Algorithm for Multitarget Tracking Using Generalized
  Labeled Multi-Bernoulli Filters</title><categories>eess.SP eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of Labeled Random Finite Set filters known as the delta-Generalized
Labeled Multi-Bernoulli (dGLMB) filter represents the filtering density as a
set of weighted hypotheses, with each hypothesis consisting of a set of labeled
tracks, which are in turn pairs of a track label and a track (kinematic)
density. Upon update with a batch of measurements, each hypothesis gives rise
to many child hypotheses, and therefore for any practical application,
truncation has to be performed and compute budget has to be utilized
efficiently. We have adopted a factored filtering density through the use of a
novel Merge/Split algorithm: When some factors become coupled through new
measurements that gate with them, they are merged into one factor by forming
&quot;product hypotheses.&quot; The merged factor can subsequently be split into two
factors, one gating with the measurements while the other not, if the &quot;joint
probability reconstruction error&quot; is within a given tolerance and therefore
independence between the two factors can be considered to hold true. A key to
the algorithm is the exploitation of &quot;diminishing influence&quot; of old
measurements on the current state, so that a kinematic density is indexed by a
sequence of most recently incorporated measurement IDs. With such indexing, the
problem is discretized, and factorization of the dGLMB density is carried out
through marginalization that &quot;combines terms&quot; to have a reduction in the total
number of hypotheses. Factors that have become &quot;empty&quot; are deleted. Thus, the
Merge/Split algorithm adaptively creates and maintains significant factors
within a compute budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01768</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01768</id><created>2019-08-04</created><authors><author><keyname>Yousefi</keyname><forenames>Midia</forenames></author><author><keyname>Khorram</keyname><forenames>Soheil</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Probabilistic Permutation Invariant Training for Speech Separation</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Interspeech 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Single-microphone, speaker-independent speech separation is normally
performed through two steps: (i) separating the specific speech sources, and
(ii) determining the best output-label assignment to find the separation error.
The second step is the main obstacle in training neural networks for speech
separation. Recently proposed Permutation Invariant Training (PIT) addresses
this problem by determining the output-label assignment which minimizes the
separation error. In this study, we show that a major drawback of this
technique is the overconfident choice of the output-label assignment,
especially in the initial steps of training when the network generates
unreliable outputs. To solve this problem, we propose Probabilistic PIT
(Prob-PIT) which considers the output-label permutation as a discrete latent
random variable with a uniform prior distribution. Prob-PIT defines a
log-likelihood function based on the prior distributions and the separation
errors of all permutations; it trains the speech separation networks by
maximizing the log-likelihood function. Prob-PIT can be easily implemented by
replacing the minimum function of PIT with a soft-minimum function. We evaluate
our approach for speech separation on both TIMIT and CHiME datasets. The
results show that the proposed method significantly outperforms PIT in terms of
Signal to Distortion Ratio and Signal to Interference Ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01786</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01786</id><created>2019-08-05</created><authors><author><keyname>Bradford</keyname><forenames>Eric</forenames></author><author><keyname>Imsland</keyname><forenames>Lars</forenames></author><author><keyname>Zhang</keyname><forenames>Dongda</forenames></author><author><keyname>Chanona</keyname><forenames>Ehecatl Antonio del Rio</forenames></author></authors><title>Stochastic data-driven model predictive control using Gaussian processes</title><categories>math.OC cs.LG cs.SY eess.SY</categories><comments>Submitted to Journal of Process Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear model predictive control (NMPC) is one of the few control methods
that can handle multivariable nonlinear control systems with constraints.
Gaussian processes (GPs) present a powerful tool to identify the required plant
model and quantify the residual uncertainty of the plant-model mismatch given
its probabilistic nature . It is crucial to account for this uncertainty, since
it may lead to worse control performance and constraint violations. In this
paper we propose a new method to design a GP-based NMPC algorithm for finite
horizon control problems. The method generates Monte Carlo samples of the GP
offline for constraint tightening using back-offs. The tightened constraints
then guarantee the satisfaction of joint chance constraints online. Advantages
of our proposed approach over existing methods include fast online evaluation
time, consideration of closed-loop behaviour, and the possibility to alleviate
conservativeness by accounting for both online learning and state dependency of
the uncertainty. The algorithm is verified on a challenging semi-batch
bioprocess case study, with its high performance thoroughly demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01790</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01790</id><created>2019-08-05</created><authors><author><keyname>Talreja</keyname><forenames>Veeru</forenames></author><author><keyname>Taherkhani</keyname><forenames>Fariborz</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser M</forenames></author></authors><title>Attribute-Guided Coupled GAN for Cross-Resolution Face Recognition</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel attribute-guided cross-resolution
(low-resolution to high-resolution) face recognition framework that leverages a
coupled generative adversarial network (GAN) structure with adversarial
training to find the hidden relationship between the low-resolution and
high-resolution images in a latent common embedding subspace. The coupled GAN
framework consists of two sub-networks, one dedicated to the low-resolution
domain and the other dedicated to the high-resolution domain. Each sub-network
aims to find a projection that maximizes the pair-wise correlation between the
two feature domains in a common embedding subspace. In addition to projecting
the images into a common subspace, the coupled network also predicts facial
attributes to improve the cross-resolution face recognition. Specifically, our
proposed coupled framework exploits facial attributes to further maximize the
pair-wise correlation by implicitly matching facial attributes of the low and
high-resolution images during the training, which leads to a more
discriminative embedding subspace resulting in performance enhancement for
cross-resolution face recognition. The efficacy of our approach compared with
the state-of-the-art is demonstrated using the LFWA, Celeb-A, SCFace and UCCS
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01822</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01822</id><created>2019-08-05</created><authors><author><keyname>Dong</keyname><forenames>Annan</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander</forenames></author><author><keyname>Dabin</keyname><forenames>Jason</forenames></author></authors><title>Blind Sparse Estimation of Intermittent Sources over Unknown Fading
  Channels</title><categories>eess.SP</categories><comments>to appear on IEEE TVT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio frequency sources are observed at a fusion center via sensor
measurements made over slow flat-fading channels. The number of sources may be
larger than the number of sensors, but their activity is sparse and
intermittent with bursty transmission patterns. To account for this, sources
are modeled as hidden Markov models with known or unknown parameters. The
problem of blind source estimation in the absence of channel state information
is tackled via a novel algorithm, consisting of a dictionary learning (DL)
stage and a per-source stochastic filtering (PSF) stage. The two stages work in
tandem, with the latter operating on the output produced by the former. Both
stages are designed so as to account for the sparsity and memory of the
sources. To this end, smooth LASSO is integrated with DL, while the
forward-backward algorithm and Expectation Maximization (EM) algorithm are
leveraged for PSF. It is shown that the proposed algorithm can enhance the
detection and the estimation performance of the sources, and that it is robust
to the sparsity level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01872</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01872</id><created>2019-08-05</created><authors><author><keyname>Liu</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Guo</keyname><forenames>Zhenhua</forenames></author><author><keyname>You</keyname><forenames>Jane</forenames></author><author><keyname>Kumar</keyname><forenames>B. V. K Vijaya</forenames></author></authors><title>Attention Control with Metric Learning Alignment for Image Set-based
  Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted to IEEE T-IFS (Extension of ECCV 2018 paper:
  Dependency-aware Attention Control for Unconstrained Face Recognition with
  Image Sets). arXiv admin note: substantial text overlap with
  arXiv:1907.03030; text overlap with arXiv:1707.00130 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of image set-based face verification and
identification. Unlike traditional single sample (an image or a video) setting,
this situation assumes the availability of a set of heterogeneous collection of
orderless images and videos. The samples can be taken at different check
points, different identity documents $etc$. The importance of each image is
usually considered either equal or based on a quality assessment of that image
independent of other images and/or videos in that image set. How to model the
relationship of orderless images within a set remains a challenge. We address
this problem by formulating it as a Markov Decision Process (MDP) in a latent
space. Specifically, we first propose a dependency-aware attention control
(DAC) network, which uses actor-critic reinforcement learning for attention
decision of each image to exploit the correlations among the unordered images.
An off-policy experience replay is introduced to speed up the learning process.
Moreover, the DAC is combined with a temporal model for videos using divide and
conquer strategies. We also introduce a pose-guided representation (PGR) scheme
that can further boost the performance at extreme poses. We propose a
parameter-free PGR without the need for training as well as a novel metric
learning-based PGR for pose alignment without the need for pose detection in
testing stage. Extensive evaluations on IJB-A/B/C, YTF, Celebrity-1000 datasets
demonstrate that our method outperforms many state-of-art approaches on the
set-based as well as video-based face recognition databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01883</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01883</id><created>2019-08-05</created><updated>2019-10-28</updated><authors><author><keyname>Wei</keyname><forenames>Tianhao</forenames></author><author><keyname>Liu</keyname><forenames>Changliu</forenames></author></authors><title>Safe Control Algorithms Using Energy Functions: A Unified Framework,
  Benchmark, and New Directions</title><categories>eess.SY cs.SY</categories><comments>This is the extended version of a paper submitted to 58th Conference
  on Decision and Control March, 2019; revised August, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Safe autonomy is important in many application domains, especially for
applications involving interactions with humans. Existing safe control
algorithms are similar to one another in the sense that: they all provide
control inputs to maintain a low value of an energy function that measures
safety. In different methods, the energy function is called a potential
function, a safety index, or a barrier function. The connections and relative
advantages among these methods remain unclear. This paper introduces a unified
framework to derive safe control laws using energy functions. We demonstrate
how to integrate existing controllers based on potential field method, safe set
algorithm, barrier function method, and sliding mode algorithm into this
unified framework. In addition to theoretical comparison, this paper also
introduces a benchmark which implements and compares existing methods on a
variety of problems with different system dynamics and interaction modes. Based
on the comparison results, a new method, called the sublevel safe set
algorithm, is derived under the unified framework by optimizing the
hyperparameters. The proposed algorithm achieves the best performance in terms
of safety and efficiency on the vast majority of benchmark tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01901</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01901</id><created>2019-08-05</created><authors><author><keyname>Delahunt</keyname><forenames>Charles B.</forenames></author><author><keyname>Jaiswal</keyname><forenames>Mayoore S.</forenames></author><author><keyname>Horning</keyname><forenames>Matthew P.</forenames></author><author><keyname>Janko</keyname><forenames>Samantha</forenames></author><author><keyname>Thompson</keyname><forenames>Clay M.</forenames></author><author><keyname>Kulhare</keyname><forenames>Sourabh</forenames></author><author><keyname>Hu</keyname><forenames>Liming</forenames></author><author><keyname>Ostbye</keyname><forenames>Travis</forenames></author><author><keyname>Yun</keyname><forenames>Grace</forenames></author><author><keyname>Gebrehiwot</keyname><forenames>Roman</forenames></author><author><keyname>Wilson</keyname><forenames>Benjamin K.</forenames></author><author><keyname>Long</keyname><forenames>Earl</forenames></author><author><keyname>Proux</keyname><forenames>Stephane</forenames></author><author><keyname>Gamboa</keyname><forenames>Dionicia</forenames></author><author><keyname>Chiodini</keyname><forenames>Peter</forenames></author><author><keyname>Carter</keyname><forenames>Jane</forenames></author><author><keyname>Dhorda</keyname><forenames>Mehul</forenames></author><author><keyname>Isaboke</keyname><forenames>David</forenames></author><author><keyname>Ogutu</keyname><forenames>Bernhards</forenames></author><author><keyname>Oyibo</keyname><forenames>Wellington</forenames></author><author><keyname>Villasis</keyname><forenames>Elizabeth</forenames></author><author><keyname>Tun</keyname><forenames>Kyaw Myo</forenames></author><author><keyname>Bachman</keyname><forenames>Christine</forenames></author><author><keyname>Bell</keyname><forenames>David</forenames></author><author><keyname>Mehanian</keyname><forenames>Courosh</forenames></author></authors><title>Fully-automated patient-level malaria assessment on field-prepared thin
  blood film microscopy images, including Supplementary Information</title><categories>cs.LG eess.IV stat.ML</categories><comments>16 pages, 13 figures</comments><msc-class>68T10</msc-class><acm-class>I.5.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malaria is a life-threatening disease affecting millions. Microscopy-based
assessment of thin blood films is a standard method to (i) determine malaria
species and (ii) quantitate high-parasitemia infections. Full automation of
malaria microscopy by machine learning (ML) is a challenging task because
field-prepared slides vary widely in quality and presentation, and artifacts
often heavily outnumber relatively rare parasites. In this work, we describe a
complete, fully-automated framework for thin film malaria analysis that applies
ML methods, including convolutional neural nets (CNNs), trained on a large and
diverse dataset of field-prepared thin blood films. Quantitation and species
identification results are close to sufficiently accurate for the concrete
needs of drug resistance monitoring and clinical use-cases on field-prepared
samples. We focus our methods and our performance metrics on the field use-case
requirements. We discuss key issues and important metrics for the application
of ML methods to malaria microscopy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01919</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01919</id><created>2019-08-05</created><authors><author><keyname>Lee</keyname><forenames>Juheon</forenames></author><author><keyname>Choi</keyname><forenames>Hyeong-Seok</forenames></author><author><keyname>Jeon</keyname><forenames>Chang-Bin</forenames></author><author><keyname>Koo</keyname><forenames>Junghyun</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author></authors><title>Adversarially Trained End-to-end Korean Singing Voice Synthesis System</title><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, INTERSPEECH 2019 (oral presentation)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we propose an end-to-end Korean singing voice synthesis system
from lyrics and a symbolic melody using the following three novel approaches:
1) phonetic enhancement masking, 2) local conditioning of text and pitch to the
super-resolution network, and 3) conditional adversarial training. The proposed
system consists of two main modules; a mel-synthesis network that generates a
mel-spectrogram from the given input information, and a super-resolution
network that upsamples the generated mel-spectrogram into a linear-spectrogram.
In the mel-synthesis network, phonetic enhancement masking is applied to
generate implicit formant masks solely from the input text, which enables a
more accurate phonetic control of singing voice. In addition, we show that two
other proposed methods -- local conditioning of text and pitch, and conditional
adversarial training -- are crucial for a realistic generation of the human
singing voice in the super-resolution process. Finally, both quantitative and
qualitative evaluations are conducted, confirming the validity of all proposed
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01927</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01927</id><created>2019-08-05</created><updated>2019-10-30</updated><authors><author><keyname>Yang</keyname><forenames>Peng</forenames></author><author><keyname>Liu</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Zhaojian</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author></authors><title>Distributed Stability Conditions for Power Systems with Heterogeneous
  Nonlinear Bus Dynamics</title><categories>eess.SY cs.SY</categories><comments>Accepted by IEEE Transactions on Power Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives distributed conditions that guarantee the system-wide
stability for power systems with nonlinear and heterogeneous bus dynamics
interconnected via power network. Our conditions require each bus dynamics
should satisfy certain passivity-like conditions with a large enough passivity
index, a sufficient requirement of which is dictated by the steady-state power
flow. The passivity indices uniformly quantify the impacts on the system-wide
stability of individual bus dynamics and the coupling strength from the power
network. Furthermore, taking three typical bus dynamics as examples, we show
that these conditions can be easily fulfilled via proper control design.
Simulations on a rudimentary 3-bus example and the IEEE 39-bus system well
verify our results under both small and large disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01964</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01964</id><created>2019-08-06</created><authors><author><keyname>Kubo</keyname><forenames>Yuki</forenames></author><author><keyname>Takamune</keyname><forenames>Norihiro</forenames></author><author><keyname>Kitamura</keyname><forenames>Daichi</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>Acceleration of rank-constrained spatial covariance matrix estimation
  for blind speech extraction</title><categories>cs.SD eess.AS</categories><comments>7 pages, 3 figures, To appear in the Proceedings of Asia-Pacific
  Signal and Information Processing Association Annual Summit and Conference
  2019 (APSIPA 2019)</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In this paper, we propose new accelerated update rules for rank-constrained
spatial covariance model estimation, which efficiently extracts a directional
target source in diffuse background noise.The naive updat e rule requires heavy
computation such as matrix inversion or matrix multiplication. We resolve this
problem by expanding matrix inversion to reduce computational complexity; in
the parameter update step, we need neither matrix inversion nor multiplication.
In an experiment, we show that the proposed accelerated update rule achieves 87
times faster calculation than the naive one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01974</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01974</id><created>2019-08-06</created><authors><author><keyname>Gao</keyname><forenames>Jun</forenames></author><author><keyname>Gan</keyname><forenames>Luyun</forenames></author><author><keyname>Buschendorf</keyname><forenames>Fabiola</forenames></author><author><keyname>Zhang</keyname><forenames>Liao</forenames></author><author><keyname>Liu</keyname><forenames>Hua</forenames></author><author><keyname>Li</keyname><forenames>Peixue</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>Lu</keyname><forenames>Tao</forenames></author></authors><title>Omni SCADA Intrusion Detection Using Deep Learning Algorithms</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We investigate deep learning based omni intrusion detection system (IDS) for
supervisory control and data acquisition (SCADA) networks that are capable of
detecting both temporally uncorrelated and correlated attacks. Regarding the
IDSs developed in this paper, a feedforward neural network (FNN) can detect
temporally uncorrelated attacks at an {F$_{1}$} of {99.967${\pm}$0.005\%} but
correlated attacks as low as {58${\pm}$2\%}. In contrast, long-short term
memory (LSTM) detects correlated attacks at {99.56${\pm}$0.01\%} while
uncorrelated attacks at {99.3${\pm}$0.1\%}. Combining LSTM and FNN through an
ensemble approach further improves the IDS performance with {F$_{1}$} of
{99.68${\pm}$0.04\%} regardless the temporal correlations among the data
packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01979</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01979</id><created>2019-08-06</created><authors><author><keyname>Vamja</keyname><forenames>Harsh</forenames></author><author><keyname>Agrawal</keyname><forenames>Richa</forenames></author><author><keyname>Vemuri</keyname><forenames>Ranga</forenames></author></authors><title>Non-Invasive Reverse Engineering of Finite State Machines Using Power
  Analysis and Boolean Satisfiability</title><categories>eess.SY cs.CR cs.SY</categories><comments>Black-box Analysis, Finite State Machines, Power Analysis, Reverse
  Engineering, Satisfiability Checking, Proceedings of the 2019 IEEE
  International Midwest Symposium on Circuits and Systems</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we present a non-invasive reverse engineering attack based on
a novel approach that combines functional and power analysis to recover finite
state machines from their synchronous sequential circuit implementations. The
proposed technique formulates the machine exploration and state identification
problem as a Boolean constraint satisfaction problem and solves it using a SMT
(Satisfiability Modulo Theories) solver. It uses power measurements to achieve
fast convergence. Experimental results using the LGSynth'91 benchmark suite
show that the satisfiability-based approach is several times faster compared to
existing techniques and can successfully recover 90%-100% of the transitions of
a target machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01980</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01980</id><created>2019-08-06</created><authors><author><keyname>Herrmann</keyname><forenames>Martin</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Johannes</forenames></author><author><keyname>Strohbeck</keyname><forenames>Jan</forenames></author><author><keyname>Buchholz</keyname><forenames>Michael</forenames></author></authors><title>Environment Modeling Based on Generic Infrastructure Sensor Interfaces
  Using a Centralized Labeled-Multi-Bernoulli Filter</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urban intersections put high demands on fully automated vehicles, in
particular, if occlusion occurs. In order to resolve such and support vehicles
in unclear situations, a popular approach is the utilization of additional
information from infrastructure-based sensing systems. However, a widespread
use of such systems is circumvented by their complexity and thus, high costs.
Within this paper, a generic interface is proposed, which enables a huge
variety of sensors to be connected. The sensors are only required to measure
very few features of the objects, if multiple distributed sensors with
different viewing directions are available. Furthermore, a Labeled
Multi-Bernoulli (LMB) filter is presented, which can not only handle such
measurements, but also infers missing object information about the objects'
extents. The approach is evaluated on simulations and demonstrated on a
real-world infrastructure setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01994</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01994</id><created>2019-08-06</created><authors><author><keyname>Ahang</keyname><forenames>Najmeh</forenames></author><author><keyname>Jahromi</keyname><forenames>Amin Torabi</forenames></author><author><keyname>Doostfatemeh</keyname><forenames>Mansour</forenames></author></authors><title>Comprehensive Fuzzy Turing Machines, An Evolution to the Concept of
  Finite State Machine Control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Turing machine is an abstract concept of a computing device which
introduced new models for computation. The idea of Fuzzy algorithms defined by
Zadeh and Lee was followed by introducing Fuzzy Turing Machine (FTM) to create
a platform for a new fuzzy computation model. Then, in his investigations on
its computational power, Wiedermann showed that FTM is able to solve
undecidable problems. His suggested FTM structure, which highly resembles the
original definition was one of the most well-known classical definitions of FTM
lately.To improve some of its weaknesses and vague points which will be
discussed extensively in this paper, we will develop a more complete definition
for fuzzy Turing machines. Our proposed definition of FTM, which encompasses
the conventional definition, is motivated from the definition of General Fuzzy
Automata (GFA) introduced by Doostfatemeh and Kremer. As it improved the
conventional definition of fuzzy automata, especially the problem of membership
assignment and multi-membership resolution, we also improved the same aspects
of FTM through the definition of Comprehensive Fuzzy Turing Machine (CFTM). In
addition, we address on some possible vaguenesses in FTM was not the subject of
focus in fuzzy automata. As example, we investigate the issue of multi-path and
multi-direction which are possible in case of nondeterminism. Finally, we show
the simplicity, applicability and computational efficiency of the CFTM through
an explanatory example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01996</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01996</id><created>2019-08-06</created><authors><author><keyname>Grace</keyname><forenames>Michael R</forenames></author><author><keyname>Dutton</keyname><forenames>Zachary</forenames></author><author><keyname>Ashok</keyname><forenames>Amit</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author></authors><title>Approaching Quantum Limited Super-Resolution Imaging without Prior
  Knowledge of the Object Location</title><categories>quant-ph eess.IV physics.optics</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recently identified class of receivers which demultiplex an optical field
into a set of orthogonal spatial modes prior to detection can surpass canonical
diffraction limits on spatial resolution for simple incoherent imaging tasks.
However, these mode-sorting receivers tend to exhibit high sensitivity to
contextual nuisance parameters (e.g., the centroid of a clustered or extended
object), raising questions on their viability in realistic imaging scenarios
where little or no prior information about the scene is available. We propose a
multi-stage passive imaging strategy which segments the total recording time
between different physical measurements to build up the required prior
information for near quantum-optimal imaging performance at sub-Rayleigh length
scales. We show via Monte Carlo simulations that an adaptive two-stage scheme
which dynamically allocates the total recording time between a traditional
direct detection measurement and a binary mode-sorting receiver outperforms
idealized direct detection alone for simple estimation tasks when no prior
knowledge of the object centroid is available, achieving one to two orders of
magnitude improvement in mean squared error. Our scheme can be generalized for
more sophisticated imaging tasks with multiple parameters and minimal prior
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01997</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.01997</id><created>2019-08-06</created><authors><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Sun</keyname><forenames>Hui</forenames></author><author><keyname>Liu</keyname><forenames>Zaiyi</forenames></author><author><keyname>Wang</keyname><forenames>Meiyun</forenames></author><author><keyname>Zheng</keyname><forenames>Hairong</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author></authors><title>Learning Cross-Modal Deep Representations for Multi-Modal MR Image
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-modal magnetic resonance imaging (MRI) is essential in clinics for
comprehensive diagnosis and surgical planning. Nevertheless, the segmentation
of multi-modal MR images tends to be time-consuming and challenging.
Convolutional neural network (CNN)-based multi-modal MR image analysis commonly
proceeds with multiple down-sampling streams fused at one or several layers.
Although inspiring performance has been achieved, the feature fusion is usually
conducted through simple summation or concatenation without optimization. In
this work, we propose a supervised image fusion method to selectively fuse the
useful information from different modalities and suppress the respective noise
signals. Specifically, an attention block is introduced as guidance for the
information selection. From the different modalities, one modality that
contributes most to the results is selected as the master modality, which
supervises the information selection of the other assistant modalities. The
effectiveness of the proposed method is confirmed through breast mass
segmentation in MR images of two modalities and better segmentation results are
achieved compared to the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02014</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02014</id><created>2019-08-06</created><authors><author><keyname>Xiong</keyname><forenames>Guojun</forenames></author><author><keyname>Kim</keyname><forenames>Taejoon</forenames></author><author><keyname>Perrins</keyname><forenames>Erik</forenames></author></authors><title>Decorrelation Deep Learning for Fingerprint-based Indoor Localization</title><categories>eess.SP</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor localization is of particular interest due to its immense practical
applications. However, the rich multipath and high penetration loss of indoor
wireless signal propagation make this task arduous. Though recently studied
fingerprint-based techniques can handle the multipath effects, the sensitivity
of the localization performance to channel fluctuation is a drawback. To
address the latter challenge, we adopt an artificial multi-layer neural network
(MNN) to learn the complex channel impulse responses (CIRs) as fingerprint
measurements. However, the performance of the location classification using MNN
critically depends on the correlation among the training data. Therefore, we
design two different decorrelation filters that preprocess the training data
for discriminative learning. The first one is a linear whitening filter
combined with the principal component analysis (PCA), which forces the
covariance matrix of different feature dimensions to be identity. The other
filter is a nonlinear quantizer that is optimized to minimize the distortion
incurred by the quantization. Numerical results using indoor channel models
illustrate the significant improvement of the proposed decorrelation MNN (DMNN)
compared to other benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02039</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02039</id><created>2019-08-06</created><updated>2019-08-23</updated><authors><author><keyname>Artru</keyname><forenames>Romain</forenames></author><author><keyname>Gouaillard</keyname><forenames>Alexandre</forenames></author><author><keyname>Ebrahimi</keyname><forenames>Touradj</forenames></author></authors><title>Digital Watermarking of video streams: Review of the State-Of-The-Art</title><categories>eess.IV cs.MM</categories><comments>33 pages, 11 figues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Watermarking is an extremely wide aspect of information security,
either by its applications, by its properties, or by its designs. In
particular, a lot of research has been made about video watermarking and it can
make it quite difficult to put into perspective the various schemes possible in
order to implement a watermarking process for a given application. This paper
presents an in-depth overview of the current video watermarking technologies
and how they each respond to certain criteria that may be imposed by the aimed
application. The goal being in first place to be able to define the desired
equilibrium point between invisibility, robustness and efficiency for an
application. Then, given this balance, being able to deduce the best location
of the information embedding as well as the method used to embed it. The
equilibrium point is to be found using the needed properties of the watermark
and by studying the threat model that the scheme will have to face. The
location describes whether the extra information should be added to the
metadata of the video, to its frames or to specific regions of its frames.
Finally, the method to embed the watermark refers to the insertion domain and
its coefficients to be altered in order to insert the wanted information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02054</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02054</id><created>2019-08-06</created><authors><author><keyname>Chen</keyname><forenames>Yanxia</forenames></author><author><keyname>Xiao</keyname><forenames>Taohui</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Liu</keyname><forenames>Qiegen</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author></authors><title>Model-based Convolutional De-Aliasing Network Learning for Parallel MR
  Imaging</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel imaging has been an essential technique to accelerate MR imaging.
Nevertheless, the acceleration rate is still limited due to the ill-condition
and challenges associated with the undersampled reconstruction. In this paper,
we propose a model-based convolutional de-aliasing network with adaptive
parameter learning to achieve accurate reconstruction from multi-coil
undersampled k-space data. Three main contributions have been made: a
de-aliasing reconstruction model was proposed to accelerate parallel MR imaging
with deep learning exploring both spatial redundancy and multi-coil
correlations; a split Bregman iteration algorithm was developed to solve the
model efficiently; and unlike most existing parallel imaging methods which rely
on the accuracy of the estimated multi-coil sensitivity, the proposed method
can perform parallel reconstruction from undersampled data without explicit
sensitivity calculation. Evaluations were conducted on \emph{in vivo} brain
dataset with a variety of undersampling patterns and different acceleration
factors. Our results demonstrated that this method could achieve superior
performance in both quantitative and qualitative analysis, compared to three
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02077</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02077</id><created>2019-08-06</created><authors><author><keyname>Menon</keyname><forenames>Aiswarya</forenames></author><author><keyname>Prakash</keyname><forenames>Ravi</forenames></author><author><keyname>Behera</keyname><forenames>Laxmidhar</forenames></author></authors><title>Adaptive Critic Based Optimal Kinematic Control for a Robot Manipulator</title><categories>eess.SY cs.SY</categories><comments>Accepted for publication in IEEE International Conference on Robotics
  and Automation (ICRA), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the optimal kinematic control of a robot
manipulator where the robot end effector position follows a task space
trajectory. The joints are actuated with the desired velocity profile to
achieve this task. This problem has been solved using a single network adaptive
critic (SNAC) by expressing the forward kinematics as input affine system.
Usually in SNAC, the critic weights are updated using back propagation
algorithm while little attention is given to convergence to the optimal cost.
In this paper, we propose a critic weight update law that ensures convergence
to the desired optimal cost while guaranteeing the stability of the closed loop
kinematic control. In kinematic control, the robot is required to reach a
specific target position. This has been solved as an optimal regulation problem
in the context of SNAC based kinematic control. When the robot is required to
follow a time varying task space trajectory, then the kinematic control has
been framed as an optimal tracking problem. For tracking, an augmented system
consisting of tracking error and reference trajectory is constructed and the
optimal control policy is derived using SNAC framework. The stability and
performance of the system under the proposed novel weight tuning law is
guaranteed using Lyapunov approach. The proposed kinematic control scheme has
been validated in simulations and experimentally executed using a real six
degrees of freedom (DOF) Universal Robot (UR) 10 manipulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02101</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02101</id><created>2019-08-06</created><updated>2019-12-04</updated><authors><author><keyname>Dees</keyname><forenames>Bruno Scalzo</forenames></author></authors><title>Analysing Global Fixed Income Markets with Tensors</title><categories>q-fin.PM econ.EM eess.SP q-fin.ST stat.AP</categories><comments>9 pages, 6 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global fixed income returns span across multiple maturities and economies,
that is, they naturally reside on multi-dimensional data structures referred to
as tensors. In contrast to standard &quot;flat-view&quot; multivariate models that are
agnostic to data structure and only describe linear pairwise relationships, we
introduce a tensor-valued approach to model the global risks shared by multiple
interest rate curves. In this way, the estimated risk factors can be
analytically decomposed into maturity-domain and country-domain constituents,
which allows the investor to devise rigorous and tractable global portfolio
management and hedging strategies tailored to each risk domain. An empirical
analysis confirms the existence of global risk factors shared by eight
developed economies, and demonstrates their ability to compactly describe the
global macroeconomic environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02111</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02111</id><created>2019-08-06</created><authors><author><keyname>Wu</keyname><forenames>Huikai</forenames></author><author><keyname>Zhang</keyname><forenames>Junge</forenames></author><author><keyname>Huang</keyname><forenames>Kaiqi</forenames></author></authors><title>Point Cloud Super Resolution with Adversarial Residual Graph Networks</title><categories>cs.GR eess.IV</categories><comments>Code is available at
  https://github.com/wuhuikai/PointCloudSuperResolution</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Point cloud super-resolution is a fundamental problem for 3D reconstruction
and 3D data understanding. It takes a low-resolution (LR) point cloud as input
and generates a high-resolution (HR) point cloud with rich details. In this
paper, we present a data-driven method for point cloud super-resolution based
on graph networks and adversarial losses. The key idea of the proposed network
is to exploit the local similarity of point cloud and the analogy between LR
input and HR output. For the former, we design a deep network with graph
convolution. For the latter, we propose to add residual connections into graph
convolution and introduce a skip connection between input and output. The
proposed network is trained with a novel loss function, which combines Chamfer
Distance (CD) and graph adversarial loss. Such a loss function captures the
characteristics of HR point cloud automatically without manual design. We
conduct a series of experiments to evaluate our method and validate the
superiority over other methods. Results show that the proposed method achieves
the state-of-the-art performance and have a good generalization ability to
unseen data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02118</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02118</id><created>2019-08-06</created><authors><author><keyname>Ndonda</keyname><forenames>Gorby Kabasele</forenames></author><author><keyname>Sadre</keyname><forenames>Ramin</forenames></author></authors><title>A Public Network Trace of a Control and Automation System</title><categories>cs.CR cs.NI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing number of attacks against automation systems such as SCADA and
their network infrastructure have demonstrated that there is a need to secure
those systems. Unfortunately, directly applying existing ICT security
mechanisms to automation systems is hard due to constraints of the latter, such
as availability requirements or limitations of the hardware. Thus, the solution
privileged by researchers is the use of network-based intrusion detection
systems (N-IDS). One of the issue that many researchers encounter is how to
validate and evaluate their N-IDS. Having access to a real and large automation
systems for experimentation is almost impossible as companies are not inclined
to give access to their systems due to obvious concerns. The few public traffic
datasets that could be used for off-line experiments are either synthetic or
collected at small testbeds. In this paper, we will describe and characterize a
public traffic dataset collected at the HVAC management system of a university
campus. Although the dataset contains only packet headers, we believe that it
can help researchers, in particular designers of flow-based IDS, to validate
their solutions under more realistic conditions. The traces can be found on
https://github.com/gkabasele/HVAC_Traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02119</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02119</id><created>2019-08-06</created><authors><author><keyname>Hatala</keyname><forenames>Zulkarnaen</forenames></author></authors><title>Practical Speech Recognition with HTK</title><categories>eess.AS cs.HC cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The practical aspects of developing an Automatic Speech Recognition System
(ASR) with HTK are reviewed. Steps are explained concerning hardware, software,
libraries, applications and computer programs used. The common procedure to
rapidly apply speech recognition system is summarized. The procedure is
illustrated, to implement a speech based electrical switch in home automation
for the Indonesian language. The main key of the procedure is to match the
environment for training and testing using the training data recorded from the
testing program, HVite. Often the silence detector of HTK is wrongly triggered
by noises because the microphone is too sensitive. This problem is mitigated by
simply scaling down the volume. In this sub-word phone-based speech
recognition, noise is included in the training database and labelled
particularly. Illustration of the procedure is applied to a home automation
application. Electrical switches are controlled by Indonesian speech
recognizer. The results show 100% command completion rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02125</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02125</id><created>2019-08-04</created><authors><author><keyname>Wang</keyname><forenames>Wei-Ting</forenames></author><author><keyname>Li</keyname><forenames>Han-Lin</forenames></author><author><keyname>Lin</keyname><forenames>Wei-Shiang</forenames></author><author><keyname>Chiang</keyname><forenames>Cheng-Ming</forenames></author><author><keyname>Tsai</keyname><forenames>Yi-Min</forenames></author></authors><title>Architecture-aware Network Pruning for Vision Quality Applications</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted to be Published in the 26th IEEE International Conference on
  Image Processing (ICIP 2019). Updated to contain the IEEE copyright notice</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural network (CNN) delivers impressive achievements in
computer vision and machine learning field. However, CNN incurs high
computational complexity, especially for vision quality applications because of
large image resolution. In this paper, we propose an iterative
architecture-aware pruning algorithm with adaptive magnitude threshold while
cooperating with quality-metric measurement simultaneously. We show the
performance improvement applied on vision quality applications and provide
comprehensive analysis with flexible pruning configuration. With the proposed
method, the Multiply-Accumulate (MAC) of state-of-the-art low-light imaging
(SID) and super-resolution (EDSR) are reduced by 58% and 37% without quality
drop, respectively. The memory bandwidth (BW) requirements of convolutional
layer can be also reduced by 20% to 40%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02170</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02170</id><created>2019-08-06</created><authors><author><keyname>Banga</keyname><forenames>Dennis</forenames></author><author><keyname>Waiganjo</keyname><forenames>Peter</forenames></author></authors><title>Abnormality Detection in Musculoskeletal Radiographs with Convolutional
  Neural Networks(Ensembles) and Performance Optimization</title><categories>cs.CY cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musculoskeletal conditions affect more than 1.7 billion people worldwide
based on a study by Global Burden Disease, and they are the second greatest
cause of disability[1,2]. The diagnosis of these conditions vary but mostly
physical exams carried out and image tests. There are few imaging and
diagnostic experts while there is a huge workload of radiograph examinations
which might affect diagnostic accuracy. We built machine learning models to
perform abnormality detection using the available musculoskeletal public
dataset [3]. Convolutional Neural Networks (CNN) were used as are the most
successful models in performing various tasks such as classification and object
detection [4]. The development of the models involved theoretical study,
iterative prototyping, and empirical evaluation of the results. The current
model, 169 layer DenseNet, by Pranav et al.(2018) on the abnormality detection
task, the performance was lower than the worst radiologist in 5 out of the 7
studies, and the overall model performance was lower than the best radiologist.
We developed the ensemble200 model which scored 0.66 Cohen Kappa which was
lower than the DenseNet model (Pranav et al, 2018) but the model performance
with the F1 score outperforms the DenseNet model and its Cohen Kappa score
variability with the different studies is lower as the best cohen kappa score
on the upper extremity studies is 0.7408 (Wrist) and the lowest is (0.5844)
hand. The ensemble200 model outperformed DenseNet model on the finger studies
with a Cohen Kappa score of 0.653 showing reduced performance variability on
the model performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02182</identifier>
 <datestamp>2019-10-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02182</id><created>2019-08-06</created><updated>2019-10-04</updated><authors><author><keyname>Isensee</keyname><forenames>Fabian</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Klaus H.</forenames></author></authors><title>An attempt at beating the 3D U-Net</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The U-Net is arguably the most successful segmentation architecture in the
medical domain. Here we apply a 3D U-Net to the 2019 Kidney and Kidney Tumor
Segmentation Challenge and attempt to improve upon it by augmenting it with
residual and pre-activation residual blocks. Cross-validation results on the
training cases suggest only very minor, barely measurable improvements. Due to
marginally higher dice scores, the residual 3D U-Net is chosen for test set
prediction. With a Composite Dice score of 91.23 on the test set, our method
outperformed all 105 competing teams and won the KiTS2019 challenge by a small
margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02242</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02242</id><created>2019-08-01</created><updated>2019-08-12</updated><authors><author><keyname>Tsopanidis</keyname><forenames>Stylianos</forenames></author><author><keyname>Moreno</keyname><forenames>Ra&#xfa;l Herrero</forenames></author><author><keyname>Osovski</keyname><forenames>Shmuel</forenames></author></authors><title>Toward quantitative fractography using convolutional neural networks</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The science of fractography revolves around the correlation between
topographic characteristics of the fracture surface and the mechanisms and
external conditions leading to their creation. While being a topic of
investigation for centuries, it has remained mostly qualitative to date. A
quantitative analysis of fracture surfaces is of prime interest for both the
scientific community and the industrial sector, bearing the potential for
improved understanding on the mechanisms controlling the fracture process and
at the same time assessing the reliability of computational models currently
being used for material design. With new advances in the field of image
analysis, and specifically with machine learning tools becoming more accessible
and reliable, it is now feasible to automate the process of extracting
meaningful information from fracture surface images. Here, we propose a method
of identifying and quantifying the relative appearance of intergranular and
transgranular fracture events from scanning electron microscope images. The
newly proposed method is based on a convolutional neural network algorithm for
semantic segmentation. The proposed method is extensively tested and evaluated
against two ceramic material systems ($Al_2O_3$,$MgAl_2O_4$) and shows high
prediction accuracy, despite being trained on only one material system
($MgAl_2O_4$). While here attention is focused on brittle fracture
characteristics, the method can be easily extended to account for other
fracture morphologies, such as dimples, fatigue striations, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02252</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02252</id><created>2019-08-06</created><updated>2019-10-31</updated><authors><author><keyname>Zhang</keyname><forenames>Guangyi</forenames></author><author><keyname>Davoodnia</keyname><forenames>Vandad</forenames></author><author><keyname>Sepas-Moghaddam</keyname><forenames>Alireza</forenames></author><author><keyname>Zhang</keyname><forenames>Yaoxue</forenames></author><author><keyname>Etemad</keyname><forenames>Ali</forenames></author></authors><title>Classification of Hand Movements from EEG using a Deep Attention-based
  LSTM Network</title><categories>cs.LG eess.SP stat.ML</categories><doi>10.1109/JSEN.2019.2956998</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifying limb movements using brain activity is an important task in
Brain-computer Interfaces (BCI) that has been successfully used in multiple
application domains, ranging from human-computer interaction to medical and
biomedical applications. This paper proposes a novel solution for
classification of left/right hand movement by exploiting a Long Short-Term
Memory (LSTM) network with attention mechanism to learn the
electroencephalogram (EEG) time-series information. To this end, a wide range
of time and frequency domain features are extracted from the EEG signals and
used to train an LSTM network to perform the classification task. We conduct
extensive experiments with the EEG Movement dataset and show that our proposed
solution our method achieves improvements over several benchmarks and
state-of-the-art methods in both intra-subject and cross-subject validation
schemes. Moreover, we utilize the proposed framework to analyze the information
as received by the sensors and monitor the activated regions of the brain by
tracking EEG topography throughout the experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02283</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02283</id><created>2019-08-06</created><authors><author><keyname>Ren</keyname><forenames>Zongze</forenames></author><author><keyname>Chen</keyname><forenames>Zhiyong</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author></authors><title>Triplet Based Embedding Distance and Similarity Learning for
  Text-independent Speaker Verification</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>5 pages, Accepted to The Asia-Pacific Signal and Information
  Processing Association Annual Summit and Conference 2019 (APSIPA ASC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker embeddings become growing popular in the text-independent speaker
verification task. In this paper, we propose two improvements during the
training stage. The improvements are both based on triplet cause the training
stage and the evaluation stage of the baseline x-vector system focus on
different aims. Firstly, we introduce triplet loss for optimizing the Euclidean
distances between embeddings while minimizing the multi-class cross entropy
loss. Secondly, we design an embedding similarity measurement network for
controlling the similarity between the two selected embeddings. We further
jointly train the two new methods with the original network and achieve
state-of-the-art. The multi-task training synergies are shown with a 9%
reduction equal error rate (EER) and detected cost function (DCF) on the 2016
NIST Speaker Recognition Evaluation (SRE) Test Set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02284</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02284</id><created>2019-08-06</created><updated>2019-08-10</updated><authors><author><keyname>Ren</keyname><forenames>Zongze</forenames></author><author><keyname>Yang</keyname><forenames>Guofu</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author></authors><title>Two-stage Training for Chinese Dialect Recognition</title><categories>cs.CL cs.LG eess.AS</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a two-stage language identification (LID) system
based on a shallow ResNet14 followed by a simple 2-layer recurrent neural
network (RNN) architecture, which was used for Xunfei (iFlyTek) Chinese Dialect
Recognition Challenge and won the first place among 110 teams. The system
trains an acoustic model (AM) firstly with connectionist temporal
classification (CTC) to recognize the given phonetic sequence annotation and
then train another RNN to classify dialect category by utilizing the
intermediate features as inputs from the AM. Compared with a three-stage system
we further explore, our results show that the two-stage system can achieve high
accuracy for Chinese dialects recognition under both short utterance and long
utterance conditions with less training time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02288</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02288</id><created>2019-08-06</created><updated>2019-08-30</updated><authors><author><keyname>Combalia</keyname><forenames>Marc</forenames></author><author><keyname>Codella</keyname><forenames>Noel C. F.</forenames></author><author><keyname>Rotemberg</keyname><forenames>Veronica</forenames></author><author><keyname>Helba</keyname><forenames>Brian</forenames></author><author><keyname>Vilaplana</keyname><forenames>Veronica</forenames></author><author><keyname>Reiter</keyname><forenames>Ofer</forenames></author><author><keyname>Carrera</keyname><forenames>Cristina</forenames></author><author><keyname>Barreiro</keyname><forenames>Alicia</forenames></author><author><keyname>Halpern</keyname><forenames>Allan C.</forenames></author><author><keyname>Puig</keyname><forenames>Susana</forenames></author><author><keyname>Malvehy</keyname><forenames>Josep</forenames></author></authors><title>BCN20000: Dermoscopic Lesions in the Wild</title><categories>eess.IV cs.CV</categories><comments>Abstract for BCN20000</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article summarizes the BCN20000 dataset, composed of 19424 dermoscopic
images of skin lesions captured from 2010 to 2016 in the facilities of the
Hospital Cl\'inic in Barcelona. With this dataset, we aim to study the problem
of unconstrained classification of dermoscopic images of skin cancer, including
lesions found in hard-to-diagnose locations (nails and mucosa), large lesions
which do not fit in the aperture of the dermoscopy device, and hypo-pigmented
lesions. The BCN20000 will be provided to the participants of the ISIC
Challenge 2019, where they will be asked to train algorithms to classify
dermoscopic images of skin cancer automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02300</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02300</id><created>2019-08-06</created><authors><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>Mathew</keyname><forenames>Melvin J.</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author><author><keyname>Khalifa</keyname><forenames>Yousuf M.</forenames></author></authors><title>Relative Afferent Pupillary Defect Screening through Transfer Learning</title><categories>cs.CV eess.IV eess.SP</categories><comments>8 pages, 7 figures, 4 tables. IEEE Journal of Biomedical and Health
  Informatics, 2019</comments><acm-class>I.4</acm-class><doi>10.1109/JBHI.2019.2933773</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abnormalities in pupillary light reflex can indicate optic nerve disorders
that may lead to permanent visual loss if not diagnosed in an early stage. In
this study, we focus on relative afferent pupillary defect (RAPD), which is
based on the difference between the reactions of the eyes when they are exposed
to light stimuli. Incumbent RAPD assessment methods are based on subjective
practices that can lead to unreliable measurements. To eliminate subjectivity
and obtain reliable measurements, we introduced an automated framework to
detect RAPD. For validation, we conducted a clinical study with
lab-on-a-headset, which can perform automated light reflex test. In addition to
benchmarking handcrafted algorithms, we proposed a transfer learning-based
approach that transformed a deep learning-based generic object recognition
algorithm into a pupil detector. Based on the conducted experiments, proposed
algorithm RAPDNet can achieve a sensitivity and a specificity of 90.6% over 64
test cases in a balanced set, which corresponds to an AUC of 0.929 in ROC
analysis. According to our benchmark with three handcrafted algorithms and nine
performance metrics, RAPDNet outperforms all other algorithms in every
performance category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02304</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02304</id><created>2019-08-06</created><authors><author><keyname>Sarmento</keyname><forenames>Thiago</forenames></author><author><keyname>Nakamura</keyname><forenames>Andrey</forenames></author><author><keyname>Filho</keyname><forenames>Itelo</forenames></author><author><keyname>Correa</keyname><forenames>Lucas</forenames></author><author><keyname>Takeda</keyname><forenames>Marcos</forenames></author><author><keyname>Castro</keyname><forenames>Adalbery</forenames></author><author><keyname>Klautau</keyname><forenames>Aldebaro</forenames></author></authors><title>Development and Evaluation of Least Square Satellite Tracking in Real
  Antenna Control System</title><categories>eess.SP</categories><comments>4 pages, XXXVI SIMPOSIO BRASILEIRO DE TELECOMUNICA\c{C}\~OES E
  PROCESSAMENTO DE SINAIS - SBrT2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work describes the implementation of a satellite tracking technique in a
real antenna control system. The technique uses least squares estimation to
search for the best antenna pointing position to receive the satellite beacon
signal tracked in the 2D region created by the motion axes. The work also
presents the technique implementation results in the real system to prove its
operation with the beacon signal intensity and the orbit obtained with the
search over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02313</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02313</id><created>2019-08-06</created><authors><author><keyname>Rejesh</keyname><forenames>Nadaparambil Aravindakshan</forenames></author><author><keyname>Kalva</keyname><forenames>Sandeep Kumar</forenames></author><author><keyname>Pramanik</keyname><forenames>Manojit</forenames></author><author><keyname>Arigovindan</keyname><forenames>Muthuvel</forenames></author></authors><title>Model based image recovery in photoacoustic tomography using hybrid
  non-convex regularization</title><categories>eess.IV</categories><comments>First draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel model based image reconstruction method in photoacoustic
tomography (PAT) involving a novel form of regularization that is specifically
tuned for PAT images, and a novel computational scheme for implementing the
forward model without building large matrices. The regularization is
constructed by combining second order derivatives and intensity into a
non-convex form so as to exploit the properties of typical PAT images that we
observed: in PAT images, high intensities and high second order derivatives are
jointly sparse. As non-convex regularized reconstruction requires large number
of iterations, and the PAT forward model has to be applied in the iterations,
we propose efficient computational structures for matrix-free implementation of
the forward model. We evaluate the proposed method on both simulated and real
measured data sets and compare with recent fast iterative shrinkage threshold
algorithm (FISTA)-based reconstruction method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02333</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02333</id><created>2019-08-06</created><authors><author><keyname>Ranjbar</keyname><forenames>Sara</forenames></author><author><keyname>Singleton</keyname><forenames>Kyle W.</forenames></author><author><keyname>Curtin</keyname><forenames>Lee</forenames></author><author><keyname>Massey</keyname><forenames>Susan Christine</forenames></author><author><keyname>Hawkins-Daarud</keyname><forenames>Andrea</forenames></author><author><keyname>Jackson</keyname><forenames>Pamela R.</forenames></author><author><keyname>Swanson</keyname><forenames>Kristin R.</forenames></author></authors><title>Sex differences in predicting fluid intelligence of adolescent brain
  from T1-weighted MRIs</title><categories>q-bio.NC eess.IV</categories><comments>8 pages plus references, 2 figures, 2 tables. Submission to the ABCD
  Neurocognitive Prediction Challenge at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluid intelligence (Gf) has been defined as the ability to reason and solve
previously unseen problems. Links to Gf have been found in magnetic resonance
imaging (MRI) sequences such as functional MRI and diffusion tensor imaging. As
part of the Adolescent Brain Cognitive Development Neurocognitive Prediction
Challenge 2019, we sought to predict Gf in children aged 9-10 from T1-weighted
(T1W) MRIs. The data included atlas-aligned volumetric T1W images,
atlas-defined segmented regions, age, and sex for 3739 subjects used for
training and internal validation and 415 subjects used for external validation.
We trained sex-specific convolutional neural net (CNN) and random forest models
to predict Gf. For the convolutional model, skull-stripped volumetric T1W
images aligned to the SRI24 brain atlas were used for training. Volumes of
segmented atlas regions along with each subject's age were used to train the
random forest regressor models. Performance was measured using the mean squared
error (MSE) of the predictions. Random forest models achieved lower MSEs than
CNNs. Further, the external validation data had a better MSE for females than
males (60.68 vs. 80.74), with a combined MSE of 70.83. Our results suggest that
predictive models of Gf from volumetric T1W MRI features alone may perform
better when trained separately on male and female data. However, the
performance of our models indicates that more information is necessary beyond
the available data to make accurate predictions of Gf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02334</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02334</id><created>2019-08-06</created><authors><author><keyname>Diller</keyname><forenames>Emily E</forenames></author><author><keyname>Cao</keyname><forenames>Sha</forenames></author><author><keyname>Ey</keyname><forenames>Beth</forenames></author><author><keyname>Lober</keyname><forenames>Robert</forenames></author><author><keyname>Parker</keyname><forenames>Jason G</forenames></author></authors><title>Predicted disease compositions of human gliomas estimated from
  multiparametric MRI can predict endothelial proliferation, tumor grade, and
  overall survival</title><categories>q-bio.QM cs.LG eess.IV physics.med-ph stat.AP stat.ML</categories><comments>13 pages, 3 figures, 5 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Background and Purpose: Biopsy is the main determinants of glioma clinical
management, but require invasive sampling that fail to detect relevant features
because of tumor heterogeneity. The purpose of this study was to evaluate the
accuracy of a voxel-wise, multiparametric MRI radiomic method to predict
features and develop a minimally invasive method to objectively assess
neoplasms.
  Methods: Multiparametric MRI were registered to T1-weighted gadolinium
contrast-enhanced data using a 12 degree-of-freedom affine model. The
retrospectively collected MRI data included T1-weighted, T1-weighted gadolinium
contrast-enhanced, T2-weighted, fluid attenuated inversion recovery, and
multi-b-value diffusion-weighted acquired at 1.5T or 3.0T. Clinical experts
provided voxel-wise annotations for five disease states on a subset of patients
to establish a training feature vector of 611,930 observations. Then, a
k-nearest-neighbor (k-NN) classifier was trained using a 25% hold-out design.
The trained k-NN model was applied to 13,018,171 observations from seventeen
histologically confirmed glioma patients. Linear regression tested overall
survival (OS) relationship to predicted disease compositions (PDC) and
diagnostic age (alpha = 0.05). Canonical discriminant analysis tested if PDC
and diagnostic age could differentiate clinical, genetic, and microscopic
factors (alpha = 0.05).
  Results: The model predicted voxel annotation class with a Dice similarity
coefficient of 94.34% +/- 2.98. Linear combinations of PDCs and diagnostic age
predicted OS (p = 0.008), grade (p = 0.014), and endothelia proliferation (p =
0.003); but fell short predicting gene mutations for TP53BP1 and IDH1.
  Conclusions: This voxel-wise, multi-parametric MRI radiomic strategy holds
potential as a non-invasive decision-making aid for clinicians managing
patients with glioma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02366</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02366</id><created>2019-08-06</created><updated>2020-02-01</updated><authors><author><keyname>Ma</keyname><forenames>Meiyi</forenames></author><author><keyname>Bartocci</keyname><forenames>Ezio</forenames></author><author><keyname>Feng</keyname><forenames>Lu</forenames></author><author><keyname>Stankovic</keyname><forenames>John</forenames></author></authors><title>Runtime Monitoring of Real-time Safety Requirements in Smart Cities</title><categories>cs.CY cs.SY eess.SY</categories><comments>12 pages, 7 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an increasing need for the runtime monitoring of real time safety
and performance requirements in smart cities. In this paper, we present SaSTL,
a novel Spatial Aggregation Signal Temporal Logic, to specify and monitor real
time requirements in smart cities. We also develop an efficient runtime
monitoring algorithm that can check in parallel a SaSTL requirement over
multiple data streams generated from thousands of sensors that are typically
spatially distributed over a smart city. We evaluate the real time SaSTL
monitor by applying it to two city application scenarios with large scale real
sensing data, (e.g., up to 10,000 sensors in one requirement). The results show
that SaSTL monitoring can help improve the city performance in simulated
experiments (e.g., 21.1% on the environment and 16.6% on public safety) with a
significant reduction of computation time compared with previous approaches
(e.g., from 2 hours to 30 minutes on average when monitoring 80 requirements).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02379</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02379</id><created>2019-08-06</created><authors><author><keyname>Haber</keyname><forenames>Aleksandar</forenames></author></authors><title>Subspace Identification of Temperature Dynamics</title><categories>eess.SY cs.SY</categories><comments>10 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven modeling and control of temperature dynamics in mechatronics
systems and industrial processes are challenging control engineering problems.
This is mainly because the temperature dynamics is inherently
infinite-dimensional, nonlinear, spatially distributed, and coupled with other
physical processes. Furthermore, the dominant time constants are usually long,
implying that in practice due to various economic and time constraints, we can
only collect a relatively small number of data samples that can be used for
data-driven modeling. Finally, since sensing and actuation of temperature
dynamics are often spatially discrete, special attention needs to be given to
sensor (actuator) placement and identifiability problems. Motivated by these
challenges, in this manuscript, we consider the problem of data-driven modeling
and validation of temperature dynamics. We have developed an experimental setup
consisting of a long aluminum bar whose temperature dynamics is influenced by
spatially distributed heat actuators and whose temperature is sensed by
spatially distributed thermocouples. We address the noise reduction problem and
perform step response and nonlinearity analyses. We combine predictor based
subspace identification methods with time series analysis methods to identify a
multiple-input multiple-output system model. We provide detailed treatments of
model structure selection, validation, and residual analysis problems under
different modeling and prediction scenarios. Our extensive experimental results
show that the temperature dynamics of the experimental setup can be relatively
accurately estimated by low-order models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02392</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02392</id><created>2019-08-06</created><authors><author><keyname>Lakshminarayana</keyname><forenames>Subhash</forenames></author><author><keyname>Belmega</keyname><forenames>E. Veronica</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Moving-Target Defense for Detecting Coordinated Cyber-Physical Attacks
  in Power Grids</title><categories>cs.CR cs.IT cs.SY eess.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a moving target defense (MTD) strategy to detect
coordinated cyber-physical attacks (CCPAs) against power grids. A CCPA consists
of a physical attack, such as disconnecting a transmission line, followed by a
coordinated cyber attack that injects false data into the sensor measurements
to mask the effects of the physical attack. Such attacks can lead to
undetectable line outages and cause significant damage to the grid. The main
idea of the proposed approach is to invalidate the knowledge that the attackers
use to mask the effects of the physical attack by actively perturbing the
grid's transmission line reactances using distributed flexible AC transmission
system (D-FACTS) devices. We identify the MTD design criteria in this context
to thwart CCPAs. The proposed MTD design consists of two parts. First, we
identify the subset of links for D-FACTS device deployment that enables the
defender to detect CCPAs against any link in the system. Then, in order to
minimize the defense cost during the system's operational time, we use a
game-theoretic approach to identify the best subset of links (within the
D-FACTS deployment set) to perturb which will provide adequate protection.
Extensive simulations performed using the MATPOWER simulator on IEEE bus
systems verify the effectiveness of our approach in detecting CCPAs and
reducing the operator's defense cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02405</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02405</id><created>2019-08-06</created><authors><author><keyname>Xiong</keyname><forenames>Xi</forenames></author><author><keyname>Wang</keyname><forenames>Teze</forenames></author><author><keyname>Jin</keyname><forenames>Li</forenames></author></authors><title>Evaluation of Headway Threshold-based Coordinated Platooning over a
  Cascade of Highway Junctions</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Platooning of vehicles with coordinated adaptive cruise control (CACC)
capabilities is a promising technology with a strong potential for fuel savings
and congestion mitigation. Although some researchers have studied the
vehicle-level fuel savings of platooning, few have considered the system-level
benefits. This paper evaluates vehicle platooning as a fuel-reduction method
and propose a hierarchical control system. We particularly focus on the impact
of platooning coordination algorithm on system-wide benefits. The main task of
platooning coordination is to regulate the times at which multiple vehicles
arrive at a particular junction: these vehicles can platoon only if they meet
(i.e. arrive within a common time interval) at the junction. We use a
micro-simulation model to evaluate a class of threshold-based coordination
strategies and derive insights about the trade-off between the fuel savings due
to air drag reduction in platoons and the extra fuel consumption due to the
coordination (i.e. acceleration of some vehicles to catch up with the leading
ones). The model is calibrated using real traffic data of a section of
Interstate 210 in the Los Angeles metropolitan area. We study the relation
between key decision variables, including the platooning threshold and the
coordination radius, and key performance metric, fuel consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02408</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02408</id><created>2019-08-06</created><updated>2020-01-03</updated><authors><author><keyname>Mandal</keyname><forenames>Sumit K.</forenames></author><author><keyname>Ayoub</keyname><forenames>Raid</forenames></author><author><keyname>Kishinevsky</keyname><forenames>Michael</forenames></author><author><keyname>Ogras</keyname><forenames>Umit Y.</forenames></author></authors><title>Analytical Performance Models for NoCs with Multiple Priority Traffic
  Classes</title><categories>cs.PF cs.SY eess.SY</categories><comments>This article will appear as part of the ESWEEK-TECS special issue and
  will be presented in the International Conference on Compilers, Architecture,
  and Synthesis for Embedded Systems (CASES) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks-on-chip (NoCs) have become the standard for interconnect solutions
in industrial designs ranging from client CPUs to many-core
chip-multiprocessors. Since NoCs play a vital role in system performance and
power consumption, pre-silicon evaluation environments include cycle-accurate
NoC simulators. Long simulations increase the execution time of evaluation
frameworks, which are already notoriously slow, and prohibit design-space
exploration. Existing analytical NoC models, which assume fair arbitration,
cannot replace these simulations since industrial NoCs typically employ
priority schedulers and multiple priority classes. To address this limitation,
we propose a systematic approach to construct priority-aware analytical
performance models using micro-architecture specifications and input traffic.
Our approach consists of developing two novel transformations of queuing system
and designing an algorithm which iteratively uses these two transformations to
estimate end-to-end latency. Our approach decomposes the given NoC into
individual queues with modified service time to enable accurate and scalable
latency computations. Specifically, we introduce novel transformations along
with an algorithm that iteratively applies these transformations to decompose
the queuing system. Experimental evaluations using real architectures and
applications show high accuracy of 97% and up to 2.5x speedup in full-system
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02426</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02426</id><created>2019-08-06</created><authors><author><keyname>Cheng</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Haifeng</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author></authors><title>Model Learning: Primal Dual Networks for Fast MR imaging</title><categories>eess.IV cs.CV cs.LG physics.med-ph stat.ML</categories><comments>accepted in MICCAI2019. arXiv admin note: text overlap with
  arXiv:1906.08143</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) is known to be a slow imaging modality and
undersampling in k-space has been used to increase the imaging speed. However,
image reconstruction from undersampled k-space data is an ill-posed inverse
problem. Iterative algorithms based on compressed sensing have been used to
address the issue. In this work, we unroll the iterations of the primal-dual
hybrid gradient algorithm to a learnable deep network architecture, and
gradually relax the constraints to reconstruct MR images from highly
undersampled k-space data. The proposed method combines the theoretical
convergence guarantee of optimi-zation methods with the powerful learning
capability of deep networks. As the constraints are gradually relaxed, the
reconstruction model is finally learned from the training data by updating in
k-space and image domain alternatively. Experi-ments on in vivo MR data
demonstrate that the proposed method achieves supe-rior MR reconstructions from
highly undersampled k-space data over other state-of-the-art image
reconstruction methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02446</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02446</id><created>2019-08-07</created><updated>2019-08-30</updated><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Watanabe</keyname><forenames>Ryosuke</forenames></author><author><keyname>Nonaka</keyname><forenames>Keisuke</forenames></author><author><keyname>Konno</keyname><forenames>Tomoaki</forenames></author><author><keyname>Sankoh</keyname><forenames>Hiroshi</forenames></author><author><keyname>Naito</keyname><forenames>Sei</forenames></author></authors><title>A Robust Billboard-based Free-viewpoint Video Synthesizing Algorithm for
  Sports Scenes</title><categories>cs.MM cs.GR eess.IV</categories><comments>10 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a billboard-based free-viewpoint video synthesizing algorithm for
sports scenes that can robustly reconstruct and render a high-fidelity
billboard model for each object, including an occluded one, in each camera. Its
contributions are (1) applicable to a challenging shooting condition where a
high precision 3D model cannot be built because a small number of cameras
featuring wide-baseline are equipped; (2) capable of reproducing appearances of
occlusions, that is one of the most significant issues for billboard-based
approaches due to the ineffective detection of overlaps. To achieve
contributions above, the proposed method does not attempt to find a
high-quality 3D model but utilizes a raw 3D model that is obtained directly
from space carving. Although the model is insufficiently accurate for producing
an impressive visual effect, precise objects segmentation and occlusions
detection can be performed by back-projecting it onto each camera plane. The
billboard model of each object in each camera is rendered according to whether
it is occluded or not, and its location in the virtual stadium is determined
considering the location of its 3D model. We synthesized free-viewpoint videos
of two soccer sequences recorded by five cameras with the proposed and
state-of-art methods to demonstrate its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02447</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02447</id><created>2019-08-07</created><authors><author><keyname>Meng</keyname><forenames>Deyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Jingyao</forenames></author></authors><title>Optimization-Based Learning Control for Nonlinear Time-Varying Systems</title><categories>eess.SY cs.SY</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning to perform perfect tracking tasks based on measurement data is
desirable in the controller design of systems operating repetitively. This
motivates the present paper to seek an optimization-based design approach for
iterative learning control (ILC) of repetitive systems with unknown nonlinear
time-varying dynamics. It is shown that perfect output tracking can be realized
with updating inputs, where no explicit model knowledge but only measured
input/output data are leveraged. In particular, adaptive updating strategies
are proposed to obtain parameter estimations of nonlinearities. A
double-dynamics analysis approach is applied to establish ILC convergence,
together with boundedness of input, output, and estimated parameters, which
benefits from employing properties of nonnegative matrices. Moreover, robust
convergence is explored for optimization-based adaptive ILC in the presence of
nonrepetitive uncertainties. Simulation tests are also implemented to verify
the validity of our optimization-based adaptive ILC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02458</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02458</id><created>2019-08-07</created><authors><author><keyname>Shokri</keyname><forenames>Mohammad</forenames></author><author><keyname>Kebriaei</keyname><forenames>Hamed</forenames></author></authors><title>Leader-Follower Network Aggregative Game with Stochastic Agents'
  Communication and Activeness</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical note presents a leader-follower scheme for network aggregative
games. The followers and leader are selfish cost minimizing agents. The cost
function of each follower is affected by strategy of leader and aggregated
strategies of its neighbors through a communication graph. The leader
infinitely often wakes up and receives the aggregated strategy of the
followers, updates its decision value and broadcasts it to all the followers.
Then, the followers apply the updated strategy of the leader into their cost
functions. The establishment of information exchange between each neighboring
pair of followers, and the activeness of each follower to update its decision
at each iteration are both considered to be drawn from two arbitrary
distributions. Moreover, a distributed algorithm based on subgradient method is
proposed for updating the strategies of leader and followers. The convergence
of the proposed algorithm to the unique generalized Nash equilibrium point of
the game is proven in both almost sure and mean square senses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02461</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02461</id><created>2019-08-07</created><updated>2020-02-24</updated><authors><author><keyname>Shi</keyname><forenames>Sheng</forenames></author><author><keyname>Yang</keyname><forenames>Runkai</forenames></author><author><keyname>You</keyname><forenames>Haihang</forenames></author></authors><title>ATSFFT: A Novel Sparse Fast Fourier Transform Enabled With Sparsity
  Detection</title><categories>eess.SP eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fast Fourier Transform(FFT) is a classic signal processing algorithm that
is utilized in a wide range of applications. For image processing, FFT computes
on every pixel's value of an image, regardless of their properties in frequency
domain. The Sparse Fast Fourier Transform (SFFT) is an innovative algorithm for
discrete Fourier transforms on signals that possess characteristics of the
sparsity in frequency domain. A reference implementation of the algorithm has
been proven to be efficient than modern FFT library in cases of sufficient
sparsity. However, the SFFT implementation has a critical drawback that it only
works reliably for very specific input parameters, especially signal sparsity
$k$, which hinders the extensive application of SFFT. In this paper, we propose
an Adaptive Tuning Sparse Fast Fourier Transform (ATSFFT), which is a novel
sparse fast fourier transform enabled with sparsity detection. In the case of
unknown sparsity $k$, ATSFFT is capable of probing the sparsity $k$ via
adaptive dynamic tuning and completing the sparse Fourier transform.
Experimental results show that ATSFFT outperforms SFFT while it is able to
control the computation error better than SFFT. Furthermore, ATSFFT achieves an
order of magnitude of performance improvement than the state-of-the-art FFT
library, FFTW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02498</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02498</id><created>2019-08-07</created><authors><author><keyname>Kwon</keyname><forenames>Gihyun</forenames></author><author><keyname>Han</keyname><forenames>Chihye</forenames></author><author><keyname>Kim</keyname><forenames>Dae-shik</forenames></author></authors><title>Generation of 3D Brain MRI Using Auto-Encoding Generative Adversarial
  Networks</title><categories>eess.IV cs.CV</categories><comments>8.5 pages, 4 figures, Accepted by the 22nd International Conference
  on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As deep learning is showing unprecedented success in medical image analysis
tasks, the lack of sufficient medical data is emerging as a critical problem.
While recent attempts to solve the limited data problem using Generative
Adversarial Networks (GAN) have been successful in generating realistic images
with diversity, most of them are based on image-to-image translation and thus
require extensive datasets from different domains. Here, we propose a novel
model that can successfully generate 3D brain MRI data from random vectors by
learning the data distribution. Our 3D GAN model solves both image blurriness
and mode collapse problems by leveraging alpha-GAN that combines the advantages
of Variational Auto-Encoder (VAE) and GAN with an additional code discriminator
network. We also use the Wasserstein GAN with Gradient Penalty (WGAN-GP) loss
to lower the training instability. To demonstrate the effectiveness of our
model, we generate new images of normal brain MRI and show that our model
outperforms baseline models in both quantitative and qualitative measurements.
We also train the model to synthesize brain disorder MRI data to demonstrate
the wide applicability of our model. Our results suggest that the proposed
model can successfully generate various types and modalities of 3D whole brain
volumes from a small set of training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02504</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02504</id><created>2019-08-07</created><authors><author><keyname>Zhu</keyname><forenames>Bin</forenames></author><author><keyname>Ferrante</keyname><forenames>Augusto</forenames></author><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author><author><keyname>Zorzi</keyname><forenames>Mattia</forenames></author></authors><title>Fusion of Sensors Data in Automotive Radar Systems: A Spectral
  Estimation Approach</title><categories>eess.SP</categories><comments>6 pages in IEEE conference template; accepted for presentation in CDC
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To accurately estimate locations and velocities of surrounding targets (cars)
is crucial for advanced driver assistance systems based on radar sensors. In
this paper we derive methods for fusing data from multiple radar sensors in
order to improve the accuracy and robustness of such estimates. First we pose
the target estimation problem as a multivariate multidimensional spectral
estimation problem. The problem is multivariate since each radar sensor gives
rise to a measurement channel. Then we investigate how the use of the
cross-spectra affects target estimates. We see that the use of the magnitude of
the cross-spectrum significantly improves the accuracy of the target estimates,
whereas an attempt to compensate the phase lag of the cross-spectrum only gives
marginal improvement. This paper may be viewed as a first step towards applying
high-resolution methods that builds on multidimensional multivariate spectral
estimation for sensor fusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02507</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02507</id><created>2019-08-07</created><authors><author><keyname>Yuan</keyname><forenames>Yu-Jie</forenames></author><author><keyname>Lai</keyname><forenames>Yu-Kun</forenames></author><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Fu</keyname><forenames>Hongbo</forenames></author><author><keyname>Gao</keyname><forenames>Lin</forenames></author></authors><title>Mesh Variational Autoencoders with Edge Contraction Pooling</title><categories>cs.GR cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D shape analysis is an important research topic in computer vision and
graphics. While existing methods have generalized image-based deep learning to
meshes using graph-based convolutions, the lack of an effective pooling
operation restricts the learning capability of their networks. In this paper,
we propose a novel pooling operation for mesh datasets with the same
connectivity but different geometry, by building a mesh hierarchy using mesh
simplification. For this purpose, we develop a modified mesh simplification
method to avoid generating highly irregularly sized triangles. Our pooling
operation effectively encodes the correspondence between coarser and finer
meshes in the hierarchy. We then present a variational auto-encoder structure
with the edge contraction pooling and graph-based convolutions, to explore
probability latent spaces of 3D surfaces. Our network requires far fewer
parameters than the original mesh VAE and thus can handle denser models thanks
to our new pooling operation and convolutional kernels. Our evaluation also
shows that our method has better generalization ability and is more reliable in
various applications, including shape generation, shape interpolation and shape
embedding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02510</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02510</id><created>2019-08-07</created><authors><author><keyname>Usman</keyname><forenames>Muhammad</forenames></author><author><keyname>Ibrahim</keyname><forenames>Muhammad Sohail</forenames></author><author><keyname>Ahmad</keyname><forenames>Jawwad</forenames></author><author><keyname>Hussain</keyname><forenames>Syed Saiq</forenames></author><author><keyname>Moinuddin</keyname><forenames>Muhammad</forenames></author></authors><title>Quantum Calculus-based Volterra LMS for Nonlinear Channel Estimation</title><categories>math.OC cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel adaptive filtering method called $q$-Volterra least mean square
($q$-VLMS) is presented in this paper. The $q$-VLMS is a nonlinear extension of
conventional LMS and it is based on Jackson's derivative also known as
$q$-calculus. In Volterra LMS, due to large variance of input signal the
convergence speed is very low. With proper manipulation we successfully
improved the convergence performance of the Volterra LMS. The proposed
algorithm is analyzed for the step-size bounds and results of analysis are
verified through computer simulations for nonlinear channel estimation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02547</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02547</id><created>2019-08-04</created><authors><author><keyname>Andalib</keyname><forenames>Vahid</forenames></author><author><keyname>Sarkar</keyname><forenames>Jyotirmoy</forenames></author></authors><title>A Repairable System Supported by Two Spare Units and Serviced by Two
  Types of Repairers</title><categories>cs.PF cs.SY eess.SY</categories><comments>13 pages, 4 figures, research paper submitted to journal of
  Reliability Engineering and System Safety</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a one-unit repairable system, supported by two identical spare units
on cold standby, and serviced by two types of repairers. The model applies, for
instance, to ANSI (American National Standard Institute) centrifugal pumps in a
chemical plant. The failed unit undergoes repair either by an in-house repairer
within a random or deterministic patience time, or else by a visiting expert
repairer. The expert repairs one or all failed units before leaving, and does
so faster but at a higher cost rate than the regular repairer. Four models
arise depending on the number of repairs done by the expert and the nature of
the patience time. We compare these models based on the limiting availability
$A_{\infty}$, and the limiting profit per unit time $\omega$, using semi-Markov
processes, when all distributions are exponential. As anticipated, to maximize
$A_{\infty}$, the expert should repair all failed units. To maximize $\omega$,
a suitably chosen deterministic patience time is better than a random patience
time. Furthermore, given all cost parameters, we determine the optimum number
of repairs the expert should complete, and the optimum patience time given to
the regular repairer in order to maximize $\omega$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02548</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02548</id><created>2019-08-03</created><authors><author><keyname>Nash</keyname><forenames>W. T.</forenames></author><author><keyname>Powell</keyname><forenames>C. J.</forenames></author><author><keyname>Drummond</keyname><forenames>T.</forenames></author><author><keyname>Birbilis</keyname><forenames>N.</forenames></author></authors><title>Automated Corrosion Detection Using Crowd Sourced Training for Deep
  Learning</title><categories>cs.HC eess.IV</categories><comments>presubmission, computer vision, deep learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automated detection of corrosion from images (i.e., photographs) or video
(i.e., drone footage) presents significant advantages in terms of corrosion
monitoring. Such advantages include access to remote locations, mitigation of
risk to inspectors, cost savings and monitoring speed. The automated detection
of corrosion requires deep learning to approach human level artificial
intelligence (A.I.). The training of a deep learning model requires intensive
image labelling, and in order to generate a large database of labelled images,
crowd sourced labelling via a dedicated website was sought. The website
(corrosiondetector.com) permits any user to label images, with such labelling
then contributing to the training of a cloud based A.I. model - with such a
cloud-based model then capable of assessing any fresh (or uploaded) image for
the presence of corrosion. In other words, the website includes both the crowd
sourced training process, but also the end use of the evolving model. Herein,
the results and findings from the website (corrosiondetector.com) over the
period of approximately one month, are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02582</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02582</id><created>2019-08-07</created><authors><author><keyname>Budd</keyname><forenames>Samuel</forenames></author><author><keyname>Sinclair</keyname><forenames>Matthew</forenames></author><author><keyname>Khanal</keyname><forenames>Bishesh</forenames></author><author><keyname>Matthew</keyname><forenames>Jacqueline</forenames></author><author><keyname>Lloyd</keyname><forenames>David</forenames></author><author><keyname>Gomez</keyname><forenames>Alberto</forenames></author><author><keyname>Toussaint</keyname><forenames>Nicolas</forenames></author><author><keyname>Robinson</keyname><forenames>Emma</forenames></author><author><keyname>Kainz</keyname><forenames>Bernhard</forenames></author></authors><title>Confident Head Circumference Measurement from Ultrasound with Real-time
  Feedback for Sonographers</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted at MICCAI 2019; Demo video available on Twitter
  (@sambuddinc)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manual estimation of fetal Head Circumference (HC) from Ultrasound (US) is a
key biometric for monitoring the healthy development of fetuses. Unfortunately,
such measurements are subject to large inter-observer variability, resulting in
low early-detection rates of fetal abnormalities. To address this issue, we
propose a novel probabilistic Deep Learning approach for real-time automated
estimation of fetal HC. This system feeds back statistics on measurement
robustness to inform users how confident a deep neural network is in evaluating
suitable views acquired during free-hand ultrasound examination. In real-time
scenarios, this approach may be exploited to guide operators to scan planes
that are as close as possible to the underlying distribution of training
images, for the purpose of improving inter-operator consistency. We train on
free-hand ultrasound data from over 2000 subjects (2848 training/540 test) and
show that our method is able to predict HC measurements within 1.81$\pm$1.65mm
deviation from the ground truth, with 50% of the test images fully contained
within the predicted confidence margins, and an average of 1.82$\pm$1.78mm
deviation from the margin for the remaining cases that are not fully contained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02590</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02590</id><created>2019-08-07</created><updated>2020-02-07</updated><authors><author><keyname>Sadeghi</keyname><forenames>Mostafa</forenames></author><author><keyname>Leglaive</keyname><forenames>Simon</forenames></author><author><keyname>Alameda-PIneda</keyname><forenames>Xavier</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>Audio-visual Speech Enhancement Using Conditional Variational
  Auto-Encoder</title><categories>cs.SD cs.LG eess.AS</categories><comments>Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variational auto-encoders (VAEs) are deep generative latent variable models
that can be used for learning the distribution of complex data. VAEs have been
successfully used to learn a probabilistic prior over speech signals, which is
then used to perform speech enhancement. One advantage of this generative
approach is that it does not require pairs of clean and noisy speech signals at
training. In this paper, we propose audio-visual variants of VAEs for
single-channel and speaker-independent speech enhancement. We develop a
conditional VAE (CVAE) where the audio speech generative process is conditioned
on visual information of the lip region. At test time, the audio-visual speech
generative model is combined with a noise model based on nonnegative matrix
factorization, and speech enhancement relies on a Monte Carlo
expectation-maximization algorithm. Experiments are conducted with the recently
published NTCD-TIMIT dataset as well as the GRID corpus. The results confirm
that the proposed audio-visual CVAE effectively fuses audio and visual
information, and it improves the speech enhancement performance compared with
the audio-only VAE model, especially when the speech signal is highly corrupted
by noise. We also show that the proposed unsupervised audio-visual speech
enhancement approach outperforms a state-of-the-art supervised deep learning
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02612</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02612</id><created>2019-08-06</created><authors><author><keyname>Yun</keyname><forenames>Sungrack</forenames></author><author><keyname>Cho</keyname><forenames>Janghoon</forenames></author><author><keyname>Eum</keyname><forenames>Jungyun</forenames></author><author><keyname>Chang</keyname><forenames>Wonil</forenames></author><author><keyname>Hwang</keyname><forenames>Kyuwoong</forenames></author></authors><title>An End-to-End Text-independent Speaker Verification Framework with a
  Keyword Adversarial Network</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Will be appeared in INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an end-to-end text-independent speaker verification
framework by jointly considering the speaker embedding (SE) network and
automatic speech recognition (ASR) network. The SE network learns to output an
embedding vector which distinguishes the speaker characteristics of the input
utterance, while the ASR network learns to recognize the phonetic context of
the input. In training our speaker verification framework, we consider both the
triplet loss minimization and adversarial gradient of the ASR network to obtain
more discriminative and text-independent speaker embedding vectors. With the
triplet loss, the distances between the embedding vectors of the same speaker
are minimized while those of different speakers are maximized. Also, with the
adversarial gradient of the ASR network, the text-dependency of the speaker
embedding vector can be reduced. In the experiments, we evaluated our speaker
verification framework using the LibriSpeech and CHiME 2013 dataset, and the
evaluation results show that our speaker verification framework shows lower
equal error rate and better text-independency compared to the other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02625</identifier>
 <datestamp>2019-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02625</id><created>2019-08-07</created><authors><author><keyname>O'Reilly</keyname><forenames>Jamie A.</forenames></author><author><keyname>Sangworasil</keyname><forenames>Manas</forenames></author><author><keyname>Matsuura</keyname><forenames>Takenobu</forenames></author></authors><title>Kidney and Kidney Tumor Segmentation using a Logical Ensemble of U-nets
  with Volumetric Validation</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures, 1 table, competition submission manuscript</comments><doi>10.24926/548719.082</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated medical image segmentation is a priority research area for
computational methods. In particular, detection of cancerous tumors represents
a current challenge in this area with potential for real-world impact. This
paper describes a method developed in response to the 2019 Kidney Tumor
Segmentation Challenge (KiTS19). Axial computed tomography (CT) scans from 210
kidney cancer patients were used to develop and evaluate this automatic
segmentation method based on a logical ensemble of fully-convolutional network
(FCN) architectures, followed by volumetric validation. Data was pre-processed
using conventional computer vision techniques, thresholding, histogram
equalization, morphological operations, centering, zooming and resizing. Three
binary FCN segmentation models were trained to classify kidney and tumor (2),
and only tumor (1), respectively. Model output images were stacked and
volumetrically validated to produce the final segmentation for each patient
scan. The average F1 score from kidney and tumor pixel classifications was
calculated as 0.6758 using preprocessed images and annotations; although
restoring to the original image format reduced this score. It remains to be
seen how this compares to other solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02648</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02648</id><created>2019-08-07</created><updated>2019-11-29</updated><authors><author><keyname>Hwang</keyname><forenames>Seongmin</forenames></author><author><keyname>Yu</keyname><forenames>Gwanghuyn</forenames></author><author><keyname>Jung</keyname><forenames>Cheolkon</forenames></author><author><keyname>Kim</keyname><forenames>Jinyoung</forenames></author></authors><title>Attention-Aware Linear Depthwise Convolution for Single Image
  Super-Resolution</title><categories>eess.IV cs.CV</categories><comments>9 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although deep convolutional neural networks (CNNs) have obtained outstanding
performance in image superresolution (SR), their computational cost increases
geometrically as CNN models get deeper and wider. Meanwhile, the features of
intermediate layers are treated equally across the channel, thus hindering the
representational capability of CNNs. In this paper, we propose an
attention-aware linear depthwise network to address the problems for single
image SR, named ALDNet. Specifically, linear depthwise convolution allows
CNN-based SR models to preserve useful information for reconstructing a
super-resolved image while reducing computational burden. Furthermore, we
design an attention-aware branch that enhances the representation ability of
depthwise convolution layers by making full use of depthwise filter
interdependency. Experiments on publicly available benchmark datasets show that
ALDNet achieves superior performance to traditional depthwise separable
convolutions in terms of quantitative measurements and visual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02650</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02650</id><created>2019-08-07</created><updated>2019-08-19</updated><authors><author><keyname>Pirovano</keyname><forenames>Antoine</forenames></author><author><keyname>Almeida</keyname><forenames>Leandro G.</forenames></author><author><keyname>Ladjal</keyname><forenames>Said</forenames></author></authors><title>Regression Constraint for an Explainable Cervical Cancer Classifier</title><categories>eess.IV cs.CV cs.LG</categories><comments>5 pages, 9 figures, accepted at GRETSI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article adresses the problem of automatic squamous cells classification
for cervical cancer screening using Deep Learning methods. We study different
architectures on a public dataset called Herlev dataset, which consists in
classifying cells, obtained by cervical pap smear, regarding the severity of
the abnormalities they represent. Furthermore, we use an attribution method to
understand which cytomorphological features are actually learned as
discriminative to classify severity of the abnormalities. Through this paper,
we show how we trained a performant classifier: 74.5\% accuracy on severity
classification and 94\% accuracy on normal/abnormal classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02673</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02673</id><created>2019-08-07</created><authors><author><keyname>Laval</keyname><forenames>Jorge A.</forenames></author><author><keyname>Zhou</keyname><forenames>Hao</forenames></author></authors><title>Large-scale traffic signal control using machine learning: some traffic
  flow considerations</title><categories>cs.AI cs.SY eess.SY</categories><comments>15 pages, 10 figures</comments><msc-class>14J60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper uses supervised learning, random search and deep reinforcement
learning (DRL) methods to control large signalized intersection networks. The
traffic model is Cellular Automaton rule 184, which has been shown to be a
parameter-free representation of traffic flow, and is the most efficient
implementation of the Kinematic Wave model with triangular fundamental diagram.
We are interested in the steady-state performance of the system, both spatially
and temporally: we consider a homogeneous grid network inscribed on a torus,
which makes the network boundary-free, and drivers choose random routes. As a
benchmark we use the longest-queue-first (LQF) greedy algorithm. We find that:
(i) a policy trained with supervised learning with only two examples
outperforms LQF, (ii) random search is able to generate near-optimal policies,
(iii) the prevailing average network occupancy during training is the major
determinant of the effectiveness of DRL policies. When trained under free-flow
conditions one obtains DRL policies that are optimal for all traffic
conditions, but this performance deteriorates as the occupancy during training
increases. For occupancies &gt; 75% during training, DRL policies perform very
poorly for all traffic conditions, which means that DRL methods cannot learn
under highly congested conditions. We conjecture that DRL's inability to learn
under congestion might be explained by a property of urban networks found here,
whereby even a very bad policy produces an intersection throughput higher than
downstream capacity. This means that the actual throughput tends to be
independent of the policy. Our findings imply that it is advisable for current
DRL methods in the literature to discard any congested data when training, and
that doing this will improve their performance under all traffic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02678</identifier>
 <datestamp>2020-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02678</id><created>2019-08-07</created><updated>2020-02-03</updated><authors><author><keyname>Abanto-Leon</keyname><forenames>Luis F.</forenames><affiliation>Allyson</affiliation></author><author><keyname>Hollick</keyname><forenames>Matthias</forenames><affiliation>Allyson</affiliation></author><author><keyname>Hong</keyname><forenames>Gek</forenames><affiliation>Allyson</affiliation></author><author><keyname>Sim</keyname></author></authors><title>Hybrid Precoding for Multi-Group Multicasting in mmWave Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>IEEE GLOBECOM 2019, pp. 1-7</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multicast beamforming is known to improve spectral efficiency. However, its
benefits and challenges for hybrid precoders design in millimeter-wave (mmWave)
systems remain understudied. To this end, this paper investigates the first
joint design of hybrid transmit precoders (with an arbitrary number of
finite-resolution phase shifts) and receive combiners for mmWave multi-group
multicasting. Our proposed design leverages semidefinite relaxation (SDR),
alternating optimization and Cholesky matrix factorization to sequentially
optimize the digital/analog precoders at the transmitter and the combiners at
each receiver. By considering receivers with multiple-antenna architecture, our
design remarkably improves the overall system performance. Specifically, with
only two receive antennas the average transmit power per received message
improves by $ 16.8\% $ while the successful information reception is boosted by
$ 60\% $. We demonstrate by means of extensive simulations that our hybrid
precoder design performs very close to its fully-digital counterpart even under
challenging scenarios (i.e., when co-located users belong to distinct multicast
groups).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02689</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02689</id><created>2019-08-07</created><authors><author><keyname>Huang</keyname><forenames>Hsien-Yung</forenames></author><author><keyname>Farkhatdinov</keyname><forenames>Ildar</forenames></author><author><keyname>Arami</keyname><forenames>Arash</forenames></author><author><keyname>Bouri</keyname><forenames>Mohamed</forenames></author><author><keyname>Burdet</keyname><forenames>Etienne</forenames></author></authors><title>Cable-driven robotic interface for lower limb neuromechanics
  identification</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a versatile cable-driven robotic interface to investigate
the single-joint joint neuromechanics of the hip, knee and ankle. This
endpoint-based interface offers highly dynamic interaction and accurate
position control, as is typically required for neuromechanics identification.
It can be used with the subject upright, corresponding to natural posture
during walking or standing, and does not impose kinematic constraints on a
joint, in contrast to existing interfaces. Mechanical evaluations demonstrated
that the interface yields a rigidity above 500N/m with low viscosity. Tests
with a rigid dummy leg and linear springs show that it can identify the
mechanical impedance of a limb accurately. A smooth perturbation is developed
and tested with a human subject, which can be used to estimate the hip
neuromechanics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02704</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02704</id><created>2019-08-07</created><authors><author><keyname>Dai</keyname><forenames>Xunhua</forenames></author><author><keyname>Ke</keyname><forenames>Chenxu</forenames></author><author><keyname>Quan</keyname><forenames>Quan</forenames></author><author><keyname>Cai</keyname><forenames>Kai-Yuan</forenames></author></authors><title>Unified Simulation and Test Platform for Control Systems of Unmanned
  Vehicles</title><categories>eess.SY cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control systems on unmanned vehicles are safety-critical systems whose
requirements on reliability and safety are ever-increasing. Currently, testing
a complex autonomous control system is an expensive and time-consuming process,
which requires massive repeated experimental testing during the whole
development stage. This paper presents a unified simulation and test platform
for vehicle autonomous control systems aiming to significantly improve the
development speed and safety level of unmanned vehicles. First, a unified
modular modeling framework compatible with different types of vehicles is
proposed with methods to ensure modeling credibility. Then, the simulation
software system is developed by the model-based design framework, whose modular
programming methods and automatic code generation functions ensure the
efficiency, credibility, and standardization of the system development process.
Finally, an FPGA-based real-time hardware-in-the-loop simulation platform is
proposed to ensure the comprehensiveness and credibility of the simulation and
test results. In the end, the proposed platform is applied to a multicopter
control system. By comparing with experimental results, the accuracy and
credibility of the simulation testing results are verified by using the
simulation credibility assessment method proposed in our previous work. To
verify the practicability of the proposed platform, several successful
applications are presented for the multicopter rapid prototyping, estimation
algorithm verification, autonomous flight testing, and automatic safety testing
with automatic fault injection and result evaluation of unmanned vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02710</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02710</id><created>2019-08-06</created><authors><author><keyname>Nakatani</keyname><forenames>Tomohiro</forenames></author><author><keyname>Kinoshita</keyname><forenames>Keisuke</forenames></author></authors><title>Maximum likelihood convolutional beamformer for simultaneous denoising
  and dereverberation</title><categories>eess.AS cs.SD</categories><comments>Accepted for EUSIPCO 2019. arXiv admin note: text overlap with
  arXiv:1812.08400</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a probabilistic formulation of a Weighted Power
minimization Distortionless response convolutional beamformer (WPD). The WPD
unifies a weighted prediction error based dereverberation method (WPE) and a
minimum power distortionless response beamformer (MPDR) into a single
convolutional beamformer, and achieves simultaneous dereverberation and
denoising in an optimal way. However, the optimization criterion is obtained
simply by combining existing criteria without any clear theoretical
justification. This article presents a generative model and a probabilistic
formulation of a WPD, and derives an optimization algorithm based on a maximum
likelihood estimation. We also describe a method for estimating the steering
vector of the desired signal by utilizing WPE within the WPD framework to
provide an effective and efficient beamformer for denoising and
dereverberation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02728</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02728</id><created>2019-06-06</created><authors><author><keyname>Ma</keyname><forenames>Chonghuai</forenames></author><author><keyname>Laporte</keyname><forenames>Floris</forenames></author><author><keyname>Dambre</keyname><forenames>Joni</forenames></author><author><keyname>Bienstman</keyname><forenames>Peter</forenames></author></authors><title>Addressing Limited Weight Resolution in a Fully Optical Neuromorphic
  Reservoir Computing Readout</title><categories>cs.ET cs.LG eess.SP</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using optical hardware for neuromorphic computing has become more and more
popular recently due to its efficient high-speed data processing capabilities
and low power consumption. However, there are still some remaining obstacles to
realizing the vision of a completely optical neuromorphic computer. One of them
is that, depending on the technology used, optical weighting elements may not
share the same resolution as in the electrical domain. Moreover, noise and
drift are important considerations as well. In this article, we investigate a
new method for improving the performance of optical weighting, even in the
presence of noise and in the case of very low resolution. Even with only 8 to
32 levels of resolution, the method can outperform the naive traditional
low-resolution weighting by several orders of magnitude in terms of bit error
rate and can deliver performance very close to full-resolution weighting
elements, also in noisy environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02738</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02738</id><created>2019-08-07</created><updated>2019-10-11</updated><authors><author><keyname>Dalca</keyname><forenames>Adrian V.</forenames></author><author><keyname>Rakic</keyname><forenames>Marianne</forenames></author><author><keyname>Guttag</keyname><forenames>John</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author></authors><title>Learning Conditional Deformable Templates with Convolutional Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>NeurIPS 2019: Neural Information Processing Systems. Keywords:
  deformable templates, conditional atlases, diffeomorphic image registration,
  probabilistic models, neuroimaging</comments><journal-ref>NeurIPS: Thirty-third Conference on Neural Information Processing
  Systems, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a learning framework for building deformable templates, which play
a fundamental role in many image analysis and computational anatomy tasks.
Conventional methods for template creation and image alignment to the template
have undergone decades of rich technical development. In these frameworks,
templates are constructed using an iterative process of template estimation and
alignment, which is often computationally very expensive. Due in part to this
shortcoming, most methods compute a single template for the entire population
of images, or a few templates for specific sub-groups of the data. In this
work, we present a probabilistic model and efficient learning strategy that
yields either universal or conditional templates, jointly with a neural network
that provides efficient alignment of the images to these templates. We
demonstrate the usefulness of this method on a variety of domains, with a
special focus on neuroimaging. This is particularly useful for clinical
applications where a pre-existing template does not exist, or creating a new
one with traditional methods can be prohibitively expensive. Our code and
atlases are available online as part of the VoxelMorph library at
http://voxelmorph.csail.mit.edu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02789</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02789</id><created>2019-08-07</created><authors><author><keyname>Sargolzaei</keyname><forenames>Arman</forenames></author><author><keyname>Abbaspour</keyname><forenames>Alireza</forenames></author><author><keyname>Crane</keyname><forenames>Carl D.</forenames></author></authors><title>Control of Cooperative Unmanned Aerial Vehicles: Review of Applications,
  Challenges, and Algorithms</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A system of cooperative unmanned aerial vehicles (UAVs) is a group of agents
interacting with each other and the surrounding environment to achieve a
specific task. In contrast with a single UAV, UAV swarms are expected to
benefit efficiency, flexibility, accuracy, robustness, and reliability.
However, the provision of external communications potentially exposes them to
an additional layer of faults, failures, uncertainties, and cyber-attacks and
can contribute to the propagation of error from one component to other
components in a network. Also, other challenges such as complex nonlinear
dynamic of UAVs, collision avoidance, velocity matching, and cohesion should be
addressed adequately. The main applications of cooperative UAVs are border
patrol; search and rescue; surveillance; mapping; military. Challenges to be
addressed in decision and control in cooperative systems may include the
complex nonlinear dynamic of UAVs, collision avoidance, velocity matching, and
cohesion. In this paper, emerging topics in the field of cooperative UAVs
control and their associated practical approaches are reviewed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02798</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02798</id><created>2019-08-07</created><updated>2019-12-24</updated><authors><author><keyname>Luj&#xe1;n</keyname><forenames>Emmanuel</forenames></author><author><keyname>Mellino</keyname><forenames>Juan A. Zuloaga</forenames></author><author><keyname>Otero</keyname><forenames>Alejandro D.</forenames></author><author><keyname>Vega</keyname><forenames>Leonardo Rey</forenames></author><author><keyname>Galarza</keyname><forenames>Cecilia G.</forenames></author><author><keyname>Mocskos</keyname><forenames>Esteban E.</forenames></author></authors><title>Extreme coverage in 5G Narrowband IoT: a LUT-based strategy to optimize
  shared channels</title><categories>cs.NI eess.SP</categories><comments>Paper accepted at IEEE IoT Journal</comments><doi>10.1109/JIOT.2019.2959552</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main challenges in IoT is providing communication support to an
increasing number of connected devices. In recent years, narrowband radio
technology has emerged to address this situation: Narrowband Internet of Things
(NB-IoT), which is now part of 5G. Supporting massive connectivity becomes
particularly demanding in extreme coverage scenarios such as underground or
deep inside buildings sites. We propose a novel strategy for these situations
focused on optimizing NB-IoT shared channels through the selection of link
parameters: modulation and coding scheme, as well as the number of repetitions.
These parameters are established by the base station (BS) for each block
transmitted until reaching a target block error rate (BLER_t ). A wrong
selection of these magnitudes leads to radio resource waste and a decrease in
the number of possible concurrent connections. Specifically, our strategy is
based on a look-up table (LUT) scheme which is used for rapidly delivering the
optimal link parameters given a target QoS. To validate our proposal, we
compare with alternative strategies using an open source NB-IoT uplink
simulator. The experiments are based on transmitting blocks of 256 bits using
an AWGN channel over the NPUSCH. Results show that, especially under extreme
conditions, only a few options for link parameters are available, favoring
robustness against measurement uncertainties. Our strategy minimizes resource
usage in all scenarios of acknowledged mode and remarkably reduces losses in
the unacknowledged mode, presenting also substantial gains in performance. We
expect to influence future BS software design and implementation, favoring
connection support under extreme environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02815</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02815</id><created>2019-08-07</created><authors><author><keyname>Baso</keyname><forenames>C. J. D&#xed;az</forenames></author><author><keyname>Rodr&#xed;guez</keyname><forenames>J. de la Cruz</forenames></author><author><keyname>Danilovic</keyname><forenames>S.</forenames></author></authors><title>Solar image denoising with convolutional neural networks</title><categories>astro-ph.SR eess.IV</categories><comments>13 pages; accepted for publication in A&amp;A</comments><journal-ref>A&amp;A 629, A99 (2019)</journal-ref><doi>10.1051/0004-6361/201936069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The topology and dynamics of the solar chromosphere are greatly affected by
the presence of magnetic fields. The magnetic field can be inferred by
analyzing polarimetric observations of spectral lines. Polarimetric signals
induced by chromospheric magnetic fields are, however, particularly weak, and
in most cases very close to the detection limit of current instrumentation.
Because of this, there are only few observational studies that have
successfully reconstructed the three components of the magnetic field vector in
the chromosphere. Traditionally, the signal-to-noise ratio of observations has
been improved by performing time-averages or spatial averages, but in both
cases, some information is lost. More advanced techniques, like
principal-component-analysis, have also been employed to take advantage of the
sparsity of the observations in the spectral direction. In the present study,
we propose to use the spatial coherence of the observations to reduce the noise
using deep-learning techniques. We design a neural network that is capable of
recovering weak signals under a complex noise corruption (including
instrumental artifacts and non-linear post-processing). The training of the
network is carried out without a priori knowledge of the clean signals, or an
explicit statistical characterization of the noise or other corruption. We only
use the same observations as our generative model. The performance of this
method is demonstrated on both, synthetic experiments and real data. We show
examples of the improvement in typical signals obtained in current telescopes
such as the Swedish 1-meter Solar Telescope. The presented method can recover
weak signals equally well no matter on what spectral line or spectral sampling
is used. It is especially suitable for cases when the wavelength sampling is
scarce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02825</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02825</id><created>2019-08-07</created><authors><author><keyname>Biton</keyname><forenames>Shai</forenames></author><author><keyname>Arbel</keyname><forenames>Nadav</forenames></author><author><keyname>Drozdov</keyname><forenames>Gilad</forenames></author><author><keyname>Gilboa</keyname><forenames>Guy</forenames></author><author><keyname>Rosenthal</keyname><forenames>Amir</forenames></author></authors><title>Optoacoustic Model-Based Inversion Using Anisotropic Adaptive
  Total-Variation Regularization</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In optoacoustic tomography, image reconstruction is often performed with
incomplete or noisy data, leading to reconstruction errors. Significant
improvement in reconstruction accuracy may be achieved in such cases by using
nonlinear regularization schemes, such as total-variation minimization and
$L_1$-based sparsity-preserving schemes. In this paper, we introduce a new
framework for optoacoustic image reconstruction based on adaptive anisotropic
total-variation regularization, which is more capable of preserving complex
boundaries than conventional total-variation regularization. The new scheme is
demonstrated in numerical simulations on blood-vessel images \textcolor{black}
{as well as on experimental data} and is shown to be more capable than the
total-variation-$L_1$ scheme in enhancing image contrast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02832</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02832</id><created>2019-08-07</created><updated>2019-08-13</updated><authors><author><keyname>Nguyen</keyname><forenames>Quan</forenames></author><author><keyname>Lao</keyname><forenames>Keng-Weng</forenames></author><author><keyname>Vu</keyname><forenames>Phuong</forenames></author><author><keyname>Santoso</keyname><forenames>Surya</forenames></author></authors><title>Loss Minimization with Optimal Power Dispatch in Multi-Frequency HVac
  Power Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-frequency high voltage ac transmission scheme has recently been proposed
as an alternative approach for bulk power transmission. This paper proposes a
multi-period optimal power flow (OPF) for a multi-frequency HVac transmission
system that interconnects both conventional 50/60-Hz and low-frequency grids
using back-to-back converters with a centralized control scheme. The OPF
objective is to minimize system losses by determining the optimal dispatch for
generators, shunt capacitors, and converters. The OPF constraints include the
operational constraints of all HVac grid and converter stations. The resulting
mixed-integer nonlinear programing problem is solved using a proposed framework
based on the predictor-corrector primal-dual interior-point method. The
proposed OPF formulation and solution approach are verified using a
multi-frequency HVac transmission system that is modified from the IEEE 57-bus
system. The results with the optimal dispatch from the proposed method during a
simulated day show a significant loss reduction and an improved voltage
regulation compared to those when an arbitrary dispatch is chosen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02848</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02848</id><created>2019-08-07</created><authors><author><keyname>Sch&#xe4;fer</keyname><forenames>Mirko</forenames></author><author><keyname>Hofmann</keyname><forenames>Fabian</forenames></author><author><keyname>Abdel-Khalek</keyname><forenames>Hazem</forenames></author><author><keyname>Weidlich</keyname><forenames>Anke</forenames></author></authors><title>Principal Cross-Border Flow Patterns in the European Electricity Markets</title><categories>physics.soc-ph cs.SY eess.SY</categories><comments>Accepted conference proceedings paper for the EEM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interconnected European Electricity Markets see considerable cross-border
trade between different countries. In conjunction with the structure and
technical characteristics of the power grid and its operating rules, the
corresponding commercial flows translate into actual physical flows on the
interconnection lines. From the interplay of different physical, technical, and
economic factors thus emerge complex spatiotemporal power flow patterns. Using
Principal Component Analysis, in this contribution hourly time-series of
cross-border physical flows between European countries in 2017 and 2018 are
analyzed. The most important patterns in the time series of imports/exports and
cross-border physical flows are identified. Their spatial and temporal
structure, as well as their contribution to the overall variance is described.
Additionally, we apply a tracing technique to the overall flow patterns, which
allows identifying the physical power transfers between European countries
through the common grid infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02858</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02858</id><created>2019-08-07</created><authors><author><keyname>Diethe</keyname><forenames>Tom</forenames></author><author><keyname>Kull</keyname><forenames>Meelis</forenames></author><author><keyname>Twomey</keyname><forenames>Niall</forenames></author><author><keyname>Sokol</keyname><forenames>Kacper</forenames></author><author><keyname>Song</keyname><forenames>Hao</forenames></author><author><keyname>Perello-Nieto</keyname><forenames>Miquel</forenames></author><author><keyname>Tonkin</keyname><forenames>Emma</forenames></author><author><keyname>Flach</keyname><forenames>Peter</forenames></author></authors><title>HyperStream: a Workflow Engine for Streaming Data</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes HyperStream, a large-scale, flexible and robust software
package, written in the Python language, for processing streaming data with
workflow creation capabilities. HyperStream overcomes the limitations of other
computational engines and provides high-level interfaces to execute complex
nesting, fusion, and prediction both in online and offline forms in streaming
environments. HyperStream is a general purpose tool that is well-suited for the
design, development, and deployment of Machine Learning algorithms and
predictive models in a wide space of sequential predictive problems.
  Source code, installation instructions, examples, and documentation can be
found at: https://github.com/IRC-SPHERE/HyperStream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02860</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02860</id><created>2019-08-07</created><updated>2020-01-24</updated><authors><author><keyname>Queiroz</keyname><forenames>Saulo</forenames></author><author><keyname>Silva</keyname><forenames>Wesley</forenames></author><author><keyname>Vilela</keyname><forenames>Jo&#xe3;o P.</forenames></author><author><keyname>Monteiro</keyname><forenames>Edmundo</forenames></author></authors><title>Maximal Spectral Efficiency of OFDM with Index Modulation under
  Polynomial Space Complexity</title><categories>eess.SP cs.CC</categories><comments>Copyright (c) 2020 IEEE. Personal use is permitted. For any other
  purposes, permission must be obtained from the IEEE by emailing
  pubs-permissions@ieee.org</comments><journal-ref>IEEE Wireless Communications Letters, 2020</journal-ref><doi>10.1109/LWC.2020.2965533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we demonstrate a mapper that enables all waveforms of OFDM
with Index Modulation (OFDM-IM) while preserving polynomial time and space
computational complexities. Enabling all OFDM-IM waveforms maximizes the
spectral efficiency (SE) gain over the classic OFDM but, as far as we know, the
computational overhead of the resulting mapper remains conjectured as
prohibitive across the OFDM-IM literature. We show that the largest number of
binomial coefficient calculations performed by the original OFDM-IM mapper is
polynomial on the number of subcarriers, even under the setup that maximizes
the SE gain over OFDM. Also, such coefficients match the entries of the
so-called Pascal's triangle (PT). Thus, by assisting the OFDM-IM mapper with a
PT table, we show that the maximum SE gain over OFDM can be achieved under
polynomial (rather than exponential) time and space complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02875</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02875</id><created>2019-08-07</created><authors><author><keyname>Chen</keyname><forenames>Di</forenames></author><author><keyname>Fu</keyname><forenames>Chichen</forenames></author><author><keyname>Liu</keyname><forenames>Zoe</forenames></author><author><keyname>Zhu</keyname><forenames>Fengqing</forenames></author></authors><title>Convolutional Neural Networks Based Texture Modeling For AV1</title><categories>eess.IV</categories><comments>22 pages, 7 figures. arXiv admin note: substantial text overlap with
  arXiv:1804.09291</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern video codecs including the newly developed AOMedia Video 1 (AV1)
utilize hybrid coding techniques to remove spatial and temporal redundancy.
However, efficient exploitation of statistical dependencies measured by a mean
squared error (MSE) does not always produce the best psychovisual result. One
interesting approach is to only encode visually relevant information and use a
different coding method for &quot;perceptually insignificant&quot; regions in the frame,
which can lead to substantial data rate reductions while maintaining visual
quality. In this paper, we introduce a texture analyzer before encoding the
input sequences to identify &quot;perceptually insignificant&quot; regions in the frame
using convolutional neural networks. We designed and developed a new scheme
that integrate the texture analyzer into the codec that can largely reduce the
temporal flickering artifact for codec with hierarchical coding structure. The
proposed method is implemented in AV1 codec by introducing a new coding tool
called texture mode, where texture mode is a special inter mode treated at the
encoder, that if texture mode is selected, no inter prediction is performed for
the identified texture regions. Instead, displacement of the entire region is
modeled by just one set of motion parameters. Therefore, only the model
parameters are transmitted to the decoder for reconstructing the texture
regions. Non-texture regions in the frame are coded conventionally. We show
that for many standard test sets, the proposed method achieved significant data
rate reductions with satisfying visual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02876</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02876</id><created>2019-08-07</created><authors><author><keyname>Kim</keyname><forenames>Bongjun</forenames></author><author><keyname>Ghaffarzadegan</keyname><forenames>Shabnam</forenames></author></authors><title>Self-supervised Attention Model for Weakly Labeled Audio Event
  Classification</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><journal-ref>European Signal Processing Conference, EUSIPCO 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a novel weakly labeled Audio Event Classification approach based
on a self-supervised attention model. The weakly labeled framework is used to
eliminate the need for expensive data labeling procedure and self-supervised
attention is deployed to help a model distinguish between relevant and
irrelevant parts of a weakly labeled audio clip in a more effective manner
compared to prior attention models. We also propose a highly effective strongly
supervised attention model when strong labels are available. This model also
serves as an upper bound for the self-supervised model. The performances of the
model with self-supervised attention training are comparable to the strongly
supervised one which is trained using strong labels. We show that our
self-supervised attention method is especially beneficial for short audio
events. We achieve 8.8% and 17.6% relative mean average precision improvements
over the current state-of-the-art systems for SL-DCASE-17 and balanced
AudioSet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02877</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02877</id><created>2019-08-07</created><authors><author><keyname>Reite</keyname><forenames>Aaron</forenames></author><author><keyname>Kangas</keyname><forenames>Scott</forenames></author><author><keyname>Steck</keyname><forenames>Zackery</forenames></author><author><keyname>Goley</keyname><forenames>Steven</forenames></author><author><keyname>Von Stroh</keyname><forenames>Jonathan</forenames></author><author><keyname>Forsyth</keyname><forenames>Steven</forenames></author></authors><title>Unsupervised Feature Learning in Remote Sensing</title><categories>cs.CV cs.LG eess.IV</categories><doi>10.1117/12.2529791</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for labeled data is among the most common and well-known practical
obstacles to deploying deep learning algorithms to solve real-world problems.
The current generation of learning algorithms requires a large volume of data
labeled according to a static and pre-defined schema. Conversely, humans can
quickly learn generalizations based on large quantities of unlabeled data, and
turn these generalizations into classifications using spontaneous labels, often
including labels not seen before. We apply a state-of-the-art unsupervised
learning algorithm to the noisy and extremely imbalanced xView data set to
train a feature extractor that adapts to several tasks: visual similarity
search that performs well on both common and rare classes; identifying outliers
within a labeled data set; and learning a natural class hierarchy
automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02878</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02878</id><created>2019-08-07</created><authors><author><keyname>Huang</keyname><forenames>Pengzhi</forenames></author><author><keyname>Casta&#xf1;eda</keyname><forenames>Oscar</forenames></author><author><keyname>G&#xf6;n&#xfc;lta&#x15f;</keyname><forenames>Emre</forenames></author><author><keyname>Medjkouh</keyname><forenames>Sa&#xef;d</forenames></author><author><keyname>Tirkkonen</keyname><forenames>Olav</forenames></author><author><keyname>Goldstein</keyname><forenames>Tom</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Improving Channel Charting with Representation-Constrained Autoencoders</title><categories>eess.SP cs.IT math.IT stat.ML</categories><comments>Presented at the 20th IEEE International Workshop on Signal
  Processing Advances in Wireless Communications (SPAWC), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel charting (CC) has been proposed recently to enable logical
positioning of user equipments (UEs) in the neighborhood of a multi-antenna
base-station solely from channel-state information (CSI). CC relies on
dimensionality reduction of high-dimensional CSI features in order to construct
a channel chart that captures spatial and radio geometries so that UEs close in
space are close in the channel chart. In this paper, we demonstrate that
autoencoder (AE)-based CC can be augmented with side information that is
obtained during the CSI acquisition process. More specifically, we propose to
include pairwise representation constraints into AEs with the goal of improving
the quality of the learned channel charts. We show that such
representation-constrained AEs recover the global geometry of the learned
channel charts, which enables CC to perform approximate positioning without
global navigation satellite systems or supervised learning methods that rely on
extensive and expensive measurement campaigns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02884</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02884</id><created>2019-08-07</created><authors><author><keyname>Ghods</keyname><forenames>Ramina</forenames></author><author><keyname>Gallyas-Sanhueza</keyname><forenames>Alexandra</forenames></author><author><keyname>Mirfarshbafan</keyname><forenames>Seyed Hadi</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>BEACHES: Beamspace Channel Estimation for Multi-Antenna mmWave Systems
  and Beyond</title><categories>eess.SP cs.IT math.IT</categories><comments>Presented at SPAWC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multi-antenna millimeter wave (mmWave) and terahertz wireless systems
promise high-bandwidth communication to multiple user equipments in the same
time-frequency resource. The high path loss of wave propagation at such
frequencies and the fine-grained nature of beamforming with massive antenna
arrays necessitates accurate channel estimation to fully exploit the advantages
of such systems. In this paper, we propose BEAmspace CHannel EStimation
(BEACHES), a low-complexity channel estimation algorithm for multi-antenna
mmWave systems and beyond. BEACHES leverages the fact that wave propagation at
high frequencies is directional, which enables us to denoise the
(approximately) sparse channel state information in the beamspace domain. To
avoid tedious parameter selection, BEACHES includes a computationally-efficient
tuning stage that provably minimizes the mean-square error of the channel
estimate in the large-antenna limit. To demonstrate the efficacy of BEACHES, we
provide simulation results for line-of-sight (LoS) and non-LoS mmWave channel
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02919</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02919</id><created>2019-08-07</created><authors><author><keyname>Ritch</keyname><forenames>Matthew D.</forenames></author><author><keyname>Hannon</keyname><forenames>Bailey G.</forenames></author><author><keyname>Read</keyname><forenames>A. Thomas</forenames></author><author><keyname>Feola</keyname><forenames>Andrew J.</forenames></author><author><keyname>Cull</keyname><forenames>Grant A.</forenames></author><author><keyname>Reynaud</keyname><forenames>Juan</forenames></author><author><keyname>Morrison</keyname><forenames>John C.</forenames></author><author><keyname>Burgoyne</keyname><forenames>Claude F.</forenames></author><author><keyname>Pardue</keyname><forenames>Machelle T.</forenames></author><author><keyname>Ethier</keyname><forenames>C. Ross</forenames></author></authors><title>AxoNet: an AI-based tool to count retinal ganglion cell axons</title><categories>q-bio.QM eess.IV</categories><comments>11 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goal: In this work, we develop a robust, extensible tool to automatically and
accurately count retinal ganglion cell axons in images of optic nerve tissue
from various animal models of glaucoma. Methods: The U-Net convolutional neural
network architecture was adapted to learn pixelwise axon count density
estimates, which were then integrated over the image area to determine axon
counts. The tool, termed AxoNet, was trained and evaluated using a dataset
containing images of optic nerve regions randomly selected from complete cross
sections of intact rat optic nerves and manually annotated for axon count and
location. Both control and damaged optic nerves were used. This rat-trained
network was then applied to a separate dataset of non-human primate (NHP) optic
nerve images. AxoNet was then compared to two existing automated axon counting
tools, AxonMaster and AxonJ, using both datasets. Results: AxoNet outperformed
the existing tools on both the rat and NHP optic nerve datasets as judged by
mean absolute error, R2 values when regressing automated vs. manual counts, and
Bland-Altman analysis. Conclusion: The proposed tool allows for accurate
quantification of axon numbers as a measure of glaucomatous damage. AxoNet is
robust to variations in optic nerve tissue damage extent, image quality, and
species of mammal. Significance: The deep learning method does not rely on
hand-crafted image features for axon recognition. Therefore, this approach is
not species-specific and can be extended to quantify additional optic nerve
features. It will aid evaluation of optic nerve changes in glaucoma and
potentially other neurodegenerative diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02924</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02924</id><created>2019-08-08</created><authors><author><keyname>Solovyev</keyname><forenames>Roman</forenames></author><author><keyname>Melekhov</keyname><forenames>Iaroslav</forenames></author><author><keyname>Lesonen</keyname><forenames>Timo</forenames></author><author><keyname>Vaattovaara</keyname><forenames>Elias</forenames></author><author><keyname>Tervonen</keyname><forenames>Osmo</forenames></author><author><keyname>Tiulpin</keyname><forenames>Aleksei</forenames></author></authors><title>Bayesian Feature Pyramid Networks for Automatic Multi-Label Segmentation
  of Chest X-rays and Assessment of Cardio-Thoratic Ratio</title><categories>eess.IV cs.CV</categories><comments>Roman Solovyev and Iaroslav Melekhov contributed equally. Timo
  Lesonen and Elias Vaattovaara contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiothoratic ratio (CTR) estimated from chest radiographs is a marker
indicative of cardiomegaly, the presence of which is in the criteria for heart
failure diagnosis. Existing methods for automatic assessment of CTR are driven
by Deep Learning-based segmentation. However, these techniques produce only
point estimates of CTR but clinical decision making typically assumes the
uncertainty. In this paper, we propose a novel method for chest X-ray
segmentation and CTR assessment in an automatic manner. In contrast to the
previous art, we, for the first time, propose to estimate CTR with uncertainty
bounds. Our method is based on Deep Convolutional Neural Network with Feature
Pyramid Network (FPN) decoder. We propose two modifications of FPN: replace the
batch normalization with instance normalization and inject the dropout which
allows to obtain the Monte-Carlo estimates of the segmentation maps at test
time. Finally, using the predicted segmentation mask samples, we estimate CTR
with uncertainty. In our experiments we demonstrate that the proposed method
generalizes well to three different test sets. Finally, we make the annotations
produced by two radiologists for all our datasets publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02929</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02929</id><created>2019-08-08</created><authors><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author></authors><title>Theoretical Analysis for Extended Target Recovery in Randomized Stepped
  Frequency Radars</title><categories>eess.SP</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized Stepped Frequency Radar (RSFR) is very attractive for tasks under
complex electromagnetic environment. Due to the synthetic high range resolution
in RSRFs, a target usually occupies a series of range cells and is called an
extended target. To reconstruct the range-Doppler information in a RSFR,
previous studies based on sparse recovery mainly exploit the sparsity of the
target scene but do not adequately address the extended-target characteristics,
which exist in many practical applications. Block sparsity, which combines the
sparsity and the target extension, better characterizes a priori knowledge of
the target scene in a wideband RSFR. This paper studies the RSFR range-Doppler
reconstruction problem using block sparse recovery. Particularly, we
theoretically analyze the block coherence and spectral norm of the observation
matrix in RSFR and build a bound on the parameters of the radar, under which
the exact recovery of the range-Doppler information is guaranteed. Both
simulation and field experiment results demonstrate the superiority of the
block sparse recovery over conventional sparse recovery in RSFRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02939</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02939</id><created>2019-08-08</created><updated>2019-10-24</updated><authors><author><keyname>Cheng</keyname><forenames>Boya</forenames></author><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author></authors><title>A neural network approach to GOP-level rate control of x265 using
  Lookahead</title><categories>eess.IV</categories><comments>5 pages 2019PCS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To optimize the perceived quality under a specific bitrate constraint,
multi-pass encoding is usually performed with the rate control mode of the
average bitrate (ABR) or the constant rate factor (CRF) to distribute bits as
reasonably as possible in terms of perceived quality, leading to high
computational complexity. In this paper, we propose to utilize the video
information generated during the encoding to adaptively adjust the CRF setting
at GOP level, ensuring the bits of frames in each GOP are allocated reasonably
under the bitrate constraint with a single-pass encoding framework. In
particular, due to the inherent relationship between CRF values and bitrates,
we adopt a shallow neural network (NN) to map video content features to the
CRF-bitrate model. The content-related features are collected from the
lookahead module inside the x265 encoder, including encoding cost estimation,
motion vector and so on. Further, a rate control method, called content
adaptive rate factor (CARF), is proposed to adjust the CRF value of each GOP
with the requirement of the target bitrate by using the predicted CRF-bitrate
models of each GOP. The experimental results show that the proposed approach
can make 84.5\% testing data within 20% bitrate error (or better) and
outperform the ABR mode in x265, leading to 5.23% BD-rate reduction on average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02950</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02950</id><created>2019-08-08</created><authors><author><keyname>Das</keyname><forenames>Deepan</forenames></author><author><keyname>Ghouse</keyname><forenames>Noor Mohammed</forenames></author><author><keyname>Verma</keyname><forenames>Shashank</forenames></author><author><keyname>Li</keyname><forenames>Yin</forenames></author></authors><title>Semi Supervised Phrase Localization in a Bidirectional Caption-Image
  Retrieval Framework</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel deep neural network architecture that links visual
regions to corresponding textual segments including phrases and words. To
accomplish this task, our architecture makes use of the rich semantic
information available in a joint embedding space of multi-modal data. From this
joint embedding space, we extract the associative localization maps that
develop naturally, without explicitly providing supervision during training for
the localization task. The joint space is learned using a bidirectional ranking
objective that is optimized using a $N$-Pair loss formulation. This training
mechanism demonstrates the idea that localization information is learned
inherently while optimizing a Bidirectional Retrieval objective. The model's
retrieval and localization performance is evaluated on MSCOCO and Flickr30K
Entities datasets. This architecture outperforms the state of the art results
in the semi-supervised phrase localization setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02982</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02982</id><created>2019-08-08</created><authors><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Brihuega</keyname><forenames>Alberto</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>On Antenna Array Out-of-Band Emissions</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Wireless Communications Letters</comments><doi>10.1109/LWC.2019.2934442</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We substantiate and extend recent research on the behavior of the out-of-band
emissions in antenna array transmitters. Specifically, with multi-user
precoding, we show that the emissions are always beamformed in the directions
of the intended receivers, contrary to some claims in the recent literature.
Moreover, while also other spurious directions exist, we show that the
emissions are always strongest in the directions of the intended receivers. We
also show that power amplifiers with mutually different nonlinear phase
characteristics will reduce the beamforming gain of the unwanted emissions,
with the gain approaching the noncoherent combining limit as the phase
deviations are increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.02994</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.02994</id><created>2019-08-08</created><authors><author><keyname>Leclerc</keyname><forenames>Sarah</forenames></author><author><keyname>Smistad</keyname><forenames>Erik</forenames></author><author><keyname>&#xd8;stvik</keyname><forenames>Andreas</forenames></author><author><keyname>Cervenansky</keyname><forenames>Frederic</forenames></author><author><keyname>Espinosa</keyname><forenames>Florian</forenames></author><author><keyname>Espeland</keyname><forenames>Torvald</forenames></author><author><keyname>Berg</keyname><forenames>Erik Andreas Rye</forenames></author><author><keyname>Jodoin</keyname><forenames>Pierre-Marc</forenames></author><author><keyname>Grenier</keyname><forenames>Thomas</forenames></author><author><keyname>Lartizien</keyname><forenames>Carole</forenames></author><author><keyname>Lovstakken</keyname><forenames>Lasse</forenames></author><author><keyname>Bernard</keyname><forenames>Olivier</forenames></author></authors><title>Deep Learning Segmentation in 2D echocardiography using the CAMUS
  dataset : Automatic Assessment of the Anatomical Shape Validity</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/Byx4AM1ntN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We recently published a deep learning study on the potential of
encoder-decoder networks for the segmentation of the 2D CAMUS ultrasound
dataset. We propose in this abstract an extension of the evaluation criteria to
anatomical assessment, as traditional geometric and clinical metrics in cardiac
segmentation do not take into account the anatomical correctness of the
predicted shapes. The completed study sheds a new light on the ranking of
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03009</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03009</id><created>2019-08-08</created><updated>2020-02-24</updated><authors><author><keyname>Falvo</keyname><forenames>Antonio</forenames></author><author><keyname>Comminiello</keyname><forenames>Danilo</forenames></author><author><keyname>Scardapane</keyname><forenames>Simone</forenames></author><author><keyname>Scarpiniti</keyname><forenames>Michele</forenames></author><author><keyname>Uncini</keyname><forenames>Aurelio</forenames></author></authors><title>A Multimodal Deep Network for the Reconstruction of T2W MR Images</title><categories>eess.SP cs.LG cs.NE</categories><comments>29th Italian Neural Networks Workshop (WIRN 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple sclerosis is one of the most common chronic neurological diseases
affecting the central nervous system. Lesions produced by the MS can be
observed through two modalities of magnetic resonance (MR), known as T2W and
FLAIR sequences, both providing useful information for formulating a diagnosis.
However, long acquisition time makes the acquired MR image vulnerable to motion
artifacts. This leads to the need of accelerating the execution of the MR
analysis. In this paper, we present a deep learning method that is able to
reconstruct subsampled MR images obtained by reducing the k-space data, while
maintaining a high image quality that can be used to observe brain lesions. The
proposed method exploits the multimodal approach of neural networks and it also
focuses on the data acquisition and processing stages to reduce execution time
of the MR analysis. Results prove the effectiveness of the proposed method in
reconstructing subsampled MR images while saving execution time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03054</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03054</id><created>2019-08-07</created><authors><author><keyname>Gupta</keyname><forenames>Shruti</forenames></author><author><keyname>Fahad</keyname><forenames>Md. Shah</forenames></author><author><keyname>Deepak</keyname><forenames>Akshay</forenames></author></authors><title>Pitch-Synchronous Single Frequency Filtering Spectrogram for Speech
  Emotion Recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>11 pages and less than 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) are widely used for speech emotion
recognition (SER). In such cases, the short time fourier transform (STFT)
spectrogram is the most popular choice for representing speech, which is fed as
input to the CNN. However, the uncertainty principles of the short-time Fourier
transform prevent it from capturing time and frequency resolutions
simultaneously. On the other hand, the recently proposed single frequency
filtering (SFF) spectrogram promises to be a better alternative because it
captures both time and frequency resolutions simultaneously. In this work, we
explore the SFF spectrogram as an alternative representation of speech for SER.
We have modified the SFF spectrogram by taking the average of the amplitudes of
all the samples between two successive glottal closure instants (GCI)
locations. The duration between two successive GCI locations gives the pitch,
motivating us to name the modified SFF spectrogram as pitch-synchronous SFF
spectrogram. The GCI locations were detected using zero frequency filtering
approach. The proposed pitch-synchronous SFF spectrogram produced accuracy
values of 63.95% (unweighted) and 70.4% (weighted) on the IEMOCAP dataset.
These correspond to an improvement of +7.35% (unweighted) and +4.3% (weighted)
over state-of-the-art result on the STFT sepctrogram using CNN. Specially, the
proposed method recognized 22.7% of the happy emotion samples correctly,
whereas this number was 0% for state-of-the-art results. These results also
promise a much wider use of the proposed pitch-synchronous SFF spectrogram for
other speech-based applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03081</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03081</id><created>2019-08-07</created><authors><author><keyname>Picallo</keyname><forenames>Miguel</forenames></author><author><keyname>Anta</keyname><forenames>Adolfo</forenames></author><author><keyname>De Schutter</keyname><forenames>Bart</forenames></author></authors><title>Comparison of Bounds for Optimal PMU Placement for State Estimation in
  Distribution Grids</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: text overlap with arXiv:1810.12195</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of measurements in distribution grids poses a severe challenge for
their monitoring: since there may not be enough sensors to achieve numerical
observability, load forecasts (pseudo-measurements) are typically used, and
thus an accurate state estimation is not guaranteed. However, an estimation is
required to control distribution grids given the increasing amount of
distributed generation. Therefore, we consider the problem of optimal sensor
placement to improve the state estimation accuracy in large-scale, 3-phase
coupled, unbalanced distribution grids. This is a combinatorial optimization
problem whose optimal solution is unpractical to obtain for large networks. We
explore the properties of different metrics in the context of optimal
experimental design, like convexity and modularity, to propose and compare
several tight lower and upper bounds on the performance of the optimal
solution. Moreover, we show how to use these bounds to choose near-optimal
solutions. We test the method on two IEEE benchmark test feeders, the 123-bus
and the 8500-node feeders, to show the effectiveness of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03119</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03119</id><created>2019-08-08</created><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author></authors><title>Scalable Cell-Free Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Communications, 30 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imagine a coverage area with many wireless access points that cooperate to
jointly serve the users, instead of creating autonomous cells. Such a cell-free
network operation can potentially resolve many of the interference issues that
appear in current cellular networks. This ambition was previously called
Network MIMO (multiple-input multiple-output) and has recently reappeared under
the name Cell-Free Massive MIMO. The main challenge is to achieve the benefits
of cell-free operation in a practically feasible way, with computational
complexity and fronthaul requirements that are scalable to large networks with
many users. We propose a new framework for scalable Cell-Free Massive MIMO
systems by exploiting the dynamic cooperation cluster concept from the Network
MIMO literature. We provide algorithms for initial access, pilot assignment,
cluster formation, precoding, and combining that are proved to be scalable.
Interestingly, the proposed scalable precoding and combining outperform
conventional maximum ratio processing and also performs closely to the best
unscalable alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03129</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03129</id><created>2019-08-08</created><updated>2020-01-05</updated><authors><author><keyname>Edinburgh</keyname><forenames>Tom</forenames></author><author><keyname>Smielewski</keyname><forenames>Peter</forenames></author><author><keyname>Czosnyka</keyname><forenames>Marek</forenames></author><author><keyname>Eglen</keyname><forenames>Stephen J.</forenames></author><author><keyname>Ercole</keyname><forenames>Ari</forenames></author></authors><title>DeepClean -- self-supervised artefact rejection for intensive care
  waveform data using deep generative learning</title><categories>stat.ML cs.LG eess.IV</categories><comments>12 pages, 7 figures, 2 tables; typos corrected, minor changes
  (results unchanged)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Waveform physiological data is important in the treatment of critically ill
patients in the intensive care unit. Such recordings are susceptible to
artefacts, which must be removed before the data can be re-used for alerting or
reprocessed for other clinical or research purposes. Accurate removal of
artefacts reduces bias and uncertainty in clinical assessment, as well as the
false positive rate of intensive care unit alarms, and is therefore a key
component in providing optimal clinical care. In this work, we present
DeepClean; a prototype self-supervised artefact detection system using a
convolutional variational autoencoder deep neural network that avoids costly
and painstaking manual annotation, requiring only easily-obtained 'good' data
for training. For a test case with invasive arterial blood pressure, we
demonstrate that our algorithm can detect the presence of an artefact within a
10-second sample of data with sensitivity and specificity around 90%.
Furthermore, DeepClean was able to identify regions of artefact within such
samples with high accuracy and we show that it significantly outperforms a
baseline principle component analysis approach in both signal reconstruction
and artefact detection. DeepClean learns a generative model and therefore may
also be used for imputation of missing data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03133</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03133</id><created>2019-08-08</created><updated>2019-11-11</updated><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author></authors><title>Demystifying the Power Scaling Law of Intelligent Reflecting Surfaces
  and Metasurfaces</title><categories>eess.SP cs.IT math.IT</categories><comments>To appear at IEEE International Workshop on Computational Advances in
  Multi-Sensor Adaptive Processing (CAMSAP), 2019, 5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surfaces (IRSs) have recently attracted the attention
of communication theorists as a means to control the wireless propagation
channel. It has been shown that the signal-to-noise ratio (SNR) of a
single-user IRS-aided transmission increases as $N^2$, with $N$ being the
number of passive reflecting elements in the IRS. This has been interpreted as
a major potential advantage of using IRSs, instead of conventional Massive MIMO
(mMIMO) whose SNR scales only linearly in $N$. This paper shows that this
interpretation is incorrect. We first prove analytically that mMIMO always
provides higher SNRs, and then show numerically that the gap is substantial; a
very large number of reflecting elements is needed for an IRS to obtain SNRs
comparable to mMIMO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03143</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03143</id><created>2019-08-06</created><authors><author><keyname>Hatala</keyname><forenames>Zulkarnaen</forenames></author><author><keyname>Puturuhu</keyname><forenames>Victor</forenames></author></authors><title>Viterbi Extraction tutorial with Hidden Markov Toolkit</title><categories>cs.SD cs.AI eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm used to extract HMM parameters is revisited. Most parts of the
extraction process are taken from implemented Hidden Markov Toolkit (HTK)
program under name HInit. The algorithm itself shows a few variations compared
to another domain of implementations. The HMM model is introduced briefly based
on the theory of Discrete Time Markov Chain. We schematically outline the
Viterbi method implemented in HTK. Iterative definition of the method which is
ready to be implemented in computer programs is reviewed. We also illustrate
the method calculation precisely using manual calculation and extensive
graphical illustration. The distribution of observation probability used is
simply independent Gaussians r.v.s. The purpose of the content is not to
justify the performance or accuracy of the method applied in a specific area.
This writing merely to describe how the algorithm is performed. The whole
content should enlighten the audience the insight of the Viterbi Extraction
method used by HTK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03167</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03167</id><created>2019-08-08</created><authors><author><keyname>Virasjoki</keyname><forenames>Vilma</forenames></author><author><keyname>Siddiqui</keyname><forenames>Afzal</forenames></author><author><keyname>Oliveira</keyname><forenames>Fabricio</forenames></author><author><keyname>Salo</keyname><forenames>Ahti</forenames></author></authors><title>Utility-Scale Energy Storage in an Imperfectly Competitive Power Sector</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interest in sustainability has increased the share of variable renewable
energy sources (VRES) in power generation. Energy storage systems' potential to
mitigate intermittencies from non-dispatchable VRES has enhanced their appeal.
However, the impacts of storage vary based on the owner and market conditions.
We examine the policy implications of investments in utility-scale battery
storage via a bi-level optimization model. The lower level depicts power system
operations, modeled as either perfect competition or Cournot oligopoly to allow
for the assessment of producer market power. The upper-level investor is either
a welfare-maximizer or a profit-maximizing standalone merchant to reflect
either welfare enhancement or arbitrage, respectively. We implement a realistic
case study for Western Europe based on all possible size-location storage
investment combinations. We find that market competition affects investment
sizes, locations, and their profitability more than the investor's objectives.
A welfare-maximizer under perfect competition invests the most in storage
capacity. Consumers typically gain most from storage investments in all cases,
exceeding the gains for the investors. Specifically, our results show that
storage investments may either not occur or be located differently than at
social optimum, if market power is exerted. Thus, policy makers need to
anticipate producer market power when setting regulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03173</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03173</id><created>2019-08-08</created><updated>2019-11-26</updated><authors><author><keyname>Abdoli</keyname><forenames>Sajjad</forenames></author><author><keyname>Hafemann</keyname><forenames>Luiz G.</forenames></author><author><keyname>Rony</keyname><forenames>Jerome</forenames></author><author><keyname>Ayed</keyname><forenames>Ismail Ben</forenames></author><author><keyname>Cardinal</keyname><forenames>Patrick</forenames></author><author><keyname>Koerich</keyname><forenames>Alessandro L.</forenames></author></authors><title>Universal Adversarial Audio Perturbations</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the existence of universal adversarial perturbations, which
can fool a family of audio classification architectures, for both targeted and
untargeted attack scenarios. We propose two methods for finding such
perturbations. The first method is based on an iterative, greedy approach that
is well-known in computer vision: it aggregates small perturbations to the
input so as to push it to the decision boundary. The second method, which is
the main contribution of this work, is a novel penalty formulation, which finds
targeted and untargeted universal adversarial perturbations. Differently from
the greedy approach, the penalty method minimizes an appropriate objective
function on a batch of samples. Therefore, it produces more successful attacks
when the number of training samples is limited. Moreover, we provide a proof
that the proposed penalty method theoretically converges to a solution that
corresponds to universal adversarial perturbations. We also demonstrate that it
is possible to provide successful attacks using the penalty method when only
one sample from the target dataset is available for the attacker. Experimental
results on attacking five 1D CNN architectures have shown attack success rates
higher than 85.4% and 83.1% for targeted and untargeted attacks, respectively
using the proposed penalty method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03176</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03176</id><created>2019-08-08</created><authors><author><keyname>Soleymani</keyname><forenames>Sobhan</forenames></author><author><keyname>Dabouei</keyname><forenames>Ali</forenames></author><author><keyname>Dawson</keyname><forenames>Jeremy</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser M.</forenames></author></authors><title>Defending Against Adversarial Iris Examples Using Wavelet Decomposition</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>The Tenth IEEE International Conference on Biometrics: Theory,
  Applications, and Systems (BTAS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have presented impressive performance in biometric
applications. However, their performance is highly at risk when facing
carefully crafted input samples known as adversarial examples. In this paper,
we present three defense strategies to detect adversarial iris examples. These
defense strategies are based on wavelet domain denoising of the input examples
by investigating each wavelet sub-band and removing the sub-bands that are most
affected by the adversary. The first proposed defense strategy reconstructs
multiple denoised versions of the input example through manipulating the mid-
and high-frequency components of the wavelet domain representation of the input
example and makes a decision upon the classification result of the majority of
the denoised examples. The second and third proposed defense strategies aim to
denoise each wavelet domain sub-band and determine the sub-bands that are most
likely affected by the adversary using the reconstruction error computed for
each sub-band. We test the performance of the proposed defense strategies
against several attack scenarios and compare the results with five state of the
art defense strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03187</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03187</id><created>2019-08-08</created><updated>2019-10-30</updated><authors><author><keyname>Arachchi</keyname><forenames>W. A. Chamalee Wickrama</forenames></author><author><keyname>Manosha</keyname><forenames>K. B. Shashika</forenames></author><author><keyname>Rajatheva</keyname><forenames>N.</forenames></author><author><keyname>Latva-aho</keyname><forenames>M.</forenames></author></authors><title>An Alternating Algorithm for Uplink Max-Min SINR in Cell-Free Massive
  MIMO with Local-MMSE Receiver</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of max-min signal-to-interference plus noise ratio (SINR) for
uplink transmission of cell-free massive multiple-input multiple-output (MIMO)
system is considered. We assume that the system is employed with local minimum
mean square error (L-MMSE) combining. The objective is to preserve user
fairness by solving max-min SINR optimization problem, by optimizing transmit
power of each user equipment (UE) and weighting coefficients at central
processing unit (CPU), subject to transmit power constraints of UEs. This
problem is not jointly convex. Hence, we decompose original problem into two
subproblems, particularly for optimizing power allocation and receiver
weighting coefficients. Then, we propose an alternating algorithm to solve
these two subproblems. The weighting coefficient subproblem is formulated as a
generalized eigenvalue problem while power allocation subproblem is
approximated as geometric programming (GP). We empirically show that the
proposed algorithm achieves higher min-user uplink spectral efficiency (SE)
over existing fixed power scheme which is not optimized with respect to the
transmit power. Moreover, the convergence of the proposed algorithm is
numerically illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03202</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03202</id><created>2019-08-08</created><updated>2019-08-12</updated><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author></authors><title>Received Signal Strength Based Wireless Source Localization with Inexact
  Anchor Position</title><categories>eess.SP cs.OH</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Received signal strength(RSS)-based approach of wireless localization is easy
to implement at low cost. In practice, exact positions of anchors may not be
available. This paper focuses on determining the location of the source in the
presence of inexact position of anchors based on RSS directly. This study at
first uses Taylor expansion and a min-max approach to get the approximate
maximum likelihood estimator of the source coordinates. Then this paper
proposes a relaxed semi-definite programming model to circumvent the
non-convexity. This paper also proposes a rounding algorithm concerning both
the inexact source location and the inaccurate anchor location. Experimental
results together with analysis are presented to validate the proposed method
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03204</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03204</id><created>2019-08-08</created><updated>2019-08-13</updated><authors><author><keyname>Zhao</keyname><forenames>Wenshuai</forenames></author><author><keyname>Zeng</keyname><forenames>Zengfeng</forenames></author></authors><title>Multi Scale Supervised 3D U-Net for Kidney and Tumor Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  U-Net has achieved huge success in various medical image segmentation
challenges. Kinds of new architectures with bells and whistles might succeed in
certain dataset when employed with optimal hyper-parameter, but their
generalization always can't be guaranteed. Here, we focused on the basic U-Net
architecture and proposed a multi scale supervised 3D U-Net for the
segmentation task in KiTS19 challenge. To enhance the performance, our work can
be summarized as three folds: first, we used multi scale supervision in the
decoder pathway, which could encourage the network to predict right results
from the deep layers; second, with the aim to alleviate the bad effect from the
sample imbalance of kidney and tumor, we adopted exponential logarithmic loss;
third, a connected-component based post processing method was designed to
remove the obviously wrong voxels. In the published KiTS19 training dataset
(totally 210 patients), we divided 42 patients to be test dataset and finally
obtained DICE scores of 0.969 and 0.805 for the kidney and tumor respectively.
In the challenge, we finally achieved the 7th place among 106 teams with the
Composite Dice of 0.8961, namely 0.9741 for kidney and 0.8181 for tumor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03238</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03238</id><created>2019-08-08</created><updated>2019-09-19</updated><authors><author><keyname>Izadi</keyname><forenames>Saeed</forenames></author><author><keyname>Mirikharaji</keyname><forenames>Zahra</forenames></author><author><keyname>Zhao</keyname><forenames>Mengliu</forenames></author><author><keyname>Hamarneh</keyname><forenames>Ghassan</forenames></author></authors><title>WhiteNNer-Blind Image Denoising via Noise Whiteness Priors</title><categories>eess.IV cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The accuracy of medical imaging-based diagnostics is directly impacted by the
quality of the collected images. A passive approach to improve image quality is
one that lags behind improvements in imaging hardware, awaiting better sensor
technology of acquisition devices. An alternative, active strategy is to
utilize prior knowledge of the imaging system to directly post-process and
improve the acquired images. Traditionally, priors about the image properties
are taken into account to restrict the solution space. However, few techniques
exploit the prior about the noise properties. In this paper, we propose a
neural network-based model for disentangling the signal and noise components of
an input noisy image, without the need for any ground truth training data. We
design a unified loss function that encodes priors about signal as well as
noise estimate in the form of regularization terms. Specifically, by using
total variation and piecewise constancy priors along with noise whiteness
priors such as auto-correlation and stationary losses, our network learns to
decouple an input noisy image into the underlying signal and noise components.
We compare our proposed method to Noise2Noise and Noise2Self, as well as
non-local mean and BM3D, on three public confocal laser endomicroscopy
datasets. Experimental results demonstrate the superiority of our network
compared to state-of-the-art in terms of PSNR and SSIM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03245</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03245</id><created>2019-08-08</created><authors><author><keyname>Liu</keyname><forenames>Xiaohong</forenames></author><author><keyname>Ma</keyname><forenames>Yongrui</forenames></author><author><keyname>Shi</keyname><forenames>Zhihao</forenames></author><author><keyname>Chen</keyname><forenames>Jun</forenames></author></authors><title>GridDehazeNet: Attention-Based Multi-Scale Network for Image Dehazing</title><categories>cs.CV eess.IV</categories><comments>10 pages, accepted in ICCV 2019, project page:
  https://proteus1991.github.io/GridDehazeNet/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an end-to-end trainable Convolutional Neural Network (CNN), named
GridDehazeNet, for single image dehazing. The GridDehazeNet consists of three
modules: pre-processing, backbone, and post-processing. The trainable
pre-processing module can generate learned inputs with better diversity and
more pertinent features as compared to those derived inputs produced by
hand-selected pre-processing methods. The backbone module implements a novel
attention-based multi-scale estimation on a grid network, which can effectively
alleviate the bottleneck issue often encountered in the conventional
multi-scale approach. The post-processing module helps to reduce the artifacts
in the final output. Experimental results indicate that the GridDehazeNet
outperforms the state-of-the-arts on both synthetic and real-world images. The
proposed hazing method does not rely on the atmosphere scattering model, and we
provide an explanation as to why it is not necessarily beneficial to take
advantage of the dimension reduction offered by the atmosphere scattering model
for image dehazing, even if only the dehazing results on synthetic images are
concerned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03251</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03251</id><created>2019-08-05</created><authors><author><keyname>Zhang</keyname><forenames>Yunxuan</forenames></author><author><keyname>Zhang</keyname><forenames>Siwei</forenames></author><author><keyname>He</keyname><forenames>Yue</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author><author><keyname>Liu</keyname><forenames>Ziwei</forenames></author></authors><title>One-shot Face Reenactment</title><categories>cs.CV eess.IV</categories><comments>To appear in BMVC 2019 as a spotlight presentation. Code and models
  are available at: https://github.com/bj80heyue/One_Shot_Face_Reenactment</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To enable realistic shape (e.g. pose and expression) transfer, existing face
reenactment methods rely on a set of target faces for learning subject-specific
traits. However, in real-world scenario end-users often only have one target
face at hand, rendering existing methods inapplicable. In this work, we bridge
this gap by proposing a novel one-shot face reenactment learning framework. Our
key insight is that the one-shot learner should be able to disentangle and
compose appearance and shape information for effective modeling. Specifically,
the target face appearance and the source face shape are first projected into
latent spaces with their corresponding encoders. Then these two latent spaces
are associated by learning a shared decoder that aggregates multi-level
features to produce the final reenactment results. To further improve the
synthesizing quality on mustache and hair regions, we additionally propose
FusionNet which combines the strengths of our learned decoder and the
traditional warping method. Extensive experiments show that our one-shot face
reenactment system achieves superior transfer fidelity as well as identity
preserving capability than alternatives. More remarkably, our approach trained
with only one target image per subject achieves competitive results to those
using a set of target images, demonstrating the practical merit of this work.
Code, models and an additional set of reenacted faces have been publicly
released at the project page.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03260</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03260</id><created>2019-08-08</created><authors><author><keyname>Ravindra</keyname><forenames>Vikram</forenames></author><author><keyname>Grama</keyname><forenames>Ananth</forenames></author></authors><title>De-anonymization Attacks on Neuroimaging Datasets</title><categories>cs.CR eess.IV q-bio.NC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Advances in imaging technologies, combined with inexpensive storage, have led
to an explosion in the volume of publicly available neuroimaging datasets.
Effective analyses of these images hold the potential for uncovering mechanisms
that govern functioning of the human brain, and understanding various
neurological diseases and disorders. The potential significance of these
studies notwithstanding, a growing concern relates to the protection of privacy
and confidentiality of subjects who participate in these studies. In this
paper, we present a de-anonymization attack rooted in the innate uniqueness of
the structure and function of the human brain. We show that the attack reveals
not only the identity of an individual, but also the task they are performing,
and their efficacy in performing the tasks. Our attack relies on novel matrix
analyses techniques that are used to extract discriminating features in
neuroimages. These features correspond to individual-specific signatures that
can be matched across datasets to yield highly accurate identification. We
present data preprocessing, signature extraction, and matching techniques that
are computationally inexpensive, and can scale to large datasets. We discuss
implications of the attack and challenges associated with defending against
such attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03264</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03264</id><created>2019-08-08</created><authors><author><keyname>Sanchez-Romero</keyname><forenames>Ruben</forenames></author><author><keyname>Ramsey</keyname><forenames>Joseph D.</forenames></author><author><keyname>Zhang</keyname><forenames>Kun</forenames></author><author><keyname>Glymour</keyname><forenames>Clark</forenames></author></authors><title>Identification of Effective Connectivity Subregions</title><categories>q-bio.NC cs.LG eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard fMRI connectivity analyses depend on aggregating the time series of
individual voxels within regions of interest (ROIs). In certain cases, this
spatial aggregation implies a loss of valuable functional and anatomical
information about smaller subsets of voxels that drive the ROI level
connectivity. We use two recently published graphical search methods to
identify subsets of voxels that are highly responsible for the connectivity
between larger ROIs. To illustrate the procedure, we apply both methods to
longitudinal high-resolution resting state fMRI data from regions in the medial
temporal lobe from a single individual. Both methods recovered similar subsets
of voxels within larger ROIs of entorhinal cortex and hippocampus subfields
that also show spatial consistency across different scanning sessions and
across hemispheres. In contrast to standard functional connectivity methods,
both algorithms applied here are robust against false positive connections
produced by common causes and indirect paths (in contrast to Pearson's
correlation) and common effect conditioning (in contrast to partial correlation
based approaches). These algorithms allow for identification of subregions of
voxels driving the connectivity between regions of interest, recovering
valuable anatomical and functional information that is lost when ROIs are
aggregated. Both methods are specially suited for voxelwise connectivity
research, given their running times and scalability to big data problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03271</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03271</id><created>2019-08-08</created><updated>2019-08-19</updated><authors><author><keyname>Zhang</keyname><forenames>Qianqian</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>Reflections in the Sky: Millimeter Wave Communication with UAV-Carried
  Intelligent Reflectors</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel approach that uses an unmanned aerial vehicle
(UAV)-carried intelligent reflector (IR) is proposed to enhance the performance
of millimeter wave (mmW) networks. In particular, the UAV-IR is used to
intelligently reflect mmW beamforming signals from a base station towards a
mobile outdoor user, while harvesting energy from mmW signals to power the IR.
To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL)
approach, based on Q-learning and neural networks, is proposed to model the
propagation environment, such that the location and reflection coefficient of
the UAV-IR can be optimized to maximize the downlink transmission capacity.
Simulation results show a significant advantage for using a UAV-IR over a
static IR, in terms of the average data rate and the achievable downlink LOS
probability. The results also show that the RL-based deployment of the UAV-IR
further improves the network performance, relative to a scheme without
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03272</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03272</id><created>2019-08-08</created><authors><author><keyname>Shrivastava</keyname><forenames>Aman</forenames></author><author><keyname>Kant</keyname><forenames>Karan</forenames></author><author><keyname>Sengupta</keyname><forenames>Saurav</forenames></author><author><keyname>Kang</keyname><forenames>Sung-Jun</forenames></author><author><keyname>Khan</keyname><forenames>Marium</forenames></author><author><keyname>Ali</keyname><forenames>Asad</forenames></author><author><keyname>Moore</keyname><forenames>Sean R.</forenames></author><author><keyname>Amadi</keyname><forenames>Beatrice C.</forenames></author><author><keyname>Kelly</keyname><forenames>Paul</forenames></author><author><keyname>Brown</keyname><forenames>Donald E.</forenames></author><author><keyname>Syed</keyname><forenames>Sana</forenames></author></authors><title>Deep Learning for Visual Recognition of Environmental Enteropathy and
  Celiac Disease</title><categories>q-bio.QM cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physicians use biopsies to distinguish between different but histologically
similar enteropathies. The range of syndromes and pathologies that could cause
different gastrointestinal conditions makes this a difficult problem. Recently,
deep learning has been used successfully in helping diagnose cancerous tissues
in histopathological images. These successes motivated the research presented
in this paper, which describes a deep learning approach that distinguishes
between Celiac Disease (CD) and Environmental Enteropathy (EE) and normal
tissue from digitized duodenal biopsies. Experimental results show accuracies
of over 90% for this approach. We also look into interpreting the neural
network model using Gradient-weighted Class Activation Mappings and filter
activations on input images to understand the visual explanations for the
decisions made by the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03284</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03284</id><created>2019-08-08</created><authors><author><keyname>Abate</keyname><forenames>Matthew</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author></authors><title>Monitor-Based Runtime Assurance for Temporal Logic Specifications</title><categories>eess.SY cs.SY</categories><comments>8 Pages, 4 Figures. IEEE Conference on Decision and Control, 2019, to
  appear</comments><msc-class>93A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the safety controller architecture as a runtime
assurance mechanism for system specifications expressed as safety properties in
Linear Temporal Logic (LTL). The safety controller has three fundamental
components: a performance controller, a backup controller, and an assurance
mechanism. The assurance mechanism uses a monitor, constructed as a finite
state machine (FSM), to analyze a suggested performance control input and
search for system trajectories that are bad prefixes of the system
specification. A fault flag from the assurance mechanism denotes a potentially
dangerous future system state and triggers a sequence of inputs that is
guaranteed to keep the system safe for all time. A case study is presented
which details the construction and implementation of a safety controller on a
non-deterministic cyber-physical system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03288</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03288</id><created>2019-08-08</created><authors><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Casta&#xf1;eda</keyname><forenames>Oscar</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>A 354Mb/s 0.37mm^2 151mW 32-User 256-QAM Near-MAP Soft-Input Soft-Output
  Massive MU-MIMO Data Detector in 28nm CMOS</title><categories>cs.IT eess.SP math.IT</categories><comments>to appear in the IEEE Solid-State Circuits Letters (invited) and the
  IEEE 45th European Solid-State Circuits Conference (ESSCIRC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel data detector ASIC for massive multiuser
multiple-input multiple-output (MU-MIMO) wireless systems. The ASIC implements
a modified version of the large-MIMO approximate message passing algorithm
(LAMA), which achieves near-optimal error-rate performance (i) under realistic
channel conditions and (ii) for systems with as many users as base-station (BS)
antennas. The hardware architecture supports 32 users transmitting 256-QAM
simultaneously and in the same time-frequency resource, and provides soft-input
soft-output capabilities for iterative detection and decoding. The fabricated
28nm CMOS ASIC occupies 0.37mm^2 , achieves a throughput of 354Mb/s, consumes
151mW, and improves the SNR by more than 11dB compared to existing data
detectors in systems with 32 BS antennas and 32 users for realistic channels.
In addition, the ASIC achieves 4x higher throughput per area compared to a
recently proposed message-passing detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03299</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03299</id><created>2019-08-08</created><authors><author><keyname>Koizumi</keyname><forenames>Yuma</forenames></author><author><keyname>Saito</keyname><forenames>Shoichiro</forenames></author><author><keyname>Uematsu</keyname><forenames>Hisashi</forenames></author><author><keyname>Harada</keyname><forenames>Noboru</forenames></author><author><keyname>Imoto</keyname><forenames>Keisuke</forenames></author></authors><title>ToyADMOS: A Dataset of Miniature-Machine Operating Sounds for Anomalous
  Sound Detection</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>5 pages, to appear in IEEE WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new dataset called &quot;ToyADMOS&quot; designed for anomaly
detection in machine operating sounds (ADMOS). To the best our knowledge, no
large-scale datasets are available for ADMOS, although large-scale datasets
have contributed to recent advancements in acoustic signal processing. This is
because anomalous sound data are difficult to collect. To build a large-scale
dataset for ADMOS, we collected anomalous operating sounds of miniature
machines (toys) by deliberately damaging them. The released dataset consists of
three sub-datasets for machine-condition inspection, fault diagnosis of
machines with geometrically fixed tasks, and fault diagnosis of machines with
moving tasks. Each sub-dataset includes over 180 hours of normal
machine-operating sounds and over 4,000 samples of anomalous sounds collected
with four microphones at a 48-kHz sampling rate. The dataset is freely
available for download at https://github.com/YumaKoizumi/ToyADMOS-dataset
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03302</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03302</id><created>2019-08-09</created><authors><author><keyname>Martiartu</keyname><forenames>N. Korta</forenames><affiliation>Institute of Geophysics, ETH Zurich, Zurich, Switzerland</affiliation></author><author><keyname>Boehm</keyname><forenames>C.</forenames><affiliation>Institute of Geophysics, ETH Zurich, Zurich, Switzerland</affiliation></author><author><keyname>Fichtner</keyname><forenames>A.</forenames><affiliation>Institute of Geophysics, ETH Zurich, Zurich, Switzerland</affiliation></author></authors><title>3D Wave-Equation-Based Finite-Frequency Tomography for Ultrasound
  Computed Tomography</title><categories>physics.med-ph eess.IV</categories><comments>12 pages, 9 figures, to be submitted to IEEE Transactions on
  Ultrasonics, Ferroelectrics and Frequency Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound Computed Tomography (USCT) has great potential for 3D quantitative
imaging of acoustic breast tissue properties. Typical devices include
high-frequency transducers, which makes tomography techniques based on
numerical wave propagation simulations computationally challenging, especially
in 3D. Therefore, despite the finite-frequency nature of ultrasonic waves,
ray-theoretical approaches to transmission tomography are still widely used.
  This work introduces finite-frequency traveltime tomography to medical
ultrasound. In addition to being computationally tractable for 3D imaging at
high frequencies, the method has two main advantages: (1) It correctly accounts
for the frequency dependence and volumetric sensitivity of traveltime
measurements, which are related to off-ray-path scattering and diffraction. (2)
It naturally enables out-of-plane imaging and the construction of 3D images
from 2D slice-by-slice acquisition systems.
  Our method rests on the availability of calibration data in water, used to
linearize the forward problem and to provide analytical expressions of
cross-correlation traveltime sensitivity. As a consequence of the finite
frequency content, sensitivity is distributed in multiple Fresnel volumes,
thereby providing out-of-plane sensitivity. To improve computational
efficiency, we develop a memory-efficient implementation by encoding the
Jacobian operator with a 1D parameterization, which allows us to extend the
method to large-scale domains. We validate our tomographic approach using lab
measurements collected with a 2D setup of transducers and using a cylindrically
symmetric phantom. We then demonstrate its applicability for 3D reconstructions
by simulating a slice-by-slice acquisition systems using the same dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03339</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03339</id><created>2019-08-09</created><authors><author><keyname>Sabarinathan</keyname><forenames>D.</forenames></author><author><keyname>Beham</keyname><forenames>M. Parisa</forenames></author><author><keyname>Roomi</keyname><forenames>S. M. Md. Mansoor</forenames></author></authors><title>Hyper Vision Net: Kidney Tumor Segmentation Using Coordinate
  Convolutional Layer and Attention Unit</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 3 figures, KiTs19 challenge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  KiTs19 challenge paves the way to haste the improvement of solid kidney tumor
semantic segmentation methodologies. Accurate segmentation of kidney tumor in
computer tomography (CT) images is a challenging task due to the non-uniform
motion, similar appearance and various shape. Inspired by this fact, in this
manuscript, we present a novel kidney tumor segmentation method using deep
learning network termed as Hyper vision Net model. All the existing U-net
models are using a modified version of U-net to segment the kidney tumor
region. In the proposed architecture, we introduced supervision layers in the
decoder part, and it refines even minimal regions in the output. A dataset
consists of real arterial phase abdominal CT scans of 300 patients, including
45964 images has been provided from KiTs19 for training and validation of the
proposed model. Compared with the state-of-the-art segmentation methods, the
results demonstrate the superiority of our approach on training dice value
score of 0.9552 and 0.9633 in tumor region and kidney region, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03359</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03359</id><created>2019-08-09</created><authors><author><keyname>Hegde</keyname><forenames>Ganapati</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Pesavento</keyname><forenames>Marius</forenames></author></authors><title>Coordinated Hybrid Precoding for Interference Exploitation in
  Heterogeneous Networks</title><categories>eess.SP</categories><comments>IEEE Communications Letters 2019</comments><doi>10.1109/LCOMM.2019.2933840</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a downlink multiuser massive MIMO system comprising multiple
heterogeneous base stations with hybrid precoding architectures. To enhance the
energy efficiency of the network, we propose a novel coordinated hybrid
precoding technique, where the coordination between the base stations is aimed
at exploiting interference as opposed to mitigating it as per conventional
approaches. We formulate an optimization problem to compute the coordinated
hybrid precoders that minimize the total transmit power while fulfilling the
required quality of service at each user. Furthermore, we devise a
low-complexity suboptimal precoding scheme to compute approximate solutions of
the precoding problem. The simulation results reveal that the proposed
coordinated hybrid precoding yields superior performance when compared to the
conventional hybrid precoding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03360</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03360</id><created>2019-08-09</created><updated>2019-08-25</updated><authors><author><keyname>Yang</keyname><forenames>Yuwen</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author><author><keyname>Jian</keyname><forenames>Mengnan</forenames></author></authors><title>Deep Learning based Downlink Channel Prediction for FDD Massive MIMO
  System</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a frequency division duplexing (FDD) massive multiple-input
multiple-output (MIMO) system, the acquisition of downlink channel state
information (CSI) at base station (BS) is a very challenging task due to the
overwhelming overheads required for downlink training and uplink feedback. In
this paper, we reveal a deterministic uplink-to-downlink mapping function when
the position-to-channel mapping is bijective. Motivated by the universal
approximation theorem, we then propose a sparse complex-valued neural network
(SCNet) to approximate the uplink-to-downlink mapping function. Different from
general deep networks that operate in the real domain, the SCNet is constructed
in the complex domain and is able to learn the complex-valued mapping function
by off-line training. After training, the SCNet is used to directly predict the
downlink CSI based on the estimated uplink CSI without the need of either
downlink training or uplink feedback. Numerical results show that the SCNet
achieves better performance than general deep networks in terms of prediction
accuracy and exhibits remarkable robustness over complicated wireless channels,
demonstrating its great potential for practical deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03361</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03361</id><created>2019-08-09</created><authors><author><keyname>Barz</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Schr&#xf6;ter</keyname><forenames>Kai</forenames></author><author><keyname>M&#xfc;nch</keyname><forenames>Moritz</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author><author><keyname>Unger</keyname><forenames>Andrea</forenames></author><author><keyname>Dransch</keyname><forenames>Doris</forenames></author><author><keyname>Denzler</keyname><forenames>Joachim</forenames></author></authors><title>Enhancing Flood Impact Analysis using Interactive Retrieval of Social
  Media Images</title><categories>cs.IR cs.CV cs.MM eess.IV</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The analysis of natural disasters such as floods in a timely manner often
suffers from limited data due to a coarse distribution of sensors or sensor
failures. This limitation could be alleviated by leveraging information
contained in images of the event posted on social media platforms, so-called
&quot;Volunteered Geographic Information (VGI)&quot;. To save the analyst from the need
to inspect all images posted online manually, we propose to use content-based
image retrieval with the possibility of relevance feedback for retrieving only
relevant images of the event to be analyzed. To evaluate this approach, we
introduce a new dataset of 3,710 flood images, annotated by domain experts
regarding their relevance with respect to three tasks (determining the flooded
area, inundation depth, water pollution). We compare several image features and
relevance feedback methods on that dataset, mixed with 97,085 distractor
images, and are able to improve the precision among the top 100 retrieval
results from 55% with the baseline retrieval to 87% after 5 rounds of feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03398</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03398</id><created>2019-08-09</created><authors><author><keyname>Wei</keyname><forenames>Bo</forenames></author><author><keyname>Li</keyname><forenames>Kai</forenames></author><author><keyname>Luo</keyname><forenames>Chengwen</forenames></author><author><keyname>Xu</keyname><forenames>Weitao</forenames></author><author><keyname>Zhang</keyname><forenames>Jin</forenames></author></authors><title>No Need of Data Pre-processing: A General Framework for Radio-Based
  Device-Free Context Awareness</title><categories>cs.NI eess.SP</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-free context awareness is important to many applications. There are
two broadly used approaches for device-free context awareness, i.e. video-based
and radio-based. Video-based applications can deliver good performance, but
privacy is a serious concern. Radio-based context awareness has drawn
researchers attention instead because it does not violate privacy and radio
signal can penetrate obstacles. Recently, deep learning has been introduced
into radio-based device-free context awareness and helps boost the recognition
accuracy. The present works design explicit methods for each radio based
application. They also use one additional step to extract features before
conducting classification and exploit deep learning as a classification tool.
The additional initial data processing step introduces unnecessary noise and
information loss. Without initial data processing, it is, however, challenging
to explore patterns of raw signals. In this paper, we are the first to propose
an innovative deep learning based general framework for both signal processing
and classification. The key novelty of this paper is that the framework can be
generalised for all the radio-based context awareness applications. We also
eliminate the additional effort to extract features from raw radio signals. We
conduct extensive evaluations to show the superior performance of our proposed
method and its generalisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03418</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03418</id><created>2019-08-09</created><authors><author><keyname>Barneto</keyname><forenames>Carlos Baquero</forenames></author><author><keyname>Riihonen</keyname><forenames>Taneli</forenames></author><author><keyname>Turunen</keyname><forenames>Matias</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Fleischer</keyname><forenames>Marko</forenames></author><author><keyname>Stadius</keyname><forenames>Kari</forenames></author><author><keyname>Ryyn&#xe4;nen</keyname><forenames>Jussi</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Full-Duplex OFDM Radar With LTE and 5G NR Waveforms: Challenges,
  Solutions, and Measurements</title><categories>eess.SP</categories><comments>Paper accepted by IEEE Transactions on Microwave Theory and
  Techniques</comments><doi>10.1109/TMTT.2019.2930510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the processing principles, implementation challenges, and
performance of OFDM-based radars, with particular focus on the
fourth-generation Long-Term Evolution (LTE) and fifth-generation (5G) New Radio
(NR) mobile networks' base stations and their utilization for radar/sensing
purposes. First, we address the problem stemming from the unused subcarriers
within the LTE and NR transmit signal passbands, and their impact on
frequency-domain radar processing. Particularly, we formulate and adopt a
computationally efficient interpolation approach to mitigate the effects of
such empty subcarriers in the radar processing. We evaluate the target
detection and the corresponding range and velocity estimation performance
through computer simulations, and show that high-quality target detection as
well as high-precision range and velocity estimation can be achieved.
Especially 5G NR waveforms, through their impressive channel bandwidths and
configurable subcarrier spacing, are shown to provide very good radar/sensing
performance. Then, a fundamental implementation challenge of
transmitter-receiver (TX-RX) isolation in OFDM radars is addressed, with
specific emphasis on shared-antenna cases, where the TX-RX isolation challenges
are the largest. It is confirmed that from the OFDM radar processing
perspective, limited TX-RX isolation is primarily a concern in detection of
static targets while moving targets are inherently more robust to transmitter
self-interference. Properly tailored analog/RF and digital self-interference
cancellation solutions for OFDM radars are also described and implemented, and
shown through RF measurements to be key technical ingredients for practical
deployments, particularly from static and slowly moving targets' point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03433</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03433</id><created>2019-08-09</created><authors><author><keyname>Chagnon</keyname><forenames>Johan</forenames></author><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author></authors><title>Mixed-transform based codec for 2D compression of ECG signals</title><categories>eess.SP</categories><comments>MATLAB software for implementing the codec has been made available on
  http://www.nonlinear-approx.info/examples/node014.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for ECG compression, by imaging the record as a 2D array and
implementing a transform lossy compression strategy, is advanced. The
particularity of the proposed transformation consists in applying a Discrete
Wavelet Transform along one of the dimensions and the Discrete Cosine Transform
along the other dimension. The performance of the method is demonstrated on the
MIT-BIH Arrhythmia database. Significant improvements upon the 1D version of
the codec, and on benchmarks for 2D ECG compression, are achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03441</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03441</id><created>2019-08-08</created><authors><author><keyname>Bi</keyname><forenames>Dadi</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Pierobon</keyname><forenames>Massimiliano</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Chemical Reactions-Based Microfluidic Transmitter and Receiver for
  Molecular Communication</title><categories>cs.ET eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of communication systems capable of processing and exchanging
information through molecules and chemical processes is a rapidly growing
interdisciplinary field, which holds the promise to revolutionize how we
realize computing and communication devices. While molecular communication (MC)
theory has had major developments in recent years, more practical aspects in
designing components capable of MC functionalities remain less explored.
Motivated by this, we design a microfluidic MC system with a microfluidic MC
transmitter and a microfluidic MC receiver based on chemical reactions.
Considering existing MC literature on information transmission via molecular
pulse modulation, the proposed microfluidic MC transmitter is capable of
generating continuously predefined pulse-shaped molecular concentrations upon
rectangular triggering signals using chemical reactions inspired by how cells
generate pulse-shaped molecular signals in biology. We further design a
microfluidic MC receiver capable of demodulating a received signal to a
rectangular output signal using a thresholding reaction and an amplifying
reaction. Our chemical reactions-based microfluidic molecular communication
system is reproducible and well-designed, and more importantly, it overcomes
the slow-speed, unreliability, and non-scalability of biological processes in
cells. To reveal design insights, we also derive the theoretical signal
responses for our designed microfluidic transmitter and receiver, which further
facilitate the transmitter design optimization. Our theoretical results are
validated via simulations performed through the COMSOL Multiphysics finite
element solver. We demonstrate the predefined nature of the generated pulse and
the demodulated rectangular signal together with their dependence on design
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03447</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03447</id><created>2019-07-30</created><authors><author><keyname>Wang</keyname><forenames>Liang</forenames></author><author><keyname>Ye</keyname><forenames>Hao</forenames></author><author><keyname>Liang</keyname><forenames>Le</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Learn to Allocate Resources in Vehicular Networks</title><categories>cs.NI cs.IT cs.LG eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource allocation has a direct and profound impact on the performance of
vehicle-to-everything (V2X) networks. Considering the dynamic nature of
vehicular environments, it is appealing to devise a decentralized strategy to
perform effective resource sharing. In this paper, we exploit deep learning to
promote coordination among multiple vehicles and propose a hybrid architecture
consisting of centralized decision making and distributed resource sharing to
maximize the long-term sum rate of all vehicles. To reduce the network
signaling overhead, each vehicle uses a deep neural network to compress its own
observed information that is thereafter fed back to the centralized
decision-making unit, which employs a deep Q-network to allocate resources and
then sends the decision results to all vehicles. We further adopt a
quantization layer for each vehicle that learns to quantize the continuous
feedback. Extensive simulation results demonstrate that the proposed hybrid
architecture can achieve near-optimal performance. Meanwhile, there exists an
optimal number of continuous feedback and binary feedback, respectively.
Besides, this architecture is robust to different feedback intervals, input
noise, and feedback noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03454</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03454</id><created>2019-08-09</created><updated>2020-01-28</updated><authors><author><keyname>Heimowitz</keyname><forenames>Ayelet</forenames></author><author><keyname>And&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Bias and variance reduction and denoising for CTF Estimation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When using an electron microscope for imaging of particles embedded in
vitreous ice, the objective lens will inevitably corrupt the projection images.
This corruption manifests as a band-pass filter on the micrograph. In addition,
it causes the phase of several frequency bands to be flipped and distorts
frequency bands. As a precursor to compensating for this distortion, the
corrupting point spread function, which is termed the contrast transfer
function (CTF) in reciprocal space, must be estimated. In this paper, we will
present a novel method for CTF estimation. Our method is based on the
multi-taper method for power spectral density estimation, which aims to reduce
the bias and variance of the estimator. Furthermore, we use known properties of
the CTF and of the background of the power spectrum to increase the accuracy of
our estimation. We will show that the resulting estimates capture the
zero-crossings of the CTF in the low-mid frequency range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03455</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03455</id><created>2019-08-09</created><authors><author><keyname>Picheny</keyname><forenames>Michael</forenames></author><author><keyname>T&#xfc;ske</keyname><forenames>Z&#xf3;ltan</forenames></author><author><keyname>Kingsbury</keyname><forenames>Brian</forenames></author><author><keyname>Audhkhasi</keyname><forenames>Kartik</forenames></author><author><keyname>Cui</keyname><forenames>Xiaodong</forenames></author><author><keyname>Saon</keyname><forenames>George</forenames></author></authors><title>Challenging the Boundaries of Speech Recognition: The MALACH Corpus</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for publication at INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been huge progress in speech recognition over the last several
years. Tasks once thought extremely difficult, such as SWITCHBOARD, now
approach levels of human performance. The MALACH corpus (LDC catalog
LDC2012S05), a 375-Hour subset of a large archive of Holocaust testimonies
collected by the Survivors of the Shoah Visual History Foundation, presents
significant challenges to the speech community. The collection consists of
unconstrained, natural speech filled with disfluencies, heavy accents,
age-related coarticulations, un-cued speaker and language switching, and
emotional speech - all still open problems for speech recognition systems.
Transcription is challenging even for skilled human annotators. This paper
proposes that the community place focus on the MALACH corpus to develop speech
recognition systems that are more robust with respect to accents, disfluencies
and emotional speech. To reduce the barrier for entry, a lexicon and training
and testing setups have been created and baseline results using current deep
learning technologies are presented. The metadata has just been released by LDC
(LDC2019S11). It is hoped that this resource will enable the community to build
on top of these baselines so that the extremely important information in these
and related oral histories becomes accessible to a wider audience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03478</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03478</id><created>2019-08-09</created><authors><author><keyname>Zheng</keyname><forenames>Minghui</forenames></author><author><keyname>Chen</keyname><forenames>Zhu</forenames></author><author><keyname>Liang</keyname><forenames>Xiao</forenames></author></authors><title>A Preliminary Study on A Physical Model Oriented Learning Algorithm with
  Application to UAVs</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a preliminary study for an efficient learning algorithm
by reasoning the error from first principle physics to generate learning
signals in near real time. Motivated by iterative learning control (ILC), this
learning algorithm is applied to the feedforward control loop of the unmanned
aerial vehicles (UAVs), enabling the learning from errors made by other UAVs
with different dynamics or flying in different scenarios. This learning
framework improves the data utilization efficiency and learning reliability via
analytically incorporating the physical model mapping, and enhances the
flexibility of the model-based methodology with equipping it with the
self-learning capability. Numerical studies are performed to validate the
proposed learning algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03518</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03518</id><created>2019-07-11</created><authors><author><keyname>Almarashdeh</keyname><forenames>Ibrahim</forenames></author><author><keyname>Alsmadi</keyname><forenames>Mutasem K.</forenames></author><author><keyname>Farag</keyname><forenames>Tamer</forenames></author><author><keyname>Albahussain</keyname><forenames>Abdullah S.</forenames></author><author><keyname>Badawi</keyname><forenames>Usama A</forenames></author><author><keyname>Altuwaijri</keyname><forenames>Njoud</forenames></author><author><keyname>Almaimoni</keyname><forenames>Hala</forenames></author><author><keyname>Asiry</keyname><forenames>Fatima</forenames></author><author><keyname>Alowaid</keyname><forenames>Shahad</forenames></author><author><keyname>Alshabanah</keyname><forenames>Muneerah</forenames></author><author><keyname>Alrajhi</keyname><forenames>Daniah</forenames></author><author><keyname>Fraihet</keyname><forenames>Amirah Al</forenames></author><author><keyname>Jaradat</keyname><forenames>Ghaith</forenames></author></authors><title>Real-Time Elderly Healthcare Monitoring Expert System Using Wireless
  Sensor Network</title><categories>cs.HC cs.CY eess.SP</categories><comments>7 pages,5 figures</comments><journal-ref>International Journal of Applied Engineering Research 2018</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Elderly chronic diseases are the main cause of death in the world, accounting
60% of all death. Because elderly with chronic diseases at the early stages has
no observed symptoms, and then symptoms starts to appear, it is critical to
observe the symptoms as early as possible to avoid any complication. This paper
presents an expert system for an Elderly Health Care (EHC) at elderly home
tailored for the specific needs of Elderly. The proposed EHC aims to develop an
integrated and multidisciplinary method to employ communication technologies
and information for covering real health needs of elderly people, mainly of
people at high risk due to social and geographic isolation in addition to
specific chronic diseases. The proposed EHC provides personalized intervention
plans covering chronic diseases such as (body temperature (BT), blood pressure
(BP), and Heart beat rate (HR)). The processes and architecture of the proposed
EHC are based on the server side and three main clients, one for the elderly
and another two for the nurse and the physicians whom take care of them. The
proposed EHC model is discussed for proving the usefulness and effectiveness of
the expert system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03538</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03538</id><created>2019-08-09</created><updated>2019-09-29</updated><authors><author><keyname>Feng</keyname><forenames>Siyuan</forenames></author><author><keyname>Lee</keyname><forenames>Tan</forenames></author></authors><title>Exploiting Cross-Lingual Speaker and Phonetic Diversity for Unsupervised
  Subword Modeling</title><categories>eess.AS cs.CL</categories><comments>12 pages, 6 figures. Manuscript published in the IEEE/ACM
  Transactions on Audio, Speech and Language Processing (Volume: 27 , Issue: 12
  , Dec. 2019)</comments><doi>10.1109/TASLP.2019.2937953</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research addresses the problem of acoustic modeling of low-resource
languages for which transcribed training data is absent. The goal is to learn
robust frame-level feature representations that can be used to identify and
distinguish subword-level speech units. The proposed feature representations
comprise various types of multilingual bottleneck features (BNFs) that are
obtained via multi-task learning of deep neural networks (MTL-DNN). One of the
key problems is how to acquire high-quality frame labels for untranscribed
training data to facilitate supervised DNN training. It is shown that learning
of robust BNF representations can be achieved by effectively leveraging
transcribed speech data and well-trained automatic speech recognition (ASR)
systems from one or more out-of-domain (resource-rich) languages. Out-of-domain
ASR systems can be applied to perform speaker adaptation with untranscribed
training data of the target language, and to decode the training speech into
frame-level labels for DNN training. It is also found that better frame labels
can be generated by considering temporal dependency in speech when performing
frame clustering. The proposed methods of feature learning are evaluated on the
standard task of unsupervised subword modeling in Track 1 of the ZeroSpeech
2017 Challenge. The best performance achieved by our system is $9.7\%$ in terms
of across-speaker triphone minimal-pair ABX error rate, which is comparable to
the best systems reported recently. Lastly, our investigation reveals that the
closeness between target languages and out-of-domain languages and the amount
of available training data for individual target languages could have
significant impact on the goodness of learned features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03544</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03544</id><created>2019-08-09</created><authors><author><keyname>Abeida</keyname><forenames>Habti</forenames></author><author><keyname>Delmas</keyname><forenames>Jean-Pierre</forenames></author></authors><title>Slepian-Bangs formula and Cramer Rao bound for circular and non-circular
  complex elliptical symmetric distributions</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/LSP.2019.2939714</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is mainly dedicated to an extension of the Slepian-Bangs formula
to non-circular complex elliptical symmetric (NC-CES) distributions, which is
derived from a new stochastic representation theorem. This formula includes the
non-circular complex Gaussian and the circular CES (CCES) distributions. Some
general relations between the Cramer Rao bound (CRB) under CES and Gaussian
distributions are deduced. It is proved in particular that the Gaussian
distribution does not always lead to the largest stochastic CRB (SCRB) as many
authors tend to believe it. Finally a particular attention is paid to the noisy
mixture where closedform expressions for the SCRBs of the parameters of
interest are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03565</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03565</id><created>2019-08-12</created><updated>2019-08-13</updated><authors><author><keyname>Rhatushnyak</keyname><forenames>Alexander</forenames></author><author><keyname>Wassenberg</keyname><forenames>Jan</forenames></author><author><keyname>Sneyers</keyname><forenames>Jon</forenames></author><author><keyname>Alakuijala</keyname><forenames>Jyrki</forenames></author><author><keyname>Vandevenne</keyname><forenames>Lode</forenames></author><author><keyname>Versari</keyname><forenames>Luca</forenames></author><author><keyname>Obryk</keyname><forenames>Robert</forenames></author><author><keyname>Szabadka</keyname><forenames>Zoltan</forenames></author><author><keyname>Kliuchnikov</keyname><forenames>Evgenii</forenames></author><author><keyname>Comsa</keyname><forenames>Iulia-Maria</forenames></author><author><keyname>Potempa</keyname><forenames>Krzysztof</forenames></author><author><keyname>Bruse</keyname><forenames>Martin</forenames></author><author><keyname>Firsching</keyname><forenames>Moritz</forenames></author><author><keyname>Khasanova</keyname><forenames>Renata</forenames></author><author><keyname>van Asseldonk</keyname><forenames>Ruud</forenames></author><author><keyname>Boukortt</keyname><forenames>Sami</forenames></author><author><keyname>Gomez</keyname><forenames>Sebastian</forenames></author><author><keyname>Fischbacher</keyname><forenames>Thomas</forenames></author></authors><title>Committee Draft of JPEG XL Image Coding System</title><categories>eess.IV cs.GR</categories><comments>Royalty-free, open-source reference implementation in Q4 2019. v3
  fixes PDF links and paper size</comments><msc-class>94A08</msc-class><acm-class>I.4.2</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  JPEG XL is a practical approach focused on scalable web distribution and
efficient compression of high-quality images. It provides various benefits
compared to existing image formats: 60% size reduction at equivalent subjective
quality; fast, parallelizable decoding and encoding configurations; features
such as progressive, lossless, animation, and reversible transcoding of
existing JPEG with 22% size reduction; support for high-quality applications
including wide gamut, higher resolution/bit depth/dynamic range, and visually
lossless coding. The JPEG XL architecture is traditional block-transform coding
with upgrades to each component.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03571</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03571</id><created>2019-08-09</created><authors><author><keyname>Wang</keyname><forenames>Hongzhi</forenames></author><author><keyname>Song</keyname><forenames>Yang</forenames></author><author><keyname>Tang</keyname><forenames>Shihan</forenames></author></authors><title>LSTM-based Flow Prediction</title><categories>cs.LG eess.SP stat.ML</categories><comments>8 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a method of prediction on continuous time series variables
from the production or flow -- an LSTM algorithm based on multivariate tuning
-- is proposed. The algorithm improves the traditional LSTM algorithm and
converts the time series data into supervised learning sequences regarding
industrial data's features. The main innovation of this paper consists in
introducing the concepts of periodic measurement and time window in the
industrial prediction problem, especially considering industrial data with time
series characteristics. Experiments using real-world datasets show that the
prediction accuracy is improved, 54.05% higher than that of traditional LSTM
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03573</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03573</id><created>2019-08-09</created><authors><author><keyname>Wildeboer</keyname><forenames>R. R.</forenames></author><author><keyname>van Sloun</keyname><forenames>R. J. G.</forenames></author><author><keyname>Mannaerts</keyname><forenames>C. K.</forenames></author><author><keyname>Salomon</keyname><forenames>G.</forenames></author><author><keyname>Wijkstra</keyname><forenames>H.</forenames></author><author><keyname>Mischi</keyname><forenames>M.</forenames></author></authors><title>Synthetic Elastography using B-mode Ultrasound through a Deep
  Fully-Convolutional Neural Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shear-wave elastography (SWE) permits local estimation of tissue elasticity,
an important imaging marker in biomedicine. This recently-developed, advanced
technique assesses the speed of a laterally-travelling shear wave after an
acoustic radiation force &quot;push&quot; to estimate local Young's moduli in an
operator-independent fashion. In this work, we show how synthetic SWE (sSWE)
images can be generated based on conventional B-mode imaging through deep
learning. Using side-by-side-view B-mode/SWE images collected in 50 patients
with prostate cancer, we show that sSWE images with a pixel-wise mean absolute
error of 4.8 kPa with regard to the original SWE can be generated.
Visualization of high-level feature levels through t-Distributed Stochastic
Neighbor Embedding reveals a high degree of overlap between data from different
scanners. Also qualitatively, sSWE results seem generalisable to single B-mode
acquisitions and other scanners. In the future, we envision sSWE as a reliable
elasticity-related tissue typing strategy that is solely based on B-mode
ultrasound acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03588</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03588</id><created>2019-08-09</created><authors><author><keyname>Sharf</keyname><forenames>Miel</forenames></author><author><keyname>Zelazo</keyname><forenames>Daniel</forenames></author></authors><title>A Data-Driven and Model-Based Approach to Fault Detection and Isolation
  in Networked Systems</title><categories>eess.SY cs.SY math.OC</categories><comments>16 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fault detection and isolation is a field of engineering dealing with
designing on-line protocols for systems that allow one to identify the
existence of faults, pinpoint their exact location, and overcome them. We
consider the case of multi-agent systems, where faults correspond to the
disappearance of links in the underlying graph, simulating a communication
failure between the corresponding agents. We study the case in which the agents
and controllers are maximal equilibrium-independent passive (MEIP), and use the
known connection between steady-states of these multi-agent systems and network
optimization theory. We first study asymptotic methods of differentiating the
faultless system from its faulty versions by studying their steady-state
outputs. We explain how to apply the asymptotic differentiation to fault
detection and isolation, with graph-theoretic guarantees on the number of
faults that can be isolated, assuming the existence of a &quot;convergence assertion
protocol&quot;, a data-driven method of asserting that a multi-agent system
converges to a conjectured limit. We then construct two data-driven model-based
convergence assertion protocols. We demonstrate our results by case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03608</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03608</id><created>2019-08-07</created><updated>2019-08-14</updated><authors><author><keyname>Calvo-Zaragoza</keyname><forenames>Jorge</forenames></author><author><keyname>Haji&#x10d;</keyname><forenames>Jan</forenames><suffix>Jr.</suffix></author><author><keyname>Pacha</keyname><forenames>Alexander</forenames></author></authors><title>Understanding Optical Music Recognition</title><categories>cs.CV cs.AI cs.IR cs.SD eess.AS</categories><comments>Preprint version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For over 50 years, researchers have been trying to teach computers to read
music notation, referred to as Optical Music Recognition (OMR). However, this
field is still difficult to access for new researchers, especially those
without a significant musical background: few introductory materials are
available, and furthermore the field has struggled with defining itself and
building a shared terminology. In this tutorial, we address these shortcomings
by (1) providing a robust definition of OMR and its relationship to related
fields, (2) analyzing how OMR inverts the music encoding process to recover the
musical notation and the musical semantics from documents, (3) proposing a
taxonomy of OMR, with most notably a novel taxonomy of applications.
Additionally, we discuss how deep learning affects modern OMR research, as
opposed to the traditional pipeline. Based on this work, the reader should be
able to attain a basic understanding of OMR: its objectives, its inherent
structure, its relationship to other fields, the state of the art, and the
research opportunities it affords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03609</identifier>
 <datestamp>2019-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03609</id><created>2019-08-09</created><authors><author><keyname>Bayev</keyname><forenames>Andrey</forenames></author><author><keyname>Gartseev</keyname><forenames>Ilya</forenames></author><author><keyname>Chistyakov</keyname><forenames>Ivan</forenames></author><author><keyname>Nikulin</keyname><forenames>Alexey</forenames></author><author><keyname>Derevyankin</keyname><forenames>Alexey</forenames></author><author><keyname>Pikhletsky</keyname><forenames>Mikhail</forenames></author></authors><title>RuDaCoP: The Dataset for Smartphone-based Intellectual Pedestrian
  Navigation</title><categories>eess.SY cs.LG cs.SY</categories><doi>10.1109/IPIN.2019.8911823</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the large and diverse dataset for development of
smartphone-based pedestrian navigation algorithms. This dataset consists of
about 1200 sets of inertial measurements from sensors of several smartphones.
The measurements are collected while walking through different trajectories up
to 10 minutes long. The data are accompanied by the high accuracy ground truth
collected with two foot-mounted inertial measurement units and post-processed
by the presented algorithms. The dataset suits both for training of
intellectual pedestrian navigation algorithms based on learning techniques and
for development of pedestrian navigation algorithms based on classical
approaches. The dataset is accessible at http://gartseev.ru/projects/ipin2019.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03620</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03620</id><created>2019-08-09</created><updated>2019-12-23</updated><authors><author><keyname>Swischuk</keyname><forenames>Renee</forenames></author><author><keyname>Kramer</keyname><forenames>Boris</forenames></author><author><keyname>Huang</keyname><forenames>Cheng</forenames></author><author><keyname>Willcox</keyname><forenames>Karen</forenames></author></authors><title>Learning physics-based reduced-order models for a single-injector
  combustion process</title><categories>physics.comp-ph cs.LG cs.SY eess.SY math.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a physics-based data-driven method to learn predictive
reduced-order models (ROMs) from high-fidelity simulations, and illustrates it
in the challenging context of a single-injector combustion process. The method
combines the perspectives of model reduction and machine learning. Model
reduction brings in the physics of the problem, constraining the ROM
predictions to lie on a subspace defined by the governing equations. This is
achieved by defining the ROM in proper orthogonal decomposition (POD)
coordinates, which embed the rich physics information contained in solution
snapshots of a high-fidelity computational fluid dynamics (CFD) model. The
machine learning perspective brings the flexibility to use transformed physical
variables to define the POD basis. This is in contrast to traditional model
reduction approaches that are constrained to use the physical variables of the
high-fidelity code. Combining the two perspectives, the approach identifies a
set of transformed physical variables that expose quadratic structure in the
combustion governing equations and learns a quadratic ROM from transformed
snapshot data. This learning does not require access to the high-fidelity model
implementation. Numerical experiments show that the ROM accurately predicts
temperature, pressure, velocity, species concentrations, and the limit-cycle
amplitude, with speedups of more than five orders of magnitude over
high-fidelity models. Our ROM simulation is shown to be predictive 200% past
the training interval. Moreover, ROM-predicted pressure traces accurately match
the phase of the pressure signal and yield good approximations of the
limit-cycle amplitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03625</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03625</id><created>2019-08-02</created><authors><author><keyname>Kleis</keyname><forenames>Sebastian</forenames></author><author><keyname>Rueckmann</keyname><forenames>Max</forenames></author><author><keyname>Schaeffer</keyname><forenames>Christian G.</forenames></author></authors><title>Continuous-Variable Quantum Key Distribution with a Real Local
  Oscillator and without Auxiliary Signals</title><categories>quant-ph cs.CR cs.LG eess.SP physics.optics</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continuous-variable quantum key distribution (CV-QKD) is realized with
coherent detection and is therefore very suitable for a cost-efficient
implementation. The major challenge in CV-QKD is mitigation of laser phase
noise at a signal to noise ratio of much less than 0 dB. So far, this has been
achieved with a remote local oscillator or with auxiliary signals. For the
first time, we experimentally demonstrate that CV-QKD can be performed with a
real local oscillator and without auxiliary signals which is achieved by
applying Machine Learning methods. It is shown that, with the most established
discrete modulation protocol, the experimental system works down to a quantum
channel signal to noise ratio of -19.1 dB. The performance of the experimental
system allows CV-QKD at a key rate of 9.2 Mbit/s over a fiber distance of 26
km. After remote local oscillator and auxiliary signal aided CV-QKD, this could
mark a starting point for a third generation of CV-QKD systems that are even
more attractive for a wide implementation because they are almost identical to
standard coherent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03631</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03631</id><created>2019-08-09</created><authors><author><keyname>Liu</keyname><forenames>Jerry</forenames></author><author><keyname>Wang</keyname><forenames>Shenlong</forenames></author><author><keyname>Urtasun</keyname><forenames>Raquel</forenames></author></authors><title>DSIC: Deep Stereo Image Compression</title><categories>eess.IV cs.CV</categories><comments>Accepted at International Conference on Computer Vision 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we tackle the problem of stereo image compression, and leverage
the fact that the two images have overlapping fields of view to further
compress the representations. Our approach leverages state-of-the-art
single-image compression autoencoders and enhances the compression with novel
parametric skip functions to feed fully differentiable, disparity-warped
features at all levels to the encoder/decoder of the second image. Moreover, we
model the probabilistic dependence between the image codes using a conditional
entropy model. Our experiments show an impressive 30 - 50% reduction in the
second image bitrate at low bitrates compared to deep single-image compression,
and a 10 - 20% reduction at higher bitrates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03632</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03632</id><created>2019-08-09</created><authors><author><keyname>Aloufi</keyname><forenames>Ranya</forenames></author><author><keyname>Haddadi</keyname><forenames>Hamed</forenames></author><author><keyname>Boyle</keyname><forenames>David</forenames></author></authors><title>Emotionless: Privacy-Preserving Speech Analysis for Voice Assistants</title><categories>cs.CR cs.LG cs.SD eess.AS stat.ML</categories><comments>5 pages, 4 figures, privacy Preserving Machine Learning Workshop, CCS
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice-enabled interactions provide more human-like experiences in many
popular IoT systems. Cloud-based speech analysis services extract useful
information from voice input using speech recognition techniques. The voice
signal is a rich resource that discloses several possible states of a speaker,
such as emotional state, confidence and stress levels, physical condition, age,
gender, and personal traits. Service providers can build a very accurate
profile of a user's demographic category, personal preferences, and may
compromise privacy. To address this problem, a privacy-preserving intermediate
layer between users and cloud services is proposed to sanitize the voice input.
It aims to maintain utility while preserving user privacy. It achieves this by
collecting real time speech data and analyzes the signal to ensure privacy
protection prior to sharing of this data with services providers. Precisely,
the sensitive representations are extracted from the raw signal by using
transformation functions and then wrapped it via voice conversion technology.
Experimental evaluation based on emotion recognition to assess the efficacy of
the proposed method shows that identification of sensitive emotional state of
the speaker is reduced by ~96 %.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03670</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03670</id><created>2019-08-09</created><authors><author><keyname>Wang</keyname><forenames>Yongxing</forenames></author><author><keyname>Bi</keyname><forenames>Jun</forenames></author></authors><title>Optimal charging guidance strategies for electric vehicles by
  considering dynamic charging requests in a time-varying road network</title><categories>eess.SY cs.SY</categories><comments>33 pages,11 figures,5 tables, journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electric vehicles (EVs) have enjoyed increasing adoption because of the
global concerns about the petroleum dependence and greenhouse gas emissions.
However, their limited driving range fosters the occurrence of charging
requests deriving from EV drivers in urban road networks, which have
significant uncertain characteristic from time dimension in the real-world
situation. To tackle the challenge brought by the dynamic charging requests,
this study is devoted to proposing optimal strategies to provide guidance for
EV charging. The time-varying characteristic of road network is further
involved in the problem formulation. Based on the charging request information,
we propose two charging guidance strategies from different perspectives. One of
the strategies considers the travel demands of EV drivers and uses the driving
distance as the optimization criterion. In contrast, the other strategy focuses
on the impacts of EV number on the charging station operation and service
satisfaction. The reachable charging stations with minimum vehicle number are
selected as the optimal ones. More importantly, both the strategies have the
ability to ensure the reachability of selected charging stations in a
time-varying road network. In addition, we conduct simulation examples to
investigate the performance of the proposed charging guidance strategies.
Besides, the insights and recommendations on application scenarios of the
strategies are introduced according to the simulation results under various
parameter scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03678</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03678</id><created>2019-08-09</created><authors><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Interference Exploitation 1-Bit Massive MIMO Precoding: A Partial
  Branch-and-Bound Solution with Near-Optimal Performance</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on 1-bit precoding approaches for downlink massive
multiple-input multiple-output (MIMO) systems, where we exploit the concept of
constructive interference (CI). For both PSK and QAM signaling, we firstly
formulate the optimization problem that maximizes the CI effect subject to the
requirement of the 1-bit transmit signals. We then mathematically prove that,
when employing the CI formulation and relaxing the 1-bit constraint, the
majority of the transmit signals already satisfy the 1-bit formulation.
Building upon this important observation, we propose a 1-bit precoding approach
that further improves the performance of the conventional 1-bit CI precoding
via a partial branch-and-bound (P-BB) process, where the BB procedure is
performed only for the entries that do not comply with the 1-bit requirement.
This operation allows a significant complexity reduction compared to the
fully-BB (F-BB) process, and enables the BB framework to be applicable to the
complex massive MIMO scenarios. We further develop an alternative 1-bit scheme
through an `Ordered Partial Sequential Update' (OPSU) process that allows an
additional complexity reduction. Numerical results show that both proposed
1-bit precoding methods exhibit a significant signal-to-noise ratio (SNR) gain
for the error rate performance, especially for higher-order modulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03679</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03679</id><created>2019-08-09</created><authors><author><keyname>Caliva</keyname><forenames>Francesco</forenames></author><author><keyname>Iriondo</keyname><forenames>Claudia</forenames></author><author><keyname>Martinez</keyname><forenames>Alejandro Morales</forenames></author><author><keyname>Majumdar</keyname><forenames>Sharmila</forenames></author><author><keyname>Pedoia</keyname><forenames>Valentina</forenames></author></authors><title>Distance Map Loss Penalty Term for Semantic Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>Medical Imaging with Deep Learning (MIDL2019) Conference
  [arXiv:1907.08612], Extended Abstract</comments><report-no>MIDL/2019/ExtendedAbstract/B1eIcvS45V</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Convolutional neural networks for semantic segmentation suffer from low
performance at object boundaries. In medical imaging, accurate representation
of tissue surfaces and volumes is important for tracking of disease biomarkers
such as tissue morphology and shape features. In this work, we propose a novel
distance map derived loss penalty term for semantic segmentation. We propose to
use distance maps, derived from ground truth masks, to create a penalty term,
guiding the network's focus towards hard-to-segment boundary regions. We
investigate the effects of this penalizing factor against cross-entropy, Dice,
and focal loss, among others, evaluating performance on a 3D MRI bone
segmentation task from the publicly available Osteoarthritis Initiative
dataset. We observe a significant improvement in the quality of segmentation,
with better shape preservation at bone boundaries and areas affected by partial
volume. We ultimately aim to use our loss penalty term to improve the
extraction of shape biomarkers and derive metrics to quantitatively evaluate
the preservation of shape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03693</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03693</id><created>2019-08-10</created><updated>2019-08-26</updated><authors><author><keyname>Imran</keyname><forenames>Abdullah-Al-Zubaer</forenames></author><author><keyname>Terzopoulos</keyname><forenames>Demetri</forenames></author></authors><title>Semi-Supervised Multi-Task Learning With Chest X-Ray Images</title><categories>eess.IV cs.CV</categories><comments>Accepted to Machine Learning in Medical Imaging (MLMI 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discriminative models that require full supervision are inefficacious in the
medical imaging domain when large labeled datasets are unavailable. By
contrast, generative modeling---i.e., learning data generation and
classification---facilitates semi-supervised training with limited labeled
data. Moreover, generative modeling can be advantageous in accomplishing
multiple objectives for better generalization. We propose a novel multi-task
learning model for jointly learning a classifier and a segmentor, from chest
X-ray images, through semi-supervised learning. In addition, we propose a new
loss function that combines absolute KL divergence with Tversky loss (KLTV) to
yield faster convergence and better segmentation performance. Based on our
experimental results using a novel segmentation model, an Adversarial Pyramid
Progressive Attention U-Net (APPAU-Net), we hypothesize that KLTV can be more
effective for generalizing multi-tasking models while being competitive in
segmentation-only tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03696</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03696</id><created>2019-08-10</created><authors><author><keyname>Lonhus</keyname><forenames>Kirill</forenames></author><author><keyname>Rychtarikova</keyname><forenames>Renata</forenames></author><author><keyname>Platonova</keyname><forenames>Ganna</forenames></author><author><keyname>Stys</keyname><forenames>Dalibor</forenames></author></authors><title>Quasi-spectral characterization of intracellular regions in bright-field
  light microscopy images</title><categories>eess.IV physics.optics</categories><comments>18 pages, 5 figures, 1 supplementary pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Investigation of cell structure is hardly imaginable without bright-field
microscopy. Numerous modifications such as depth-wise scanning or
videoenhancement makes this method being state-of-the-art. This raises a
question what maximal information content can be extracted from ordinary (but
well acquired) bright-field images in nearly model-free way. Here we introduce
a method of a physically correct extraction of features for each pixel when
these features resemble a transparency spectrum. The method is compatible with
existent, ordinary bright-field microscopes and requires mathematically
sophisticated data processing. Dimensionality reduction and unsupervised
clustering of the spectra yield reasonable semantic segmentation of cells
without any a priori information about their structures. Despite the lack of
reference data (to strictly prove that the proposed feature vectors coincide
with transparency) we believe that this method is the right approach to an
intracellular (semi)quantitative and qualitative chemical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03734</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03734</id><created>2019-08-10</created><authors><author><keyname>Pala</keyname><forenames>Mythili Sharan</forenames></author><author><keyname>Laxminarayana</keyname><forenames>Parayitam</forenames></author><author><keyname>Ramana</keyname><forenames>A. V.</forenames></author></authors><title>Unsupervised Stemming based Language Model for Telugu Broadcast News
  Transcription</title><categories>cs.CL eess.AS</categories><comments>first draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Indian Languages , native speakers are able to understand new words formed
by either combining or modifying root words with tense and / or gender. Due to
data insufficiency, Automatic Speech Recognition system (ASR) may not
accommodate all the words in the language model irrespective of the size of the
text corpus. It also becomes computationally challenging if the volume of the
data increases exponentially due to morphological changes to the root word. In
this paper a new unsupervised method is proposed for a Indian language: Telugu,
based on the unsupervised method for Hindi, to generate the Out of Vocabulary
(OOV) words in the language model. By using techniques like smoothing and
interpolation of pre-processed data with supervised and unsupervised stemming,
different issues in language model for Indian language: Telugu has been
addressed. We observe that the smoothing techniques Witten-Bell and Kneser-Ney
perform well when compared to other techniques on pre-processed data from
supervised learning. The ASRs accuracy is improved by 0.76% and 0.94% with
supervised and unsupervised stemming respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03735</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03735</id><created>2019-08-10</created><authors><author><keyname>Zhao</keyname><forenames>Bin</forenames></author><author><keyname>Wu</keyname><forenames>Hong</forenames></author><author><keyname>Liu</keyname><forenames>Guohua</forenames></author><author><keyname>Cao</keyname><forenames>Chen</forenames></author><author><keyname>Jin</keyname><forenames>Song</forenames></author><author><keyname>Liu</keyname><forenames>Zhiyang</forenames></author><author><keyname>Ding</keyname><forenames>Shuxue</forenames></author></authors><title>Automatic acute ischemic stroke lesion segmentation using
  semi-supervised learning</title><categories>eess.IV cs.CV cs.LG</categories><comments>submitted to Neuroimage: Clinical</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ischemic stroke is a common disease in the elderly population, which can
cause long-term disability and even death. However, the time window for
treatment of ischemic stroke in its acute stage is very short. To fast localize
and quantitively evaluate the acute ischemic stroke (AIS) lesions, many
deep-learning-based lesion segmentation methods have been proposed in the
literature, where a deep convolutional neural network (CNN) was trained on
hundreds of fully labeled subjects with accurate annotations of AIS lesions.
Despite that high segmentation accuracy can be achieved, the accurate labels
should be annotated by experienced clinicians, and it is therefore very
time-consuming to obtain a large number of fully labeled subjects. In this
paper, we propose a semi-supervised method to automatically segment AIS lesions
in diffusion weighted images and apparent diffusion coefficient maps. By using
a large number of weakly labeled subjects and a small number of fully labeled
subjects, our proposed method is able to accurately detect and segment the AIS
lesions. In particular, our proposed method consists of three parts: 1) a
double-path classification net (DPC-Net) trained in a weakly-supervised way is
used to detect the suspicious regions of AIS lesions; 2) a pixel-level K-Means
clustering algorithm is used to identify the hyperintensive regions on the
DWIs; and 3) a region-growing algorithm combines the outputs of the DPC-Net and
the K-Means to obtain the final precise lesion segmentation. In our experiment,
we use 460 weakly labeled subjects and 15 fully labeled subjects to train and
fine-tune the proposed method. By evaluating on a clinical dataset with 150
fully labeled subjects, our proposed method achieves a mean dice coefficient of
0.639, and a lesion-wise F1 score of 0.799.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03736</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03736</id><created>2019-08-10</created><updated>2019-12-10</updated><authors><author><keyname>L&#xf6;ser</keyname><forenames>Inga</forenames></author><author><keyname>Sampathirao</keyname><forenames>Ajay Kumar</forenames></author><author><keyname>Hofmann</keyname><forenames>Steffen</forenames></author><author><keyname>Raisch</keyname><forenames>Joerge</forenames></author></authors><title>Fallback Strategies in Operation Control of Microgrids with
  Communication Failures</title><categories>eess.SY cs.SY</categories><comments>accepted for publication in CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a model predictive control (MPC)-based energy management
system to address communication failures in an islanded microgrid (MG). The
energy management system relies on a communication network to monitor and
control power generation in the units. A communication failure to a unit
inhibits the ability of the MPC to change the power of the unit. However, this
unit is electrically connected to the network and ignoring this aspect could
have adverse effect in the operation of the microgrid. Therefore, this paper
considers an MPC design that includes the electrical connectivity of the unit
during communication failures. This paper also highlights the benefit of
including the lower layer control behaviour of the MG to withstand
communication failures. The proposed approaches are validated with a case
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03753</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03753</id><created>2019-08-10</created><authors><author><keyname>Davydova</keyname><forenames>Nadezhda</forenames></author><author><keyname>Shchetinin</keyname><forenames>Dmitry</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author></authors><title>Optimization-based Settingless Algorithm Combining Protection and Fault
  Identification</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The demand for faster protection algorithms is growing due to the
increasingly faster dynamics in the system. The majority of existing algorithms
require empirically selected set-points, which may reduce sensitivity to
internal faults and cause security problems. This paper addresses these
challenges by proposing a settingless time-domain unit protection algorithm for
medium-voltage lines. The main idea of the algorithm is to identify which model
of a protected line, i.e. healthy or with an internal fault, is more consistent
with the input measurements. This is done by solving a number of small-scale
convex optimization problems, which at the same time determine the
characteristics of an internal fault that best fit the measurements. Thus, the
proposed algorithm merges protection, fault location and fault type
identification functionalities. The algorithm's performance is extensively
tested on a grid model in MATLAB Simulink for different types of generation and
grid operating conditions. The results demonstrate that the algorithm can
operate quickly and reliably, and accurately estimate fault characteristics
even in the presence of noisy measurements and uncertain line parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03809</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03809</id><created>2019-08-10</created><authors><author><keyname>Howe</keyname><forenames>Jonathan</forenames></author><author><keyname>Pula</keyname><forenames>Kyle</forenames></author><author><keyname>Reite</keyname><forenames>Aaron A.</forenames></author></authors><title>Conditional Generative Adversarial Networks for Data Augmentation and
  Adaptation in Remotely Sensed Imagery</title><categories>cs.CV cs.LG eess.IV</categories><doi>10.1117/12.2529586</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The difficulty in obtaining labeled data relevant to a given task is among
the most common and well-known practical obstacles to applying deep learning
techniques to new or even slightly modified domains. The data volumes required
by the current generation of supervised learning algorithms typically far
exceed what a human needs to learn and complete a given task. We investigate
ways to expand a given labeled corpus of remote sensed imagery into a larger
corpus using Generative Adversarial Networks (GANs). We then measure how these
additional synthetic data affect supervised machine learning performance on an
object detection task.
  Our data driven strategy is to train GANs to (1) generate synthetic
segmentation masks and (2) generate plausible synthetic remote sensing imagery
corresponding to these segmentation masks. Run sequentially, these GANs allow
the generation of synthetic remote sensing imagery complete with segmentation
labels. We apply this strategy to the data set from ISPRS' 2D Semantic Labeling
Contest - Potsdam, with a follow on vehicle detection task. We find that in
scenarios with limited training data, augmenting the available data with such
synthetically generated data can improve detector performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03823</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03823</id><created>2019-08-10</created><authors><author><keyname>Deng</keyname><forenames>Xianda</forenames></author><author><keyname>Li</keyname><forenames>Hongyu</forenames></author><author><keyname>Yu</keyname><forenames>Wenpeng</forenames></author><author><keyname>Weikang</keyname><forenames>Wang</forenames></author><author><keyname>Liu</keyname><forenames>Yilu</forenames></author></authors><title>Frequency Observations and Statistic Analysis of Worldwide Main Power
  Grids Using FNET/GridEye</title><categories>eess.SY cs.SY</categories><comments>5 pages, 8 figures. 2019 IEEE Power &amp; Energy Society General Meeting,
  Atlanta, GA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing renewable energy sources, concerns about how renewable
energy sources impact frequency have risen. There are few reports regarding
power frequency status in worldwide main power grids and what are differences
of frequency status between power grids in mainland and island. FNET/GridEye, a
wide-area measurement system collecting frequency and phase angle data at the
distribution level, provides an opportunity to observe and study the power
frequency in different power grids over the world. In this paper, 13 different
power grids, spreading at different mainland and islands over the world, are
observed and compared. A more detail statistical analysis was conducted for
typical power grids in three different places, e.g., U.S Eastern
Interconnection (EI), Egypt, and Japan. The probability functions of frequency
based on the measured data are calculated. The distributions of frequency in
different power grids fall into two categories, e.g., single-peak distribution
and multi-peak distribution. Furthermore, a meaningful insight that the
single-peak distributions of the frequency almost follow the normal
distribution is found. The frequency observations and statistic analysis of
worldwide main power grids using FNET/GridEye could help the power system
operators understand the frequency statistical characteristic more deeply.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03835</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03835</id><created>2019-08-10</created><authors><author><keyname>Gong</keyname><forenames>Xinyu</forenames></author><author><keyname>Chang</keyname><forenames>Shiyu</forenames></author><author><keyname>Jiang</keyname><forenames>Yifan</forenames></author><author><keyname>Wang</keyname><forenames>Zhangyang</forenames></author></authors><title>AutoGAN: Neural Architecture Search for Generative Adversarial Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>accepted by ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural architecture search (NAS) has witnessed prevailing success in image
classification and (very recently) segmentation tasks. In this paper, we
present the first preliminary study on introducing the NAS algorithm to
generative adversarial networks (GANs), dubbed AutoGAN. The marriage of NAS and
GANs faces its unique challenges. We define the search space for the generator
architectural variations and use an RNN controller to guide the search, with
parameter sharing and dynamic-resetting to accelerate the process. Inception
score is adopted as the reward, and a multi-level search strategy is introduced
to perform NAS in a progressive way. Experiments validate the effectiveness of
AutoGAN on the task of unconditional image generation. Specifically, our
discovered architectures achieve highly competitive performance compared to
current state-of-the-art hand-crafted GANs, e.g., setting new state-of-the-art
FID scores of 12.42 on CIFAR-10, and 31.01 on STL-10, respectively. We also
conclude with a discussion of the current limitations and future potential of
AutoGAN. The code is available at https://github.com/TAMU-VITA/AutoGAN
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03858</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03858</id><created>2019-08-11</created><authors><author><keyname>Zhou</keyname><forenames>Wenzhong</forenames></author><author><keyname>Du</keyname><forenames>Huiqian</forenames></author><author><keyname>Mei</keyname><forenames>Wenbo</forenames></author><author><keyname>Fang</keyname><forenames>Liping</forenames></author></authors><title>Efficient Structurally-Strengthened Generative Adversarial Network for
  MRI Reconstruction</title><categories>eess.IV cs.CV</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing based magnetic resonance imaging (CS-MRI) provides an
efficient way to reduce scanning time of MRI. Recently deep learning has been
introduced into CS-MRI to further improve the image quality and shorten
reconstruction time. In this paper, we propose an efficient structurally
strengthened Generative Adversarial Network, termed ESSGAN, for reconstructing
MR images from highly under-sampled k-space data. ESSGAN consists of a
structurally strengthened generator (SG) and a discriminator. In SG, we
introduce strengthened connections (SCs) to improve the utilization of the
feature maps between the proposed strengthened convolutional autoencoders
(SCAEs), where each SCAE is a variant of a typical convolutional autoencoder.
In addition, we creatively introduce a residual in residual block (RIRB) to SG.
RIRB increases the depth of SG, thus enhances feature expression ability of SG.
Moreover, it can give the encoder blocks and the decoder blocks richer texture
features. To further reduce artifacts and preserve more image details, we
introduce an enhanced structural loss to SG. ESSGAN can provide higher image
quality with less model parameters than the state-of-the-art deep
learning-based methods at different undersampling rates of different
subsampling masks, and reconstruct a 256*256 MR image in tens of milliseconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03888</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03888</id><created>2019-08-11</created><authors><author><keyname>Li</keyname><forenames>Duo</forenames></author><author><keyname>Zhou</keyname><forenames>Aojun</forenames></author><author><keyname>Yao</keyname><forenames>Anbang</forenames></author></authors><title>HBONet: Harmonious Bottleneck on Two Orthogonal Dimensions</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by ICCV 2019. Code and pretrained models are available at
  https://github.com/d-li14/HBONet</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MobileNets, a class of top-performing convolutional neural network
architectures in terms of accuracy and efficiency trade-off, are increasingly
used in many resourceaware vision applications. In this paper, we present
Harmonious Bottleneck on two Orthogonal dimensions (HBO), a novel architecture
unit, specially tailored to boost the accuracy of extremely lightweight
MobileNets at the level of less than 40 MFLOPs. Unlike existing bottleneck
designs that mainly focus on exploring the interdependencies among the channels
of either groupwise or depthwise convolutional features, our HBO improves
bottleneck representation while maintaining similar complexity via jointly
encoding the feature interdependencies across both spatial and channel
dimensions. It has two reciprocal components, namely spatial
contraction-expansion and channel expansion-contraction, nested in a
bilaterally symmetric structure. The combination of two interdependent
transformations performing on orthogonal dimensions of feature maps enhances
the representation and generalization ability of our proposed module,
guaranteeing compelling performance with limited computational resource and
power. By replacing the original bottlenecks in MobileNetV2 backbone with HBO
modules, we construct HBONets which are evaluated on ImageNet classification,
PASCAL VOC object detection and Market-1501 person re-identification. Extensive
experiments show that with the severe constraint of computational budget our
models outperform MobileNetV2 counterparts by remarkable margins of at most
6.6%, 6.3% and 5.0% on the above benchmarks respectively. Code and pretrained
models are available at https://github.com/d-li14/HBONet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03904</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03904</id><created>2019-08-11</created><authors><author><keyname>Sadiq</keyname><forenames>Rizwan</forenames></author><author><keyname>AsadiAbadi</keyname><forenames>Sasan</forenames></author><author><keyname>Erzin</keyname><forenames>Engin</forenames></author></authors><title>Emotion Dependent Facial Animation from Affective Speech</title><categories>eess.AS cs.MM cs.SD</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In human-to-computer interaction, facial animation in synchrony with
affective speech can deliver more naturalistic conversational agents. In this
paper, we present a two-stage deep learning approach for affective speech
driven facial shape animation. In the first stage, we classify affective speech
into seven emotion categories. In the second stage, we train separate deep
estimators within each emotion category to synthesize facial shape from the
affective speech. Objective and subjective evaluations are performed over the
SAVEE dataset. The proposed emotion dependent facial shape model performs
better in terms of the Mean Squared Error (MSE) loss and in generating the
landmark animations, as compared to training a universal model regardless of
the emotion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03913</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03913</id><created>2019-08-11</created><authors><author><keyname>Pillonetto</keyname><forenames>Gianluigi</forenames></author><author><keyname>Chiuso</keyname><forenames>Alessandro</forenames></author><author><keyname>De Nicolao</keyname><forenames>Giuseppe</forenames></author></authors><title>Stable spline identification of linear systems under missing data</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A different route to identification of time-invariant linear systems has been
recently proposed which does not require committing to a specific parametric
model structure. Impulse responses are described in a nonparametric Bayesian
framework as zero-mean Gaussian processes. Their covariances are given by the
so-called stable spline kernels encoding information on regularity and BIBO
stability. In this paper, we demonstrate that these kernels also lead to a new
family of radial basis functions kernels suitable to model system components
subject to disturbances given by filtered white noise. This novel class, in
cooperation with the stable spline kernels, paves the way to a new approach to
solve missing data problems in both discrete and continuous-time settings.
Numerical experiments show that the new technique may return models more
predictive than those obtained by standard parametric Prediction Error Methods,
also when these latter exploit the full data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03929</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03929</id><created>2019-08-11</created><authors><author><keyname>Matsui</keyname><forenames>Shoma</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author></authors><title>Secret Securing with Multiple Protections and Minimum Costs</title><categories>eess.SY cs.SY</categories><comments>8 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a security problem of protecting secrets with multiple
protections and minimum costs. The target system is modeled as a discrete-event
system (DES) in which a few states are secrets, and there are multiple subsets
of protectable events with different cost levels. We formulate the problem as
to ensure that every string that reaches a secret state (from the initial
state) contains a specified number of protectable events and the highest cost
level of these events is minimum. We first provide a necessary and sufficient
condition under which this security problem is solvable, and then propose an
algorithm to solve the problem based on the supervisory control theory of DES.
The resulting solution is a protection policy which specifies at each state
which events to protect and the highest cost level of protecting these events
is minimum. Finally, we demonstrate the effectiveness of our solution with a
network security example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03938</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03938</id><created>2019-08-11</created><updated>2019-10-24</updated><authors><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author><author><keyname>Bopardikar</keyname><forenames>Shaunak D.</forenames></author><author><keyname>Srivastava</keyname><forenames>Vaibhav</forenames></author></authors><title>Incentivizing Collaboration in Heterogeneous Teams via Common-Pool
  Resource Games</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a team of heterogeneous agents that is collectively responsible
for servicing and subsequently reviewing a stream of homogeneous tasks. Each
agent (autonomous system or human operator) has an associated mean service time
and mean review time for servicing and reviewing the tasks, respectively, which
are based on their expertise and skill-sets. Agents receive a utility based on
the rates at which they service and review the tasks. The team objective is to
collaboratively maximize the number of &quot;serviced and reviewed&quot; tasks. We
formulate a Common-Pool Resource (CPR) game and design utility functions to
incentivize collaboration among heterogeneous team-members in a decentralized
manner. We show that there exists a unique Pure Nash Equilibrium (PNE) for the
CPR game. We characterize the structure of this PNE and study the effect of
heterogeneity which we characterize by the variation in the ratio of mean
review time and mean service time among the agents. We show that the CPR game
is a best response potential game for which both sequential best response
dynamics and simultaneous best reply dynamics converge to the PNE. Finally, we
numerically illustrate different measures of inefficiency for the PNE such as
the price of anarchy, ratio of total review admission rate and ratio of
latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03958</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03958</id><created>2019-08-11</created><updated>2019-09-18</updated><authors><author><keyname>Kumar</keyname><forenames>Nishant</forenames></author><author><keyname>Hoffmann</keyname><forenames>Nico</forenames></author><author><keyname>Oelschl&#xe4;gel</keyname><forenames>Martin</forenames></author><author><keyname>Koch</keyname><forenames>Edmund</forenames></author><author><keyname>Kirsch</keyname><forenames>Matthias</forenames></author><author><keyname>Gumhold</keyname><forenames>Stefan</forenames></author></authors><title>Structural Similarity based Anatomical and Functional Brain Imaging
  Fusion</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted at MICCAI-MBIA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal medical image fusion helps in combining contrasting features from
two or more input imaging modalities to represent fused information in a single
image. One of the pivotal clinical applications of medical image fusion is the
merging of anatomical and functional modalities for fast diagnosis of malignant
tissues. In this paper, we present a novel end-to-end unsupervised
learning-based Convolutional Neural Network (CNN) for fusing the high and low
frequency components of MRI-PET grayscale image pairs, publicly available at
ADNI, by exploiting Structural Similarity Index (SSIM) as the loss function
during training. We then apply color coding for the visualization of the fused
image by quantifying the contribution of each input image in terms of the
partial derivatives of the fused image. We find that our fusion and
visualization approach results in better visual perception of the fused image,
while also comparing favorably to previous methods when applying various
quantitative assessment metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03965</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03965</id><created>2019-08-11</created><updated>2019-08-13</updated><authors><author><keyname>Zhao</keyname><forenames>Jun</forenames></author></authors><title>Optimizations with Intelligent Reflecting Surfaces (IRSs) in 6G Wireless
  Networks: Power Control, Quality of Service, Max-Min Fair Beamforming for
  Unicast, Broadcast, and Multicast with Multi-antenna Mobile Users and
  Multiple IRSs</title><categories>cs.IT eess.SP math.IT</categories><comments>21 pages. Comments are welcome and can be sent to email addresses in
  the paper</comments><msc-class>Intelligent reflecting surfaces, 6G communications, power control,
  quality of service, max-min fair design, wireless networks</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surfaces (IRSs) have received much attention recently
and are envisioned to promote 6G communication networks. In this paper, for
wireless communications aided by IRS units, we formulate optimization problems
for power control under quality of service (QoS) and max-min fair QoS under
three kinds of traffic patterns from a base station (BS) to mobile users (MUs):
unicast, broadcast, and multicast. The optimizations are achieved by jointly
designing the transmit beamforming of the BS and the phase shift matrix of the
IRS. For power control under QoS, existing IRS studies in the literature
address only the unicast setting, whereas no IRS work has considered max-min
fair QoS. Furthermore, we extend our above optimization studies to the novel
settings of multi-antenna mobile users or/and multiple intelligent reflecting
surfaces. For all the above optimizations, we provide detailed analyses to
propose efficient algorithms. To summarize, our paper presents a comprehensive
study of optimization problems involving power control, QoS, and fairness in
wireless networks enhanced by IRSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03973</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03973</id><created>2019-08-11</created><updated>2019-10-05</updated><authors><author><keyname>Lu</keyname><forenames>Ping</forenames></author><author><keyname>Zhang</keyname><forenames>Yanyan</forenames></author><author><keyname>Chen</keyname><forenames>Jianxiong</forenames></author><author><keyname>Xiao</keyname><forenames>Yuan</forenames></author><author><keyname>Zhao</keyname><forenames>George</forenames></author></authors><title>Enhanced Seismic Imaging with Predictive Neural Networks for Geophysics</title><categories>eess.IV cs.LG physics.geo-ph stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a predictive neural network architecture that can be utilized to
update reference velocity models as inputs to the full waveform inversion. Deep
learning models are explored to augment velocity model building workflows
during processing the 3D seismic volume in salt-prone environments.
Specifically, a neural network architecture, with 3D convolutional,
de-convolutional layers, and 3D max-pooling, is designed to take standard
amplitude 3D seismic volumes as an input. Enhanced data augmentations through
generative adversarial networks and a weighted loss function enable the network
to train with few sparsely annotated slices. Batch normalization is also
applied for faster convergence. A 3D probability cube for salt bodies and
inclusions is generated through ensembles of predictions from multiple models
in order to reduce variance. Velocity models inferred from the proposed
networks provide opportunities for FWI forward models to converge faster with
an initial condition closer to the true model. In addition, in each iteration
step, the probability cubes of salt bodies and inclusions inferred from the
proposed networks can be used as a regularization term within the FWI forward
modelling, which may result in an improved velocity model estimation while the
output of seismic migration can be utilized as an input of the 3D neural
network for subsequent iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03984</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03984</id><created>2019-08-11</created><updated>2020-01-21</updated><authors><author><keyname>Huang</keyname><forenames>Yuwei</forenames></author><author><keyname>Mo</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author></authors><title>Online Maneuver Design for UAV-Enabled NOMA Systems via Reinforcement
  Learning</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper is to appear in IEEE WCNC 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers an unmanned aerial vehicle enabled-up link
non-orthogonal multiple-access system, where multiple mobile users on the
ground send independent messages to a unmanned aerial vehicle in the sky via
non-orthogonal multiple-access transmission. Our objective is to design the
unmanned aerial vehicle dynamic maneuver for maximizing the sum-rate throughput
of all mobile ground users over a finite time horizon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03990</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03990</id><created>2019-08-12</created><authors><author><keyname>Chen</keyname><forenames>Zhiyong</forenames></author><author><keyname>Ren</keyname><forenames>Zongze</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author></authors><title>A Study on Angular Based Embedding Learning for Text-independent Speaker
  Verification</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning a good speaker embedding is important for many automatic speaker
recognition tasks, including verification, identification and diarization. The
embeddings learned by softmax are not discriminative enough for open-set
verification tasks. Angular based embedding learning target can achieve such
discriminativeness by optimizing angular distance and adding margin penalty. We
apply several different popular angular margin embedding learning strategies in
this work and explicitly compare their performance on Voxceleb speaker
recognition dataset. Observing the fact that encouraging inter-class
separability is important when applying angular based embedding learning, we
propose an exclusive inter-class regularization as a complement for angular
based loss. We verify the effectiveness of these methods for learning a
discriminative embedding space on ASV task with several experiments. These
methods together, we manage to achieve an impressive result with 16.5%
improvement on equal error rate (EER) and 18.2% improvement on minimum
detection cost function comparing with baseline softmax systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.03995</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.03995</id><created>2019-08-12</created><updated>2020-01-27</updated><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author></authors><title>Temporally Discounted Differential Privacy for Evolving Datasets on an
  Infinite Horizon</title><categories>cs.CR cs.SY econ.TH eess.SP eess.SY</categories><journal-ref>2020 ACM/IEEE 11th International Conference on Cyber-Physical
  Systems (ICCPS)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define discounted differential privacy, as an alternative to
(conventional) differential privacy, to investigate privacy of evolving
datasets, containing time series over an unbounded horizon. We use privacy loss
as a measure of the amount of information leaked by the reports at a certain
fixed time. We observe that privacy losses are weighted equally across time in
the definition of differential privacy, and therefore the magnitude of
privacy-preserving additive noise must grow without bound to ensure
differential privacy over an infinite horizon. Motivated by the discounted
utility theory within the economics literature, we use exponential and
hyperbolic discounting of privacy losses across time to relax the definition of
differential privacy under continual observations. This implies that privacy
losses in distant past are less important than the current ones to an
individual. We use discounted differential privacy to investigate privacy of
evolving datasets using additive Laplace noise and show that the magnitude of
the additive noise can remain bounded under discounted differential privacy. We
illustrate the quality of privacy-preserving mechanisms satisfying discounted
differential privacy on smart-meter measurement time-series of real households,
made publicly available by Ausgrid (an Australian electricity distribution
company).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04001</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04001</id><created>2019-08-12</created><authors><author><keyname>Mei</keyname><forenames>Wenjie</forenames></author><author><keyname>Zhao</keyname><forenames>Chengyan</forenames></author><author><keyname>Ogura</keyname><forenames>Masaki</forenames></author><author><keyname>Sugimoto</keyname><forenames>Kenji</forenames></author></authors><title>Mixed $H_2/H_{\infty}$ Control for Markov Jump Linear Systems with State
  and Mode-observation Delays</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study state-feedback control of Markov jump linear systems
with state and mode-observation delays. We assume that the delay of the mode
observation induced by the controllers follows an exponential distribution. We
also introduce a time-varying state delay factor that is applied in the
state-feedback controller. Our formulation provides a novel framework to
analyze and design feedback control laws for the delayed Markov jump linear
systems. We present a procedure to transform the closed-loop system into a
standard Markov jump linear system with delays. Moreover, based on this
transformation, we propose a set of Linear Matrix Inequalities (LMI) to design
feedback gains for stabilization and mixed $H_2/H_{\infty}$ control. Numerical
simulation is presented to illustrate the effectiveness of the theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04009</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04009</id><created>2019-08-12</created><authors><author><keyname>Gomes</keyname><forenames>Gabriel</forenames></author></authors><title>Open Traffic Models -- A framework for hybrid simulation of
  transportation networks</title><categories>cs.MS cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new approach to hybrid traffic modeling, along with
its implementation in software. The software allows modelers to assign traffic
models to individual links in a network. Each model implements a series of
methods, refered to as the modeling interface. These methods are used by the
program to exchange information between adjacent models. Traffic controllers
are implemented in a similar manner. The paper outlines the important
components of the method: the network description, the description of demands,
and the modeling and control interfaces. We include tests demonstrating the
propagation of congestion between pairs of macroscpoic, mesoscopic, and
microscopic models. Open Traffic Models is an open source implementation of
these concepts, and is available at https://github.com/ggomes/otm-sim.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04010</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04010</id><created>2019-08-12</created><authors><author><keyname>Li</keyname><forenames>Sijing</forenames></author><author><keyname>Wang</keyname><forenames>Zhongjian</forenames></author><author><keyname>Yau</keyname><forenames>Stephen S. T.</forenames></author><author><keyname>Zhang</keyname><forenames>Zhiwen</forenames></author></authors><title>Solving high-dimensional nonlinear filtering problems using a tensor
  train decomposition method</title><categories>math.NA cs.CE cs.NA cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient numerical method to solve
high-dimensional nonlinear filtering (NLF) problems. Specifically, we use the
tensor train decomposition method to solve the forward Kolmogorov equation
(FKE) arising from the NLF problem. Our method consists of offline and online
stages. In the offline stage, we use the finite difference method to discretize
the partial differential operators involved in the FKE and extract
low-dimensional structures in the solution space using the tensor train
decomposition method. In addition, we approximate the evolution of the FKE
operator using the tensor train decomposition method. In the online stage using
the pre-computed low-rank approximation tensors, we can quickly solve the FKE
given new observation data. Therefore, we can solve the NLF roblem in a
real-time manner. Under some mild assumptions, we provide convergence analysis
for the proposed method. Finally, we present numerical results to show the
efficiency and accuracy of the proposed method in solving high-dimensional NLF
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04109</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04109</id><created>2019-08-12</created><authors><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author></authors><title>Successive Projection Algorithm Robust to Outliers</title><categories>eess.SP cs.LG cs.NA eess.IV math.NA stat.ML</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The successive projection algorithm (SPA) is a fast algorithm to tackle
separable nonnegative matrix factorization (NMF). Given a nonnegative data
matrix $X$, SPA identifies an index set $\mathcal{K}$ such that there exists a
nonnegative matrix $H$ with $X \approx X(:,\mathcal{K})H$. SPA has been
successfully used as a pure-pixel search algorithm in hyperspectral unmixing
and for anchor word selection in document classification. Moreover, SPA is
provably robust in low-noise settings. The main drawbacks of SPA are that it is
not robust to outliers and does not take the data fitting term into account
when selecting the indices in $\mathcal{K}$. In this paper, we propose a new
SPA variant, dubbed Robust SPA (RSPA), that is robust to outliers while still
being provably robust in low-noise settings, and that takes into account the
reconstruction error for selecting the indices in $\mathcal{K}$. We illustrate
the effectiveness of RSPA on synthetic data sets and hyperspectral images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04118</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04118</id><created>2019-08-12</created><authors><author><keyname>Hampe</keyname><forenames>Nils</forenames></author><author><keyname>Katscher</keyname><forenames>Ulrich</forenames></author><author><keyname>Berg</keyname><forenames>Cornelis A. T. van den</forenames></author><author><keyname>Tha</keyname><forenames>Khin Khin</forenames></author><author><keyname>Mandija</keyname><forenames>Stefano</forenames></author></authors><title>Deep learning brain conductivity mapping using a patch-based 3D U-net</title><categories>physics.med-ph eess.IV q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To investigate deep learning electrical properties tomography (EPT)
for application on different simulated and in-vivo datasets including
pathologies for obtaining quantitative brain conductivity maps. Methods: 3D
patch-based convolutional neural networks were trained to predict conductivity
maps from B1 transceive phase data. To compare the performance of DLEPT
networks on different datasets, three datasets were used throughout this work,
one from simulations and two from in-vivo measurements from healthy volunteers
and cancer patients, respectively. At first, networks trained on simulations
are tested on all datasets with different levels of homogeneous Gaussian noise
introduced in training and testing. Secondly, to investigate potential
robustness towards systematical differences between simulated and measured
phase maps, in-vivo data with conductivity labels from conventional EPT is used
for training. Results: High quality of reconstructions from networks trained on
simulations with and without noise confirms the potential of deep learning for
EPT. However, artifact encumbered results in this work uncover challenges in
application of DLEPT to in-vivo data. Training DLEPT networks on conductivity
labels from conventional EPT improves quality of results. This is argued to be
caused by robustness to artifacts from image acquisition. Conclusions: Networks
trained on simulations with added homogeneous Gaussian noise yield
reconstruction artifacts when applied to in-vivo data. Training with realistic
phase data and conductivity labels from conventional EPT allows for severely
reducing these artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04123</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04123</id><created>2019-08-12</created><authors><author><keyname>Kumar</keyname><forenames>Kundan</forenames></author><author><keyname>Samal</keyname><forenames>Debashisa</forenames></author><author><keyname>Suraj</keyname></author></authors><title>Automated retinal vessel segmentation based on morphological
  preprocessing and 2D-Gabor wavelets</title><categories>eess.IV cs.CV</categories><comments>12 pages, 5 figures, conference</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Automated segmentation of vascular map in retinal images endeavors a
potential benefit in diagnostic procedure of different ocular diseases. In this
paper, we suggest a new unsupervised retinal blood vessel segmentation approach
using top-hat transformation, contrast-limited adaptive histogram equalization
(CLAHE), and 2-D Gabor wavelet filters. Initially, retinal image is
preprocessed using top-hat morphological transformation followed by CLAHE to
enhance only the blood vessel pixels in the presence of exudates, optic disc,
and fovea. Then, multiscale 2-D Gabor wavelet filters are applied on
preprocessed image for better representation of thick and thin blood vessels
located at different orientations. The efficacy of the presented algorithm is
assessed on publicly available DRIVE database with manually labeled images. On
DRIVE database, we achieve an average accuracy of 94.32% with a small standard
deviation of 0.004. In comparison with major algorithms, our algorithm produces
better performance concerning the accuracy, sensitivity, and kappa agreement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04126</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04126</id><created>2019-08-12</created><updated>2019-10-27</updated><authors><author><keyname>Panfilov</keyname><forenames>Egor</forenames></author><author><keyname>Tiulpin</keyname><forenames>Aleksei</forenames></author><author><keyname>Klein</keyname><forenames>Stefan</forenames></author><author><keyname>Nieminen</keyname><forenames>Miika T.</forenames></author><author><keyname>Saarakkala</keyname><forenames>Simo</forenames></author></authors><title>Improving Robustness of Deep Learning Based Knee MRI Segmentation: Mixup
  and Adversarial Domain Adaptation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Degeneration of articular cartilage (AC) is actively studied in knee
osteoarthritis (OA) research via magnetic resonance imaging (MRI). Segmentation
of AC tissues from MRI data is an essential step in quantification of their
damage. Deep learning (DL) based methods have shown potential in this realm and
are the current state-of-the-art, however, their robustness to heterogeneity of
MRI acquisition settings remains an open problem. In this study, we
investigated two modern regularization techniques -- mixup and adversarial
unsupervised domain adaptation (UDA) -- to improve the robustness of DL-based
knee cartilage segmentation to new MRI acquisition settings. Our validation
setup included two datasets produced by different MRI scanners and using
distinct data acquisition protocols. We assessed the robustness of automatic
segmentation by comparing mixup and UDA approaches to a strong baseline method
at different OA severity stages and, additionally, in relation to anatomical
locations. Our results showed that for moderate changes in knee MRI data
acquisition settings both approaches may provide notable improvements in the
robustness, which are consistent for all stages of the disease and affect the
clinically important areas of the knee joint. However, mixup may be considered
as a recommended approach, since it is more computationally efficient and does
not require additional data from the target acquisition setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04142</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04142</id><created>2019-08-12</created><authors><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Guo</keyname><forenames>Jiajia</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author></authors><title>3-D Positioning and Environment Mapping for mmWave Communication Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>30 pages, 9 figures, 4 tables. This work has been submitted to the
  IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) cloud radio access networks (CRANs) provide new
opportunities for accurate cooperative localization, in which large bandwidths,
large antenna arrays, and increased densities of base stations allow for their
unparalleled delay and angular resolution. Combining localization into
communications and designing simultaneous localization and mapping (SLAM)
algorithms are challenging problems. This study considers the joint position
and velocity estimation and environment mapping problem in a three-dimensional
mmWave CRAN architecture. We first embed cooperative localization into
communications and establish the joint estimation and mapping model with hybrid
delay and angle measurements. Then, we propose a closed-form weighted least
square (WLS) solution for the joint estimation and mapping problems. The
proposed WLS estimator is proven asymptotically unbiased and confirmed by
simulations as effective in achieving the Cramer-Rao lower bound (CRLB) and the
desired decimeter-level accuracy. Furthermore, we propose a WLS-Net-based SLAM
algorithm by embedding neural networks into the proposed WLS estimators to
replace the linear approximations. The solution possesses both powerful
learning ability of the neural network and robustness of the proposed geometric
model, and the ensemble learning is applied to further improve positioning
accuracy. A public ray-tracing dataset is used in the simulations to test the
performance of the WLS-Net-based SLAM algorithm, which is proven fast and
effective in attaining the centimeter-level accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04162</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04162</id><created>2019-08-12</created><updated>2019-10-30</updated><authors><author><keyname>Eskandari</keyname><forenames>Mahdi</forenames></author><author><keyname>Bakhshi</keyname><forenames>Hamidreza</forenames></author></authors><title>Channel Estimation for MIMO Hybrid Architectures with Low Resolution
  ADCs for mmWave Communication</title><categories>eess.SP</categories><comments>This submission has been withdrawn by arXiv administrators due to
  inappropriate text reuse from external sources</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Hybrid analog/digital architectures and receivers with low-resolution
analog-to-digital converters (ADCs) are two low power solutions for wireless
systems with large antenna arrays. Most prior work represents two extreme cases
in which either a small number of radio frequency (RF) chains with
full-resolution ADCs, or low-resolution ADC with a number of RF chains equal to
the number of antennas is assumed. In this paper, a generalized hybrid
architecture with a small number of RF chains and a finite number of ADC bits
is proposed. In such a system, the received signal suffers from two compression
stages. One is due to the analog processing stage and the reduced number of RF
chains, while the other is a result of signal quantization by the ADC
converters. The compression steps both complicate the estimation of the MIMO
channel. In this paper, we propose an off grid compressive channel estimator
that exploits the sparse structure of the millimeter wave channel to compensate
for the loss of information inheren to the proposed architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04168</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04168</id><created>2019-08-12</created><authors><author><keyname>Westland</keyname><forenames>Natasha</forenames></author><author><keyname>Dias</keyname><forenames>Andr&#xe9; Seixas</forenames></author><author><keyname>Mrak</keyname><forenames>Marta</forenames></author></authors><title>Decision Trees for Complexity Reduction in Video Compression</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for complexity reduction in practical video
encoders using multiple decision tree classifiers. The method is demonstrated
for the fast implementation of the 'High Efficiency Video Coding' (HEVC)
standard, chosen because of its high bit rate reduction capability but large
complexity overhead. Optimal partitioning of each video frame into coding units
(CUs) is the main source of complexity as a vast number of combinations are
tested. The decision tree models were trained to identify when the CU testing
process, a time-consuming Lagrangian optimisation, can be skipped i.e a high
probability that the CU can remain whole. A novel approach to finding the
simplest and most effective decision tree model called 'manual pruning' is
described. Implementing the skip criteria reduced the average encoding time by
42.1% for a Bj{\o}ntegaard Delta rate detriment of 0.7%, for 17 standard test
sequences in a range of resolutions and quantisation parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04173</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04173</id><created>2019-08-12</created><authors><author><keyname>Bockelmann</keyname><forenames>Niclas</forenames></author><author><keyname>Kr&#xfc;ger</keyname><forenames>Diana</forenames></author><author><keyname>Wieland</keyname><forenames>D. C. Florian</forenames></author><author><keyname>Zeller-Plumhoff</keyname><forenames>Berit</forenames></author><author><keyname>Peruzzi</keyname><forenames>Niccol&#xf3;</forenames></author><author><keyname>Galli</keyname><forenames>Silvia</forenames></author><author><keyname>Willumeit-R&#xf6;mer</keyname><forenames>Regine</forenames></author><author><keyname>Wilde</keyname><forenames>Fabian</forenames></author><author><keyname>Beckmann</keyname><forenames>Felix</forenames></author><author><keyname>Hammel</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Moosmann</keyname><forenames>Julian</forenames></author><author><keyname>Heinrich</keyname><forenames>Mattias P.</forenames></author></authors><title>Sparse Annotations with Random Walks for U-Net Segmentation of
  Biodegradable Bone Implants in Synchrotron Microtomograms</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612] Extended Abstract</comments><report-no>MIDL/2019/ExtendedAbstract/HJll3eNCY4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Currently, most bone implants used in orthopedics and traumatology are
non-degradable and may need to be surgically removed later on e.g. in the case
of children. This removal is associated with health risks which could be
minimized by using biodegradable implants. Therefore, research on
magnesium-based implants is ongoing, which can be objectively quantified
through synchrotron radiation microtomography and subsequent image analysis. In
order to evaluate the suitability of these materials, e.g. their stability over
time, accurate pixelwise segmentations of these high-resolution scans are
necessary. The fully-convolutional U-Net architecture achieves a Dice
coefficient of 0.750 +/- 0.102 when trained with a small dataset with dense
expert annotations. However, extending the learning to larger databases would
require prohibitive annotation efforts. Hence, in this work we implemented and
compared new training methods that require only a small fraction of manually
annotated pixels. While directly training on these scribble annotation
deteriorates the segmentation quality by 26.8 percentage points, our new random
walk-based semi-automatic target achieves the same Dice overlap as a dense
supervision, and thus offers a more promising approach for sparse annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04181</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04181</id><created>2019-08-12</created><authors><author><keyname>Gessert</keyname><forenames>Nils</forenames></author><author><keyname>Schlaefer</keyname><forenames>Alexander</forenames></author></authors><title>Left Ventricle Quantification Using Direct Regression with Segmentation
  Regularization and Ensembles of Pretrained 2D and 3D CNNs</title><categories>eess.IV cs.CV</categories><comments>Accepted at the MICCAI Workshop STACOM 2019</comments><doi>10.1007/978-3-030-39074-7_39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiac left ventricle (LV) quantification provides a tool for diagnosing
cardiac diseases. Automatic calculation of all relevant LV indices from cardiac
MR images is an intricate task due to large variations among patients and
deformation during the cardiac cycle. Typical methods are based on segmentation
of the myocardium or direct regression from MR images. To consider cardiac
motion and deformation, recurrent neural networks and spatio-temporal
convolutional neural networks (CNNs) have been proposed. We study an approach
combining state-of-the-art models and emphasizing transfer learning to account
for the small dataset provided for the LVQuan19 challenge. We compare 2D
spatial and 3D spatio-temporal CNNs for LV indices regression and cardiac phase
classification. To incorporate segmentation information, we propose an
architecture-independent segmentation-based regularization. To improve the
robustness further, we employ a search scheme that identifies the optimal
ensemble from a set of architecture variants. Evaluating on the LVQuan19
Challenge training dataset with 5-fold cross-validation, we achieve mean
absolute errors of 111 +- 76mm^2, 1.84 +- 0.9mm and 1.22 +- 0.6mm for area,
dimension and regional wall thickness regression, respectively. The error rate
for cardiac phase classification is 6.7%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04187</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04187</id><created>2019-08-09</created><authors><author><keyname>Patel</keyname><forenames>Yash</forenames></author><author><keyname>Appalaraju</keyname><forenames>Srikar</forenames></author><author><keyname>Manmatha</keyname><forenames>R.</forenames></author></authors><title>Human Perceptual Evaluations for Image Compression</title><categories>eess.IV cs.CV</categories><comments>arXiv admin note: text overlap with arXiv:1907.08310</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there has been much interest in deep learning techniques to do
image compression and there have been claims that several of these produce
better results than engineered compression schemes (such as JPEG, JPEG2000 or
BPG). A standard way of comparing image compression schemes today is to use
perceptual similarity metrics such as PSNR or MS-SSIM (multi-scale structural
similarity). This has led to some deep learning techniques which directly
optimize for MS-SSIM by choosing it as a loss function. While this leads to a
higher MS-SSIM for such techniques, we demonstrate using user studies that the
resulting improvement may be misleading. Deep learning techniques for image
compression with a higher MS-SSIM may actually be perceptually worse than
engineered compression schemes with a lower MS-SSIM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04197</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04197</id><created>2019-08-12</created><authors><author><keyname>Rana</keyname><forenames>Aakanksha</forenames></author><author><keyname>Singh</keyname><forenames>Praveer</forenames></author><author><keyname>Valenzise</keyname><forenames>Giuseppe</forenames></author><author><keyname>Dufaux</keyname><forenames>Frederic</forenames></author><author><keyname>Komodakis</keyname><forenames>Nikos</forenames></author><author><keyname>Smolic</keyname><forenames>Aljosa</forenames></author></authors><title>Deep Tone Mapping Operator for High Dynamic Range Images</title><categories>eess.IV cs.CV cs.GR</categories><doi>10.1109/TIP.2019.2936649</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computationally fast tone mapping operator (TMO) that can quickly adapt to
a wide spectrum of high dynamic range (HDR) content is quintessential for
visualization on varied low dynamic range (LDR) output devices such as movie
screens or standard displays. Existing TMOs can successfully tone-map only a
limited number of HDR content and require an extensive parameter tuning to
yield the best subjective-quality tone-mapped output. In this paper, we address
this problem by proposing a fast, parameter-free and scene-adaptable deep tone
mapping operator (DeepTMO) that yields a high-resolution and high-subjective
quality tone mapped output. Based on conditional generative adversarial network
(cGAN), DeepTMO not only learns to adapt to vast scenic-content (e.g., outdoor,
indoor, human, structures, etc.) but also tackles the HDR related
scene-specific challenges such as contrast and brightness, while preserving the
fine-grained details. We explore 4 possible combinations of
Generator-Discriminator architectural designs to specifically address some
prominent issues in HDR related deep-learning frameworks like blurring, tiling
patterns and saturation artifacts. By exploring different influences of scales,
loss-functions and normalization layers under a cGAN setting, we conclude with
adopting a multi-scale model for our task. To further leverage on the
large-scale availability of unlabeled HDR data, we train our network by
generating targets using an objective HDR quality metric, namely Tone Mapping
Image Quality Index (TMQI). We demonstrate results both quantitatively and
qualitatively, and showcase that our DeepTMO generates high-resolution,
high-quality output images over a large spectrum of real-world scenes. Finally,
we evaluate the perceived quality of our results by conducting a pair-wise
subjective study which confirms the versatility of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04250</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04250</id><created>2019-08-12</created><updated>2019-09-23</updated><authors><author><keyname>Mazumdar</keyname><forenames>Indrajit</forenames></author></authors><title>Automated Brain Tumour Segmentation Using Deep Fully Residual
  Convolutional Neural Networks</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated brain tumour segmentation has the potential of making a massive
improvement in disease diagnosis, surgery, monitoring and surveillance.
However, this task is extremely challenging. Here, we describe our automated
segmentation method using 2D CNNs that are based on U-Net. To deal with class
imbalance effectively, we have formulated a novel weighted Dice loss function.
We found that increasing the depth of the 'U' shape beyond a certain level
results in a decrease in performance, so it is essential to choose an optimum
depth. We also found that 3D contextual information cannot be captured by a
single 2D network that is trained with patches extracted from multiple views
whereas an ensemble of three 2D networks trained in multiple views can
effectively capture the information and deliver much better performance. We
obtained Dice scores of 0.79 for enhancing tumour, 0.90 for whole tumour, and
0.82 for tumour core on the BraTS 2018 validation set. Our method using 2D
network consumes very less time and memory, and is much simpler and easier to
implement compared to the state-of-the-art methods that used 3D networks;
still, it manages to achieve comparable performance to those methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04259</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04259</id><created>2019-08-09</created><authors><author><keyname>Niu</keyname><forenames>Yakun</forenames></author><author><keyname>Tondi</keyname><forenames>Benedetta</forenames></author><author><keyname>Zhao</keyname><forenames>Yao</forenames></author><author><keyname>Barni</keyname><forenames>Mauro</forenames></author></authors><title>Primary quantization matrix estimation of double compressed JPEG images
  via CNN</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Available model-based techniques for the estimation of the primary
quantization matrix in double-compressed JPEG images work only under specific
conditions regarding the relationship between the first and second compression
quality factors, and the alignment of the first and second JPEG compression
grids. In this paper, we propose a single CNN-based estimation technique that
can work under a very general range of settings. We do so, by adapting a dense
CNN network to the problem at hand. Particular attention is paid to the choice
of the loss function. Experimental results highlight several advantages of the
new method, including: i) capability of working under very general conditions,
ii) improved performance in terms of MSE and accuracy especially in the
non-aligned case, iii) better spatial resolution due to the ability of
providing good results also on small image patches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04278</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04278</id><created>2019-08-12</created><authors><author><keyname>Eskandari</keyname><forenames>Mahdi</forenames></author><author><keyname>Bakhshi</keyname><forenames>Hamidreza</forenames></author></authors><title>A Frequency Domain Channel Estimation Based on Atomic Norm Minimization
  for Frequency Selective MmWave MIMO Systems</title><categories>eess.SP</categories><comments>6 pages, 3 Figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this study, a channel estimator for millimeter wave (mmWave) systems is
proposed. By considering the sparse nature of channels in millimeter wave band,
the channel estimation problem formulated as an atomic norm minimization
problem. Previous studies on mmWave channel estimation have focused on
frequency flat channels. However, in this study the work is based on a
frequency selective channel and adopted atomic norm minimization and reweighed
atomic norm minimization technique for channel estimation in the frequency
domain. Simulation results verify the accuracy of the atomic and reweighted
atomic norm minimization techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04284</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04284</id><created>2019-08-12</created><updated>2020-02-01</updated><authors><author><keyname>Ding</keyname><forenames>Shaojin</forenames></author><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Chang</keyname><forenames>Shuo-yiin</forenames></author><author><keyname>Wan</keyname><forenames>Li</forenames></author><author><keyname>Moreno</keyname><forenames>Ignacio Lopez</forenames></author></authors><title>Personal VAD: Speaker-Conditioned Voice Activity Detection</title><categories>eess.AS cs.LG stat.ML</categories><comments>To be submitted to ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose &quot;personal VAD&quot;, a system to detect the voice
activity of a target speaker at the frame level. This system is useful for
gating the inputs to a streaming on-device speech recognition system, such that
it only triggers for the target user, which helps reduce the computational cost
and battery consumption. We achieve this by training a VAD-alike neural network
that is conditioned on the target speaker embedding or the speaker verification
score. For each frame, personal VAD outputs the probabilities for three
classes: non-speech, target speaker speech, and non-target speaker speech.
Under our optimal setup, we are able to train a model with 130K parameters that
outperforms a baseline system where individually trained standard VAD and
speaker recognition networks are combined to perform the same task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04289</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04289</id><created>2019-08-10</created><authors><author><keyname>Gao</keyname><forenames>Peng</forenames></author><author><keyname>You</keyname><forenames>Haoxuan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhanpeng</forenames></author><author><keyname>Wang</keyname><forenames>Xiaogang</forenames></author><author><keyname>Li</keyname><forenames>Hongsheng</forenames></author></authors><title>Multi-modality Latent Interaction Network for Visual Question Answering</title><categories>cs.CV cs.SD eess.AS eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exploiting relationships between visual regions and question words have
achieved great success in learning multi-modality features for Visual Question
Answering (VQA). However, we argue that existing methods mostly model relations
between individual visual regions and words, which are not enough to correctly
answer the question. From humans' perspective, answering a visual question
requires understanding the summarizations of visual and language information.
In this paper, we proposed the Multi-modality Latent Interaction module (MLI)
to tackle this problem. The proposed module learns the cross-modality
relationships between latent visual and language summarizations, which
summarize visual regions and question into a small number of latent
representations to avoid modeling uninformative individual region-word
relations. The cross-modality information between the latent summarizations are
propagated to fuse valuable information from both modalities and are used to
update the visual and word features. Such MLI modules can be stacked for
several stages to model complex and latent relations between the two modalities
and achieves highly competitive performance on public VQA benchmarks, VQA v2.0
and TDIUC . In addition, we show that the performance of our methods could be
significantly improved by combining with pre-trained language model BERT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04297</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04297</id><created>2019-08-12</created><authors><author><keyname>Ozcinar</keyname><forenames>Cagri</forenames></author><author><keyname>Rana</keyname><forenames>Aakanksha</forenames></author><author><keyname>Smolic</keyname><forenames>Aljosa</forenames></author></authors><title>Super-resolution of Omnidirectional Images Using Adversarial Learning</title><categories>cs.CV cs.LG cs.MM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An omnidirectional image (ODI) enables viewers to look in every direction
from a fixed point through a head-mounted display providing an immersive
experience compared to that of a standard image. Designing immersive virtual
reality systems with ODIs is challenging as they require high resolution
content. In this paper, we study super-resolution for ODIs and propose an
improved generative adversarial network based model which is optimized to
handle the artifacts obtained in the spherical observational space.
Specifically, we propose to use a fast PatchGAN discriminator, as it needs
fewer parameters and improves the super-resolution at a fine scale. We also
explore the generative models with adversarial learning by introducing a
spherical-content specific loss function, called 360-SS. To train and test the
performance of our proposed model we prepare a dataset of 4500 ODIs. Our
results demonstrate the efficacy of the proposed method and identify new
challenges in ODI super-resolution for future investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04346</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04346</id><created>2019-08-06</created><authors><author><keyname>Zhang</keyname><forenames>Tianyang</forenames></author><author><keyname>Fu</keyname><forenames>Huazhu</forenames></author><author><keyname>Zhao</keyname><forenames>Yitian</forenames></author><author><keyname>Cheng</keyname><forenames>Jun</forenames></author><author><keyname>Guo</keyname><forenames>Mengjie</forenames></author><author><keyname>Gu</keyname><forenames>Zaiwang</forenames></author><author><keyname>Yang</keyname><forenames>Bing</forenames></author><author><keyname>Xiao</keyname><forenames>Yuting</forenames></author><author><keyname>Gao</keyname><forenames>Shenghua</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author></authors><title>SkrGAN: Sketching-rendering Unconditional Generative Adversarial
  Networks for Medical Image Synthesis</title><categories>cs.CV eess.IV</categories><comments>Accepted to MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative Adversarial Networks (GANs) have the capability of synthesizing
images, which have been successfully applied to medical image synthesis tasks.
However, most of existing methods merely consider the global contextual
information and ignore the fine foreground structures, e.g., vessel, skeleton,
which may contain diagnostic indicators for medical image analysis. Inspired by
human painting procedure, which is composed of stroking and color rendering
steps, we propose a Sketching-rendering Unconditional Generative Adversarial
Network (SkrGAN) to introduce a sketch prior constraint to guide the medical
image generation. In our SkrGAN, a sketch guidance module is utilized to
generate a high quality structural sketch from random noise, then a color
render mapping is used to embed the sketch-based representations and resemble
the background appearances. Experimental results show that the proposed SkrGAN
achieves the state-of-the-art results in synthesizing images for various image
modalities, including retinal color fundus, X-Ray, Computed Tomography (CT) and
Magnetic Resonance Imaging (MRI). In addition, we also show that the
performances of medical image segmentation method have been improved by using
our synthesized images as data augmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04347</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04347</id><created>2019-08-09</created><authors><author><keyname>Hepburn</keyname><forenames>Alexander</forenames></author><author><keyname>Laparra</keyname><forenames>Valero</forenames></author><author><keyname>McConville</keyname><forenames>Ryan</forenames></author><author><keyname>Santos-Rodriguez</keyname><forenames>Raul</forenames></author></authors><title>Enforcing Perceptual Consistency on Generative Adversarial Networks by
  Using the Normalised Laplacian Pyramid Distance</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years there has been a growing interest in image generation through
deep learning. While an important part of the evaluation of the generated
images usually involves visual inspection, the inclusion of human perception as
a factor in the training process is often overlooked. In this paper we propose
an alternative perceptual regulariser for image-to-image translation using
conditional generative adversarial networks (cGANs). To do so automatically
(avoiding visual inspection), we use the Normalised Laplacian Pyramid Distance
(NLPD) to measure the perceptual similarity between the generated image and the
original image. The NLPD is based on the principle of normalising the value of
coefficients with respect to a local estimate of mean energy at different
scales and has already been successfully tested in different experiments
involving human perception. We compare this regulariser with the originally
proposed L1 distance and note that when using NLPD the generated images contain
more realistic values for both local and global contrast. We found that using
NLPD as a regulariser improves image segmentation accuracy on generated images
as well as improving two no-reference image quality metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04372</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04372</id><created>2019-08-12</created><authors><author><keyname>Watson</keyname><forenames>Ryan M.</forenames></author><author><keyname>Gross</keyname><forenames>Jason N.</forenames></author><author><keyname>Taylor</keyname><forenames>Clark N.</forenames></author><author><keyname>Leishman</keyname><forenames>Robert C.</forenames></author></authors><title>Uncertainty Model Estimation in an Augmented Data Space for Robust State
  Estimation</title><categories>eess.SP</categories><comments>6 pages, 5 figures, Correspondence submitted to the IEEE Transactions
  on Aerospace and Electronic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The requirement to generate robust robotic platforms is a critical enabling
step to allow such platforms to permeate safety-critical applications (i.e.,
the localization of autonomous platforms in urban environments). One of the
primary components of such a robotic platform is the state estimation engine,
which enables the platform to reason about itself and the environment based
upon sensor readings. When such sensor readings are degraded traditional state
estimation approaches are known to breakdown. To overcome this issue, several
robust state estimation frameworks have been proposed. One such method is the
batch covariance estimation (BCE) framework. The BCE approach enables robust
state estimation by iteratively updating the measurement error uncertainty
model through the fitting of a Gaussian mixture model (GMM) to the measurement
residuals. This paper extends upon the BCE approach by arguing that the
uncertainty estimation process should be augmented to include metadata (e.g.,
the signal strength of the associated GNSS observation). The modification of
the uncertainty estimation process to an augmented data space is significant
because it increases the likelihood of a unique partitioning in the measurement
residual domain and thus provides the ability to more accurately characterize
the measurement uncertainty model. The proposed batch covariance estimation
over an augmented data-space (BCE-AD) is experimentally validated on collected
data where it is shown that a significant increase in state estimation accuracy
can be granted compared to previously proposed robust estimation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04376</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04376</id><created>2019-08-12</created><authors><author><keyname>Cisek</keyname><forenames>Grzegorz</forenames></author><author><keyname>Zielinski</keyname><forenames>Tomasz P.</forenames></author></authors><title>Prototyping Software Transceiver for the 5G New Radio Physical Uplink
  Shared Channel</title><categories>cs.NI eess.SP</categories><comments>Conference: Signal Processing Symposium (SPSympo), Cracow, Poland,
  17-19 Sep. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G New Radio (NR) is an emerging radio access technology, which is planned to
succeed 4G Long Term Evolution (LTE) as global standard of cellular
communications in the upcoming years. This paper considers a digital signal
processing model and a software implementation of a complete transceiver chain
of the Physical Uplink Shared Channel (PUSCH) defined by the version 15 of the
3GPP standard, consisting of both baseband transmitter and receiver chains on a
physical layer level. The BLER performance of the prototype system
implementation under AWGN and Rayleigh fading channel conditions is evaluated.
Moreover, the source code of high-level numerical model was made available
online on a public repository by the authors. In the paper's tutorial part, the
aspects of the 5G NR standard are reviewed and their impact on different
functional building blocks of the system is discussed, including
synchronization, channel estimation, equalization, soft-bit demodulation and
LDPC encoding/decoding. A review of State-of-Art algorithms that can be
utilized to increase the performance of the system is provided together with a
guidelines for practical implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04405</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04405</id><created>2019-08-12</created><authors><author><keyname>Zarifakis</keyname><forenames>Marios</forenames></author><author><keyname>Coffey</keyname><forenames>William T.</forenames></author><author><keyname>Kalmykov</keyname><forenames>Yuri P.</forenames></author><author><keyname>Titov</keyname><forenames>Serguey V.</forenames></author><author><keyname>Byrne</keyname><forenames>Declan J.</forenames></author><author><keyname>Carrig</keyname><forenames>Stephen J.</forenames></author></authors><title>Active Damping of Power Oscillations Following Frequency Changes in Low
  Inertia Power Systems</title><categories>eess.SY cs.SY</categories><comments>8 pages, 7 figures. Published in: IEEE Transactions on Power Systems
  (Early Access), 17 April 2019</comments><doi>10.1109/TPWRS.2019.2911845</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The absolute requirement to increase the amount of energy generation from
renewable sources e.g. predominantly asynchronously connected wind turbines and
photovoltaic installations, may in practice during transient events (where
frequency changes are examined) excite oscillatory response of the power output
of large grid connected synchronous-generators. The response of such generators
must be controlled either by varying the applied torque of a turbine or by
altering the electromagnetic torque in the airgap. Choosing the latter, the
adequacy of a voltage regulator, particularly that of the embedded Power System
Stabilizer (PSS) circuit, is investigated using the IEEE PSS1A model for the
automatic voltage regulator of a synchronous generator driven by a gas turbine.
The response is obtained via closed form analytic solutions for both small
(linear) and large (nonlinear) scale transient events in the energy grid
system. In tandem with the analytical study, the behavior simulated with a
computer model from MatLab-SimPowerSystems is reviewed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04407</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04407</id><created>2019-08-12</created><authors><author><keyname>Zarifakis</keyname><forenames>Marios</forenames></author><author><keyname>Byrne</keyname><forenames>Declan J.</forenames></author><author><keyname>Coffey</keyname><forenames>William T.</forenames></author><author><keyname>Kalmykov</keyname><forenames>Yuri P.</forenames></author><author><keyname>Titov</keyname><forenames>Serguey V.</forenames></author><author><keyname>Carrig</keyname><forenames>Stephen J.</forenames></author></authors><title>Comparison of coupled nonlinear oscillator models for the transient
  response of power generating stations connected to low inertia systems</title><categories>eess.SY cs.SY</categories><comments>8 pages, 7 figures. Published in: IEEE Transactions on Power Systems
  (Early Access), 31 July 2019</comments><doi>10.1109/TPWRS.2019.2932376</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coupled nonlinear oscillators, e.g., Kuramoto models, are commonly used to
analyze electrical power systems. The cage model from statistical mechanics has
also been used to describe the dynamics of synchronously connected generation
stations. Whereas the Kuramoto model is good for describing high inertia grid
systems, the cage one allows both high and low inertia grids to be modelled.
This is illustrated by comparing both the synchronization time and relaxation
towards synchronization of each model by treating their equations of motion in
a common framework rooted in the dynamics of many coupled phase oscillators. A
solution of these equations via matrix continued fractions is implemented
rendering the characteristic relaxation times of a grid-generator system over a
wide range of inertia and damping. Following an abrupt change in the dynamical
system, the power output and both generator and grid frequencies all exhibit
damped oscillations now depending on the (finite) grid inertia. In practical
applications, it appears that for a small inertia system the cage model is
preferable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04411</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04411</id><created>2019-08-09</created><updated>2019-09-27</updated><authors><author><keyname>Shirin</keyname><forenames>Afroza</forenames></author><author><keyname>Klickstein</keyname><forenames>Isaac S.</forenames></author><author><keyname>Sorrentino</keyname><forenames>Francesco</forenames></author></authors><title>Stability Analysis of Reservoir Computers Dynamics via Lyapunov
  Functions</title><categories>eess.SY cs.SY nlin.AO</categories><doi>10.1063/1.5123733</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Lyapunov design method is used to analyze the nonlinear stability of a
generic reservoir computer for both the cases of continuous-time and
discrete-time dynamics. Using this method, for a given nonlinear reservoir
computer, a radial region of stability around a fixed point is analytically
determined. We see that the training error of the reservoir computer is lower
in the region where the analysis predicts global stability but is also affected
by the particular choice of the individual dynamics for the reservoir systems.
For the case that the dynamics is polynomial, it appears to be important for
the polynomial to have nonzero coefficients corresponding to at least one odd
power (e.g., linear term) and one even power (e.g., quadratic term).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04412</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04412</id><created>2019-08-05</created><authors><author><keyname>Moscoso</keyname><forenames>Miguel</forenames></author><author><keyname>Novikov</keyname><forenames>Alexei</forenames></author><author><keyname>Papanicolaou</keyname><forenames>George</forenames></author><author><keyname>Tsogka</keyname><forenames>Chrysoula</forenames></author></authors><title>The Noise Collector for sparse recovery in high dimensions</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to detect sparse signals from noisy high-dimensional data is a
top priority in modern science and engineering. A sparse solution of the linear
system $A \rho = b_0$ can be found efficiently with an $l_1$-norm minimization
approach if the data is noiseless. Detection of the signal's support from data
corrupted by noise is still a challenging problem, especially if the level of
noise must be estimated. We propose a new efficient approach that does not
require any parameter estimation. We introduce the Noise Collector (NC) matrix
$C$ and solve an augmented system $A \rho + C \eta = b_0 + e$, where $ e$ is
the noise. We show that the $l_1$-norm minimal solution of the augmented system
has zero false discovery rate for any level of noise and with probability that
tends to one as the dimension of $ b_0$ increases to infinity. We also obtain
exact support recovery if the noise is not too large, and develop a Fast Noise
Collector Algorithm which makes the computational cost of solving the augmented
system comparable to that of the original one. Finally, we demonstrate the
effectiveness of the method in applications to passive array imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04413</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04413</id><created>2019-08-09</created><authors><author><keyname>Qiu</keyname><forenames>Hao</forenames></author><author><keyname>Gu</keyname><forenames>Zaiwang</forenames></author><author><keyname>Mou</keyname><forenames>Lei</forenames></author><author><keyname>Mao</keyname><forenames>Xiaoqian</forenames></author><author><keyname>Fang</keyname><forenames>Liyang</forenames></author><author><keyname>Zhao</keyname><forenames>Yitian</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author><author><keyname>Cheng</keyname><forenames>Jun</forenames></author></authors><title>The Channel Attention based Context Encoder Network for Inner Limiting
  Membrane Detection</title><categories>eess.IV cs.CV q-bio.QM</categories><comments>This paper has been accepted by the miccai workshop (OMIA-6)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optic disc segmentation is an important step for retinal image-based
disease diagnosis such as glaucoma. The inner limiting membrane (ILM) is the
first boundary in the OCT, which can help to extract the retinal pigment
epithelium (RPE) through gradient edge information to locate the boundary of
the optic disc. Thus, the ILM layer segmentation is of great importance for
optic disc localization. In this paper, we build a new optic disc centered
dataset from 20 volunteers and manually annotated the ILM boundary in each OCT
scan as ground-truth. We also propose a channel attention based context encoder
network modified from the CE-Net to segment the optic disc. It mainly contains
three phases: the encoder module, the channel attention based context encoder
module, and the decoder module. Finally, we demonstrate that our proposed
method achieves state-of-the-art disc segmentation performance on our dataset
mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04417</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04417</id><created>2019-08-12</created><authors><author><keyname>Alizadeh</keyname><forenames>Mostafa</forenames></author><author><keyname>Abedi</keyname><forenames>Hajar</forenames></author><author><keyname>Shaker</keyname><forenames>George</forenames></author></authors><title>Low-cost low-power in-vehicle occupant detection with mm-wave FMCW radar</title><categories>eess.SP eess.IV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this paper, we use a low-cost low-power mm-wave frequency modulated
continuous wave (FMCW) radar for the in-vehicle occupant detection. We propose
an algorithm using Capon filter for the joint range-azimuth estimation. Then,
the minimum necessary features are extracted to train machine learning
classifiers to have reasonable computational complexity while achieving high
accuracy. In addition, experiments were carried out in a minivan to detect
occupancy of each row using support vector machine (SVM). Finally, our proposed
system achieved 97.8% accuracy on average in finding the defined scenarios.
Moreover, the system can correctly identify if the vehicle is occupied or not
with 100% accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04431</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04431</id><created>2019-08-12</created><authors><author><keyname>Chen</keyname><forenames>Juntao</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Dynamic Contract Design for Systemic Cyber Risk Management of
  Interdependent Enterprise Networks</title><categories>eess.SY cs.SY</categories><comments>32 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interconnectivity of cyber and physical systems and Internet of things
has created ubiquitous concerns of cyber threats for enterprise system
managers. It is common that the asset owners and enterprise network operators
need to work with cybersecurity professionals to manage the risk by
remunerating them for their efforts that are not directly observable. In this
paper, we use a principal-agent framework to capture the service relationships
between the two parties, i.e., the asset owner (principal) and the cyber risk
manager (agent). Specifically, we consider a dynamic systemic risk management
problem with asymmetric information where the principal can only observe cyber
risk outcomes of the enterprise network rather than directly the efforts that
the manager expends on protecting the resources. Under this information
pattern, the principal aims to minimize the systemic cyber risks by designing a
dynamic contract that specifies the compensation flows and the anticipated
efforts of the manager by taking into account his incentives and rational
behaviors. We formulate a bi-level mechanism design problem for dynamic
contract design within the framework of a class of stochastic differential
games. We show that the principal has rational controllability of the systemic
risk by designing an incentive compatible estimator of the agent's hidden
efforts. We characterize the optimal solution by reformulating the problem as a
stochastic optimal control program which can be solved using dynamic
programming. We further investigate a benchmark scenario with complete
information and identify conditions that yield zero information rent and lead
to a new certainty equivalence principle for principal-agent problems. Finally,
case studies over networked systems are carried out to illustrate the
theoretical results obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04433</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04433</id><created>2019-08-12</created><updated>2020-01-23</updated><authors><author><keyname>Taheri</keyname><forenames>Hossein</forenames></author><author><keyname>Pedarsani</keyname><forenames>Ramtin</forenames></author><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author></authors><title>Sharp Guarantees for Solving Random Equations with One-Bit Information</title><categories>math.ST cs.IT cs.LG eess.SP math.IT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of a wide class of convex optimization-based
estimators for recovering a signal from corrupted one-bit measurements in
high-dimensions. Our general result predicts sharply the performance of such
estimators in the linear asymptotic regime when the measurement vectors have
entries IID Gaussian. This includes, as a special case, the previously studied
least-squares estimator and various novel results for other popular estimators
such as least-absolute deviations, hinge-loss and logistic-loss. Importantly,
we exploit the fact that our analysis holds for generic convex loss functions
to prove a bound on the best achievable performance across the entire class of
estimators. Numerical simulations corroborate our theoretical findings and
suggest they are accurate even for relatively small problem dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04469</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04469</id><created>2019-08-12</created><authors><author><keyname>Tan</keyname><forenames>Chaowei</forenames></author><author><keyname>Yan</keyname><forenames>Zhennan</forenames></author><author><keyname>Zhang</keyname><forenames>Shaoting</forenames></author><author><keyname>Li</keyname><forenames>Kang</forenames></author><author><keyname>Metaxas</keyname><forenames>Dimitris N.</forenames></author></authors><title>Collaborative Multi-agent Learning for MR Knee Articular Cartilage
  Segmentation</title><categories>eess.IV cs.CV cs.LG cs.MA</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The 3D morphology and quantitative assessment of knee articular cartilages
(i.e., femoral, tibial, and patellar cartilage) in magnetic resonance (MR)
imaging is of great importance for knee radiographic osteoarthritis (OA)
diagnostic decision making. However, effective and efficient delineation of all
the knee articular cartilages in large-sized and high-resolution 3D MR knee
data is still an open challenge. In this paper, we propose a novel framework to
solve the MR knee cartilage segmentation task. The key contribution is the
adversarial learning based collaborative multi-agent segmentation network. In
the proposed network, we use three parallel segmentation agents to label
cartilages in their respective region of interest (ROI), and then fuse the
three cartilages by a novel ROI-fusion layer. The collaborative learning is
driven by an adversarial sub-network. The ROI-fusion layer not only fuses the
individual cartilages from multiple agents, but also backpropagates the
training loss from the adversarial sub-network to each agent to enable joint
learning of shape and spatial constraints. Extensive evaluations are conducted
on a dataset including hundreds of MR knee volumes with diverse populations,
and the proposed method shows superior performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04483</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04483</id><created>2019-08-13</created><updated>2020-02-12</updated><authors><author><keyname>Huynh</keyname><forenames>Khoi Minh</forenames></author><author><keyname>Xu</keyname><forenames>Tiantian</forenames></author><author><keyname>Wu</keyname><forenames>Ye</forenames></author><author><keyname>Chen</keyname><forenames>Geng</forenames></author><author><keyname>Wang</keyname><forenames>Xifeng</forenames></author><author><keyname>Thung</keyname><forenames>Kim-Han</forenames></author><author><keyname>Wu</keyname><forenames>Haiyong</forenames></author><author><keyname>Lin</keyname><forenames>Weili</forenames></author><author><keyname>Shen</keyname><forenames>Dinggang</forenames></author><author><keyname>Yap</keyname><forenames>Pew-Thian</forenames></author></authors><title>Probing Tissue Microarchitecture of the Baby Brain via Spherical Mean
  Spectrum Imaging</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the first years of life, the human brain undergoes dynamic
spatially-heterogeneous changes, involving differentiation of neuronal types,
dendritic arborization, axonal ingrowth, outgrowth and retraction,
synaptogenesis, and myelination. To better quantify these changes, this article
presents a method for probing tissue microarchitecture by characterizing water
diffusion in a spectrum of length scales, factoring out the effects of
intra-voxel orientation heterogeneity. Our method is based on the spherical
means of the diffusion signal, computed over gradient directions for a fixed
set of diffusion weightings (i.e., b-values). We decompose the spherical mean
series at each voxel into a spherical mean spectrum (SMS), which essentially
encodes the fractions of spin packets undergoing fine- to coarse-scale
diffusion processes, characterizing hindered and restricted diffusion stemming
respectively from extra- and intra-neurite water compartments. From the SMS,
multiple orientation distribution invariant indices can be computed, allowing
for example the quantification of neurite density, microscopic fractional
anisotropy ($\mu$FA), per-axon axial/radial diffusivity, and free/restricted
isotropic diffusivity. We show maps of these indices for baby brains,
demonstrating that microscopic tissue features can be extracted from the
developing brain for greater sensitivity and specificity to development related
changes. Also, we demonstrate that our method, called spherical mean spectrum
imaging (SMSI), is fast, accurate, and can overcome the biases associated with
other state-of-the-art microstructure models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04484</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04484</id><created>2019-08-13</created><authors><author><keyname>Kao</keyname><forenames>Sheng-Chun</forenames></author><author><keyname>Yang</keyname><forenames>Chao-Han Huck</forenames></author><author><keyname>Chen</keyname><forenames>Pin-Yu</forenames></author><author><keyname>Ma</keyname><forenames>Xiaoli</forenames></author><author><keyname>Krishna</keyname><forenames>Tushar</forenames></author></authors><title>Reinforcement Learning based Interconnection Routing for Adaptive
  Traffic Optimization</title><categories>cs.NI cs.AI cs.AR cs.LG cs.SY eess.SY</categories><doi>10.1145/3313231.335236</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying Machine Learning (ML) techniques to design and optimize computer
architectures is a promising research direction. Optimizing the runtime
performance of a Network-on-Chip (NoC) necessitates a continuous learning
framework. In this work, we demonstrate the promise of applying reinforcement
learning (RL) to optimize NoC runtime performance. We present three RL-based
methods for learning optimal routing algorithms. The experimental results show
the algorithms can successfully learn a near-optimal solution across different
environment states. Reproducible Code:
github.com/huckiyang/interconnect-routing-gym
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04512</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04512</id><created>2019-08-13</created><authors><author><keyname>Mao</keyname><forenames>Jiageng</forenames></author><author><keyname>Wang</keyname><forenames>Xiaogang</forenames></author><author><keyname>Li</keyname><forenames>Hongsheng</forenames></author></authors><title>Interpolated Convolutional Networks for 3D Point Cloud Understanding</title><categories>cs.CV cs.CG eess.IV</categories><comments>ICCV2019 oral. Code will be released soon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point cloud is an important type of 3D representation. However, directly
applying convolutions on point clouds is challenging due to the sparse,
irregular and unordered data structure. In this paper, we propose a novel
Interpolated Convolution operation, InterpConv, to tackle the point cloud
feature learning and understanding problem. The key idea is to utilize a set of
discrete kernel weights and interpolate point features to neighboring
kernel-weight coordinates by an interpolation function for convolution. A
normalization term is introduced to handle neighborhoods of different sparsity
levels. Our InterpConv is shown to be permutation and sparsity invariant, and
can directly handle irregular inputs. We further design Interpolated
Convolutional Neural Networks (InterpCNNs) based on InterpConv layers to handle
point cloud recognition tasks including shape classification, object part
segmentation and indoor scene semantic parsing. Experiments show that the
networks can capture both fine-grained local structures and global shape
context information effectively. The proposed approach achieves
state-of-the-art performance on public benchmarks including ModelNet40,
ShapeNet Parts and S3DIS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04538</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04538</id><created>2019-08-13</created><authors><author><keyname>Puyol-Ant&#xf3;n</keyname><forenames>Esther</forenames></author><author><keyname>Ruijsink</keyname><forenames>Bram</forenames></author><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Oksuz</keyname><forenames>Ilkay</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author><author><keyname>Razavi</keyname><forenames>Reza</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author></authors><title>Assessing the Impact of Blood Pressure on Cardiac Function Using
  Interpretable Biomarkers and Variational Autoencoders</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintaining good cardiac function for as long as possible is a major concern
for healthcare systems worldwide and there is much interest in learning more
about the impact of different risk factors on cardiac health. The aim of this
study is to analyze the impact of systolic blood pressure (SBP) on cardiac
function while preserving the interpretability of the model using known
clinical biomarkers in a large cohort of the UK Biobank population. We propose
a novel framework that combines deep learning based estimation of interpretable
clinical biomarkers from cardiac cine MR data with a variational autoencoder
(VAE). The VAE architecture integrates a regression loss in the latent space,
which enables the progression of cardiac health with SBP to be learnt. Results
on 3,600 subjects from the UK Biobank show that the proposed model allows us to
gain important insight into the deterioration of cardiac function with
increasing SBP, identify key interpretable factors involved in this process,
and lastly exploit the model to understand patterns of positive and adverse
adaptation of cardiac function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04541</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04541</id><created>2019-08-13</created><updated>2019-08-15</updated><authors><author><keyname>Gao</keyname><forenames>Junyuan</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Wei</keyname><forenames>Fan</forenames></author></authors><title>Random Pilot and Data Access for Massive MIMO Spatially Correlated
  Rayleigh Fading Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>This work was accepted by IEEE Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random access is necessary in crowded scenarios due to the limitation of
pilot sequences and the intermittent pattern of device activity. Nowadays, most
of the related works are based on independent and identically distributed
(i.i.d.) channels. However, massive multiple-input multiple-output (MIMO)
channels are not always i.i.d. in realistic outdoor wireless propagation
environments. In this paper, a device grouping and pilot set allocation
algorithm is proposed for the uplink massive MIMO systems over spatially
correlated Rayleigh fading channels. Firstly, devices are divided into multiple
groups, and the channel covariance matrixes of devices within the same group
are approximately orthogonal. In each group, a dedicated pilot set is assigned.
Then active devices perform random pilot and data access process. The mean
square error of channel estimation (MSE-CE) and the spectral efficiency of this
scheme are derived, and the MSE-CE can be minimized when collision devices have
non-overlapping angle of arrival (AoA) intervals. Simulation results indicate
that the MSE-CE and spectral efficiency of this protocol are improved compared
with the traditional scheme. The MSE-CE of the proposed scheme is close to the
theoretical lower bound over a wide signal-to-noise ratio (SNR) region
especially for long pilot sequence. Furthermore, the MSE-CE performance gains
are significant in high SNR and strongly correlated scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04542</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04542</id><created>2019-08-13</created><authors><author><keyname>Leijsen</keyname><forenames>Reijer L.</forenames></author><author><keyname>Berg</keyname><forenames>Cornelis A. T. van den</forenames></author><author><keyname>Webb</keyname><forenames>Andrew G.</forenames></author><author><keyname>Remis</keyname><forenames>Rob F.</forenames></author><author><keyname>Mandija</keyname><forenames>Stefano</forenames></author></authors><title>Combining Deep Learning and 3D Contrast Source Inversion in MR-based
  Electrical Properties Tomography</title><categories>physics.med-ph eess.IV</categories><comments>8 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance-electrical properties tomography (MR-EPT) is a technique
used to estimate the conductivity and permittivity of tissues from MR
measurements of the transmit magnetic field. Different reconstruction methods
are available, however all these methods present several limitations which
hamper the clinical applicability. Standard Helmholtz based MR-EPT methods are
severely affected by noise. Iterative reconstruction methods such as contrast
source inversion-EPT (CSI-EPT) are typically time consuming and are dependent
on their initialization. Deep learning (DL) based methods require a large
amount of training data before sufficient generalization can be achieved. Here,
we investigate the benefits achievable using a hybrid approach, i.e. using
MR-EPT or DL-EPT as initialization guesses for standard 3D CSI-EPT. Using
realistic electromagnetic simulations at 3 T and 7 T, the accuracy and
precision of hybrid CSI reconstructions are compared to standard 3D CSI-EPT
reconstructions. Our results indicate that a hybrid method consisting of an
initial DL-EPT reconstruction followed by a 3D CSI-EPT reconstruction would be
beneficial. DL-EPT combined with standard 3D CSI-EPT exploits the power of data
driven DL-based EPT reconstructions while the subsequent CSI-EPT facilitates a
better generalization by providing data consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04568</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04568</id><created>2019-08-13</created><updated>2019-12-14</updated><authors><author><keyname>Pisov</keyname><forenames>Maxim</forenames></author><author><keyname>Goncharov</keyname><forenames>Mikhail</forenames></author><author><keyname>Kurochkina</keyname><forenames>Nadezhda</forenames></author><author><keyname>Morozov</keyname><forenames>Sergey</forenames></author><author><keyname>Gombolevskiy</keyname><forenames>Victor</forenames></author><author><keyname>Chernina</keyname><forenames>Valeria</forenames></author><author><keyname>Vladzymyrskyy</keyname><forenames>Anton</forenames></author><author><keyname>Zamyatina</keyname><forenames>Ksenia</forenames></author><author><keyname>Chesnokova</keyname><forenames>Anna</forenames></author><author><keyname>Pronin</keyname><forenames>Igor</forenames></author><author><keyname>Shifrin</keyname><forenames>Michael</forenames></author><author><keyname>Belyaev</keyname><forenames>Mikhail</forenames></author></authors><title>Incorporating Task-Specific Structural Knowledge into CNNs for Brain
  Midline Shift Detection</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Midline shift (MLS) is a well-established factor used for outcome prediction
in traumatic brain injury, stroke and brain tumors. The importance of automatic
estimation of MLS was recently highlighted by ACR Data Science Institute. In
this paper we introduce a novel deep learning based approach for the problem of
MLS detection, which exploits task-specific structural knowledge. We evaluate
our method on a large dataset containing heterogeneous images with significant
MLS and show that its mean error approaches the inter-expert variability.
Finally, we show the robustness of our approach by validating it on an external
dataset, acquired during routine clinical practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04594</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04594</id><created>2019-08-13</created><authors><author><keyname>Herbst</keyname><forenames>Gernot</forenames></author></authors><title>A Building-Block Approach to State-Space Modeling of DC-DC Converter
  Systems</title><categories>eess.SY cs.SY</categories><journal-ref>J, vol. 2, no. 3, pp. 247-267, Jul. 2019</journal-ref><doi>10.3390/j2030018</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Small-signal models of DC-DC converters are often based on a state-space
averaging approach, from which both control-oriented and other frequency-domain
characteristics, such as input or output impedance, can be derived. Updating
these models when extending the converter by filters or non-trivial loads, or
adding control loops, can become a tedious task, however. To simplify this
potentially error-prone process, a modular modeling approach is being proposed
in this article. It consists of small state-space models for certain building
blocks of a converter system on the one hand, and standardized operations for
connecting these subsystem models to an overall converter system model on the
other hand. The resulting state-space system model builds upon a two-port
converter description and allows the extraction of control-oriented and
impedance characteristics at any modeling stage, be it open loop or closed
loop, single converter or series connections of converters. The ease of
creating more complex models enabled by the proposed approach is also
demonstrated with examples comprising multiple control loops or cascaded
converters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04596</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04596</id><created>2019-08-13</created><authors><author><keyname>Herbst</keyname><forenames>Gernot</forenames></author></authors><title>A Simulative Study on Active Disturbance Rejection Control (ADRC) as a
  Control Tool for Practitioners</title><categories>eess.SY cs.SY</categories><journal-ref>Electronics, vol. 2, no. 3, pp. 246-279, Aug. 2013</journal-ref><doi>10.3390/electronics2030246</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As an alternative to both classical PID-type and modern model-based
approaches to solving control problems, active disturbance rejection control
(ADRC) has gained significant traction in recent years. With its simple tuning
method and robustness against process parameter variations, it puts itself
forward as a valuable addition to the toolbox of control engineering
practitioners. This article aims at providing a single-source introduction and
reference to linear ADRC with this audience in mind. A simulative study is
carried out using generic first- and second-order plants to enable a quick
visual assessment of the abilities of ADRC. Finally, a modified form of the
discrete-time case is introduced to speed up real-time implementations as
necessary in applications with high dynamic requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04610</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04610</id><created>2019-08-13</created><authors><author><keyname>Herbst</keyname><forenames>Gernot</forenames></author></authors><title>Practical Active Disturbance Rejection Control: Bumpless Transfer, Rate
  Limitation and Incremental Algorithm</title><categories>eess.SY cs.SY</categories><journal-ref>IEEE Transactions on Industrial Electronics, vol. 63, no. 3, pp.
  1754-1762, March 2016</journal-ref><doi>10.1109/TIE.2015.2499168</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Practical applications of controllers often impose further requirements on
the implementation beyond the actual control performance, such as the ability
to switch between manual and automatic control or between different control
laws or controller parameter settings, known as bumpless transfer. Another
common requirement is to limit the control signal in magnitude and/or rate.
This article examines and extends several discrete-time variants of active
disturbance rejection control (ADRC), which is increasingly being applied
especially in the field of power electronics and drives, in this regard.
Detailed guidelines for practical ADRC implementations with these abilities are
presented, and all features are being demonstrated with the help of simulation
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04633</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04633</id><created>2019-08-13</created><authors><author><keyname>Cheng</keyname><forenames>Qian</forenames></author><author><keyname>Fusco</keyname><forenames>Vincent</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Wang</keyname><forenames>Shilian</forenames></author><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author></authors><title>WFRFT-aided Power-efficient Multi-beam Directional Modulation Schemes
  Based on Frequency Diverse Array</title><categories>eess.SP</categories><comments>accepted by IEEE Transactions on Wireless Communications, 16 pages,
  12 figures</comments><doi>10.1109/TWC.2019.2934462</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The artificial noise (AN) aided multi-beam directional modulation (DM)
technology is capable of wireless physical layer secure (PLS) transmissions for
multiple desired receivers in free space. The application of AN, however, makes
it less power-efficient for such a DM system. To address this problem, the
weighted fractional Fourier transform (WFRFT) technology is employed in this
paper to achieve power-efficient multi-beam DM transmissions. Specifically, a
power-efficient multi-beam WFRFT-DM scheme with cooperative receivers and a
power-efficient multi-beam WFRFT-DM scheme with independent receivers are
proposed based on frequency diverse array (FDA), respectively. The bit error
rate (BER), secrecy rate, and robustness of the proposed multi-beam WFRFT-DM
schemes are analyzed. Simulations demonstrate that 1) the proposed multi-beam
WFRFT-DM schemes are more power-efficient than the conventional multi-beam
AN-DM scheme; 2) the transmission security can also be guaranteed even if the
eavesdroppers are located close to or the same as the desired receivers; and 3)
the proposed multi-beam WFRFT-DM schemes are capable of independent
transmissions for different desired receivers with different modulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04648</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04648</id><created>2019-08-13</created><authors><author><keyname>Cheng</keyname><forenames>Qian</forenames></author><author><keyname>Fusco</keyname><forenames>Vincent</forenames></author><author><keyname>Wang</keyname><forenames>Shilian</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author></authors><title>A Two-Ray Multipath Model for Frequency Diverse Array-Based Directional
  Modulation in MISOME Wiretap Channels</title><categories>eess.SP</categories><comments>accepted by IEEE VTC2019-Fall, 5 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-ray multipath model for frequency diverse array (FDA)-based directional
modulation (DM) is proposed in multi-input single-output multi-eavesdropper
(MISOME) wiretap channels for the first time. The excitation factors of the FDA
and the weighting coefficients of the inserted artificial noise (AN) are
jointly designed in a way which imposes no impact on the desired receiver while
simultaneously distorting the received signals of eavesdroppers. Secrecy rate
is analyzed for the proposed two-ray multipath FDA-based DM model. Numerical
simulations verify the capability of physical layer secure (PLS) transmissions
of the proposed FDA-DM model in two-ray multipath MISOME wiretap channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04650</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04650</id><created>2019-08-13</created><authors><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Ratnarajah</keyname><forenames>Tharmalingam</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author></authors><title>On Range Sidelobe Reduction for Dual-functional Radar-Communication
  Waveforms</title><categories>eess.SP</categories><comments>4 pages, 4 figures, submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel waveform design for multi-input
multi-output (MIMO) dual-functional radar-communication systems by taking the
range sidelobe control into consideration. In particular, we focus on
optimizing the weighted summation of communication and radar metrics under
per-antenna power budget. While the formulated optimization problem is
non-convex, we develop a first-order descent algorithm by exploiting the
manifold structure of its feasible region, which finds a near-optimal solution
within a low computational overhead. Numerical results show that the proposed
waveform design outperforms the conventional techniques by improving the
communication rate while reducing the range sidelobe level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04672</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04672</id><created>2019-08-13</created><authors><author><keyname>Matt</keyname><forenames>Amogh</forenames></author><author><keyname>Stowell</keyname><forenames>Dan</forenames></author></authors><title>Estimating &amp; Mitigating the Impact of Acoustic Environments on
  Machine-to-Machine Signalling</title><categories>eess.AS cs.SD eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The advance of technology for transmitting Data-over-Sound in various IoT and
telecommunication applications has led to the concept of machine-to-machine
over-the-air acoustic signalling. Reverberation can have a detrimental effect
on such machine-to-machine signals while decoding. Various methods have been
studied to combat the effects of reverberation in speech and audio signals, but
it is not clear how well they generalise to other sound types. We look at
extending these models to facilitate machine-to-machine acoustic signalling.
This research investigates dereverberation techniques to shortlist a
single-channel reverberation suppression method through a pilot test. In order
to apply the chosen dereverberation method a novel method of estimating
acoustic parameters governing reverberation is proposed. The performance of the
final algorithm is evaluated on quality metrics as well as the performance of a
real machine-to-machine decoder. We demonstrate a dramatic reduction in error
rate for both audible and ultrasonic signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04682</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04682</id><created>2019-08-11</created><updated>2019-11-27</updated><authors><author><keyname>Mishra</keyname><forenames>Amit</forenames></author><author><keyname>Reddy</keyname><forenames>Pranath</forenames></author><author><keyname>Nigam</keyname><forenames>Rahul</forenames></author></authors><title>CMB-GAN: Fast Simulations of Cosmic Microwave background anisotropy maps
  using Deep Learning</title><categories>astro-ph.CO cs.LG eess.IV</categories><comments>9 pages, cosmic microwave background radiation, deep learning,
  generative adversarial network. arXiv admin note: text overlap with
  arXiv:1903.12253</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cosmic Microwave Background (CMB) has been a cornerstone in many cosmology
experiments and studies since it was discovered back in 1964. Traditional
computational models like CAMB that are used for generating CMB temperature
anisotropy maps are extremely resource intensive and act as a bottleneck in
cosmology experiments that require a large amount of CMB data for analysis. In
this paper, we present a new approach to the generation of CMB temperature maps
using a specific class of neural networks called Generative Adversarial Network
(GAN). We train our deep generative model to learn the complex distribution of
CMB maps and efficiently generate new sets of CMB data in the form of 2D
patches of anisotropy maps without losing much accuracy. We limit our
experiment to the generation of 56$^{\circ}$ and 112$^{\circ}$ square patches
of CMB maps. We have also trained a Multilayer perceptron model for estimation
of baryon density from a CMB map, we will be using this model for the
performance evaluation of our generative model using diagnostic measures like
Histogram of pixel intensities, the standard deviation of pixel intensity
distribution, Power Spectrum, Cross power spectrum, Correlation matrix of the
power spectrum and Peak count. We show that the GAN model is able to
efficiently generate CMB samples of multiple sizes and is sensitive to the
cosmological parameters corresponding to the underlying distribution of the
data. The primiary advantage of this method is the exponential reduction in the
computational time needed to generate the CMB data, the GAN model is able to
generate the samples within seconds as opposed to hours required by the CAMB
package with an acceptable value to error and loss of information. We hope that
future iterations of this methodology will replace traditional statistical
methods of CMB data generation and help in large scale cosmological
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04685</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04685</id><created>2019-08-11</created><authors><author><keyname>Wang</keyname><forenames>Liang</forenames></author><author><keyname>Ye</keyname><forenames>Hao</forenames></author><author><keyname>Liang</keyname><forenames>Le</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Learn to Compress CSI and Allocate Resources in Vehicular Networks</title><categories>eess.SP cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1908.03447</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource allocation has a direct and profound impact on the performance of
vehicle-to-everything (V2X) networks. In this paper, we develop a hybrid
architecture consisting of centralized decision making and distributed resource
sharing (the C-Decision scheme) to maximize the long-term sum rate of all
vehicles. To reduce the network signaling overhead, each vehicle uses a deep
neural network to compress its observed information that is thereafter fed back
to the centralized decision making unit. The centralized decision unit employs
a deep Q-network to allocate resources and then sends the decision results to
all vehicles. We further adopt a quantization layer for each vehicle that
learns to quantize the continuous feedback. In addition, we devise a mechanism
to balance the transmission of vehicle-to-vehicle (V2V) links and
vehicle-to-infrastructure (V2I) links. To further facilitate distributed
spectrum sharing, we also propose a distributed decision making and spectrum
sharing architecture (the D-Decision scheme) for each V2V link. Through
extensive simulation results, we demonstrate that the proposed C-Decision and
D-Decision schemes can both achieve near-optimal performance and are robust to
feedback interval variations, input noise, and feedback noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04689</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04689</id><created>2019-08-12</created><authors><author><keyname>Yang</keyname><forenames>Zhaohui</forenames></author><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Hou</keyname><forenames>Jiancao</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>Efficient Resource Allocation for Mobile-Edge Computing Networks with
  NOMA: Completion Time and Energy Minimization</title><categories>cs.IT eess.SP math.IT</categories><comments>30 pages, 9 figures. arXiv admin note: text overlap with
  arXiv:1809.01084</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper investigates an uplink non-orthogonal multiple access (NOMA)-based
mobile-edge computing (MEC) network. Our objective is to minimize a linear
combination of the completion time of all users' tasks and the total energy
consumption of all users including transmission energy and local computation
energy subject to computation latency, uploading data rate, time sharing and
edge cloud capacity constraints. This work can significantly improve the energy
efficiency and end-to-end delay of the applications in future wireless
networks. For the general minimization problem, it is first transformed into an
equivalent form. Then, an iterative algorithm is accordingly proposed, where
closed-form solution is obtained in each step. For the special case with only
minimizing the completion time, we propose a bisection-based algorithm to
obtain the optimal solution. Also for the special case with infinite cloud
capacity, we show that the original minimization problem can be transformed
into an equivalent convex one. Numerical results show the superiority of the
proposed algorithms compared with conventional algorithms in terms of
completion time and energy consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04696</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04696</id><created>2019-08-13</created><authors><author><keyname>Daptardar</keyname><forenames>Saurabh</forenames></author><author><keyname>Schrater</keyname><forenames>Paul</forenames></author><author><keyname>Pitkow</keyname><forenames>Xaq</forenames></author></authors><title>Inverse Rational Control with Partially Observable Continuous Nonlinear
  Dynamics</title><categories>cs.AI cs.SY eess.SY q-bio.NC</categories><comments>8 pages plus references</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continuous control and planning remains a major challenge in robotics and
machine learning. Neuroscience offers the possibility of learning from animal
brains that implement highly successful controllers, but it is unclear how to
relate an animal's behavior to control principles. Animals may not always act
optimally from the perspective of an external observer, but may still act
rationally: we hypothesize that animals choose actions with highest expected
future subjective value according to their own internal model of the world.
Their actions thus result from solving a different optimal control problem from
those on which they are evaluated in neuroscience experiments. With this
assumption, we propose a novel framework of model-based inverse rational
control that learns the agent's internal model that best explains their actions
in a task described as a partially observable Markov decision process (POMDP).
In this approach we first learn optimal policies generalized over the entire
model space of dynamics and subjective rewards, using an extended Kalman filter
to represent the belief space, a neural network in the actor-critic framework
to optimize the policy, and a simplified basis for the parameter space. We then
compute the model that maximizes the likelihood of the experimentally
observable data comprising the agent's sensory observations and chosen actions.
Our proposed method is able to recover the true model of simulated agents
within theoretical error bounds given by limited data. We illustrate this
method by applying it to a complex naturalistic task currently used in
neuroscience experiments. This approach provides a foundation for interpreting
the behavioral and neural dynamics of highly adapted controllers in animal
brains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04701</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04701</id><created>2019-08-13</created><authors><author><keyname>Dikici</keyname><forenames>Engin</forenames></author><author><keyname>Ryu</keyname><forenames>John L.</forenames></author><author><keyname>Demirer</keyname><forenames>Mutlu</forenames></author><author><keyname>Bigelow</keyname><forenames>Matthew</forenames></author><author><keyname>White</keyname><forenames>Richard D.</forenames></author><author><keyname>Slone</keyname><forenames>Wayne</forenames></author><author><keyname>Erdal</keyname><forenames>Barbaros Selnur</forenames></author><author><keyname>Prevedello</keyname><forenames>Luciano M.</forenames></author></authors><title>Automated Brain Metastases Detection Framework for T1-Weighted
  Contrast-Enhanced 3D MRI</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain Metastases (BM) complicate 20-40% of cancer cases. BM lesions can
present as punctate (1 mm) foci, requiring high-precision Magnetic Resonance
Imaging (MRI) in order to prevent inadequate or delayed BM treatment. However,
BM lesion detection remains challenging partly due to their structural
similarities to normal structures (e.g., vasculature). We propose a
BM-detection framework using a single-sequence gadolinium-enhanced T1-weighted
3D MRI dataset. The framework focuses on detection of smaller (&lt; 15 mm) BM
lesions and consists of: (1) candidate-selection stage, using Laplacian of
Gaussian approach for highlighting parts of a MRI volume holding higher BM
occurrence probabilities, and (2) detection stage that iteratively processes
cropped region-of-interest volumes centered by candidates using a custom-built
3D convolutional neural network (&quot;CropNet&quot;). Data is augmented extensively
during training via a pipeline consisting of random gamma correction and
elastic deformation stages; the framework thereby maintains its invariance for
a plausible range of BM shape and intensity representations. This approach is
tested using five-fold cross-validation on 217 datasets from 158 patients, with
training and testing groups randomized per patient to eliminate learning bias.
The BM database included lesions with a mean diameter of ~5.4 mm and a mean
volume of ~160 mm3. For 90% BM-detection sensitivity, the framework produced on
average 9.12 false-positive BM detections per patient (standard deviation of
3.49); for 85% sensitivity, the average number of false-positives declined to
5.85. Comparative analysis showed that the framework produces comparable
BM-detection accuracy with the state-of-art approaches validated for
significantly larger lesions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04702</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04702</id><created>2019-08-13</created><authors><author><keyname>Bermudez</keyname><forenames>Camilo</forenames></author><author><keyname>Blaber</keyname><forenames>Justin</forenames></author><author><keyname>Remedios</keyname><forenames>Samuel W.</forenames></author><author><keyname>Reynolds</keyname><forenames>Jess E.</forenames></author><author><keyname>Lebel</keyname><forenames>Catherine</forenames></author><author><keyname>McHugo</keyname><forenames>Maureen</forenames></author><author><keyname>Heckers</keyname><forenames>Stephan</forenames></author><author><keyname>Huo</keyname><forenames>Yuankai</forenames></author><author><keyname>Landman</keyname><forenames>Bennett A.</forenames></author></authors><title>Generalizing Deep Whole Brain Segmentation for Pediatric and
  Post-Contrast MRI with Augmented Transfer Learning</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalizability is an important problem in deep neural networks, especially
in the context of the variability of data acquisition in clinical magnetic
resonance imaging (MRI). Recently, the Spatially Localized Atlas Network Tiles
(SLANT) approach has been shown to effectively segment whole brain non-contrast
T1w MRI with 132 volumetric labels. Enhancing generalizability of SLANT would
enable broader application of volumetric assessment in multi-site studies.
Transfer learning (TL) is commonly used to update the neural network weights
for local factors; yet, it is commonly recognized to risk degradation of
performance on the original validation/test cohorts. Here, we explore TL by
data augmentation to address these concerns in the context of adapting SLANT to
anatomical variation and scanning protocol. We consider two datasets: First, we
optimize for age with 30 T1w MRI of young children with manually corrected
volumetric labels, and accuracy of automated segmentation defined relative to
the manually provided truth. Second, we optimize for acquisition with 36 paired
datasets of pre- and post-contrast clinically acquired T1w MRI, and accuracy of
the post-contrast segmentations assessed relative to the pre-contrast automated
assessment. For both studies, we augment the original TL step of SLANT with
either only the new data or with both original and new data. Over baseline
SLANT, both approaches yielded significantly improved performance (signed rank
tests; pediatric: 0.89 vs. 0.82 DSC, p&lt;0.001; contrast: 0.80 vs 0.76, p&lt;0.001).
The performance on the original test set decreased with the new-data only
transfer learning approach, so data augmentation was superior to strict
transfer learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04737</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04737</id><created>2019-08-13</created><authors><author><keyname>Denisov</keyname><forenames>Pavel</forenames></author><author><keyname>Vu</keyname><forenames>Ngoc Thang</forenames></author></authors><title>End-to-End Multi-Speaker Speech Recognition using Speaker Embeddings and
  Transfer Learning</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Interspeech 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents our latest investigation on end-to-end automatic speech
recognition (ASR) for overlapped speech. We propose to train an end-to-end
system conditioned on speaker embeddings and further improved by transfer
learning from clean speech. This proposed framework does not require any
parallel non-overlapped speech materials and is independent of the number of
speakers. Our experimental results on overlapped speech datasets show that
joint conditioning on speaker embeddings and transfer learning significantly
improves the ASR performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04743</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04743</id><created>2019-08-13</created><authors><author><keyname>Denisov</keyname><forenames>Pavel</forenames></author><author><keyname>Vu</keyname><forenames>Ngoc Thang</forenames></author></authors><title>IMS-Speech: A Speech to Text Tool</title><categories>cs.CL cs.SD eess.AS</categories><comments>ESSV 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present the IMS-Speech, a web based tool for German and English speech
transcription aiming to facilitate research in various disciplines which
require accesses to lexical information in spoken language materials. This tool
is based on modern open source software stack, advanced speech recognition
methods and public data resources and is freely available for academic
researchers. The utilized models are built to be generic in order to provide
transcriptions of competitive accuracy on a diverse set of tasks and
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04751</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04751</id><created>2019-08-09</created><authors><author><keyname>Abavisani</keyname><forenames>Ali</forenames></author><author><keyname>Hasegawa-Johnson</keyname><forenames>Mark A</forenames></author></authors><title>The role of cue enhancement and frequency fine-tuning in hearing
  impaired phone recognition</title><categories>q-bio.QM cs.SD eess.AS</categories><comments>16 pages, 10 figures, proceedings of the Acoustical Society of
  America meeting, May 2019, Louisville, KY</comments><doi>10.1121/1.5101104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A speech-based hearing test is designed to identify the susceptible
error-prone phones for individual hearing impaired (HI) ear. Only robust tokens
in the experiment noise levels had been chosen for the test. The
noise-robustness of tokens is measured as SNR90 of the token, which is the
signal to the speech-weighted noise ratio where a normal hearing (NH) listener
would recognize the token with an accuracy of 90% on average. Two sets of
tokens T1 and T2 having the same consonant-vowels but different talkers with
distinct SNR90 had been presented with flat gain at listeners' most comfortable
level. We studied the effects of frequency fine-tuning of the primary cue by
presenting tokens of the same consonant but different vowels with similar
SNR90. Additionally, we investigated the role of changing the intensity of
primary cue in HI phone recognition, by presenting tokens from both sets T1 and
T2. On average, 92% of tokens are improved when we replaced the CV with the
same CV but with a more robust talker. Additionally, using CVs with similar
SNR90, on average, tokens are improved by 75%, 71%, 63%, and 72%, when we
replaced vowels /A, ae, I, E/, respectively. The confusion pattern in each case
provides insight into how these changes affect the phone recognition in each HI
ear. We propose to prescribe hearing aid amplification tailored to individual
HI ears, based on the confusion pattern, the response from cue enhancement, and
the response from frequency fine-tuning of the cue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04752</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04752</id><created>2019-08-10</created><updated>2019-11-11</updated><authors><author><keyname>Xu</keyname><forenames>Tongda</forenames></author><author><keyname>Cai</keyname><forenames>Xiyan</forenames></author><author><keyname>Wang</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Xiuyuan</forenames></author><author><keyname>Chung</keyname><forenames>Sohae</forenames></author><author><keyname>Fieremans</keyname><forenames>Els</forenames></author><author><keyname>Rath</keyname><forenames>Joseph</forenames></author><author><keyname>Flanagan</keyname><forenames>Steven</forenames></author><author><keyname>Lui</keyname><forenames>Yvonne W</forenames></author></authors><title>Identification of relevant diffusion MRI metrics impacting cognitive
  functions using a novel feature selection method</title><categories>eess.IV cs.LG q-bio.QM stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mild Traumatic Brain Injury (mTBI) is a significant public health problem.
The most troubling symptoms after mTBI are cognitive complaints. Studies show
measurable differences between patients with mTBI and healthy controls with
respect to tissue microstructure using diffusion MRI. However, it remains
unclear which diffusion measures are the most informative with regard to
cognitive functions in both the healthy state as well as after injury. In this
study, we use diffusion MRI to formulate a predictive model for performance on
working memory based on the most relevant MRI features. The key challenge is to
identify relevant features over a large feature space with high accuracy in an
efficient manner. To tackle this challenge, we propose a novel improvement of
the best first search approach with crossover operators inspired by genetic
algorithm. Compared against other heuristic feature selection algorithms, the
proposed method achieves significantly more accurate predictions and yields
clinically interpretable selected features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04767</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04767</id><created>2019-08-12</created><authors><author><keyname>Marzahl</keyname><forenames>Christian</forenames></author><author><keyname>Aubreville</keyname><forenames>Marc</forenames></author><author><keyname>Bertram</keyname><forenames>Christof A.</forenames></author><author><keyname>Stayt</keyname><forenames>Jason</forenames></author><author><keyname>Jasensky</keyname><forenames>Anne-Katherine</forenames></author><author><keyname>Bartenschlager</keyname><forenames>Florian</forenames></author><author><keyname>Fragoso-Garcia</keyname><forenames>Marco</forenames></author><author><keyname>Barton</keyname><forenames>Ann K.</forenames></author><author><keyname>Elsemann</keyname><forenames>Svenja</forenames></author><author><keyname>Jabari</keyname><forenames>Samir</forenames></author><author><keyname>Krauth</keyname><forenames>Jens</forenames></author><author><keyname>Madhu</keyname><forenames>Prathmesh</forenames></author><author><keyname>Voigt</keyname><forenames>J&#xf6;rn</forenames></author><author><keyname>Hill</keyname><forenames>Jenny</forenames></author><author><keyname>Klopfleisch</keyname><forenames>Robert</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Deep Learning-Based Quantification of Pulmonary Hemosiderophages in
  Cytology Slides</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Exercise-induced pulmonary hemorrhage (EIPH) is a common syndrome in
sport horses with negative impact on performance. Cytology of bronchoalveolar
lavage fluid by use of a scoring system is considered the most sensitive
diagnostic method. Macrophages are classified depending on the degree of
cytoplasmic hemosiderin content. The current gold standard is manual grading,
which is however monotonous and time-consuming. Methods: We evaluated
state-of-the-art deep learning-based methods for single cell macrophage
classification and compared them against the performance of nine cytology
experts and evaluated inter- and intra-observer variability. Additionally, we
evaluated object detection methods on a novel data set of 17 completely
annotated cytology whole slide images (WSI) containing 78,047 hemosiderophages.
Resultsf: Our deep learning-based approach reached a concordance of 0.85,
partially exceeding human expert concordance (0.68 to 0.86, $\mu$=0.73,
$\sigma$ =0.04). Intra-observer variability was high (0.68 to 0.88) and
inter-observer concordance was moderate (Fleiss kappa = 0.67). Our object
detection approach has a mean average precision of 0.66 over the five classes
from the whole slide gigapixel image and a computation time of below two
minutes. Conclusion: To mitigate the high inter- and intra-rater variability,
we propose our automated object detection pipeline, enabling accurate,
reproducible and quick EIPH scoring in WSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04769</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04769</id><created>2019-08-09</created><updated>2019-08-13</updated><authors><author><keyname>Li</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Dvornek</keyname><forenames>Nicha C.</forenames></author><author><keyname>Zhuang</keyname><forenames>Juntang</forenames></author><author><keyname>Ventola</keyname><forenames>Pamela</forenames></author><author><keyname>Duncan</keyname><forenames>James</forenames></author></authors><title>Graph Embedding Using Infomax for ASD Classification and Brain
  Functional Difference Detection</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Significant progress has been made using fMRI to characterize the brain
changes that occur in ASD, a complex neuro-developmental disorder. However, due
to the high dimensionality and low signal-to-noise ratio of fMRI, embedding
informative and robust brain regional fMRI representations for both graph-level
classification and region-level functional difference detection tasks between
ASD and healthy control (HC) groups is difficult. Here, we model the whole
brain fMRI as a graph, which preserves geometrical and temporal information and
use a Graph Neural Network (GNN) to learn from the graph-structured fMRI data.
We investigate the potential of including mutual information (MI) loss
(Infomax), which is an unsupervised term encouraging large MI of each nodal
representation and its corresponding graph-level summarized representation to
learn a better graph embedding. Specifically, this work developed a pipeline
including a GNN encoder, a classifier and a discriminator, which forces the
encoded nodal representations to both benefit classification and reveal the
common nodal patterns in a graph. We simultaneously optimize graph-level
classification loss and Infomax. We demonstrated that Infomax graph embedding
improves classification performance as a regularization term. Furthermore, we
found separable nodal representations of ASD and HC groups in prefrontal
cortex, cingulate cortex, visual regions, and other social, emotional and
execution related brain regions. In contrast with GNN with classification loss
only, the proposed pipeline can facilitate training more robust ASD
classification models. Moreover, the separable nodal representations can detect
the functional differences between the two groups and contribute to revealing
new ASD biomarkers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04780</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04780</id><created>2019-08-13</created><authors><author><keyname>Chen</keyname><forenames>Kewei</forenames></author><author><keyname>Ghavidel</keyname><forenames>Donya</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author><author><keyname>Huang</keyname><forenames>Yih-Fang</forenames></author></authors><title>Distributed Estimation in the Presence of Strategic Data Sources</title><categories>eess.SP cs.SY eess.SY</categories><doi>10.1109/TSP.2019.2954974</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed estimation that recruits potentially large groups of humans to
collect data about a phenomenon of interest has emerged as a paradigm
applicable to a broad range of detection and estimation tasks. However, it also
presents a number of challenges especially with regard to user participation
and data quality, since the data resources may be strategic human agents
instead of physical sensors. We consider a static estimation problem in which
an estimator collects data from self-interested agents. Since it incurs cost to
participate, mechanisms to incentivize the agents to collect and transmit data
of desired quality are needed. Agents are strategic in the sense that they can
take measurement with different levels of accuracy by expending different
levels of effort. They may also misreport their information in order to obtain
greater compensation, if possible. With both the measurements from the agents
and their accuracy unknown to the estimator, we design incentive mechanisms
that encourage desired behavior from strategic agents. Specifically, we solve
an optimization problem at the estimator which minimizes the expected total
compensation to the agents while guaranteeing a specified quality of the global
estimate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04809</identifier>
 <datestamp>2020-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04809</id><created>2019-08-13</created><authors><author><keyname>Fu</keyname><forenames>Jie</forenames></author><author><keyname>Singhrao</keyname><forenames>Kamal</forenames></author><author><keyname>Cao</keyname><forenames>Minsong</forenames></author><author><keyname>Yu</keyname><forenames>Victoria</forenames></author><author><keyname>Santhanam</keyname><forenames>Anand P.</forenames></author><author><keyname>Yang</keyname><forenames>Yingli</forenames></author><author><keyname>Guo</keyname><forenames>Minghao</forenames></author><author><keyname>Raldow</keyname><forenames>Ann C.</forenames></author><author><keyname>Ruan</keyname><forenames>Dan</forenames></author><author><keyname>Lewis</keyname><forenames>John H.</forenames></author></authors><title>Generation of abdominal synthetic CTs from 0.35T MR images using
  generative adversarial networks for MR-only liver radiotherapy</title><categories>physics.med-ph eess.IV</categories><comments>Review in progress</comments><journal-ref>2020 Biomed. Phys. Eng. Express</journal-ref><doi>10.1088/2057-1976/ab6e1f</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electron density maps must be accurately estimated to achieve valid dose
calculation in MR-only radiotherapy. The goal of this study is to assess
whether two deep learning models, the conditional generative adversarial
network (cGAN) and the cycle-consistent generative adversarial network
(cycleGAN), can generate accurate abdominal synthetic CT (sCT) images from
0.35T MR images for MR-only liver radiotherapy. A retrospective study was
performed using CT images and 0.35T MR images of 12 patients with liver (n=8)
and non-liver abdominal (n=4) cancer. CT images were deformably registered to
the corresponding MR images to generate deformed CT (dCT) images for treatment
planning. Both cGAN and cycleGAN were trained using MR and dCT transverse
slices. Four-fold cross-validation testing was conducted to generate sCT images
for all patients. The HU prediction accuracy was evaluated by voxel-wise
similarity metric between each dCT and sCT image for all 12 patients. dCT-based
and sCT-based dose distributions were compared using gamma and dose-volume
histogram (DVH) metric analysis for 8 liver patients. sCTcycleGAN achieved the
average mean absolute error (MAE) of 94.1 HU, while sCTcGAN achieved 89.8 HU.
In both models, the average gamma passing rates within all volumes of interest
were higher than 95% using a 2%, 2 mm criterion, and 99% using a 3%, 3 mm
criterion. The average differences in the mean dose and DVH metrics were within
+/-0.6% for the planning target volume and within +/-0.15% for evaluated organs
in both models. Results demonstrated that abdominal sCT images generated by
both cGAN and cycleGAN achieved accurate dose calculation for 8 liver
radiotherapy plans. sCTcGAN images had smaller average MAE and achieved better
dose calculation accuracy than sCTcyleGAN images. More abdominal patients will
be enrolled in the future to further evaluate two models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04840</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04840</id><created>2019-08-13</created><authors><author><keyname>Rajan</keyname><forenames>Ronnie</forenames></author><author><keyname>Sathish</keyname><forenames>Rachana</forenames></author><author><keyname>Sheet</keyname><forenames>Debdoot</forenames></author></authors><title>Significance of Residual Learning and Boundary Weighted Loss in
  Ischaemic Stroke Lesion Segmentation</title><categories>eess.IV</categories><comments>International Conference on Medical Imaging with Deep Learning
  (MIDL), 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SyeOMoR4q4</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Radiologists use various imaging modalities to aid in different tasks like
diagnosis of disease, lesion visualization, surgical planning and prognostic
evaluation. Most of these tasks rely on the the accurate delineation of the
anatomical morphology of the organ, lesion or tumor. Deep learning frameworks
can be designed to facilitate automated delineation of the region of interest
in such cases with high accuracy. Performance of such automated frameworks for
medical image segmentation can be improved with efficient integration of
information from multiple modalities aided by suitable learning strategies. In
this direction, we show the effectiveness of residual network trained
adversarially in addition to a boundary weighted loss. The proposed methodology
is experimentally verified on the SPES-ISLES 2015 dataset for ischaemic stroke
segmentation with an average Dice coefficient of $0.881$ for penumbra and
$0.877$ for core. It was observed that addition of residual connections and
boundary weighted loss improved the performance significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04848</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04848</id><created>2019-08-13</created><authors><author><keyname>G&#xf6;&#xdf;ling</keyname><forenames>Nico</forenames></author><author><keyname>Middelberg</keyname><forenames>Wiebke</forenames></author><author><keyname>Doclo</keyname><forenames>Simon</forenames></author></authors><title>RTF-steered binaural MVDR beamforming incorporating multiple external
  microphones</title><categories>eess.AS cs.SD</categories><comments>To appear at WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The binaural minimum-variance distortionless-response (BMVDR) beamformer is a
well-known noise reduction algorithm that can be steered using the relative
transfer function (RTF) vector of the desired speech source. Exploiting the
availability of an external microphone that is spatially separated from the
head-mounted microphones, an efficient method has been recently proposed to
estimate the RTF vector in a diffuse noise field. When multiple external
microphones are available, different RTF vector estimates can be obtained by
using this method for each external microphone. In this paper, we propose
several procedures to combine these RTF vector estimates, either by selecting
the estimate corresponding to the highest input SNR, by averaging the estimates
or by combining the estimates in order to maximize the output SNR of the BMVDR
beamformer. Experimental results for a moving speaker and diffuse noise in a
reverberant environment show that the output SNR-maximizing combination yields
the largest binaural SNR improvement and also outperforms the state-of-the art
covariance whitening method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04863</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04863</id><created>2019-08-13</created><updated>2020-02-18</updated><authors><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Ren</keyname><forenames>Hong</forenames></author><author><keyname>Wang</keyname><forenames>Kezhi</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Intelligent Reflecting Surface Aided MIMO Broadcasting for Simultaneous
  Wireless Information and Power Transfer</title><categories>eess.SP</categories><comments>Accepted in IEEE JSAC</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An intelligent reflecting surface (IRS) is invoked for enhancing the energy
harvesting performance of a simultaneous wireless information and power
transfer (SWIPT) aided system. Specifically, an IRS-assisted SWIPT system is
considered, where a multi-antenna aided base station (BS) communicates with
several multi-antenna assisted information receivers (IRs), while guaranteeing
the energy harvesting requirement of the energy receivers (ERs). To maximize
the weighted sum rate (WSR) of IRs, the transmit precoding (TPC) matrices of
the BS and passive phase shift matrix of the IRS should be jointly optimized.
To tackle this challenging optimization problem, we first adopt the classic
block coordinate descent (BCD) algorithm for decoupling the original
optimization problem into several subproblems and alternatively optimize the
TPC matrices and the phase shift matrix. For each subproblem, we provide a
low-complexity iterative algorithm, which is guaranteed to converge to the
Karush-Kuhn-Tucker (KKT) point of each subproblem. The BCD algorithm is
rigorously proved to converge to the KKT point of the original problem. We also
conceive a feasibility checking method to study its feasibility. Our extensive
simulation results confirm that employing IRSs in SWIPT beneficially enhances
the system performance and the proposed BCD algorithm converges rapidly, which
is appealing for practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04887</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04887</id><created>2019-08-13</created><authors><author><keyname>Dong</keyname><forenames>Yanjie</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Jahangir</forenames></author><author><keyname>Cheng</keyname><forenames>Julian</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Cross-Layer Scheduling and Beamforming in Smart Grid Powered Small-Cell
  Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>This work was accepted by IEEE ICC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the small-cell networks (SCNs) with multiple small-cell base stations
(ScBSs), the joint design of beamforming vectors, user scheduling and ScBS
sleeping is investigated with the constraints on proportional rate. A long-term
grid-energy expenditure minimization problem is formulated for the considered
SCNs, which are powered by the smart grid and natural renewable energy. Since
the scheduled user indicators are coupled with the beamforming vectors, the
formulated problem is challenging to handle. In order to decouple the
beamforming vectors from the scheduled user indicators, the Lyapunov
optimization technique is used. As a result, a practical two-scale algorithm is
proposed to allocate the user scheduling indicators and ScBS sleeping variables
at the coarse-grained granularity (frame) as well as obtain the beamforming
vectors at the fine-grained granularity (slot). Numerical results are used to
verify the performance of the proposed two-scale algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04924</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04924</id><created>2019-08-13</created><authors><author><keyname>Bai</keyname><forenames>Mingyuan</forenames></author><author><keyname>Choy</keyname><forenames>S. T. Boris</forenames></author><author><keyname>Song</keyname><forenames>Xin</forenames></author><author><keyname>Gao</keyname><forenames>Junbin</forenames></author></authors><title>Tensor-Train Parameterization for Ultra Dimensionality Reduction</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Locality preserving projections (LPP) are a classical dimensionality
reduction method based on data graph information. However, LPP is still
responsive to extreme outliers. LPP aiming for vectorial data may undermine
data structural information when it is applied to multidimensional data.
Besides, it assumes the dimension of data to be smaller than the number of
instances, which is not suitable for high-dimensional data. For
high-dimensional data analysis, the tensor-train decomposition is proved to be
able to efficiently and effectively capture the spatial relations. Thus, we
propose a tensor-train parameterization for ultra dimensionality reduction
(TTPUDR) in which the traditional LPP mapping is tensorized in terms of
tensor-trains and the LPP objective is replaced with the Frobenius norm to
increase the robustness of the model. The manifold optimization technique is
utilized to solve the new model. The performance of TTPUDR is assessed on
classification problems and TTPUDR significantly outperforms the past methods
and the several state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04940</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.04940</id><created>2019-08-13</created><authors><author><keyname>Sahin</keyname><forenames>Alphan</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Lou</keyname><forenames>Hanqing</forenames></author><author><keyname>Yang</keyname><forenames>Rui</forenames></author></authors><title>Low-PAPR Multi-channel OOK Waveform for IEEE 802.11ba Wake-up Radio</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear in IEEE GLOBECOM'19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The peak-to-average-power ratio (PAPR) of the frequency domain multiplexed
wake-up signals (WUSs) specified in IEEE P802.11ba can be very large and
difficult to manage since it depends on the number and allocation of the active
channels, and the data rate on each channel. To address this issue, we propose
a transmission scheme based on complementary sequences (CSs) for multiple WUSs
multiplexed in the frequency domain. We discuss how to construct CSs compatible
with the framework of IEEE P802.11ba by exploiting a recursive Golay
complementary pair (GCP) construction to reduce the instantaneous power
fluctuations in time. We compare the proposed scheme with the other options
under a non-linear power amplifier (PA) distortion. Numerical results show that
the proposed scheme can lower the PAPR of the transmitted signal in frequency
division multiple access (FDMA) scenarios more than 3 dB and yields a superior
error rate performance under severe PA distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05005</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05005</id><created>2019-08-14</created><authors><author><keyname>Kamann</keyname><forenames>Christoph</forenames></author><author><keyname>Rother</keyname><forenames>Carsten</forenames></author></authors><title>Benchmarking the Robustness of Semantic Segmentation Models</title><categories>cs.CV eess.IV</categories><comments>24 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When designing a semantic segmentation module for a practical application,
such as autonomous driving, it is crucial to understand the robustness of the
module with respect to a wide range of image corruptions. While there are
recent robustness studies for full-image classification, we are the first to
present an exhaustive study for semantic segmentation, based on the
state-of-the-art model DeepLabv3$+$. To increase the realism of our study, we
utilize almost 200,000 images generated from Cityscapes and PASCAL VOC 2012,
and we furthermore present a realistic noise model, imitating HDR camera noise.
Based on the benchmark study we gain several new insights. Firstly, model
robustness increases with model performance, in most cases. Secondly, some
architecture properties affect robustness significantly, such as a Dense
Prediction Cell which was designed to maximize performance on clean data only.
Thirdly, to achieve good generalization with respect to various types of image
noise, it is recommended to train DeepLabv3+ with our realistic noise model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05007</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05007</id><created>2019-08-14</created><authors><author><keyname>Lee</keyname><forenames>Seung Jae</forenames></author><author><keyname>Kim</keyname><forenames>Seung Hyun</forenames></author><author><keyname>Kim</keyname><forenames>H. Jin</forenames></author></authors><title>Robust Translational Force Control of Multi-Rotor UAV for Precise
  Acceleration Tracking</title><categories>cs.RO cs.SY eess.SY</categories><comments>11 pages, 14 figures, Accepted in the T-ASE Journal on Aug. 10th,
  2019</comments><doi>10.1109/TASE.2019.2935792</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we introduce a translational force control method with
disturbance observer (DOB)-based force disturbance cancellation for precise
three-dimensional acceleration control of a multi-rotor UAV. The acceleration
control of the multi-rotor requires conversion of the desired acceleration
signal to the desired roll, pitch, and total thrust. But because the attitude
dynamics and the thrust dynamics are different, simple kinematic signal
conversion without consideration of those difference can cause serious
performance degradation in acceleration tracking. Unlike most existing
translational force control techniques that are based on such simple inversion,
our new method allows controlling the acceleration of the multi-rotor more
precisely by considering the dynamics of the multi-rotor during the kinematic
inversion. By combining the DOB with the translational force system that
includes the improved conversion technique, we achieve robustness with respect
to the external force disturbances that hinders the accurate acceleration
control. mu-analysis is performed to ensure the robust stability of the overall
closed-loop system, considering the combined effect of various possible model
uncertainties. Both simulation and experiment are conducted to validate the
proposed technique, which confirms the satisfactory performance to track the
desired acceleration of the multi-rotor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05020</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05020</id><created>2019-08-14</created><authors><author><keyname>Gadiya</keyname><forenames>Shrey</forenames></author><author><keyname>Anand</keyname><forenames>Deepak</forenames></author><author><keyname>Sethi</keyname><forenames>Amit</forenames></author></authors><title>Histographs: Graphs in Histopathology</title><categories>eess.IV cs.CV</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial arrangement of cells of various types, such as tumor infiltrating
lymphocytes and the advancing edge of a tumor, are important features for
detecting and characterizing cancers. However, convolutional neural networks
(CNNs) do not explicitly extract intricate features of the spatial arrangements
of the cells from histopathology images. In this work, we propose to classify
cancers using graph convolutional networks (GCNs) by modeling a tissue section
as a multi-attributed spatial graph of its constituent cells. Cells are
detected using their nuclei in H&amp;E stained tissue image, and each cell's
appearance is captured as a multi-attributed high-dimensional vertex feature.
The spatial relations between neighboring cells are captured as edge features
based on their distances in a graph. We demonstrate the utility of this
approach by obtaining classification accuracy that is competitive with CNNs,
specifically, Inception-v3, on two tasks-cancerous versus non-cancerous and in
situ versus invasive-on the BACH breast cancer dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05033</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05033</id><created>2019-08-14</created><authors><author><keyname>Gong</keyname><forenames>Ruihao</forenames></author><author><keyname>Liu</keyname><forenames>Xianglong</forenames></author><author><keyname>Jiang</keyname><forenames>Shenghu</forenames></author><author><keyname>Li</keyname><forenames>Tianxiang</forenames></author><author><keyname>Hu</keyname><forenames>Peng</forenames></author><author><keyname>Lin</keyname><forenames>Jiazhen</forenames></author><author><keyname>Yu</keyname><forenames>Fengwei</forenames></author><author><keyname>Yan</keyname><forenames>Junjie</forenames></author></authors><title>Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit
  Neural Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>IEEE ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hardware-friendly network quantization (e.g., binary/uniform quantization)
can efficiently accelerate the inference and meanwhile reduce memory
consumption of the deep neural networks, which is crucial for model deployment
on resource-limited devices like mobile phones. However, due to the
discreteness of low-bit quantization, existing quantization methods often face
the unstable training process and severe performance degradation. To address
this problem, in this paper we propose Differentiable Soft Quantization (DSQ)
to bridge the gap between the full-precision and low-bit networks. DSQ can
automatically evolve during training to gradually approximate the standard
quantization. Owing to its differentiable property, DSQ can help pursue the
accurate gradients in backward propagation, and reduce the quantization loss in
forward process with an appropriate clipping range. Extensive experiments over
several popular network structures show that training low-bit neural networks
with DSQ can consistently outperform state-of-the-art quantization methods.
Besides, our first efficient implementation for deploying 2 to 4-bit DSQ on
devices with ARM architecture achieves up to 1.7$\times$ speed up, compared
with the open-source 8-bit high-performance inference framework NCNN. [31]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05062</identifier>
 <datestamp>2020-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05062</id><created>2019-08-14</created><updated>2020-02-26</updated><authors><author><keyname>Roth</keyname><forenames>Karsten</forenames></author><author><keyname>Hesser</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Konopczy&#x144;ski</keyname><forenames>Tomasz</forenames></author></authors><title>Mask Mining for Improved Liver Lesion Segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel procedure to improve liver and lesion segmentation from CT
scans for U-Net based models. Our method extends standard segmentation
pipelines to focus on higher target recall or reduction of noisy false-positive
predictions, boosting overall segmentation performance. To achieve this, we
include segmentation errors into a new learning process appended to the main
training setup, allowing the model to find features which explain away previous
errors. We evaluate this on semantically distinct architectures: cascaded two-
and three-dimensional as well as combined learning setups for multitask
segmentation. Liver and lesion segmentation data are provided by the Liver
Tumor Segmentation challenge (LiTS), with an increase in dice score of up to 2
points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05077</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05077</id><created>2019-08-14</created><authors><author><keyname>Moura</keyname><forenames>Jose</forenames></author><author><keyname>Hutchison</keyname><forenames>David</forenames></author></authors><title>Cyber-Physical Systems Resilience: State of the Art, Research Issues and
  Future Trends</title><categories>cs.CR cs.NI cs.SY eess.SY</categories><comments>42 pages, 7 figures, 9 tables, 168 references, submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ideally, full integration is needed between the Internet and Cyber-Physical
Systems (CPSs). These systems should fulfil time-sensitive functions with
variable levels of integration with their environment, incorporating data
storage, computation, communications, sensing, and control. There are, however,
significant problems emerging from the convergence between CPS and Internet of
Things (IoT) areas. The high heterogeneity, complexity, and dynamics of these
resource-constrained systems bring new challenges to their robust and reliable
operation, which implies the need for novel resilience management strategies.
This paper surveys the state of the art in the relevant fields and, discusses
the research issues and future trends that emerge. Thus, we hope to provide new
insights into the management of resilient CPSs, formed by IoT devices, modelled
by Game Theory, and flexibly programmed using the latest software and
virtualization platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05085</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05085</id><created>2019-08-14</created><authors><author><keyname>Anagnostopoulos</keyname><forenames>Grigorios G.</forenames></author><author><keyname>Kalousis</keyname><forenames>Alexandros</forenames></author></authors><title>A Reproducible Comparison of RSSI Fingerprinting Localization Methods
  Using LoRaWAN</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of fingerprinting localization techniques in outdoor IoT settings has
started to gain popularity over the recent years. Communication signals of Low
Power Wide Area Networks (LPWAN), such as LoRaWAN, are used to estimate the
location of low power mobile devices. In this study, a publicly available
dataset of LoRaWAN RSSI measurements is utilized to compare different machine
learning methods and their accuracy in producing location estimates. The tested
methods are: the k Nearest Neighbours method, the Extra Trees method and a
neural network approach using a Multilayer Perceptron. To facilitate the
reproducibility of tests and the comparability of results, the code and the
train/validation/test split of the dataset used in this study have become
available. The neural network approach was the method with the highest
accuracy, achieving a mean error of 358 meters and a median error of 204
meters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05087</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05087</id><created>2019-08-14</created><authors><author><keyname>Xu</keyname><forenames>Ziyi</forenames></author><author><keyname>Elshamy</keyname><forenames>Samy</forenames></author><author><keyname>Zhao</keyname><forenames>Ziyue</forenames></author><author><keyname>Fingscheidt</keyname><forenames>Tim</forenames></author></authors><title>Components Loss for Neural Networks in Mask-Based Speech Enhancement</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating time-frequency domain masks for single-channel speech enhancement
using deep learning methods has recently become a popular research field with
promising results. In this paper, we propose a novel components loss (CL) for
the training of neural networks for mask-based speech enhancement. During the
training process, the proposed CL offers separate control over preservation of
the speech component quality, suppression of the residual noise component, and
preservation of a naturally sounding residual noise component. We illustrate
the potential of the proposed CL by evaluating a standard convolutional neural
network (CNN) for mask-based speech enhancement. The new CL obtains a better
and more balanced performance in almost all employed instrumental quality
metrics over the baseline losses, the latter comprising the conventional mean
squared error (MSE) loss and also auditory-related loss functions, such as the
perceptual evaluation of speech quality (PESQ) loss and the recently proposed
perceptual weighting filter loss. Particularly, applying the CL offers better
speech component quality, better overall enhanced speech perceptual quality, as
well as a more naturally sounding residual noise. On average, an at least 0.1
points higher PESQ score on the enhanced speech is obtained while also
obtaining a higher SNR improvement by more than 0.5 dB, for seen noise types.
This improvement is stronger for unseen noise types, where an about 0.2 points
higher PESQ score on the enhanced speech is obtained, while also the output SNR
is ahead by more than 0.5 dB. The new proposed CL is easy to implement and code
is provided at https://github.com/ifnspaml/Components-Loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05094</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05094</id><created>2019-08-14</created><authors><author><keyname>Tao</keyname><forenames>Xumin</forenames></author><author><keyname>Wei</keyname><forenames>Hongrong</forenames></author><author><keyname>Xue</keyname><forenames>Wufeng</forenames></author><author><keyname>Ni</keyname><forenames>Dong</forenames></author></authors><title>Segmentation of Multimodal Myocardial Images Using Shape-Transfer GAN</title><categories>eess.IV cs.CV</categories><comments>accepted by STACOM 21019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Myocardium segmentation of late gadolinium enhancement (LGE) Cardiac MR
images is important for evaluation of infarction regions in clinical practice.
The pathological myocardium in LGE images presents distinctive brightness and
textures compared with the healthy tissues, making it much more challenging to
be segment. Instead, the balanced-Steady State Free Precession (bSSFP) cine
images show clearly boundaries and can be easily segmented. Given this fact, we
propose a novel shape-transfer GAN for LGE images, which can 1) learn to
generate realistic LGE images from bSSFP with the anatomical shape preserved,
and 2) learn to segment the myocardium of LGE images from these generated
images. It's worth to note that no segmentation label of the LGE images is used
during this procedure. We test our model on dataset from the Multi-sequence
Cardiac MR Segmentation Challenge. The results show that the proposed
Shape-Transfer GAN can achieve accurate myocardium masks of LGE images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05104</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05104</id><created>2019-08-14</created><authors><author><keyname>Zhou</keyname><forenames>Yongjin</forenames></author><author><keyname>Huang</keyname><forenames>Weijian</forenames></author><author><keyname>Dong</keyname><forenames>Pei</forenames></author><author><keyname>Xia</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author></authors><title>D-UNet: a dimension-fusion U shape network for chronic stroke lesion
  segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assessing the location and extent of lesions caused by chronic stroke is
critical for medical diagnosis, surgical planning, and prognosis. In recent
years, with the rapid development of 2D and 3D convolutional neural networks
(CNN), the encoder-decoder structure has shown great potential in the field of
medical image segmentation. However, the 2D CNN ignores the 3D information of
medical images, while the 3D CNN suffers from high computational resource
demands. This paper proposes a new architecture called dimension-fusion-UNet
(D-UNet), which combines 2D and 3D convolution innovatively in the encoding
stage. The proposed architecture achieves a better segmentation performance
than 2D networks, while requiring significantly less computation time in
comparison to 3D networks. Furthermore, to alleviate the data imbalance issue
between positive and negative samples for the network training, we propose a
new loss function called Enhance Mixing Loss (EML). This function adds a
weighted focal coefficient and combines two traditional loss functions. The
proposed method has been tested on the ATLAS dataset and compared to three
state-of-the-art methods. The results demonstrate that the proposed method
achieves the best quality performance in terms of DSC = 0.5349+0.2763 and
precision = 0.6331+0.295).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05108</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05108</id><created>2019-08-14</created><authors><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Liu</keyname><forenames>Zhi</forenames></author><author><keyname>Ren</keyname><forenames>Fuji</forenames></author></authors><title>WiFi-based Real-time Breathing and Heart Rate Monitoring during Sleep</title><categories>cs.HC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Good quality sleep is essential for good health and sleep monitoring becomes
a vital research topic. This paper provides a low cost, continuous and
contactless WiFi-based vital signs (breathing and heart rate) monitoring
method. In particular, we set up the antennas based on Fresnel diffraction
model and signal propagation theory, which enhances the detection of weak
breathing/heartbeat motion. We implement a prototype system using the off-shelf
devices and a real-time processing system to monitor vital signs in real time.
The experimental results indicate the accurate breathing rate and heart rate
detection performance. To the best of our knowledge, this is the first work to
use a pair of WiFi devices and omnidirectional antennas to achieve real-time
individual breathing rate and heart rate monitoring in different sleeping
postures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05125</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05125</id><created>2019-08-14</created><authors><author><keyname>Ortega</keyname><forenames>Romeo</forenames></author><author><keyname>Aranovskiy</keyname><forenames>Stanislav</forenames></author><author><keyname>Pyrkin</keyname><forenames>Anton A.</forenames></author><author><keyname>Astolfi</keyname><forenames>Alessandro</forenames></author><author><keyname>Bobtsov</keyname><forenames>Alexey A.</forenames></author></authors><title>New Results on Parameter Estimation via Dynamic Regressor Extension and
  Mixing: Continuous and Discrete-time Cases</title><categories>eess.SY cs.PF cs.SY</categories><comments>8 pages, 7 figures, under review in IEEE TAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present some new results on the dynamic regressor extension and mixing
parameter estimators for linear regression models recently proposed in the
literature. This technique has proven instrumental in the solution of several
open problems in system identification and adaptive control. The new results
include: (i) a unified treatment of the continuous and the discrete-time cases;
(ii) the proposal of two new extended regressor matrices, one which guarantees
a quantifiable transient performance improvement, and the other exponential
convergence under conditions that are strictly weaker than regressor
persistence of excitation; and (iii) an alternative estimator ensuring
parameter estimation in finite-time that retains its alertness to track
time-varying parameters. Simulations that illustrate our results are also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05133</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05133</id><created>2019-08-14</created><authors><author><keyname>Choi</keyname><forenames>Byungjoo</forenames></author><author><keyname>Lee</keyname><forenames>Gaang</forenames></author><author><keyname>Jebelli</keyname><forenames>Houtan</forenames></author><author><keyname>Lee</keyname><forenames>SangHyun</forenames></author></authors><title>Assessing Workers Perceived Risk During Construction Task Using A
  Wristband-Type Biosensor</title><categories>eess.SP cs.HC</categories><journal-ref>Proceedings of the Creative Construction Conference (CCC 2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction industry has demonstrated a high frequency and severity of
accidents. Construction accidents are the result of the interaction between
unsafe work conditions and workers unsafe behaviors. Given this relation,
perceived risk is determined by an individual response to a potential work
hazard during the work. As such, risk perception is critical to understand
workers unsafe behaviors. Established methods of assessing workers perceived
risk have mainly relied on surveys and interviews. However, these post-hoc
methods, which are limited to monitoring dynamic changes in risk perception and
conducting surveys at a construction site, may prove cumbersome to workers.
Additionally, these methods frequently suffer from self-reported bias. To
overcome the limitations of previous subjective measures, this study aims to
develop a framework for the objective and continuous prediction of construction
workers perceived risk using physiological signals [e.g., electrodermal
activity (EDA)] acquired from workers wristband-type biosensors. To achieve
this objective, physiological signals were collected from eight construction
workers while they performed regular tasks in the field. Various filtering
methods were applied to exclude noises recorded in the signal and to extract
various features of the signals as workers experienced different risk levels.
Then, a supervised machine-learning model was trained to explore the
applicability of the collected physiological signals for the prediction of risk
perception. The results showed that features based on EDA data collected from
wristbands are feasible and useful to the process of continuously monitoring
workers perceived risk during ongoing work. This study contributes to an
in-depth understanding of construction workers perceived risk by developing a
noninvasive means of continuously monitoring workers perceived risk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05168</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05168</id><created>2019-08-14</created><authors><author><keyname>Michelini</keyname><forenames>Pablo Navarrete</forenames></author><author><keyname>Liu</keyname><forenames>Hanwen</forenames></author><author><keyname>Lu</keyname><forenames>Yunhua</forenames></author><author><keyname>Jiang</keyname><forenames>Xingqun</forenames></author></authors><title>A Tour of Convolutional Networks Guided by Linear Interpreters</title><categories>cs.CV cs.LG cs.NA eess.IV math.NA</categories><comments>To appear in ICCV 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Convolutional networks are large linear systems divided into layers and
connected by non-linear units. These units are the &quot;articulations&quot; that allow
the network to adapt to the input. To understand how a network manages to solve
a problem we must look at the articulated decisions in entirety. If we could
capture the actions of non-linear units for a particular input, we would be
able to replay the whole system back and forth as if it was always linear. It
would also reveal the actions of non-linearities because the resulting linear
system, a Linear Interpreter, depends on the input image. We introduce a
hooking layer, called a LinearScope, which allows us to run the network and the
linear interpreter in parallel. Its implementation is simple, flexible and
efficient. From here we can make many curious inquiries: how do these linear
systems look like? When the rows and columns of the transformation matrix are
images, how do they look like? What type of basis do these linear
transformations rely on? The answers depend on the problems presented, through
which we take a tour to some popular architectures used for classification,
super-resolution (SR) and image-to-image translation (I2I). For classification
we observe that popular networks use a pixel-wise vote per class strategy and
heavily rely on bias parameters. For SR and I2I we find that CNNs use
wavelet-type basis similar to the human visual system. For I2I we reveal
copy-move and template-creation strategies to generate outputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05182</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05182</id><created>2019-08-14</created><authors><author><keyname>Doire</keyname><forenames>Clement S. J.</forenames></author><author><keyname>Okubadejo</keyname><forenames>Olumide</forenames></author></authors><title>Interleaved Multitask Learning for Audio Source Separation with
  Independent Databases</title><categories>cs.SD cs.LG eess.AS</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Neural Network-based source separation methods usually train independent
models to optimize for the separation of individual sources. Although this can
lead to good performance for well-defined targets, it can also be
computationally expensive. The multitask alternative of a single network
jointly optimizing for all targets simultaneously usually requires the
availability of all target sources for each input. This requirement hampers the
ability to create large training databases. In this paper, we present a model
that decomposes the learnable parameters into a shared parametric model
(encoder) and independent components (decoders) specific to each source. We
propose an interleaved training procedure that optimizes the sub-task decoders
independently and thus does not require each sample to possess a ground truth
for all of its composing sources. Experimental results on MUSDB18 with the
proposed method show comparable performance to independently trained models,
with less trainable parameters, more efficient inference, and an encoder
transferable to future target objectives. The results also show that using the
proposed interleaved training procedure leads to better Source-to-Interference
energy ratios when compared to the simultaneous optimization of all training
objectives, even when all composing sources are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05188</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05188</id><created>2019-08-14</created><authors><author><keyname>Fiederer</keyname><forenames>Lukas D. J.</forenames></author><author><keyname>Alwanni</keyname><forenames>Hisham</forenames></author><author><keyname>V&#xf6;lker</keyname><forenames>Martin</forenames></author><author><keyname>Schnell</keyname><forenames>Oliver</forenames></author><author><keyname>Beck</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Ball</keyname><forenames>Tonio</forenames></author></authors><title>A Research Framework for Virtual Reality Neurosurgery Based on
  Open-Source Tools</title><categories>cs.HC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully immersive virtual reality (VR) has the potential to improve
neurosurgical planning. For example, it may offer 3D visualizations of relevant
anatomical structures with complex shapes, such as blood vessels and tumors.
However, there is a lack of research tools specifically tailored for this area.
We present a research framework for VR neurosurgery based on open-source tools
and preliminary evaluation results. We showcase the potential of such a
framework using clinical data of two patients and research data of one subject.
As a first step toward practical evaluations, two certified senior
neurosurgeons positively assessed the usefulness of the VR visualizations using
head-mounted displays. The methods and findings described in our study thus
provide a foundation for research and development aiming at versatile and
user-friendly VR tools for improving neurosurgical planning and training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05191</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05191</id><created>2019-08-14</created><authors><author><keyname>Saadatmand</keyname><forenames>Sepehr</forenames></author><author><keyname>Sanjarinia</keyname><forenames>Mohammad Saleh</forenames></author><author><keyname>Shamsi</keyname><forenames>Pourya</forenames></author><author><keyname>Ferdowsi</keyname><forenames>Mehdi</forenames></author></authors><title>Dual Heuristic Dynamic Programing Control of Grid-Connected
  Synchronverters</title><categories>eess.SY cs.NE cs.SY</categories><comments>NAPS 2019 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new approach to control a grid-connected synchronverter by
using a dual heuristic dynamic programing (DHP) design is presented. The
disadvantages of conventional synchronverter controller such as the challenges
to cope with nonlinearity, uncertainties, and non-inductive grids are
discussed.To deal with the aforementioned challenges a neural network based
adaptive critic design is introduced to optimize the associated cost function.
The characteristic of the neural networks facilitates the performance under
uncertainties and unknown parameters (for example different power angles). The
proposed DHP design includes three neural networks: system NN, action NN, and
critic NN. The simulation results compare the performance of the proposed DHP
with a traditional PI-based design and with a neural network predictive
controller. It is shown a well trained DHP design performs in a trajectory,
which is more optimal compared to the other two controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05199</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05199</id><created>2019-08-14</created><authors><author><keyname>Saadatmand</keyname><forenames>Sepehr</forenames></author><author><keyname>Sanjarinia</keyname><forenames>Mohammad Saleh</forenames></author><author><keyname>Shamsi</keyname><forenames>Pourya</forenames></author><author><keyname>Ferdowsi</keyname><forenames>Mehdi</forenames></author><author><keyname>Wunsch</keyname><forenames>Donald C.</forenames></author></authors><title>Neural Network Predictive Controller for Grid-Connected Virtual
  Synchronous Generator</title><categories>cs.NE cs.SY eess.SY</categories><comments>NAPS 2019 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a neural network predictive controller is proposed to regulate
the active and the reactive power delivered to the grid generated by a
three-phase virtual inertia-based inverter. The concept of the conventional
virtual synchronous generator (VSG) is discussed, and it is shown that when the
inverter is connected to non-inductive grids, the conventional PI-based VSGs
are unable to perform acceptable tracking. The concept of the neural network
predictive controller is also discussed to replace the traditional VSGs. This
replacement enables inverters to perform in both inductive and non-inductive
grids. The simulation results confirm that a well-trained neural network
predictive controller illustrates can adapt to any grid impedance angle,
compared to the traditional PI-based virtual inertia controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05209</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05209</id><created>2019-08-14</created><updated>2019-12-16</updated><authors><author><keyname>Majumdar</keyname><forenames>Anirudha</forenames></author><author><keyname>Hall</keyname><forenames>Georgina</forenames></author><author><keyname>Ahmadi</keyname><forenames>Amir Ali</forenames></author></authors><title>A Survey of Recent Scalability Improvements for Semidefinite Programming
  with Applications in Machine Learning, Control, and Robotics</title><categories>math.OC cs.LG cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Historically, scalability has been a major challenge to the successful
application of semidefinite programming in fields such as machine learning,
control, and robotics. In this paper, we survey recent approaches for
addressing this challenge including (i) approaches for exploiting structure
(e.g., sparsity and symmetry) in a problem, (ii) approaches that produce
low-rank approximate solutions to semidefinite programs, (iii) more scalable
algorithms that rely on augmented Lagrangian techniques and the alternating
direction method of multipliers, and (iv) approaches that trade off scalability
with conservatism (e.g., by approximating semidefinite programs with linear and
second-order cone programs). For each class of approaches we provide a
high-level exposition, an entry-point to the corresponding literature, and
examples drawn from machine learning, control, or robotics. We also present a
list of software packages that implement many of the techniques discussed in
the paper. Our hope is that this paper will serve as a gateway to the rich and
exciting literature on scalable semidefinite programming for both theorists and
practitioners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05216</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05216</id><created>2019-08-01</created><authors><author><keyname>Ghafourian</keyname><forenames>Amin</forenames></author><author><keyname>Georgiou</keyname><forenames>Orestis</forenames></author><author><keyname>Barter</keyname><forenames>Edmund</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Wireless localization with diffusion maps</title><categories>eess.SP physics.soc-ph</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Wireless Localization Matching Problem (WLMP) the challenge is to
match pieces of equipment with a set of candidate locations based on wireless
signal measurements taken by the pieces of equipment. This challenge is
complicated by the noise that is inherent in wireless signal measurements. Here
we propose the use of diffusion maps, a manifold learning technique, to obtain
an embedding of positions and equipment coordinates in a space that enables
coordinate comparison and reliable evaluation of assignment quality at very low
computational cost. We show that the mapping is robust to noise and using
diffusion maps allows for accurate matching in a realistic setting. This
suggests that the diffusion-map-based approach could significantly increase the
accuracy of wireless localization in applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05227</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05227</id><created>2019-08-08</created><authors><author><keyname>Dey</keyname><forenames>Subhadeep</forenames></author><author><keyname>Motlicek</keyname><forenames>Petr</forenames></author><author><keyname>Bui</keyname><forenames>Trung</forenames></author><author><keyname>Dernoncourt</keyname><forenames>Franck</forenames></author></authors><title>Exploiting semi-supervised training through a dropout regularization in
  end-to-end speech recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Interspeech 2019</comments><msc-class>62H30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore various approaches for semi supervised learning in
an end to end automatic speech recognition (ASR) framework. The first step in
our approach involves training a seed model on the limited amount of labelled
data. Additional unlabelled speech data is employed through a data selection
mechanism to obtain the best hypothesized output, further used to retrain the
seed model. However, uncertainties of the model may not be well captured with a
single hypothesis. As opposed to this technique, we apply a dropout mechanism
to capture the uncertainty by obtaining multiple hypothesized text transcripts
of an speech recording. We assume that the diversity of automatically generated
transcripts for an utterance will implicitly increase the reliability of the
model. Finally, the data selection process is also applied on these
hypothesized transcripts to reduce the uncertainty. Experiments on freely
available TEDLIUM corpus and proprietary Adobe's internal dataset show that the
proposed approach significantly reduces ASR errors, compared to the baseline
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05235</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05235</id><created>2019-08-08</created><authors><author><keyname>Sutavani</keyname><forenames>S</forenames></author><author><keyname>Sonam</keyname><forenames>K</forenames></author><author><keyname>Wagh</keyname><forenames>S</forenames></author><author><keyname>Singh</keyname><forenames>N</forenames></author></authors><title>Disturbance Decoupling and Instantaneous Fault Detection in Boolean
  Control Networks</title><categories>eess.SY cs.SY math.LO math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The literature available on disturbance decoupling (DD) of Boolean control
network (BCN) is built on a restrictive notion of what constitutes as
disturbance decoupling. The results available on necessary and sufficient
conditions are of limited applicability because of their stringent
requirements. This work tries to expand the notion of DD in BCN to incorporate
a larger number of systems deemed unsuitable for DD. The methods available are
further restrictive in the sense that system is forced to follow trajectory
unaffected by the disturbances rather than decoupling disturbances while the
system follows its natural course. Some sufficient conditions are provided
under which the problem can be addressed. This work tries to establish the
notion of disturbance decoupling via feedback control,analogous to the
classical control theory. This approach though, is not limited to DD problems
and can be extended to the general control problems of BCNs. Determination of
observability, which is sufficient for the fault detection, is proven to be
NP-hard for Boolean Control Network. Algorithms based on reconstructability, a
necessary condition, of BCN turn out to be of exponential complexity in
general.In such cases it makes sense to search for the availability of some
special structure in BCN that could be utilized for fault detection with
minimal computational efforts. An attempt is made to address this problem by
introducing instantaneous fault detection (IFD) and providing necessary and
sufficient conditions for the same. Later necessary and sufficient conditions
are proposed for solving the problem of instantaneous fault detection along
with disturbance decoupling using a single controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05244</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05244</id><created>2019-08-14</created><authors><author><keyname>Idehen</keyname><forenames>Ikponmwosa</forenames></author><author><keyname>Jang</keyname><forenames>Wonhyeok</forenames></author><author><keyname>Overbye</keyname><forenames>Thomas</forenames></author></authors><title>PMU Data Feature Considerations for Realistic, Synthetic Data Generation</title><categories>eess.SY cs.SY</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is critical that the qualities and features of synthetically-generated,
PMU measurements used for grid analysis matches those of measurements obtained
from field-based PMUs. This ensures that analysis results generated by
researchers during grid studies replicate those outcomes typically expected by
engineers in real-life situations. In this paper, essential features associated
with industry PMU-derived data measurements are analyzed for input
considerations in the generation of vast amounts of synthetic power system
data. Inherent variabilities in PMU data as a result of the random dynamics in
power system operations, oscillatory contents, and the prevalence of bad data
are presented. Statistical results show that in the generation of large
datasets of synthetic, grid measurements, an inclusion of different data
anomalies, ambient oscillation contents, and random cases of missing data
samples due to packet drops helps to improve the realism of experimental data
used in power systems analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05256</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05256</id><created>2019-08-14</created><authors><author><keyname>P&#xe9;rez-Dattari</keyname><forenames>Rodrigo</forenames></author><author><keyname>Celemin</keyname><forenames>Carlos</forenames></author><author><keyname>Ruiz-del-Solar</keyname><forenames>Javier</forenames></author><author><keyname>Kober</keyname><forenames>Jens</forenames></author></authors><title>Continuous Control for High-Dimensional State Spaces: An Interactive
  Learning Approach</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY</categories><comments>7 pages, 8 figures, IEEE International Conference on Robotics and
  Automation (ICRA 2019)</comments><msc-class>68T05, 68T40, 93C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Reinforcement Learning (DRL) has become a powerful methodology to solve
complex decision-making problems. However, DRL has several limitations when
used in real-world problems (e.g., robotics applications). For instance, long
training times are required and cannot be accelerated in contrast to simulated
environments, and reward functions may be hard to specify/model and/or to
compute. Moreover, the transfer of policies learned in a simulator to the
real-world has limitations (reality gap). On the other hand, machine learning
methods that rely on the transfer of human knowledge to an agent have shown to
be time efficient for obtaining well performing policies and do not require a
reward function. In this context, we analyze the use of human corrective
feedback during task execution to learn policies with high-dimensional state
spaces, by using the D-COACH framework, and we propose new variants of this
framework. D-COACH is a Deep Learning based extension of COACH (COrrective
Advice Communicated by Humans), where humans are able to shape policies through
corrective advice. The enhanced version of D-COACH, which is proposed in this
paper, largely reduces the time and effort of a human for training a policy.
Experimental results validate the efficiency of the D-COACH framework in three
different problems (simulated and with real robots), and show that its enhanced
version reduces the human training effort considerably, and makes it feasible
to learn policies within periods of time in which a DRL agent do not reach any
improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05285</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05285</id><created>2019-08-14</created><authors><author><keyname>Corona</keyname><forenames>Veronica</forenames></author><author><keyname>Benning</keyname><forenames>Martin</forenames></author><author><keyname>Gladden</keyname><forenames>Lynn F.</forenames></author><author><keyname>Reci</keyname><forenames>Andi</forenames></author><author><keyname>Sederman</keyname><forenames>Andrew J.</forenames></author><author><keyname>Schoenlieb</keyname><forenames>Carola-Bibiane</forenames></author></authors><title>Joint phase reconstruction and magnitude segmentation from
  velocity-encoded MRI data</title><categories>eess.IV cs.NA math.NA</categories><comments>22 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Velocity-encoded MRI is an imaging technique used in different areas to
assess flow motion. Some applications include medical imaging such as
cardiovascular blood flow studies, and industrial settings in the areas of
rheology, pipe flows, and reactor hydrodynamics, where the goal is to
characterise dynamic components of some quantity of interest. The problem of
estimating velocities from such measurements is a nonlinear dynamic inverse
problem. To retrieve time-dependent velocity information, careful mathematical
modelling and appropriate regularisation is required. In this work, we propose
an optimisation algorithm based on non-convex Bregman iteration to jointly
estimate velocity-, magnitude- and segmentation-information for the application
of bubbly flow imaging. Furthermore, we demonstrate through numerical
experiments on synthetic and real data that the joint model improves velocity,
magnitude and segmentation over a classical sequential approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05308</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05308</id><created>2019-08-14</created><authors><author><keyname>Nickel</keyname><forenames>Ulrich</forenames></author><author><keyname>Crouse</keyname><forenames>David F</forenames></author></authors><title>Angular Resolution of Closely-Spaced Targets with Antenna Arrays</title><categories>eess.SP</categories><comments>The dissertation was originally defended on 17 December 1982</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This is an English translation of Ulrich Nickel's PhD dissertation with the
original title &quot;Winkelaufl\&quot;osung eng benachbarter Ziele mit Gruppenantennen.&quot;
It describes maximum-likelihood angular superresolution of closely-spaced
targets. It also discusses estimating the number of targets present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05317</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05317</id><created>2019-08-14</created><updated>2020-02-08</updated><authors><author><keyname>Goyal</keyname><forenames>Manu</forenames></author><author><keyname>Reeves</keyname><forenames>Neil</forenames></author><author><keyname>Rajbhandari</keyname><forenames>Satyan</forenames></author><author><keyname>Ahmad</keyname><forenames>Naseer</forenames></author><author><keyname>Wang</keyname><forenames>Chuan</forenames></author><author><keyname>Yap</keyname><forenames>Moi Hoon</forenames></author></authors><title>Recognition of Ischaemia and Infection in Diabetic Foot Ulcers: Dataset
  and Techniques</title><categories>eess.IV cs.CV</categories><comments>25 pages, 13 figures and 3 tables</comments><journal-ref>Computers in Biology and Medicine, Volume 117, February 2020,
  103616</journal-ref><doi>10.1016/j.compbiomed.2020.103616</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognition and analysis of Diabetic Foot Ulcers (DFU) using computerized
methods is an emerging research area with the evolution of image-based machine
learning algorithms. Existing research using visual computerized methods mainly
focuses on recognition, detection, and segmentation of the visual appearance of
the DFU as well as tissue classification. According to DFU medical
classification systems, the presence of infection (bacteria in the wound) and
ischaemia (inadequate blood supply) has important clinical implications for DFU
assessment, which are used to predict the risk of amputation. In this work, we
propose a new dataset and computer vision techniques to identify the presence
of infection and ischaemia in DFU. This is the first time a DFU dataset with
ground truth labels of ischaemia and infection cases is introduced for research
purposes. For the handcrafted machine learning approach, we propose a new
feature descriptor, namely the Superpixel Color Descriptor. Then we use the
Ensemble Convolutional Neural Network (CNN) model for more effective
recognition of ischaemia and infection. We propose to use a natural
data-augmentation method, which identifies the region of interest on foot
images and focuses on finding the salient features existing in this area.
Finally, we evaluate the performance of our proposed techniques on binary
classification, i.e. ischaemia versus non-ischaemia and infection versus
non-infection. Overall, our method performed better in the classification of
ischaemia than infection. We found that our proposed Ensemble CNN deep learning
algorithms performed better for both classification tasks as compared to
handcrafted machine learning algorithms, with 90% accuracy in ischaemia
classification and 73% in infection classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05338</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05338</id><created>2019-08-14</created><updated>2019-11-23</updated><authors><author><keyname>Ghazi</keyname><forenames>Mostafa Mehdipour</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author><author><keyname>Pai</keyname><forenames>Akshay</forenames></author><author><keyname>Modat</keyname><forenames>Marc</forenames></author><author><keyname>Cardoso</keyname><forenames>M. Jorge</forenames></author><author><keyname>Ourselin</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>S&#xf8;rensen</keyname><forenames>Lauge</forenames></author></authors><title>Robust parametric modeling of Alzheimer's disease progression</title><categories>stat.AP cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative characterization of disease progression using longitudinal data
can provide long-term predictions for the pathological stages of individuals.
This work studies robust modeling of Alzheimer's disease progression using
parametric methods. The proposed method linearly maps the individual's
chronological age to a disease progression score (DPS) and robustly fits a
constrained generalized logistic function to the longitudinal dynamics of a
biomarker as a function of the DPS using M-estimation. Robustness of the
estimates is quantified using bootstrapping via Monte Carlo resampling, and the
inflection points are used to temporally order the modeled biomarkers in the
disease course. Moreover, kernel density estimation is applied to the obtained
DPSs for clinical status prediction using a Bayesian classifier. Different
M-estimators and logistic functions, including a new generalized type proposed
in this study, called modified Stannard, are evaluated on the Alzheimer's
Disease Neuroimaging Initiative (ADNI) database for robust modeling of
volumetric MRI and PET biomarkers, as well as cognitive tests. The results show
that the modified Stannard function fitted using the modified Huber loss
achieves the best modeling performance with an MAE of 0.071 across all
biomarkers and bootstraps. In addition, applied to the ADNI test set, this
model achieves a multi-class AUC of 0.87 in clinical status prediction, and it
significantly outperforms an analogous state-of-the-art method with a biomarker
modeling MAE of 0.071 vs. 0.073 (p &lt; 0.001). Finally, the experiments show that
the proposed model, trained using abundant ADNI data, generalizes well to data
from the independent National Alzheimer's Coordinating Center (NACC) database,
where modeling performance is significantly improved (p &lt; 0.001) compared with
using a model trained on relatively scarce NACC data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05343</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05343</id><created>2019-08-14</created><authors><author><keyname>Wolterink</keyname><forenames>Jelmer M.</forenames></author><author><keyname>Leiner</keyname><forenames>Tim</forenames></author><author><keyname>I&#x161;gum</keyname><forenames>Ivana</forenames></author></authors><title>Graph Convolutional Networks for Coronary Artery Segmentation in Cardiac
  CT Angiography</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019 Workshop on Graph Learning in Medical Image (GLMI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of coronary artery stenosis in coronary CT angiography (CCTA)
requires highly personalized surface meshes enclosing the coronary lumen. In
this work, we propose to use graph convolutional networks (GCNs) to predict the
spatial location of vertices in a tubular surface mesh that segments the
coronary artery lumen. Predictions for individual vertex locations are based on
local image features as well as on features of neighboring vertices in the mesh
graph. The method was trained and evaluated using the publicly available
Coronary Artery Stenoses Detection and Quantification Evaluation Framework.
Surface meshes enclosing the full coronary artery tree were automatically
extracted. A quantitative evaluation on 78 coronary artery segments showed that
these meshes corresponded closely to reference annotations, with a Dice
similarity coefficient of 0.75/0.73, a mean surface distance of 0.25/0.28 mm,
and a Hausdorff distance of 1.53/1.86 mm in healthy/diseased vessel segments.
The results showed that inclusion of mesh information in a GCN improves
segmentation overlap and accuracy over a baseline model without interaction on
the mesh. The results indicate that GCNs allow efficient extraction of coronary
artery surface meshes and that the use of GCNs leads to regular and more
accurate meshes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05347</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05347</id><created>2019-08-08</created><authors><author><keyname>Peters</keyname><forenames>Jeffrey R.</forenames></author><author><keyname>Surana</keyname><forenames>Amit</forenames></author><author><keyname>Taylor</keyname><forenames>Grant S.</forenames></author><author><keyname>Turpin</keyname><forenames>Terry S.</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>UAV Surveillance Under Visibility and Dwell-Time Constraints: A
  Sampling-Based Approach</title><categories>eess.SY cs.MA cs.RO cs.SY math.OC</categories><journal-ref>J. Dyn. Sys., Meas., Control. 2019;141(6):064501-064501-6</journal-ref><doi>10.1115/1.4042669</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A framework is introduced for planning unmanned aerial vehicle flight paths
for visual surveillance of ground targets, each having particular viewing
requirements. Specifically, each target is associated with a set of imaging
parameters, including a desired (i) tilt angle, (ii) azimuth, with the option
of a 360-degree view, and (iii) dwell-time. Tours are sought to image the
targets, while minimizing both the total mission time and the time required to
reach the initial target. An epsilon-constraint scalarization is used to pose
the multi-objective problem as a constrained optimization, which, through
careful discretization, can be approximated as a discrete graph-search. It is
shown that, in many cases, this approximation is equivalent to a generalized
traveling salesperson problem. A heuristic procedure for solving the discrete
approximation and recovering solutions to the full routing problem is
presented, and is shown to have resolution completeness properties. Algorithms
are illustrated through numerical studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05377</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05377</id><created>2019-08-14</created><updated>2020-02-21</updated><authors><author><keyname>Chatterjee</keyname><forenames>Oindrila</forenames></author><author><keyname>Chakrabartty</keyname><forenames>Shantanu</forenames></author></authors><title>Resonant Machine Learning Based on Complex Growth Transform Dynamical
  Systems</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>Version2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional energy-based learning models associate a single energy metric to
each configuration of variables involved in the underlying optimization
process. Such models associate the lowest energy state to the optimal
configuration of variables under consideration, and are thus inherently
dissipative in nature. In this paper we propose an energy-efficient learning
framework that exploits structural and functional similarities between a
machine learning network and a general electrical network satisfying the
Tellegen's theorem. In contrast to the standard energy-based models, the
proposed formulation associates two energy components, namely, active and
reactive energy to the original network. This ensures that the network's
active-power is dissipated only during the process of learning, whereas the
reactive-power is maintained to be zero at all times. As a result, in
steady-state, the learned parameters are stored and self-sustained by
electrical resonance determined by the network's nodal inductances and
capacitances. Based on this approach, this paper introduces three novel
concepts: (a) A learning framework where the network's active-power dissipation
is used as a regularization for a learning objective function that is subjected
to zero total reactive-power constraint; (b) A dynamical system based on
complex-domain, continuous-time growth transforms which optimizes the learning
objective function and drives the network towards electrical resonance under
steady-state operation; and (c) An annealing procedure that controls the
trade-off between active-power dissipation and the speed of convergence. As a
representative example, we show how the proposed framework can be used for
designing resonant support vector machines (SVMs), where we show that the
support-vectors correspond to an LC network with self-sustained oscillations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05388</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05388</id><created>2019-08-14</created><authors><author><keyname>Sanjarinia</keyname><forenames>Mohamad Saleh</forenames></author><author><keyname>Saadatmand</keyname><forenames>Sepehr</forenames></author><author><keyname>Shamsi</keyname><forenames>Pourya</forenames></author><author><keyname>Ferdowsi</keyname><forenames>Mehdi</forenames></author></authors><title>Analysis of Various Transformer Structures for High Frequency Isolation
  Applications</title><categories>eess.SY cs.SY</categories><comments>6 pages, 10 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High frequency transformers are an integral part of power electronics devices
and their parasitic parameters influence the performance and efficiency of the
overall system. In this paper, transformer leakage inductances and parasitic
capacitances are analyzed using finite element method (FEM) for different
structures and windings arrangements of high frequency transformers. Also,
magnetic field, electric field, and voltage distribution within the transformer
is simulated and analyzed. Six different high frequency transformers with
toroidal, EE, and UU cores with different windings are investigated for a
400(V)/400(V), 8 kVA transformer operating at 10 kHz. Additionally, interleaved
windings for EE core are simulated and results compared with previous outcomes.
Analysis results will help categorize each structure, based on its balance
between leakage inductances and series parasitic capacitance. This information
can later be used for optimal selection of transformers as a function of their
operating frequency and enable designers to compromise between various
parameters in different applications, especially new fast switches such as SiC
and GaN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05402</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05402</id><created>2019-08-14</created><authors><author><keyname>Wu</keyname><forenames>Meng</forenames></author><author><keyname>Wang</keyname><forenames>Jingbo</forenames></author><author><keyname>Deshmukh</keyname><forenames>Jyotirmoy</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>Shield Synthesis for Real: Enforcing Safety in Cyber-Physical Systems</title><categories>cs.LO cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber-physical systems are often safety-critical in that violations of safety
properties may lead to catastrophes. We propose a method to enforce the safety
of systems with real-valued signals by synthesizing a runtime enforcer called
the shield. Whenever the system violates a property, the shield, composed with
the system, makes correction instantaneously to ensure that no erroneous output
is generated by the combined system. While techniques for synthesizing Boolean
shields are well understood, they do not handle real-valued signals ubiquitous
in cyber-physical systems, meaning corrections may be either unrealizable or
inefficient to compute in the real domain. We solve the realizability and
efficiency problems by statically analyzing the compatibility of predicates
defined over real-valued signals, and using the analysis result to constrain a
two-player safety game used to synthesize the shield. We have implemented the
method and demonstrated its effectiveness and efficiency on a variety of
applications, including an automotive powertrain control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05418</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05418</id><created>2019-08-15</created><authors><author><keyname>Hu</keyname><forenames>Szu-Yeu</forenames></author><author><keyname>Weng</keyname><forenames>Wei-Hung</forenames></author><author><keyname>Lu</keyname><forenames>Shao-Lun</forenames></author><author><keyname>Cheng</keyname><forenames>Yueh-Hung</forenames></author><author><keyname>Xiao</keyname><forenames>Furen</forenames></author><author><keyname>Hsu</keyname><forenames>Feng-Ming</forenames></author><author><keyname>Lu</keyname><forenames>Jen-Tang</forenames></author></authors><title>Multimodal Volume-Aware Detection and Segmentation for Brain Metastases
  Radiosurgery</title><categories>eess.IV cs.CV</categories><comments>Accepted to 2019 MICCAI AIRT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stereotactic radiosurgery (SRS), which delivers high doses of irradiation in
a single or few shots to small targets, has been a standard of care for brain
metastases. While very effective, SRS currently requires manually intensive
delineation of tumors. In this work, we present a deep learning approach for
automated detection and segmentation of brain metastases using multimodal
imaging and ensemble neural networks. In order to address small and multiple
brain metastases, we further propose a volume-aware Dice loss which optimizes
model performance using the information of lesion size. This work surpasses
current benchmark levels and demonstrates a reliable AI-assisted system for SRS
treatment planning for multiple brain metastases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05447</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05447</id><created>2019-08-15</created><updated>2019-08-19</updated><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Gu</keyname><forenames>Yifan</forenames></author><author><keyname>Chen</keyname><forenames>He</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>On the Age of Information of Short-Packet Communications with Packet
  Management</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a point-to-point wireless communication system.
The source monitors a physical process and generates status update packets
according to a Poisson process. The packets are transmitted to the destination
by using finite blocklength coding to update the status (e.g., temperature,
speed, position) of the monitored process. In some applications, such as
real-time monitoring and tracking, the timeliness of the status updates is
critical since the users are interested in the latest condition of the process.
The timeliness of the status updates can be reflected by a recently proposed
metric, termed the age of information (AoI). We focus on the packet management
policies for the considered system. Specifically, the preemption and discard of
status updates are important to decrease the AoI. For example, it is
meaningless to transmit stale status updates when a new status update is
generated. We propose three packet management schemes in the transmission
between the source and the destination, namely non-preemption (NP), preemption
(PR) and retransmission (RT) schemes. We derive closed-form expressions of the
average AoI for the proposed three schemes. Based on the derived analytical
expressions of the average AoI, we further minimize the average AoI by
optimizing the packet blocklength for each status update. Simulation results
are provided to validate our theoretical analysis, which further show that the
proposed schemes can outperform each other for different system setups, and the
proposed schemes considerably outperform the existing ones without packet
management at medium to high generation rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05467</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05467</id><created>2019-08-15</created><authors><author><keyname>Gunz</keyname><forenames>Samuel</forenames></author><author><keyname>Erne</keyname><forenames>Svenja</forenames></author><author><keyname>Rawdon</keyname><forenames>Eric J.</forenames></author><author><keyname>Ampanozi</keyname><forenames>Garyfalia</forenames></author><author><keyname>Sieberth</keyname><forenames>Till</forenames></author><author><keyname>Affolter</keyname><forenames>Raffael</forenames></author><author><keyname>Ebert</keyname><forenames>Lars C.</forenames></author><author><keyname>Dobay</keyname><forenames>Akos</forenames></author></authors><title>Automated Rib Fracture Detection of Postmortem Computed Tomography
  Images Using Machine Learning Techniques</title><categories>eess.IV cs.CV</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging techniques is widely used for medical diagnostics. This leads in some
cases to a real bottleneck when there is a lack of medical practitioners and
the images have to be manually processed. In such a situation there is a need
to reduce the amount of manual work by automating part of the analysis. In this
article, we investigate the potential of a machine learning algorithm for
medical image processing by computing a topological invariant classifier.
First, we select retrospectively from our database of postmortem computed
tomography images of rib fractures. The images are prepared by applying a rib
unfolding tool that flattens the rib cage to form a two-dimensional projection.
We compare the results of our analysis with two independent convolutional
neural network models. In the case of the neural network model, we obtain an
$F_1$ Score of 0.73. To access the performance of our classifier, we compute
the relative proportion of images that were not shared between the two classes.
We obtain a precision of 0.60 for the images with rib fractures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05480</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05480</id><created>2019-08-15</created><authors><author><keyname>Kuzina</keyname><forenames>Anna</forenames></author><author><keyname>Egorov</keyname><forenames>Evgenii</forenames></author><author><keyname>Burnaev</keyname><forenames>Evgeny</forenames></author></authors><title>Bayesian Generative Models for Knowledge Transfer in MRI Semantic
  Segmentation Problems</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>24 page, 6 figures, 6 tabels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic segmentation methods based on deep learning have recently
demonstrated state-of-the-art performance, outperforming the ordinary methods.
Nevertheless, these methods are inapplicable for small datasets, which are very
common in medical problems. To this end, we propose a knowledge transfer method
between diseases via the Generative Bayesian Prior network. Our approach is
compared to a pre-train approach and random initialization and obtains the best
results in terms of Dice Similarity Coefficient metric for the small subsets of
the Brain Tumor Segmentation 2018 database (BRATS2018).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05513</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05513</id><created>2019-08-15</created><authors><author><keyname>L&#xf3;pez</keyname><forenames>Onel L. A.</forenames></author><author><keyname>Alves</keyname><forenames>Hirley</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>Distributed Rate Control in Downlink NOMA Networks with Reliability
  Constraints</title><categories>cs.NI cs.IT eess.SP math.IT</categories><comments>14 pages, 10 figures, accepted at IEEE TWC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) has been identified as a promising
technology for future wireless systems due to its performance gains in spectral
efficiency when compared to conventional orthogonal schemes (OMA). This gain
can be easily translated to an increasing number of served users, but imposes a
challenge in the system reliability which is of vital importance for new
services and applications of coming cellular systems. To cope with these issues
we propose a NOMA rate control strategy that makes use only of topological
characteristics of the scenario and the reliability constraint. We attain the
necessary conditions so that NOMA overcomes the OMA alternative, while we
discuss the optimum allocation strategies for the 2-user NOMA setup when
operating with equal rate or maximum sum-rate goals. In such scenario we show
that the user with the largest target error probability times the ratio between
the average receive signal power and the average interference power, should be
scheduled to be decoded first for optimum performance. We compare numerically
the performance of our allocation scheme with its ideal counterpart requiring
full CSI at the BSs and infinitely long blocklength, and show how the gap
increases as the reliability constraint becomes more stringent. Results also
evidence the benefits of NOMA when the co-interference can be efficiently
canceled, specially when the goal is to maximize the sum-rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05519</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05519</id><created>2019-08-15</created><updated>2019-12-18</updated><authors><author><keyname>Perraudin</keyname><forenames>Nathana&#xeb;l</forenames></author><author><keyname>Srivastava</keyname><forenames>Ankit</forenames></author><author><keyname>Lucchi</keyname><forenames>Aurelien</forenames></author><author><keyname>Kacprzak</keyname><forenames>Tomasz</forenames></author><author><keyname>Hofmann</keyname><forenames>Thomas</forenames></author><author><keyname>R&#xe9;fr&#xe9;gier</keyname><forenames>Alexandre</forenames></author></authors><title>Cosmological N-body simulations: a challenge for scalable generative
  models</title><categories>physics.comp-ph astro-ph.CO cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep generative models, such as Generative Adversarial Networks (GANs) or
Variational Autoencoders (VAs) have been demonstrated to produce images of high
visual quality. However, the existing hardware severely limits the size of the
images that can be generated. The rapid growth of high dimensional data in many
fields of science therefore poses a significant challenge for generative
models. In cosmology, the large-scale, three-dimensional matter distribution,
modeled with N-body simulations, plays a crucial role in understanding the
evolution of the universe. As these simulations are computationally very
expensive, GANs have recently generated interest as a possible method to
emulate these datasets, but they have been, so far, mostly limited to two
dimensional data. In this work, we introduce a new benchmark for the generation
of three dimensional N-body simulations, in order to stimulate new ideas in the
machine learning community and move closer to the practical use of generative
models in cosmology. As a first benchmark result, we propose a scalable GAN
approach for training a generator of N-body three-dimensional cubes. Our
technique relies on two key building blocks, (i) splitting the generation of
the high-dimensional data into smaller parts, and (ii) using a multi-scale
approach that efficiently captures global image features that might otherwise
be lost in the splitting process. We evaluate the performance of our model for
the generation of N-body samples using various statistical measures commonly
used in cosmology. Our results show that the proposed model produces samples of
high visual quality, although the statistical analysis reveals that capturing
rare features in the data poses significant problems for the generative models.
We make the data, quality evaluation routines, and the proposed GAN
architecture publicly available at https://github.com/nperraud/3DcosmoGAN
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05551</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05551</id><created>2019-08-15</created><authors><author><keyname>Yu</keyname><forenames>Yi</forenames></author><author><keyname>Canales</keyname><forenames>Simon</forenames></author></authors><title>Conditional LSTM-GAN for Melody Generation from Lyrics</title><categories>cs.AI cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Melody generation from lyrics has been a challenging research issue in the
field of artificial intelligence and music, which enables to learn and discover
latent relationship between interesting lyrics and accompanying melody.
Unfortunately, the limited availability of paired lyrics-melody dataset with
alignment information has hindered the research progress. To address this
problem, we create a large dataset consisting of 12,197 MIDI songs each with
paired lyrics and melody alignment through leveraging different music sources
where alignment relationship between syllables and music attributes is
extracted. Most importantly, we propose a novel deep generative model,
conditional Long Short-Term Memory - Generative Adversarial Network (LSTM-GAN)
for melody generation from lyrics, which contains a deep LSTM generator and a
deep LSTM discriminator both conditioned on lyrics. In particular,
lyrics-conditioned melody and alignment relationship between syllables of given
lyrics and notes of predicted melody are generated simultaneously. Experimental
results have proved the effectiveness of our proposed lyrics-to-melody
generative model, where plausible and tuneful sequences can be inferred from
lyrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05553</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05553</id><created>2019-08-15</created><authors><author><keyname>S</keyname><forenames>Bhavana V.</forenames></author><author><keyname>Das</keyname><forenames>Pradip K.</forenames></author></authors><title>Speaker Verification Using Simple Temporal Features and Pitch
  Synchronous Cepstral Coefficients</title><categories>cs.SD eess.AS</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker verification is the process by which a speakers claim of identity is
tested against a claimed speaker by his or her voice. Speaker verification is
done by the use of some parameters (features) from the speakers voice which can
be used to differentiate among many speakers. The efficiency of speaker
verification system mainly depends on the feature set providing high
inter-speaker variability and low intra-speaker variability. There are many
methods used for speaker verification. Some systems use Mel Frequency Cepstral
Coefficients as features (MFCCs), while others use Hidden Markov Models (HMM)
based speaker recognition, Support Vector Machines (SVM), GMMs . In this paper
simple intra-pitch temporal information in conjunction with pitch synchronous
cepstral coefficients forms the feature set. The distinct feature of a speaker
is determined from the steady state part of five cardinal spoken English
vowels. The performance was found to be average when these features were used
independently. But very encouraging results were observed when both features
were combined to form a decision for speaker verification. For a database of
twenty speakers of 100 utterances per speaker, an accuracy of 91.04% has been
observed. The analysis of speakers whose recognition was incorrect is conducted
and discussed .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05554</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05554</id><created>2019-08-15</created><authors><author><keyname>Hagmar</keyname><forenames>Hannes</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Eriksson</keyname><forenames>Robert</forenames></author><author><keyname>Tuan</keyname><forenames>Le Anh</forenames></author></authors><title>Voltage Instability Prediction Using a Deep Recurrent Neural Network</title><categories>eess.SY cs.SY eess.SP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a new method for voltage instability prediction using a
recurrent neural network with long short-term memory. The method is aimed to be
used as a supplementary warning system for system operators, capable of
assessing whether the current state will cause voltage instability issues
several minutes into the future. The proposed method use a long sequence-based
network, where both real-time and historic data are used to enhance the
classification accuracy. The network is trained and tested on the Nordic32 test
system, wherecombinations of different operating conditions and contingency
scenarios are generated using time-domain simulations. The method shows that
almost all N-1 contingency test cases were predicted correctly, and N-1-1
contingency test cases were predicted with over 93 % accuracy only seconds
after a disturbance. Further, the impact of sequence length is examined,
showing that the proposed long sequenced-based method provides significantly
better classification accuracy than both a feedforward neural network and a
network using a shorter sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05599</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05599</id><created>2019-08-15</created><authors><author><keyname>Peng</keyname><forenames>Cheng</forenames></author><author><keyname>Lin</keyname><forenames>Wei-An</forenames></author><author><keyname>Liao</keyname><forenames>Haofu</forenames></author><author><keyname>Chellappa</keyname><forenames>Rama</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author></authors><title>Deep Slice Interpolation via Marginal Super-Resolution, Fusion and
  Refinement</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a marginal super-resolution (MSR) approach based on 2D
convolutional neural networks (CNNs) for interpolating an anisotropic brain
magnetic resonance scan along the highly under-sampled direction, which is
assumed to axial without loss of generality. Previous methods for slice
interpolation only consider data from pairs of adjacent 2D slices. The
possibility of fusing information from the direction orthogonal to the 2D
slices remains unexplored. Our approach performs MSR in both sagittal and
coronal directions, which provides an initial estimate for slice interpolation.
The interpolated slices are then fused and refined in the axial direction for
improved consistency. Since MSR consists of only 2D operations, it is more
feasible in terms of GPU memory consumption and requires fewer training samples
compared to 3D CNNs. Our experiments demonstrate that the proposed method
outperforms traditional linear interpolation and baseline 2D/3D CNN-based
approaches. We conclude by showcasing the method's practical utility in
estimating brain volumes from under-sampled brain MR scans through semantic
segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05612</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05612</id><created>2019-08-15</created><updated>2020-02-21</updated><authors><author><keyname>Yang</keyname><forenames>Xue</forenames></author><author><keyname>Liu</keyname><forenames>Qingqing</forenames></author><author><keyname>Yan</keyname><forenames>Junchi</forenames></author><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Zhang</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Yu</keyname><forenames>Gang</forenames></author></authors><title>R3Det: Refined Single-Stage Detector with Feature Refinement for
  Rotating Object</title><categories>cs.CV cs.LG eess.IV</categories><comments>13 pages, 14 figures, 10 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rotation detection is a challenging task due to the difficulties of locating
the multi-angle objects and separating them accurately and quickly from the
background. Though considerable progress has been made, for practical settings,
there still exist challenges for rotating objects with large aspect ratio,
dense distribution and category extremely imbalance. In this paper, we propose
an end-to-end refined single-stage rotation detector for fast and accurate
positioning objects. Considering the shortcoming of feature misalignment in
existing refined single-stage detector, we design a feature refinement module
to improve detection performance by getting more accurate features. The key
idea of feature refinement module is to re-encode the position information of
the current refined bounding box to the corresponding feature points through
feature interpolation to realize feature reconstruction and alignment.
Extensive experiments on two remote sensing public datasets DOTA, HRSC2016 as
well as scene text data ICDAR2015 show the state-of-the-art accuracy and speed
of our detector. Code is available at
https://github.com/Thinklab-SJTU/R3Det_Tensorflow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05615</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05615</id><created>2019-08-15</created><updated>2019-08-15</updated><authors><author><keyname>Peng</keyname><forenames>Cheng</forenames></author><author><keyname>Lin</keyname><forenames>Wei-An</forenames></author><author><keyname>Chellappa</keyname><forenames>Rama</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author></authors><title>Towards multi-sequence MR image recovery from undersampled k-space data</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undersampled MR image recovery has been widely studied for accelerated MR
acquisition. However, it has been mostly studied under a single sequence
scenario, despite the fact that multi-sequence MR scan is common in practice.
In this paper, we aim to optimize multi-sequence MR image recovery from
undersampled k-space data under an overall time constraint while considering
the difference in acquisition time for various sequences. We first formulate it
as a constrained optimization problem and then show that finding the optimal
sampling strategy for all sequences and the best recovery model at the same
time is combinatorial and hence computationally prohibitive. To solve this
problem, we propose a blind recovery model that simultaneously recovers
multiple sequences, and an efficient approach to find proper combination of
sampling strategy and recovery model. Our experiments demonstrate that the
proposed method outperforms sequence-wise recovery, and sheds light on how to
decide the undersampling strategy for sequences within an overall time budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05621</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05621</id><created>2019-08-15</created><authors><author><keyname>Liefers</keyname><forenames>Bart</forenames></author><author><keyname>Colijn</keyname><forenames>Johanna M.</forenames></author><author><keyname>Gonz&#xe1;lez-Gonzalo</keyname><forenames>Cristina</forenames></author><author><keyname>Verzijden</keyname><forenames>Timo</forenames></author><author><keyname>Mitchell</keyname><forenames>Paul</forenames></author><author><keyname>Hoyng</keyname><forenames>Carel B.</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author><author><keyname>Klaver</keyname><forenames>Caroline C. W.</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Clara I.</forenames></author></authors><title>A deep learning model for segmentation of geographic atrophy to study
  its long-term natural history</title><categories>eess.IV cs.CV</categories><comments>22 pages, 3 tables, 4 figures, 1 supplemental figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop and validate a deep learning model for automatic
segmentation of geographic atrophy (GA) in color fundus images (CFIs) and its
application to study growth rate of GA. Participants: 409 CFIs of 238 eyes with
GA from the Rotterdam Study (RS) and the Blue Mountain Eye Study (BMES) for
model development, and 5,379 CFIs of 625 eyes from the Age-Related Eye Disease
Study (AREDS) for analysis of GA growth rate. Methods: A deep learning model
based on an ensemble of encoder-decoder architectures was implemented and
optimized for the segmentation of GA in CFIs. Four experienced graders
delineated GA in CFIs from RS and BMES. These manual delineations were used to
evaluate the segmentation model using 5-fold cross-validation. The model was
further applied to CFIs from the AREDS to study the growth rate of GA. Linear
regression analysis was used to study associations between structural
biomarkers at baseline and GA growth rate. A general estimate of the
progression of GA area over time was made by combining growth rates of all eyes
with GA from the AREDS set. Results: The model obtained an average Dice
coefficient of 0.72 $\pm$ 0.26 on the BMES and RS. An intraclass correlation
coefficient of 0.83 was reached between the automatically estimated GA area and
the graders' consensus measures. Eight automatically calculated structural
biomarkers (area, filled area, convex area, convex solidity, eccentricity,
roundness, foveal involvement and perimeter) were significantly associated with
growth rate. Combining all growth rates indicated that GA area grows
quadratically up to an area of around 12 mm$^{2}$, after which growth rate
stabilizes or decreases. Conclusion: The presented deep learning model allowed
for fully automatic and robust segmentation of GA in CFIs. These segmentations
can be used to extract structural characteristics of GA that predict its growth
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05630</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05630</id><created>2019-08-15</created><authors><author><keyname>Bhat</keyname><forenames>Raghavendra</forenames></author><author><keyname>Yazicioglu</keyname><forenames>Yasin</forenames></author><author><keyname>Aksaray</keyname><forenames>Derya</forenames></author></authors><title>Distributed Path Planning for Executing Cooperative Tasks with Time
  Windows</title><categories>cs.RO cs.MA cs.SY eess.SY</categories><comments>Accepted to the 8th IFAC Workshop on Distributed Estimation and
  Control in Networked Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the distributed planning of robot trajectories for optimal
execution of cooperative tasks with time windows. In this setting, each task
has a value and is completed if sufficiently many robots are simultaneously
present at the necessary location within the specified time window. Tasks keep
arriving periodically over cycles. The task specifications (required number of
robots, location, time window, and value) are unknown a priori and the robots
try to maximize the value of completed tasks by planning their own trajectories
for the upcoming cycle based on their past observations in a distributed
manner. Considering the recharging and maintenance needs, robots are required
to start and end each cycle at their assigned stations located in the
environment. We map this problem to a game theoretic formulation and maximize
the collective performance through distributed learning. Some simulation
results are also provided to demonstrate the performance of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05649</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05649</id><created>2019-08-15</created><authors><author><keyname>Sun</keyname><forenames>Dongming</forenames></author><author><keyname>Huang</keyname><forenames>Xiao</forenames></author><author><keyname>Yang</keyname><forenames>Kailun</forenames></author></authors><title>A Multimodal Vision Sensor for Autonomous Driving</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a multimodal vision sensor that integrates three types
of cameras, including a stereo camera, a polarization camera and a panoramic
camera. Each sensor provides a specific dimension of information: the stereo
camera measures depth per pixel, the polarization obtains the degree of
polarization, and the panoramic camera captures a 360-degree landscape. Data
fusion and advanced environment perception could be built upon the combination
of sensors. Designed especially for autonomous driving, this vision sensor is
shipped with a robust semantic segmentation network. In addition, we
demonstrate how cross-modal enhancement could be achieved by registering the
color image and the polarization image. An example of water hazard detection is
given. To prove the multimodal vision sensor's compatibility with different
devices, a brief runtime performance analysis is carried out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05663</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05663</id><created>2019-08-14</created><authors><author><keyname>Shenkman</keyname><forenames>Yigal</forenames></author><author><keyname>Qutteineh</keyname><forenames>Bilal</forenames></author><author><keyname>Joskowicz</keyname><forenames>Leo</forenames></author><author><keyname>Szeskin</keyname><forenames>Adi</forenames></author><author><keyname>Azraq</keyname><forenames>Yusef</forenames></author><author><keyname>Mayer</keyname><forenames>Arnaldo</forenames></author><author><keyname>Eshed</keyname><forenames>Iris</forenames></author></authors><title>Automatic detection and diagnosis of sacroiliitis in CT scans as
  incidental findings</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1016/j.media.2019.07.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early diagnosis of sacroiliitis may lead to preventive treatment which can
significantly improve the patient's quality of life in the long run.
Oftentimes, a CT scan of the lower back or abdomen is acquired for suspected
back pain. However, since the differences between a healthy and an inflamed
sacroiliac joint in the early stages are subtle, the condition may be missed.
We have developed a new automatic algorithm for the diagnosis and grading of
sacroiliitis CT scans as incidental findings, for patients who underwent CT
scanning as part of their lower back pain workout. The method is based on
supervised machine and deep learning techniques. The input is a CT scan that
includes the patient's pelvis. The output is a diagnosis for each sacroiliac
joint. The algorithm consists of four steps: 1) computation of an initial
region of interest (ROI) that includes the pelvic joints region using
heuristics and a U-Net classifier; 2) refinement of the ROI to detect both
sacroiliac joints using a four-tree random forest; 3) individual sacroiliitis
grading of each sacroiliac joint in each CT slice with a custom slice CNN
classifier, and; 4) sacroiliitis diagnosis and grading by combining the
individual slice grades using a random forest. Experimental results on 484
sacroiliac joints yield a binary and a 3-class case classification accuracy of
91.9% and 86%, a sensitivity of 95% and 82%, and an Area-Under-the-Curve of
0.97 and 0.57, respectively. Automatic computer-based analysis of CT scans has
the potential of being a useful method for the diagnosis and grading of
sacroiliitis as an incidental finding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05667</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05667</id><created>2019-08-14</created><authors><author><keyname>Erdal</keyname><forenames>Barbaros S.</forenames></author><author><keyname>Demirer</keyname><forenames>Mutlu</forenames></author><author><keyname>Amadi</keyname><forenames>Chiemezie C.</forenames></author><author><keyname>Ibrahim</keyname><forenames>Gehan F. M.</forenames></author><author><keyname>O'Donnell</keyname><forenames>Thomas P.</forenames></author><author><keyname>Grimmer</keyname><forenames>Rainer</forenames></author><author><keyname>Wimmer</keyname><forenames>Andreas</forenames></author><author><keyname>Little</keyname><forenames>Kevin J.</forenames></author><author><keyname>Gupta</keyname><forenames>Vikash</forenames></author><author><keyname>Bigelow</keyname><forenames>Matthew T.</forenames></author><author><keyname>Prevedello</keyname><forenames>Luciano M.</forenames></author><author><keyname>White</keyname><forenames>Richard D.</forenames></author></authors><title>Are Quantitative Features of Lung Nodules Reproducible at Different CT
  Acquisition and Reconstruction Parameters?</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consistency and duplicability in Computed Tomography (CT) output is essential
to quantitative imaging for lung cancer detection and monitoring. This study of
CT-detected lung nodules investigated the reproducibility of volume-, density-,
and texture-based features (outcome variables) over routine ranges of
radiation-dose, reconstruction kernel, and slice thickness. CT raw data of 23
nodules were reconstructed using 320 acquisition/reconstruction conditions
(combinations of 4 doses, 10 kernels, and 8 thicknesses). Scans at 12.5%, 25%,
and 50% of protocol dose were simulated; reduced-dose and full-dose data were
reconstructed using conventional filtered back-projection and
iterative-reconstruction kernels at a range of thicknesses (0.6-5.0 mm).
Full-dose/B50f kernel reconstructions underwent expert segmentation for
reference Region-Of-Interest (ROI) and nodule volume per thickness; each ROI
was applied to 40 corresponding images (combinations of 4 doses and 10
kernels). Typical texture analysis metrics (including 5 histogram features, 13
Gray Level Co-occurrence Matrix, 5 Run Length Matrix, 2 Neighboring Gray-Level
Dependence Matrix, and 2 Neighborhood Gray-Tone Difference Matrix) were
computed per ROI. Reconstruction conditions resulting in no significant change
in volume, density, or texture metrics were identified as &quot;compatible pairs&quot;
for a given outcome variable. Our results indicate that as thickness increases,
volumetric reproducibility decreases, while reproducibility of histogram- and
texture-based features across different acquisition and reconstruction
parameters improves. In order to achieve concomitant reproducibility of
volumetric and radiomic results across studies, balanced standardization of the
imaging acquisition parameters is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05674</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05674</id><created>2019-08-15</created><updated>2019-09-02</updated><authors><author><keyname>Cao</keyname><forenames>Dong</forenames></author><author><keyname>Xu</keyname><forenames>Lisha</forenames></author></authors><title>Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of
  Autonomous Vehicles</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted to ACPR 2019 - Workshop on Computer Vision for Modern
  Vehicles</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pedestrian action recognition and intention prediction is one of the core
issues in the field of autonomous driving. In this research field, action
recognition is one of the key technologies. A large number of scholars have
done a lot of work to im-prove the accuracy of the algorithm for the task.
However, there are relatively few studies and improvements in the computational
complexity of algorithms and sys-tem real-time. In the autonomous driving
application scenario, the real-time per-formance and ultra-low latency of the
algorithm are extremely important evalua-tion indicators, which are directly
related to the availability and safety of the au-tonomous driving system. To
this end, we construct a bypass enhanced RGB flow model, which combines the
previous two-branch algorithm to extract RGB feature information and optical
flow feature information respectively. In the train-ing phase, the two branches
are merged by distillation method, and the bypass enhancement is combined in
the inference phase to ensure accuracy. The real-time behavior of the behavior
recognition algorithm is significantly improved on the premise that the
accuracy does not decrease. Experiments confirm the superiority and
effectiveness of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05698</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05698</id><created>2019-08-15</created><authors><author><keyname>Haldar</keyname><forenames>Justin P.</forenames></author><author><keyname>Fan</keyname><forenames>Qiuyun</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author></authors><title>Fast Sub-millimeter Diffusion MRI using gSlider-SMS and SNR-Enhancing
  Joint Reconstruction</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We evaluate a new approach for achieving diffusion MRI data with high spatial
resolution, large volume coverage, and fast acquisition speed.
  A recent method called gSlider-SMS enables whole-brain sub-millimeter
diffusion MRI with high signal-to-noise ratio (SNR) efficiency. However,
despite the efficient acquisition, the resulting images can still suffer from
low SNR due to the small size of the imaging voxels. This work proposes to
mitigate the SNR problem by combining gSlider-SMS with a regularized
SNR-enhancing reconstruction approach.
  Illustrative results show that, from gSlider-SMS data acquired over a span of
only 25 minutes on a 3T scanner, the proposed method is able to produce 71 MRI
images (64 diffusion encoding orientations with $b=$1500 s/mm$^2$, and 7 images
without diffusion weighting) of the entire \emph{in vivo} human brain with
nominal 0.66 mm spatial resolution. Using data acquired from 75 minutes of
acquisition as a gold standard reference, we demonstrate that the proposed
SNR-ehancement procedure leads to substantial improvements in estimated
diffusion parameters compared to conventional gSlider reconstruction. Results
also demonstrate that the proposed method has advantages relative to denoising
methods based on low-rank matrix modeling. A theoretical analysis of the
trade-off between spatial resolution and SNR suggests that the proposed
approach has high efficiency.
  The combination of gSlider-SMS with advanced regularized reconstruction
enables high-resolution quantitative diffusion MRI from a relatively fast
acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05715</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05715</id><created>2019-08-15</created><updated>2019-08-27</updated><authors><author><keyname>Olshevsky</keyname><forenames>Vyacheslav</forenames></author><author><keyname>Khotyaintsev</keyname><forenames>Yuri V.</forenames></author><author><keyname>Divin</keyname><forenames>Andrey</forenames></author><author><keyname>Delzanno</keyname><forenames>Gian Luca</forenames></author><author><keyname>Anderzen</keyname><forenames>Sven</forenames></author><author><keyname>Herman</keyname><forenames>Pawel</forenames></author><author><keyname>Chien</keyname><forenames>Steven W. D.</forenames></author><author><keyname>Avanov</keyname><forenames>Levon</forenames></author><author><keyname>Markidis</keyname><forenames>Stefano</forenames></author></authors><title>Automated classification of plasma regions using 3D particle energy
  distribution</title><categories>physics.space-ph cs.LG eess.IV</categories><comments>Submitted to JGR: Space Physics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though automatic classification and interpretation would be highly
desired features for the Magnetospheric Multiscale mission (MMS), the gold rush
era in machine learning has yet to reach the science done with observations
collected by MMS. We investigate the properties of the ion sky maps produced by
the Dual Ion Spectrometers (DIS) from the Fast Plasma Investigation (FPI).
Running the Principal Component Analysis (PCA) on a mixed subset of the data
suggests that more than 500 components are needed to cover 80% of the variance.
Hence, simple machine learning techniques might not deal with classification of
plasma regions. Use of a three-dimensional (3D) convolutional autoencoder
(3D-CAE) allows to reduce the data dimensionality by 128 times while still
maintaining a decent quality energy distribution. However, k-means clustering
computed over the compressed data is not capable of separating measurements
according to the physical properties of the plasma. A three-dimensional
convolutional neural network (3D-CNN), trained on a rather small amount of
human labelled training examples is able to predict plasma regions with 99%
accuracy. The low probability predictions of the 3D-CNN reveal the mixed state
regions, such as the magnetopause or bow shock, which are of key interest to
researchers of the MMS mission. The 3D-CNN and data processing software could
easily be deployed on ground-based computers and provide classification for the
whole MMS database. Data processing through the trained 3D-CNN is fast and
efficient, opening up the possibility for deployment in data-centers or in situ
operation onboard the spacecraft.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05717</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05717</id><created>2019-08-14</created><updated>2019-11-13</updated><authors><author><keyname>Habibian</keyname><forenames>Amirhossein</forenames></author><author><keyname>van Rozendaal</keyname><forenames>Ties</forenames></author><author><keyname>Tomczak</keyname><forenames>Jakub M.</forenames></author><author><keyname>Cohen</keyname><forenames>Taco S.</forenames></author></authors><title>Video Compression With Rate-Distortion Autoencoders</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted to ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a a deep generative model for lossy video
compression. We employ a model that consists of a 3D autoencoder with a
discrete latent space and an autoregressive prior used for entropy coding. Both
autoencoder and prior are trained jointly to minimize a rate-distortion loss,
which is closely related to the ELBO used in variational autoencoders. Despite
its simplicity, we find that our method outperforms the state-of-the-art
learned video compression networks based on motion compensation or
interpolation. We systematically evaluate various design choices, such as the
use of frame-based or spatio-temporal autoencoders, and the type of
autoregressive prior. In addition, we present three extensions of the basic
method that demonstrate the benefits over classical approaches to compression.
First, we introduce semantic compression, where the model is trained to
allocate more bits to objects of interest. Second, we study adaptive
compression, where the model is adapted to a domain with limited variability,
e.g., videos taken from an autonomous car, to achieve superior compression on
that domain. Finally, we introduce multimodal compression, where we demonstrate
the effectiveness of our model in joint compression of multiple modalities
captured by non-standard imaging sensors, such as quad cameras. We believe that
this opens up novel video compression applications, which have not been
feasible with classical codecs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05727</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05727</id><created>2019-08-15</created><authors><author><keyname>Seyedi</keyname><forenames>Sepehr</forenames></author><author><keyname>Yazicioglu</keyname><forenames>Yasin</forenames></author><author><keyname>Aksaray</keyname><forenames>Derya</forenames></author></authors><title>Persistent Surveillance With Energy-Constrained UAVs and Mobile Charging
  Stations</title><categories>eess.SY cs.RO cs.SY</categories><comments>Accepted to the 8th IFAC Workshop on Distributed Estimation and
  Control in Networked Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of achieving persistent surveillance over an
environment by using energy-constrained unmanned aerial vehicles (UAVs), which
are supported by unmanned ground vehicles (UGVs) serving as mobile charging
stations. Specifically, we plan the trajectories of all vehicles and the
charging schedule of UAVs to minimize the long-term maximum age, where age is
defined as the time between two consecutive visits to regions of interest in a
partitioned environment. We introduce a scalable planning strategy based on 1)
creating UAV- UGV teams, 2) decomposing the environment into optimal partitions
that can be covered by any of the teams in a single fuel cycle, 3) uniformly
distributing the teams over a cyclic path traversing those partitions, and 4)
having the UAVs in each team cover their current partition and be transported
to the next partition while being recharged by the UGV. We show some results
related to the safety and performance of the proposed strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05730</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05730</id><created>2019-08-13</created><authors><author><keyname>Ali</keyname><forenames>Redha</forenames></author><author><keyname>Hardie</keyname><forenames>Russell C.</forenames></author><author><keyname>De Silva</keyname><forenames>Manawaduge Supun</forenames></author><author><keyname>Kebede</keyname><forenames>Temesguen Messay</forenames></author></authors><title>Skin Lesion Segmentation and Classification for ISIC 2018 by Combining
  Deep CNN and Handcrafted Features</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>4 pages and 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short report describes our submission to the ISIC 2018 Challenge in Skin
Lesion Analysis Towards Melanoma Detection for Task1 and Task 3. This work has
been accomplished by a team of researchers at the University of Dayton Signal
and Image Processing Lab. Our proposed approach is computationally efficient
are combines information from both deep learning and handcrafted features. For
Task3, we form a new type of image features, called hybrid features, which has
stronger discrimination ability than single method features. These features are
utilized as inputs to a decision-making model that is based on a multiclass
Support Vector Machine (SVM) classifier. The proposed technique is evaluated on
online validation databases. Our score was 0.841 with SVM classifier on the
validation dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05743</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05743</id><created>2019-08-14</created><updated>2019-10-27</updated><authors><author><keyname>Krishna</keyname><forenames>Gautam</forenames></author><author><keyname>Han</keyname><forenames>Yan</forenames></author><author><keyname>Tran</keyname><forenames>Co</forenames></author><author><keyname>Carnahan</keyname><forenames>Mason</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H</forenames></author></authors><title>State-of-the-art Speech Recognition using EEG and Towards Decoding of
  Speech Spectrum From EEG</title><categories>eess.AS cs.SD</categories><comments>arXiv admin note: text overlap with arXiv:1906.08871</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we first demonstrate continuous noisy speech recognition using
electroencephalography (EEG) signals on English vocabulary using different
types of state of the art end-to-end automatic speech recognition (ASR) models,
we further provide results obtained using EEG data recorded under different
experimental conditions. We finally demonstrate decoding of speech spectrum
from EEG signals using a long short term memory (LSTM) based regression model
and Generative Adversarial Network (GAN) based model. Our results demonstrate
the feasibility of using EEG signals for continuous noisy speech recognition
under different experimental conditions and we provide preliminary results for
synthesis of speech from EEG features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05744</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05744</id><created>2019-08-14</created><authors><author><keyname>Saadatmand</keyname><forenames>Sepehr</forenames></author><author><keyname>Sanjarinia</keyname><forenames>Mohammad Saleh</forenames></author><author><keyname>Shamsi</keyname><forenames>Pourya</forenames></author><author><keyname>Ferdowsi</keyname><forenames>Mehdi</forenames></author><author><keyname>Wunsch</keyname><forenames>Donald C.</forenames></author></authors><title>Heuristic Dynamic Programming for Adaptive Virtual Synchronous
  Generators</title><categories>cs.LG cs.NE cs.SY eess.SY stat.ML</categories><comments>NAPS 2019 Conference. arXiv admin note: substantial text overlap with
  arXiv:1908.05191; text overlap with arXiv:1908.05199</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a neural network heuristic dynamic programing (HDP) is used for
optimal control of the virtual inertia based control of grid connected three
phase inverters. It is shown that the conventional virtual inertia controllers
are not suited for non inductive grids. A neural network based controller is
proposed to adapt to any impedance angle. Applying an adaptive dynamic
programming controller instead of a supervised controlled method enables the
system to adjust itself to different conditions. The proposed HDP consists of
two subnetworks, critic network and action network. These networks can be
trained during the same training cycle to decrease the training time. The
simulation results confirm that the proposed neural network HDP controller
performs better than the traditional direct fed voltage and reactive power
controllers in virtual inertia control schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05750</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05750</id><created>2019-08-15</created><updated>2019-12-07</updated><authors><author><keyname>Battan</keyname><forenames>Neeraj</forenames></author><author><keyname>Venkat</keyname><forenames>Abbhinav</forenames></author><author><keyname>Sharma</keyname><forenames>Avinash</forenames></author></authors><title>DeepHuMS: Deep Human Motion Signature for 3D Skeletal Sequences</title><categories>cs.CV cs.LG eess.IV</categories><comments>Under Review, Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D Human Motion Indexing and Retrieval is an interesting problem due to the
rise of several data-driven applications aimed at analyzing and/or re-utilizing
3D human skeletal data, such as data-driven animation, analysis of sports
bio-mechanics, human surveillance etc. Spatio-temporal articulations of humans,
noisy/missing data, different speeds of the same motion etc. make it
challenging and several of the existing state of the art methods use hand-craft
features along with optimization based or histogram based comparison in order
to perform retrieval. Further, they demonstrate it only for very small datasets
and few classes. We make a case for using a learned representation that should
recognize the motion as well as enforce a discriminative ranking. To that end,
we propose, a 3D human motion descriptor learned using a deep network. Our
learned embedding is generalizable and applicable to real-world data -
addressing the aforementioned challenges and further enables sub-motion
searching in its embedding space using another network. Our model exploits the
inter-class similarity using trajectory cues, and performs far superior in a
self-supervised setting. State of the art results on all these fronts is shown
on two large scale 3D human motion datasets - NTU RGB+D and HDM05.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05755</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05755</id><created>2019-08-15</created><updated>2019-08-19</updated><authors><author><keyname>Ardeshiri</keyname><forenames>Ghazaleh</forenames></author><author><keyname>Yazdani</keyname><forenames>Hassan</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>Power Adaptation for Distributed Detection in Energy Harvesting WSNs
  with Finite-Capacity Battery</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless sensor network, consisting of N heterogeneous sensors
and a fusion center (FC), that is tasked with solving a binary distributed
detection problem. Each sensor is capable of harvesting randomly arrived energy
and storing it in a finite capacity battery. Sensors are informed of their
fading channel states, via a bandwidth-limited feedback channel from the FC.
Each sensor has the knowledge of its current battery state and its channel
state (quantized channel gain). Our goal is to study how sensors should choose
their transmit powers such that J-divergence of the received signal densities
under two hypotheses at the FC is maximized, subject to certain (battery and
power) constraints. We derive the optimal power map, which depends on the
energy arrival rate, the battery capacity, and the battery states probabilities
at the steady state. Using the optimal power map, each sensor optimally adapts
its transmit power, based on its battery state and its channel state. Our
simulation results demonstrate the performance of our proposed power adaptation
scheme for different system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05761</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05761</id><created>2019-08-13</created><updated>2019-09-28</updated><authors><author><keyname>Bian</keyname><forenames>Zichao</forenames></author><author><keyname>Jiang</keyname><forenames>Shaowei</forenames></author><author><keyname>Song</keyname><forenames>Pengming</forenames></author><author><keyname>Zhang</keyname><forenames>He</forenames></author><author><keyname>Hoveida</keyname><forenames>Pouria</forenames></author><author><keyname>Hoshino</keyname><forenames>Kazunori</forenames></author><author><keyname>Zheng</keyname><forenames>Guoan</forenames></author></authors><title>Ptychographic modulation engine (PME): a low-cost DIY microscope add-on
  for coherent super-resolution imaging</title><categories>physics.ins-det eess.IV physics.optics</categories><doi>10.1088/1361-6463/ab489d</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging of biological cells and tissues often relies on fluorescent labels,
which offer high contrast with molecular specificity. The use of exogenous
labeling agents, however, may alter the normal physiology of the bio-specimens.
Complementary to the established fluorescence microscopy, label-free
quantitative phase imaging provides an objective morphological measurement tool
for bio-specimens and is free of variability introduced by contrast agents.
Here we report a simple and low-cost microscope add-on, termed Ptychographic
Modulation Engine (PME), for super-resolution quantitative phase imaging. In
this microscope add-on module, we attach a diffuser to a 3D-printed holder that
can be mechanically moved to different x-y positions. We then use two
vibrational motors to introduce random positional shifts to the diffuser. The
add-on module can be placed between the objective lens and the specimen in most
existing microscope platforms. Thanks to the diffuser modulation process, the
otherwise inaccessible high-resolution object information can now be encoded
into the captured images. In the ptychographic phase retrieval process, we
jointly recover the complex object wavefront, the complex diffuser profile, and
the unknown positional shifts of the diffuser. We demonstrate a 4-fold
resolution gain over the diffraction limit of the employed 2X objective lens.
We also test our approach for in-vivo cell imaging, where we are able to adjust
the focus after the data has been captured. The reported microscope add-on
provides a turnkey solution for super-resolution quantitative phase imaging. It
may find applications in label-free bio-imaging where both large field-of-view
and high resolution are needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05764</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05764</id><created>2019-08-15</created><authors><author><keyname>Huijben</keyname><forenames>Iris A. M.</forenames></author><author><keyname>Veeling</keyname><forenames>Bastiaan S.</forenames></author><author><keyname>Janse</keyname><forenames>Kees</forenames></author><author><keyname>Mischi</keyname><forenames>Massimo</forenames></author><author><keyname>van Sloun</keyname><forenames>Ruud J. G.</forenames></author></authors><title>Learning Sub-Sampling and Signal Recovery with Applications in
  Ultrasound Imaging</title><categories>eess.IV cs.LG</categories><comments>The paper is 10 pages with 7 figures (subfigures not counted
  seperately). The paper is send for review to the IEEE TMI journal</comments><msc-class>94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Limitations on bandwidth and power consumption impose strict bounds on data
rates of diagnostic imaging systems. Consequently, the design of suitable (i.e.
task- and data-aware) compression and reconstruction techniques has attracted
considerable attention in recent years. Compressed sensing emerged as a popular
framework for sparse signal reconstruction from a small set of compressed
measurements. However, typical compressed sensing designs measure a
(non)linearly weighted combination of all input signal elements, which poses
practical challenges. These designs are also not necessarily task-optimal. In
addition, real-time recovery is hampered by the iterative and time-consuming
nature of sparse recovery algorithms. Recently, deep learning methods have
shown promise for fast recovery from compressed measurements, but the design of
adequate and practical sensing strategies remains a challenge. Here, we propose
a deep learning solution, termed LASSY (LeArning Sub-Sampling and recoverY),
that jointly learns a task-driven sub-sampling pattern and subsequent
reconstruction model. The learned sub-sampling patterns are straightforwardly
implementable, and based on the task at hand. LASSY's effectiveness is
demonstrated in-silico for sparse signal recovery from partial Fourier
measurements, and in-vivo for both anatomical-image and motion (Doppler)
reconstruction from sub-sampled medical ultrasound imaging data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05782</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05782</id><created>2019-08-15</created><authors><author><keyname>Huang</keyname><forenames>Ouwen</forenames></author><author><keyname>Long</keyname><forenames>Will</forenames></author><author><keyname>Bottenus</keyname><forenames>Nick</forenames></author><author><keyname>Trahey</keyname><forenames>Gregg E.</forenames></author><author><keyname>Farsiu</keyname><forenames>Sina</forenames></author><author><keyname>Palmeri</keyname><forenames>Mark L.</forenames></author></authors><title>MimickNet, Matching Clinical Post-Processing Under Realistic Black-Box
  Constraints</title><categories>eess.IV cs.CV stat.ML</categories><comments>This work has been submitted to the IEEE Transactions on Medical
  Imaging on July 1st, 2019 for possible publication. Copyright may be
  transferred without notice, after which this version may no longer be
  accessible</comments><doi>10.5281/zenodo.3368028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image post-processing is used in clinical-grade ultrasound scanners to
improve image quality (e.g., reduce speckle noise and enhance contrast). These
post-processing techniques vary across manufacturers and are generally kept
proprietary, which presents a challenge for researchers looking to match
current clinical-grade workflows. We introduce a deep learning framework,
MimickNet, that transforms raw conventional delay-and-summed (DAS) beams into
the approximate post-processed images found on clinical-grade scanners.
Training MimickNet only requires post-processed image samples from a scanner of
interest without the need for explicit pairing to raw DAS data. This
flexibility allows it to hypothetically approximate any manufacturer's
post-processing without access to the pre-processed data. MimickNet generates
images with an average similarity index measurement (SSIM) of 0.930$\pm$0.0892
on a 300 cineloop test set, and it generalizes to cardiac cineloops outside of
our train-test distribution achieving an SSIM of 0.967$\pm$0.002. We also
explore the theoretical SSIM achievable by evaluating MimickNet performance
when trained under gray-box constraints (i.e., when both pre-processed and
post-processed images are available). To our knowledge, this is the first work
to establish deep learning models that closely approximate current
clinical-grade ultrasound post-processing under realistic black-box constraints
where before and after post-processing data is unavailable. MimickNet serves as
a clinical post-processing baseline for future works in ultrasound image
formation to compare against. To this end, we have made the MimickNet software
open source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05794</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05794</id><created>2019-08-15</created><authors><author><keyname>Puscas</keyname><forenames>Mihai Marian</forenames></author><author><keyname>Xu</keyname><forenames>Dan</forenames></author><author><keyname>Pilzer</keyname><forenames>Andrea</forenames></author><author><keyname>Sebe</keyname><forenames>Nicu</forenames></author></authors><title>Structured Coupled Generative Adversarial Networks for Unsupervised
  Monocular Depth Estimation</title><categories>cs.CV eess.IV</categories><comments>Accepted at 3DV 2019 as ORAL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the success of adversarial learning, we propose a new end-to-end
unsupervised deep learning framework for monocular depth estimation consisting
of two Generative Adversarial Networks (GAN), deeply coupled with a structured
Conditional Random Field (CRF) model. The two GANs aim at generating distinct
and complementary disparity maps and at improving the generation quality via
exploiting the adversarial learning strategy. The deep CRF coupling model is
proposed to fuse the generative and discriminative outputs from the dual GAN
nets. As such, the model implicitly constructs mutual constraints on the two
network branches and between the generator and discriminator. This facilitates
the optimization of the whole network for better disparity generation.
Extensive experiments on the KITTI, Cityscapes, and Make3D datasets clearly
demonstrate the effectiveness of the proposed approach and show superior
performance compared to state of the art methods. The code and models are
available at https://github.com/mihaipuscas/ 3dv---coupled-crf-disparity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05798</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05798</id><created>2019-08-15</created><authors><author><keyname>Mambou</keyname><forenames>Elie Ngomseu</forenames></author><author><keyname>Tonnellier</keyname><forenames>Thibaud</forenames></author><author><keyname>Hashemi</keyname><forenames>Seyyed Ali</forenames></author><author><keyname>Gross</keyname><forenames>Warren J.</forenames></author></authors><title>Efficient Flicker-Free FEC Codes using Knuth's Balancing Algorithm for
  VLC</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 8 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) provides a short-range optical wireless
communication through light-emitting diode (LED) lighting. Light beam
flickering and dimming are among the challenges to be addressed in VLC.
Conventional methods for generating flicker-free codes in VLC are based on
run-length limited codes that have poor error correction performance, use
lookup tables which are memory consuming, and have low transmission rates. In
this paper, we propose an efficient construction of flicker-free forward error
correction codes to tackle the issue of flickering in VLC. Our simulation
results show that by using polar codes and at a dimming ratio of 50%, the
proposed system generates flicker-free codes without using lookup tables, while
having lower complexity and higher transmission rates than the standard VLC
methods. For an information block length of 256, the error correction
performance of the proposed scheme is $1.8$ dB and $0.9$ dB better than that of
the regular schemes at the bit error rate of $10^{-6}$ for a rate of 0.44 and
0.23, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05804</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05804</id><created>2019-08-15</created><updated>2019-10-26</updated><authors><author><keyname>Guo</keyname><forenames>Hongzhi</forenames></author><author><keyname>Ben</keyname><forenames>Bincy</forenames></author></authors><title>Reinforcement Learning-Enabled Reliable Wireless Sensor Networks in
  Dynamic Underground Environments</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless underground sensor networks play an important role in underground
sensing such as climate-smart agriculture and underground infrastructure
monitoring. Existing works consider a static underground environment, which is
not practical since the dielectric parameters of soil change frequently due to
precipitation and harsh weather. This challenge cannot be ignored in real
implementation due to the drastic change of wireless underground channel. In
this paper, we study the effect of dynamic underground environment on wireless
communications for sensor networks. We use the real data collected by in-situ
sensors to train a Hidden Markov Model. Then, by using reinforcement learning,
we derive the optimal transmission policies for underground sensors to
efficiently use their energy and reduce the number of dropped and
unsuccessfully transmitted packets. Through simulations using real data, we
find that the developed algorithm can reduce the packet loss and transmit the
sensed data in a timely manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05817</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05817</id><created>2019-08-15</created><authors><author><keyname>Shi</keyname><forenames>Libao</forenames></author><author><keyname>Pan</keyname><forenames>Yang</forenames></author><author><keyname>Ni</keyname><forenames>Yixin</forenames></author></authors><title>An Analytical Probabilistic Expression for Modeling Sum of
  Spatial-dependent Wind Power Output</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying probability-related knowledge to accurately explore and exploit the
inherent uncertainty of wind power output is one of the key issues that need to
be solved urgently in the development of smart grid. This letter develops an
analytical probabilistic expression for modeling sum of spatial-dependent wind
farm power output through introducing unit impulse function, copulas, and
Gaussian mixture model. A comparative Monte Carlo sampling study is given to
illustrate the validity of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05835</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05835</id><created>2019-08-15</created><updated>2019-08-19</updated><authors><author><keyname>Xiang</keyname><forenames>Qikun</forenames></author><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author></authors><title>Bayesian Spatial Field Reconstruction with Unknown Distortions in Sensor
  Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial regression of random fields based on unreliable sensing information
is proposed in this paper. One major concern in such applications is that since
it is not known a-priori what the accuracy of the collected data from each
sensor is, the performance can be negatively affected if the collected
information is not fused appropriately. For example, the data collector may
measure the phenomenon inappropriately, or alternatively, the sensors could be
out of calibration, thus introducing random gain and bias to the measurement
process. Such readings would be systematically distorted, leading to incorrect
estimation of the spatial field. To combat this detrimental effect, we develop
a robust version of the spatial field model based on a mixture of Gaussian
process experts. We then develop two different approaches for Bayesian spatial
field reconstruction: the first algorithm is the Spatial Best Linear Unbiased
Estimator (S-BLUE), in which one considers a quadratic loss functions and
restricts the estimator to the linear family of transformations; the second
algorithm is based on empirical Bayes, which utilises a two-stage estimation
procedure to produce accurate predictive inference in the presence of
&quot;misbehaving&quot; sensors. We present extensive simulation results of both
synthetic and real-world scenarios and draw useful conclusions regarding the
performance of each of the algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05843</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05843</id><created>2019-08-16</created><authors><author><keyname>Fooladivanda</keyname><forenames>Dariush</forenames></author><author><keyname>Hu</keyname><forenames>Qie</forenames></author><author><keyname>Chang</keyname><forenames>Young Hwan</forenames></author><author><keyname>Sauer</keyname><forenames>Peter</forenames></author></authors><title>Secure State Estimation and Control for Cyber Security of AC Microgrids</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A timely, accurate, and secure dynamic state estimation is needed for
reliable monitoring and efficient control of microgrids. The synchrophasor
technology enables us to obtain synchronized measurements in real-time and to
develop dynamic state estimators for real-time monitoring and control of
microgrids. In this study, we consider an AC microgrid comprising several
synchronous generators and inverter-interface power supplies, and focus on
securely estimating the dynamic states of the microgrid from a set of corrupted
data. We propose a dynamic state estimator which enables the microgrid operator
to reconstruct the dynamic states of the microgrid from a set of corrupted
data. Finally, we consider an AC microgrid with the same topology as the IEEE
33-bus distribution system, and numerically show that the proposed secure
estimation algorithm can accurately reconstruct the attack signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05857</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05857</id><created>2019-08-16</created><authors><author><keyname>Mukherjee</keyname><forenames>Sudarshan</forenames></author><author><keyname>Lee</keyname><forenames>Jemin</forenames></author></authors><title>Edge Computing-Enabled Cell-Free Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile edge computing (MEC) has been introduced to provide additional
computing capabilities at network edges in order to improve performance of
latency critical applications. In this paper, we consider the cell-free (CF)
massive MIMO framework with implementing MEC functionalities. We consider
multiple types of users with different average time requirements for
computing/processing the tasks, and consider access points (APs) with MEC
servers and a central server (CS) with the cloud computing capability. After
deriving successful communication and computing probabilities using stochastic
geometry and queueing theory, we present the successful edge computing
probability (SECP) for a target computation latency. Through numerical results,
we also analyze the impact of the AP coverage and the offloading probability to
the CS on the SECP. It is observed that the optimal probability of offloading
to the CS in terms of the SECP decreases with the AP coverage. Finally, we
numerically characterize the minimum required energy consumption for
guaranteeing a desired level of SECP. It is observed that for any desired level
of SECP, it is more energy efficient to have larger number of APs as compared
to having more number of antennas at each AP with smaller AP density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05858</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05858</id><created>2019-08-16</created><authors><author><keyname>Zhang</keyname><forenames>Jianhao</forenames></author><author><keyname>Pan</keyname><forenames>Yingwei</forenames></author><author><keyname>Yao</keyname><forenames>Ting</forenames></author><author><keyname>Zhao</keyname><forenames>He</forenames></author><author><keyname>Mei</keyname><forenames>Tao</forenames></author></authors><title>daBNN: A Super Fast Inference Framework for Binary Neural Networks on
  ARM devices</title><categories>cs.CV cs.MM eess.IV</categories><comments>Accepted by 2019 ACMMM Open Source Software Competition. Source code:
  https://github.com/JDAI-CV/dabnn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is always well believed that Binary Neural Networks (BNNs) could
drastically accelerate the inference efficiency by replacing the arithmetic
operations in float-valued Deep Neural Networks (DNNs) with bit-wise
operations. Nevertheless, there has not been open-source implementation in
support of this idea on low-end ARM devices (e.g., mobile phones and embedded
devices). In this work, we propose daBNN --- a super fast inference framework
that implements BNNs on ARM devices. Several speed-up and memory refinement
strategies for bit-packing, binarized convolution, and memory layout are
uniquely devised to enhance inference efficiency. Compared to the recent
open-source BNN inference framework, BMXNet, our daBNN is
$7\times$$\sim$$23\times$ faster on a single binary convolution, and about
$6\times$ faster on Bi-Real Net 18 (a BNN variant of ResNet-18). The daBNN is a
BSD-licensed inference framework, and its source code, sample projects and
pre-trained models are available on-line: https://github.com/JDAI-CV/dabnn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05863</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05863</id><created>2019-08-16</created><authors><author><keyname>Qiao</keyname><forenames>Tianhao</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Zhang</keyname><forenames>Zhichao</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author></authors><title>Sub-Spectrogram Segmentation for Environmental Sound Classification via
  Convolutional Recurrent Neural Network and Score Level Fusion</title><categories>cs.SD cs.LG eess.AS</categories><comments>accepted in the 2019 IEEE International Workshop on Signal Processing
  Systems (SiPS2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental Sound Classification (ESC) is an important and challenging
problem, and feature representation is a critical and even decisive factor in
ESC. Feature representation ability directly affects the accuracy of sound
classification. Therefore, the ESC performance is heavily dependent on the
effectiveness of representative features extracted from the environmental
sounds. In this paper, we propose a subspectrogram segmentation based ESC
classification framework. In addition, we adopt the proposed Convolutional
Recurrent Neural Network (CRNN) and score level fusion to jointly improve the
classification accuracy. Extensive truncation schemes are evaluated to find the
optimal number and the corresponding band ranges of sub-spectrograms. Based on
the numerical experiments, the proposed framework can achieve 81.9% ESC
classification accuracy on the public dataset ESC-50, which provides 9.1%
accuracy improvement over traditional baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05874</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05874</id><created>2019-08-16</created><updated>2019-12-07</updated><authors><author><keyname>Nguyen</keyname><forenames>Dan</forenames></author><author><keyname>McBeth</keyname><forenames>Rafe</forenames></author><author><keyname>Barkousaraie</keyname><forenames>Azar Sadeghnejad</forenames></author><author><keyname>Bohara</keyname><forenames>Gyanendra</forenames></author><author><keyname>Shen</keyname><forenames>Chenyang</forenames></author><author><keyname>Jia</keyname><forenames>Xun</forenames></author><author><keyname>Jiang</keyname><forenames>Steve</forenames></author></authors><title>Incorporating human and learned domain knowledge into training deep
  neural networks: A differentiable dose volume histogram and adversarial
  inspired framework for generating Pareto optimal dose distributions in
  radiation therapy</title><categories>physics.med-ph cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel domain specific loss, which is a differentiable loss
function based on the dose volume histogram, and combine it with an adversarial
loss for the training of deep neural networks to generate Pareto optimal dose
distributions. The mean squared error (MSE) loss, dose volume histogram (DVH)
loss, and adversarial (ADV) loss were used to train 4 instances of the neural
network model: 1) MSE, 2) MSE+ADV, 3) MSE+DVH, and 4) MSE+DVH+ADV. 70 prostate
patients were acquired, and the dose influence arrays were calculated for each
patient. 1200 Pareto surface plans per patient were generated by
pseudo-randomizing the tradeoff weights (84,000 plans total). We divided the
data into 54 training, 6 validation, and 10 testing patients. Each model was
trained for 100,000 iterations, with a batch size of 2. The prediction time of
each model is 0.052 seconds. Quantitatively, the MSE+DVH+ADV model had the
lowest prediction error of 0.038 (conformation), 0.026 (homogeneity), 0.298
(R50), 1.65% (D95), 2.14% (D98), 2.43% (D99). The MSE model had the worst
prediction error of 0.134 (conformation), 0.041 (homogeneity), 0.520 (R50),
3.91% (D95), 4.33% (D98), 4.60% (D99). For both the mean dose PTV error and the
max dose PTV, Body, Bladder and rectum error, the MSE+DVH+ADV outperformed all
other models. All model's predictions have an average mean and max dose error
less than 2.8% and 4.2%, respectively. Expert human domain specific knowledge
can be the largest driver in the performance improvement, and adversarial
learning can be used to further capture nuanced features. The real-time
prediction capabilities allow for a physician to quickly navigate the tradeoff
space, and produce a dose distribution as a tangible endpoint for the
dosimetrist to use for planning. This can considerably reduce the treatment
planning time, allowing for clinicians to focus their efforts on challenging
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05887</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05887</id><created>2019-08-16</created><updated>2019-09-25</updated><authors><author><keyname>Li</keyname><forenames>Xiangyu</forenames></author><author><keyname>Luo</keyname><forenames>Gongning</forenames></author><author><keyname>Wang</keyname><forenames>Kuanquan</forenames></author></authors><title>Multi-step Cascaded Networks for Brain Tumor Segmentation</title><categories>eess.IV cs.CV</categories><comments>Paper for BraTS 2019 runs in conjunction with the MICCAI 2019
  conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic brain tumor segmentation method plays an extremely important role
in the whole process of brain tumor diagnosis and treatment. In this paper, we
propose a multi-step cascaded network which takes the hierarchical topology of
the brain tumor substructures into consideration and segments the substructures
from coarse to fine .During segmentation, the result of the former step is
utilized as the prior information for the next step to guide the finer
segmentation process. The whole network is trained in an end-to-end fashion.
Besides, to alleviate the gradient vanishing issue and reduce overfitting, we
added several auxiliary outputs as a kind of deep supervision for each step and
introduced several data augmentation strategies, respectively, which proved to
be quite efficient for brain tumor segmentation. Lastly, focal loss is utilized
to solve the problem of remarkably imbalance of the tumor regions and
background. Our model is tested on the BraTS 2019 validation dataset, the
preliminary results of mean dice coefficients are 0.886, 0.813, 0.771 for the
whole tumor, tumor core and enhancing tumor respectively. Code is available at
https://github.com/JohnleeHIT/Brats2019
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05895</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05895</id><created>2019-08-16</created><authors><author><keyname>Park</keyname><forenames>Jihong</forenames></author><author><keyname>Wang</keyname><forenames>Shiqiang</forenames></author><author><keyname>Elgabli</keyname><forenames>Anis</forenames></author><author><keyname>Oh</keyname><forenames>Seungeun</forenames></author><author><keyname>Jeong</keyname><forenames>Eunjeong</forenames></author><author><keyname>Cha</keyname><forenames>Han</forenames></author><author><keyname>Kim</keyname><forenames>Hyesung</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Lyun</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>Distilling On-Device Intelligence at the Network Edge</title><categories>cs.IT cs.LG cs.NI eess.SP math.IT</categories><comments>7 pages, 6 figures; This work has been submitted to the IEEE for
  possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Devices at the edge of wireless networks are the last mile data sources for
machine learning (ML). As opposed to traditional ready-made public datasets,
these user-generated private datasets reflect the freshest local environments
in real time. They are thus indispensable for enabling mission-critical
intelligent systems, ranging from fog radio access networks (RANs) to
driverless cars and e-Health wearables. This article focuses on how to distill
high-quality on-device ML models using fog computing, from such user-generated
private data dispersed across wirelessly connected devices. To this end, we
introduce communication-efficient and privacy-preserving distributed ML
frameworks, termed fog ML (FML), wherein on-device ML models are trained by
exchanging model parameters, model outputs, and surrogate data. We then present
advanced FML frameworks addressing wireless RAN characteristics, limited
on-device resources, and imbalanced data distributions. Our study suggests that
the full potential of FML can be reached by co-designing communication and
distributed ML operations while accounting for heterogeneous hardware
specifications, data characteristics, and user requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05898</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05898</id><created>2019-08-16</created><authors><author><keyname>Lu</keyname><forenames>Rui</forenames></author><author><keyname>Xue</keyname><forenames>Feng</forenames></author><author><keyname>Zhou</keyname><forenames>Menghan</forenames></author><author><keyname>Ming</keyname><forenames>Anlong</forenames></author><author><keyname>Zhou</keyname><forenames>Yu</forenames></author></authors><title>Occlusion-shared and Feature-separated Network for Occlusion
  Relationship Reasoning</title><categories>cs.CV eess.IV</categories><comments>Accepted by ICCV 2019. Code and pretrained model are available at
  https://github.com/buptlr/OFNet</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Occlusion relationship reasoning demands closed contour to express the
object, and orientation of each contour pixel to describe the order
relationship between objects. Current CNN-based methods neglect two critical
issues of the task: (1) simultaneous existence of the relevance and distinction
for the two elements, i.e, occlusion edge and occlusion orientation; and (2)
inadequate exploration to the orientation features. For the reasons above, we
propose the Occlusion-shared and Feature-separated Network (OFNet). On one
hand, considering the relevance between edge and orientation, two sub-networks
are designed to share the occlusion cue. On the other hand, the whole network
is split into two paths to learn the high-level semantic features separately.
Moreover, a contextual feature for orientation prediction is extracted, which
represents the bilateral cue of the foreground and background areas. The
bilateral cue is then fused with the occlusion cue to precisely locate the
object regions. Finally, a stripe convolution is designed to further aggregate
features from surrounding scenes of the occlusion edge. The proposed OFNet
remarkably advances the state-of-the-art approaches on PIOD and BSDS ownership
dataset. The source code is available at https://github.com/buptlr/OFNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05911</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05911</id><created>2019-08-16</created><authors><author><keyname>Corona</keyname><forenames>Veronica</forenames></author><author><keyname>Aviles-Rivero</keyname><forenames>Angelica I.</forenames></author><author><keyname>Debroux</keyname><forenames>No&#xe9;mie</forenames></author><author><keyname>Guyader</keyname><forenames>Carole Le</forenames></author><author><keyname>Sch&#xf6;nlieb</keyname><forenames>Carola-Bibiane</forenames></author></authors><title>Variational Multi-Task MRI Reconstruction: Joint Reconstruction,
  Registration and Super-Resolution</title><categories>eess.IV cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion degradation is a central problem in Magnetic Resonance Imaging (MRI).
This work addresses the problem of how to obtain higher quality, super-resolved
motion-free, reconstructions from highly undersampled MRI data. In this work,
we present for the first time a variational multi-task framework that allows
joining three relevant tasks in MRI: reconstruction, registration and
super-resolution. Our framework takes a set of multiple undersampled MR
acquisitions corrupted by motion into a novel multi-task optimisation model,
which is composed of an $L^2$ fidelity term that allows sharing representation
between tasks, super-resolution foundations and hyperelastic deformations to
model biological tissue behaviors. We demonstrate that this combination yields
to significant improvements over sequential models and other bi-task methods.
Our results exhibit fine details and compensate for motion producing sharp and
highly textured images compared to state of the art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05926</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05926</id><created>2019-08-16</created><authors><author><keyname>Brudfors</keyname><forenames>Mikael</forenames></author><author><keyname>Ashburner</keyname><forenames>John</forenames></author><author><keyname>Nachev</keyname><forenames>Parashkev</forenames></author><author><keyname>Balbastre</keyname><forenames>Yael</forenames></author></authors><title>Empirical Bayesian Mixture Models for Medical Image Translation</title><categories>eess.IV cs.CV</categories><comments>Accepted to the Simulation and Synthesis in Medical Imaging (SASHIMI)
  workshop at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatically generating one medical imaging modality from another is known
as medical image translation, and has numerous interesting applications. This
paper presents an interpretable generative modelling approach to medical image
translation. By allowing a common model for group-wise normalisation and
segmentation of brain scans to handle missing data, the model allows for
predicting entirely missing modalities from one, or a few, MR contrasts.
Furthermore, the model can be trained on a fairly small number of subjects. The
proposed model is validated on three clinically relevant scenarios. Results
appear promising and show that a principled, probabilistic model of the
relationship between multi-channel signal intensities can be used to infer
missing modalities -- both MR contrasts and CT images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05946</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05946</id><created>2019-08-16</created><authors><author><keyname>Petrov</keyname><forenames>Vitaly</forenames></author><author><keyname>Moltchanov</keyname><forenames>Dmitri</forenames></author><author><keyname>Andreev</keyname><forenames>Sergey</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Analysis of Intelligent Vehicular Relaying in Urban 5G+ Millimeter-Wave
  Cellular Deployments</title><categories>cs.NI eess.SP</categories><comments>6 pages, 8 figures. The paper has been accepted for IEEE GLOBECOM
  2019. Copyright may be transferred without notice, after which this version
  may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capability of smarter networked devices to dynamically select appropriate
radio connectivity options is especially important in the emerging
millimeter-wave (mmWave) systems to mitigate abrupt link blockage in complex
environments. To enrich the levels of diversity, mobile mmWave relays can be
employed for improved connection reliability. These are considered by 3GPP for
on-demand densification on top of the static mmWave infrastructure. However,
performance dynamics of mobile mmWave relaying is not nearly well explored,
especially in realistic conditions, such as urban vehicular scenarios. In this
paper, we develop a mathematical framework for the performance evaluation of
mmWave vehicular relaying in a typical street deployment. We analyze and
compare alternative connectivity strategies by quantifying the performance
gains made available to smart devices in the presence of mmWave relays. We
identify situations where the use of mmWave vehicular relaying is particularly
beneficial. Our methodology and results can support further standardization and
deployment of mmWave relaying in more intelligent 5G+ &quot;all-mmWave&quot; cellular
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05959</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05959</id><created>2019-08-16</created><updated>2019-09-17</updated><authors><author><keyname>Orbes-Arteaga</keyname><forenames>Mauricio</forenames></author><author><keyname>Varsavsky</keyname><forenames>Thomas</forenames></author><author><keyname>Sudre</keyname><forenames>Carole H.</forenames></author><author><keyname>Eaton-Rosen</keyname><forenames>Zach</forenames></author><author><keyname>Haddow</keyname><forenames>Lewis J.</forenames></author><author><keyname>S&#xf8;rensen</keyname><forenames>Lauge</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author><author><keyname>Pai</keyname><forenames>Akshay</forenames></author><author><keyname>Ourselin</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Modat</keyname><forenames>Marc</forenames></author><author><keyname>Nachev</keyname><forenames>Parashkev</forenames></author><author><keyname>Cardoso</keyname><forenames>M. Jorge</forenames></author></authors><title>Multi-Domain Adaptation in Brain MRI through Paired Consistency and
  Adversarial Learning</title><categories>eess.IV cs.AI cs.CV cs.LG stat.ML</categories><comments>Accepted at 1st International Workshop on Domain Adaptation and
  Representation Transfer held at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised learning algorithms trained on medical images will often fail to
generalize across changes in acquisition parameters. Recent work in domain
adaptation addresses this challenge and successfully leverages labeled data in
a source domain to perform well on an unlabeled target domain. Inspired by
recent work in semi-supervised learning we introduce a novel method to adapt
from one source domain to $n$ target domains (as long as there is paired data
covering all domains). Our multi-domain adaptation method utilises a
consistency loss combined with adversarial learning. We provide results on
white matter lesion hyperintensity segmentation from brain MRIs using the
MICCAI 2017 challenge data as the source domain and two target domains. The
proposed method significantly outperforms other domain adaptation baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05991</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05991</id><created>2019-08-16</created><authors><author><keyname>Rudsari</keyname><forenames>Hamid Khoshfekr</forenames></author><author><keyname>Javan</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Multiple-type Transmission Multiple-type Reception Framework on
  Molecular Communication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new Multiple-Input Multiple-Output (MIMO)
Molecular Communication (MC) system where multiple types of molecules are
utilized for transmission and reception of information. We call the proposed
framework as Multiple-type Transmission and Multiple-type Reception (MTMR). We
also obtain the bit error rate (BER) of the system and an optimization problem
is formulated to minimize BER by optimizing the drug dosage for designing drug
release mechanism. As numerical analysis shows, the BER of MIMO-MTMR in MC is
minimized to $\text{3.7}\times\text{10}^{\text{-3}}$ by considering the budget
of molecules as 10000. Furthermore, MIMO-MTMR outperforms Single-type
Transmission Single-type Reception MIMO from the BER performance point of view
approximately 54% for time slot 10s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05995</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.05995</id><created>2019-08-16</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author></authors><title>Stability Results for the Continuity Equation</title><categories>math.OC cs.SY eess.SY math.AP</categories><comments>18 pages, to be submitted to Systems and Control Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a thorough study of stability of the 1-D continuity equation,
which models many physical conservation laws. In our system-theoretic
perspective, the velocity is considered to be an input. An additional input
appears in the boundary condition (boundary disturbance). Stability estimates
are provided in all Lp state norms with p&gt;1, as well as in the sup norm.
However, in our Input-to-State Stability estimates, the gain and overshoot
coefficients depend on the velocity. Moreover, the logarithmic norm of the
state appears instead of the usual norm. The obtained results can be used in
the stability analysis of larger models that contain the continuity equation.
In particular, it is shown that the obtained results can be used in a
straightforward way for the stability analysis of non-local, nonlinear
manufacturing models under feedback control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06047</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06047</id><created>2019-08-16</created><authors><author><keyname>Baghaie</keyname><forenames>Ahmadreza</forenames></author></authors><title>Robust Principal Component Analysis for Background Estimation of
  Particle Image Velocimetry Data</title><categories>cs.CV eess.IV</categories><comments>Presented in LISAT 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Particle Image Velocimetry (PIV) data processing procedures are adversely
affected by light reflections and backgrounds as well as defects in the models
and sticky particles that occlude the inner walls of the boundaries. In this
paper, a novel approach is proposed for decomposition of the PIV data into
background/foreground components, greatly reducing the effects of such
artifacts. This is achieved by utilizing Robust Principal Component Analysis
(RPCA) applied to the data matrix, generated by aggregating the vectorized PIV
frames. It is assumed that the data matrix can be decomposed into two
statistically different components, a low-rank component depicting the still
background and a sparse component representing the moving particles within the
imaged geometry. Formulating the assumptions as an optimization problem,
Augmented Lagrange Multiplier (ALM) method is used for decomposing the data
matrix into the low-rank and sparse components. Experiments and comparisons
with the state-of-the-art using several PIV image sequences reveal the
superiority of the proposed approach for background removal of PIV data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06062</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06062</id><created>2019-08-16</created><authors><author><keyname>Liu</keyname><forenames>Daniel</forenames></author><author><keyname>Yu</keyname><forenames>Ronald</forenames></author><author><keyname>Su</keyname><forenames>Hao</forenames></author></authors><title>Adversarial point perturbations on 3D objects</title><categories>cs.CV cs.CR cs.LG eess.IV stat.ML</categories><comments>17 pages, source code available at this https url:
  https://github.com/Daniel-Liu-c0deb0t/Adversarial-point-perturbations-on-3D-objects</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of training robust neural network grows as 3D data is
increasingly utilized in deep learning for vision tasks, like autonomous
driving. We examine this problem from the perspective of the attacker, which is
necessary in understanding how neural networks can be exploited, and thus
defended. More specifically, we propose adversarial attacks based on solving
different optimization problems, like minimizing the perceptibility of our
generated adversarial examples, or maintaining a uniform density distribution
of points across the adversarial object surfaces. Our four proposed algorithms
for attacking 3D point cloud classification are all highly successful on
existing neural networks, and we find that some of them are even effective
against previously proposed point removal defenses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06065</identifier>
 <datestamp>2020-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06065</id><created>2019-08-16</created><updated>2020-01-08</updated><authors><author><keyname>Sheriff</keyname><forenames>Mohammed Rayyan</forenames></author><author><keyname>Chatterjee</keyname><forenames>Debasish</forenames></author></authors><title>On Convex Duality in Linear Inverse Problems</title><categories>cs.LG eess.SP math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we dwell into the class of so called ill posed Linear Inverse
Problems (LIP) in machine learning, which has become almost a classic in recent
times. The fundamental task in an LIP is to recover the entire signal / data
from its relatively few random linear measurements. Such problems arise in
variety of settings with applications ranging from medical image processing,
recommender systems etc. We provide an exposition to the convex duality of the
linear inverse problems, and obtain a novel and equivalent convex-concave
min-max reformulation that gives rise to simple ascend-descent type algorithms
to solve an LIP. Moreover, such a reformulation is crucial in developing
methods to solve the dictionary learning problem with almost sure recovery
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06070</identifier>
 <datestamp>2019-08-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06070</id><created>2019-08-16</created><authors><author><keyname>Vasconcelos</keyname><forenames>Marcos M.</forenames></author><author><keyname>Gagrani</keyname><forenames>Mukul</forenames></author><author><keyname>Nayyar</keyname><forenames>Ashutosh</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Optimal scheduling strategy for networked estimation with energy
  harvesting</title><categories>eess.SY cs.SY</categories><comments>25 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint optimization of scheduling and estimation policies is considered for a
system with two sensors and two non-collocated estimators. Each sensor produces
an independent and identically distributed sequence of random variables, and
each estimator forms estimates of the corresponding sequence with respect to
the mean-squared error sense. The data generated by the sensors is transmitted
to the corresponding estimators, over a bandwidth-constrained wireless network
that can support a single packet per time slot. The access to the limited
communication resources is determined by a scheduler who decides which sensor
measurement to transmit based on both observations. The scheduler has an
energy-harvesting battery of limited capacity, which couples the
decision-making problem in time. Despite the overall lack of convexity of the
team decision problem, it is shown that this system admits globally optimal
scheduling and estimation strategies under the assumption that the
distributions of the random variables at the sensors are symmetric and
unimodal. Additionally, the optimal scheduling policy has a structure
characterized by a threshold function that depends on the time index and energy
level. A recursive algorithm for threshold computation is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06131</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06131</id><created>2019-08-05</created><authors><author><keyname>Li</keyname><forenames>Weizi</forenames></author></authors><title>Simulation and Learning for Urban Mobility: City-scale Traffic
  Reconstruction and Autonomous Driving</title><categories>cs.OH eess.SP</categories><comments>PhD Thesis, Department of Computer Science, The University of North
  Carolina at Chapel Hill, July 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Traffic congestion has become one of the most critical issues worldwide. The
costs due to traffic gridlock and jams are approximately $160 billion in the
United States, more than {\pounds}13 billion in the United Kingdom, and over
one trillion dollars across the globe annually. As more metropolitan areas will
experience increasingly severe traffic conditions, the ability to analyze,
understand, and improve traffic dynamics becomes critical. This dissertation is
an effort towards achieving such an ability. I propose various techniques
combining simulation and machine learning to tackle the problem of traffic from
two perspectives: city-scale traffic reconstruction and autonomous driving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06137</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06137</id><created>2019-08-16</created><authors><author><keyname>de Fran&#xe7;a</keyname><forenames>Joelle Feij&#xf3;</forenames></author><author><keyname>Mendes</keyname><forenames>Hugo Abreu</forenames></author><author><keyname>Costa</keyname><forenames>Lucas Gallindo</forenames></author><author><keyname>Dantas</keyname><forenames>Andrea Tavares</forenames></author><author><keyname>Duarte</keyname><forenames>Angela Luzia Branco Pinto</forenames></author><author><keyname>Gomes</keyname><forenames>Anderson Stevens Le&#xf4;nidas</forenames></author><author><keyname>Lins</keyname><forenames>Emery Cleiton Cabral Correia</forenames></author></authors><title>Using Near Infrared Spectroscopy and Machine Learning to diagnose
  Systemic Sclerosis</title><categories>physics.med-ph cs.LG eess.SP</categories><comments>9 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The motivation of this work is the use of non-invasive and low cost
techniques to obtain a faster and more accurate diagnosis of systemic sclerosis
(SSc), rheumatic, autoimmune, chronic and rare disease. The technique in
question is Near Infrared Spectroscopy (NIRS). Spectra were acquired from three
different regions of hand's volunteers. Machine learning algorithms are used to
classify and search for the best optical wavelength. The results demonstrate
that it is easy to obtain wavelength bands more important for the diagnosis. We
use the algorithm RFECV and SVC. The results suggests that the most important
wavelength band is at 1270 nm, referring to the luminescence of Singlet Oxygen.
The results indicates that the Proximal Interphalangeal Joints region returns
better accuracy's scores. Optical spectrometers can be found at low prices and
can be easily used in clinical evaluations, while the algorithms used are
completely diffused on open source platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06152</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06152</id><created>2019-08-16</created><authors><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author></authors><title>Debunking Seven Myths about 5G New Radio</title><categories>cs.NI eess.SP</categories><comments>8 pages, 4 figures, 1 table, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New radio (NR) is a new wireless access technology developed as part of the
fifth-generation (5G) of mobile communications to support a wide range of
services, devices, and deployments. NR features spectrum flexibility,
ultra-lean design, forward compatibility, low latency support, and advanced
antenna technologies. There has been excitement about NR, sometimes clouded by
confusion. This article is an attempt to summarize and overview the key
features of NR by debunking seven of the more popular myths and revealing what
NR really is. The seven topics include spectrum, flexible waveform and multiple
access, LTE-NR interworking and coexistence, low latency support, massive
machine type communications, non-terrestrial communications, and beyond radio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06168</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06168</id><created>2019-08-16</created><authors><author><keyname>Khosla</keyname><forenames>Meenakshi</forenames></author><author><keyname>Jamison</keyname><forenames>Keith</forenames></author><author><keyname>Kuceyeski</keyname><forenames>Amy</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author></authors><title>Detecting abnormalities in resting-state dynamics: An unsupervised
  learning approach</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resting-state functional MRI (rs-fMRI) is a rich imaging modality that
captures spontaneous brain activity patterns, revealing clues about the
connectomic organization of the human brain. While many rs-fMRI studies have
focused on static measures of functional connectivity, there has been a recent
surge in examining the temporal patterns in these data. In this paper, we
explore two strategies for capturing the normal variability in resting-state
activity across a healthy population: (a) an autoencoder approach on the
rs-fMRI sequence, and (b) a next frame prediction strategy. We show that both
approaches can learn useful representations of rs-fMRI data and demonstrate
their novel application for abnormality detection in the context of
discriminating autism patients from healthy controls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06170</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06170</id><created>2019-08-11</created><authors><author><keyname>Hurley</keyname><forenames>Nathan C.</forenames></author><author><keyname>Spatz</keyname><forenames>Erica S.</forenames></author><author><keyname>Krumholz</keyname><forenames>Harlan M.</forenames></author><author><keyname>Jafari</keyname><forenames>Roozbeh</forenames></author><author><keyname>Mortazavi</keyname><forenames>Bobak J.</forenames></author></authors><title>A Survey of Challenges and Opportunities in Sensing and Analytics for
  Cardiovascular Disorders</title><categories>eess.SP cs.CY cs.LG</categories><comments>32 pages, 3 figures, to be submitted to ACM Transactions on Computing
  for Healthcare (HEALTH), Special Issue on Wearable Technologies for Smart
  Health 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Cardiovascular disorders account for nearly 1 in 3 deaths in the United
States. Care for these disorders are often determined during visits to acute
care facilities, such as hospitals. While the length of stay in these settings
represents just a small proportion of patients' lives, they account for a
disproportionately large amount of decision making. To overcome this bias
towards data from acute care settings, there is a need for longitudinal
monitoring in patients with cardiovascular disorders. Longitudinal monitoring
can provide a more comprehensive picture of patient health, allowing for more
informed decision making. This work surveys the current field of sensing
technologies and machine learning analytics that exist in the field of remote
monitoring for cardiovascular disorders. We highlight three primary needs in
the design of new smart health technologies: 1) the need for sensing technology
that can track longitudinal trends in signs and symptoms of the cardiovascular
disorder despite potentially infrequent, noisy, or missing data measurements;
2) the need for new analytic techniques that model data captured in a
longitudinal, continual fashion to aid in the development of new risk
prediction techniques and in tracking disease progression; and 3) the need for
machine learning techniques that are personalized and interpretable, allowing
for advancements in shared clinical decision making. We highlight these needs
based upon the current state-of-the-art in smart health technologies and
analytics and discuss the ample opportunities that exist in addressing all
three needs in the development of smart health technologies and analytics
applied to the field of cardiovascular disorders and care.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06171</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06171</id><created>2019-08-12</created><authors><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Yantong</forenames></author><author><keyname>Liu</keyname><forenames>Zhi</forenames></author><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author></authors><title>SleepGuardian: An RF-based Healthcare System Guarding Your Sleep from
  Afar</title><categories>eess.SP cs.CY cs.HC</categories><comments>17 pages accepted by IEEE Network Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever accelerating process of urbanization urges more and more population
into the swelling cities. While city residents are enjoying an entertaining
life supported by advanced informatics techniques like 5G and cloud computing,
the same technologies have also gradually deprived their sleep, which is
crucial for their wellness. Therefore, sleep monitoring has drawn significant
attention from both research and industry communities. In this article, we
first review the sleep monitoring issue and point out three essential
properties of an ideal sleep healthcare system, i.e., realtime guarding,
fine-grained logging, and cost-effectiveness. Based on the analysis, we present
SleepGuardian, a Radio Frequence (RF) based sleep healthcare system leveraging
signal processing, edge computing and machine learning.SleepGuardian offers an
offline sleep logging service and an online abnormality warning service. The
offline service provides a fine-grained sleep log like timing and regularity of
bed time, onset of sleep and night time awakenings. The online service keeps
guarding the subject for any abnormal behaviors during sleep like intensive
body twitches and a sudden seizure attack. Once an abnormality happens,it will
automatically warn the designated contacts like a nearby emergency room or a
closeby relative.We prototype SleepGuardian with low-cost WiFi devices and
evaluate it in real scenarios. Experimental results demonstrate that
SleepGuardian is very effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06194</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06194</id><created>2019-08-16</created><authors><author><keyname>Ali</keyname><forenames>Sharib</forenames></author><author><keyname>Rittscher</keyname><forenames>Jens</forenames></author></authors><title>Conv2Warp: An unsupervised deformable image registration with continuous
  convolution and warping</title><categories>cs.CV cs.LG eess.IV</categories><comments>8 pages (accepted at 10th International Workshop on Machine Learning
  in Medical Imaging, in conjunction with MICCAI2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent successes in deep learning based deformable image registration (DIR)
methods have demonstrated that complex deformation can be learnt directly from
data while reducing computation time when compared to traditional methods.
However, the reliance on fully linear convolutional layers imposes a uniform
sampling of pixel/voxel locations which ultimately limits their performance. To
address this problem, we propose a novel approach of learning a continuous warp
of the source image. Here, the required deformation vector fields are obtained
from a concatenated linear and non-linear convolution layers and a learnable
bicubic Catmull-Rom spline resampler. This allows to compute smooth deformation
field and more accurate alignment compared to using only linear convolutions
and linear resampling. In addition, the continuous warping technique penalizes
disagreements that are due to topological changes. Our experiments demonstrate
that this approach manages to capture large non-linear deformations and
minimizes the propagation of interpolation errors. While improving accuracy the
method is computationally efficient. We present comparative results on a range
of public 4D CT lung (POPI) and brain datasets (CUMC12, MGH10).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06210</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06210</id><created>2019-08-16</created><authors><author><keyname>Li</keyname><forenames>Fuwei</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On the Adversarial Robustness of Subspace Learning</title><categories>eess.SP cs.CR cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the adversarial robustness of subspace learning
problems. Different from the assumptions made in existing work on robust
subspace learning where data samples are contaminated by gross sparse outliers
or small dense noises, we consider a more powerful adversary who can first
observe the data matrix and then intentionally modify the whole data matrix. We
first characterize the optimal rank-one attack strategy that maximizes the
subspace distance between the subspace learned from the original data matrix
and that learned from the modified data matrix. We then generalize the study to
the scenario without the rank constraint and characterize the corresponding
optimal attack strategy. Our analysis shows that the optimal strategies depend
on the singular values of the original data matrix and the adversary's energy
budget. Finally, we provide numerical experiments and practical applications to
demonstrate the efficiency of the attack strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06232</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06232</id><created>2019-08-16</created><authors><author><keyname>Hafiz</keyname><forenames>Faizal</forenames></author><author><keyname>Swain</keyname><forenames>Akshya</forenames></author><author><keyname>Mendes</keyname><forenames>Eduardo MAM</forenames></author></authors><title>Multi-Objective Evolutionary Framework for Non-linear System
  Identification: A Comprehensive Investigation</title><categories>eess.SY cs.NE cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study proposes a multi-objective framework for structure
selection of nonlinear systems which are represented by polynomial NARX models.
This framework integrates the key components of Multi-Criteria Decision Making
(MCDM) which include preference handling, Multi-Objective Evolutionary
Algorithms (MOEAs) and a posteriori selection. To this end, three well-known
MOEAs such as NSGA-II, SPEA-II and MOEA/D are thoroughly investigated to
determine if there exists any significant difference in their search
performance. The sensitivity of all these MOEAs to various qualitative and
quantitative parameters, such as the choice of recombination mechanism,
crossover and mutation probabilities, is also studied. These issues are
critically analyzed considering seven discrete-time and a continuous-time
benchmark nonlinear system as well as a practical case study of non-linear
wave-force modeling. The results of this investigation demonstrate that MOEAs
can be tailored to determine the correct structure of nonlinear systems.
Further, it has been established through frequency domain analysis that it is
possible to identify multiple valid discrete-time models for continuous-time
systems. A rigorous statistical analysis of MOEAs via performance sweet spots
in the parameter space convincingly demonstrates that these algorithms are
robust over a wide range of control parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06239</identifier>
 <datestamp>2019-11-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06239</id><created>2019-08-17</created><authors><author><keyname>Tran</keyname><forenames>Huyen T. T.</forenames></author><author><keyname>Nguyen</keyname><forenames>Duc V.</forenames></author><author><keyname>Ngoc</keyname><forenames>Nam Pham</forenames></author><author><keyname>Hoang</keyname><forenames>Trang H.</forenames></author><author><keyname>Huong</keyname><forenames>Truong Thu</forenames></author><author><keyname>Thang</keyname><forenames>Truong Cong</forenames></author></authors><title>Impacts of Retina-related Zones on Quality Perception of Omnidirectional
  Image</title><categories>eess.IV cs.MM</categories><comments>IEEE Access, 2019</comments><doi>10.1109/ACCESS.2019.2953983</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual Reality (VR), which brings immersive experiences to viewers, has been
gaining popularity in recent years. A key feature in VR systems is the use of
omnidirectional content, which provides 360-degree views of scenes. In this
work, we study the human quality perception of omnidirectional images, focusing
on different zones surrounding the foveation point. For that purpose, an
extensive subjective experiment is carried out to assess the perceptual quality
of omnidirectional images with non-uniform quality. Through experimental
results, the impacts of different zones are analyzed. Moreover, nineteen
objective quality metrics, including foveal quality metrics, are evaluated
using our database. It is quantitatively shown that the zones corresponding to
the fovea and parafovea of human eyes are extremely important for quality
perception, while the impacts of the other zones corresponding to the perifovea
and periphery are small. Besides, the investigated metrics are found to be not
effective enough to reflect the quality perceived by viewers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06245</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06245</id><created>2019-08-17</created><authors><author><keyname>Gao</keyname><forenames>Shen</forenames></author><author><keyname>Dong</keyname><forenames>Peihao</forenames></author><author><keyname>Pan</keyname><forenames>Zhiwen</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Deep Learning based Channel Estimation for Massive MIMO with
  Mixed-Resolution ADCs</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted by IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, deep learning is applied to estimate the uplink channels for
mixed analog-to-digital converters (ADCs) massive multiple-input
multiple-output (MIMO) systems, where a portion of antennas are equipped with
high-resolution ADCs while others employ low-resolution ones at the base
station. A direct-input deep neural network (DI-DNN) is first proposed to
estimate channels by using the received signals of all antennas. To eliminate
the adverse impact of the coarsely quantized signals, a selective-input
prediction DNN (SIP-DNN) is developed, where only the signals received by the
high-resolution ADC antennas are exploited to predict the channels of other
antennas as well as to estimate their own channels. Numerical results show the
superiority of the proposed DNN based approaches over the existing methods,
especially with mixed one-bit ADCs, and the effectiveness of the proposed
approaches on different ADC resolution patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06248</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06248</id><created>2019-08-17</created><authors><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Mitsui</keyname><forenames>Kentaro</forenames></author><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Koriyama</keyname><forenames>Tomoki</forenames></author><author><keyname>Tanji</keyname><forenames>Naoko</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>JVS corpus: free Japanese multi-speaker voice corpus</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Thanks to improvements in machine learning techniques, including deep
learning, speech synthesis is becoming a machine learning task. To accelerate
speech synthesis research, we are developing Japanese voice corpora reasonably
accessible from not only academic institutions but also commercial companies.
In 2017, we released the JSUT corpus, which contains 10 hours of reading-style
speech uttered by a single speaker, for end-to-end text-to-speech synthesis.
For more general use in speech synthesis research, e.g., voice conversion and
multi-speaker modeling, in this paper, we construct the JVS corpus, which
contains voice data of 100 speakers in three styles (normal, whisper, and
falsetto). The corpus contains 30 hours of voice data including 22 hours of
parallel normal voices. This paper describes how we designed the corpus and
summarizes the specifications. The corpus is available at our project page.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06261</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06261</id><created>2019-08-17</created><authors><author><keyname>Dinesh</keyname><forenames>Chinthaka</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author></authors><title>3D Point Cloud Super-Resolution via Graph Total Variation on Surface
  Normals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point cloud is a collection of 3D coordinates that are discrete geometric
samples of an object's 2D surfaces. Using a low-cost 3D scanner to acquire data
means that point clouds are often in lower resolution than desired for
rendering on high-resolution displays. Building on recent advances in graph
signal processing, we design a local algorithm for 3D point cloud
super-resolution (SR). First, we initialize new points at centroids of local
triangles formed using the low-resolution point cloud, and connect all points
using a k-nearestneighbor graph. Then, to establish a linear relationship
between surface normals and 3D point coordinates, we perform bipartite graph
approximation to divide all nodes into two disjoint sets, which are optimized
alternately until convergence. For each node set, to promote piecewise smooth
(PWS) 2D surfaces, we design a graph total variation (GTV) objective for nearby
surface normals, under the constraint that coordinates of the original points
are preserved. We pursue an augmented Lagrangian approach to tackle the
optimization, and solve the unconstrained equivalent using the alternating
method of multipliers (ADMM). Extensive experiments show that our proposed
point cloud SR algorithm outperforms competing schemes objectively and
subjectively for a large variety of point clouds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06274</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06274</id><created>2019-08-17</created><authors><author><keyname>Zhang</keyname><forenames>Yanfeng</forenames></author></authors><title>Sparse Representation Based Efficient Radiation Symmetry Analysis Method
  for Cylindrical Model of Inertial Confinement Fusion</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiation symmetry evaluation is critical to the laser driven Inertial
Confinement Fusion (ICF), which is usually done by solving a view-factor
equation model. The model is nonlinear, and the number of equations can be very
large when the size of discrete mesh element is very small to achieve a
prescribed accuracy, which may lead to an intensive equation solving process.
In this paper, an efficient radiation symmetry analysis approach based on
sparse representation is presented, in which, 1) the Spherical harmonics,
annular Zernike polynomials and Legendre-Fourier polynomials are employed to
sparsely represent the radiation flux on the capsule and cylindrical cavity,
and the nonlinear energy equilibrium equations are transformed into the
equations with sparse coefficients, which means there are many redundant
equations, 2) only a few equations are selected to recover such sparse
coefficients with Latin hypercube sampling, 3) a Conjugate Gradient Subspace
Thresholding Pursuit (CGSTP) algorithm is then given to rapidly obtain such
sparse coefficients equation with as few iterations as possible. Finally, the
proposed method is validated with two experiment targets for Shenguang II and
Shenguang III laser facility in China. The results show that only one tenth of
computation time is required to solve one tenth of equations to achieve the
radiation flux with comparable accuracy. Further more, the solution is much
more efficient as the size of discrete mesh element decreases, in which, only
1.2\% computation time is required to obtain the accurate result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06280</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06280</id><created>2019-08-17</created><authors><author><keyname>Shi</keyname><forenames>Likun</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author></authors><title>No-Reference Light Field Image Quality Assessment Based on
  Spatial-Angular Measurement</title><categories>eess.IV cs.CG cs.CV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light field image quality assessment (LFI-QA) is a significant and
challenging research problem. It helps to better guide light field acquisition,
processing and applications. However, only a few objective models have been
proposed and none of them completely consider intrinsic factors affecting the
LFI quality. In this paper, we propose a No-Reference Light Field image Quality
Assessment (NR-LFQA) scheme, where the main idea is to quantify the LFI quality
degradation through evaluating the spatial quality and angular consistency. We
first measure the spatial quality deterioration by capturing the naturalness
distribution of the light field cyclopean image array, which is formed when
human observes the LFI. Then, as a transformed representation of LFI, the
Epipolar Plane Image (EPI) contains the slopes of lines and involves the
angular information. Therefore, EPI is utilized to extract the global and local
features from LFI to measure angular consistency degradation. Specifically, the
distribution of gradient direction map of EPI is proposed to measure the global
angular consistency distortion in the LFI. We further propose the weighted
local binary pattern to capture the characteristics of local angular
consistency degradation. Extensive experimental results on four publicly
available LFI quality datasets demonstrate that the proposed method outperforms
state-of-the-art 2D, 3D, multi-view, and LFI quality assessment algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06283</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06283</id><created>2019-08-17</created><updated>2019-09-14</updated><authors><author><keyname>Batra</keyname><forenames>Priya</forenames></author><author><keyname>Krithika</keyname><forenames>V. R.</forenames></author><author><keyname>Mahesh</keyname><forenames>T. S.</forenames></author></authors><title>Push-Pull Optimization of Quantum Controls</title><categories>quant-ph cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum optimal control involves setting up an objective function that
evaluates the quality of an operator representing the realized process w.r.t.
the target process. Here we propose a stronger objective function which
incorporates not only the target operator but also a set of its orthogonal
operators. We find significantly superior convergence of optimization routines
with the combined influences of all the operators. We refer to this method as
the $\textit{push-pull}$ optimization. In particular, we describe adopting the
push-pull optimization to a gradient based approach and a variational-principle
based approach. We carry out extensive numerical simulations of the push-pull
optimization of quantum controls on a pair of Ising coupled qubits. Finally, we
demonstrate its experimental application by preparing a long-lived
singlet-order in a two-qubit system using NMR techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06287</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06287</id><created>2019-08-17</created><updated>2019-10-09</updated><authors><author><keyname>Yang</keyname><forenames>Howard H.</forenames></author><author><keyname>Liu</keyname><forenames>Zuozhu</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Scheduling Policies for Federated Learning in Wireless Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the increasing computational capacity of wireless user
equipments (UEs), e.g., smart phones, tablets, or vehicles, as well as the
increasing concerns about sharing private data, a new machine learning model
has emerged, namely federated learning (FL), that allows a decoupling of data
acquisition and computation at the central unit. Unlike centralized learning
taking place in a data center, FL usually operates in a wireless edge network
where the communication medium is resource-constrained and unreliable. Due to
limited bandwidth, only a portion of UEs can be scheduled for updates at each
iteration. Due to the shared nature of the wireless medium, transmissions are
subjected to interference and are not guaranteed. The performance of FL system
in such a setting is not well understood. In this paper, an analytical model is
developed to characterize the performance of FL in wireless networks.
Particularly, tractable expressions are derived for the convergence rate of FL
in a wireless setting, accounting for effects from both scheduling schemes and
inter-cell interference. Using the developed analysis, the effectiveness of
three different scheduling policies, i.e., random scheduling (RS), round robin
(RR), and proportional fair (PF), are compared in terms of FL convergence rate.
It is shown that running FL with PF outperforms RS and RR if the network is
operating under a high signal-to-interference-plus-noise ratio (SINR)
threshold, while RR is more preferable when the SINR threshold is low.
Moreover, the FL convergence rate decreases rapidly as the SINR threshold
increases, thus confirming the importance of compression and quantization of
the update parameters. The analysis also reveals a trade-off between the number
of scheduled UEs and subchannel bandwidth under a fixed amount of available
spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06301</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06301</id><created>2019-08-17</created><authors><author><keyname>Dai</keyname><forenames>Xunhua</forenames></author><author><keyname>Quan</keyname><forenames>Quan</forenames></author><author><keyname>Cai</keyname><forenames>Kai-Yuan</forenames></author></authors><title>Design Automation and Optimization Methodology for Electric Multicopter
  UAVs</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional multicopter design method usually requires a long iterative
process to find the optimal design based on given performance requirements. The
method is uneconomical and inefficient. In this paper, a practical method is
proposed to automatically calculate the optimal multicopter design according to
the given design requirements including flight time, altitude, payload
capacity, and maneuverability. The proposed method contains two algorithms: an
offline algorithm and an online algorithm. The offline algorithm finds the
optimal components (propeller and electronic speed controller) for each motor
to establish its component combination, and subsequently, these component
combinations and their key performance parameters are stored in a combination
database. The online algorithm obtains the multicopter design results that
satisfy the given requirements by searching through the component combinations
in the database and calculating the optimal parameters for the battery and
airframe. Subsequently, these requirement-satisfied multicopter design results
are obtained and sorted according to an objective function that contains
evaluation indexes including size, weight, performance, and practicability. The
proposed method has the advantages of high precision and quick calculating
speed because parameter calibrations and time-consuming calculations are
completed offline. Experiments are performed to validate the effectiveness and
practicality of the proposed method. Comparisons with the brutal search method
and other design methods demonstrate the efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06306</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06306</id><created>2019-08-17</created><updated>2019-10-17</updated><authors><author><keyname>Patro</keyname><forenames>Badri N.</forenames></author><author><keyname>Lunayach</keyname><forenames>Mayank</forenames></author><author><keyname>Patel</keyname><forenames>Shivansh</forenames></author><author><keyname>Namboodiri</keyname><forenames>Vinay P.</forenames></author></authors><title>U-CAM: Visual Explanation using Uncertainty based Class Activation Maps</title><categories>cs.CV cs.CL cs.LG eess.IV</categories><comments>ICCV 2019 (accepted)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Understanding and explaining deep learning models is an imperative task.
Towards this, we propose a method that obtains gradient-based certainty
estimates that also provide visual attention maps. Particularly, we solve for
visual question answering task. We incorporate modern probabilistic deep
learning methods that we further improve by using the gradients for these
estimates. These have two-fold benefits: a) improvement in obtaining the
certainty estimates that correlate better with misclassified samples and b)
improved attention maps that provide state-of-the-art results in terms of
correlation with human attention regions. The improved attention maps result in
consistent improvement for various methods for visual question answering.
Therefore, the proposed technique can be thought of as a recipe for obtaining
improved certainty estimates and explanation for deep learning models. We
provide detailed empirical analysis for the visual question answering task on
all standard benchmarks and comparison with state of the art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06319</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06319</id><created>2019-08-17</created><updated>2019-11-06</updated><authors><author><keyname>Sidhu</keyname><forenames>Gagan</forenames></author></authors><title>Locally Linear Embedding and fMRI feature selection in psychiatric
  classification</title><categories>eess.IV cs.LG stat.ML</categories><comments>Main article is 10 pages. Supplementary Information is 15 pages, and
  includes figures/results for six additional datasets, w/ performance plots
  (as a function of dimensionality 'd'), proportion(s) of brain regions defined
  by the respective atlases, subject ID partitioning for all eleven datasets.
  Statistical Volumes and GraphVizModel are included in 8_statmaps.rar and
  9_graphviz_model.rar</comments><journal-ref>IEEE Journal of Translational Engineering in Health &amp; Medicine
  7:10, 2019</journal-ref><doi>10.1109/JTEHM.2019.2936348 10.21227/zkkm-es92</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Background:
  Functional magnetic resonance imaging (fMRI) provides non-invasive measures
of neuronal activity using an endogenous Blood Oxygenation-Level Dependent
(BOLD) contrast. This article introduces a nonlinear dimensionality reduction
(Locally Linear Embedding) to extract informative measures of the underlying
neuronal activity from BOLD time-series. The method is validated using the
Leave-One-Out-Cross-Validation (LOOCV) accuracy of classifying psychiatric
diagnoses using resting-state and task-related fMRI.
  Methods:
  Locally Linear Embedding of BOLD time-series (into each voxel's respective
tensor) was used to optimise feature selection. This uses Gau\ss' Principle of
Least Constraint to conserve quantities over both space and time. This
conservation was assessed using LOOCV to greedily select time points in an
incremental fashion on training data that was categorised in terms of
psychiatric diagnoses.
  Findings:
  The embedded fMRI gave highly diagnostic performances (&gt; 80%) on eleven
publicly-available datasets containing healthy controls and patients with
either Schizophrenia, Attention-Deficit Hyperactivity Disorder (ADHD), or
Autism Spectrum Disorder (ASD). Furthermore, unlike the original fMRI data
before or after using Principal Component Analysis (PCA) for artefact
reduction, the embedded fMRI furnished significantly better than chance
classification (defined as the majority class proportion) on ten of eleven
datasets
  Interpretation:
  Locally Linear Embedding appears to be a useful feature extraction procedure
that retains important information about patterns of brain activity
distinguishing among psychiatric cohorts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06334</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06334</id><created>2019-08-17</created><authors><author><keyname>Xing</keyname><forenames>Hong</forenames></author><author><keyname>Cui</keyname><forenames>Jingjing</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Energy-Efficient Proactive Caching for Fog Computing with Correlated
  Task Arrivals</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, pre-print version for IEEE SPAWC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the proliferation of latency-critical applications, fog-radio network
(FRAN) has been envisioned as a paradigm shift enabling distributed deployment
of cloud-clone facilities at the network edge. In this paper, we consider
proactive caching for a one-user one-access point (AP) fog computing system
over a finite time horizon, in which consecutive tasks of the same type of
application are temporarily correlated. Under the assumption of predicable
length of the task-input bits, we formulate a long-term weighted-sum energy
minimization problem with three-slot correlation to jointly optimize
computation offloading policies and caching decisions subject to stringent
per-slot deadline constraints. The formulated problem is hard to solve due to
the mixed-integer non-convexity. To tackle this challenge, first, we assume
that task-related information are perfectly known {\em a priori}, and provide
offline solution leveraging the technique of semi-definite relaxation (SDR),
thereby serving as theoretical upper bound. Next, based on the offline
solution, we propose a sliding-window based online algorithm under arbitrarily
distributed prediction error. Finally, the advantage of computation caching as
well the proposed algorithm is verified by numerical examples by comparison
with several benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06337</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06337</id><created>2019-08-17</created><authors><author><keyname>Gaonkar</keyname><forenames>Bilwaj</forenames></author><author><keyname>Bui</keyname><forenames>Alex</forenames></author><author><keyname>Macyszyn</keyname><forenames>Luke</forenames></author></authors><title>EigenRank by Committee: A Data Subset Selection and Failure Prediction
  paradigm for Robust Deep Learning based Medical Image Segmentation</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Translation of fully automated deep learning based medical image segmentation
technologies to clinical workflows face two main algorithmic challenges. The
first, is the collection and archival of large quantities of manually annotated
ground truth data for both training and validation. The second is the relative
inability of the majority of deep learning based segmentation techniques to
alert physicians to a likely segmentation failure. Here we propose a novel
algorithm, named `Eigenrank' which addresses both of these challenges.
Eigenrank can select for manual labeling, a subset of medical images from a
large database, such that a U-Net trained on this subset is superior to one
trained on a randomly selected subset of the same size. Eigenrank can also be
used to pick out, cases in a large database, where deep learning segmentation
will fail. We present our algorithm, followed by results and a discussion of
how Eigenrank exploits the Von Neumann information to perform both data subset
selection and failure prediction for medical image segmentation using deep
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06352</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06352</id><created>2019-08-17</created><updated>2020-01-27</updated><authors><author><keyname>Nazemi</keyname><forenames>Seyyed Danial</forenames></author><author><keyname>Mahani</keyname><forenames>Khashayar</forenames></author><author><keyname>Ghofrani</keyname><forenames>Ali</forenames></author><author><keyname>Kose</keyname><forenames>Burcu Ece</forenames></author><author><keyname>Amini</keyname><forenames>Mahraz</forenames></author><author><keyname>Jafari</keyname><forenames>Mohsen A.</forenames></author></authors><title>Techno-Economic Analysis and Optimization of a Microgrid Considering
  Demand-Side Management</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control and managing of power demand and supply become very crucial
because of penetration of renewables in the electricity networks and energy
demand increase in residential and commercial sectors. In this paper, a new
approach is presented to bridge the gap between Demand-Side Management (DSM)
and microgrid portfolio, sizing and placement optimization. Although DSM helps
energy consumers to take advantage of recent developments in utilization of
Distributed Energy Resources (DERs) especially microgrids, a huge need of
connecting DSM results to microgrid optimization is being felt. Consequently, a
novel model that integrates the DSM techniques and microgrid modules in a
two-layer configuration is proposed. In the first layer, DSM is employed to
minimize the electricity demand (e.g. heating and cooling loads) based on zone
temperature set-point. Using the optimal load profile obtained from the first
layer, all investment and operation costs of a microgrid are then optimized in
the second layer. The presented model is based on the existing optimization
platform developed by RU-LESS (Rutgers University, Laboratory for Energy Smart
Systems) team. As a demonstration, the developed model has been used to study
the impact of smart HVAC control on microgrid compared to traditional HVAC
control. The results show a noticeable reduction in total annual energy
consumption and annual cost of microgrid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06359</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06359</id><created>2019-08-17</created><authors><author><keyname>Tai</keyname><forenames>Ching-Lun</forenames></author><author><keyname>Hsieh</keyname><forenames>Sung-Hsien</forenames></author><author><keyname>Lu</keyname><forenames>Chun-Shien</forenames></author></authors><title>Greedy Algorithms for Hybrid Compressed Sensing</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 6 figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) is a technique which uses fewer measurements than
dictated by the Nyquist sampling theorem. The traditional CS with linear
measurements achieves efficient recovery performances, but it suffers from the
large bit consumption due to the huge storage occupied by those measurements.
Then, the one-bit CS with binary measurements is proposed and saves the bit
budget, but it is infeasible when the energy information of signals is not
available as a prior knowledge. Subsequently, the hybrid CS which combines the
traditional CS and one-bit CS appears, striking a balance between the pros and
cons of both types of CS. Considering the fact that the one-bit CS is optimal
for the direction estimation of signals under noise with a fixed bit budget and
that the traditional CS is able to provide residue information and estimated
signals, we focus on the design of greedy algorithms, which consist of the main
steps of support detection and recovered signal update, for the hybrid CS in
this paper. We first propose a theorem on the random uniform tessellations for
sparse signals to further investigate the properties of one-bit CS. Afterwards,
we propose two greedy algorithms for the hybrid CS, with the one-bit CS
responsible for support detection and traditional CS offering updated residues
and signal estimates. For each of the proposed algorithms, we provide the
corresponding theorem with proof to analyze their capabilities theoretically.
Simulation results have demonstrated the efficacy of the proposed greedy
algorithms under a limited bit budget in noisy environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06372</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06372</id><created>2019-08-18</created><authors><author><keyname>Gupta</keyname><forenames>Anant</forenames></author><author><keyname>Ingle</keyname><forenames>Atul</forenames></author><author><keyname>Gupta</keyname><forenames>Mohit</forenames></author></authors><title>Asynchronous Single-Photon 3D Imaging</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-photon avalanche diodes (SPADs) are becoming popular in time-of-flight
depth-ranging due to their unique ability to capture individual photons with
picosecond timing resolution. However, ambient light (e.g., sunlight) incident
on a SPAD-based 3D camera leads to severe non-linear distortions (pileup) in
the measured waveform, resulting in large depth errors. We propose asynchronous
single-photon 3D imaging, a family of acquisition schemes to mitigate pileup
during data acquisition itself. Asynchronous acquisition temporally misaligns
SPAD measurement windows and the laser cycles through deterministically
predefined or randomized offsets. Our key insight is that pileup distortions
can be &quot;averaged out&quot; by choosing a sequence of offsets that span the entire
depth range. We develop a generalized image formation model and perform
theoretical analysis to explore the space of asynchronous acquisition schemes
and design high-performance schemes. Our simulations and experiments
demonstrate an improvement in depth accuracy of up to an order of magnitude as
compared to the state-of-the-art, across a wide range of imaging scenarios,
including those with high ambient flux.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06381</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06381</id><created>2019-08-18</created><authors><author><keyname>Malyuta</keyname><forenames>Danylo</forenames></author><author><keyname>Brommer</keyname><forenames>Christian</forenames></author><author><keyname>Hentzen</keyname><forenames>Daniel</forenames></author><author><keyname>Stastny</keyname><forenames>Thomas</forenames></author><author><keyname>Siegwart</keyname><forenames>Roland</forenames></author><author><keyname>Brockers</keyname><forenames>Roland</forenames></author></authors><title>Long-Duration Fully Autonomous Operation of Rotorcraft Unmanned Aerial
  Systems for Remote-Sensing Data Acquisition</title><categories>cs.RO cs.CV cs.SY eess.SY</categories><comments>38 pages, 28 figures</comments><journal-ref>J Field Robotics (2019) 1-21</journal-ref><doi>10.1002/rob.21898</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent applications of unmanned aerial systems (UAS) to precision agriculture
have shown increased ease and efficiency in data collection at precise remote
locations. However, further enhancement of the field requires operation over
long periods of time, e.g. days or weeks. This has so far been impractical due
to the limited flight times of such platforms and the requirement of humans in
the loop for operation. To overcome these limitations, we propose a fully
autonomous rotorcraft UAS that is capable of performing repeated flights for
long-term observation missions without any human intervention. We address two
key technologies that are critical for such a system: full platform autonomy to
enable mission execution independently from human operators and the ability of
vision-based precision landing on a recharging station for automated energy
replenishment. High-level autonomous decision making is implemented as a
hierarchy of master and slave state machines. Vision-based precision landing is
enabled by estimating the landing pad's pose using a bundle of AprilTag
fiducials configured for detection from a wide range of altitudes. We provide
an extensive evaluation of the landing pad pose estimation accuracy as a
function of the bundle's geometry. The functionality of the complete system is
demonstrated through two indoor experiments with a duration of 11 and 10.6
hours, and one outdoor experiment with a duration of 4 hours. The UAS executed
16, 48 and 22 flights respectively during these experiments. In the outdoor
experiment, the ratio between flying to collect data and charging was 1 to 10,
which is similar to past work in this domain. All flights were fully autonomous
with no human in the loop. To our best knowledge this is the first research
publication about the long-term outdoor operation of a quadrotor system with no
human interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06386</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06386</id><created>2019-08-18</created><authors><author><keyname>Aumentado-Armstrong</keyname><forenames>Tristan</forenames></author><author><keyname>Tsogkas</keyname><forenames>Stavros</forenames></author><author><keyname>Jepson</keyname><forenames>Allan</forenames></author><author><keyname>Dickinson</keyname><forenames>Sven</forenames></author></authors><title>Geometric Disentanglement for Generative Latent Shape Models</title><categories>cs.CV cs.LG eess.IV</categories><comments>ICCV 2019</comments><acm-class>I.2.10; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Representing 3D shape is a fundamental problem in artificial intelligence,
which has numerous applications within computer vision and graphics. One avenue
that has recently begun to be explored is the use of latent representations of
generative models. However, it remains an open problem to learn a generative
model of shape that is interpretable and easily manipulated, particularly in
the absence of supervised labels. In this paper, we propose an unsupervised
approach to partitioning the latent space of a variational autoencoder for 3D
point clouds in a natural way, using only geometric information. Our method
makes use of tools from spectral differential geometry to separate intrinsic
and extrinsic shape information, and then considers several hierarchical
disentanglement penalties for dividing the latent space in this manner,
including a novel one that penalizes the Jacobian of the latent representation
of the decoded output with respect to the latent encoding. We show that the
resulting representation exhibits intuitive and interpretable behavior,
enabling tasks such as pose transfer and pose-aware shape retrieval that cannot
easily be performed by models with an entangled representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06388</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06388</id><created>2019-08-18</created><updated>2019-08-30</updated><authors><author><keyname>Rudsari</keyname><forenames>Hamid Khoshfekr</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Javan</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Drug Release Management for Dynamic TDMA-Based Molecular Communication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we design a drug release mechanism for dynamic time division
multiple access (TDMA)-based molecular communication via diffusion (MCvD). In
the proposed scheme, the communication frame is divided into several time slots
over each of which a transmitter nanomachine is scheduled to convey its
information by releasing the molecules into the medium. To optimize the number
of released molecules and the time duration of each time slot (symbol
duration), we formulate a multi-objective optimization problem whose objective
functions are the bit error rate (BER) of each transmitter nanomachine. Based
on the number of released molecules and symbol durations, we consider four
cases, namely: &quot;static-time static-number of molecules&quot; (STSN), &quot;static-time
dynamic-number of molecules&quot; (STDN), &quot;dynamic-time static-number of molecules&quot;
(DTSN), and &quot;dynamic-time dynamic-number of molecules&quot; (DTDN). We consider
three types of medium in which the molecules are propagated, namely: &quot;mild
diffusive environment&quot; (MDE), &quot;moderate diffusive environment&quot; (MODE), and
&quot;severe diffusive environment&quot; (SDE). For the channel model, we consider a
3-dimensional (3D) diffusive environment, such as blood, with drift in three
directions. Simulation results show that the STSN approach is the least complex
one with BER around $\text{10}^{\text{-2}}$, but, the DTDN is the most complex
scenario with the BER around $\text{10}^{\text{-8}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06399</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06399</id><created>2019-08-18</created><authors><author><keyname>Rogers</keyname><forenames>T W</forenames></author><author><keyname>Gonzalez-Bueno</keyname><forenames>J</forenames></author><author><keyname>Franco</keyname><forenames>R Garcia</forenames></author><author><keyname>Star</keyname><forenames>E Lopez</forenames></author><author><keyname>Mar&#xed;n</keyname><forenames>D M&#xe9;ndez</forenames></author><author><keyname>Vassallo</keyname><forenames>J</forenames></author><author><keyname>Lansingh</keyname><forenames>V C</forenames></author><author><keyname>Trikha</keyname><forenames>S</forenames></author><author><keyname>Jaccard</keyname><forenames>N</forenames></author></authors><title>Evaluation of an AI System for the Detection of Diabetic Retinopathy
  from Images Captured with a Handheld Portable Fundus Camera: the MAILOR AI
  study</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objectives: To evaluate the performance of an Artificial Intelligence (AI)
system (Pegasus, Visulytix Ltd., UK), at the detection of Diabetic Retinopathy
(DR) from images captured by a handheld portable fundus camera.
  Methods: A cohort of 6,404 patients (~80% with diabetes mellitus) was
screened for retinal diseases using a handheld portable fundus camera (Pictor
Plus, Volk Optical Inc., USA) at the Mexican Advanced Imaging Laboratory for
Ocular Research. The images were graded for DR by specialists according to the
Scottish DR grading scheme. The performance of the AI system was evaluated,
retrospectively, in assessing Referable DR (RDR) and Proliferative DR (PDR) and
compared to the performance on a publicly available desktop camera benchmark
dataset.
  Results: For RDR detection, Pegasus performed with an 89.4% (95% CI:
88.0-90.7) Area Under the Receiver Operating Characteristic (AUROC) curve for
the MAILOR cohort, compared to an AUROC of 98.5% (95% CI: 97.8-99.2) on the
benchmark dataset. This difference was statistically significant. Moreover, no
statistically significant difference was found in performance for PDR detection
with Pegasus achieving an AUROC of 94.3% (95% CI: 91.0-96.9) on the MAILOR
cohort and 92.2% (95% CI: 89.4-94.8) on the benchmark dataset.
  Conclusions: Pegasus showed good transferability for the detection of PDR
from a curated desktop fundus camera dataset to real-world clinical practice
with a handheld portable fundus camera. However, there was a substantial, and
statistically significant, decrease in the diagnostic performance for RDR when
using the handheld device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06444</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06444</id><created>2019-08-18</created><updated>2019-08-24</updated><authors><author><keyname>Pan</keyname><forenames>Jinshan</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Sun</keyname><forenames>Deqing</forenames></author><author><keyname>Ren</keyname><forenames>Jimmy</forenames></author><author><keyname>Cheng</keyname><forenames>Ming-Ming</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Tang</keyname><forenames>Jinhui</forenames></author></authors><title>Image Formation Model Guided Deep Image Super-Resolution</title><categories>eess.IV cs.CV</categories><comments>We need to improve this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and effective image super-resolution algorithm that
imposes an image formation constraint on the deep neural networks via pixel
substitution. The proposed algorithm first uses a deep neural network to
estimate intermediate high-resolution images, blurs the intermediate images
using known blur kernels, and then substitutes values of the pixels at the
un-decimated positions with those of the corresponding pixels from the
low-resolution images. The output of the pixel substitution process strictly
satisfies the image formation model and is further refined by the same deep
neural network in a cascaded manner. The proposed framework is trained in an
end-to-end fashion and can work with existing feed-forward deep neural networks
for super-resolution and converges fast in practice. Extensive experimental
results show that the proposed algorithm performs favorably against
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06468</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06468</id><created>2019-08-18</created><updated>2020-02-06</updated><authors><author><keyname>Zhen</keyname><forenames>Kai</forenames></author><author><keyname>Lee</keyname><forenames>Mi Suk</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>A Dual-Staged Context Aggregation Method Towards Efficient End-To-End
  Speech Enhancement</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted in Proceedings of the ICASSP, Barcelona, Spain, May 4-8,
  2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In speech enhancement, an end-to-end deep neural network converts a noisy
speech signal to a clean speech directly in time domain without time-frequency
transformation or mask estimation. However, aggregating contextual information
from a high-resolution time domain signal with an affordable model complexity
still remains challenging. In this paper, we propose a densely connected
convolutional and recurrent network (DCCRN), a hybrid architecture, to enable
dual-staged temporal context aggregation. With the dense connectivity and
cross-component identical shortcut, DCCRN consistently outperforms competing
convolutional baselines with an average STOI improvement of 0.23 and PESQ of
1.38 at three SNR levels. The proposed method is computationally efficient with
only 1.38 million parameters. The generalizability performance on the unseen
noise types is still decent considering its low complexity, although it is
relatively weaker comparing to Wave-U-Net with 7.25 times more parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06472</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06472</id><created>2019-08-18</created><authors><author><keyname>Kamilaris</keyname><forenames>Andreas</forenames></author><author><keyname>Brink</keyname><forenames>Corjan van den</forenames></author><author><keyname>Karatsiolis</keyname><forenames>Savvas</forenames></author></authors><title>Training Deep Learning Models via Synthetic Data: Application in
  Unmanned Aerial Vehicles</title><categories>cs.CV cs.LG eess.IV</categories><comments>Workshop on Deep-learning based computer vision for UAV in
  conjunction with CAIP 2019, Salerno, italy, September 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper describes preliminary work in the recent promising approach of
generating synthetic training data for facilitating the learning procedure of
deep learning (DL) models, with a focus on aerial photos produced by unmanned
aerial vehicles (UAV). The general concept and methodology are described, and
preliminary results are presented, based on a classification problem of fire
identification in forests as well as a counting problem of estimating number of
houses in urban areas. The proposed technique constitutes a new possibility for
the DL community, especially related to UAV-based imagery analysis, with much
potential, promising results, and unexplored ground for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06505</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06505</id><created>2019-08-18</created><authors><author><keyname>Roberts</keyname><forenames>Ian P.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Beamforming Cancellation Design for Millimeter-Wave Full-Duplex</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been extensive research on millimeter-wave
(mmWave) communication and on in-band full-duplex (FD) communication, but work
on the combination of the two is relatively lacking. FD mmWave systems could
offer increased spectral efficiency and decreased latency while also suggesting
the redesign of existing mmWave applications. While FD technology has been
well-explored for sub-6 GHz systems, the developed methods do not translate
well to mmWave. This turns us to a method called beamforming cancellation
(BFC), where the highly directional mmWave beams are steered to mitigate
self-interference (SI) and enable simultaneous transmission and reception
in-band. In this paper, we present BFC designs for two fully-connected hybrid
beamforming scenarios, both of which sufficiently suppress the SI such that the
sum spectral efficiency approaches that of a SI-free FD system. A simulation
and its results are then used to verify our designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06535</identifier>
 <datestamp>2020-01-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06535</id><created>2019-08-18</created><authors><author><keyname>Liu</keyname><forenames>Zhenwei</forenames></author><author><keyname>Saberi</keyname><forenames>Ali</forenames></author><author><keyname>Stoorvogel</keyname><forenames>Anton A.</forenames></author><author><keyname>Nojavanzadeh</keyname><forenames>Donya</forenames></author></authors><title>State Synchronization for Homogeneous Networks of Non-introspective
  Agents in Presence of Input Saturation -A Scale-free Protocol Design</title><categories>eess.SY cs.SY eess.SP</categories><comments>8 pages, 6 figures, extended version of the paper submitted to 58th
  Conference on Decision and Control - Nice, France - December 11th-13th 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies global and semi-global regulated state synchronization of
homogeneous networks of non-introspective agents in presence of input
saturation based on additional information exchange where the reference
trajectory is given by a so-called exosystem which is assumed to be globally
reachable. Our protocol design methodology does not need any knowledge of the
directed network topology and the spectrum of the associated Laplacian matrix.
Moreover, the proposed protocol is scalable and achieves synchronization for
any arbitrary number of agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06548</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06548</id><created>2019-08-18</created><authors><author><keyname>Wang</keyname><forenames>Zhaojian</forenames></author><author><keyname>Liu</keyname><forenames>Feng</forenames></author><author><keyname>Su</keyname><forenames>Yifan</forenames></author><author><keyname>Qin</keyname><forenames>Boyu</forenames></author></authors><title>Asynchronous Distributed Voltage Control in Active Distribution Networks</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the explosion of distributed energy resources (DERs), voltage regulation
in distribution networks has been facing a great challenge. This paper derives
an asynchronous distributed voltage control strategy based on the partial
primal-dual gradient algorithm, where both active and reactive controllable
power of DERs are considered. Different types of asynchrony due to imperfect
communication or practical limits, such as random time delays and non-identical
sampling/control rates, are fitted into a unified analytic framework. The
asynchronous algorithm is then converted into a fixed-point problem by
employing the operator splitting method, which leads to a convergence proof
with mild conditions. Moreover, an online implementation method is provided to
make the controller adjustable to time-varying environments. Finally, numerical
experiments are carried out on a rudimentary 8-bus system and the IEEE-123
distribution network to verify the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06553</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06553</id><created>2019-08-18</created><authors><author><keyname>Ding</keyname><forenames>Zijian</forenames></author><author><keyname>Qiu</keyname><forenames>Shan</forenames></author><author><keyname>Guo</keyname><forenames>Yutong</forenames></author><author><keyname>Lin</keyname><forenames>Jianping</forenames></author><author><keyname>Sun</keyname><forenames>Li</forenames></author><author><keyname>Fu</keyname><forenames>Dapeng</forenames></author><author><keyname>Yang</keyname><forenames>Zhen</forenames></author><author><keyname>Li</keyname><forenames>Chengquan</forenames></author><author><keyname>Yu</keyname><forenames>Yang</forenames></author><author><keyname>Meng</keyname><forenames>Long</forenames></author><author><keyname>Lv</keyname><forenames>Tingting</forenames></author><author><keyname>Li</keyname><forenames>Dan</forenames></author><author><keyname>Zhang</keyname><forenames>Ping</forenames></author></authors><title>LabelECG: A Web-based Tool for Distributed Electrocardiogram Annotation</title><categories>cs.DB eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrocardiography plays an essential role in diagnosing and screening
cardiovascular diseases in daily healthcare. Deep neural networks have shown
the potentials to improve the accuracies of arrhythmia detection based on
electrocardiograms (ECGs). However, more ECG records with ground truth are
needed to promote the development and progression of deep learning techniques
in automatic ECG analysis. Here we propose a web-based tool for ECG viewing and
annotating, LabelECG. With the facilitation of unified data management,
LabelECG is able to distribute large cohorts of ECGs to dozens of technicians
and physicians, who can simultaneously make annotations through web-browsers on
PCs, tablets and cell phones. Along with the doctors from four hospitals in
China, we applied LabelECG to support the annotations of about 15,000 12-lead
resting ECG records in three months. These annotated ECGs have successfully
supported the First China ECG intelligent Competition. La-belECG will be freely
accessible on the Internet to support similar researches, and will also be
upgraded through future works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06557</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06557</id><created>2019-08-18</created><authors><author><keyname>Kinoshita</keyname><forenames>Yuma</forenames></author><author><keyname>Seo</keyname><forenames>Kouki</forenames></author><author><keyname>Visavakitcharoen</keyname><forenames>Artit</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>A hue-preserving tone mapping scheme based on constant-hue plane without
  gamut problem</title><categories>eess.IV</categories><doi>10.1587/transfun.E102.A.1865</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel hue-preserving tone mapping scheme. Various tone mapping
operations have been studied so far, but there are very few works on color
distortion caused in image tone mapping. First, LDR images produced from HDR
ones by using conventional tone mapping operators (TMOs) are pointed out to
have some distortion in hue values due to clipping and rounding quantization
processing. Next,we propose a novel method which allows LDR images to have the
same maximally saturated color values as those of HDR ones. Generated LDR
images by the proposed method have smaller hue degradation than LDR ones
generated by conventional TMOs. Moreover, the proposed method is applicable to
any TMOs. In an experiment, the proposed method is demonstrated not only to
produce images with small hue degradation but also to maintain well-mapped
luminance, in terms of three objective metrics: TMQI, hue value in CIEDE2000,
and the maximally saturated color on the constant-hue plane in the RGB color
space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06566</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06566</id><created>2019-08-18</created><updated>2019-09-03</updated><authors><author><keyname>Zhang</keyname><forenames>Zhendong</forenames></author><author><keyname>Jung</keyname><forenames>Cheolkon</forenames></author><author><keyname>Liang</keyname><forenames>Xiaolong</forenames></author></authors><title>Adversarial Defense by Suppressing High-frequency Components</title><categories>cs.CV cs.LG eess.IV</categories><comments>3 pages. This paper is a technical report of the 5th place solution
  in the IJCAI-2019 Alibaba Adversarial AI Challenge. This paper has been
  accepted by the corresponding workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent works show that deep neural networks trained on image classification
dataset bias towards textures. Those models are easily fooled by applying small
high-frequency perturbations to clean images. In this paper, we learn robust
image classification models by removing high-frequency components.
Specifically, we develop a differentiable high-frequency suppression module
based on discrete Fourier transform (DFT). Combining with adversarial training,
we won the 5th place in the IJCAI-2019 Alibaba Adversarial AI Challenge. Our
code is available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06593</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06593</id><created>2019-08-19</created><authors><author><keyname>Lee</keyname><forenames>Jie Hwan</forenames></author><author><keyname>Choi</keyname><forenames>Hyeong-Seok</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author></authors><title>Audio query-based music source separation</title><categories>cs.SD eess.AS</categories><comments>8 pages, 7 figures, Appearing in the proceedings of the 20th
  International Society for Music Information Retrieval Conference (ISMIR 2019)
  (camera-ready version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, music source separation has been one of the most intensively
studied research areas in music information retrieval. Improvements in deep
learning lead to a big progress in music source separation performance.
However, most of the previous studies are restricted to separating a few
limited number of sources, such as vocals, drums, bass, and other. In this
study, we propose a network for audio query-based music source separation that
can explicitly encode the source information from a query signal regardless of
the number and/or kind of target signals. The proposed method consists of a
Query-net and a Separator: given a query and a mixture, the Query-net encodes
the query into the latent space, and the Separator estimates masks conditioned
by the latent vector, which is then applied to the mixture for separation. The
Separator can also generate masks using the latent vector from the training
samples, allowing separation in the absence of a query. We evaluate our method
on the MUSDB18 dataset, and experimental results show that the proposed method
can separate multiple sources with a single network. In addition, through
further investigation of the latent space we demonstrate that our method can
generate continuous outputs via latent vector interpolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06599</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06599</id><created>2019-08-19</created><authors><author><keyname>Zhu</keyname><forenames>Yongli</forenames></author><author><keyname>Liu</keyname><forenames>Chengxi</forenames></author></authors><title>Mitigating Multi-Stage Cascading Failure by Reinforcement Learning</title><categories>cs.LG cs.SY eess.SY math.DS stat.ML</categories><comments>This paper has been accepted and presented in the IEEE ISGT-Asia
  conference in 2019</comments><acm-class>I.2.1; I.2.8; I.6.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a cascading failure mitigation strategy based on
Reinforcement Learning (RL) method. Firstly, the principles of RL are
introduced. Then, the Multi-Stage Cascading Failure (MSCF) problem is presented
and its challenges are investigated. The problem is then tackled by the RL
based on DC-OPF (Optimal Power Flow). Designs of the key elements of the RL
framework (rewards, states, etc.) are also discussed in detail. Experiments on
the IEEE 118-bus system by both shallow and deep neural networks demonstrate
promising results in terms of reduced system collapse rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06612</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06612</id><created>2019-08-19</created><authors><author><keyname>Young</keyname><forenames>Kyle</forenames></author><author><keyname>Booth</keyname><forenames>Gareth</forenames></author><author><keyname>Simpson</keyname><forenames>Becks</forenames></author><author><keyname>Dutton</keyname><forenames>Reuben</forenames></author><author><keyname>Shrapnel</keyname><forenames>Sally</forenames></author></authors><title>Deep neural network or dermatologist?</title><categories>cs.LG eess.IV stat.ML</categories><doi>10.1007/978-3-030-33850-3_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning techniques have proven high accuracy for identifying melanoma
in digitised dermoscopic images. A strength is that these methods are not
constrained by features that are pre-defined by human semantics. A down-side is
that it is difficult to understand the rationale of the model predictions and
to identify potential failure modes. This is a major barrier to adoption of
deep learning in clinical practice. In this paper we ask if two existing local
interpretability methods, Grad-CAM and Kernel SHAP, can shed light on
convolutional neural networks trained in the context of melanoma detection. Our
contributions are (i) we first explore the domain space via a reproducible,
end-to-end learning framework that creates a suite of 30 models, all trained on
a publicly available data set (HAM10000), (ii) we next explore the reliability
of GradCAM and Kernel SHAP in this context via some basic sanity check
experiments (iii) finally, we investigate a random selection of models from our
suite using GradCAM and Kernel SHAP. We show that despite high accuracy, the
models will occasionally assign importance to features that are not relevant to
the diagnostic task. We also show that models of similar accuracy will produce
different explanations as measured by these methods. This work represents first
steps in bridging the gap between model accuracy and interpretability in the
domain of skin cancer classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06619</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06619</id><created>2019-08-19</created><authors><author><keyname>Zhu</keyname><forenames>Zhanyu</forenames></author><author><keyname>Xu</keyname><forenames>Feng</forenames></author></authors><title>Demonstration of 3D ISAR Security Imaging at 24GHz with a Sparse MIMO
  Array</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 3D ISAR security imaging experiment at 24GHz is demonstrated with a sparse
MIMO array. The MIMO array is an 8Tx/16Rx linear array to achieve real-aperture
imaging along the vertical dimension. It is time-switching multiplexed with a
low-cost FMCW transceiver working at 22GHz-26GHz. A calibration procedure is
proposed to calibrate the channel imbalance across the MIMO array. The
experiment is conducted on human moving on a cart, where we take advantage of
the linear motion of human to form inverse synthetic aperture along the
horizontal dimension. To track the motion of human, a 3D depth camera is used
as an auxiliary sensor to capture the rough position of target to aid ISAR
imaging. The back projection imaging algorithm is implemented on GPU for
quasi-real-time operation. Finally, experiments are conducted with real human
with concealed objects and a preliminary automatic object recognition algorithm
based on convolutional neural networks are developed and evaluated on real
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06693</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06693</id><created>2019-08-19</created><authors><author><keyname>George</keyname><forenames>Jemin</forenames></author><author><keyname>Yang</keyname><forenames>Tao</forenames></author><author><keyname>Bai</keyname><forenames>He</forenames></author><author><keyname>Gurram</keyname><forenames>Prudhvi</forenames></author></authors><title>Distributed Stochastic Gradient Method for Non-Convex Problems with
  Applications in Supervised Learning</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a distributed stochastic gradient descent algorithm for solving
non-convex optimization problems under the assumption that the local objective
functions are twice continuously differentiable with Lipschitz continuous
gradients and Hessians. We provide sufficient conditions on step-sizes that
guarantee the asymptotic mean-square convergence of the proposed algorithm. We
apply the developed algorithm to a distributed supervised-learning problem, in
which a set of networked agents collaboratively train their individual neural
nets to recognize handwritten digits in images. Results indicate that all
agents report similar performance that is also comparable to the performance of
a centrally trained neural net. Numerical results also show that the proposed
distributed algorithm allows the individual agents to recognize the digits even
though the training data corresponding to all the digits is not locally
available to each agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06709</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06709</id><created>2019-08-19</created><authors><author><keyname>Gref</keyname><forenames>Michael</forenames></author><author><keyname>Schmidt</keyname><forenames>Christoph</forenames></author><author><keyname>Behnke</keyname><forenames>Sven</forenames></author><author><keyname>K&#xf6;hler</keyname><forenames>Joachim</forenames></author></authors><title>Two-Staged Acoustic Modeling Adaption for Robust Speech Recognition by
  the Example of German Oral History Interviews</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted for IEEE International Conference on Multimedia and Expo
  (ICME), Shanghai, China, July 2019</comments><journal-ref>IEEE International Conference on Multimedia and Expo (ICME),
  Shanghai, China, July 2019</journal-ref><doi>10.1109/ICME.2019.00142</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automatic speech recognition, often little training data is available for
specific challenging tasks, but training of state-of-the-art automatic speech
recognition systems requires large amounts of annotated speech. To address this
issue, we propose a two-staged approach to acoustic modeling that combines
noise and reverberation data augmentation with transfer learning to robustly
address challenges such as difficult acoustic recording conditions, spontaneous
speech, and speech of elderly people. We evaluate our approach using the
example of German oral history interviews, where a relative average reduction
of the word error rate by 19.3% is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06724</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06724</id><created>2019-08-15</created><authors><author><keyname>Venkataramanaiah</keyname><forenames>Shreyas Kolala</forenames></author><author><keyname>Ma</keyname><forenames>Yufei</forenames></author><author><keyname>Yin</keyname><forenames>Shihui</forenames></author><author><keyname>Nurvithadhi</keyname><forenames>Eriko</forenames></author><author><keyname>Dasu</keyname><forenames>Aravind</forenames></author><author><keyname>Cao</keyname><forenames>Yu</forenames></author><author><keyname>Seo</keyname><forenames>Jae-sun</forenames></author></authors><title>Automatic Compiler Based FPGA Accelerator for CNN Training</title><categories>cs.LG cs.NE eess.SP</categories><comments>6 pages, 9 figures, paper accepted at FPL2019 conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Training of convolutional neural networks (CNNs)on embedded platforms to
support on-device learning is earning vital importance in recent days.
Designing flexible training hard-ware is much more challenging than inference
hardware, due to design complexity and large computation/memory requirement. In
this work, we present an automatic compiler-based FPGA accelerator with 16-bit
fixed-point precision for complete CNNtraining, including Forward Pass (FP),
Backward Pass (BP) and Weight Update (WU). We implemented an optimized RTL
library to perform training-specific tasks and developed an RTL compiler to
automatically generate FPGA-synthesizable RTL based on user-defined
constraints. We present a new cyclic weight storage/access scheme for on-chip
BRAM and off-chip DRAMto efficiently implement non-transpose and transpose
operations during FP and BP phases, respectively. Representative CNNs for
CIFAR-10 dataset are implemented and trained on Intel Stratix 10-GX FPGA using
proposed hardware architecture, demonstrating up to 479 GOPS performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06749</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06749</id><created>2019-08-19</created><authors><author><keyname>&#xd6;zcan</keyname><forenames>Alpay</forenames></author></authors><title>On Using Signal Magnitude in Diffusion Magnetic Resonance Measurements
  of Restricted Motion</title><categories>physics.med-ph cs.SY eess.SY</categories><doi>10.1016/j.mri.2019.06.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tissue microstructure has significance as a biomarker, however its accurate
inference with diffusion magnetic resonance (MR) is still an open problem. With
few exceptions, diffusion weighted (DW) MR models either process diffusion MR
data using signal magnitude, whereby microstructural information is forcefully
confined to symmetry due to Fourier transform properties, or directly use
symmetric basis expansions.
  Herein, information loss from magnitude utilization is demonstrated by
numerically simulating particles undergoing diffusion near a fully reflective
infinite wall and an orthogonal corner.
  Simulation results show that the loss of the Hermitian property when using
signal magnitude impedes DW--MR from accurately inferring microstructural
information in both of the geometries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06752</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06752</id><created>2019-08-16</created><authors><author><keyname>Rana</keyname><forenames>Aakanksha</forenames></author><author><keyname>Ozcinar</keyname><forenames>Cagri</forenames></author><author><keyname>Smolic</keyname><forenames>Aljoscha</forenames></author></authors><title>Towards Generating Ambisonics Using Audio-Visual Cue for Virtual Reality</title><categories>cs.SD cs.CV cs.LG cs.MM eess.AS</categories><comments>ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)</comments><doi>10.1109/ICASSP.2019.8683318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ambisonics i.e., a full-sphere surround sound, is quintessential with
360-degree visual content to provide a realistic virtual reality (VR)
experience. While 360-degree visual content capture gained a tremendous boost
recently, the estimation of corresponding spatial sound is still challenging
due to the required sound-field microphones or information about the
sound-source locations. In this paper, we introduce a novel problem of
generating Ambisonics in 360-degree videos using the audio-visual cue. With
this aim, firstly, a novel 360-degree audio-visual video dataset of 265 videos
is introduced with annotated sound-source locations. Secondly, a pipeline is
designed for an automatic Ambisonic estimation problem. Benefiting from the
deep learning-based audio-visual feature-embedding and prediction modules, our
pipeline estimates the 3D sound-source locations and further use such locations
to encode to the B-format. To benchmark our dataset and pipeline, we
additionally propose evaluation criteria to investigate the performance using
different 360-degree input representations. Our results demonstrate the
efficacy of the proposed pipeline and open up a new area of research in
360-degree audio-visual analysis for future investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06767</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06767</id><created>2019-08-19</created><authors><author><keyname>Seyedsalehi</keyname><forenames>Shirin</forenames></author><author><keyname>Pourahmadi</keyname><forenames>Vahid</forenames></author><author><keyname>Sheikhzadeh</keyname><forenames>Hamid</forenames></author><author><keyname>Foumani</keyname><forenames>Ali Hossein Gharari</forenames></author></authors><title>Propagation Channel Modeling by Deep learning Techniques</title><categories>eess.SP cs.LG</categories><comments>11 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel, as the medium for the propagation of electromagnetic waves, is one
of the most important parts of a communication system. Being aware of how the
channel affects the propagation waves is essential for designing, optimization
and performance analysis of a communication system. For this purpose, a proper
channel model is needed. This paper presents a novel propagation channel model
which considers the time-frequency response of the channel as an image. It
models the distribution of these channel images using Deep Convolutional
Generative Adversarial Networks. Moreover, for the measurements with different
user speeds, the user speed is considered as an auxiliary parameter for the
model. StarGAN as an image-to-image translation technique is used to change the
generated channel images with respect to the desired user speed. The
performance of the proposed model is evaluated using existing metrics.
Furthermore, to capture 2D similarity in both time and frequency, a new metric
is introduced. Using this metric, the generated channels show significant
statistical similarity to the measurement data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06770</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06770</id><created>2019-08-16</created><authors><author><keyname>Du</keyname><forenames>Ming</forenames></author><author><keyname>Gursoy</keyname><forenames>Doga</forenames></author><author><keyname>Jacobsen</keyname><forenames>Chris</forenames></author></authors><title>Near, far, wherever you are: simulations on the dose efficiency of
  holographic and ptychographic coherent imaging</title><categories>eess.IV physics.app-ph physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different studies in x-ray microscopy have arrived at conflicting conclusions
about the dose efficiency of imaging modes involving the recording of intensity
distributions in the near (Fresnel regime) or far (Fraunhofer regime) field
downstream of a specimen. We present here a numerical study on the dose
efficiency of near-field holography versus ptychography, a variant of far-field
coherent diffraction imaging (CDI) involving multiple overlapping finite
illumination positions. Unlike what has been reported for single-illumination
CDI, we find that the quality, measured by spatial resolution and mean error,
of reconstructed images from ptychography is similar (though slightly better)
to what one can obtain from near-field holography at identical fluence on the
specimen. These results support the concept that, if the experiment and image
reconstruction are done properly, the sample can be near, or far; wherever you
are, photon fluence on the specimen sets one limit to spatial resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06792</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06792</id><created>2019-08-19</created><updated>2019-08-28</updated><authors><author><keyname>Huang</keyname><forenames>Yixing</forenames></author><author><keyname>Preuhs</keyname><forenames>Alexander</forenames></author><author><keyname>Lauritsch</keyname><forenames>Guenter</forenames></author><author><keyname>Manhart</keyname><forenames>Michael</forenames></author><author><keyname>Huang</keyname><forenames>Xiaolin</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Data Consistent Artifact Reduction for Limited Angle Tomography with
  Deep Learning Prior</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted by MICCAI MLMIR workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness of deep learning methods for limited angle tomography is
challenged by two major factors: a) due to insufficient training data the
network may not generalize well to unseen data; b) deep learning methods are
sensitive to noise. Thus, generating reconstructed images directly from a
neural network appears inadequate. We propose to constrain the reconstructed
images to be consistent with the measured projection data, while the unmeasured
information is complemented by learning based methods. For this purpose, a data
consistent artifact reduction (DCAR) method is introduced: First, a prior image
is generated from an initial limited angle reconstruction via deep learning as
a substitute for missing information. Afterwards, a conventional iterative
reconstruction algorithm is applied, integrating the data consistency in the
measured angular range and the prior information in the missing angular range.
This ensures data integrity in the measured area, while inaccuracies
incorporated by the deep learning prior lie only in areas where no information
is acquired. The proposed DCAR method achieves significant image quality
improvement: for 120-degree cone-beam limited angle tomography more than 10%
RMSE reduction in noise-free case and more than 24% RMSE reduction in noisy
case compared with a state-of-the-art U-Net based method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06800</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06800</id><created>2019-08-15</created><authors><author><keyname>Javadpour</keyname><forenames>Abdollah</forenames></author><author><keyname>rahimi</keyname><forenames>abolfazl</forenames></author><author><keyname>Javadpour</keyname><forenames>Amir</forenames></author><author><keyname>vazini</keyname><forenames>Hossien</forenames></author><author><keyname>Farhadi</keyname><forenames>Zeynab</forenames></author><author><keyname>baghdadpour</keyname><forenames>Gholam hossein</forenames></author><author><keyname>Korani</keyname><forenames>Zahra Mardani</forenames></author></authors><title>An Accurate Measurement System Comprising of Wireless Thermometers for
  Neonate Body Temperature Monitoring</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the design and implementation of a real-time monitoring
system consisting of wireless thermometers for continuous recording of neonate
body temperature in an intensive care unit (ICU). Each wireless thermometer
incorporates an accurate semiconductor temperature sensor, a transceiver
operating on ISM frequency band (i.e., 915 MHz) as well as a microcontroller
which is used to control the thermometers functionalities including wireless
medium access (e.g., free space or body channel), transmission and reception. A
voltage regulator and a low-pass filter were also used for removing spurious
signals and environmental noise from the thermometer feed line. In order to
distinguish the reading of each thermometer from measurements performed by
other thermometers, the I-wire protocol was used. This protocol can securely
tag the temperature value by incorporating a unique ID (provided by the
manufacturer) into the packet sent wirelessly. An array of two thermometers was
implemented and successfully tested in different scenarios, namely free-space,
water (immersed thermometers) and on a volunteers wrist. Moreover, an in-house
developed computer software was used in order to visualize the readings in
addition to alerting rapid increase and high body temperature. The software
also compares the measurement results with actual values. The agreement between
the experimental data and real temperature values is reasonably acceptable and
that of the on-body testing is significant. Keywords : Temperature measurement,
Wireless thermometer, Temperature sensors, Wireless sensor networks, Wireless
communication, Monitoring, Protocols, Time measurement
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06802</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06802</id><created>2019-08-15</created><authors><author><keyname>Yuan</keyname><forenames>Binhang</forenames></author><author><keyname>Xing</keyname><forenames>Wenhui</forenames></author></authors><title>Diagnosing Cardiac Abnormalities from 12-Lead Electrocardiograms Using
  Enhanced Deep Convolutional Neural Networks</title><categories>eess.SP cs.LG eess.IV stat.ML</categories><comments>Accepted by MLMECH-MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We train an enhanced deep convolutional neural network in order to identify
eight cardiac abnormalities from the standard 12-lead electrocardiograms (ECGs)
using the dataset of 14000 ECGs. Instead of straightforwardly applying an
end-to-end deep learning approach, we find that deep convolutional neural
networks enhanced with sophisticated hand crafted features show advantages in
reducing generalization errors. Additionally, data preprocessing and
augmentation are essential since the distribution of eight cardiac
abnormalities are highly biased in the given dataset. Our approach achieves
promising generalization performance in the First China ECG Intelligent
Competition; an empirical evaluation is also provided to validate the efficacy
of our design on the competition ECG dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06803</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06803</id><created>2019-08-16</created><authors><author><keyname>Islam</keyname><forenames>Md Tamzeed</forenames></author><author><keyname>Nirjon</keyname><forenames>Shahriar</forenames></author></authors><title>Wi-Fringe: Leveraging Text Semantics in WiFi CSI-Based Device-Free Named
  Gesture Recognition</title><categories>eess.SP cs.LG stat.ML</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of adequate training data is one of the major hurdles in WiFi-based
activity recognition systems. In this paper, we propose Wi-Fringe, which is a
WiFi CSI-based device-free human gesture recognition system that recognizes
named gestures, i.e., activities and gestures that have a semantically
meaningful name in English language, as opposed to arbitrary free-form
gestures. Given a list of activities (only their names in English text), along
with zero or more training examples (WiFi CSI values) per activity, Wi-Fringe
is able to detect all activities at runtime. In other words, a subset of
activities that Wi-Fringe detects do not require any training examples at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06816</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06816</id><created>2019-08-15</created><authors><author><keyname>Dagefu</keyname><forenames>Fikadu T.</forenames></author><author><keyname>Twigg</keyname><forenames>Jeffrey N.</forenames></author><author><keyname>Rao</keyname><forenames>Chirag R.</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author></authors><title>Directional Communication Enabled by Mobile Parasitic Elements</title><categories>eess.SP</categories><comments>International Conference on Military Communications and Information
  Systems ICMCIS2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile communications in complex environments such as mega-cities is a
challenging problem that limits the ability to deploy autonomous agents in
support of operations. Building on recent progress in low frequency networking
that utilizes miniature antennas to provide persistent connectivity among
agents, we consider the design and collaborative manipulation of a distributed
robotic antenna array to provide directional communications that will enable
enhanced networking, interference rejection, and collaborative control. The use
of parasitic elements in a Yagi-Uda type array design avoids the need for
synchronization and highly accurate position control among the agents. We
utilize physics-based simulations to investigate the feasibility of using
mobile agents equipped with an excited antenna element along with a set of
support nodes having parasitic elements that adaptively configure to enhance
radiation in a desired direction. We take into account mobile node pose
uncertainty including element position and angular orientation, as well as
ground scattering effects. We pursue an optimal design approach for different
types of ground electromagnetic characteristics based on a hybrid full-wave
propagation simulation and genetic algorithm optimization. We also present
experiment with one mobile node and two static elements. The results
demonstrate the ability to achieve directional low frequency communications
that is robust to robotic pose error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06830</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06830</id><created>2019-08-12</created><authors><author><keyname>Heller</keyname><forenames>Nicholas</forenames></author><author><keyname>Rickman</keyname><forenames>Jack</forenames></author><author><keyname>Weight</keyname><forenames>Christopher</forenames></author><author><keyname>Papanikolopoulos</keyname><forenames>Nikolaos</forenames></author></authors><title>The Role of Publicly Available Data in MICCAI Papers from 2014 to 2018</title><categories>cs.LG eess.IV stat.ML</categories><comments>8 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Widely-used public benchmarks are of huge importance to computer vision and
machine learning research, especially with the computational resources required
to reproduce state of the art results quickly becoming untenable. In medical
image computing, the wide variety of image modalities and problem formulations
yields a huge task-space for benchmarks to cover, and thus the widespread
adoption of standard benchmarks has been slow, and barriers to releasing
medical data exacerbate this issue. In this paper, we examine the role that
publicly available data has played in MICCAI papers from the past five years.
We find that more than half of these papers are based on private data alone,
although this proportion seems to be decreasing over time. Additionally, we
observed that after controlling for open access publication and the release of
code, papers based on public data were cited over 60% more per year than their
private-data counterparts. Further, we found that more than 20% of papers using
public data did not provide a citation to the dataset or associated manuscript,
highlighting the &quot;second-rate&quot; status that data contributions often take
compared to theoretical ones. We conclude by making recommendations for MICCAI
policies which could help to better incentivise data sharing and move the field
toward more efficient and reproducible science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06836</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06836</id><created>2019-08-13</created><authors><author><keyname>Jiang</keyname><forenames>Weiheng</forenames></author><author><keyname>Wu</keyname><forenames>Xiaogang</forenames></author><author><keyname>Gong</keyname><forenames>Yi</forenames></author><author><keyname>Yu</keyname><forenames>Wanxin</forenames></author><author><keyname>Zhong</keyname><forenames>Xinhui</forenames></author></authors><title>Monthly electricity consumption forecasting by the fruit fly
  optimization algorithm enhanced Holt-Winters smoothing method</title><categories>eess.SP cs.NE cs.SY eess.SY</categories><comments>9 pages, 12 figures, submitted for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electricity consumption forecasting is a critical component of the
intelligent power system. And accurate monthly electricity consumption
forecasting, as one of the the medium and long term electricity consumption
forecasting problems, plays an important role in dispatching and management for
electric power systems. Although there are many studies for this problem, large
sample data set is generally required to obtain higher prediction accuracy, and
the prediction performance become worse when only a little data is available.
However, in practical, mostly we experience the problem of insufficient sample
data and how to accurately forecast the monthly electricity consumption with
limited sample data is a challenge task. The Holt-Winters exponential smoothing
method often used to forecast periodic series due to low demand for training
data and high accuracy for forecasting. In this paper, based on Holt-Winters
exponential smoothing method, we propose a hybrid forecasting model named
FOA-MHW. The main idea is that, we use fruit fly optimization algorithm to
select smoothing parameters for Holt-Winters exponential smoothing method.
Besides, electricity consumption data of a city in China is used to
comprehensively evaluate the forecasting performance of the proposed model. The
results indicate that our model can significantly improve the accuracy of
monthly electricity consumption forecasting even in the case that only a small
number of training data is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06842</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06842</id><created>2019-08-11</created><authors><author><keyname>Jameel</keyname><forenames>Furqan</forenames></author><author><keyname>Javed</keyname><forenames>Muhammad Awais</forenames></author><author><keyname>Ngo</keyname><forenames>Duy T.</forenames></author></authors><title>Performance Analysis of Cooperative V2V and V2I Communications under
  Correlated Fading</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>Internet of Vehicles (IoV), Vehicular communication, Antenna
  correlation, Stackelberg game, Vehicle-to-infrastructure (V2I),
  Vehicle-to-vehicle (V2V), Game theory, Cooperative vehicular networks</comments><journal-ref>IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative vehicular networks will play a vital role in the coming years to
implement various intelligent transportation-related applications. Both
vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications
will be needed to reliably disseminate information in a vehicular network. In
this regard, a roadside unit (RSU) equipped with multiple antennas can improve
the network capacity. While the traditional approaches assume antennas to
experience independent fading, we consider a more practical uplink scenario
where antennas at the RSU experience correlated fading. In particular, we
evaluate the packet error probability for two renowned antenna correlation
models, i.e., constant correlation (CC) and exponential correlation (EC). We
also consider intermediate cooperative vehicles for reliable communication
between the source vehicle and the RSU. Here, we derive closed-form expressions
for packet error probability which help quantify the performance variations due
to fading parameter, correlation coefficients and the number of intermediate
helper vehicles. To evaluate the optimal transmit power in this network
scenario, we formulate a Stackelberg game, wherein, the source vehicle is
treated as a buyer and the helper vehicles are the sellers. The optimal
solutions for the asking price and the transmit power are devised which
maximize the utility functions of helper vehicles and the source vehicle,
respectively. We verify our mathematical derivations by extensive simulations
in MATLAB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06843</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06843</id><created>2019-08-01</created><authors><author><keyname>Exarchakis</keyname><forenames>Georgios</forenames></author><author><keyname>Bornschein</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Sheikh</keyname><forenames>Abdul-Saboor</forenames></author><author><keyname>Dai</keyname><forenames>Zhenwen</forenames></author><author><keyname>Henniges</keyname><forenames>Marc</forenames></author><author><keyname>Drefs</keyname><forenames>Jakob</forenames></author><author><keyname>L&#xfc;cke</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>ProSper -- A Python Library for Probabilistic Sparse Coding with
  Non-Standard Priors and Superpositions</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ProSper is a python library containing probabilistic algorithms to learn
dictionaries. Given a set of data points, the implemented algorithms seek to
learn the elementary components that have generated the data. The library
widens the scope of dictionary learning approaches beyond implementations of
standard approaches such as ICA, NMF or standard L1 sparse coding. The
implemented algorithms are especially well-suited in cases when data consist of
components that combine non-linearly and/or for data requiring flexible prior
distributions. Furthermore, the implemented algorithms go beyond standard
approaches by inferring prior and noise parameters of the data, and they
provide rich a-posteriori approximations for inference. The library is designed
to be extendable and it currently includes: Binary Sparse Coding (BSC), Ternary
Sparse Coding (TSC), Discrete Sparse Coding (DSC), Maximal Causes Analysis
(MCA), Maximum Magnitude Causes Analysis (MMCA), and Gaussian Sparse Coding
(GSC, a recent spike-and-slab sparse coding approach). The algorithms are
scalable due to a combination of variational approximations and
parallelization. Implementations of all algorithms allow for parallel execution
on multiple CPUs and multiple machines for medium to large-scale applications.
Typical large-scale runs of the algorithms can use hundreds of CPUs to learn
hundreds of dictionary elements from data with tens of millions of
floating-point numbers such that models with several hundred thousand
parameters can be optimized. The library is designed to have minimal
dependencies and to be easy to use. It targets users of dictionary learning
algorithms and Machine Learning researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06844</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06844</id><created>2019-08-12</created><authors><author><keyname>Abdalzaher</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Muta</keyname><forenames>Osamu</forenames></author></authors><title>Employing Game Theory and TDMA Protocol to Enhance Security and Manage
  Power Consumption in WSNs-based Cognitive Radio</title><categories>eess.SP cs.GT</categories><comments>14 pages 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of wireless sensor networks (WSNs) is the significant
incentive to contribute in the vulnerable applications such as cognitive radio
(CR). This paper proposes a Stackelberg game approach to enhance the WSN-based
CR security against the spectrum sensing data falsification (SSDF) attack and
conserve the consequent lost power consumption. The attack aims to corrupt the
spectrum decision by imposing interference power to the delivered reports from
the sensor nodes (SNs) to the fusion center (FC) to make a protection level
below a specific threshold. The proposed model utilizes the intelligent
Stackelberg game features along with the matched filter (MF) to maximize the
number of protected reports sent by the SNs to the FC leading to accurate
decision of the spectrum status. Furthermore, the TDMA protocol is utilized to
resolve the complexity of employing MF for the spectrum detection to avoid the
collision between the delivered reports. The proposed model aims to enhance the
number of correctly received reports at the FC, and hence manage the lost
energy of reports retransmission due to the malicious attack effect. Moreover,
the model can conserve the lost power of the failure communication attempts due
to the SSDF attack impact. Simulation results indicate the improved performance
of the proposed protection model along with the MF over the six different
environments against the SSDF attack as compared to two defense schemes,
namely, random and equal weight defense strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06845</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06845</id><created>2019-08-01</created><authors><author><keyname>Shlezinger</keyname><forenames>Nir</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Deep Task-Based Quantization</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantizers play a critical role in digital signal processing systems. Recent
works have shown that the performance of quantization systems acquiring
multiple analog signals using scalar analog-to-digital converters (ADCs) can be
significantly improved by properly processing the analog signals prior to
quantization. However, the design of such hybrid quantizers is quite complex,
and their implementation requires complete knowledge of the statistical model
of the analog signal, which may not be available in practice. In this work we
design data-driven task-oriented quantization systems with scalar ADCs, which
determine how to map an analog signal into its digital representation using
deep learning tools. These representations are designed to facilitate the task
of recovering underlying information from the quantized signals, which can be a
set of parameters to estimate, or alternatively, a classification task. By
utilizing deep learning, we circumvent the need to explicitly recover the
system model and to find the proper quantization rule for it. Our main target
application is multiple-input multiple-output (MIMO) communication receivers,
which simultaneously acquire a set of analog signals, and are commonly subject
to constraints on the number of bits. Our results indicate that, in a MIMO
channel estimation setup, the proposed deep task-bask quantizer is capable of
approaching the optimal performance limits dictated by indirect rate-distortion
theory, achievable using vector quantizers and requiring complete knowledge of
the underlying statistical model. Furthermore, for a symbol detection scenario,
it is demonstrated that the proposed approach can realize reliable
bit-efficient hybrid MIMO receivers capable of setting their quantization rule
in light of the task, e.g., to minimize the bit error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06846</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06846</id><created>2019-07-31</created><authors><author><keyname>Gao</keyname><forenames>Guangyu</forenames></author><author><keyname>Liu</keyname><forenames>Naijin</forenames></author></authors><title>A photonic-assisted method based on the MDA technique for the frequency
  estimation precision improvement</title><categories>eess.SP</categories><comments>3 pages,5 figs,conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel photonics-assisted method based on presampling and MDA technique is
proposed for significantly improving the frequency estimation precision without
introducing other complex algorithms. This method is also compatible with
existing FFT-based high-precision estimation algorithms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06847</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06847</id><created>2019-07-30</created><updated>2019-09-06</updated><authors><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Dhillon</keyname><forenames>Harpreet S.</forenames></author><author><keyname>Reed</keyname><forenames>Jeffery H.</forenames></author></authors><title>Federated Learning for Wireless Communications: Motivation,
  Opportunities and Challenges</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing interest in the wireless communications community to
complement the traditional model-based design approaches with data-driven
machine learning (ML)-based solutions. While conventional ML approaches rely on
the assumption of having the data and processing heads in a central entity,
this is not always feasible in wireless communications applications because of
the inaccessibility of private data and large communication overhead required
to transmit raw data to central ML processors. As a result, decentralized ML
approaches that keep the data where it is generated are much more appealing.
Owing to its privacy-preserving nature, federated learning is particularly
relevant for many wireless applications, especially in the context of fifth
generation (5G) networks. In this article, we provide an accessible
introduction to the general idea of federated learning, discuss several
possible applications in 5G networks, and describe key technical challenges and
open problems for future research on federated learning in the context of
wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06848</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06848</id><created>2019-07-26</created><updated>2019-12-03</updated><authors><author><keyname>Boull&#xe9;</keyname><forenames>Nicolas</forenames></author><author><keyname>Dallas</keyname><forenames>Vassilios</forenames></author><author><keyname>Nakatsukasa</keyname><forenames>Yuji</forenames></author><author><keyname>Samaddar</keyname><forenames>D.</forenames></author></authors><title>Classification of chaotic time series with deep learning</title><categories>eess.SP cs.LG math.DS nlin.CD physics.comp-ph stat.ML</categories><comments>15 pages, 13 figures, accepted in Physica D: Nonlinear Phenomena</comments><doi>10.1016/j.physd.2019.132261</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use standard deep neural networks to classify univariate time series
generated by discrete and continuous dynamical systems based on their chaotic
or non-chaotic behaviour. Our approach to circumvent the lack of precise models
for some of the most challenging real-life applications is to train different
neural networks on a data set from a dynamical system with a basic or
low-dimensional phase space and then use these networks to classify univariate
time series of a dynamical system with more intricate or high-dimensional phase
space. We illustrate this generalisation approach using the logistic map, the
sine-circle map, the Lorenz system, and the Kuramoto--Sivashinsky equation. We
observe that a convolutional neural network without batch normalization layers
outperforms state-of-the-art neural networks for time series classification and
is able to generalise and classify time series as chaotic or not with high
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06849</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06849</id><created>2019-07-25</created><authors><author><keyname>Liu</keyname><forenames>Lei</forenames></author><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Pei</keyname><forenames>Qingqi</forenames></author><author><keyname>Maharjan</keyname><forenames>Sabita</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author></authors><title>Vehicular Edge Computing and Networking: A Survey</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As one key enabler of Intelligent Transportation System (ITS), Vehicular Ad
Hoc Network (VANET) has received remarkable interest from academia and
industry. The emerging vehicular applications and the exponential growing data
have naturally led to the increased needs of communication, computation and
storage resources, and also to strict performance requirements on response time
and network bandwidth. In order to deal with these challenges, Mobile Edge
Computing (MEC) is regarded as a promising solution. MEC pushes powerful
computational and storage capacities from the remote cloud to the edge of
networks in close proximity of vehicular users, which enables low latency and
reduced bandwidth consumption. Driven by the benefits of MEC, many efforts have
been devoted to integrating vehicular networks into MEC, thereby forming a
novel paradigm named as Vehicular Edge Computing (VEC). In this paper, we
provide a comprehensive survey of state-of-art research on VEC. First of all,
we provide an overview of VEC, including the introduction, architecture, key
enablers, advantages, challenges as well as several attractive application
scenarios. Then, we describe several typical research topics where VEC is
applied. After that, we present a careful literature review on existing
research work in VEC by classification. Finally, we identify open research
issues and discuss future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06851</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06851</id><created>2019-08-14</created><authors><author><keyname>Anagnostopoulos</keyname><forenames>Grigorios G.</forenames></author><author><keyname>Kalousis</keyname><forenames>Alexandros</forenames></author></authors><title>A Reproducible Analysis of RSSI Fingerprinting for Outdoor Localization
  Using Sigfox: Preprocessing and Hyperparameter Tuning</title><categories>eess.SP cs.LG stat.ML</categories><comments>Preprint of a paper to be presented in IPIN2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingerprinting techniques, which are a common method for indoor localization,
have been recently applied with success into outdoor settings. Particularly,
the communication signals of Low Power Wide Area Networks (LPWAN) such as
Sigfox, have been used for localization. In this rather recent field of study,
not many publicly available datasets, which would facilitate the consistent
comparison of different positioning systems, exist so far. In the current
study, a published dataset of RSSI measurements on a Sigfox network deployed in
Antwerp, Belgium is used to analyse the appropriate selection of preprocessing
steps and to tune the hyperparameters of a kNN fingerprinting method.
Initially, the tuning of hyperparameter k for a variety of distance metrics,
and the selection of efficient data transformation schemes, proposed by
relevant works, is presented. In addition, accuracy improvements are achieved
in this study, by a detailed examination of the appropriate adjustment of the
parameters of the data transformation schemes tested, and of the handling of
out of range values. With the appropriate tuning of these factors, the achieved
mean localization error was 298 meters, and the median error was 109 meters. To
facilitate the reproducibility of tests and comparability of results, the code
and train/validation/test split used in this study are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06854</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06854</id><created>2019-08-03</created><authors><author><keyname>Natroshvili</keyname><forenames>K</forenames></author><author><keyname>Loffeld</keyname><forenames>O</forenames></author><author><keyname>Nies</keyname><forenames>H</forenames></author><author><keyname>Ortiz</keyname><forenames>A. M</forenames></author></authors><title>First steps to bistatic focusing</title><categories>eess.SP</categories><comments>2005 IEEE International Geoscience and Remote Sensing Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although this work is a bit theoretical and contains lots of derivations, it
leads to very explicit practical results in bistatic focusing. Our approach is
based on Loffelds bistatic formula describing the point targets reference
spectrum for arbitrary bistatic configuration. Based on various simulations the
validity of LBF for both airborne and spaceborne configurations is
demonstrated. Focusing for special bistatic configurations like: Tandem and
Translationally Invariant constellations is considered. The focusing for the
Tandem configuration is solved analytically. Focusing in the TI case is
realized by blockwise processing. All focusing algorithms are developed in IDL
and adequate simulation results are presented. In the end of the paper outlines
the conceptual solution of the most difficult bistatic General Case and
presents some first focusing results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06855</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06855</id><created>2019-08-06</created><authors><author><keyname>Shao</keyname><forenames>Wenyi</forenames></author></authors><title>A Phase Shift and Sum Method for UWB Radar Imaging in Dispersive Media</title><categories>eess.SP eess.IV</categories><comments>10 pages</comments><journal-ref>IEEE Trans Microw Theory Techn 2019</journal-ref><doi>10.1109/TMTT.2019.2891539</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A phase shift and sum (PSAS) algorithm to image objects in dispersive media
is presented. The algorithm compensates the phase shift of the scattered field
from the receiver to the source for each frequency component in an
ultrawideband (UWB) and then integrates all the frequency responses. This
method resolves the multispeed and multipath issue when UWB signals propagate
in dispersive media. In addition, a multipath effect due to refraction on a
curved boundary is also explored. By collecting data using a customized
microwave measurement system of two different objects placed in a plastic
graduated cylinder filled with glycerin, along the measured dielectric
parameters of glycerin (a dispersive medium), highquality reconstructed images
are formed using PSAS. Quantitative and qualitative comparisons with two other
traditional time-shift radar-based microwave imaging algorithms for the same
objects under test demonstrate the advantages of PSAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06856</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06856</id><created>2019-08-09</created><authors><author><keyname>Chung</keyname><forenames>Yu-Min</forenames></author><author><keyname>Hu</keyname><forenames>Chuan-Shen</forenames></author><author><keyname>Lo</keyname><forenames>Yu-Lun</forenames></author><author><keyname>Wu</keyname><forenames>Hau-Tieng</forenames></author></authors><title>A persistent homology approach to heart rate variability analysis with
  an application to sleep-wake classification</title><categories>eess.SP cs.LG physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Persistent homology (PH) is a recently developed theory in the field of
algebraic topology. It is an effective and robust tool to study shapes of
datasets and has been widely applied. We demonstrate a general pipeline to
apply PH to study time series; particularly the heart rate variability (HRV).
First, we study the shapes of time series in two different ways -- sub-level
set and Taken's lag map. Second, we propose a systematic approach to
summarize/vectorize persistence diagrams, a companion tool of PH. To
demonstrate our proposed method, we apply these tools to the HRV analysis and
the sleep-wake, REM-NREM (rapid eyeball movement and non rapid eyeball
movement) and sleep-REM-NREM classification problems. The proposed algorithm is
evaluated on three different datasets via the cross-database validation scheme.
The performance of our approach is comparable with the state-of-the-art
algorithms, and are consistent throughout these different datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06857</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06857</id><created>2019-08-09</created><authors><author><keyname>Zhou</keyname><forenames>Yuxi</forenames></author><author><keyname>Hong</keyname><forenames>Shenda</forenames></author><author><keyname>Shang</keyname><forenames>Junyuan</forenames></author><author><keyname>Wu</keyname><forenames>Meng</forenames></author><author><keyname>Wang</keyname><forenames>Qingyun</forenames></author><author><keyname>Li</keyname><forenames>Hongyan</forenames></author><author><keyname>Xie</keyname><forenames>Junqing</forenames></author></authors><title>K-margin-based Residual-Convolution-Recurrent Neural Network for Atrial
  Fibrillation Detection</title><categories>eess.SP</categories><comments>IJCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Atrial Fibrillation (AF) is an abnormal heart rhythm which can trigger
cardiac arrest and sudden death. Nevertheless, its interpretation is mostly
done by medical experts due to high error rates of computerized interpretation.
One study found that only about 66% of AF were correctly recognized from noisy
ECGs. This is in part due to insufficient training data, class skewness, as
well as semantical ambiguities caused by noisy segments in an ECG record. In
this paper, we propose a K-margin-based Residual-Convolution-Recurrent neural
network (K-margin-based RCR-net) for AF detection from noisy ECGs. In detail, a
skewness-driven dynamic augmentation method is employed to handle the problems
of data inadequacy and class imbalance. A novel RCR-net is proposed to
automatically extract both long-term rhythm-level and local heartbeat-level
characters. Finally, we present a K-margin-based diagnosis model to
automatically focus on the most important parts of an ECG record and handle
noise by naturally exploiting expected consistency among the segments
associated for each record. The experimental results demonstrate that the
proposed method with 0.8125 F1NAOP score outperforms all state-of-the-art deep
learning methods for AF detection task by 6.8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06865</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06865</id><created>2019-08-13</created><authors><author><keyname>Das</keyname><forenames>Anup</forenames></author><author><keyname>Catthoor</keyname><forenames>Francky</forenames></author><author><keyname>Schaafsma</keyname><forenames>Siebren</forenames></author></authors><title>Heartbeat Classification in Wearables Using Multi-layer Perceptron and
  Time-Frequency Joint Distribution of ECG</title><categories>eess.SP cs.LG</categories><comments>6 pages, 7 figures, published in IEEE/ACM International Conference on
  Connected Health: Applications, Systems and Engineering Technologies (CHASE)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Heartbeat classification using electrocardiogram (ECG) data is a vital
assistive technology for wearable health solutions. We propose heartbeat
feature classification based on a novel sparse representation using
time-frequency joint distribution of ECG. Fundamental to this is a multi-layer
perceptron, which incorporates these signatures to detect cardiac arrhythmia.
This approach is validated with ECG data from MIT-BIH arrhythmia database.
Results show that our approach has an average 95.7% accuracy, an improvement of
22% over state-of-the-art approaches. Additionally, ECG sparse distributed
representations generates only 3.7% false negatives, reduction of 89% with
respect to existing ECG signal classification techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06866</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06866</id><created>2019-08-12</created><authors><author><keyname>Hisham</keyname><forenames>Anver</forenames></author><author><keyname>Str&#xf6;m</keyname><forenames>Erik G.</forenames></author><author><keyname>Br&#xe4;nnstr&#xf6;m</keyname><forenames>Fredrik</forenames></author></authors><title>Radio Resource Management for V2V Multihop Communication Considering
  Adjacent Channel Interference</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This paper investigate joint scheduling and power control for V2V multicast
allowing multihop communication. The effects of both co-channel interference
and adjacent channel interference are considered. First, we solve the problem
with the objective of maximizing the throughput and connectivity of vehicles in
the network. Then extend the same problem formulation to include the objective
of minimizing the latency and the average age of information (AoI), which is
the age of the latest received message. In order to account for fairness, we
also show the problem formulation to maximize the worst-case throughput and
connectivity. All the problems are formulated as mixed Boolean linear
programming problems, which allows computation of optimal solutions.
Furthermore, we consider the error probability of a link failure in all the
problem formulations and accommodate the probability requirements for
satisfying a certain throughput/connectivity/latency/AoI. In order to support a
large V2V network, a clustering algorithm is proposed whose computational
complexity scale well with the network size. To handle the case of zero channel
information at the scheduler, a multihop distributed scheduling scheme is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06868</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06868</id><created>2019-08-19</created><authors><author><keyname>Bontonou</keyname><forenames>Myriam</forenames><affiliation>IMT Atlantique - ELEC, MILA</affiliation></author><author><keyname>Lassance</keyname><forenames>Carlos</forenames><affiliation>IMT Atlantique - ELEC, MILA</affiliation></author><author><keyname>Gripon</keyname><forenames>Vincent</forenames><affiliation>IMT Atlantique - ELEC, MILA</affiliation></author><author><keyname>Farrugia</keyname><forenames>Nicolas</forenames><affiliation>IMT Atlantique - ELEC</affiliation></author></authors><title>Comparing linear structure-based and data-driven latent spatial
  representations for sequence prediction</title><categories>eess.SP cs.LG</categories><proxy>ccsd</proxy><journal-ref>Wavelets and Sparsity XVIII, Aug 2019, San Diego, United States</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the future of Graph-supported Time Series (GTS) is a key challenge
in many domains, such as climate monitoring, finance or neuroimaging. Yet it is
a highly difficult problem as it requires to account jointly for time and graph
(spatial) dependencies. To simplify this process, it is common to use a
two-step procedure in which spatial and time dependencies are dealt with
separately. In this paper, we are interested in comparing various linear
spatial representations, namely structure-based ones and data-driven ones, in
terms of how they help predict the future of GTS. To that end, we perform
experiments with various datasets including spontaneous brain activity and raw
videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06884</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06884</id><created>2019-08-19</created><authors><author><keyname>Shin</keyname><forenames>Hyo-Sang</forenames></author><author><keyname>He</keyname><forenames>Shaoming</forenames></author><author><keyname>Tsourdos</keyname><forenames>Antonios</forenames></author></authors><title>Computational Flight Control: A Domain-Knowledge-Aided Deep
  Reinforcement Learning Approach</title><categories>cs.AI cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This papers aims to examine the potential of using the emerging deep
reinforcement learning techniques in flight control. Instead of learning from
scratch, the autopilot structure is fixed as typical three-loop autopilot and
deep reinforcement learning is utilised to learn the autopilot gains. This
domain-knowledge-aided approach is proved to significantly improve the learning
efficiency. To solve the flight control problem, we then formulate a Markovian
decision process with a proper reward function that enable the application of
reinforcement learning theory. The state-of-the-art deep deterministic policy
gradient algorithm is utilised to learn an action policy that maps the observed
states to the autopilot gains. Extensive empirical numerical simulations are
performed to validate the proposed computational control algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06907</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06907</id><created>2019-08-19</created><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Probability Estimation with Truncated Inverse Binomial Sampling</title><categories>math.ST cs.SY eess.SY stat.ML stat.TH</categories><comments>14 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a general theory of truncated inverse binomial
sampling. In this theory, the fixed-size sampling and inverse binomial sampling
are accommodated as special cases. In particular, the classical
Chernoff-Hoeffding bound is an immediate consequence of the theory. Moreover,
we propose a rigorous and efficient method for probability estimation, which is
an adaptive Monte Carlo estimation method based on truncated inverse binomial
sampling. Our proposed method of probability estimation can be orders of
magnitude more efficient as compared to existing methods in literature and
widely used software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06912</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06912</id><created>2019-08-19</created><authors><author><keyname>Zhou</keyname><forenames>Zongwei</forenames></author><author><keyname>Sodha</keyname><forenames>Vatsal</forenames></author><author><keyname>Siddiquee</keyname><forenames>Md Mahfuzur Rahman</forenames></author><author><keyname>Feng</keyname><forenames>Ruibin</forenames></author><author><keyname>Tajbakhsh</keyname><forenames>Nima</forenames></author><author><keyname>Gotway</keyname><forenames>Michael B.</forenames></author><author><keyname>Liang</keyname><forenames>Jianming</forenames></author></authors><title>Models Genesis: Generic Autodidactic Models for 3D Medical Image
  Analysis</title><categories>eess.IV cs.CV</categories><comments>International Conference on Medical Image Computing and Computer
  Assisted Intervention (MICCAI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transfer learning from natural image to medical image has established as one
of the most practical paradigms in deep learning for medical image analysis.
However, to fit this paradigm, 3D imaging tasks in the most prominent imaging
modalities (e.g., CT and MRI) have to be reformulated and solved in 2D, losing
rich 3D anatomical information and inevitably compromising the performance. To
overcome this limitation, we have built a set of models, called Generic
Autodidactic Models, nicknamed Models Genesis, because they are created ex
nihilo (with no manual labeling), self-taught (learned by self-supervision),
and generic (served as source models for generating application-specific target
models). Our extensive experiments demonstrate that our Models Genesis
significantly outperform learning from scratch in all five target 3D
applications covering both segmentation and classification. More importantly,
learning a model from scratch simply in 3D may not necessarily yield
performance better than transfer learning from ImageNet in 2D, but our Models
Genesis consistently top any 2D approaches including fine-tuning the models
pre-trained from ImageNet as well as fine-tuning the 2D versions of our Models
Genesis, confirming the importance of 3D anatomical information and
significance of our Models Genesis for 3D medical imaging. This performance is
attributed to our unified self-supervised learning framework, built on a simple
yet powerful observation: the sophisticated yet recurrent anatomy in medical
images can serve as strong supervision signals for deep models to learn common
anatomical representation automatically via self-supervision. As open science,
all pre-trained Models Genesis are available at
https://github.com/MrGiovanni/ModelsGenesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06925</identifier>
 <datestamp>2019-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06925</id><created>2019-08-19</created><updated>2019-12-11</updated><authors><author><keyname>Borsoi</keyname><forenames>Ricardo Augusto</forenames></author><author><keyname>Imbiriba</keyname><forenames>Tales</forenames></author><author><keyname>Bermudez</keyname><forenames>Jos&#xe9; Carlos Moreira</forenames></author><author><keyname>Richard</keyname><forenames>C&#xe9;dric</forenames></author></authors><title>A Blind Multiscale Spatial Regularization Framework for Kernel-based
  Spectral Unmixing</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introducing spatial prior information in hyperspectral imaging (HSI) analysis
has led to an overall improvement of the performance of many HSI methods
applied for denoising, classification, and unmixing. Extending such
methodologies to nonlinear settings is not always straightforward, specially
for unmixing problems where the consideration of spatial relationships between
neighboring pixels might comprise intricate interactions between their
fractional abundances and nonlinear contributions. In this paper, we consider a
multiscale regularization strategy for nonlinear spectral unmixing with
kernels. The proposed methodology splits the unmixing problem into two
sub-problems at two different spatial scales: a coarse scale containing
low-dimensional structures, and the original fine scale. The coarse spatial
domain is defined using superpixels that result from a multiscale
transformation. Spectral unmixing is then formulated as the solution of
quadratically constrained optimization problems, which are solved efficiently
by exploring their strong duality and a reformulation of their dual cost
functions in the form of root-finding problems. Furthermore, we employ a
theory-based statistical framework to devise a consistent strategy to estimate
all required parameters, including both the regularization parameters of the
algorithm and the number of superpixels of the transformation, resulting in a
truly blind (from the parameters setting perspective) unmixing method.
Experimental results attest the superior performance of the proposed method
when comparing with other, state-of-the-art, related strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06933</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06933</id><created>2019-08-19</created><updated>2019-10-08</updated><authors><author><keyname>Hatamizadeh</keyname><forenames>Ali</forenames></author><author><keyname>Hoogi</keyname><forenames>Assaf</forenames></author><author><keyname>Sengupta</keyname><forenames>Debleena</forenames></author><author><keyname>Lu</keyname><forenames>Wuyue</forenames></author><author><keyname>Wilcox</keyname><forenames>Brian</forenames></author><author><keyname>Rubin</keyname><forenames>Daniel</forenames></author><author><keyname>Terzopoulos</keyname><forenames>Demetri</forenames></author></authors><title>DALS: Deep Active Lesion Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted to Machine Learning in Medical Imaging (MLMI 2019)</comments><journal-ref>MLMI 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lesion segmentation is an important problem in computer-assisted diagnosis
that remains challenging due to the prevalence of low contrast, irregular
boundaries that are unamenable to shape priors. We introduce Deep Active Lesion
Segmentation (DALS), a fully automated segmentation framework for that
leverages the powerful nonlinear feature extraction abilities of fully
Convolutional Neural Networks (CNNs) and the precise boundary delineation
abilities of Active Contour Models (ACMs). Our DALS framework benefits from an
improved level-set ACM formulation with a per-pixel-parameterized energy
functional and a novel multiscale encoder-decoder CNN that learns an
initialization probability map along with parameter maps for the ACM. We
evaluate our lesion segmentation model on a new Multiorgan Lesion Segmentation
(MLS) dataset that contains images of various organs, including brain, liver,
and lung, across different imaging modalities---MR and CT. Our results
demonstrate favorable performance compared to competing methods, especially for
small training datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06943</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06943</id><created>2019-08-15</created><authors><author><keyname>H&#xe4;gele</keyname><forenames>Miriam</forenames></author><author><keyname>Seegerer</keyname><forenames>Philipp</forenames></author><author><keyname>Lapuschkin</keyname><forenames>Sebastian</forenames></author><author><keyname>Bockmayr</keyname><forenames>Michael</forenames></author><author><keyname>Samek</keyname><forenames>Wojciech</forenames></author><author><keyname>Klauschen</keyname><forenames>Frederick</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Klaus-Robert</forenames></author><author><keyname>Binder</keyname><forenames>Alexander</forenames></author></authors><title>Resolving challenges in deep learning-based analyses of
  histopathological images using explanation methods</title><categories>eess.IV cs.CV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has recently gained popularity in digital pathology due to its
high prediction quality. However, the medical domain requires explanation and
insight for a better understanding beyond standard quantitative performance
evaluation. Recently, explanation methods have emerged, which are so far still
rarely used in medicine. This work shows their application to generate heatmaps
that allow to resolve common challenges encountered in deep learning-based
digital histopathology analyses. These challenges comprise biases typically
inherent to histopathology data. We study binary classification tasks of tumor
tissue discrimination in publicly available haematoxylin and eosin slides of
various tumor entities and investigate three types of biases: (1) biases which
affect the entire dataset, (2) biases which are by chance correlated with class
labels and (3) sampling biases. While standard analyses focus on patch-level
evaluation, we advocate pixel-wise heatmaps, which offer a more precise and
versatile diagnostic instrument and furthermore help to reveal biases in the
data. This insight is shown to not only detect but also to be helpful to remove
the effects of common hidden biases, which improves generalization within and
across datasets. For example, we could see a trend of improved area under the
receiver operating characteristic curve by 5% when reducing a labeling bias.
Explanation techniques are thus demonstrated to be a helpful and highly
relevant tool for the development and the deployment phases within the life
cycle of real-world applications in digital pathology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06948</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06948</id><created>2019-08-16</created><updated>2019-08-22</updated><authors><author><keyname>Leclerc</keyname><forenames>Sarah</forenames></author><author><keyname>Smistad</keyname><forenames>Erik</forenames></author><author><keyname>Pedrosa</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>&#xd8;stvik</keyname><forenames>Andreas</forenames></author><author><keyname>Cervenansky</keyname><forenames>Frederic</forenames></author><author><keyname>Espinosa</keyname><forenames>Florian</forenames></author><author><keyname>Espeland</keyname><forenames>Torvald</forenames></author><author><keyname>Berg</keyname><forenames>Erik Andreas Rye</forenames></author><author><keyname>Jodoin</keyname><forenames>Pierre-Marc</forenames></author><author><keyname>Grenier</keyname><forenames>Thomas</forenames></author><author><keyname>Lartizien</keyname><forenames>Carole</forenames></author><author><keyname>D'hooge</keyname><forenames>Jan</forenames></author><author><keyname>Lovstakken</keyname><forenames>Lasse</forenames></author><author><keyname>Bernard</keyname><forenames>Olivier</forenames></author></authors><title>Deep Learning for Segmentation using an Open Large-Scale Dataset in 2D
  Echocardiography</title><categories>eess.IV</categories><doi>10.1109/TMI.2019.2900516</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Delineation of the cardiac structures from 2D echocardiographic images is a
common clinical task to establish a diagnosis. Over the past decades, the
automation of this task has been the subject of intense research. In this
paper, we evaluate how far the state-of-the-art encoder-decoder deep
convolutional neural network methods can go at assessing 2D echocardiographic
images, i.e segmenting cardiac structures as well as estimating clinical
indices, on a dataset especially designed to answer this objective. We
therefore introduce the Cardiac Acquisitions for Multi-structure Ultrasound
Segmentation (CAMUS) dataset, the largest publicly-available and
fully-annotated dataset for the purpose of echocardiographic assessment. The
dataset contains two and four-chamber acquisitions from 500 patients with
reference measurements from one cardiologist on the full dataset and from three
cardiologists on a fold of 50 patients. Results show that encoder-decoder based
architectures outperform state-of-the-art non-deep learning methods and
faithfully reproduce the expert analysis for the end-diastolic and end-systolic
left ventricular volumes, with a mean correlation of 0.95 and an absolute mean
error of 9.5 ml. Concerning the ejection fraction of the left ventricle,
results are more contrasted with a mean correlation coefficient of 0.80 and an
absolute mean error of 5.6 %. Although these results are below the
inter-observer scores, they remain slightly worse than the intra-observer's
ones. Based on this observation, areas for improvement are defined, which open
the door for accurate and fully-automatic analysis of 2D echocardiographic
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06965</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06965</id><created>2019-08-16</created><updated>2019-08-29</updated><authors><author><keyname>Siddiquee</keyname><forenames>Md Mahfuzur Rahman</forenames></author><author><keyname>Zhou</keyname><forenames>Zongwei</forenames></author><author><keyname>Tajbakhsh</keyname><forenames>Nima</forenames></author><author><keyname>Feng</keyname><forenames>Ruibin</forenames></author><author><keyname>Gotway</keyname><forenames>Michael B.</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Liang</keyname><forenames>Jianming</forenames></author></authors><title>Learning Fixed Points in Generative Adversarial Networks: From
  Image-to-Image Translation to Disease Detection and Localization</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks (GANs) have ushered in a revolution in
image-to-image translation. The development and proliferation of GANs raises an
interesting question: can we train a GAN to remove an object, if present, from
an image while otherwise preserving the image? Specifically, can a GAN
&quot;virtually heal&quot; anyone by turning his medical image, with an unknown health
status (diseased or healthy), into a healthy one, so that diseased regions
could be revealed by subtracting those two images? Such a task requires a GAN
to identify a minimal subset of target pixels for domain translation, an
ability that we call fixed-point translation, which no GAN is equipped with
yet. Therefore, we propose a new GAN, called Fixed-Point GAN, trained by (1)
supervising same-domain translation through a conditional identity loss, and
(2) regularizing cross-domain translation through revised adversarial, domain
classification, and cycle consistency loss. Based on fixed-point translation,
we further derive a novel framework for disease detection and localization
using only image-level annotation. Qualitative and quantitative evaluations
demonstrate that the proposed method outperforms the state of the art in
multi-domain image-to-image translation and that it surpasses predominant
weakly-supervised localization methods in both disease detection and
localization. Implementation is available at
https://github.com/jlianglab/Fixed-Point-GAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.06969</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.06969</id><created>2019-08-18</created><authors><author><keyname>Nakamura</keyname><forenames>Eita</forenames></author><author><keyname>Yoshii</keyname><forenames>Kazuyoshi</forenames></author></authors><title>Music Transcription Based on Bayesian Piece-Specific Score Models
  Capturing Repetitions</title><categories>cs.SD cs.AI cs.LG eess.AS</categories><comments>17 pages, 9 figures, version submitted to IEEE/ACM TASLP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most work on models for music transcription has focused on describing local
sequential dependence of notes in musical scores and failed to capture their
global repetitive structure, which can be a useful guide for transcribing
music. Focusing on the rhythm, we formulate several classes of Bayesian Markov
models of musical scores that describe repetitions indirectly by sparse
transition probabilities of notes or note patterns. This enables us to
construct piece-specific models for unseen scores with unfixed repetitive
structure and to derive tractable inference algorithms. Moreover, to describe
approximate repetitions, we explicitly incorporate a process of modifying the
repeated notes/note patterns. We apply these models as a prior music language
model for rhythm transcription, where piece-specific score models are inferred
from performed MIDI data by unsupervised learning, in contrast to the
conventional supervised construction of score models. Evaluations using vocal
melodies of popular music showed that the Bayesian models improved the
transcription accuracy for most of the tested model types, indicating the
universal efficacy of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07045</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07045</id><created>2019-08-19</created><authors><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author><author><keyname>Lim</keyname><forenames>Felicia S. C.</forenames></author><author><keyname>Chinen</keyname><forenames>Michael</forenames></author><author><keyname>Skoglund</keyname><forenames>Jan</forenames></author></authors><title>Salient Speech Representations Based on Cloned Networks</title><categories>eess.AS cs.SD</categories><comments>Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define salient features as features that are shared by signals that are
defined as being equivalent by a system designer. The definition allows the
designer to contribute qualitative information. We aim to find salient features
that are useful as conditioning for generative networks. We extract salient
features by jointly training a set of clones of an encoder network. Each
network clone receives as input a different signal from a set of equivalent
signals. The objective function encourages the network clones to map their
input into a set of features that is identical across the clones. It
additionally encourages feature independence and, optionally, reconstruction of
a desired target signal by a decoder. As an application, we train a system that
extracts a time-sequence of feature vectors of speech and uses it as a
conditioning of a WaveNet generative system, facilitating both coding and
enhancement.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="8000" completeListSize="16166">4250076|9001</resumptionToken>
</ListRecords>
</OAI-PMH>
